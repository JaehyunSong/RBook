# データハンドリング [要約] {#sec-datahandling2}

```{r}
#| include: false
source("_common.R")
pacman::p_load(tidyverse, gt, gtExtras)
```

前章ではデータの一部（subset）を抽出する方法について説明しましたが、本章はデータを拡張する、あるいは全く別のデータが得られるような処理について解説します。後者は主に元のデータを要約し（記述統計量）、その結果を出力する方法で、前者はデータ内の変数に基づき、指定された計算を行った結果を新しい列として追加する方法です。今回も[前章と同じデータ](Data/Ramen.csv)を使用します。

```{r}
#| message: false
pacman::p_load(tidyverse)
# データのパスは適宜修正すること
# 文字化けが生じる場合、以下のコードに書き換える。
# df <- read_csv("Data/Ramen.csv", locale = locale(encoding = "utf8"))
df <- read_csv("Data/Ramen.csv")
```

データの詳細については第[-@sec-handling1-select]章を参照してください。

## 記述統計量の計算 {#sec-handling2-summarise}

### `summarise()`による記述統計量の計算

ある変数の平均値や標準偏差、最小値、最大値などの記述統計量（要約統計量）を計算することも可能です。これは`summarize()`または`summarise()`関数を使いますが、この関数は後で紹介する`group_by()`関数と組み合わせることで力を発揮します。ここではグルーピングを考えずに、全データの記述統計量を計算する方法を紹介します。

`summarise()`関数の使い方は以下の通りです。

```{r}
#| eval: false
# summarise()関数の使い方
データフレーム名 |>
  summarise(新しい変数名 = 関数名(計算の対象となる変数名))
```

もし、`Score`変数の平均値を計算し、その結果を`Mean`という列にしたい場合は以下のようなコードになります。

```{r}
df |>
  summarise(Mean = mean(Score))
```

ただし、`mean()`関数は欠損値が含まれるベクトルの場合、`NA`を返します。この場合方法は2つ考えられます。

1. `filter()`関数を使って`Score`が欠損しているケースを予め除去する。
2. `na.rm`引数を指定し、欠損値を除去した平均値を求める。

ここでは2番目の方法を使います。

```{r}
df |>
  summarise(Mean = mean(Score, na.rm = TRUE))
```

`df`の`Score`変数の平均値は`r round(mean(df$Score), 2)`であることが分かります。また、`summarise()`関数は複数の記述統計量を同時に計算することも可能です。以下は`Score`変数の平均値、中央値、標準偏差、最小値、最大値、第一四分位点、第三四分位点を計算し、`Score.Desc`という名のデータフレームに格納するコードです。

```{r}
Score.Desc <- df |>
  summarize(Mean   =     mean(Score,       na.rm = TRUE),  # 平均値
            Median =   median(Score,       na.rm = TRUE),  # 中央値
            SD     =       sd(Score,       na.rm = TRUE),  # 標準偏差
            Min    =      min(Score,       na.rm = TRUE),  # 最小値
            Max    =      max(Score,       na.rm = TRUE),  # 最大値
            Q1     = quantile(Score, 0.25, na.rm = TRUE),  # 第一四分位点
            Q3     = quantile(Score, 0.75, na.rm = TRUE))  # 第三四分位点
```

```{r}
Score.Desc
```

むろん、複数の変数に対して記述統計量を計算することも可能です。たとえば、平均予算 (`Budget`)、口コミ数 (`ScoreN`)、口コミ評価 (`Score`)の平均値を求めるとしたら、

```{r}
df |>
  summarize(Budget_Mean = mean(Budget, na.rm = TRUE), # 平均予算の平均値
            SocreN_Mean = mean(ScoreN, na.rm = TRUE), # 口コミ数の平均値
            Score_Mean  = mean(Score,  na.rm = TRUE)) # 評価の平均値
```

のように書きます。実は`summarise()`はこれくらいで十分便利です。ただし、以上の操作はもっと簡単なコードに置換できます。ただし、ラムダ関数など、やや高度な内容になるため、以下の内容は飛ばして、次の節 (グルーピング)を読んでいただいても構いません。

まずは、複数の変数に対して同じ記述統計量を求める例を考えてみましょう。たとえば、`Budget`、`ScoreN`、`Score`に対して平均値を求める例です。これは`across()`関数を使うとよりコードが短くなります。まずは`across()`関数の書き方から見ましょう。

```{r}
#| eval: false
# across()の使い方
データフレーム名 |>
  summarise(across(変数名のベクトル, ラムダ関数))
```

**変数名のベクトル**は長さ1以上のベクトルです。たとえば、`Budget`、`ScoreN`、`Score`の場合`c(Budget, ScoreN, Score)`になります。これは`df`内で隣接する変数ですから`Budget:Score`の書き方も使えます。また、`where()`や`any_of()`、`starts_with()`のような関数を使って変数を指定することも可能です。**ラムダ関数**（lambda function; ラムダ式）は`~`で始まる関数であり、無名関数とも呼ばれます。たとえば、平均値を計算するラムダ関数は`~mean()`であり、第一引数は`.x`となります。この`.x`に`across()`の第一引数（変数たち）が入ります。また、`()`内には更に引数を指定することもでき、たとえば欠損値を除外して計算する`na.rm = TRUE`などが追加できます。ラムダ関数の詳細は後でもう一度解説するとし、とりあえず`Budget`、`ScoreN`、`Score`の平均値を計算してみましょう。

```{r}
df |>
  summarize(across(Budget:Score, ~mean(.x, na.rm = TRUE)))
```

`across()`使わない場合、4行必要だったコードが2行になりました。変数が少ない場合は`across()`を使わない方が、可読性が高くなる場合もあります。しかし、変数が多くなる場合、可読性がやや落ちても`across()`を使った方が効率的でしょう。

次は、ある変数に対して複数の記述統計量を計算したい場合について考えます。`Budget`、`ScoreN`、`Score`変数の第一四分位点と第三四分位点を`across()`を使わずに計算すると家のような7行のコードになります。

```{r}
df |>
  summarize(Budget_Q1 = quantile(Budget, 0.25, na.rm = TRUE),
            Budget_Q3 = quantile(Budget, 0.75, na.rm = TRUE),
            ScoreN_Q1 = quantile(ScoreN, 0.25, na.rm = TRUE),
            ScoreN_Q3 = quantile(ScoreN, 0.75, na.rm = TRUE),
            Score_Q1  = quantile(Score,  0.25, na.rm = TRUE),
            Score_Q3  = quantile(Score,  0.75, na.rm = TRUE))
```

この作業も`across()`を使ってより短縮することができます。ここではラムダ関数の知識が必要になります。ラムダ関数とは関数名を持たない[無名関数 (anonymous functions)](https://ja.wikipedia.org/wiki/無名関数)を意味しますが、詳細は割愛します。興味のある読者は[Wikipedia](https://ja.wikipedia.org/wiki/無名関数)などを参照してください。簡単にいうとその場で即席に関数を作成し、計算が終わったら破棄する関数です。ラムダ関数の書き方にはバリエーションがありますが、ここでは{purrr}パッケージのラムダ関数スタイルを使用します[^purrr-lambda]。まずは、書き方から確認します。

[^purrr-lambda]: ただし、`~関数名()`のような書き方のラムダ式は{purrr}パッケージが提供しているわけではない。

```{r}
#| eval: false
# ラムダ関数を用いたacross()の使い方
データフレーム名 |>
  summarise(across(変数名のベクトル, .fns = list(結果の変数名 = ラムダ関数)))
```

:::{.callout-note}
## ラムダ関数の3つの書き方

　ここでは`~mean(.x, na.rm = TRUE)`と書いたが、他の書き方もある。昔からのやり方では`function(x) mean(x, na.rm = TRUE)`のような書き方がある。関数内の内容が複数行に渡る場合は`function(x) { mean(x, na.rm = TRUE) }`と表記する。そしてR 4.1から追加された`\(x) mean(x, na.rm = TRUE)`のような書き方もある。以下のコードはすべて同じ結果を返す。Rネイティブの書き方の場合、引数は`.x`でなく、`x`であることに注意しよう（`\(y)`なら`y`が引数となる）。

```{.r}
# purrrスタイル
df |>
  summarize(across(Budget:Score, ~mean(.x, na.rm = TRUE)))

# R nativeスタイル
df |>
  summarize(across(Budget:Score, function(x) mean(x, na.rm = TRUE)))

# R nativeスタイル
df |>
  summarize(across(Budget:Score, function(x) { mean(x, na.rm = TRUE) }))

# R nativeスタイル（R 4.1以降）
# function を \ に省略したもの
df |>
  summarize(across(Budget:Score, \(x) mean(x, na.rm = TRUE)))
```
:::

先ほどの書き方と似ていますが、関数を複数書く必要があるため、今回は関数名をlist型にまとめ、`.fns`引数に指定します。そして、*結果の変数名*は結果として出力されるデータフレームの列名を指定する引数です。たとえば、`Mean`にすると結果は`元の変数名1_Mean`、`元の変数名2_Mean`...のように出力されます。そして、ラムダ関数が実際の関数が入る箇所です。とりあえず今回はコードを走らせ、結果から確認してみましょう。

```{r}
df |>
  summarize(across(Budget:Score, 
                   .fns = list(Q1 = ~quantile(.x, 0.25, na.rm = TRUE),
                               Q3 = ~quantile(.x, 0.75, na.rm = TRUE))))
```

結果の列名が`Budget_Q1`、`Budget_Q3`、`ScoreN_Q1`...のようになり、それぞれの変数の第一四分位点と第三四分位点が出力されます。問題はラムダ関数の方ですが、普通の関数に非常に近いことが分かります。`across()`内のラムダ関数は`~関数名(.x, その他の引数)`のような書き方になります。関数名の前に`~`が付いていることに注意してください。分位数を求める関数は`quantile()`であり、`quantile(ベクトル, 分位数)`であり、必要に応じて`na.rm`を付けます。この分位数が0.25なら第一四分位点、0.5なら第二四分位点 (=中央値)、0.75なら第三四分位点になります。それではラムダ関数`~quantile(.x, 0.25, na.rm = TRUE)`はどういう意味でしょうか。これは`.x`の箇所に`Budget`や`ScoreN`、`Score`が入ることを意味します。`.x`という書き方は決まりです。`.y`とか`.Song-san-Daisuki`などはダメです。そして、`0.25`を付けることによって第一四分位点を出力するように指定します。また、`Budget`、`ScoreN`、`Score`に欠損値がある場合、無視するように`na.rm = TRUE`を付けます。

ラムダ関数を第[-@sec-programming]章で解説した自作関数で表現すると、以下のようになります。

```{r}
#| eval: false
# 以下の3つは同じ機能をする関数である

# ラムダ関数
~quantile(.x, 0.25, na.rm = TRUE)

# 一般的な関数の書き方1
名無し関数 <- function(x) {
  quantile(x, 0.25, na.rm = TRUE)
}

# 一般的な関数の書き方2
名無し関数 <- function(x) quantile(x, 0.25, na.rm = TRUE)
```

この3つは全て同じですが、ラムダ関数は関数名を持たず、その場で使い捨てる関数です。むろん、ラムダ関数を使わずに事前に第一四分位点と第三四分位点を求める関数を予め作成し、ラムダ関数の代わりに使うことも可能です。まずは第一四分位点と第三四分位点を求める自作関数`FuncQ1`と`FuncQ2`を作成します。

```{r}
# ラムダ関数を使わない場合は事前に関数を定義しておく必要がある
FuncQ1 <- function(x) {
  quantile(x, 0.25, na.rm = TRUE)
}
FuncQ3 <- function(x) {
  quantile(x, 0.75, na.rm = TRUE)
}
```

後は先ほどのほぼ同じ書き方ですが、今回はラムダ関数を使わないため関数名に`~`を付けず、関数名のみで十分です。`()`も不要です。

```{r}
# やっておくと、summarise()文は簡潔になる
df |>
  summarize(across(Budget:Score, list(Q1 = FuncQ1, Q3 = FuncQ3)))
```

事前に関数を用意するのが面倒ですが、`across()`の中身はかなりスッキリしますね。もし、このような作業を何回も行うなら、ラムダ関数を使わず、自作関数を用いることも可能です。ただし、自作関数であっても引数が2つ以上必要な場合はラムダ関数を使います。

### `summarise()`に使える便利な関数

以下の内容は後で説明する`group_by()`関数を使っているため、まだ`group_by()`に馴染みのない読者はまずはここを読み飛ばし、グルーピングの節にお進みください。

**`IQR()`: 四分位範囲を求める**

四分位範囲は第三四分位点から第一四分位点を引いた値であり、Rの内蔵関数である`IQR()`を使えば便利です。この関数は`mean`や`sd()`関数と同じ使い方となります。

```{r}
df |>
  filter(!is.na(Walk)) |> # 予め欠損したケースを除くと、後でna.rm = TRUEが不要
  group_by(Pref) |>
  summarise(Mean    = mean(Walk),
            SD      = sd(Walk),
            IQR     = IQR(Walk),
            N       = n(),
            .groups = "drop") |>
  arrange(Mean)
```

**`first()`、`last()`、`nth()`: n番目の要素を求める**

稀なケースかも知れませんが、データ内、またはグループ内の`n`番目の行を抽出する時があります。たとえば、市区町村の情報が格納されているデータセットで、人口が大きい順でデータがソートされているとします。各都道府県ごとに最も人口が大きい市区町村のデータ、あるいは最も少ない市区町村のデータが必要な際、`first()`と`last()`関数が有効です。

それでは各都道府県ごとに「最も駅から遠いラーメン屋」の店舗名と最寄りの駅からの徒歩距離を出力したいとします。まずは、徒歩距離のデータが欠損しているケースを除去し、データを徒歩距離順でソートします。これは`filter()`と`arrange()`関数を使えば簡単です。続いて、`group_by()`を使って都府県単位でデータをグループ化します。最後に`summarise()`関数内に`last()`関数を使います。データは駅から近い順に鳴っているため、各都府県内の最後の行は駅から最も遠い店舗になるからです。

```{r}
df |>
  filter(!is.na(Walk)) |>
  arrange(Walk) |>
  group_by(Pref) |>
  summarise(Farthest  = last(Name),
            Distance  = last(Walk))
```

この`last()`を`first()`に変えると、最寄りの駅から最も近い店舗情報が表示されます。また、「`n`番目の情報」が必要な際は`nth()`関数を使います。`nth(Name, 2)`に変えることで2番目の店舗名が抽出できます。

**`n_distinct()`: ユニーク値の個数を求める**

`n_distinct()`は何種類の要素が含まれているかを計算する関数であり、`length(unique())`関数と同じ機能をします。たとえば、以下の`myVec1`に対して何種類の要素があるかを確認してみましょう。

```{r}
myVec1 <- c("A", "B", "B", "D", "A", "B", "D", "C", "A")

unique(myVec1)
```

`myVec1`は`"A"`、`"B"`、`"D"`、`"C"`の要素で構成されていることが分かります。これが`myVec1`の**ユニーク値 (unique values)**です。そして、このユニーク値の個数を調べるために`length()`を使います。

```{r}
length(unique(myVec1))
```

これで`myVec1`は4種類の値が存在することが分かります。これと全く同じ機能をする関数が`n_distinct()`です。

```{r}
n_distinct(myVec1)
```

この関数を`summarise()`に使うことで、都府県ごとに駅の個数が分かります。あるいは「東京都内の選挙区に、これまでの衆院選において何人の候補者が存在したか」も分かります。ここでは`df`内の都府県ごとに駅の個数を計算してみましょう。最後の駅数が多い順でソートします。

```{r}
df |>
  filter(!is.na(Station)) |> # 最寄りの駅が欠損しているケースを除去
  group_by(Pref) |>
  summarise(N_Station = n_distinct(Station),
            .groups   = "drop") |>
  arrange(desc(N_Station))
```

当たり前かも知れませんが、駅数が最も多いのは東京都で次が大阪府であることが分かります。

**`any()`、`all()`: 条件に合致するか否かを求める**

`any()`と`all()`はベクトル内の全要素に対して条件に合致するか否かを判定する関数です。ただし、`any()`は一つの要素でも条件に合致すれば`TRUE`を、全要素が合致しない場合`FALSE`を返します。一方、`all()`は全要素に対して条件を満たせば`TRUE`、一つでも満たさない要素があれば`FALSE`を返します。以下は`any()`と`all()`の例です。

```{r}
myVec1 <- c(1, 2, 3, 4, 5)
myVec2 <- c(1, 3, 5, 7, 11)

any(myVec1 %% 2 == 0) # myVec1を2で割った場合、一つでも余りが0か
all(myVec1 %% 2 == 0) # myVec1を2で割った場合、全ての余りが0か
all(myVec2 %% 2 != 0) # myVec2を2で割った場合、全ての余りが0ではないか
```

それでは実際に`df`に対して`any()`と`all()`関数を使ってみましょう。一つ目は「ある都府県に最寄りの駅から徒歩60分以上の店舗が**一つでも**あるか」であり、二つ目は「ある都府県の店舗は**全て**最寄りの駅から徒歩30分以下か」です。それぞれの結果を`Over60`と`Within30`という列で出力してみましょう。

```{r}
df |>
  group_by(Pref) |>
  summarise(Over60   = any(Walk >= 60, na.rm = TRUE),
            Within30 = all(Walk <= 30, na.rm = TRUE),
            .groups  = "drop")
```

埼玉県と神奈川県において、最寄りの駅から徒歩60以上の店がありました。また、京都府、東京都、奈良県、和歌山県の場合、全店舗が最寄りの駅から徒歩30分以下ということが分かります。当たり前ですが`Over60`が`TRUE`なら`Within30`は必ず`FALSE`になりますね。

## グルーピング {#sec-handling2-group}

### `group_by()`によるグループ化

先ほどの`summarise()`関数は確かに便利ですが、特段に便利とも言いにくいです。`df`の`Score`の平均値を計算するだけなら、`summarise()`関数を使わない方が楽です。

```{r}
# これまでのやり方
df |>
  summarise(Mean = mean(Score, na.rm = TRUE))

# 普通にこれでええんちゃう?
mean(df$Score, na.rm = TRUE)
```

しかし、これをグループごとに計算するならどうでしょう。たとえば、`Score`の平均値を都府県ごとに計算するとします。この場合、以下のようなコードになります。

```{r}
mean(df$Score[df$Pref == "東京都"],   na.rm = TRUE)
mean(df$Score[df$Pref == "神奈川県"], na.rm = TRUE)
mean(df$Score[df$Pref == "千葉県"],   na.rm = TRUE)
mean(df$Score[df$Pref == "埼玉県"],   na.rm = TRUE)
mean(df$Score[df$Pref == "大阪府"],   na.rm = TRUE)
mean(df$Score[df$Pref == "京都府"],   na.rm = TRUE)
mean(df$Score[df$Pref == "兵庫県"],   na.rm = TRUE)
mean(df$Score[df$Pref == "奈良県"],   na.rm = TRUE)
mean(df$Score[df$Pref == "和歌山県"], na.rm = TRUE)
```

変わったのは`df$Score`が`df$Score[df$Pref == "東京都"]`に変わっただけです。`df$Pref`が`"東京都"`であるか否かを`TRUE`と`FALSE`で判定し、これを基準に`df$Score`を抽出する仕組みです。`df$Score`と`df$Pref`は同じデータフレームですから、このような書き方で問題ありません。

これだけでもかなり書くのが面倒ですが、これが47都道府県なら、あるいは200ヶ国ならかなり骨の折れる作業でしょう。ここで大活躍するのが{dplyr}パッケージの`group_by()`関数です。引数はグループ化する変数名だけです。先ほどの作業を{dplyr}を使うなら`Pref`変数でグループ化し、`summarise()`関数で平均値を求めるだけです。今回は`Score`だけでなく、`ScoreN`の平均値も求めてみましょう。そして、評価が高い順にソートもしてみます。

```{r}
# ScoreNとScoreの平均値をPrefごとに求める
df |>
  group_by(Pref) |>
  summarise(ScoreN_Mean = mean(ScoreN, na.rm = TRUE),
            Score_Mean  = mean(Score,  na.rm = TRUE)) |>
  arrange(desc(Score_Mean))
```

評判が最も高い都府県は和歌山県、最も低いのは神奈川県ですね。Songも和歌山ラーメンは井出系も車庫前系も好きです。しかし、大事なのは「井出系」と「車庫前系」といった分類が正しいかどうかではありません。コードが非常に簡潔となり、ソートなども自由自在であることです。都府県ごとに`ScoreN`と`Score`の平均値を求める場合、{dplyr}を使わなかったら18行のコードとなり、ソートも自分でやる必要があります。一方、`group_by()`関数を使うことによってコードが5行になりました。

また、これは2020年6月に公開された{dplyr}1.0.0からの問題ですが、`group_by()`の後に`summarise()`を使うと以下のようなメッセージが出力されます。

```
## `summarise()` ungrouping output (override with `.groups` argument)
```

これは`group_by()`で指定された変数のグループ化が自動的に解除されたことを意味します。なぜなら`summarise()`をする際は`Pref`をグループ変数として使いましたが、出力された結果の`Pref`変数はもはやグループとして機能できなくなるからです。元の`df`には`Pref`が`"東京都"`だったケースが1000行、`"京都府"`だったのが414行あったので、`Pref`変数でグループ化する意味がありました。しかし、`summarise()`から得られたデータフレームは`Pref == "東京都"`の行が1つしかありません。これはグループ化する意味がなくなったことを意味します。したがって、自動的にグループを解除してくれます。自動的にやってくれるのはありがたいことですが、可能ならば関数内に自分で明記することが推奨されます。そこで使う引数が`.groups`であり、`"drop"`を指定すると**全ての**グループ化変数を解除します。以下のようなコードだと先ほどのメッセージが表示されません。今後、意識的に入れるようにしましょう。

```{r}
# ScoreNとScoreの平均値をPrefごとに求める
df |>
  group_by(Pref) |>
  summarise(ScoreN_Mean = mean(ScoreN, na.rm = TRUE),
            Score_Mean  = mean(Score,  na.rm = TRUE),
            .groups     = "drop") |>
  arrange(desc(Score_Mean))
```

続いて、一つ便利な関数を紹介します。それはグループのサイズを計算する関数、`n()`です。この関数を`summarise()`内に使うと、各グループに属するケース数を出力します[^n]。先ほどのコードを修正し、各グループのサイズを`N`という名の列として追加してみましょう。そしてソートの順番は`N`を最優先とし、同じ場合は`Score_Mean`が高い方を上に出力させます。また、`ScoreN_Mean`の前に、口コミ数の合計も出してみましょう。

[^n]: 今回の例のように記述統計量とケース数を同時に計算する場合は`n()`を使いますが、ケース数**のみ**を計算する場合は`group_by()`と`summarise()`と組み合わせず、`count()`関数だけ使うことも可能です。グループ化変数（ここでは`Pref`）を`count()`の引数として指定すると、`Pref`の値ごとのケース数が表示されます。

```{r}
# Prefごとに口コミ数の合計、口コミ数の平均値、評価の平均値、店舗数を求める
# 店舗数-評価の平均値順でソートする
df |>
  group_by(Pref) |>
  summarise(ScoreN_Sum  = sum(ScoreN,  na.rm = TRUE),
            ScoreN_Mean = mean(ScoreN, na.rm = TRUE),
            Score_Mean  = mean(Score,  na.rm = TRUE),
            N           = n(),
            .groups     = "drop") |>
  arrange(desc(N), desc(Score_Mean))
```

記述統計をグループごとに求めるのは普通にあり得るケースですし、実験データの場合はほぼ必須の作業でう。統制群と処置群間においてグループサイズが均一か、共変量のバラツキが十分に小さいかなどを判断する際に`group_by()`と`summarise()`関数の組み合わせは非常に便利です。

### 複数の変数を用いたグループ化

グループ化変数は2つ以上指定することも可能です。たとえば、都府県 (`Pref`)と最寄りの駅の路線 (`Line`)でグループ化することも可能です。それでは`Pref`と`Line`でグループ化し、店舗数と口コミ数、評価の平均値を計算し、ソートの順番は店舗数、店舗数が同じなら評価の平均値が高い順にしましょう。今回も`summarise()`内に`.group = "drop"`を指定し、グループ化を解除します。今回はTop 20まで出してみましょう。

```{r}
# ScoreNとScoreの平均値をPrefごとに求める
df |>
  filter(!is.na(Line)) |> # Lineが欠損していないケースのみ残す
  group_by(Pref, Line) |> # PrefとLineでグループ化
  summarise(N           = n(),
            ScoreN_Sum  = sum(ScoreN,  na.rm = TRUE),
            Score_Mean  = mean(Score,  na.rm = TRUE),
            .groups     = "drop") |>
  arrange(desc(N), desc(Score_Mean)) |>
  print(n = 20)
```

ぐるなびに登録されているラーメン屋が最も多い路線は埼玉県内の東武東上線で122店舗があります。東武東上線は東京都と埼玉県をまたがる路線ですので、東武東上線だけならもっと多いかも知れませんね。

ここで一つ考えたいのは`summarise()`内の`.groups`引数です。前回はグループ化に使った変数ごとに1行しか残っていなかったのでグループ化を全て解除しました。しかし、今回は状況がやや異なります。グループ化変数に使った`Pref`を考えると、まだ`Pref == "東京都"`であるケースがいくつかあります。やろうとすればまだグループ化出来る状態です。これは`Line`についても同じです。`Line == "東武東上線"`の行はここには表示されていないものの、まだデータに残っています。もし、これ以上グループ化しないなら今のように`.groups = "drop"`が正しいですが、もしもう一回グループ化したい場合はどうすればよいでしょうか。方法は2つ考えられます。

1. もう一度パイプ演算子を使って`group_by()`関数を使う (以下の9行目)。
    * 結果を見ると`## # Groups:   Pref, Line [523]`で、ちゃんとグループ化されていることが分かります。

```{r}
df |>
  filter(!is.na(Line)) |> 
  group_by(Pref, Line) |> 
  summarise(N           = n(),
            ScoreN_Sum  = sum(ScoreN,  na.rm = TRUE),
            Score_Mean  = mean(Score,  na.rm = TRUE),
            .groups     = "drop") |>
  arrange(desc(N), desc(Score_Mean)) |>
  group_by(Pref, Line) |> # group_by()、もう一度
  print(n = 5)
```

2. `.groups`引数を何とかする。

推奨される方法は2番です。具体的には`.groups = "keep"`を指定するだけであり、こっちの方が無駄なコードを省けることができます。

```{r}
df |>
  filter(!is.na(Line)) |> 
  group_by(Pref, Line) |> 
  summarise(N           = n(),
            ScoreN_Sum  = sum(ScoreN,  na.rm = TRUE),
            Score_Mean  = mean(Score,  na.rm = TRUE),
            .groups     = "keep") |>
  arrange(desc(N), desc(Score_Mean)) |>
  print(n = 5)
```

`.groups`引数は`"drop"`と`"keep"`以外にも`"drop_last"`があります。実は`summarise()`に`.groups`引数を指定したい場合のデフォルト値は`.groups == "drop_last"`または`"keep"`ですが、ここがややこしいです。主なケースにおいてデフォルト値は`"drop"`となりますとなります。`.groups == "drop_last"`これは最後のグループ化変数のみ解除する意味です。今回の例だと、2番目のグループ化変数である`Line`がグループ化変数から外され、`Pref`のみがグループ化変数として残る仕組みです。

それではデフォルト値が`"keep"`になるのはいつでしょうか。それは記述統計量の結果が長さ2以上のベクトルである場合です。平均値を求める`mean()`、標準偏差を求める`sd()`などは、結果として長さ1のベクトルを返します。しかし、長さ2以上ののベクトルを返す関数もあります。たとえば、分位数を求める`quantile()`関数があります。`quantile(ベクトル名, 0.25)`の場合、第一四分位点のみ返すため、結果は長さ1のベクトルです。しかし、`quantile(ベクトル名, c(0.25, 0.5, 0.75))`のように第一四分位点から第三四分位点を同時に計算し、長さ3のベクトルが返されるケースもありますし、第二引数を省略すると、最小値・第一四分位点・第二四分位点・第三四分位点・最大値、つまり、長さ5のベクトルが返される場合があります。

```{r}
# 第一四分位点のみを求める (長さ1のベクトル)
quantile(df$Walk, 0.25, na.rm = TRUE)

# 引数を省略する (長さ5のベクトル)
quantile(df$Walk, na.rm = TRUE)
```

`.groups`のデフォルト値が`"keep"`になるのは、このように長さ2以上のベクトルが返されるケースです。たとえば、都府県と最寄りの駅の路線でグループ化し、店舗までの徒歩距離の平均値を求めるとします。デフォルト値の変化を見るために、ここではあえて`.groups`引数を省略しました。

```{r}
df |>
  filter(!is.na(Walk)) |>
  group_by(Pref, Line) |>
  summarise(Mean = mean(Walk))
```

最初は`Pref`と`Line`でグループ化しましたが、`summarise()`の後、`Line`がグループ化変数から外されました。つまり、引数が`"drop_last"`になっていることです。

それでは、平均値に加えて、第一四分位点と第三四分位点も計算し、`Quantile`という名で格納してみましょう。

```{r}
df |>
  filter(!is.na(Walk)) |>
  group_by(Pref, Line) |>
  summarise(Mean     = mean(Walk),
            Quantile = quantile(Walk, c(0.25, 0.75)))
```

同じ`Pref`、`Line`のケースが2つずつ出来ています。最初に来る数値は第一四分位点、次に来るのが第三四分位点です。そして最初のグループ化変数であった`Pref`と`Line`が、`summarise()`後もグループ化変数として残っていることが分かります。

`.groups`引数は記述統計量だけを計算する意味ではあまり意識する必要がありません。しかし、得られた記述統計量から何らかの計算をしたり、さらにもう一回記述統計量を求めたりする際、予期せぬ結果が得られる可能性があるため注意する必要があります。出来る限り`.groups`引数は指定するようにしましょう。
