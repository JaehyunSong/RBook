[["index.html", "私たちのR: ベストプラクティスの探究 紹介 進捗状況 著者紹介 データのダウンロード 本書における表記法 著作権", " 私たちのR: ベストプラクティスの探究 宋財泫 (Jaehyun Song)・矢内勇生 (Yuki Yanai) 改訂: 2022-03-16 紹介 『私たちのR: ベストプラクティスの探究 (R Not for Everyone: An Esoteric Guide)』はSONG Jaehyun と 矢内勇生 が共同で執筆するRプログラミングの「入門書」である。統計学の本ではない。また、本書はデータ分析の手法の解説書でもない。Rを用いたデータ分析については他の本を参照されたい。私たちが専門とする政治学におけるデータ分析については、以下の本を勧める。 浅野正彦, 矢内勇生. 2018. 『Rによる計量政治学』オーム社. 飯田健. 2013.『計量政治分析』共立出版. 今井耕介（粕谷裕子, 原田勝孝, 久保浩樹 訳）2018.『社会科学のためのデータ分析入門（上）（下）』岩波書店. 本書が想定するのは、次のような希望をもつ読者である。 分析に入るまでの段階、つまりデータの入手やクリーニング方法が知りたい 分析結果を自分の思いどおりに可視化したい 複数のモデルを効率的に分析したい Rでシミュレーションがしたい Rと友達になりたい 本書を読んでも統計学やデータ分析を理解することはできない。本書の目的は、統計学やデータ分析についての知識を持った方々と、Rを使ってもっと効率的にデータ分析をする方法を共有することである。また、統計学やデータ分析を勉強する際に、プログラミングについての副読本として読むことも想定している。 本書を読み終える頃には、Rなしでは生活できなくなっていることだろう。 本書の執筆環境については本書の巻末節を参照されたい。 進捗状況 章立ては未定。著者が書きたいものから書く予定（全部で30~35章くらいになる見込み）。 第I部: Rの導入 第1章: R? (50%) 第2章: Rのインストール (0%) 第3章: IDEの導入 (0%) 第4章: 分析環境のカスタマイズ (0%) 第5章: Rパッケージ (50%) 第II部: Rの基礎 第6章: 基本的な操作 (80%) 第7章: データの入出力 (70%) 第8章: データ型 (90%) 第9章: データ構造 (80%) 第10章: Rプログラミングの基礎 (75%) 第11章: 関数の自作 (50%) 第III部: データハンドリング 第12章: データハンドリング [基礎編: 抽出] (95%) 第13章: データハンドリング [基礎編: 拡張] (95%) 第14章: データハンドリング [基礎編: factor型] (90%) 第15章: 整然データ構造 (85%) 第16章: 文字列の処理 (0%) 第IV部: 可視化 第17章: 可視化[理論] (85%) 第18章: 可視化[基礎] (85%) 第19章: 可視化[応用] (85%) 第20章: 可視化[発展] (85%) 第V部: 再現可能な研究 第21章: R Markdown [基礎] (85%) 第22章: R Markdown [応用] (0%) 第23章: 表の作成 (0%) 第24章: モデルの可視化 (0%) 第25章: 分析環境の管理 (0%) 第VI部: 中級者向け 第26章: データハンドリング [応用編] (0%) 第27章: 反復処理 (70%) 第28章: オブジェクト指向プログラミング (70%) 第29章: モンテカルロシミュレーション (50%) 第30章: スクレイピング (0%) 第31章: API (0%) 著者紹介 図 0.1: 事例研究をこよなく愛する著者 (Portland, OR. 2016年2月) Song Jaehyun（宋 財泫 [ソン ジェヒョン]; 写真左）はR黒帯の大学教員。猫好き。 主な著書：真に驚くべき業績を残しているが、この余白はそれを書くには狭すぎる。 公開したRパッケージ: {BalanceR}, {PRcalc}, {SimpleConjoint} など 関西大学 総合情報学部 准教授 Email: song@kansai-u.ac.jp Webpage: https://www.jaysong.net Twitter: @Tintstyle GitHub: https://github.com/JaehyunSong 矢内勇生（やない ゆうき; 写真右）はR歴15年の大学教員。猫好き。主な著書：『Rによる計量政治学』（共著, オーム社, 2018年）, 『政治経済学』（共著, 有斐閣, 2020年） 公開したRパッケージ：{rgamer} 高知工科大学 経済・マネジメント学群 准教授 Email: yanai.yuki@kochi-tech.ac.jp Webpage: https://yukiyanai.github.io Twitter: @yuki871 GitHub: https://github.com/yukiyanai データのダウンロード 本書のデータは全て筆者の GitHub リポジトリから入手可能である。データは以下の手順でダウンロードできる。 本書のGitHubリポジトリ にアクセスする。 リポジトリのURL: https://github.com/JaehyunSong/RBook dataフォルダーを選択する。 ダウンロードするファイル名を選択する。 「Raw」を右クリックし、「Save Linked Contents As…」を選択する。 保存するフォルダーを指定して、ダウンロードする。 本書における表記法 コードは以下のように背景に色が付けられている部分である。 print(&quot;Hello!&quot;) コードの中で#で始まる内容はコメントであり、分析に影響を与えない。ただし、\"や'で囲まれた#はコメントではない。また、行の途中から#が入る場合、#以降は実行されない。 # Hello!を出力するコード print(&quot;Hello!&quot;) # &quot;や&#39;内の#はコメントではない print(&quot;この#はコメントではありません&quot;) print(&quot;Hello World!&quot;) # Hellow World!を出力 出力結果は色付き背景かつ##で始まる箇所である。 ## [1] &quot;Hello!&quot; オブジェクト名は変数名や関数名()のように文中の色付き背景で示された部分である。 パッケージ名は{}で囲む。tidyverseパッケージの場合、{tidyverse}と表記する1。 著作権 本著作物は クリエイティブ・コモンズ 表示-非営利-改変禁止 4.0国際ライセンスの下に提供されています。 "],["aboutr.html", "1. R? 1.1 Rとは 1.2 Why R? 1.3 GUIとCUI", " 1. R? 1.1 Rとは 図 1.1: R Logo Rは統計、データ分析、作図のためのインタープリタープログラミング言語である。Rという名前は二人の開発者 Ross Ihaka と Robert Clifford Gentleman のイニシャルに由来する。R言語は完全にゼロベースから開発されたものではなく、1976年に開発されたS言語に起源をもつ。S言語もR言語同様、統計やデータ分析に特化した言語であり、S言語の開発が中止された現在、RはSの正当な後継者であると言ってよいだろう。 R以外にも、統計・データ分析のために利用可能なソフトウェアはたくさんある。社会科学におけるデータ分析の授業を履修したことがあるなら、SPSS や Stata という名前をきいたことがあるかもしれない。工学系ならMATLAB が有名かもしれない。企業ではSAS という高価なソフトもよく使われる2。 これらのソフト（アプリ）は基本的に有料だが、お金がないとデータ分析のソフトウェアが使えないわけではない。無料でありながら優れたソフトウェアも多く公開されている。以下にその一部を示す。 ソフト・言語名 備考 PSPP SPSSにとてもよく似た無料ソフトウェア。 JASP/jamovi 裏で動いているのはR。詳細は本章の後半で gretl 時系列分析など、計量経済学で利用される手法に特化したソフト。 GNU Octave MATLAB とほぼ同じ文法をもつ無料言語 HAD 清水裕士 先生が開発しているExcelベースのデータ分析マクロ 統計分析に特化したプログラミング言語としてRの競合相手になるのは Julia と Python だろう。Julia言語は一見Rによく似ているが、計算速度が Rより速いと言われている3。ただし、比較的新しい言語であるため、パッケージと解説書がRよりも少ないという難点がある。Pythonは現在のデータサイエンス界隈において、Rとともに最も広く使われている言語である4。Pythonは統計・データ分析に特化した言語ではないが、統計・データ分析のライブラリが非常に充実しており、機械学習（とくに、コンピュータービジョン）ではRよりも広く使われている。Python以外の言語、たとえば C や Java、Ruby、Fortranでも統計・データ分析は可能ある。実際、RやPythonのパッケージの一部はCやJavaで作成されている。ただし、RやPythonに比べると、データ分析の方法を解説したマニュアル・参考書があまりないのがつらいところだ。ひとつの言語だけでなく、複数の言語を使えるようになったほうが良いことは言うまでもない。本書はRについて解説するが、他の言語にもぜひ挑戦してほしい。 1.2 Why R? 私たちRユーザにとっての神のような存在であるHadley Wickham（通称：羽鳥先生）は Advanced R (2nd Ed.) で次のように仰せられた。 It’s free, open source, and available on every major platform. As a result, if you do your analysis in R, anyone can easily replicate it, regardless of where they live or how much money they earn. Rは無料で、オープンソースで、多くのプラットフォーム（訳注: macOS, Linux, Windowsなど）で利用できます。よって、Rを使って分析すれば、どこに住んでいるか、いくらお金を稼いでいるかに関係なく、誰でも簡単にその分析を再現できることができます。 R has a diverse and welcoming community, both online (e.g. the #rstats twitter community) and in person (like the many R meetups). Two particularly inspiring community groups are rweekly newsletter which makes it easy to keep up to date with R, and R-Ladies which has made a wonderfully welcoming community for women and other minority genders. オンライン (twitterの#rstatなど)、オフライン (訳注：日本では Tokyo.R が有名。筆者たちが開催している KUT.R もある) の両方で、多様なRコミュニティがあります。他にも最新のRをキャッチアップするためのニュースレターであるrweeklyや、女性や性的マイノリティーにやさしい R-Ladies も活発に活動しています。 A massive set of packages for statistical modelling, machine learning, visualisation, and importing and manipulating data. Whatever model or graphic you’re trying to do, chances are that someone has already tried to do it and you can learn from their efforts. 統計モデリング、機械学習、可視化、データ読み込みおよびハンドリングのための膨大なパッケージが用意されています。どのようなモデルやグラフでも、既に誰かがその実装を試みた可能性が高く、先人らの努力に学ことができます。 Powerful tools for communicating your results. R Markdown makes it easy to turn your results into HTML files, PDFs, Word documents, PowerPoint presentations, dashboards and more. Shiny allows you to make beautiful interactive apps without any knowledge of HTML or javascript. 分析結果を伝達する強力なツールを提供しています。R Makrdownは分析結果をHTML、PDF、Word、PowerPoint、Dashboard 形式に変換してくれます。HTMLや JavaScript の知識がなくても、Shinyを使って美しい対話型のアプリケーションを開発することができます。 RStudio, the IDE, provides an integrated development environment, tailored to the needs of data science, interactive data analysis, and statistical programming. 代表的な統合開発環境であるRStudioはデータサイエンス、対話型のデータ分析、そして統計的プログラミングが必要とするものに最適化されています。 Cutting edge tools. Researchers in statistics and machine learning will often publish an R package to accompany their articles. This means immediate access to the very latest statistical techniques and implementations. Rは最先端のツールです。多くの統計学や機械学習の研究者は自分の研究成果とRパッケージを同時に公開しています。これは最先端の方法を誰よりも早く実施可能にします。 Deep-seated language support for data analysis. This includes features like missing values, data frames, and vectorisation. データ分析を根強くサポートする言語です。欠損値、データフレーム、ベクトル化などがその例です。 A strong foundation of functional programming. The ideas of functional programming are well suited to the challenges of data science, and the R language is functional at heart, and provides many primitives needed for effective functional programming. Rはデータサイエンスに非常に有効である関数型プログラミングのための最適な環境を提供しています。 RStudio, the company, which makes money by selling professional products to teams of R users, and turns around and invests much of that money back into the open source community (over 50% of software engineers at RStudio work on open source projects). I work for RStudio because I fundamentally believe in its mission. RStudio社は営利企業ですが、その収益の多くをオープンソースコミュニティーに投資しています。 Powerful metaprogramming facilities. R’s metaprogramming capabilities allow you to write magically succinct and concise functions and provide an excellent environment for designing domain-specific languages like ggplot2, dplyr, data.table, and more. メタプログラミングが強力です。Rが持つメタプログラミング能力はあなたのコードを劇的に簡潔にするだけでなく、統計/データ分析に特化したggplot2、dplyr、data.tableなどの開発も可能にしました。 The ease with which R can connect to high-performance programming languages like C, Fortran, and C++. RはC、C++、Fortranのようなハイパフォーマンス言語と容易に結合できるように設計されています。 しかし、他のプログラミング言語と同様、Rは完璧な言語ではありません。以下はR言語の短所の一部です。その多くはRそのものの問題というよりも、(プログラマーではなく)データ分析の研究者が中心となっているRユーザーから起因する問題です。 Much of the R code you’ll see in the wild is written in haste to solve a pressing problem. As a result, code is not very elegant, fast, or easy to understand. Most users do not revise their code to address these shortcomings. あなたが普段見る多くのRコードは「今の」問題を解決するために迅速に書かれたものです。この場合、コードはあまりエレガントでも、速くも、読みやすくありません。ほとんどのユーザーはこの短所を克服するためのコード修正を行っておりません。 Compared to other programming languages, the R community is more focussed on results than processes. Knowledge of software engineering best practices is patchy. For example, not enough R programmers use source code control or automated testing. 他のプログラミング言語に比べ、Rコミュニティーは過程よりも結果に注目する傾向があります。多くのユーザーにおいて、ソフトウェアエンジニアリングの知識を蓄えるための方法が不完全です。たとえば、(GitHubなどの) コード管理システムや自動化された検証を使用するRプログラマーは多くありません。 Metaprogramming is a double-edged sword. Too many R functions use tricks to reduce the amount of typing at the cost of making code that is hard to understand and that can fail in unexpected ways. Rの長所でもあるメタプログラミングは諸刃の剣です。あまりにも多くのR関数はコーディングのコストを減らすようなトリックを使用しており、その代償としてコードの理解が難しく、予期せぬ失敗の可能性があります。 Inconsistency is rife across contributed packages, and even within base R. You are confronted with over 25 years of evolution every time you use R, and this can make learning R tough because there are so many special cases to remember. 開発されたパッケージは、R内蔵のパッケージさえも一貫性が乏しいです。あなたはRを使う度にこの25年を超えるRの進化に直面することになります。また、Rには覚えておくべきの特殊なケースが多く、これはR学習の妨げとなっています。 R is not a particularly fast programming language, and poorly written R code can be terribly slow. R is also a profligate user of memory. Rは格別に速い言語ではありません。下手に書かれたコードは驚くほど遅いです。また、Rはメモリの浪費が激しい言語と知られています。 1.3 GUIとCUI 現在、多くのソフトウェアはGUIを採用している。GUI とは Graphical User Interface の略で、ソフトウェア上の入力および出力にグラフィックを利用する。単純にいうと「マウスでポチポチするだけで操作できる環境」のことだ。一方、Rでは基本的にCUI (Character User Interface) を利用する5。これは全ての操作を文字列ベースで行う、つまりキーボードで行うことを意味する6。 身近な例として、あるラーメン屋での注文（呪文）システムを考えてみよう。無料トッピングを指定するときに「決まった言い方」で指定するのがCUI方式である。一文字でも間違うとオーダーは通りらない。たとえば、「野菜マッシマッシ!」とか「野菜MashMash!」と言ってしまうと、店長さんに「は？」と言われ、周りの客から白い目で見られる7。他方、食券の自動発売機でトッピングを指定できるのがGUI方式だ8。この場合、そもそも間違いは起きない。誰でも簡単に注文できるのがGUI式のメリットだが、自分で注文するものが決まっていて、注文の仕方を知っているなら CUI式のほうが早い。毎回同じ注文をするなら、注文内容を録音しておいて、次回はそれを再生することも可能である。GUI方式では、注文方法を再現するのは難しい。 図 1.2: CUIとGUIの比較 CUIとGUIを比べたとき、一見するとGUIのほうが優れているように見える。マウスでポチポチするだけで操作できるほうが楽に見えるし、間違いの心配もなさそうな気がする。キーボードで長いコマンドを打つCUIよりも、ボタンをクリックしたほうが手早く済みそうにも思える9。そして、CUIのコマンドを覚えるのはしんどい10。 しかし、CUIにはCUIなりの長所がある。まず、コードが記録できる。マウスでポチポチした操作は、パソコンの画面全体を録画しない限り記録できない。よって、GUIでは自分の分析プロセスを記録することが難しい。他方、すべてコマンドで操作した場合、入力したコマンドを文字列として記録することは容易である。また、CUIはGUIよりも柔軟である。先ほどのラーメン屋の例で考えると、CUIでは「一応」野菜ちょいマシのような注文（呪文）のカスタマイズもできる11。しかし、GUI（券売機）だと注文の自由なカスタマイズはできない。店が用意したボタンしか押せない（ソフトがメニューに表示しているコマンドしか実行できない）。また、コマンドの入力の時間や暗記も、それほど難しくはない。後で説明するように、Rユーザにとっての超有能な秘書であるRStudio (IDEの1種) がコマンド入力を助けてくれる。スペルが間違っていたり、うろ覚えのコマンドなどがあっても、RStudio （あるいはその他のIDE）が瞬時に正解に導いてくれる。 本書はCUIとしてのRについて解説する。Rは統計ソフトでありながら、言語でもある。外国語の勉強に喩えるなら、CUIを使うのは単語や熟語を覚え、文法やよく使う表現を学習して自分で考えて話すことであるのに対し、GUIを使うのは AI に翻訳を頼み、外国語については自分で一切考えないことに似ている。たいして興味のない国になぜか旅行で訪れることになった場合にはGUI方式で済ますのも良いだろう。しかし、それでその言語を「勉強した」とか「理解した」などという人はいないはずだ。Rを「理解」したいなら、CUI以外の選択肢はない12。 それでもやはりGUIのほうがとっつきやすいという頑固なあなたのために代表的なRの GUI を紹介するので、以下のリストを確認したらこの本は閉じていただきたい。またいつかどこかでお会いしましょう。CUIを使う覚悟ができたあなたは、以下のリストを読みとばし、引き続き一緒にRの世界を楽しみましょう！ R Commander 図 1.3: R Commander RKWard 図 1.4: RKWard JASP 図 1.5: JASP jamovi 図 1.6: jamovi R AnalyticFlow 図 1.7: RAnalyticFlow (画像は公式ホームページから) "],["installation.html", "2. Rのインストール", " 2. Rのインストール 本章の内容は今後、以下の資料に基づき、再作成する予定である。 矢内による資料 (macOS編、Linux (Ubuntu)編、Windows編) Windowsの場合、R 4.2からはUTF-8対応、32bit版の削除などかなりの変化があるはず "],["ide.html", "3. IDEの導入 3.1 IDE 3.2 RStudioのインストールと起動", " 3. IDEの導入 本章の内容は今後、以下の資料に基づき、再作成する予定である。 矢内による資料 (macOS編、Linux (Ubuntu)編、Windows編) 3.1 IDE プログラミングは基本的にコードを書く作業の連続だが、コードを書く他にも様々な作業を行うことになる。たとえば、自分が書いたコードの結果が正しく動作するかの確認作業や、なにか問題がある場合の対処（デバッグ）などがある。また、コードを書く際、誤字やミスなどがないかも確認する必要がある。他にもプログラムで使用されるファイルを管理しなければならない。これらの仕事を手助けしてくれるのが統合開発環境 (integrated development environment; IDE) と呼ばれるものである。 プログラマにとって優れたIDEを使うということは、優れた秘書を雇用するようなものだ。ファイルの管理、うろ覚えのコマンドの補完入力、コードの色分けなどを自動的に行ってくれる。さらに、コードの実行結果の画面をコードと同時に表示してくれたり、これまでの作業を記録してくれるなど、多くの作業を手助けしてくれる。Rにはいくつかの優れたIDEが用意されている。本書では代表的なIDEである RStudio を使うことにする。ただし、プログラミングにIDEは必須ではない。IDEをインストールしなくても、本書を読む上で特に問題はない（RStudioに関する説明の部分を除く）が、Rの実行環境に特にこだわりがないなら RStudioの導入を強く推奨する。 図 3.1: RStudio RStudio以外にもRのIDEはある。魔界において圧倒的なシェアを誇ると噂されるWindowsという名のOSを使用しているなら、R Tools for Visual Studio がRStudioの代替候補として有力だ。 図 3.2: R Tools for Visual Studio 自分が使い慣れたテキストエディタをIDEとして使うことも可能である。Sublime Text や Atom はむろん、伝統のある Emacs や Vim を使うこともできる。 3.2 RStudioのインストールと起動 3.2.1 macOSの場合 ポチポチ、ドラッグ・アンド・ドロップ 3.2.2 Linux (Ubuntu)の場合 ダウンロードしたバージョン (例えば、最新バージョン) が分かっていれば、ターミナルでwgetコマンドで直接ダウンロード たとえば、~/Downloadsフォルダーに2020.02.0-443バージョンをダウンロードする場合は $ cd ~/Downloads/ $ wget https://download1.rstudio.org/desktop/bionic/amd64/rstudio-2022.02.0-443-amd64.deb 分からない場合は、RStudioのホームページの「All Installer」のリストから「Ubuntu 18+/Debian 10+」用の.debファイルをダウンロード .debファイルのインストールは、ターミナルを使って~/Downloadフォルダー内のrstudio-2022.02.0-443-amd64.debファイルをインストールするなら… $ cd ~/Downloads/ $ sudo gdebi rstudio-2022.02.0-443-amd64.deb gdebiがインストール済みならnautilus (Linux MintならNemo?)で.debファイルをダブルクリックしてインストール可能 3.2.3 Windowsの場合 ポチポチ "],["R-Customize.html", "4. 分析環境のカスタマイズ 4.1 .Rprofileの設定 4.2 RStudioのカスタマイズ", " 4. 分析環境のカスタマイズ 4.1 .Rprofileの設定 4.2 RStudioのカスタマイズ 以下の設定はRStudio 2022.02.0+442 (Prairie Trillium)の設定 Tools &gt; Global Options General Basicタブ Restore .RData into workspace at startupのチェックを消す。 Save workspace to .RData on exit:をNeverに変更する。 Always save history (even when not saving .RData)のチェックを消す。 Code Editingタブ Insert spaces for tabのチェックを付ける。 Tab widthは2か4 Auto-detect code indentationのチェックを付ける。 Insert matching parens/quotesのチェックを付ける。 Auto-indent code after pasteのチェックを付ける。 Vertically align arguments in auto-indentのチェックを付ける。 Always save R scripts before sourcingのチェックを付ける。 Ctrl + Return executes:をMulti-line R statementに変更する。 Displayタブ Highlight selected wordのチェックを付ける。 Highlight selected lineのチェックを付ける。 Show line numbersのチェックを付ける。 Show syntax highlighting in console inputのチェックを付ける。 Highlight R function callsのチェックを付ける。 Rainbow parenthesesのチェックを付ける。 Savingタブ Default text encoding:のChangeをクリックし、UTF-8を選択する。 Completionタブ Show code completion:をAutomaticallyに変更する。 Allow automatic completions in consoleのチェックを付ける。 Insert parentheses after function completionsのチェックを付ける。 Show help tooltip after function completionsのチェックを付ける。 Insert spaces around equals for argument completionsのチェックを付ける。 Use tab for autocompletionのチェックを付ける。 Appearance 自分の好みのものを選択する。 Pane Layout 左上: Source 右上: Console 左下: 全てチェックを消す。 左下: 全てチェックを付ける。 R Markdown Basicタブ Show output inline for all R Markdown documentsのチェックを消す。 左下のApplyをクリック "],["packages.html", "5. Rパッケージ 5.1 パッケージとは 5.2 パッケージのインストール 5.3 パッケージの読み込み 5.4 パッケージのアップデート 5.5 {pacman}によるパッケージ管理 5.6 必須パッケージのインストール", " 5. Rパッケージ 5.1 パッケージとは Rには様々な関数 (functions) が提供されている。平均値を求めるmean()、合計を求めるsum()、線形回帰分析を行うlm()、平均値の検定を行うt.test()などがあり、全てを列挙することはできない。しかし、データ分析の技術は日々発展し、Rがデフォルトで提供する関数では不可能ではないが、かなり長いコードが必要な分析を使わざる得ないケースもあろう。Rは開発元だけでなく、誰でも関数を作ることができる。通常なら数百行のコードが必要な分析を一行のコードで実行可能とする関数を多くのRユーザーが作ってきた。これらの関数を集めたのがパッケージである。Rにはグラフ作成に特化したパッケージ、機械学習に特化したパッケージ、テキスト分析に特化したパッケージなど、数千のパッケージが開発されている。このパッケージの豊富さがRの最大のメリットでもある。誰かが新しい分析手法を提案したら、数日内、あるいはその手法が論文として出版される前からRパッケージとして公開されるケースが多い。 本章ではパッケージをインストールし、読み込む方法について説明する。また、パッケージの管理をアシストするパッケージ、{pacman}の使い方についても紹介する。 5.2 パッケージのインストール Rの環境は何かを作るための作業台に似ている。作業台にはモノを作るために材料だけでなく、工具・道具セットなども置いたりもする。この作業台がRにおける「環境 (environment) 」であり、材料がベクトルや行列、データフレームなどのデータ、工具セットがパッケージになる。データについては後で説明するとし、ここではパッケージについて考えたい。 モノを作るためには素材・材料だけでは不十分だろう。多くの場合、なんらかの道具セットが必要となる。Rには既にいくつかの必須道具セットを用意されているが、他にも様々な道具セットがある。そして、これら道具セットには、一般的に複数の道具が含まれている。一つ一つの道具のことを、ここでは「関数 (function) 」と呼ぶ。これらの道具セットを購入し、作業台の収納に入れておくことがパッケージをインストールすることである。 install.packages(&quot;パッケージ名&quot;) これらのパッケージは基本的にCRANというRの公式道具屋からダウンロード・インストールされる。もう一つの大きな道具屋としてはGitHubがある13。GitHubは個人経営の道具屋が集まっているモールのようなものである。GitHub道具屋を使用するためには、予めCRANから{devtools}、または{remotes}というパッケージをインストールしておく必要がある。 ここでは{devtools}というパッケージをインストールしてみよう。{devtools}はCRANに登録されているため、install.pcakges()関数でインストールできる。パッケージ名を\"で囲むことを忘れないこと。 install.packages(&quot;devtools&quot;) もし、CRANに登録されていないパッケージをGitHubからインストールするなら、{devtools}パッケージ、または{remotes}のinstall_github()関数を使う。 # あらかじめ{devtools}、または{remotes}をインストールしておく # {remotes}をインストールした場合は、remotes::install_github()を使用する devtools::install_github(&quot;作成者のGitHubのID/パッケージ名&quot;) たとえば、筆者 (Song) が作成しました{BalanceR}パッケージがインストールしたいなら、以下のように打つ。 # {remotes}をインストールした場合は、 # remotes::install_github(&quot;JaehyunSong/BalanceR&quot;) devtools::install_github(&quot;JaehyunSong/BalanceR&quot;) ここでJaehyunSongはSongのGitHub IDであり、BalanceRはパッケージ名である。 5.3 パッケージの読み込み 先ほど述べたように、パッケージのインストールは道具セットの購入と収納に似ている。ただし、実際に道具セットを使うためには、それを自分の作業台上に載せた方が効率がいいだろう14 15。この作業がパッケージの読み込み (load) である。インストールしたパッケージを読み込むにはlibrary()またはrequire()関数を使う。require()は関数内に使う目的で設計された関数だが、パッケージを読み込むという点では全く同じである。 図 5.1: Rパッケージと作業環境 library(&quot;パッケージ名&quot;) #または require(&quot;パッケージ名&quot;) 読み込まれたパッケージはセッションが開かれている時のみに有効である。一通りの作業が終わり、作業部屋から退出すると、作業台上の道具セットは収納に自動的に戻される。つまり、RまたはRStudioを閉じると読み込まれたパッケージは自動的に取り外されるということである。しかし、作業の途中に読み込んだパッケージをセッションから取り外したい時があるかも知れない。この場合、detach()関数を使う。 detach(&quot;パッケージ名&quot;) 5.4 パッケージのアップデート Rパッケージはバグが修正されたり、新しい機能 (=関数) が追加されるなど、日々更新される。できる限りパッケージは最新版に維持した方が良いだろう。パッケージのアップデートはパッケージのインストールと同じである。{dplyr}というパッケージを最新版にアップデートしたい場合、install.packages(\"dplyr\")で十分である。 しかし、Rを使っていくうちに数十個のパッケージをインストールしていくこととなり、一つ一つアップデートするのは面倒だろう。そもそも既に最新版が入っていて (または開発休止/中止)、アップデートが不要なパッケージがあるかも知れない。実はRStudioを使えば、アップデートが必要なパッケージのリストが表示され、一気にアップデートすることができる。RStudioのPackagesペインにある「Update」をクリックしてみれば、アップデート可能なパッケージの一覧が表示される。ここでアップデートしたいパッケージの左にチェックをするか、下段の「Select All」を選択して「Install Updates」をクリックすれば、チェックされているパッケージがアップデートされる。 ただし、場合によってはアップデート時、以下のようなメッセージがコンソールに表示されるかも知れない。 There are binary versions available but the source versions are later: binary source needs_compilation terra 1.5-17 1.5-21 TRUE yaml 2.2.2 2.3.4 TRUE Do you want to install from sources the packages which need compilation? (Yes/no/cancel) コンソールにYes、no、cancelのいずれかを入力してReturnキー (Enterキー)を押す必要がある。どうしても最新のパッケージが欲しい場合はYesを入力すれば良いが、インストールに時間がかかる場合がある。一方、noを入力した場合は、若干古いバージョンがインストールされるが、インストールに必要な時間が短いため、基本的にはnoでも問題ないだろう。cancelを入力した場合はアップデートが全てキャンセルされる。 5.5 {pacman}によるパッケージ管理 CRANとGitHubなどには数千のRパッケージが公開されており、Rの使用歴が長くなればインストールされているパッケージが増えたり、一つのスクリプト内で使用するパッケージも増えていくだろう。また、パッケージは他のパッケージの機能に依存することがほとんどなので、自分の想像以上の数のパッケージがインストールされているかも知れない。このように膨大な数のパッケージを管理するためのパッケージが{pacman}である。{pacman}はCRANから入手可能である。 install.packages(&quot;pacman&quot;) 5.5.1 インストール パッケージをCRANからインストールにはp_install()関数を使用する。使い方はinstall.packages()と同じであり、複数のパッケージをインストールしたい場合はパッケージ名の箇所にc(パッケージ名1, パッケージ名2, ...)を入れる。パッケージ名は\"で囲んでも、囲まなくても良い。GitHubに公開されているパッケージはp_install_gh()関数を使用する。これは{devtools}、または{remotes}のinstall_github()と同じ使い方となり、必ず\"で囲む必要がある。 これらの関数を使う際、わざわざlibrary(pacman)を使う必要はない。パッケージのインストールや、読み込みなどはコード内に何回も使われることがほとんどないため、{pacman}を読み込まずpacman::関数名()で当該関数を使うことができる。 # CRANからインストール pacman::p_install(パッケージ名) # githubからインストール pacman::p_install_gh(&quot;作成者のGitHubのID/パッケージ名&quot;) 5.5.2 読み込み パッケージの読み込みにはp_load()関数を使い、実はこの関数は{pacman}を使う最も大きな要素である。p_load()関数の使い方は以下の通りである。 pacman::p_load(パッケージ名) p_load()の便利なところは (1) 複数のパッケージが指定可能であることと、 (2) インストールされていないパッケージはCRANから自動的にインストールして読み込んでくれる点だ。たとえば、{tidyverse}と{broom}、{estimatr}という3つのパッケージを読み込む場合、library()関数を使うと以下のようになる。 # library() を使う場合 library(tidyverse) library(broom) library(estimatr) 一方、{pacman}のp_load()を使えば、以下のように3つのパッケージを読み込むことができる。 # {pacman}のp_load() を使う場合 pacman::p_load(tidyverse, broom, estimatr) また、p_load()内のパッケージがインストールされていない場合、CRANのパッケージリストから検索し、そのパッケージをインストールしてくれる。したがって、上で紹介したp_install()は実質的に使うケースはほぼない。ただし、GitHub上のパッケージは自動的にインストールしてくれない。たとえば、GitHub上のみにて公開されている{BlanceR}パッケージがインストールされていない場合、p_load(BalanceR)を実行しても{BalanceR}はインストールされない16。あらかじめp_install_gh()でインストールしておく必要がある。 5.5.3 アップデート {pacman}にはアップデートが可能なパッケージを全てアップデートしてくれるp_update()という関数も用意されている。使い方は簡単で、コンソール上にp_update()のみの入力すれば良い。ただし、一部のパッケージのみをアップデートしたいのであれば、RStudioが提供するアップデート機能を使った方が良いかも知れない17。 また、同じ機能の関数としてp_up()があるが、コードの可読性のためにp_update()の方を推奨したい。 pacman::p_update() 5.6 必須パッケージのインストール ここでは現在のRにおいて必須パッケージである{tidyverse}をインストールする。{tidyverse}は{dplyr}、{ggplot2}、{tidyr}など、Rにおいて不可欠なパッケージを含むパッケージ群である。また、上で紹介した{devtools}も今のうちにインストールしておこう。既に導入済みの読者は走らせなくても良い。 install.packages(&quot;tidyverse&quot;) install.packages(&quot;devtools&quot;) "],["rbasic.html", "6. 基本的な操作 6.1 コンピュータの基礎知識 6.2 「プロジェクト」のすゝめ 6.3 電卓としてのR 6.4 格納とオブジェクトの作成 6.5 要素の抽出 演習問題", " 6. 基本的な操作 6.1 コンピュータの基礎知識 Rを使い始める前に、コンピュータについて最低限知っておいてほしい基礎知識について説明する。 6.1.1 ファイル名 まず、コンピュータ上のファイル名について説明する。 6.1.1.1 ファイル名拡張子 コンピュータの中には、様々な種類のファイルが含まれている。例えば、多くの人は Microsoft Word や Microsoft Excel のファイルを作ったことがあるだろう。Word や Excel で作ったファイルは、基本的にはそれぞれ専用のソフトウェア（アプリ）で開く必要がある。Word で作ったファイルをExcel で開くことや、Excel で作ったファイルを Wordで開くことなどはできない。 ユーザが特に意識しなくても、Word で作ったファイルを [ダブル] クリックすれば Word が起動してそのファイルを開くし、Excel で作ったファイルを [ダブル] クリックすれば Excel が起動して開きたいファイルが開かれる。仮に、Word のファイルとExcelファイルのファイル名が同じ kadai01 だとしても、パソコンは正しいアプリを選んでくれる。パソコンがファイルを区別し、正しいアプリを起動してくれるのはなぜだろうか。 実は、各アプリで作ったファイル名は、自分で名前を付けた部分（上の例では kadai01）の後に続きがある。 Word で作ったファイルには自動的に “.docx” が付けられ、Excel の場合には “.xlsx” が同様に付けられている。 したがって、自分では両方のファイルにまったく同じ kadai01 という名前を付けたつもりでも、実際には、kadai01.docx と kadai01.xlsx という別のファイル名が付いている。 この仕組みにより、パソコンは正しいアプリを選択することができる。ファイル名の末尾に .docx があるファイルがクリックされれば Word を、.xlsx があるファイルが選択されれば Excel を開くのである。 ファイル名の末尾にあってファイルの種類を区別する部分のことをファイル名拡張子 (filename extension) と呼ぶ。上の例からわかるとおり、ファイル名拡張子はファイルの種類を区別する重要情報である。プログラミングをしないパソコンユーザにとっては、ファイルの種類の違いを気にせずにパソコンを使えたほうが便利なので、パソコン購入時の初期設定ではファイル名拡張子が非表示になっている場合がある。しかし、プログラミングをする場合（つまり、この本を読んでいるあなた）は、ファイル名拡張子が見えないと困る。 例えば、Rは様々な形式で保存されたデータファイルを扱うことができるが、種類に応じてデータを読み込む方法（読み込みに使う関数）が異なる。ファイル名拡張子でファイルの種類を区別し、どの方法を使うかを決めるので、拡張子が表示されていないと不便である（MacのFinderやWindows のエクスプローラーで「ファイルの種類」を確認できるので、絶対無理というわけではないが、面倒くさい）。よく使うデータファイルのファイル名拡張子として、次のものがある。 .csv .tsv .txt .dat .dta .RData .Rds 後の章で説明するが、この他にも種類がある。ファイルの種類がわからないと、様々な方法を試行錯誤することになってしまい、効率が悪い。ファイル名拡張子があればファイルの種類がわかるので、正しい方法を選んで作業を進めることができる。 よって、Rユーザ（あるいはその他のプログラミングをする者）にとって、ファイル名拡張子の表示は必須である。自分のパソコンでファイル名拡張子が表示されていないなら、ファイル名拡張子を表示する設定に変えよう。macOS では、Finder の 環境設定 (Preferences) で、詳細設定 (Advanced) タブを開き、「すべてのファイル名拡張子を表示する (Show all filename extensions)」にチェックマークを付ける。 Windows では、エクスプローラー (Explorer) （注意：インターネットエクスプローラーではない。画面下部のタスクバーに表示されている、黄色のフォルダのアイコン）を開き、上部の [表示]タブをクリックする。すると、「ファイル名拡張子」という項目があるので、チェックマークを付ける。チェックマークを付けたら、Word ファイルに .docx （または .doc）、Excelファイルに .xlsx （または .xls）、PDFファイルに .pdf などが付いていることを確認しよう。 6.1.1.2 ファイル名の付け方 ファイル名は、ファイルの中身がわかるように付けるのが基本である。例えば、日記を書いて保存するなら、diary_20200701.txt, diary_20200702.txt のように名前を付ければ、特定の日付の日記であることがすぐにわかる。 また、他人にファイルを渡す必要があるときは、相手の立場になってファイル名を付けるのが望ましい。例えば、比較政治学 (Comparative Politics) の授業のレポートをWord で書く場合を考えよう。レポートを書いている本人にとっては、cp_report.docx というファイル名で中身がわかるので問題ないだろう。しかし、これをメールに添付して担当教員に提出する場合はどうだろうか。受講生が100人いて、全員がこの名前でレポートを提出してきたら、担当教員の元には同じ名前のファイルが100個届く。これでは、担当教員は困ってしまう。つまり、cp_report.docx というファイル名は、受け取る相手のことを考えていない、思いやりのないファイル名である。代わりに、学籍番号（例：123456789）を使い、cp_report_123456789.docx のようにすると、ファイル名の重複がないので、受け取る相手（私たちのことだが）は喜ぶだろう。自分が1つのファイル名を変えるのは大した手間ではないのに対し、相手が全員分のファイル名を変えるの大変な手間だということを理解しよう。 加えて、ファイル名の付け方には形式的なルールがある。ファイル名は、英数字と特定の記号（_ [「アンダースコア」、「アンスコ」、「アンダーバー」などと読む] と - [ハイフン]）のみで付けるべきだ。 ファイル名に日本語（または韓国語、中国語などのマルチバイト文字）を使うのは愚かなのでやめよう。日本語のファイル名でも問題ない場合が多いのは確かだが、問題がある場合もあるので使用を回避するのが賢い。日本語のファイル名だと、次のような問題が起こりうる。 日本語（マルチバイト文字）を扱えないプログラムが停止する。 さらに悪いと、日本語（マルチバイト文字）を扱えないプログラムが想定外の動作をする。 文字コードの違いにより、ファイル名が文字化けする 例えば、日本語のファイル名がついたファイルを Windows で圧縮 (zip) して macOS で展開すると、日本語部分が謎の暗号になるので、どのファイルを開いていいのかわからず、超絶面倒くさい。本当にやめてほしい。お願いだからやめてください。 日本語のなかでも特に凶悪なのが「全角スペース」である。そもそも、スペースは存在に気付きにくい。万が一末尾にスペースがあると、スペースがない場合との区別が難しい。日本語（マルチバイト文字）を扱えないプログラムでは、半角スペースなら問題ないが、全角でスペースだと問題が起きることがある。しかし、目視で半角スペースと全角スペースの区別をするのは非常に困難である。よって、スペースは使うべきではないし、全角スペースは絶対に使ってはいけない。 また、ファイル名の最初の1文字はアルファベットにすることが望ましい。ファイルを並べ替えるときに、数字だとややわかりにくいところがある。例えば、1.txt, 12.txt, 110.txt という3つのファイルをファイル名で並べ替えると、1.txt, 110.txt, 12.txt という順番になる。多くの場合、これはユーザが期待する順番ではない。中身がわかるようにという大原則にしたがえば、アルファベットから始まるファイル名が自然に選ばれるだろう。 ファイル名の付け方をまとめると、次のようになる。 ファイル名は、英数字 (A-Z, a-z, 0-9) と_, - のみで付ける。 ただし、ハイフンがあると動かないプログラムもあるので、できればハイフンも避ける。 ファイル名の1文字目はアルファベットにする（数字を1文字目にすることを避ける）。 .（ドット; ピリオド）は使わない（ファイル名拡張子との混同を避けるため）。 ファイル名にスペースを使わない。全角スペースはもちろん、半角スペースも避けるべき。 - 例えば、my diary.txt というファイル名の代わりに、my_diary.txt または myDiary.txt、MyDiary.txt などのファイル名を使う。 ちなみに、my_diary.txt のように単語をアンスコで繋ぐ書き方をスネークケース (snake case) [_ が地を這うヘビである]、myDiary.txt のように単語の1文字目を大文字にして前の単語と区別する書き方をキャメルケース (camel case) [大文字部分がラクダのコブである] と呼ぶ。 ただし、次のような例外もある。 隠しファイル（Windows 以外では通常は非表示のファイル）の1文字目は . である。 Rユーザが作る隠しファイルとして、.Rprofile と .Renviron がある。 自分で作るファイル以外には、_ や # などの記号からファイル名が始まるものもある。 次の節で説明するフォルダ（ディレクトリ）の名前を付ける際も、基本的にはファイル名と同じルールに従うことが望ましい。 6.1.2 ファイルシステムとパス 次に、ファイルシステムについて解説する。私たちが使用しているコンピュータには、数千〜数万（あるいはそれ以上）のファイルが含まれている。これらのファイルは基本的には1つのドライブ (ハードディスクドライブ [Hard Disk Drive; HDD] またはソリッドステートドライブ [Solid State Drive; SSD]） に保存されているが、ドライブの中にあるファイルはグループ化・階層化されて保存されている。 図6.1はファイルシステムの例を示している。矢印の左側には、ドライブ内にあるファイル（の一部）が示されている。通常、これらのファイルは矢印の右側に示されているように、階層化されている。 図 6.1: ファイルシステムの例 図6.1の左側にある Diary_YYYYMMDD.txt がYYYY年MM月DD日の日記を保存したテキストファイルだとしよう18。 3年間毎日日記を書くと、それだけでファイル数は1000個以上になる。また、Analysis_blahblah.R はRスクリプトである19。Rスクリプトファイルも複数ある。さらに、上の図には表示されていないが、自分で作ったファイル以外に、OSやソフトウェア（アプリ）を構成するファイルもドライブ内に保存されているだろう。これらのファイルが整理されずに1つの場所にまとめて置いてあるとしよう（上の図の左側の状態）。そうすると、特定のファイルを開いたり、それぞれのファイルがどのような目的で存在するのかを把握したりするのに少なからぬ労を要する。 単に面倒なだけならいい（私たちは面倒なことが大嫌いなので良くないと考える）が、ファイルの置き場が1つだけだと解決できない問題がある。それは、ファイル名の重複が許されないということだ。世の中には、特定の目的のために使われる「お決まりのファイル名」というものがある。例えば、GitHubにレポジトリを追加するときは、そのレポジトリについて説明する README.md というファイルを作ることになっている。しかし、名前が同じだとファイルが区別できないので、同じ場所にまったく同じ名前のファイルを2つ置くことはできない。したがって、ドライブ内にファイル置き場が1つしかないとなると、1つのパソコンで作れる README.md は1つだけということになってしまい、困ってしまう。 そこで、多くのOSではファイルをグループ化して管理するという方法が採用されている。このグループのことを「フォルダ (folder)」または「ディレクトリ (directory)」と呼ぶ20。 上の図の右側は、ファイルをフォルダに分けた様子を表している。 日記のテキストファイルに注目すると、まず、“Diary” という名前のフォルダがあり、Diary フォルダの中に年ごとのフォルダ “2018”, “2019”, “2020” というフォルダがある。それぞれの年のフォルダの中には、“January”, “February”, \\(\\dots\\), “December” という月ごとのフォルダがある。そして、それぞれの月のフォルダの中に、日付がファイル名になったテキストファイルd_01.txt, d_02.txt, \\(\\dots\\) が保存されている。この例からわかるように、フォルダの中にフォルダを作り、そのフォルダの中にフォルダを作り \\(\\cdots\\) ということができるので、フォルダを入れ子にした階層構造を利用してファイルを管理することができる。 ファイルを階層化して管理する場合、フォルダの構造と場所を把握することが必要になる。そのために使われるのがパス (path) である。パスは、コンピュータ内の住所のようなものだと考えればよい。例えば、“Diary” フォルダ内の “2018” フォルダ内の “January” フォルダ内の “d_01.txt” というファイルのパスは、Diary/2018/January/d_01.txt である。この例からわかるように、パスにはフォルダ名やファイル名がそのまま使われる。そして、フォルダの「中」であることは、/ （スラッシュ）記号によって表される。例えば、Diary/ の部分が、Diary フォルダの中であることを示す。ただし、Windows では / の代わりに \\（バックスラッシュ）または ￥（円記号; 日本語環境の場合）が使われる21。 Diary/2018/January/d_01.txt と Diary/2018/February/d_01.txt は、ファイル名だけを見れば同じ d_01.txt だが、パスが異なるので異なるファイルとして認識され、1つのドライブ内に共存することができる。 しかし、上に書いたパスは、“Diary” フォルダがどこにあるかを指定していないので完全ではない。パソコンがファイルの場所を正しく把握するには、“Diary” フォルダの置き場所がどこかという情報も必要である。 パソコン内でパスの起点になる場所は、OSによって異なる。Linux やmacOSでは、パスの起点となる最上位フォルダは / であり、多くのWindows機では C:\\ （Cドライブと呼ばれる）である22。また、多くのOSでは、ドライブ内に「ホーム (HOME)」と呼ばれる特別なフォルダがあらかじめ用意されており、通常はホームフォルダの中に自分で作ったファイルを保存する。ただし、ホームフォルダの名前は “HOME” ではないので注意が必要である。例えば、macOSではユーザ名がホームフォルダの名前である。例えば、ユーザ名が yukiなら /Users/yuki/ が、ユーザ名が jaehyunsong なら /Users/jaehyunsong/ がホームフォルダのパスである。パスの先頭に / がついており、最上位フォルダの中の “Users” フォルダの中にユーザ名でホームフォルダが作られれている。 ホームフォルダの中に Diary フォルダがあるとすると、2018年1月1日の日記までのパスは、 /Users/jaehyunsong/Diary/2018/January/d_01.txt である。このように、ドライブ内の起点から書いた完全なパスを 絶対パス (absolute path) または フルパス (full path) と呼ぶ。絶対パスを使えば、コンピュータ内の特定のファイルを一意に示すことができる。 絶対パスにホームディレクトリが含まれている場合には、ホームディレクトリまでのパスを省略して ${HOME}/ または ~/ と書くことができる。よって、上の絶対パスは、~/Diary/2018/January/d_01.txt と書くことができる。この書き方を使えば、パスを書き換えることなく共同研究者とファイルを共有することが可能になる（もちろん、ホームフォルダ以下の構造を揃える必要がある）。 自分が作業・操作の対象としているフォルダは、作業フォルダ (working directory; current directory) と呼ばれる23。絶対パスの代わりに、作業フォルダから見た相対パス (relative path)を使うこともできる。例えば、現在の作業フォルダが ~/Diary/2018/ だとすると、2018年1月1日の日記への相対パスは、Januaray/d_01.txt と書ける。 作業フォルダを指定していることを明示したい場合（プログラムを実行する場合にはこれが必要なことがある）には、 ./Januaray/d_01.txt と書く。つまり、./ が作業フォルダを示す。 また、作業フォルダよりも階層が1つ上のフォルダ（親 [parent] フォルダと呼ぶ）には、../ でアクセスでききる。例えば、、現在の作業フォルダが ~/Diary/2018/ だとすると、../ は ~/Diary/ なので、 2020年1月1日の日記への相対パスは ../2020/Januaray/d_01.txt と書くことができる。 相対パスの利点は、 絶対パスより短い 同じ構造を再利用できる ということである。1は自明だろう。2は、例えば日記の一覧を作るためのプログラムを書き、それを「年」を表すフォルダに保存すれば、1つひとつの日記に毎年同じ相対パスでアクセスできる（ただし、2月29日は除く）ので、毎年同じプログラムを利用できて便利である。絶対パスを使うと、「年」の部分を毎年書き換えなければいけない。 絶対パスと相対パスは、目的に応じて使い分けることが必要である。 6.2 「プロジェクト」のすゝめ Rを使ったプログラミングやデータ分析を進めていくと、自分が書いたRスクリプトや作成した図表だけでなく、 Rが自動的に生成するファイルもどんどん溜まる。そう遠くない将来、ドライブ内のファイル数が数万に達しても不思議ではない。効率よくプログラミングを行うために、ファイルの管理方法を明確にしておいたほうが良い。そのためには、フォルダの階層化を利用してファイルを管理することが必要である。 しかし、フォルダによる階層化を導入すればファイルの管理が楽になるかというと、必ずしもそうとは限らない。かえって不便になる部分もある。前の節で見たとおり、フォルダを階層化すると、絶対パスが長く（複雑に）なる。ファイルを階層化によって整理したとしても、ファイルを利用するたびに長い絶対パスの入力が必要なら、ファイル管理の効率が上がったとは言えないだろう。 Rを使う場合にファイル管理の効率化を助けてくれるのが、RStudio の「プロジェクト」機能である。 6.2.1 プロジェクト Rの既定（デフォルト）の作業フォルダはホームフォルダある。分析に使うデータが、ホームフォルダの中の Documents フォルダの中の R フォルダの中の Analysis1 フォルダ内の Data フォルダにある data.csv だとしたら、このファイルにアクセスするためには、\"Documents/R/Analysis1/Data/data.csv\"と入力する必要がある24 \\(^,\\) 25。新たに作った図を “histogram.pdf” という名前でホームフォルダの中の Documents フォルダの中の R フォルダの中の Analysis1 フォルダ内の Figures というフォルダに保存するためには、\"Documents/R/Analysis1/Figures/historam.pdf\"と入力する必要がある。どちらもかなり面倒で、効率が悪い。 しかし、作業フォルダが、~/Documents/R/Analysis1/ だとすれば、相対パスにより、\"Data/data.csv\" や\"Figures/historam.pdf\" だけで済む。よって、作業フォルダを明示的に指定すればいいわけだが、作業フォルダを毎回指定するのも面倒だ。 そこで利用できるのが、RStudio のプロジェクト機能である。 プロジェクトとは、特定のフォルダを作業フォルダに設定し、すべての作業をそのフォルダと下位フォルダのみに限定してくれる機能である26。プロジェクト機能さえ使えば、ユーザが意識しなくても、ユーザが書いたコード、保存したデータ、作成した図などが作業フォルダ内に集約され、管理が楽になる。 では、ここからプロジェクトの作り方を説明しよう。 まずはRStudio を起動する。 RStudio が起動したら、“File” から “New Project” を選択する。 図 6.2: FileからNew Project… 下の画面が表示されたら、 “New Directory” を選択する。ただし、既存のフォルダを利用したい場合は、 “Existing Directory” を選ぶ。 図 6.3: New Directoryを選択 下の画面が表示されたら、“New Project” を選択する。 前の手順で “Existing Directory” を選択した場合、この画面は表示されない。 図 6.4: New Projectを選択 下の画面が表示されたら、“Directory name:” にプロジェクト名を入力する。これがフォルダ名になるので、半角英数字のみの 名前を付ける。ここでは第4章のコードということで、“Ch04” にした。統計学の授業用プロジェクトなら “statistics”、計量政治学の授業なら “quant_methods_ps” などの名前を付ければ良いだろう。英語が嫌なら “tokeigaku” のようにすれば良い。また、“Create project as subdirectory of:” では、プロジェクトのフォルダをどのフォルダの中に設置するかを指定する。 “Browse…” をクリックし、親フォルダを選ぶ。ここでは ~/Dropbox/RStudy にプロジェクトのフォルダを入れることにする。ここまでできたら、“Create Project” をクリックする。 手順3で “Existing Directory” を選んだ場合、プロジェクトのフォルダとして使う既存フォルダを選択する画面が表示される。 図 6.5: プロジェクト名と保存場所の指定 以上の手順でプロジェクトができる。RStudio 右上に、プロジェクト名が表示されているはずだ。 また、Console に getwd() と入力すると、プロジェクトまでの絶対パスが表示される。 念のため、Finder（Macの場合）やエクスプローラー （Windows の場合）で、指定した場所にプロジェクトのフォルダ（上の例では Ch04）が生成されていることを確認しよう。 プロジェクトフォルダを開いてみると、Ch04.Rproj というファイルが生成されていることがわかる（下の図）。 図 6.6: プロジェクトの確認 Ch04 プロジェクトを開くには、このCh04.Rproj ファイルをダブルクリックすれば良い。RStudio が起動していない場合でも、指定のプロジェクトを開いた状態でRStudio が起ち上がる。 RStudio 右上の表示が “Project: (None)” となっているときは、プロジェクトが開かれていない。 RStudio を使う場合には、必ず右上の表示を見て、プロジェクトが開かれていることを確認しよう。 プロジェクトが開かれていない場合には、既存のプロジェクトを開くか、新たばプロジェクトを作ろう。 6.3 電卓としてのR 前置きが長かったが、ここからはRを使っていこう。まず、新しい R Script を開くために、Cmd/Ctrl + Shift + N を入力する27（“File” メニューから “New File” - “R Script” を選んでも良い）。すると、 左上の Source Pane に “Untitled1” というタブが登場し、その pane 上でコードが入力できるようになる。ここで 3 + 3 と入力し、その行にカーソルを留めたまま command + return（Mac）または Ctrl + Enter を押してみよう。command + return というのは、command キーを押したまま、return キーも押すという意味である。 図 6.7: コード入力の例 Source ペイン (Untitled1) に入力したコードが Console（本書の説明どおりにカスタマイズしていれば、RStudio 内の右上画面）に転送され、計算結果が表示される。Rのコードは Console に直接打ち込むこともできるが、Sourceペインで入力してから Console に転送する方法が基本である28。 Source ペインの内容をファイルに保存すれば、後でもう1度同じコードを実行したり、コードを他のプロジェクトで再利用することができるようになる。先ほど 3 + 3 を入力した画面にカーソルを合わせ、Cmd/Ctrl + S を押してみよう。ファイルの保存を促されるので、ファイル名をつけて保存しよう。このとき、.R というファイル名拡張子を付ける。これにより、ファイルがRスクリプトとして認識される。例えば、“practice01.R” という名前をつけて保存しよう。Sourceペインの上部に表示されるタブの名前が、“Untitled1” から “practice01.R” に変わることが確認できるはずだ。 以下にRで計算する例を示すので、コードを practice01.R に入力し、command + return （Ctrl + Enter） で Console に送り、実行結果を確認しよう。背景が灰色になっている部分に示されているのが、Rのコマンドである。ただし、##から始まる部分は計算結果である。また、コードブロックのうち、 #（ハッシュ記号）で始まる部分はコメントであり、Rで評価（計算）されない。コメントの使い方 については第21 章で詳しく解説する。 6.3.1 算術演算子 まずは、簡単な足し算と掛け算を実行してみよう。 3 + 3 ## [1] 6 8 * 2 ## [1] 16 これ以外の基本的な演算は以下のとおりである。 演算子 意味 例 結果 + 和 2 + 5 7 - 差 2 - 8 -6 * 積 7 * 3 21 / 商 16 / 5 3.2 ^、** 累乗（べき乗） 2^3または2 ** 3 8 %% 剰余 (モジュロ) 18 %% 7 4 %/% 整数商 18 %/% 7 2 6.3.2 論理演算子 論理演算子とは、入力した式が真か偽かを判定する演算子である。返り値（戻り値）は TRUE（真の場合）または FALSE（偽の場合）のいずれかとなる。たとえば、「3 &gt; 2」は真なので、TRUE が返される。しかし、「2 + 3 = 1」は偽なので、FALSEが返される。実際にやってみよう。 3 &gt; 2 ## [1] TRUE 2 + 3 == 1 ## [1] FALSE このように、等しいかどうかを表す記号は = ではなく ==（二重等号）なので注意されたい。 論理演算子にも、いくつかの種類がある。 演算子 意味 例 結果 1 x &lt; y xはyより小さい 3 &lt; 1 FALSE 2 x &lt;= y xはyと等しいか、小さい 2 &lt;= 2 TRUE 3 x &gt; y xはyより大きい 6 &gt; 5 TRUE 4 x &gt;= y xはyと等しいか、大きい 4 &gt;= 5 FALSE 5 x == y xとyは等しい (2 + 3) == (4 + 1) TRUE 6 x != y xとyは等しくない ((2 * 3) + 1) != (2 * (3 + 1)) TRUE 6番目の例について少し説明する。通常の数式同様、Rも括弧()内の記述を優先的に計算する。したがって、!=左側の((2 * 3) + 1) は 6 + 1 = 7 であり、右側の (2 * (3 + 1)) は 2 * 4 = 8 である。したがって、7 != 8 が判定対象となり、TRUEが返される。! 記号は、「否定」を表すために使われるもので、!= は左右が等しくないときに TRUE を返す 上に挙げた論理演算子は基本的に数字を対象に使うが、TRUEとFALSE を対象に使うものもある。それが and を表す &amp; と or を表す| である。。&amp; は、&amp; を挟む左右の両側が TRUE の場合のみ TRUE を返し、| は少なくとも一方が TRUE なら TRUE を返す。 演算子 意味 例 結果 1 x | y xまたはy (2 + 3 == 5) | (1 * 2 == 3) TRUE 2 x &amp; y xかつy (2 + 3 == 5) &amp; (1 * 2 == 3) FALSE 1番の例では、|の左側は(2 + 3 == 5)であり、TRUE である。一方、右側の(1 * 2 == 3) は FALSE だ。判定対象はTRUE | FALSE となり、TRUE が返される。 2番目の例は TRUE &amp; FALSE なので、返り値は FALSE になる。 6.4 格納とオブジェクトの作成 まず、123454321 * 2 を計算しよう。 次に、123454321 * 3 を計算しよう。 最後に、123454321 * 4 を計算しよう。 これらの計算は簡単にできるだろう。しかし、123454321を3回入力するのが面倒だっただろう29。123454321という数字をxとかaに代入し、数字の代わりに x や a が使えるなら、上の計算は楽になる。ここではその方法を説明する。 xというものに123454321という数字を入れるには、&lt;- という演算子を使う。この演算子により、xという名のもの （オブジェクト）に123454321という数字を代入することができる。ここでは「代入」という表現を使ったが30、&lt;-の役割は代入よりも広いので、これからは「格納」という表現を使う。 &lt;- は、&lt; と- という2つの記号をスペースなしで入力することで作ることができる。 RStudioでは、 option + - [マイナス, ハイフン] (macOS 場合) または Alt + - （Windows の場合）で、&lt;- が入力できる。その際、演算子の前後に半角スペースが1つずつ挿入されるので、このショートカットは必ず使うべきである。 Rを起動した時点では、x というオブジェクトは存在しない。RStudio 右下のペインにある Environment タブを開くと、現時点では何も表示されていないはずだ。しかし、x に何かを格納することで、x というオブジェクトができる。 実際に xに、123454321を格納してみよう。 x &lt;- 123454321 # xに123454321を格納 Environment タブに、x が登場し、格納した数字が右側に表示されていることが確認できるだろう。 オブジェクトの中身は、オブジェクト名をそのまま入力することで表示できる。 x ## [1] 123454321 print(x) でも同じ結果が得られるが、タイプする文字数を減らしたいので xのみにする。ただし、状況やオブジェクトの型（型については後で詳しく説明する）によっては、print() を表示しないと中身が表示されない場合もあるので、R Markdown ファイルで論文などを作成していて、結果を確実に表示したい場合には print(x) とするほうが安全である。 ちなみに、格納と同時にそのオブジェクトの中身を表示することもできる。そのためには、格納コマンド全体を() で囲む。例えば、次のようにする。 (y &lt;- 2) # yに2を格納し、中身を表示 ## [1] 2 値が格納されたオブジェクトは計算に利用できるので、先ほどの計算は、次のようにできる。 x * 2 ## [1] 246908642 x * 3 ## [1] 370362963 x * 4 ## [1] 493817284 文字列を格納することもできる。ただし、文字列は必ず \"\" か '' で囲む必要がある。 x &lt;- &quot;猫の恋 やむとき閨の 朧月（芭蕉）&quot; x ## [1] &quot;猫の恋 やむとき閨の 朧月（芭蕉）&quot; オブジェクトに格納できるのは1つの数値や文字列だけではない。複数の数値や文字列を格納することもできる。そのためには c() という関数を使う。c() のc は concatenate または combine の頭文字で、複数の要素からベクトル (vector) を作るのに使われる関数である。 c() に含む要素はカンマ (,) で区切る。 # ある日の Lions の打順をベクトルに格納する numeric_vec1 &lt;- c(73, 6, 5, 3, 99, 10, 22, 9, 7) numeric_vec1 ## [1] 73 6 5 3 99 10 22 9 7 複数の文字列を格納することもできる。 character_vec &lt;- c(&#39;cat&#39;, &#39;cheetah&#39;, &#39;lion&#39;, &#39;tiger&#39;) character_vec ## [1] &quot;cat&quot; &quot;cheetah&quot; &quot;lion&quot; &quot;tiger&quot; ひとつひとつの要素を指定する代わりに、様々な方法でベクトルを作ることが可能である。 たとえば、seq() 関数を使うと、一連の数字からなるベクトルを作ることができる。from で数列の初項を、to で数列の最終項を指定し、by で要素間の差（第2要素は第1要素に by を加えた値になる ）を指定するか、length.out で最終的にできるベクトルの要素の数を指定する。Rのベクトルの length とは、要素の数のことなので、注意されたい。 いくつか例を挙げる。 # 1から20までの整数。1:20 でも同じ seq(from = 1, to = 20, by = 1) ## [1] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 1から19までの奇数 seq(from = 11, to = 20, by = 2) ## [1] 11 13 15 17 19 # 2から20までの偶数 seq(from = 2, to = 20, by = 2) ## [1] 2 4 6 8 10 12 14 16 18 20 # 降順、間隔は5 seq(from = 20, to = 1, by = -5) ## [1] 20 15 10 5 # 最小値が1、最大値が100で、長さが10のベクトル seq(from = 1, to = 100, length.out = 10) ## [1] 1 12 23 34 45 56 67 78 89 100 # 73から1つずつ数が小さくなる長さが10のベクトル seq(from = 73, by = -1, length.out = 8) ## [1] 73 72 71 70 69 68 67 66 このように1つの関数でも指定する内容は、by になったりlength.out になったりする。by や length.out、from、to などのように、関数で指定する対象になっているもののことを 仮引数 (parameter) と呼ぶ。また、by = 1 の1や、length.out = 10 の10のように、仮引数に実際に渡される値のことを実引数 (argument) と呼ぶ。特に誤解が生じないと思われる場合には、仮引数と実引数を区別せずに引数（ひきすう）と呼ぶ。 Rでは、1つの関数で使う引数の数が複数あることが多いので、仮引数を明示する習慣を身につけたほうがよい。 ただし、第1引数（関数で最初に指定する引数）として必ず入力すべきものは決められている場合がほとんどなので、第1引数の仮引数は省略されることが多い。仮引数が省略される代わりに、第1引数の実引数はほぼ必ず入力する（いくつかの例外もある）。 seq(from = x, to = y, by = 1) の場合はより単純に x:y とすることができる。 21:30 # 21 から30までの整数 ## [1] 21 22 23 24 25 26 27 28 29 30 10:1 # 10 から1までの整数（降順） ## [1] 10 9 8 7 6 5 4 3 2 1 また、rep() 関数も便利である。例を挙げよう。 # 3が10個のベクトル rep(3, times = 10) ## [1] 3 3 3 3 3 3 3 3 3 3 # aが3つ, bが1つ, cが2つのベクトル rep(c(&#39;a&#39;, &#39;b&#39;, &#39;c&#39;), times = c(3, 1, 2)) ## [1] &quot;a&quot; &quot;a&quot; &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;c&quot; # C, A, T を2つずつ rep(c(&#39;C&#39;, &#39;A&#39;, &#39;T&#39;), each = 2) ## [1] &quot;C&quot; &quot;C&quot; &quot;A&quot; &quot;A&quot; &quot;T&quot; &quot;T&quot; アルファベットのベクトルは、あらかじめ用意されている。 LETTERS # 大文字 ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; &quot;G&quot; &quot;H&quot; &quot;I&quot; &quot;J&quot; &quot;K&quot; &quot;L&quot; &quot;M&quot; &quot;N&quot; &quot;O&quot; &quot;P&quot; &quot;Q&quot; &quot;R&quot; &quot;S&quot; ## [20] &quot;T&quot; &quot;U&quot; &quot;V&quot; &quot;W&quot; &quot;X&quot; &quot;Y&quot; &quot;Z&quot; letters # 小文字 ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; &quot;k&quot; &quot;l&quot; &quot;m&quot; &quot;n&quot; &quot;o&quot; &quot;p&quot; &quot;q&quot; &quot;r&quot; &quot;s&quot; ## [20] &quot;t&quot; &quot;u&quot; &quot;v&quot; &quot;w&quot; &quot;x&quot; &quot;y&quot; &quot;z&quot; 6.5 要素の抽出 オブジェクト名（ベクトル）の後に [抽出する要素のインデクス] を付けると、ベクトルの特定の要素を抽出することができる。ちなみに [ は関数である。Console にhelp(\"[\") と打てば、これが Extract と言う名前の関数であることがわかる（help(\"[]\") ではないので注意）。 ベクトルの要素を取り出してみよう。Rのインデクスは、他の多くのプログラミング言語（例えば、C, C++, Pythonなど）とは異なり「1」から始まるので注意されたい。 # numeric_vec1の5番目の要素を抽出 numeric_vec1[5] ## [1] 99 # numeric_vec1の2, 4, 6番目の要素を抽出 numeric_vec1[c(2, 4, 6)] ## [1] 6 3 10 # numeric_vec1の1番目と4番目「以外」の要素を抽出 numeric_vec1[-c(1, 4)] ## [1] 6 5 99 10 22 9 7 # numeric_vec1の5番目から7番目の要素を抽出 numeric_vec1[5:7] ## [1] 99 10 22 c()や:だけでなく、seq()も使える。 numeric_vec2 &lt;- 1:20 # numeric_vec2 の奇数番目の要素を抽出 numeric_vec2[seq(1, 20, by = 2)] ## [1] 1 3 5 7 9 11 13 15 17 19 さらに、TRUEとFALSEを使うこともできる。この場合、抽出したい要素の場所を指定するのではなく、それぞれの場所について抽出する (TRUE) か、しない (FALSE) かを指定する。たとえば、character_vecから1, 3, 4番目の要素を抽出するなら、[c(TRUE, FALSE, TRUE, TRUE)]と指定する。 character_vec[c(TRUE, FALSE, TRUE, TRUE)] ## [1] &quot;cat&quot; &quot;lion&quot; &quot;tiger&quot; TRUEとFALSEが使えるので、論理演算子を[]の中で使うこともできる。たとえば、numeric_vec1の各要素が偶数かどうかを判定するためには、インデックスが2で割り切れるかどうか（2で割った余りが0かどうか）を確認すれば良い。 (numeric_vec1 %% 2) == 0 # 偶数かどうかの判定 ## [1] FALSE TRUE FALSE FALSE FALSE TRUE TRUE FALSE FALSE これを利用すれば、numeric_vec1から偶数のみを抽出できる。 numeric_vec1[(numeric_vec1 %% 2) == 0] ## [1] 6 10 22 [ と格納（代入）を組み合わせれば、「ベクトルの一部の要素を書き換える」ことができる。たとえば、numeric_vec1の2番目の要素は5だが、これを100に書き換えたい場合、置換したい要素の場所を[]で指定し、&lt;-で代入すれば良い。 numeric_vec1[2] &lt;- 100 numeric_vec1 ## [1] 73 100 5 3 99 10 22 9 7 複数の要素を置換することもできる。たとえば、偶数を全て0に置換したい場合、以下のようにする。 numeric_vec1[(numeric_vec1 %% 2) == 0] &lt;- 0 numeric_vec1 ## [1] 73 0 5 3 99 0 0 9 7 演習問題 問1 my_vec1という名のオブジェクトに(3, 9, 10, 8, 3, 5, 8)を格納し、表示せよ。 問2 my_vec1から2, 4, 6番目の要素を抽出せよ。 問3 my_vec1の要素の和を求めよ。 ベクトル内要素の和はsum(ベクトル名)で計算できる。たとえば、ベクトルc(1, 3, 5)の和はsum(c(1, 3, 5))である。 問4 my_vec1の要素から奇数のみを抽出し、その和を求めよ。 問5 my_vec2という名のオブジェクトに長さ7のベクトル、(1, 2, 3, 4, 3, 2, 1)を格納し、表示せよ。 問6 my_vec1とmy_vec2のそれぞれの要素の和を計算し、my_vec3に格納し、表示せよ。 問7 my_vec3の要素から10未満の要素を抽出せよ。 問7 1から100までの公差1の数列 (1, 2, 3, 4, 5, …, 100)を作成し、my_vec4と名付けよ。 問9 my_vec4の各要素を二乗した総和 (\\(1^2 + 2^2 + 3^2 + \\dots + 100^2\\))を求めよ。 問10 my_vec4から奇数のみ抽出し、二乗和 (\\(1^2 + 3^2 + 5^2 + 7^2 + \\dots + 97^2 + 99^2\\))を求めよ。 "],["io.html", "7. データの入出力 7.1 データの読み込み 7.2 データの書き出し", " 7. データの入出力 この章で使うパッケージを読み込む。 pacman::p_load(tidyverse, readxl, haven) 7.1 データの読み込み 7.1.1 csvファイルの場合 csv は、comma separated values の略である。多くの人に馴染みがあると思われる Excelファイル (.xlsx) と同じように、表形式（行列形式）のデータを保存できる。しかし、Excelファイルとは異なり、文字の大きさ、セルの背景色、複数のセルの結合のような情報はもたず、純粋にデータに含まれる変数の名前と各変数の値（数値・文字列）のみが格納されているため、ファイルサイズが小さい。また、文字データしかもたないテキストファイルであり、テキストエディタで開くことができる。テキストファイルで csv ファイルを開けば、“csv” と呼ばれる理由がわかるだろう。csvフォーマットはデータを保存のための標準フォーマットの1つであり、多くのデータがcsv形式で保存されている。データ分析ソフトでcsv ファイルを開けないものはおそらくないだろう。 Rでもcsv形式のファイルは簡単に読み込める。実際にやっててみよう。データのダウンロード方法については本書の巻頭を参照されたい。csvファイルを読み込むにはread.csv()またはreadr::read_csv()関数を使う31。読み込む際は前章のベクトルの生成同様、何らかの名前を付けて作業環境に保存する。Dataフォルダーにある FIFA_Women.csv ファイルを読み込み、my_df1と名付ける場合、以下のようなコードを実行する32。以下のコードでmy_df1 &lt;- の部分を入力しないと、データが画面に出力され、自分の作業スペースには保存されないので注意されたい。 my_df1 &lt;- read.csv(&quot;Data/FIFA_Women.csv&quot;) 読み込まれたデータの中身を見るには、ベクトルの場合と同様にprint()関数を使うか、オブジェクト名を入力する。 my_df1 ## ID Team Rank Points Prev_Points Confederation ## 1 1 Albania 75 1325 1316 UEFA ## 2 2 Algeria 85 1271 1271 CAF ## 3 3 American Samoa 133 1030 1030 OFC ## 4 4 Andorra 155 749 749 UEFA ## 5 5 Angola 121 1117 1117 CAF ## 6 6 Antigua and Barbuda 153 787 787 CONCACAF ## 7 7 Argentina 32 1659 1659 CONMEBOL ## 8 8 Armenia 126 1103 1104 UEFA ## 9 9 Aruba 157 724 724 CONCACAF ## 10 10 Australia 7 1963 1963 AFC ## 11 11 Austria 22 1792 1797 UEFA ## 12 12 Azerbaijan 76 1321 1326 UEFA ## 13 13 Bahrain 84 1274 1274 AFC ## 14 14 Bangladesh 134 1008 1008 AFC ## 15 15 Barbados 135 1002 1002 CONCACAF ## 16 16 Belarus 53 1434 1437 UEFA ## 17 17 Belgium 17 1819 1824 UEFA ## 18 18 Belize 150 824 824 CONCACAF ## 19 19 Bermuda 136 987 987 CONCACAF ## 20 20 Bhutan 154 769 769 AFC ## 21 21 Bolivia 91 1236 1236 CONMEBOL ## 22 22 Bosnia and Herzegovina 59 1411 1397 UEFA ## 23 23 Botswana 148 848 848 CAF ## 24 24 Brazil 8 1958 1956 CONMEBOL ## 25 25 Bulgaria 79 1303 1303 UEFA ## 26 26 Cameroon 51 1455 1486 CAF ## 27 27 Canada 8 1958 1958 CONCACAF ## 28 28 Chile 37 1640 1637 CONMEBOL ## 29 29 China PR 15 1867 1842 AFC ## 30 30 Chinese Taipei 40 1589 1584 AFC ## 31 31 Colombia 25 1700 1700 CONMEBOL ## 32 32 Comoros 156 731 731 CAF ## 33 33 Congo 104 1178 1178 CAF ## 34 34 Congo DR 110 1159 1159 CAF ## 35 35 Cook Islands 103 1194 1194 OFC ## 36 36 Costa Rica 36 1644 1630 CONCACAF ## 37 37 Côte d&#39;Ivoire 63 1392 1392 CAF ## 38 38 Croatia 52 1453 1439 UEFA ## 39 39 Cuba 88 1240 1240 CONCACAF ## 40 40 Cyprus 123 1114 1123 UEFA ## 41 41 Czech Republic 29 1678 1678 UEFA ## 42 42 Denmark 16 1851 1839 UEFA ## 43 43 Dominican Republic 105 1173 1173 CONCACAF ## 44 44 El Salvador 109 1164 1164 CONCACAF ## 45 45 England 6 1999 2001 UEFA ## 46 46 Equatorial Guinea 71 1356 1356 CAF ## 47 47 Estonia 95 1210 1206 UEFA ## 48 48 Eswatini 151 822 822 CAF ## 49 49 Ethiopia 111 1151 1151 CAF ## 50 50 Faroe Islands 86 1259 1262 UEFA ## 51 51 Fiji 66 1373 1373 OFC ## 52 52 Finland 30 1671 1678 UEFA ## 53 53 France 3 2036 2033 UEFA ## 54 54 Gabon 130 1066 1066 CAF ## 55 55 Gambia 113 1143 1183 CAF ## 56 56 Georgia 115 1138 1145 UEFA ## 57 57 Germany 2 2090 2078 UEFA ## 58 58 Ghana 60 1401 1404 CAF ## 59 59 Greece 62 1396 1395 UEFA ## 60 60 Guam 82 1282 1282 AFC ## 61 61 Guatemala 80 1290 1290 CONCACAF ## 62 62 Haiti 64 1391 1368 CONCACAF ## 63 63 Honduras 116 1136 1136 CONCACAF ## 64 64 Hong Kong 74 1329 1335 AFC ## 65 65 Hungary 43 1537 1526 UEFA ## 66 66 Iceland 19 1817 1821 UEFA ## 67 67 India 55 1432 1432 AFC ## 68 68 Indonesia 94 1222 1222 AFC ## 69 69 IR Iran 70 1358 1358 AFC ## 70 70 Israel 67 1369 1371 UEFA ## 71 71 Italy 14 1889 1882 UEFA ## 72 72 Jamaica 50 1460 1461 CONCACAF ## 73 73 Japan 11 1937 1942 AFC ## 74 74 Jordan 58 1419 1419 AFC ## 75 75 Kazakhstan 77 1318 1318 UEFA ## 76 76 Kenya 137 986 986 CAF ## 77 77 Korea DPR 10 1940 1940 AFC ## 78 78 Korea Republic 18 1818 1812 AFC ## 79 79 Kosovo 125 1104 1109 UEFA ## 80 80 Kyrgyz Republic 120 1118 1118 AFC ## 81 81 Latvia 93 1223 1223 UEFA ## 82 82 Lebanon 141 967 967 AFC ## 83 83 Lesotho 147 850 850 CAF ## 84 84 Lithuania 107 1169 1168 UEFA ## 85 85 Luxembourg 119 1124 1124 UEFA ## 86 86 Madagascar 158 691 691 CAF ## 87 87 Malawi 145 887 887 CAF ## 88 88 Malaysia 90 1238 1238 AFC ## 89 89 Maldives 142 966 966 AFC ## 90 90 Mali 83 1276 1276 CAF ## 91 91 Malta 101 1197 1195 UEFA ## 92 92 Mauritius 159 357 357 CAF ## 93 93 Mexico 27 1686 1699 CONCACAF ## 94 94 Moldova 92 1228 1229 UEFA ## 95 95 Mongolia 123 1114 1114 AFC ## 96 96 Montenegro 97 1201 1206 UEFA ## 97 97 Morocco 81 1289 1280 CAF ## 98 98 Mozambique 152 814 814 CAF ## 99 99 Myanmar 45 1511 1527 AFC ## 100 100 Namibia 143 956 956 CAF ## 101 101 Nepal 99 1200 1200 AFC ## 102 102 Netherlands 4 2032 2035 UEFA ## 103 103 New Caledonia 96 1208 1208 OFC ## 104 104 New Zealand 23 1757 1760 OFC ## 105 105 Nicaragua 122 1116 1116 CONCACAF ## 106 106 Nigeria 38 1614 1614 CAF ## 107 107 North Macedonia 129 1072 1073 UEFA ## 108 108 Northern Ireland 55 1432 1433 UEFA ## 109 109 Norway 12 1930 1929 UEFA ## 110 110 Palestine 117 1131 1131 AFC ## 111 111 Panama 60 1401 1437 CONCACAF ## 112 112 Papua New Guinea 46 1504 1504 OFC ## 113 113 Paraguay 48 1490 1490 CONMEBOL ## 114 114 Peru 65 1376 1376 CONMEBOL ## 115 115 Philippines 67 1369 1369 AFC ## 116 116 Poland 28 1683 1677 UEFA ## 117 117 Portugal 32 1659 1667 UEFA ## 118 118 Puerto Rico 106 1172 1172 CONCACAF ## 119 119 Republic of Ireland 31 1666 1665 UEFA ## 120 120 Romania 44 1535 1542 UEFA ## 121 121 Russia 24 1708 1708 UEFA ## 122 122 Rwanda 144 899 899 CAF ## 123 123 Samoa 107 1169 1169 OFC ## 124 124 Scotland 21 1804 1794 UEFA ## 125 125 Senegal 87 1247 1245 CAF ## 126 126 Serbia 41 1558 1553 UEFA ## 127 127 Singapore 128 1089 1089 AFC ## 128 128 Slovakia 47 1501 1500 UEFA ## 129 129 Slovenia 49 1471 1467 UEFA ## 130 130 Solomon Islands 114 1140 1140 OFC ## 131 131 South Africa 53 1434 1434 CAF ## 132 132 Spain 13 1915 1900 UEFA ## 133 133 Sri Lanka 140 968 968 AFC ## 134 134 St. Kitts and Nevis 131 1050 1054 CONCACAF ## 135 135 St. Lucia 138 982 982 CONCACAF ## 136 136 Suriname 127 1093 1093 CONCACAF ## 137 137 Sweden 5 2007 2022 UEFA ## 138 138 Switzerland 20 1815 1817 UEFA ## 139 139 Tahiti 102 1196 1196 OFC ## 140 140 Tajikistan 132 1035 1035 AFC ## 141 141 Tanzania 139 978 978 CAF ## 142 142 Thailand 39 1596 1620 AFC ## 143 143 Tonga 88 1240 1240 OFC ## 144 144 Trinidad and Tobago 72 1354 1354 CONCACAF ## 145 145 Tunisia 78 1304 1313 CAF ## 146 146 Turkey 69 1365 1361 UEFA ## 147 147 Uganda 146 868 868 CAF ## 148 148 Ukraine 26 1692 1697 UEFA ## 149 149 United Arab Emirates 97 1201 1201 AFC ## 150 150 Uruguay 73 1346 1346 CONMEBOL ## 151 151 US Virgin Islands 149 843 843 CONCACAF ## 152 152 USA 1 2181 2174 CONCACAF ## 153 153 Uzbekistan 42 1543 1543 AFC ## 154 154 Vanuatu 117 1131 1131 OFC ## 155 155 Venezuela 57 1425 1425 CONMEBOL ## 156 156 Vietnam 35 1657 1665 AFC ## 157 157 Wales 34 1658 1659 UEFA ## 158 158 Zambia 100 1198 1167 CAF ## 159 159 Zimbabwe 111 1151 1151 CAF しかし、通常はデータが読み込まれているかどうかを確認するためにデータ全体を見る必要はない。最初の数行のみで問題ないはずだ。そのために、head() 関数を使う。これは最初の6行 (n で表示行数を変える) を表示してくれる。 head(my_df1) ## ID Team Rank Points Prev_Points Confederation ## 1 1 Albania 75 1325 1316 UEFA ## 2 2 Algeria 85 1271 1271 CAF ## 3 3 American Samoa 133 1030 1030 OFC ## 4 4 Andorra 155 749 749 UEFA ## 5 5 Angola 121 1117 1117 CAF ## 6 6 Antigua and Barbuda 153 787 787 CONCACAF 同様に、最後の n行はtail() で表示する。 tail(my_df1, n = 9) ## ID Team Rank Points Prev_Points Confederation ## 151 151 US Virgin Islands 149 843 843 CONCACAF ## 152 152 USA 1 2181 2174 CONCACAF ## 153 153 Uzbekistan 42 1543 1543 AFC ## 154 154 Vanuatu 117 1131 1131 OFC ## 155 155 Venezuela 57 1425 1425 CONMEBOL ## 156 156 Vietnam 35 1657 1665 AFC ## 157 157 Wales 34 1658 1659 UEFA ## 158 158 Zambia 100 1198 1167 CAF ## 159 159 Zimbabwe 111 1151 1151 CAF ただし、今後、特殊な事情がない限り、データの読み込みはread.csv()を使用せず、read_csv()を使用しますが、使い方は同じです。read_csv()は{tidyverse}の一部である{readr}パッケージに含まれている関数であるため、あらかじめ{tidyverse}を読み込んでおく必要があります。 pacman::p_load(tidyverse) my_df1 &lt;- read_csv(&quot;Data/FIFA_Women.csv&quot;) my_df1 ## # A tibble: 159 × 6 ## ID Team Rank Points Prev_Points Confederation ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 Albania 75 1325 1316 UEFA ## 2 2 Algeria 85 1271 1271 CAF ## 3 3 American Samoa 133 1030 1030 OFC ## 4 4 Andorra 155 749 749 UEFA ## 5 5 Angola 121 1117 1117 CAF ## 6 6 Antigua and Barbuda 153 787 787 CONCACAF ## 7 7 Argentina 32 1659 1659 CONMEBOL ## 8 8 Armenia 126 1103 1104 UEFA ## 9 9 Aruba 157 724 724 CONCACAF ## 10 10 Australia 7 1963 1963 AFC ## # … with 149 more rows 同じファイルが読み込まれましたが、データを出力する際、最初の10行のみが表示されます。また、画面に収まらない横長のデータであれば、適宜省略し、見やすく出力してくれます。read_csv()で読み込まれた表形式データはtibbleと呼ばれるやや特殊なものとして格納されます。Rがデフォルトで提供する表形式データの構造はdata.frameですが、tibbleはその拡張版です。詳細は第9.4章を参照してください。 7.1.2 エンコーディングの話 Vote_ShiftJIS.csv はShift-JIS でエンコーディングされた csvファイルである。このファイルを read.csv() 関数で読み込んでみよう。 ShiftJIS_df &lt;- read.csv(&quot;Data/Vote_ShiftJIS.csv&quot;) ## Error in type.convert.default(data[[i]], as.is = as.is[i], dec = dec, : invalid multibyte string at &#39;&lt;96&gt;k&lt;8a&gt;C&lt;93&gt;&lt;b9&gt;&#39; Windowsならなんの問題なく読み込まれるだろう。しかし、macOSの場合、以下のようなエラーが表示され、読み込めない。 ## Error in type.convert.default(data[[i]], as.is = as.is[i], dec = dec, : &#39;&lt;96&gt;k&lt;8a&gt;C&lt;93&gt;&lt;b9&gt;&#39; に不正なマルチバイト文字があります このファイルは、read.csv()の代わりに readrパッケージのread_csv()を使えば読み込むことができる33。read_csv()で読み込み、中身を確認してみよう。 ShiftJIS_df1 &lt;- read_csv(&quot;Data/Vote_ShiftJIS.csv&quot;) head(ShiftJIS_df1) ## # A tibble: 6 × 11 ## ID Pref Zaisei Over65 Under30 LDP DPJ Komei Ishin JCP SDP ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 &quot;\\x96k\\x8aC\\x… 0.419 29.1 24.7 32.8 30.6 13.4 3.43 11.4 1.68 ## 2 2 &quot;\\x90\\xc2\\x90… 0.332 30.1 23.9 40.4 24.6 12.8 3.82 8.92 3.41 ## 3 3 &quot;\\x8a\\xe2\\x8e… 0.341 30.4 24.5 34.9 22.4 8.61 5.16 11.2 5.29 ## 4 4 &quot;\\x8b{\\x8f\\xe… 0.596 25.8 27.3 36.7 25.4 13.4 3.97 9.99 3.62 ## 5 5 &quot;\\x8fH\\x93c\\x… 0.299 33.8 21.4 43.5 22.7 11.2 5.17 7.56 5.12 ## 6 6 &quot;\\x8eR\\x8c`\\x… 0.342 30.8 24.8 42.5 21.5 11.8 4.3 7.6 5.2 2列目のPref列には日本語で都道府県名が入っているはずだが、謎の文字列が表示される。read.csv()の場合、少なくともWindowsでは問題なく読み込めたはずだ。なぜならread.csv()はWindowsの場合、Shift-JISで、macOSの場合UTF-8でファイルを読み込む。一方、read_csv()はOSと関係なく世界標準であるUTF-8でファイルを読み込むからだ。 正しい都道府県名を表示する方法はいくつかあるが、ここでは3つの方法を紹介する。 1. read.csv()関数のfileEncoing引数の指定 一つ目の方法は、read.csv()関数の fileEncoding 引数を追加するというものだる。この引数に、指定したファイルのエンコーディングを指定すればよいが、Shift-JISの場合、\"Shift_JIS\" を指定する。ハイフン (-)ではなく、アンダーバー (_) であることに注意されたい。この\"Shift_JIS\"は\"cp932\" に書き換えても良い。それではやってみよう。 ShiftJIS_df2 &lt;- read.csv(&quot;Data/Vote_ShiftJIS.csv&quot;, fileEncoding = &quot;Shift_JIS&quot;) head(ShiftJIS_df2) ## ID Pref Zaisei Over65 Under30 LDP DPJ Komei Ishin JCP SDP ## 1 1 北海道 0.41903 29.09 24.70 32.82 30.62 13.41 3.43 11.44 1.68 ## 2 2 青森県 0.33190 30.14 23.92 40.44 24.61 12.76 3.82 8.92 3.41 ## 3 3 岩手県 0.34116 30.38 24.48 34.90 22.44 8.61 5.16 11.24 5.29 ## 4 4 宮城県 0.59597 25.75 27.29 36.68 25.40 13.42 3.97 9.99 3.62 ## 5 5 秋田県 0.29862 33.84 21.35 43.46 22.72 11.19 5.17 7.56 5.12 ## 6 6 山形県 0.34237 30.76 24.75 42.49 21.47 11.78 4.30 7.60 5.20 Pref列の日本語が正常に表示された。むろん、WindowsならfileEncoding引数がなくても読み込める。むしろ、UTF-8で書かれたファイルが読み込めない可能性がある。この場合はfileEncoding = \"UTF-8\"を指定すれば良い。 2. read_csv()関数のlocale引数の指定 二つ目の方法は read_csv() 関数のlocale 引数を指定する方法である。read_csv()には fileEncoding 引数がないが、代わりに locale があるので、locale = locale(encoding = \"Shift_JIS\")を追加すれば良い。 ShiftJIS_df3 &lt;- read_csv(&quot;Data/Vote_ShiftJIS.csv&quot;, locale = locale(encoding = &quot;Shift_JIS&quot;)) head(ShiftJIS_df3) ## # A tibble: 6 × 11 ## ID Pref Zaisei Over65 Under30 LDP DPJ Komei Ishin JCP SDP ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 北海道 0.419 29.1 24.7 32.8 30.6 13.4 3.43 11.4 1.68 ## 2 2 青森県 0.332 30.1 23.9 40.4 24.6 12.8 3.82 8.92 3.41 ## 3 3 岩手県 0.341 30.4 24.5 34.9 22.4 8.61 5.16 11.2 5.29 ## 4 4 宮城県 0.596 25.8 27.3 36.7 25.4 13.4 3.97 9.99 3.62 ## 5 5 秋田県 0.299 33.8 21.4 43.5 22.7 11.2 5.17 7.56 5.12 ## 6 6 山形県 0.342 30.8 24.8 42.5 21.5 11.8 4.3 7.6 5.2 3. LibreOfficeなどを利用した方法 第三の方法は、そもそも Shift-JISでではなく、より一般的な UTF-8 でエンコーディングされたファイルを用意し、それを読み込むことである。ただし、この作業のためにはR以外のソフトが必要である。テキストエディタには文字コードを変更する機能がついているものが多いので、その機能を利用して文字コードを Shift-JISからUTF-8に変えれば良い。また、オープンソースのオフィススイートである LibreOffice は、CSVを開く際に文字コードを尋ねてくれるので、Shift-JIS を指定して上で使った csv ファイルを開こう。その後、文字コードをUTF-8に変更し、別名でcsvファイルを保存すれ、文字コード以外の中身が同じファイルができる。そのようにして作ったのが、Vote.csv である。これを読み込んでみよう。 UTF8_df &lt;- read.csv(&quot;Data/Vote.csv&quot;) # macOSの場合 UTF8_df &lt;- read.csv(&quot;Data/Vote.csv&quot;, fileEncoding = &quot;UTF-8&quot;) # Windowsの場合 head(UTF8_df) ## ID Pref Zaisei Over65 Under30 LDP DPJ Komei Ishin JCP SDP ## 1 1 北海道 0.41903 29.09 24.70 32.82 30.62 13.41 3.43 11.44 1.68 ## 2 2 青森県 0.33190 30.14 23.92 40.44 24.61 12.76 3.82 8.92 3.41 ## 3 3 岩手県 0.34116 30.38 24.48 34.90 22.44 8.61 5.16 11.24 5.29 ## 4 4 宮城県 0.59597 25.75 27.29 36.68 25.40 13.42 3.97 9.99 3.62 ## 5 5 秋田県 0.29862 33.84 21.35 43.46 22.72 11.19 5.17 7.56 5.12 ## 6 6 山形県 0.34237 30.76 24.75 42.49 21.47 11.78 4.30 7.60 5.20 第1引数以外の引数を何を指定しなくても、ファイルが正しく読み込まれ、都道府県名が日本語で表示されている。ただし、Windowsで文字化けが生じる場合はファイルのエンコーディングをUTF-8に指定して読み込もう。 7.1.3 その他のフォーマット データ分析で用いられるデータの多くは表の形で保存されている。表形式のデータは、.csv以外に、.xlsx (Excel)、.dta (Stata)、.sav (SPSS)、.ods (LibreOfficeなど) などのファイル形式で保存されることがある。ここでは接する機会が多い Excel 形式のファイルと Stata 形式のファイルの読み込みについて説明しよう34。 Excelファイルを読み込むためにはreadxlパッケージを使う。インストールされていない場合、コンソール上でinstall.packages(\"readxl\")を入力し、インストールする（上で pacman::p_load(readxl) を実行したのでインストールされているはずだが）。以下ではreadxlパッケージがインストールされていると想定し、Soccer.xlsxファイルを読み込み、Excel_DFと名付けてみよう。 Excel_DF &lt;- read_xlsx(&quot;Data/Soccer.xlsx&quot;, sheet = 1) Excelファイルには2つ以上のシートが含まれる場合が多いので、どのシートを読み込むかをsheetIndex で指定する。実際、Soccer.xlsxファイルをExcelまたはLibreOffice Calc で開いてみると、シートが3つある。そのうち、必要なデータは1つ目のシートにあるので、ここでは1を指定した。きちんと読み込たか確認してみよう。 head(Excel_DF) ## # A tibble: 6 × 6 ## ID Team Rank Points Prev_Points Confederation ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 Albania 75 1325 1316 UEFA ## 2 2 Algeria 85 1271 1271 CAF ## 3 3 American Samoa 133 1030 1030 OFC ## 4 4 Andorra 155 749 749 UEFA ## 5 5 Angola 121 1117 1117 CAF ## 6 6 Antigua and Barbuda 153 787 787 CONCACAF Stataの.dtaファイルはhavenパッケージのread_dta() 関数を使って読み込む。Stata形式で保存された Soccer.dta を読み込み、Stata_DFと名付けてみよう。 Stata_DF &lt;- read_dta(&quot;Data/Soccer.dta&quot;) head(Stata_DF) ## # A tibble: 6 × 6 ## id team rank points prev_points confederation ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 Albania 75 1325 1316 UEFA ## 2 2 Algeria 85 1271 1271 CAF ## 3 3 American Samoa 133 1030 1030 OFC ## 4 4 Andorra 155 749 749 UEFA ## 5 5 Angola 121 1117 1117 CAF ## 6 6 Antigua and Barbuda 153 787 787 CONCACAF Excel形式のデータと同じ内容のデータであること確認できる（ただし、変数名は少し異なる）。 実際の社会科学の場合、入手するデータの多くは.csv、.xlsx (または.xls)、.dtaであるため、以上のやり方で多くのデータの読み込みができる。 7.1.4 RDataファイルの場合 データ分析には表形式以外のデータも使われる。データ分析でよく使われるデータの形として、ベクトルや行列のほかにlist型とがある。表形式だけでなく、Rで扱える様々なデータを含むファイル形式の1つが.RDataフォーマットである。.RDataにはRが扱える形式のデータを格納するだけでなく、表形式のデータを複数格納することができる。また、データだけでなく、分析結果も保存することができる。.RData形式のファイルはRでしか読み込めないため、データの保存方法としては推奨できないが、1つのファイルにさまざまなデータが格納できるという大きな長所があるため、分析の途中経過を保存するためにしばしば利用される。 ここではDataフォルダにあるScores.RDataを読み込んでみよう。このファイルには学生5人の数学と英語の成績に関するデータがそれぞれMathScoreとEnglishScoreという名で保存されている。このデータを読み込む前に、現在の実行環境にどのようなオブジェクトがあるかを ls() 関数を使って確認してみよう35。 ls() ## [1] &quot;Excel_DF&quot; &quot;my_df1&quot; &quot;ShiftJIS_df1&quot; &quot;ShiftJIS_df2&quot; &quot;ShiftJIS_df3&quot; ## [6] &quot;Stata_DF&quot; &quot;UTF8_df&quot; 現在の実行環境に7個のオブジェクトがあることがわかる。 では、Scores.RDataを読み込んでみよう。.RData は、load() 関数で読み込む。ただし、これまでのファイルの読み込みとは異なり、保存先のオブジェクト名は指定しない。なぜなら、.Rdata の中に既にオブジェクトが保存されているからだ。 load(&quot;Data/Scores.RData&quot;) ここでもう一度実行環境上にあるオブジェクトのリストを確認してみよう。 ls() ## [1] &quot;EnglishScore&quot; &quot;Excel_DF&quot; &quot;MathScore&quot; &quot;my_df1&quot; &quot;ShiftJIS_df1&quot; ## [6] &quot;ShiftJIS_df2&quot; &quot;ShiftJIS_df3&quot; &quot;Stata_DF&quot; &quot;UTF8_df&quot; MathScoreとEnglishScoreという名前のオブジェクトが追加されていることが分かる。 このように、load()による.RData の読み込みは、.csvファイルや.xlsxファイルの読み込みと異なる。以下の2点が重要な違いである。 .RData は、1つのファイルに複数のデータを含むことができる。 .RDataの中にRのオブジェクトが保存されているので、ファイルの読み込みと同時に名前を付けて格納する必要がない。 問題なく読み込まれているか確認するため、それぞれのオブジェクトの中身を見てみよう。 MathScore # MathScoreの中身を出力 ## ID Name Score ## 1 1 Caracal 100 ## 2 2 Cheetah 37 ## 3 3 Jaguar 55 ## 4 4 Leopard 69 ## 5 5 Serval 95 EnglishScore # EnglishScoreの中身を出力 ## ID Name Score ## 1 1 Caracal 90 ## 2 2 Cheetah 21 ## 3 3 Jaguar 80 ## 4 4 Leopard 45 ## 5 5 Serval 99 7.2 データの書き出し データを手に入れた時点でそのデータ（生データ）が分析に適した状態であることは稀である。多くの場合、分析をするためには手に入れたデータを分析に適した形に整形する必要がある。この作業を「データクリーニング」と呼ぶが、データ分析の作業全体に占めるデータクリーニングの割合は5から7割ほどで、大部分の作業時をクリーニングに費やすことになる。（クリーニングの方法については、データハンドリングの章で説明する。） データクリーニングが終わったら、生データとクリーニングに使ったコード、クリーニング済みのデータをそれぞれ保存しておこう。クリーニングのコードさえあればいつでも生データからクリーニング済みのデータに変換することができるが、時間的にあまり効率的ではないので、クリーニング済みのデータも保存したほうが良い。そうすれば、いつでもそのデータを読み込んですぐに分析作業に取り組無ことができる36。 7.2.1 csvファイル データを保存する際にまず考えるべきフォーマットは.csv である。データが表の形をしていない場合には次節で紹介する.RDataフォーマットが必要になるが、多くの場合、データは表の形をしている。読み込みのところで説明したとおり、.csvファイルは汎用的なテキストファイルであり、ほとんどの統計ソフトおよび表計算ソフトで読み込むことができるので、特にこだわりがなければ業界標準のフォーマットとも言える csv 形式でデータ保存しておくのが安全だ37。 まずは、架空のデータを作ってみよう。Rにおける表形式のデータは data.frame型で表現する。（詳細については第9章で説明する。） my_data &lt;- data.frame( ID = 1:5, Name = c(&quot;Aさん&quot;, &quot;Bさん&quot;, &quot;Cさん&quot;, &quot;Dさん&quot;, &quot;Eさん&quot;), Score = c(50, 75, 60, 93, 51) ) 上のコードを実行すると、my_dataというオブジェクトが生成され、中には以下のようなデータが保持される。 my_data ## ID Name Score ## 1 1 Aさん 50 ## 2 2 Bさん 75 ## 3 3 Cさん 60 ## 4 4 Dさん 93 ## 5 5 Eさん 51 このデータをmy_data.csvという名前のcsvファイルで保存するには、write.csv()という関数を使う。必須の引数は2つで、1つ目の引数は保存するオブジェクト名、2つ目の引数 file は書き出すファイル名。もし、プロジェクトフォルダの下位フォルダ、たとえば、Dataフォルダーに保存するなら、ファイル名を\"Data/my_ata.csv\"のように指定する。他によく使う引数としてrow.namesがあり、デフォルトはTRUEだが、FALSEにすることを推奨する。TRUEのままだと、データの1列目に行番号が保存される。 write.csv(my_data, file = &quot;Data/my_data.csv&quot;, row.names = FALSE) これを実行すると、プロジェクトのフォルダの中にある Data フォルダにmy_data.csvが生成される。LibreOfficeやNumbers、Excelなどを使ってmy_data.csvを開いてみると、先ほど作成したデータが保存されていることが確認できる。 図 7.1: 保存したcsvファイルの中身 7.2.2 RDataファイル 最後に.RData形式でデータを書き出してみよう。今回は先ほど作成したmy_dataと、以下で作成するnumeric_vec1、numeric_vec2、character_vecをmy_RData.RDataという名のファイルとして Dataフォルダに書き出す。使用する関数は save() である。引数として保存するオブジェクト名をすべてカンマ区切りで書き、最後にfile 引数でファイル名を指定すればよい。 numeric_vec1 &lt;- c(1, 5, 3, 6, 99, 2, 8) numeric_vec2 &lt;- 1:20 character_vec &lt;- c(&#39;cat&#39;, &#39;cheetah&#39;, &#39;lion&#39;, &#39;tiger&#39;) save(my_data, numeric_vec1, numeric_vec2, character_vec, file = &quot;Data/my_RData.RData&quot;) 実際にmy_RData.Rdataファイルが生成されているかを確認してみよう。ファイルの保存がうまくいっていれば、my_RData.Rdataを読み込むだけで、my_data、numeric_vec1、numeric_vec2、character_vec という4つのオブジェクトを一挙に作業スペースに読み込むことができるはずだ。実際にできるか確認しよう。そのために、まず現在の実行環境上にあるmy_ata、numeric_vec1、numeric_vec2、character_vecを削除する。そのために rm() 関数を使う。 rm(my_data) rm(numeric_vec1) rm(numeric_vec2) rm(character_vec) このコードは以下のように1行のコードに書き換えられる。 rm(list = c(&quot;my_data&quot;, &quot;numeric_vec1&quot;, &quot;numeric_vec2&quot;, &quot;character_vec&quot;)) 4のオブジェクトが削除されたか、ls()関数で確認しよう。 ls() ## [1] &quot;EnglishScore&quot; &quot;Excel_DF&quot; &quot;MathScore&quot; &quot;my_df1&quot; &quot;ShiftJIS_df1&quot; ## [6] &quot;ShiftJIS_df2&quot; &quot;ShiftJIS_df3&quot; &quot;Stata_DF&quot; &quot;UTF8_df&quot; それではDataフォルダー内のmy_RData.RDataを読み込み、4つのオブジェクトが実行環境に読み込まれるか確認しよう。 load(&quot;Data/my_RData.RData&quot;) # Dataフォルダー内のmy_RData.RDataを読み込む ls() # 作業スペース上のオブジェクトのリストを確認する ## [1] &quot;character_vec&quot; &quot;EnglishScore&quot; &quot;Excel_DF&quot; &quot;MathScore&quot; ## [5] &quot;my_data&quot; &quot;my_df1&quot; &quot;numeric_vec1&quot; &quot;numeric_vec2&quot; ## [9] &quot;ShiftJIS_df1&quot; &quot;ShiftJIS_df2&quot; &quot;ShiftJIS_df3&quot; &quot;Stata_DF&quot; ## [13] &quot;UTF8_df&quot; "],["datatype.html", "8. データの型 8.1 データ型とは 8.2 Logical 8.3 Numeric 8.4 Complex 8.5 Character 8.6 Factor 8.7 Date 8.8 NA 8.9 NULL 8.10 NaN 8.11 Inf", " 8. データの型 8.1 データ型とは ここではRにおけるデータ型について説明します。第9章で説明するデータ「構造」とデータ「型」は異なる概念です。次章でも説明しますが、Rにおけるデータの最小単位はベクトルです。c(1, 2, 3, 4, 5)やc(\"Yanai\", \"Song\", \"Hadley\")もベクトルですが、30とか\"R\"もベクトルです。後者のように要素が1つのベクトルは原子ベクトル (atomic vector)とも呼ばれますが、本質的には普通ベクトルです。このベクトルの要素の性質がデータ型です。たとえばc(2, 3, 5, 7, 11)は数値型ですし、c(\"R\", \"Python\", \"Julia\")は文字型です。他にも第6章で紹介したFALSEやTRUEは論理型と呼ばれています。一つのベクトルは複数の要素で構成されることも可能ですが、必ず同じデータ型である必要があります。 しかし、データ分析を行う際はベクトル以外のデータも多いです。行列や表がその典型例です。しかし、行列でも表でも中身の一つ一つの要素は長さ1のベクトルに過ぎません。たとえば、以下のような2行5列のベクトルがあるとします。ここで1行3列目の要素は11であり、長さ1の数値型ベクトルです。あるいは5列目はc(23, 29)であり、長さ2の数値型ベクトルです。 ## [,1] [,2] [,3] [,4] [,5] ## [1,] 2 5 11 17 23 ## [2,] 3 7 13 19 29 表についても考えてみましょう。以下の表の3行2列目の要素は\"American Samoa\"という長さ1の文字型ベクトルです。また、6列目はc(\"UEFA\", \"CAF\", \"OFC\", \"UEFA\", \"CAF\", \"CONCACAF\")であり、これは長さ6の文字型ベクトルです。このようにRで扱う全てのデータは複数のベクトルが集まっているものです。 ## ID Team Rank Points Prev_Points Confederation ## 1 1 Albania 75 1325 1316 UEFA ## 2 2 Algeria 85 1271 1271 CAF ## 3 3 American Samoa 133 1030 1030 OFC ## 4 4 Andorra 155 749 749 UEFA ## 5 5 Angola 121 1117 1117 CAF ## 6 6 Antigua and Barbuda 153 787 787 CONCACAF つまり、複数のベクトルを綺麗に、または分析しやすく集めたのが行列や表であり、これがデータ構造に該当します。データ型ごとの処理方法については本書を通じて紹介して行きますので、本章は軽く読んで頂いても構いません。ただし、Factor型とDate &amp; Datetime型の処理はやや特殊ですので、手を動かしながら読み進めることをおすすめします。 ここではデータ型について紹介し、次章ではデータ構造について解説します。 8.2 Logical Logical型はTRUEとFALSEのみで構成されたデータ型です。練習としてなにかの長さ5の論理型ベクトルを作ってみましょう。 logical_vec1 &lt;- c(TRUE, FALSE, TRUE, TRUE, FALSE) logical_vec1 ## [1] TRUE FALSE TRUE TRUE FALSE 注意すべきこととしては、TRUEとFALSEは\"で囲まないことです。\"TRUE\"、\"FALSE\"と入力してしまえばlogical 型として認識されません。もし、一つ間違えて2番目の要素であるFALSEを\"FALSE\"と入力したらどうなるでしょうか。 logical_vec2 &lt;- c(TRUE, &quot;FALSE&quot;, TRUE, TRUE, FALSE) logical_vec2 ## [1] &quot;TRUE&quot; &quot;FALSE&quot; &quot;TRUE&quot; &quot;TRUE&quot; &quot;FALSE&quot; 2番目の要素だけでなく、他の全ての要素も\"で囲まれるようになりました。実際に、この2つのベクトルのデータ型を確認してみましょう。ベクトルのデータ型を確認する関数はclass()関数です。 class(logical_vec1) ## [1] &quot;logical&quot; class(logical_vec2) ## [1] &quot;character&quot; logical_vec1はlogical型ですが、logical_vec2はcharacter型と認識されます。 他にも、is.logical()関数を使ってあるベクトルがlogical型か否かを判定することも可能です。もし、ベクトルがlogical型ならTRUEが、logical型以外ならFALSEが返って来ます。 is.logical(logical_vec1) ## [1] TRUE is.logical(logical_vec2) ## [1] FALSE Logical型は様々な場面で使われますが、代表的な使い方は第6.3章で紹介しました要素の抽出と第10章で紹介する予定の条件分岐 (if()やifelse())、条件反復 (while())があります。 8.3 Numeric Numeric型は数値型ですが、まずはnumeric型のベクトルnumeric_vec1を作成し、データ型を確認してみましょう。 numeric_vec1 &lt;- c(2, 0, 0, 1, 3) class(numeric_vec1) ## [1] &quot;numeric&quot; is.logical()に似た関数is.numeric()も使用可能です。 is.numeric(numeric_vec1) ## [1] TRUE is.numeric(logical_vec1) ## [1] FALSE もうちょっと詳しく分けるとinteger型とdouble型があります。以下の内容はあまり意識的に区分して使う場面が稀ですので、(読み)飛ばしても構いません。 integerは整数型であり、doubleは実数型です。これはclass()関数では確認できず、typeof()関すを使います。 typeof(numeric_vec1) ## [1] &quot;double&quot; 一般的に作成するnumeric型のベクトルは全てdouble型です。もし、整数型のベクトルを作成したい場合、数値の後ろにLを付けます。 integer_vec1 &lt;- c(2L, 0L, 0L, 1L, 3L) typeof(integer_vec1) ## [1] &quot;integer&quot; ここでも注意すべき点としては、一つでもLが付かない要素が含まれる場合、自動的にdouble型に変換されるという点です。 integer_vec2 &lt;- c(2L, 0L, 0, 1L, 3L) typeof(integer_vec2) ## [1] &quot;double&quot; もちろんですが、小数点のある数値にLを付けてもinteger型にはならず、勝手にdouble型になります。また、integer型同士の割り算の結果もdouble型になります。これは2L/1Lのような場合でも同じです。足し算、引き算、掛け算はinteger型になります。 typeof(2.3L) ## [1] &quot;double&quot; typeof(3L / 12L) ## [1] &quot;double&quot; typeof(3L / 1L) ## [1] &quot;double&quot; typeof(3L + 1L) ## [1] &quot;integer&quot; typeof(3L - 4L) ## [1] &quot;integer&quot; typeof(3L * 6L) ## [1] &quot;integer&quot; 一般的な分析において整数と実数を厳格に区別して使う場面は多くないと考えられますので、今のところはあまり気にしなくても問題ないでしょう。 8.4 Complex Complex型は複素数を表すデータ型であり、実数部+虚数部iのように表記します。まず、複素数のベクトルcomplex_vec1を作成し、データ型を確認してみましょう。 complex_vec1 &lt;- c(1+3i, 3+2i, 2.5+7i) complex_vec1 ## [1] 1.0+3i 3.0+2i 2.5+7i class(complex_vec1) ## [1] &quot;complex&quot; あまりおすすめはできませんが、虚数部i+実数部のような書き方も可能です。 complex_vec2 &lt;- c(3i+1, 2i+3, 7i+2.5) complex_vec2 ## [1] 1.0+3i 3.0+2i 2.5+7i class(complex_vec2) ## [1] &quot;complex&quot; complex_vec1とcomplex_vec2は同じベクトルであることを確認してみましょう。 complex_vec1 == complex_vec2 ## [1] TRUE TRUE TRUE もし、ベクトル内にnumeric型とcomplex型が混在している場合、強制的にcomplex型に変換されます。変換された後の値は実数部+0iのようになります。 complex_vec3 &lt;- c(2+7i, 5, 13+1i) complex_vec3 ## [1] 2+7i 5+0i 13+1i class(complex_vec3) ## [1] &quot;complex&quot; 8.5 Character Character型は文字列で構成されているデータ型です。Rを含む多くの言語は文字列を表現するために、中身を\"で囲みます。\"abc\"はcharacter型ですが、\"1\"や\"3+5i\"もcharacter型です。数字であっても\"で囲んだらそれは文字列となります。それではいくつかのcharacter型ベクトルを作っていみましょう。 char_vec1 &lt;- c(&quot;Yanai&quot;, &quot;Song&quot;, &quot;Shigemura&quot;, &quot;Tani&quot;) char_vec2 &lt;- c(1, 2, 3, 4) char_vec3 &lt;- c(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;, &quot;4&quot;) char_vec1 ## [1] &quot;Yanai&quot; &quot;Song&quot; &quot;Shigemura&quot; &quot;Tani&quot; char_vec2 ## [1] 1 2 3 4 char_vec3 ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; char_vec2とchar_vec3の違いは通じを\"で囲んだか否かです。ベクトルの中身を見ても、char_vec2は\"で囲まれていません。データ型を見てみましょう。 class(char_vec1) ## [1] &quot;character&quot; class(char_vec2) ## [1] &quot;numeric&quot; class(char_vec3) ## [1] &quot;character&quot; やはりchar_vec3もcharacter型になっていることが分かります。 8.6 Factor Factor型はラベル付きの数値型データです。Factor型の見た目はcharacter型とほぼ同じですし、分析の場面においてもcharacter型とほぼ同じ扱いになります。Factor型とcharacter型との違いは、「順序が付いている」点です。例えば、以下の質問文に対するアンケートの結果を考えてみましょう。 あなたは猫がすきですか。 めちゃめちゃ好き めちゃ好き 好き どちらかといえば好き 以下の表8.1は5人の結果です。 表 8.1: 猫好きの度合い ID Name Cat 1 Yanai めちゃめちゃ好き 2 Song めちゃめちゃ好き 3 Shigemura どちらかといえば好き 4 Tani めちゃ好き 5 Hadley 好き 人間としてはこの表から、重村という人がどれだけ猫が嫌いなのかが分かります。ただし、Rはそうではありません。Rは日本語どころか、人間の言葉は理解できません。各項目ごとに順番を付けてあげる必要がありますが、そのために使われるのがfactor型です。 実習のために表8.1のCat列のみのベクトルを作ってみましょう。 factor_vec1 &lt;- c(&quot;めちゃめちゃ好き&quot;, &quot;めちゃめちゃ好き&quot;, &quot;どちらかといえば好き&quot;, &quot;めちゃ好き&quot;, &quot;好き&quot;) factor_vec1 ## [1] &quot;めちゃめちゃ好き&quot; &quot;めちゃめちゃ好き&quot; &quot;どちらかといえば好き&quot; ## [4] &quot;めちゃ好き&quot; &quot;好き&quot; class(factor_vec1) ## [1] &quot;character&quot; factor_vec1は普通の文字列ベクトルであることが分かります。これをfactor型に変換するためにはfactor()関数を使います。 factor_vec2 &lt;- factor(factor_vec1, ordered = TRUE, levels = c(&quot;どちらかといえば好き&quot;, &quot;好き&quot;, &quot;めちゃ好き&quot;, &quot;めちゃめちゃ好き&quot;)) class(factor_vec2) ## [1] &quot;ordered&quot; &quot;factor&quot; データ型がfactor型に変換されています。\"ordered\"というものも付いていますが、これについては後ほど説明します。それでは中身をみましょう。 factor_vec2 ## [1] めちゃめちゃ好き めちゃめちゃ好き どちらかといえば好き ## [4] めちゃ好き 好き ## Levels: どちらかといえば好き &lt; 好き &lt; めちゃ好き &lt; めちゃめちゃ好き いくつかの点で異なります。まず、文字列であるにもかかわらず、\"で囲まれていいない点です。そして3行目に4 Levels:というのが追加されている点です。このlevelは「水準」と呼ばれるものです。4 Levelsですから、factor_vec2は4つの水準で構成されていることを意味します。Factor型の値は予め指定された水準以外の値を取ることはできません。たとえば、2番目の要素を「超好き」に変えてみましょう。 factor_vec2[2] &lt;- &quot;超好き&quot; ## Warning in `[&lt;-.factor`(`*tmp*`, 2, value = &quot;超好き&quot;): invalid factor level, NA ## generated factor_vec2 ## [1] めちゃめちゃ好き &lt;NA&gt; どちらかといえば好き ## [4] めちゃ好き 好き ## Levels: どちらかといえば好き &lt; 好き &lt; めちゃ好き &lt; めちゃめちゃ好き 警告が表示され、2番目の要素が後ほど紹介する欠損値となっていることが分かります。それでは普通に「好き」を入れてみましょう。 factor_vec2[2] &lt;- &quot;好き&quot; factor_vec2 ## [1] めちゃめちゃ好き 好き どちらかといえば好き ## [4] めちゃ好き 好き ## Levels: どちらかといえば好き &lt; 好き &lt; めちゃ好き &lt; めちゃめちゃ好き 今回は問題なく置換できましたね。このようにfactor型の取りうる値は既に指定されています。また、## 4 Levels: どちらかといえば好き &lt; 好き &lt; ... &lt; めちゃめちゃ好きからも分かるように、その大小関係の情報も含まれています。猫好きの度合いは「どちらかといえば好き-好き-めちゃ好き-めちゃめちゃ好き」の順で高くなることをRも認識できるようになりました。 Factor型はこのように順序付きデータを扱う際に便利なデータ型ですが、順序情報を含まないfactor型もあります。これはfactor()を使う際、ordered = TRUE引数を削除するだけでできます。 factor_vec3 &lt;- factor(factor_vec1, levels = c(&quot;どちらかといえば好き&quot;, &quot;好き&quot;, &quot;めちゃ好き&quot;, &quot;めちゃめちゃ好き&quot;)) factor_vec3 ## [1] めちゃめちゃ好き めちゃめちゃ好き どちらかといえば好き ## [4] めちゃ好き 好き ## Levels: どちらかといえば好き 好き めちゃ好き めちゃめちゃ好き class(factor_vec3) ## [1] &quot;factor&quot; 今回は3行目が## Levels: どちらかといえば好き 好き めちゃ好き めちゃめちゃ好きとなり、順序に関する情報がなくなりました。また、class()で確認しましたデータ型に\"ordered\"が付いていません。これは順序なしfactor型であることを意味します。「順序付けしないならfactor型は要らないのでは…?」と思うかも知れませんが、これはこれで便利です。その例を考えてみましょう。 分析においてfactor型はcharacter型に近い役割を果たしますが、factor型なりの長所もあります。それは図や表を作成する際です。例えば、横軸が都道府県名で、縦軸がその都道府県の財政力指数を表す棒グラフを作成するとします。たとえば、表8.2のようなデータがあるとします。このデータは3つの列で構成されており、IDとZaisei列はnumeric型、Pref列はcharacter型です。 表 8.2: 5都道府県のH29財政力指数 ID 都道府県 財政力指数 1 Hokkaido 0.44396 2 Tokyo 1.19157 3 Aichi 0.92840 4 Osaka 0.78683 5 Fukuoka 0.64322 可視化については第17章以降で詳しく解説しますが、このPref列をcharacter型にしたままグラフにしますと図8.1のようになります。 図 8.1: 5都道府県のH29財政力指数 このようにアルファベット順で横軸が並び替えられます。別にこれでも問題ないと思う方もいるかも知れませんが、基本的に日本の都道府県は北から南の方へ並べるのが一般的な作法です38。北海道と東京、大阪の間には順序関係はありません。しかし、表示される順番は固定したい。この場合、Pref列を順序なしfactor型にすれば良いです39。データフレームの列を修正する方法は第9章で詳しく説明します。 zaisei_df$Pref &lt;- factor(zaisei_df$Pref, levels = c(&quot;Hokkaido&quot;, &quot;Tokyo&quot;, &quot;Aichi&quot;, &quot;Osaka&quot;, &quot;Fukuoka&quot;)) zaisei_dfのPref列をfactor型にしてから同じ図を描くと図8.2のようになります。 図 8.2: 5都道府県のH29財政力指数 都道府県以外にもこのような例は多くあります。順序尺度で測定された変数が代表的な例です。他にも政党名を議席数順で表示させたい場合もfactor型は有効でしょう。 8.7 Date 8.7.1 なぜDate型があるのか Date型は年月日を表すデータ型40です。この2つのデータ型はかなり複雑ですが、ここでは簡単に説明します。Date型は日付の情報を含むため、順序関係が成立します。その意味では順序付きFactor型とあまり挙動は変わらないかもしれませんが、実際はそうではありません。 たとえば、Songの1週間41の睡眠時間を記録したデータSongSleepがあるとします。Dateという列には日付が、Sleep列には睡眠時間が記録されています。睡眠時間の単位は「分」です。 SongSleep &lt;- data.frame( Date = c(&quot;2017-06-17&quot;, &quot;2017-06-18&quot;, &quot;2017-06-19&quot;, &quot;2017-06-20&quot;, &quot;2017-06-21&quot;, &quot;2017-06-22&quot;, &quot;2017-06-23&quot;), Sleep = c(173, 192, 314, 259, 210, 214, 290) ) 中身をみると、以下のようになります。 SongSleep ## Date Sleep ## 1 2017-06-17 173 ## 2 2017-06-18 192 ## 3 2017-06-19 314 ## 4 2017-06-20 259 ## 5 2017-06-21 210 ## 6 2017-06-22 214 ## 7 2017-06-23 290 日付を横軸に、睡眠時間を縦軸にした散布図を描くと図@ref{fig:datatype-date-3}のようになります。{ggplot2}を利用した作図については第@ref{visualization}章で解説しますので、ここではDate型の特徴のみ理解してもらえたら十分です。 ggplot(SongSleep, mapping = aes(x = Date, y = Sleep)) + geom_point() + labs(x = &quot;日付&quot;, y = &quot;睡眠時間 (分)&quot;) + theme_gray(base_size = 12) 図 8.3: Songの睡眠時間 この図は全く問題ないように見えます。それでは、Date列をそれぞれDate型に変換し、SoongSleepデータのDateDとしてみます。データフレームの列追加については第9.4章で解説します。 SongSleep$DateD &lt;- as.Date(SongSleep$Date) 中身を見てみますが、あまり変わっていないようです。DateとDateD列は全く同じように見えますね。 SongSleep ## Date Sleep DateD ## 1 2017-06-17 173 2017-06-17 ## 2 2017-06-18 192 2017-06-18 ## 3 2017-06-19 314 2017-06-19 ## 4 2017-06-20 259 2017-06-20 ## 5 2017-06-21 210 2017-06-21 ## 6 2017-06-22 214 2017-06-22 ## 7 2017-06-23 290 2017-06-23 図にすると実は先ほどの図と同じものが得られます。 ggplot(SongSleep, mapping = aes(x = DateD, y = Sleep)) + geom_point() + labs(x = &quot;日付&quot;, y = &quot;睡眠時間 (分)&quot;) + theme_gray(base_size = 12) 図 8.4: Songの睡眠時間 しかし、Songがうっかり6月19日に記録するのを忘れたとします。つまり、SongSleepデータの3行目が抜けている状況を考えてみましょう。データフレームの要素抽出については第9.4章で解説します。 SongSleep2 &lt;- SongSleep[-3, ] 中身をみると、以下のようになります。DateもDateDも同じように見えます。 SongSleep2 ## Date Sleep DateD ## 1 2017-06-17 173 2017-06-17 ## 2 2017-06-18 192 2017-06-18 ## 4 2017-06-20 259 2017-06-20 ## 5 2017-06-21 210 2017-06-21 ## 6 2017-06-22 214 2017-06-22 ## 7 2017-06-23 290 2017-06-23 この状態で横軸をDateにしたらどうなるでしょうか（図8.5）。 ggplot(SongSleep2, mapping = aes(x = Date, y = Sleep)) + geom_point() + labs(x = &quot;日付&quot;, y = &quot;睡眠時間 (分)&quot;) + theme_gray(base_size = 12) 図 8.5: Songの睡眠時間 一方、横軸をDateDにしたものが図8.6です。 ggplot(SongSleep2, mapping = aes(x = DateD, y = Sleep)) + geom_point() + labs(x = &quot;日付&quot;, y = &quot;睡眠時間 (分)&quot;) + theme_gray(base_size = 12) 図 8.6: Songの睡眠時間 違いが分かりますかね。違いは抜けている6月19日です。図8.5を見ると、横軸の6月18日の次が20日になっています。一方、図8.6は19日になっており、ちゃんと空けてくれますね。これはDate型でない場合、データにないものは図に表示されないことを意味します。一方、Date型は抜けている日があっても、図に表示表示されます。一般のcharacter型またはfactor型でこのようなことを再現するためには、6月19日の列を追加し、睡眠時間を欠損値として指定する必要があります。たとえば、SongSleepデータにおいて6月19日の行は温存したまま、睡眠時間だけを欠損値にしてみましょう。 SongSleep3 &lt;- SongSleep SongSleep3$Sleep[SongSleep$Date == &quot;2017-06-19&quot;] &lt;- NA SongSleep3 ## Date Sleep DateD ## 1 2017-06-17 173 2017-06-17 ## 2 2017-06-18 192 2017-06-18 ## 3 2017-06-19 NA 2017-06-19 ## 4 2017-06-20 259 2017-06-20 ## 5 2017-06-21 210 2017-06-21 ## 6 2017-06-22 214 2017-06-22 ## 7 2017-06-23 290 2017-06-23 このように日付はあるが、睡眠時間が欠損している場合、図にしたものが図8.7です。 ggplot(SongSleep3, mapping = aes(x = Date, y = Sleep)) + geom_point() + labs(x = &quot;日付&quot;, y = &quot;睡眠時間 (分)&quot;) + theme_bw() ## Warning: Removed 1 rows containing missing values (geom_point). 図 8.7: Songの睡眠時間 横軸上に6月19日が表示されます。このようにDate型でなくてもDate型と同じように動かすことは可能ですが、非常に面倒です。その意味でDate型は時系列データを扱う際に非常に便利なデータ型です。 8.7.2 Date型の作り方 Date型を作成方法はいくつかあります。 character型をDate型にする numeric型をDate型にする 主に使う方法は1であり、既に前節でお見せしましたas.Date()関数を使います。方法2もまたas.Date()を使いますが、これは「xxxx年xx月xx日から何日目」という書き方となり、起点となる日付 (origin)42を指定する必要があります。 ここでは方法1について解説します。日付を表すいくつかのベクトルを作ってみましょう。 Date1 &lt;- &quot;2020-05-21&quot; Date2 &lt;- &quot;2020-5-21&quot; Date3 &lt;- &quot;2020/5/21&quot; Date4 &lt;- &quot;20/05/21&quot; Date5 &lt;- &quot;20200521&quot; Date6 &lt;- &quot;2020 05 21&quot; Date7 &lt;- &quot;2020.05.21&quot; as.Date(Date1) ## [1] &quot;2020-05-21&quot; as.Date(Date2) ## [1] &quot;2020-05-21&quot; as.Date(Date3) ## [1] &quot;2020-05-21&quot; as.Date(Date4, &quot;%y/%m/%d&quot;) ## [1] &quot;2020-05-21&quot; as.Date(Date5, &quot;%Y%m%d&quot;) ## [1] &quot;2020-05-21&quot; as.Date(Date6, &quot;%Y %m %d&quot;) ## [1] &quot;2020-05-21&quot; as.Date(Date7, &quot;%Y.%m.%d&quot;) ## [1] &quot;2020-05-21&quot; Date1、Date2、Date3のようなベクトルの場合、as.Date()のみでDate型に変換できます。つまり、日付が数字のみで構成され、年が4桁となっており、年月日が-または/で区切られている場合はこれでだけで十分です。しかし、年が2桁になっていたり、その他の記号が使われたり、区切られていない場合は、fotmat =引数を指定する必要があります。たとえばDate4は年が2桁となっているます。2桁の年は%yと表記します。この表記法の一部を以下の表で紹介します。 表記 説明 例 %y 年 (2桁) 20 %Y 年 (4桁) 2020 %m 月 (数字) 5, 10 %b 月 (文字) Jan %B 月 (文字) January %d 日 5, 05, 13 他にも様々な表記法がありますが、詳細は?strptimeで確認してみてください。 他にも、日本では使わない表記法ですが、月を英語で表記したり、日月年の順で表記する場合があります。後者はformat =引数の順番を変えるだけで問題有りませんが、問題は前者です。そこで使うのが%bまたは%Bです。%bは3文字の月表記で、%Bはフルネームです。 as.Date(&quot;21may2020&quot;, format = &quot;%d%b%Y&quot;) ## [1] &quot;2020-05-21&quot; as.Date(&quot;May/21/2020&quot;, format = &quot;%b/%d/%Y&quot;) ## [1] &quot;2020-05-21&quot; うまくいかないですね。これはシステムの時間ロケールが日本になっているのが原因です。ロケール設定はSys.getlocale()で確認できます。 Sys.getlocale(category = &quot;LC_TIME&quot;) ## [1] &quot;en_US.UTF-8&quot; これをSys.setlocale()を使って、\"C\"に変更します。 Sys.setlocale(category = &quot;LC_TIME&quot;, locale = &quot;C&quot;) ## [1] &quot;C&quot; それではもう一回やってみましょう。 as.Date(&quot;21may2020&quot;, format = &quot;%d%b%Y&quot;) ## [1] &quot;2020-05-21&quot; as.Date(&quot;May/21/2020&quot;, format = &quot;%b/%d/%Y&quot;) ## [1] &quot;2020-05-21&quot; うまく動くことが確認できました。念の為に、ロケールを戻しておきます。 Sys.setlocale(category = &quot;LC_TIME&quot;, locale = &quot;ja_JP.UTF-8&quot;) ## [1] &quot;ja_JP.UTF-8&quot; 8.7.3 POSIXct、POSIXlt型について POSIXct、POSIXlt型は日付だけでなく時間の情報も含むデータ型です。これらはas.POSIXct()、as.POSIXlt()関数で作成することができます。どちらも見た目は同じデータ型ですが、内部構造がことなります43。詳細は?as.POSIXctまたは?as.POSIXltを参照してください。 8.8 NA NAは欠損値と呼ばれます。これは本来は値があるはずなのがなんらかの理由で欠損していることを意味します。表8.3の例を考えてみましょう。 表 8.3: 4人の支持政党 ID 名前 支持政党の有無 支持政党 1 Yanai ない NA 2 Song ある ラーメン大好き党 3 Shigemura ある 鹿児島第一党 4 Tani ない NA 3列目で支持政党があるケースのみ、4列目に値があります。YanaiとTaniの場合、支持する政党がないため、政治政党名が欠損しています。実際、多くのデータには欠損値が含まれています。世論調査データの場合はもっと多いです。理由としては「Q2で”はい”を選んだ場合のみQ3に進み、それ以外はQ4へ飛ばす」のようなのもありますが、単に回答を拒否した場合もあります。 まずは欠損値が含まれたベクトルna_vec1を作ってみましょう。 na_vec1 &lt;- c(1, NA, 3, NA, 5, 6) na_vec1 ## [1] 1 NA 3 NA 5 6 つづいて、データ型を確認してみましょう。 class(na_vec1) ## [1] &quot;numeric&quot; NAが含まれていてもデータ型はnumericのままです。これは「一応、欠損しているが、ここに何らかの値が割り当てられるとしたらそれはnumeric型だろう」とRが判断しているからです。ある要素がNAか否かを判定するにはis.na()関数を使います。 is.na(na_vec1) ## [1] FALSE TRUE FALSE TRUE FALSE FALSE 2番目と4番目の要素が欠損していることが分かります。 欠損値も要素の一つとしてカウントされるため、ベクトルの長さは6になります。ベクトルの長さはlength()関数で確認できます。 length(na_vec1) ## [1] 6 欠損値の取り扱い 欠損値を含むデータの処理方法はやや特殊です。まず、na_vec1の要素全てに1を足してみましょう。 na_vec1 + 1 ## [1] 2 NA 4 NA 6 7 この場合、欠損値の箇所には1が足されず、それ以外の要素のみに1を足した結果が返ってきます。これは直感的に考えると自然です。問題になるのは欠損値が含まれるベクトルを関数に入れた場合です。たとえば、numeric型ベクトル内の要素の総和を求めるにはsum()関数を使います。sum(c(1, 3, 5))を入力すると9が返されます。na_vec1は欠損していない要素が1, 3, 5, 6であるため、総和は15のはずです。確認してみましょう。 sum(na_vec1) ## [1] NA このように欠損値を含むベクトルの総和はNAとなります。もし、欠損値を除いた要素の総和を求めるには、まずベクトルから欠損値を除去する必要があります。そのためにはis.na()関数を使ってna_vec1の要素を抽出します。ただし、is.na()を使うと、欠損値であるところがTRUEになるため、これを反転する必要があります。この場合は!is.na()関数を使います。それではis.na()と!is.na()を使って要素を抽出してみましょう。 na_vec1[is.na(na_vec1)] ## [1] NA NA na_vec1[!is.na(na_vec1)] ## [1] 1 3 5 6 !is.na()を使うことで欠損値を除いた要素のみを取り出すことができました。これならsum()関数も使えるでしょう。 sum(na_vec1[!is.na(na_vec1)]) ## [1] 15 これで欠損値を除いた要素の総和を求めることができました。ただし、一部の関数には欠損値を自動的に除去するオプションを持つ場合があります。sum()関数のその一部であり、na.rm = TRUEオプションを付けると、欠損値を除いた総和を返します。 sum(na_vec1, na.rm = TRUE) ## [1] 15 欠損値の使い方 主に欠損値を扱うのは入手したデータに含まれる欠損値に対してですが、NAをこちらから生成することもあります。それは空ベクトルを用意する時です。第10章では関数の作り方について解説します。関数内で何らかの処理を行い、その結果を返すことになりますが、その結果を格納するベクトルを事前に作っておくこともできます。こちらの方がメモリの観点からは効率的です。以下は第10章を読んでから読んでも構いません。 もし、長さ10のベクトルresult_vec1を返すとします。ベクトルの要素として1から10の数字が入るとします。一つ目の方法としてはまず、result_vec1に1を代入し、次はc()を使って要素を一つずつ足して行く手順です。 result_vec1 &lt;- 1 result_vec1 &lt;- c(result_vec1, 2) result_vec1 &lt;- c(result_vec1, 3) result_vec1 &lt;- c(result_vec1, 4) result_vec1 &lt;- c(result_vec1, 5) result_vec1 &lt;- c(result_vec1, 6) result_vec1 &lt;- c(result_vec1, 7) result_vec1 &lt;- c(result_vec1, 8) result_vec1 &lt;- c(result_vec1, 9) result_vec1 &lt;- c(result_vec1, 10) 二つ目の方法はまず、10個のNAが格納されたベクトルReuslt.Vec2を作っておいて、その中に要素を置換してく方法です。 result_vec2 &lt;- rep(NA, 10) result_vec2[1] &lt;- 1 result_vec2[2] &lt;- 2 result_vec2[3] &lt;- 3 result_vec2[4] &lt;- 4 result_vec2[5] &lt;- 5 result_vec2[6] &lt;- 6 result_vec2[7] &lt;- 7 result_vec2[8] &lt;- 8 result_vec2[9] &lt;- 9 result_vec2[10] &lt;- 10 以上の手順を第10章で紹介するfor()を使って反復処理するとしたら、以下のようなコードになります。 # 方法1 result_vec1 &lt;- 1 for (i in 2:10) { result_vec1 &lt;- c(result_vec1, i) } # 方法2 result_vec2 &lt;- rep(NA, 10) for (i in 1:10) { result_vec2[i] &lt;- i } 結果を確認してみましょう。 result_vec1 ## [1] 1 2 3 4 5 6 7 8 9 10 result_vec2 ## [1] 1 2 3 4 5 6 7 8 9 10 コードの書き方は異なりますが、どれも結果は同じです。また、どちらが早いかというと、これくらいの計算ならどの方法でも同じです。ただし、より大規模の反復作業を行う場合、後者の方が時間が節約でき、コードの可読性も高いです。 8.9 NULL NULLは「存在しない」、空っぽであることを意味します。先ほどのNAはデータは存在するはずなのに、何らかの理由で値が存在しない、または割り当てられていないことを意味しますが、NULLは「存在しません」。したがって、NULLが含まれたベクトルを作成しても表示されません。NULLが含まれたnull_vec1を作ってみましょう。 null_vec1 &lt;- c(1, 3, NULL, 5, 10) null_vec1 ## [1] 1 3 5 10 3番目の要素であるNULLは表示されません。ということはNAと違って、データの長さも5ではなく4でしょう。確認してみます。 length(null_vec1) ## [1] 4 このnull_vec1のデータ型は何でしょう。 class(null_vec1) ## [1] &quot;numeric&quot; is.null()関数もありますが、どうでしょうか。 is.null(null_vec1) ## [1] FALSE NULLは存在しないことを意味するため、null_vec1は要素が4のnumeric型ベクトルです。is.null()でNULLが判定できるのはis.null(NULL)のようなケースです。 図8.8はNA型とNULL型の違いについてまとめたものです。 図 8.8: NAとNULLの違い このNULLはいつ使うのでしょうか。実際、使う機会はあまりありません。強いて言えば、空っぽのリストを作成する際に使うケースがあります。リストについては第9章で説明します。以下の例は第9章を読み終わってから目を通して下さい。 null_list1 &lt;- list(Room1 = 1:3, Room2 = c(&quot;Yuki&quot;, &quot;Jaehyun&quot;, &quot;Hadley&quot;), Room3 = NULL) null_list1 ## $Room1 ## [1] 1 2 3 ## ## $Room2 ## [1] &quot;Yuki&quot; &quot;Jaehyun&quot; &quot;Hadley&quot; ## ## $Room3 ## NULL このように予めリストの要素は作っておきたいが、とりあえず空けておく際に使います。続く分析の段階でnull_list1[[\"Room3\"]]に何かを格納したりすることに使えるでしょう。ちなみにこの場合はis.null()が使用可能です。 is.null(null_list1[[&quot;Room3&quot;]]) ## [1] TRUE 8.10 NaN NaNはnumeric型、中でもdouble型の一種ですが、これは計算できない値を意味します。つまり、NaN値を直接入力することはめったにありませんが、計算の結果としてNaNが返されるケースがあります。代表的な例が0を0で割った場合です。実際、0を0で割ることはできません。ここでは0を0で割った値を含むnan_vec1作ってみましょう。 nan_vec1 &lt;- c(2/5, 0/12, 0/0) nan_vec1 ## [1] 0.4 0.0 NaN class(nan_vec1) ## [1] &quot;numeric&quot; 先ほどせつめいしましたように、NaNはnumeric型の一部ですので、データ型としてはnumeircになります。ある値がNaNか否かを判定するにはis.nan()関数を使います。 is.nan(nan_vec1) ## [1] FALSE FALSE TRUE 8.11 Inf Infもまたnumeric型、中でもdouble型の一部ですが、これは無限大を意味します。Infも通常、自分から作成するケースはあまりなく、結果として帰ってくる場合があります。一つの例が0以外の数値を0で割った場合です。それではなんらかの数値を0を割った値が含まれるベクトルinf_vec1を作ってみましょう。 inf_vec1 &lt;- c(28/95, 3/0, -12/0, 0/0) inf_vec1 ## [1] 0.2947368 Inf -Inf NaN class(inf_vec1) ## [1] &quot;numeric&quot; 正の値を0で割ったらInfが負の値を0で割ったら-Infが返ってきます。これは正の無限大、負の無限大を意味します。データ型はNaNと同様、numeric型ですが、is.infinite()を使うと、無限大か否かが判定できます。 is.infinite(inf_vec1) ## [1] FALSE TRUE TRUE FALSE "],["datastructure.html", "9. データの構造 9.1 データ構造とは 9.2 ベクトル (vector) 9.3 行列 (matrix) 9.4 データフレーム (data.frame) 9.5 リスト (list) 9.6 配列 (array) 練習問題", " 9. データの構造 9.1 データ構造とは データ構造 (data structure)とは最小単位であるベクトルを何らかの形で集めたものです。ベクトル自体もデータ構造であり、同じデータ型のベクトルを積み重ねた行列、異なるデータ型の縦ベクトルを横に並べたデータフレームなど、Rでは様々なデータ構造を提供しています。また、R内臓のデータ構造以外にも、パッケージ等で提供される独自のデータ構造もあります。ここではRが基本的に提供している代表的なデータ構造について、その作り方と操作方法について解説します。 9.2 ベクトル (vector) 9.2.1 ベクトルの作り方 Rにおいてベクトルとは同じデータ型が一つ以上格納されているオブジェクトを意味します。たとえば、以下のmyVec1は長さ1のベクトルです。 myVec1 &lt;- &quot;R is fun!&quot; myVec1 ## [1] &quot;R is fun!&quot; むろん、2つ以上の文字列、または数字を格納することも可能です。以下のmyVec2は長さ5のベクトルです。 myVec2 &lt;- c(1, 3, 5, 6, 7) myVec2 ## [1] 1 3 5 6 7 注意すべきところは、ベクトル内の要素は必ず同じデータ型である必要があるということです。たとえば、数字と文字が混在したmyVec3を考えてみましょう。 myVec3 &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, 1, 2, 3) myVec3 ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;1&quot; &quot;2&quot; &quot;3&quot; 数字であるはずの1, 2, 3が\"で囲まれ、文字列に自動的に変換されていることが分かります。実際に、デーが型を確認してみましょう。 class(myVec3) ## [1] &quot;character&quot; \"character\"、つまりデータ型が文字列になっていることが分かります。これはcharacter型がnumeric型よりも優先順位が高いからです。それではnumericとlogical型はどうでしょうか。 myVec4 &lt;- c(1, 2, 3, TRUE, FALSE) myVec4 ## [1] 1 2 3 1 0 class(myVec4) ## [1] &quot;numeric&quot; TRUEが1、FALSEが0となり、自動的にnumeric型になりました。一般的によく使われるデータ型はlogical、numeric、characterですが、優先順位はlogical &lt; numeric &lt; characterの関係になります。ここで重要なのは優先順位ではなく、異なるデータ型が含まれるベクトルの場合、自動的にデータ型が統一されるということです。ベクトルを作成する際は、全ての要素が同じ型になるようにしましょう。 9.2.2 ベクトルの操作 ベクトルの長さ ベクトルの長さはベクトルに含まれている要素の数です。ベクトルの長さはlength()関数で調べることができます。それでは前節で作成した4つのベクトルの長さを調べてみましょう。 length(myVec1) # &quot;R is fun!&quot; ## [1] 1 length(myVec2) # c(1, 3, 5, 6, 7) ## [1] 5 length(myVec3) # c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;) ## [1] 6 length(myVec4) # c(1, 2, 3, 1, 0) ## [1] 5 それぞれのベクトルの長さは1、5、6、5ということが分かりますね。 要素の抽出 これは既に説明しましたので、6.5を参照してください。 ベクトルの加減乗除 ここではnumeric型のベクトルを用いた加減乗除について考えたいと思います。Rにおいてベクトルは自動的に反復作業を行います。たとえば、c(1, 2, 3, 4)というベクトルがあり、ここに5を足すと、ベクトルの全ての要素に対して同じ計算を行います。これは引き算でも、掛け算でも、割り算でも同じです。むろん、べき乗などの様々な操作に対しても同じです。それではmyVec2に対して、5を足したり、引いたり、色々してみましょう。 myVec2 + 5 ## [1] 6 8 10 11 12 myVec2 - 5 ## [1] -4 -2 0 1 2 myVec2 * 5 ## [1] 5 15 25 30 35 myVec2 / 5 ## [1] 0.2 0.6 1.0 1.2 1.4 myVec2 ^ 5 ## [1] 1 243 3125 7776 16807 また、ベクトル同士の演算も可能です。まず、myVec2と同じ長さを持つmyVec4との計算を考えてみましょう。これは長さが同じであるため、それぞれ同じ位置の要素同士の計算となります。つまり、足し算の場合、myVec2[1]とmyVec4[1]の和、myVec2[2]とmyVec4[2]の和、…といった形です。 myVec2 + myVec4 ## [1] 2 5 8 7 7 myVec2 - myVec4 ## [1] 0 1 2 5 7 myVec2 * myVec4 ## [1] 1 6 15 6 0 myVec2 / myVec4 ## [1] 1.000000 1.500000 1.666667 6.000000 Inf もし、ベクトルの長さが異なる場合はどうなるでしょう。たとえば、長さ2のベクトルmyVec5とmyVec2の足し算を考えてみましょう。 (myVec5 &lt;- c(1, 10)) ## [1] 1 10 (myVec6 &lt;- myVec2 + myVec5) ## Warning in myVec2 + myVec5: longer object length is not a multiple of shorter ## object length ## [1] 2 13 6 16 8 警告メッセージは表示されますが、計算自体はできます。同じ長さのベクトル同士なら、同じ位置の要素同士の計算になりますが、この場合は、短い方のベクトルを繰り返すことにより、長さを合わせることになります。myVec5の例だと、c(1, 10, 1, 10, 1)のように扱われます。具体的には以下の表のような関係となります。 myVec6[1] myVec6[2] myVec6[3] myVec6[4] myVec6[5] = = = = = myVec2[1] myVec2[2] myVec2[3] myVec2[4] myVec2[5] + + + + + myVec5[1] myVec5[2] myVec5[1] myVec5[2] myVec5[1] 実際は長さが異なるベクトル同士の計算を行うことは滅多にありません。例外としては長さ1のベクトルの計算くらいですね。 文字列ベクトルの扱い方はより複雑ですので、第16章で詳細に解説します。 9.3 行列 (matrix) 行列は名前とおり、行と列で構成されたデータ構造です。ただし、我々が一般に考える「表」とは異なる点があります。それは行列内部の要素に制約がある点です。具体的に、行列の要素となり得るデータ型はnumeric、complex、NA型のみです。ここではnumeric型のみで構成された行列の作成および操作方法について解説します。 9.3.1 行列の作り方 行列を作成するにはmatrix()関数を使います。引数として、行列に入る数値と行または列の数は必須です。数値はベクトルであり、行・列の数は整数です。以下のような行列を作るにはいくつかの方法があります。 \\[ \\left[ \\begin{matrix} 1 &amp; 2 &amp; 3 &amp; 4 \\\\ 5 &amp; 6 &amp; 7 &amp; 8 \\\\ 9 &amp; 10 &amp; 11 &amp; 12 \\end{matrix} \\right] \\] # 方法1: 行数を指定する Matrix1 &lt;- matrix(c(1, 5, 9, 2, 6, 10, 3, 7, 11, 4, 8, 12), nrow = 3) Matrix1 ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 ## [3,] 9 10 11 12 # 方法2: 列数を指定する Matrix2 &lt;- matrix(c(1, 5, 9, 2, 6, 10, 3, 7, 11, 4, 8, 12), ncol = 4) Matrix2 ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 ## [3,] 9 10 11 12 いずれも同じ結果が得られます。注意してもらいたいところは、第一引数の書き方です。我々は「左から右へ、そして上から下へ」という順番で読むのになれていますが、Rの行列は「上から下へ、そして左から右へ」の順番です。もし、「左から右へ、そして上から下へ」のような、より我々にとって読みやすい書き方をするためにはもう一つの引数が必要であり、それがbyrow =です。 (matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), nrow = 3, byrow = TRUE)) ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 ## [3,] 9 10 11 12 むろん、初項1、公差1、最大値12の等差数列ですのて、1:12のような書き方も可能です。 (matrix(1:12, nrow = 3, byrow = TRUE)) ## [,1] [,2] [,3] [,4] ## [1,] 1 2 3 4 ## [2,] 5 6 7 8 ## [3,] 9 10 11 12 データ構造も確認してみましょう。 class(Matrix1) ## [1] &quot;matrix&quot; &quot;array&quot; R 4.0.0からの仕様変更により行列型はmatrix構造以外にもarrayの構造も持つようになりました。array型については第9.6章で解説します。 単位行列 最後にちょっと特殊な行列である単位行列 (indetity matrix)の作り方について説明します。単位行列とは行と列の数が同じである正方形の行列ですが、対角線上は全て1、その他は全て0となっている行列です。たとえば大きさが4の単位行列は、 \\[ \\left[ \\begin{matrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ \\end{matrix} \\right] \\] です。これはmatrix(c(1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1), nrow = 4)で作成することも可能ですが、diag()関数を使えば簡単に出来ます。サイズが4の単位行列はdiag(4)です。 (diag(4)) ## [,1] [,2] [,3] [,4] ## [1,] 1 0 0 0 ## [2,] 0 1 0 0 ## [3,] 0 0 1 0 ## [4,] 0 0 0 1 9.3.2 行列の操作 まず、以下のような行列Aを作ってみましょう。 \\[ A = \\left[ \\begin{matrix} 1 &amp; 2 &amp; 3 &amp; 4 \\\\ 5 &amp; 6 &amp; 7 &amp; 8 \\\\ 9 &amp; 10 &amp; 11 &amp; 12 \\end{matrix} \\right] \\] A &lt;- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), nrow = 3, byrow = TRUE) 行列のサイズ 行列の大きさ (行と列の数)を求める際はdim()関数を使います。 dim(A) ## [1] 3 4 結果は長さ2のベクトルですが、1番目の要素が行数、2番目の要素が列数になります。もし、行列の行数のみ確認したい場合はdim(A)[1]、列数ならdim(A)[2]で確認することができます。また、全く同じ機能を持つ関数があり、それがnrow()とncol()関数です。 nrow(A) # 行列の行数を確認: dim(A)[1]と同じ ## [1] 3 ncol(A) # 列列の列数を確認: dim(A)[2]と同じ ## [1] 4 dim()およびnrow()、ncol()関数は第9.4章で紹介するデータフレームでも使用可能です。 要素の抽出 ベクトルと同様、要素の抽出は[]を使います。ただし、行列は横と縦の2次元構成となりますので、行と列のそれぞれの位置を指定する必要があります。たとえば、Aの2行目、3列目の要素を抽出するためには、 A[2, 3] ## [1] 7 のように書きます。行か列の位置を省略した場合、指定した列・行全てが抽出されます。2行目の要素全てを抽出するならA[2, ]、3列目の要素全てを抽出するならA[, 3]となります。 A[2, ] ## [1] 5 6 7 8 A[, 3] ## [1] 3 7 11 この場合、返される値のデータ構造はいずれも行列でなく、ベクトルです。確認してみましょう。 is.vector(A[2, 3]) ## [1] TRUE is.vector(A[2, ]) ## [1] TRUE is.vector(A[, 3]) ## [1] TRUE 例外は複数の行と複数の列を同時に抽出した場合です。たとえば、行列Aの1・2行目と2・3列目の要素を全て抽出するとします。その場合はA[1:2, 2:3]のように書きます。むろん、:を使わずにA[c(1, 2), c(2, 3)]のような書き方も可能です。抽出後、返された結果のデータ構造も確認してみましょう。 A[1:2, 3:4] ## [,1] [,2] ## [1,] 3 4 ## [2,] 7 8 class(A[1:2, 3:4]) ## [1] &quot;matrix&quot; &quot;array&quot; この場合、返された結果のデータ構造は行列であることが分かります。 行列の足し算と引き算 行列の足し算 (引き算)には 行列内の全要素に対して同じ数字を足す (引く) 同じサイズの2つの行列から対応する要素を足す (引く) 2パタンがあります。例えば、行列Aの全要素に5を足す場合は以下のように入力します。 (A_plus_5 &lt;- A + 5) ## [,1] [,2] [,3] [,4] ## [1,] 6 7 8 9 ## [2,] 10 11 12 13 ## [3,] 14 15 16 17 同様に、Aから10を引く場合は-演算子を使います。 (A_minus_10 &lt;- A - 10) ## [,1] [,2] [,3] [,4] ## [1,] -9 -8 -7 -6 ## [2,] -5 -4 -3 -2 ## [3,] -1 0 1 2 二つ目は同じサイズの行列同士の足し算と引き算です。行列Aは3 \\(\\times\\) 4の行列ですので、同じサイズの行列Bを作成してみましょう。 (B &lt;- matrix(c(3, 2, 1, 4, 5, 9, 7, 11, 6, 12, 8, 10), nrow = 3, byrow = TRUE)) ## [,1] [,2] [,3] [,4] ## [1,] 3 2 1 4 ## [2,] 5 9 7 11 ## [3,] 6 12 8 10 この行列AとBの足し算はそれぞれ同じ位置の要素同士の和を行列をして返し、これは引き算も同じです。 A + B ## [,1] [,2] [,3] [,4] ## [1,] 4 4 4 8 ## [2,] 10 15 14 19 ## [3,] 15 22 19 22 A - B ## [,1] [,2] [,3] [,4] ## [1,] -2 0 2 0 ## [2,] 0 -3 0 -3 ## [3,] 3 -2 3 2 注意すべき点は、2つの行列は同じ大きさでなければならない点です。たとえば、行列Bの1列から3列までを抽出した3 \\(\\times\\) 3行列Cを作成し、A + Cをしてみましょう。 (C &lt;- B[, 1:3]) ## [,1] [,2] [,3] ## [1,] 3 2 1 ## [2,] 5 9 7 ## [3,] 6 12 8 A + C ## Error in A + C: non-conformable arrays このように足し算ができなくなり、これは引き算でも同じです。 行列の掛け算 やや特殊なのは行列の掛け算です。行列Aの全要素を2倍にしたい場合、これは足し算・引き算と同じやり方で十分です。 A * 2 ## [,1] [,2] [,3] [,4] ## [1,] 2 4 6 8 ## [2,] 10 12 14 16 ## [3,] 18 20 22 24 ただし、問題は行列同士の掛け算です。行列AとBの掛け算といえば、直感的には足し算や引き算同様、同じ位置の要素の積と考えるかも知れません。実際A * Bはそのように計算を行います。 A * B ## [,1] [,2] [,3] [,4] ## [1,] 3 4 3 16 ## [2,] 25 54 49 88 ## [3,] 54 120 88 120 ただし、このような掛け算は「アダマール積 (Hadamard product)」と呼ばれる計算方法であり44、一般的に使う掛け算ではありません。実際、数学において\\(A \\times B\\)はアダマール積を意味すのではなく、アダマール積は\\(A \\circ B\\)または\\(A \\odot B\\)と表記します。 それでは一般的な行列の積は何でしょう。詳しいことは線形代数の入門書に譲りますが、以下のような2つの行列CとDを考えてみましょう。 \\[ C = \\left[ \\begin{matrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\end{matrix} \\right], D = \\left[ \\begin{matrix} 2 &amp; 7 &amp; 17 \\\\ 3 &amp; 11 &amp; 19 \\\\ 5 &amp; 13 &amp; 23 \\end{matrix} \\right] \\] 行列の大きさが異なりますね。行列Cの大きさは2 \\(\\times\\) 3、Dは3 \\(\\times\\) 3です。実はこれが正しいです。行列の積は\\(n \\times m\\)の行列と\\(m \\times p\\)の行列同士でないと計算できません。\\(n\\)と\\(p\\)は同じでも、同じでなくても構いません。その意味で\\(C \\times D\\)は計算可能でも、\\(D \\times C\\)は計算できません。そして、2つの行列の積の大きさは\\(n \\times p\\)です。したがって、\\(C \\times D\\)の大きさは\\(2 \\times 3\\)です。 行列の積がどのように求められるかを確認するために、まず行列CとDを作成してみましょう。 (C &lt;- matrix(c(1, 2, 3, 4, 5, 6), nrow = 2,byrow = TRUE)) ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 (D &lt;- matrix(c(2, 7, 17, 3, 11, 19, 5, 13, 23), nrow = 3,byrow = TRUE)) ## [,1] [,2] [,3] ## [1,] 2 7 17 ## [2,] 3 11 19 ## [3,] 5 13 23 この2つの積は%*%演算子で計算されますが、まずその結果から見ましょう。 (E &lt;- C %*% D) ## [,1] [,2] [,3] ## [1,] 23 68 124 ## [2,] 53 161 301 2行2列の行列ができました。これらの数字、どうやった計算されたのでしょうか。Eの[1, 1]は23であり、[1, 2]は68、[2, 1]は53、[2, 2]は161です。各値は以下のように求まります。 E[1, 1] = (C[1, 1] * D[1, 1]) + (C[1, 2] * D[2, 1]) + (C[1, 3] * D[3, 1]) = 23 E[1, 2] = (C[1, 1] * D[1, 2]) + (C[1, 2] * D[2, 2]) + (C[1, 3] * D[3, 2]) = 68 E[1, 3] = (C[1, 1] * D[1, 3]) + (C[1, 2] * D[2, 3]) + (C[1, 3] * D[3, 3]) = 124 E[2, 1] = (C[2, 1] * D[1, 1]) + (C[2, 2] * D[2, 1]) + (C[2, 3] * D[3, 1]) = 53 E[2, 2] = (C[2, 1] * D[1, 2]) + (C[2, 2] * D[2, 2]) + (C[2, 3] * D[3, 2]) = 161 E[2, 3] = (C[2, 1] * D[1, 3]) + (C[2, 2] * D[2, 3]) + (C[2, 3] * D[3, 3]) = 301 大きさ\\(n \\times m\\)行列Cのi行目j列目の要素を\\(C_{i,j}\\)と表記し、大きさ\\(n \\times p\\)行列Dのi行目j列目の要素を\\(D_{i,j}\\)と表記した場合、以下のような関係が成り立ちます。 行列Eのi行目j列目の要素を\\(e_{i,j}\\)と表記した場合、以下のような関係が成り立ちます。 \\[ e_{i, j} = \\sum_{k = 1}^m C_{i, k} \\cdot D_{k, j}. \\] したがって、行列\\(C\\)と\\(D\\)の積は \\[\\begin{align} CD = E &amp; = \\left[ \\begin{matrix} e_{1, 1} &amp; e_{1, 2} &amp; e_{1, 3} \\\\ e_{2, 1} &amp; e_{2, 2} &amp; e_{2, 3} \\end{matrix} \\right] \\\\ &amp; = \\left[ \\begin{matrix} \\sum_{k = 1}^m C_{1, k} \\cdot D_{k, 1} &amp; \\sum_{k = 1}^m C_{1, k} \\cdot D_{k, 2} &amp; \\sum_{k = 1}^m C_{1, k} \\cdot D_{k, 3} \\\\ \\sum_{k = 1}^m C_{2, k} \\cdot D_{k, 1} &amp; \\sum_{k = 1}^m C_{2, k} \\cdot D_{k, 2} &amp; \\sum_{k = 1}^m C_{2, k} \\cdot D_{k, 3} \\end{matrix} \\right]. \\end{align}\\] このように業績同士の積はかなり求めるのが面倒ですが、Rを使えば一瞬で終わります。 行列式 行列式 (determinant)は\\(n \\times n\\)の正方行列のみに対して定義される値の一つです。主に一次方程式において解が存在するか否かを判断するために用いられる数値ですが45、その詳しい意味や求め方については線形代数の入門書を参照してください。 行列\\(A\\)の行列式は一般的に\\(\\text{det}(A)\\)、または\\(|A|\\)と表記されます。行列式を求めるRの関数はdet()です。それでは適当に正方行列Fを作成し、その行列を求めてみましょう。 (F &lt;- matrix(c(2, -6, 4, 7, 2, 3, 8, 5, -1), nrow = 3, byrow = 3)) ## [,1] [,2] [,3] ## [1,] 2 -6 4 ## [2,] 7 2 3 ## [3,] 8 5 -1 det(F) ## [1] -144 行列Fの行列式は-144です。この場合、以下の一次方程式に何らかの一組の解が存在することを意味します (\\(p\\), \\(q\\), \\(r\\)は任意の実数)。 \\[\\begin{align} 2x - 6y + 4z = &amp; p, \\\\ 7x + 2y + 3z = &amp; q, \\\\ 8x + 5y - 1z = &amp; r. \\end{align}\\] しかし、以下のような連立方程式はいかがでしょう。これは二組以上の解が存在する方程式です46。 \\[\\begin{align} 2x - 6y + 4z = &amp; p, \\\\ 1x - 3y + 2z = &amp; q, \\\\ 5x + 9y + 3z = &amp; r. \\end{align}\\] 実際に行列Gを作成し、det(G)を計算してみましょう。 (G &lt;- matrix(c(2, -6, 4, 1, -3, 2, 5, 9, 3), nrow = 3, byrow = 3)) ## [,1] [,2] [,3] ## [1,] 2 -6 4 ## [2,] 1 -3 2 ## [3,] 5 9 3 det(G) ## [1] 0 \\(|G|\\)は0であることが分かりますね。 階数 行列の特徴を表す代表的な数値の一つが階数 (rank)です。詳しい説明は省きますが、一次方程式の例だと、階数が行列の行数と一致する場合、一組の解が存在することを意味します。階数を求める方法はqr(行列)$rankであり、行列FとGの階数を確認してみましょう。 qr(F)$rank ## [1] 3 qr(G)$rank ## [1] 2 どれも3行の行列ですが、行列Fの階数は3、行列Gの階数は2です。Gの階数はGの行数より小さいため、連立方程式に一組の解がないことが分かります。 階数の活用先は様々であり、行列式とは違って、正方行列でなくても計算可能です。 逆行列 逆行列とは掛け算すると単位行列となる行列を意味します。行列\\(A\\)の逆行列は一般的に\\(A^{\\prime}\\)と表記し、\\(A \\times A^{\\prime} = I\\)となります。この逆行列の求め方は非常に複雑であり、一定以上の大きさの行列になると手計算で解くのはほぼ不可能です。しかし、Rでは逆行列を計算するsolve()関数が内蔵されております。 以下の行列\\(A\\) (A)の逆行列、\\(A^{\\prime}\\) (Ap)を求めてみましょう。そして\\(A \\times A^{\\prime}\\)が単位行列になるかまで確認してみます。 # 行列Aの作成 (A &lt;- matrix(c(1, -2, 2, 0, 1, -1, 1, 0, 1), nrow = 3)) ## [,1] [,2] [,3] ## [1,] 1 0 1 ## [2,] -2 1 0 ## [3,] 2 -1 1 # 行列Aの逆行列を計算し、Apに格納 (Ap &lt;- solve(A)) ## [,1] [,2] [,3] ## [1,] 1 -1 -1 ## [2,] 2 -1 -2 ## [3,] 0 1 1 # AとApの積が単位行列であることを確認 A %*% Ap ## [,1] [,2] [,3] ## [1,] 1 0 0 ## [2,] 0 1 0 ## [3,] 0 0 1 ちゃんと単位行列ができましたね。 転置 行列\\(A\\)の転置行列は\\(A^T\\)と表記され、以下のような関係となります。 \\[ A = \\left[ \\begin{matrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\\\ 7 &amp; 8 &amp; 9 \\end{matrix} \\right], A^T = \\left[ \\begin{matrix} 1 &amp; 4 &amp; 7 \\\\ 2 &amp; 5 &amp; 8 \\\\ 3 &amp; 6 &amp; 9 \\end{matrix} \\right] \\] 正方行列の場合、対角成分を除き、全ての要素が対角成分を中心に反転していることが分かりますね。このような転置行列の作成にはt()関数を使います。それでは行列Aとその転置行列Atを作ってみましょう。 A &lt;- matrix(1:9, byrow = TRUE, nrow = 3) A ## [,1] [,2] [,3] ## [1,] 1 2 3 ## [2,] 4 5 6 ## [3,] 7 8 9 At &lt;- t(A) ちなみに転置行列は正方行列でなくても作成できます。 9.4 データフレーム (data.frame) データフレームはデータ分析の際に最もよく見るデータ構造です。我々が一般的に考える表形式のデータはデータフレームです。行列も見た目は表に近いですが、行列は中身の要素がnumericまたはcomplex型に限定されるに対して47、データフレームはcharacterやfactor、Dateなど様々なデータ型が許容されます。 9.4.1 データフレームの作成 まずは、表@ref(tab: datastructure-dataframe-1)のようなデータフレームを作成して見ましょう。データフレームを作成する際はdata.frame()関数を使います。 表 9.1: myDFの中身 ID Name Math Stat 1 Yanai 50 25 2 Song 90 5 3 Shigemura 100 100 4 Tani 80 85 myDF &lt;- data.frame( ID = 1:4, Name = c(&quot;Yanai&quot;, &quot;Song&quot;, &quot;Shigemura&quot;, &quot;Tani&quot;), Math = c(50, 90, 100, 80), Stat = c(25, 5, 100, 85) ) myDF ## ID Name Math Stat ## 1 1 Yanai 50 25 ## 2 2 Song 90 5 ## 3 3 Shigemura 100 100 ## 4 4 Tani 80 85 データ構造を確認してみましょう。 class(myDF) ## [1] &quot;data.frame&quot; データフレームを作成する際、事前にベクトルを用意してから作成することも可能です。 myDF_ID &lt;- 1:4 myDF_Name &lt;- c(&quot;Yanai&quot;, &quot;Song&quot;, &quot;Shigemura&quot;, &quot;Tani&quot;) myDF_Math &lt;- c(50, 90, 100, 80) myDF_Stat &lt;- c(25, 5, 100, 85) myDF2 &lt;- data.frame(myDF_ID, myDF_Name, myDF_Math, myDF_Stat) myDF2 ## myDF_ID myDF_Name myDF_Math myDF_Stat ## 1 1 Yanai 50 25 ## 2 2 Song 90 5 ## 3 3 Shigemura 100 100 ## 4 4 Tani 80 85 この場合、列の名前はベクトル名そのままになります。もし、列名を指定したい場合は以下のように作成します。 myDF3 &lt;- data.frame( ID = myDF_ID, Name = myDF_Name, Math = myDF_Math, Stat = myDF_Stat ) myDF3 ## ID Name Math Stat ## 1 1 Yanai 50 25 ## 2 2 Song 90 5 ## 3 3 Shigemura 100 100 ## 4 4 Tani 80 85 以上をコードを考えてみると、データフレームは複数のベクトルを横方向にくっつけたものになります。注意すべき点としては各ベクトルの長さが一致している点です。myDFの場合、4つのベクトルで構成されていますが、全てのベクトルの長さは4です。むろん、長さが異なる場合もデータフレームは作成できます。この場合、長さが足りないベクトルは最も長さが長いベクトルに合わせて繰り返されます。例としてmyDF4を作ってみましょう。 myDF4 &lt;- data.frame( ID = 1:4, Name = c(&quot;Yanai&quot;, &quot;Song&quot;, &quot;Shigemura&quot;, &quot;Tani&quot;), Math = c(50, 90, 100, 80), Stat = c(25, 5, 100, 85), City = &quot;Kobe&quot;, Food = c(&quot;Ramen&quot;, &quot;Udon&quot;) ) myDF4 ## ID Name Math Stat City Food ## 1 1 Yanai 50 25 Kobe Ramen ## 2 2 Song 90 5 Kobe Udon ## 3 3 Shigemura 100 100 Kobe Ramen ## 4 4 Tani 80 85 Kobe Udon City列はすべて\"Kobe\"が入り、Food列は長さが足りない3, 4番目の要素に1, 2番目の要素が代入されます。実際はあまり使わない使い方ですが、ある列の要素が全て同じ場合、このような使い方をすることがあります。 9.4.2 データフレームの操作 データフレームの大きさ 行列と同様、dim()から行と列の数を、nrow()からは行数を、ncol()から列数を計算することができます。 dim(myDF4) ## [1] 4 6 nrow(myDF4) ## [1] 4 ncol(myDF4) ## [1] 6 要素の抽出 まず、データフレーム内要素の抽出についてですが、行列型と同じやり方で問題ありません。つまり、[行番号, 列番号]で要素の抽出が可能です。これに加え、データフレームには$を使った抽出方法があります。 まず、行列と同じやり方でmyDF4の2行目、6列目の要素を抽出してみましょう。 myDF4[2, 6] ## [1] &quot;Udon&quot; 行を丸ごと抽出したい場合は、列を指定しません。myDF4の3, 4行目を抽出してみましょう。 myDF4[3:4, ] # myDF4[c(3, 4), ]も同じ ## ID Name Math Stat City Food ## 3 3 Shigemura 100 100 Kobe Ramen ## 4 4 Tani 80 85 Kobe Udon 同じやり方で列を抽出すことも可能です。好きな食べ物 (Food)列を抽出してみましょう。 myDF4[, 6] ## [1] &quot;Ramen&quot; &quot;Udon&quot; &quot;Ramen&quot; &quot;Udon&quot; 列を抽出する場合は、列名を指定することも可能です。やり方は[, \"列名\"]による方法、$列名による方法があります。Name列を抽出してみましょう。 myDF4[, &quot;Name&quot;] ## [1] &quot;Yanai&quot; &quot;Song&quot; &quot;Shigemura&quot; &quot;Tani&quot; myDF4$Name ## [1] &quot;Yanai&quot; &quot;Song&quot; &quot;Shigemura&quot; &quot;Tani&quot; どれも同じ結果が返されます。後者の方が簡単ですが、一つの列しか抽出できない限界があります。それに比べ、前者はc()を使うことで複数の列を同時に抽出することも可能です。それぞれの場面に応じて使い分けていきましょう。 また、$で列を抽出した場合、抽出されたものはベクトル扱いになるため、[]を使った要素の抽出が可能です。例えばmyDF4のName列の2番目の要素を抽出してみましょう。 myDF4$Name[2] ## [1] &quot;Song&quot; あまり意識する必要はありませんが、抽出後のデータ構造について簡単に説明します。データフレームから一部の要素を抽出した結果物は必ずしもデータフレームにはなりません。 操作 返されるデータ型 1 1行を抽出する データフレーム 2 複数の行を抽出する データフレーム 3 1列を抽出する ベクトル 4 複数の列を抽出する データフレーム 注目するのは3番目の例ですが、これはRの最小単位がベクトルであり、データフレームもベクトルの集めだからです。データフレームは「縦」ベクトルを横に並べたものです。もし、行を抽出した場合、その要素は全て同じデータ型だとは限りません。実際、myDF4の3行目を抽出しても、中にはcharacter型とnumeric型と混在しています。しかし、一つの列のみを抽出した場合、全ての要素は必ず同じデータ型となるため、ベクトルとして扱うことが可能です。同様に、行列型の一列を抽出した場合も結果はベクトルとなります。ただし、行列は全ての要素がNAを除き、同じであるため、一行を抽出しても結果はベクトル型となります。 セルの修正 特定のセルの修正する方法は簡単です。先ほど、データフレームから一つのセルを取り出すにはデータフレーム名[行番号, 列番号]だけでした。そのセルを修正するにはベクトルと同様、データフレーム名[行番号, 列番号] &lt;- 新しい値のように入力します。 たとえば、重村さんが数学試験で不正が発覚し、0点になるとします。そのためには、myDF4の3行・3列目の要素を0に修正する必要がありますが、以下のようなコマンドで修正可能です。 myDF4[3, 3] &lt;- 0 myDF4 ## ID Name Math Stat City Food ## 1 1 Yanai 50 25 Kobe Ramen ## 2 2 Song 90 5 Kobe Udon ## 3 3 Shigemura 0 100 Kobe Ramen ## 4 4 Tani 80 85 Kobe Udon ちゃんと重村さんの数学点数が0点になりました。ざまあみろですね！ もう一つのやり方としては、一旦、列を取り出し、ベクトルにおける要素の置換操作を行う方法です。矢内大先生が神戸から離れ、高知県へ移住し、小物の宋は京都へ移住したとします。myDF4のCity列の1・2番目要素をc(\"Kochi\", \"Kyoto\")に修正する必要があります。そのためには以下のように入力します。 myDF4$City[c(1, 2)] &lt;- c(&quot;Kochi&quot;, &quot;Kyoto&quot;) myDF4 ## ID Name Math Stat City Food ## 1 1 Yanai 50 25 Kochi Ramen ## 2 2 Song 90 5 Kyoto Udon ## 3 3 Shigemura 0 100 Kobe Ramen ## 4 4 Tani 80 85 Kobe Udon 修正した要素が反映されました。 列の追加・修正 まずは、データフレームに列を追加する方法について紹介します。方法は データフレーム名$新しい列名 &lt;- ベクトル のように入力するだけです。たとえば、4人を対象に英語試験を行い、それぞれの点数が95点、50点、80点、5点だとします。この英語試験の成績をmyDF4のEnglish列として追加してみましょう。 myDF4$English &lt;- c(95, 50, 80, 5) むろん、以下のように予めベクトルを作成してから代入することも可能です。 English_Score &lt;- c(95, 50, 80, 5) myDF4$English &lt;- English_Score どれも同じ結果になりますが、結果を見てみましょう。 myDF4 ## ID Name Math Stat City Food English ## 1 1 Yanai 50 25 Kochi Ramen 95 ## 2 2 Song 90 5 Kyoto Udon 50 ## 3 3 Shigemura 0 100 Kobe Ramen 80 ## 4 4 Tani 80 85 Kobe Udon 5 「EnglishがStatの次じゃなくて気持ち悪い！」と思う方もいるかも知れませんが、列順番の変更については第12章で解説します。まずは、これで我慢しましょう。 次は、列の置換についてです。実はよく考えてみるとこれは列の追加と全く同じです。たとえば、英語試験において配点が5点の問題にミスが見つかり、全生徒の英語成績に5点を上乗せるとします。そのためにはベクトルmyDF4$Englishの全ての要素に5を足し、それをもう一回myDf4$Englishに代入すれば良いです。 myDF4$English &lt;- myDF4$English + 5 myDF4 ## ID Name Math Stat City Food English ## 1 1 Yanai 50 25 Kochi Ramen 100 ## 2 2 Song 90 5 Kyoto Udon 55 ## 3 3 Shigemura 0 100 Kobe Ramen 85 ## 4 4 Tani 80 85 Kobe Udon 10 これでEnglish列の修正ができました。 行の追加・修正はなるべくしない 行の追加はなるべくしない方が良いです。その理由について考えてみましょう。今は4人の生徒のデータがありますが、ここにもう一人の生徒のデータを追加するとします。そのためにはmyDF4の5行目に生徒のID、名前、数学・統計学の成績、居住地域、好きな食べ物、英語の成績を入れれば良いでしょう。新しい学生、吐合さんの数学・統計学・英語成績は50, 50, 50点、居住地域は芦屋、好きな食べ物は二郎だとします。早速追加してみましょう。 myDF4[5, ] &lt;- c(5, &quot;Hakiai&quot;, 50, 50, &quot;Ashiya&quot;, &quot;Jiro&quot;, 50) myDF4 ## ID Name Math Stat City Food English ## 1 1 Yanai 50 25 Kochi Ramen 100 ## 2 2 Song 90 5 Kyoto Udon 55 ## 3 3 Shigemura 0 100 Kobe Ramen 85 ## 4 4 Tani 80 85 Kobe Udon 10 ## 5 5 Hakiai 50 50 Ashiya Jiro 50 問題なく吐合さんのデータが追加されたように見えますが、実は問題があります。myDF4のStat列を取り出して見ましょう。 myDF4$Stat ## [1] &quot;25&quot; &quot;5&quot; &quot;100&quot; &quot;85&quot; &quot;50&quot; 異常に気づきましたか。それではこのベクトルのデータ型を確認してみましょう。 class(myDF4$Stat) ## [1] &quot;character&quot; 元々はnumeric型であるはずのStat列がcharacter型になりました。その理由は明白です。ベクトルの要素は全て同じデータ型だからです。そして、numericとcharacter型が混在している場合は、自動的に（優先順位の高い）character型になります。以下の2つのコマンドが同じであることは理解できるでしょう。 # Case 1 myDF4[5, ] &lt;- c(5, &quot;Hakiai&quot;, 50, 50, &quot;Ashiya&quot;, &quot;Jiro&quot;, 50) # Case 2 Hakiai_Data &lt;- c(5, &quot;Hakiai&quot;, 50, 50, &quot;Ashiya&quot;, &quot;Jiro&quot;, 50) myDF4[5, ] &lt;- Hakiai_Data ここのベクトルHakiai_Dataが強制的にcharacter型になるため、myDF4の5行目の要素は全てcharacter型になります。また、データフレームは縦ベクトルを横に並べたものであるなら、myDF4$Math列にcharacter型の要素が追加されることによって、列も全てcharacter型になってしまいます。したがって、データフレームにcharacter型とnumeric型が混在している状況において新しい行の追加は全ての要素をcharacter型に変えてしまうのです。むろん、データフレームの全要素がnumeric型であれば、このような問題は生じますが、numeric型のみで構成されたデータフレームはなかなかないでしょう。 5行目を消しても問題は解決しないので、結局は列のデータ型を強制的に変更する必要があります。 myDF4$ID &lt;- as.numeric(myDF4$ID) myDF4$Math &lt;- as.numeric(myDF4$Math) myDF4$Stat &lt;- as.numeric(myDF4$Stat) myDF4$English &lt;- as.numeric(myDF4$English) class(myDF4$Math) ## [1] &quot;numeric&quot; これでやっと元通りになりましたね。 どうしても行を追加したい場合は、以下のようなやり方もありますが、おすすめはできません。 myDF4[6, ] &lt;- rep(NA, 7) # myDF4の6行目を追加し、7つの欠損値を代入 myDF4$ID[6] &lt;- 6 # myDF4$IDの6番目の要素に6を代入 myDF4$Name[6] &lt;- &quot;Yukawa&quot; # myDF4$Nameの6番目の要素にYukawaを代入 myDF4$Math[6] &lt;- 80 # 以下、省略 myDF4$Stat[6] &lt;- 30 myDF4$City[6] &lt;- &quot;Hiroshima&quot; myDF4$Food[6] &lt;- &quot;Ramen&quot; myDF4$English[6] &lt;- 90 myDF4 ## ID Name Math Stat City Food English ## 1 1 Yanai 50 25 Kochi Ramen 100 ## 2 2 Song 90 5 Kyoto Udon 55 ## 3 3 Shigemura 0 100 Kobe Ramen 85 ## 4 4 Tani 80 85 Kobe Udon 10 ## 5 5 Hakiai 50 50 Ashiya Jiro 50 ## 6 6 Yukawa 80 30 Hiroshima Ramen 90 class(myDF4$English) ## [1] &quot;numeric&quot; 欠損値 (NA)はどのようなデータ型にも対応できる特徴を利用すれば、このような操作も可能ですが、かなり面倒です。そもそも実際の分析において任意の行を追加することは滅多にないはずです。 9.4.3 tibble型 data.frame型に似ているデータ型としてtibble型があります。これはR内蔵のデータ型ではありませんが、Rの必須パッケージとも言える{tidyverse}内に含まれているデータ型であり、これからもどんどん普及していくでしょう。tibble型とdata.frame型の違いを説明するために、同じデータをそれぞれのデータ型で読み込んでみましょう。 とりあえずread.csv()で読み込み、VoteDF1と名付けましょう。 VoteDF1 &lt;- read.csv(&quot;Data/Vote.csv&quot;) 続いてVoteDF1をas_tibble()関数を使ってtibble型にし、VoteDF2と名付けます。そして、それぞれのデータ構造を確認してみます。 VoteDF2 &lt;- as_tibble(VoteDF1) class(VoteDF1) ## [1] &quot;data.frame&quot; class(VoteDF2) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; 全く同じデータですが、VoteDF2にはtblとtbl_dfというクラスが追加されていることが分かります。それではデータの中身を覗いてみましょう。まずは、data.frame型から VoteDF1 ## ID Pref Zaisei Over65 Under30 LDP DPJ Komei Ishin JCP SDP ## 1 1 北海道 0.41903 29.09 24.70 32.82 30.62 13.41 3.43 11.44 1.68 ## 2 2 青森県 0.33190 30.14 23.92 40.44 24.61 12.76 3.82 8.92 3.41 ## 3 3 岩手県 0.34116 30.38 24.48 34.90 22.44 8.61 5.16 11.24 5.29 ## 4 4 宮城県 0.59597 25.75 27.29 36.68 25.40 13.42 3.97 9.99 3.62 ## 5 5 秋田県 0.29862 33.84 21.35 43.46 22.72 11.19 5.17 7.56 5.12 ## 6 6 山形県 0.34237 30.76 24.75 42.49 21.47 11.78 4.30 7.60 5.20 ## 7 7 福島県 0.50947 28.68 25.23 33.82 28.31 10.96 3.43 10.45 3.24 ## 8 8 茨城県 0.63309 26.76 26.60 40.64 18.95 15.05 6.67 10.07 2.88 ## 9 9 栃木県 0.62166 25.87 26.78 38.78 21.63 12.42 10.88 7.00 2.05 ## 10 10 群馬県 0.60277 27.60 26.59 42.06 19.31 13.85 5.61 10.00 2.44 ## 11 11 埼玉県 0.76548 24.82 27.66 32.30 20.40 16.00 7.23 13.94 1.91 ## 12 12 千葉県 0.77694 25.86 26.71 37.79 21.70 13.98 5.46 11.34 2.01 ## 13 13 東京都 1.00321 22.67 27.39 34.37 19.76 11.44 7.34 14.21 2.82 ## 14 14 神奈川県 0.91745 23.86 27.84 34.92 21.49 12.18 7.77 12.46 2.79 ## 15 15 新潟県 0.43519 29.86 25.23 43.66 25.25 8.27 4.39 8.00 3.76 ## 16 16 富山県 0.45307 30.54 24.88 44.16 24.22 9.81 5.06 5.79 5.02 ## 17 17 石川県 0.46812 27.87 27.25 48.09 18.54 11.00 6.36 7.07 2.36 ## 18 18 福井県 0.37820 28.63 26.70 45.29 17.52 10.91 13.09 5.66 2.09 ## 19 19 山梨県 0.37876 28.41 26.37 37.36 28.04 12.83 4.32 9.20 1.67 ## 20 20 長野県 0.47586 30.06 25.52 35.27 27.69 10.70 4.23 12.61 3.59 ## 21 21 岐阜県 0.52358 28.10 27.22 39.71 23.62 12.33 5.51 9.41 1.98 ## 22 22 静岡県 0.70999 27.79 26.28 37.47 24.13 12.68 7.99 9.59 2.22 ## 23 23 愛知県 0.92052 23.79 29.44 34.32 29.27 11.67 6.41 9.55 2.14 ## 24 24 三重県 0.57544 27.90 26.74 33.67 34.23 13.07 5.09 7.59 1.76 ## 25 25 滋賀県 0.53932 24.15 29.96 37.85 22.25 9.57 12.82 11.44 1.41 ## 26 26 京都府 0.56713 27.51 27.76 31.18 19.93 12.25 11.16 18.50 1.55 ## 27 27 大阪府 0.74980 26.15 27.55 22.12 9.30 16.39 34.86 11.37 1.25 ## 28 28 兵庫県 0.62062 27.09 26.94 31.71 15.84 15.37 19.50 10.30 2.01 ## 29 29 奈良県 0.41269 28.70 26.86 33.51 18.41 13.44 18.94 9.17 1.66 ## 30 30 和歌山県 0.31955 30.89 25.08 39.61 12.10 18.00 13.51 10.43 1.23 ## 31 31 鳥取県 0.25486 29.71 25.86 41.62 20.93 16.71 5.98 7.14 2.56 ## 32 32 島根県 0.24170 32.48 24.59 48.24 19.14 13.43 4.75 7.50 2.51 ## 33 33 岡山県 0.50096 28.66 27.44 37.87 19.91 17.18 10.67 7.87 1.60 ## 34 34 広島県 0.58581 27.53 27.46 39.93 18.53 15.20 9.69 8.52 2.35 ## 35 35 山口県 0.42560 32.07 24.91 46.75 17.27 16.50 5.31 7.39 1.78 ## 36 36 徳島県 0.32018 30.95 24.31 38.44 17.72 16.87 9.46 9.10 1.81 ## 37 37 香川県 0.46060 29.93 25.29 44.07 16.60 15.14 6.20 7.56 5.07 ## 38 38 愛媛県 0.41181 30.62 24.75 43.57 19.28 14.82 6.77 6.97 2.40 ## 39 39 高知県 0.24472 32.85 23.60 37.01 16.95 15.83 3.93 17.41 2.91 ## 40 40 福岡県 0.61836 25.90 28.21 36.52 19.08 17.15 7.03 10.78 3.33 ## 41 41 佐賀県 0.32938 27.68 27.97 43.53 21.10 15.48 4.85 5.67 4.16 ## 42 42 長崎県 0.31562 29.60 25.84 41.70 20.68 16.86 5.12 6.27 3.48 ## 43 43 熊本県 0.38688 28.78 27.18 46.54 19.29 15.27 4.53 6.32 2.60 ## 44 44 大分県 0.35828 30.45 25.65 39.44 18.37 13.26 4.42 6.85 13.05 ## 45 45 宮崎県 0.32034 29.49 26.26 40.11 14.50 17.11 5.74 7.27 6.81 ## 46 46 鹿児島県 0.32140 29.43 26.04 45.97 16.19 14.49 6.47 6.52 3.62 ## 47 47 沖縄県 0.31535 19.63 33.37 27.82 13.29 15.09 7.66 15.64 12.13 つづいて、tibble型は、 VoteDF2 ## # A tibble: 47 × 11 ## ID Pref Zaisei Over65 Under30 LDP DPJ Komei Ishin JCP SDP ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 北海道 0.419 29.1 24.7 32.8 30.6 13.4 3.43 11.4 1.68 ## 2 2 青森県 0.332 30.1 23.9 40.4 24.6 12.8 3.82 8.92 3.41 ## 3 3 岩手県 0.341 30.4 24.5 34.9 22.4 8.61 5.16 11.2 5.29 ## 4 4 宮城県 0.596 25.8 27.3 36.7 25.4 13.4 3.97 9.99 3.62 ## 5 5 秋田県 0.299 33.8 21.4 43.5 22.7 11.2 5.17 7.56 5.12 ## 6 6 山形県 0.342 30.8 24.8 42.5 21.5 11.8 4.3 7.6 5.2 ## 7 7 福島県 0.509 28.7 25.2 33.8 28.3 11.0 3.43 10.4 3.24 ## 8 8 茨城県 0.633 26.8 26.6 40.6 19.0 15.0 6.67 10.1 2.88 ## 9 9 栃木県 0.622 25.9 26.8 38.8 21.6 12.4 10.9 7 2.05 ## 10 10 群馬県 0.603 27.6 26.6 42.1 19.3 13.8 5.61 10 2.44 ## # … with 37 more rows 同じデータですが、表示画面がやや異なります。data.frame型は全ての列と行が表示されましたが、tibble型の場合、「画面に収まる」程度しか表示されません。表示されなかった行や列に関しては最後に表示されています。今回は全ての列が表示されましたが、たとえば、VoteDF2の場合、下段にこのように表示される場合があります (画面の大きさによって変わり、表示されないケースもあれば、SDP以外の変数も省略されるケースがあります。)。 ## # … with 37 more rows, and 1 more variable: SDP &lt;dbl&gt; これは表示されなかった行が37行あり、SDPという変数も表示されていないということです。他の違いとしては、tibble型の場合、最初にデータのサイズ (47行11列)が、各変数名の下にデータ型 (&lt;int&gt;、&lt;chr&gt;、&lt;dbl&gt;など)が表示されるという点です。 本書はtibble型とdata.frame型を区別して解説はしませんが、一部の章・節においてはtibble型を念頭において解説をします。tibble型の作り方は先ほどのようにas_tibble()使う方法もありますが、readr::read_csv()を使う方法もあります48。read_csv()を使うと各列がどのようなデータ型として読み込まれたかも表示されるので便利です。{readr}パッケージは{tidyverse}に含まれているため、普段では以下のような使い方で十分です。 VoteDF3 &lt;- read_csv(&quot;Data/Vote.csv&quot;) class(VoteDF3) # VoteDF3の構造 ## [1] &quot;spec_tbl_df&quot; &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; tibble型とdata.frame型の最も大きな違いは、data.frame型の一つのセルには長さ1のベクトルしか入らない一方、tibble型は何でも入るという点です。つまり、tibble型なら一つのセルに数字や文字列だけでなく、長さ2以上のベクトル、後述するリスト型、行列、さらにはtibble型も入れることが出来ます。これについては本書の中盤以降に解説します。 本書で「データフレーム」と書いた場合、それはtibbleでも適用可能です。ただし、tibbleと明示した場合、データフレームでは適用不可能です。 9.5 リスト (list) リスト型は「様々なデータ構造を集めたもの」です。これは複数のデータフレームが格納されたオブジェクト、複数のベクトルが格納されたオブジェクト、行列とデータフレームが混在したオブジェクトなどを意味します。また、リスト型データはリスト型データを含むことも可能であり、非常に柔軟なデータ構造です。 9.5.1 リスト型データの作成 ここではまず、2つのデータフレームを含むリストを作成してみます。それぞれのデータフレームはFIFA国別サッカーランキングであり49、本書のサンプルデータのFIFA_Women.csvとFIFA_Men.csvです。まずは、2つのデータを読み込み、Soccer_WとSoccer_Mという名のオブジェクトに格納しましょう。また、ここでは単に例を見せるだけなので、全データを利用するのではなく、最初の10行のみを利用します。 Soccer_W &lt;- read.csv(&quot;Data/FIFA_Women.csv&quot;) Soccer_M &lt;- read.csv(&quot;Data/FIFA_Men.csv&quot;) Soccer_W &lt;- Soccer_W[1:10, ] Soccer_M &lt;- Soccer_M[1:10, ] リストの作成にはlist()関数に入れたいオブジェクト名を指定するだけです。それではList1という名前でSoccer_WとSoccer_Mデータフレームを入れてみましょう。格納後はList1のデータ構造をclass()で確認します List1 &lt;- list(Soccer_W, Soccer_M) class(List1) ## [1] &quot;list&quot; List1 ## [[1]] ## ID Team Rank Points Prev_Points Confederation ## 1 1 Albania 75 1325 1316 UEFA ## 2 2 Algeria 85 1271 1271 CAF ## 3 3 American Samoa 133 1030 1030 OFC ## 4 4 Andorra 155 749 749 UEFA ## 5 5 Angola 121 1117 1117 CAF ## 6 6 Antigua and Barbuda 153 787 787 CONCACAF ## 7 7 Argentina 32 1659 1659 CONMEBOL ## 8 8 Armenia 126 1103 1104 UEFA ## 9 9 Aruba 157 724 724 CONCACAF ## 10 10 Australia 7 1963 1963 AFC ## ## [[2]] ## ID Team Rank Points Prev_Points Confederation ## 1 1 Afghanistan 149 1052 1052 AFC ## 2 2 Albania 66 1356 1356 UEFA ## 3 3 Algeria 35 1482 1482 CAF ## 4 4 American Samoa 192 900 900 OFC ## 5 5 Andorra 135 1082 1082 UEFA ## 6 6 Angola 124 1136 1136 CAF ## 7 7 Anguilla 210 821 821 CONCACAF ## 8 8 Antigua and Barbuda 126 1127 1127 CONCACAF ## 9 9 Argentina 9 1623 1623 CONMEBOL ## 10 10 Armenia 102 1213 1213 UEFA 一つのオブジェクトに2つのデータフレームが入っていますね。これは2つのデータフレームで構成された長さ2のリストです。ただし、どちらが女性ランキングで、どちらが男子ランキングか区別が難しいです。この場合、各データフレームに名前を付けることも可能です。 List2 &lt;- list(Women = Soccer_W, Men = Soccer_M) List2 ## $Women ## ID Team Rank Points Prev_Points Confederation ## 1 1 Albania 75 1325 1316 UEFA ## 2 2 Algeria 85 1271 1271 CAF ## 3 3 American Samoa 133 1030 1030 OFC ## 4 4 Andorra 155 749 749 UEFA ## 5 5 Angola 121 1117 1117 CAF ## 6 6 Antigua and Barbuda 153 787 787 CONCACAF ## 7 7 Argentina 32 1659 1659 CONMEBOL ## 8 8 Armenia 126 1103 1104 UEFA ## 9 9 Aruba 157 724 724 CONCACAF ## 10 10 Australia 7 1963 1963 AFC ## ## $Men ## ID Team Rank Points Prev_Points Confederation ## 1 1 Afghanistan 149 1052 1052 AFC ## 2 2 Albania 66 1356 1356 UEFA ## 3 3 Algeria 35 1482 1482 CAF ## 4 4 American Samoa 192 900 900 OFC ## 5 5 Andorra 135 1082 1082 UEFA ## 6 6 Angola 124 1136 1136 CAF ## 7 7 Anguilla 210 821 821 CONCACAF ## 8 8 Antigua and Barbuda 126 1127 1127 CONCACAF ## 9 9 Argentina 9 1623 1623 CONMEBOL ## 10 10 Armenia 102 1213 1213 UEFA これでどれが女性ランキングか、男性ランキングかが区別しやすくなりました。ここでは2つのデータフレームを入れましたが、様々なデータ構造が混在したリストも可能です。様々なデータ構造が混在したリストを自分で作成する場面はあまりありません。自分で作成した独自クラスを利用するパッケージを開発する際はよく使いますが、ここでは省略します。ただし、様々なデータ構造が含まれたリスト型を見ることはよくあります。たとえば、lm()関数で回帰分析を行った際、その結果はリスト型であり、中にはベクトル、データフレーム、リストなどが混在しています。これについては今後詳細に解説していきたいと思います。 9.5.2 リスト型データの操作 リスト型の中身は何でもあり得るので、なんらかの操作方法があるわけではありません。リスト型の操作というのはリスト内の要素をどのように抽出するかであり、各要素 (データフレーム、行列、ベクトルなど)の操作はこれまで説明してきた方法と同じです。したがって、ここではリストを構成する要素を抽出する方法についてのみ解説します。 要素の番号を利用する方法 List1は各要素に名前が付いていないため、番号で抽出します。たとえば、あるリストのi番目の要素を抽出するにはリスト名[[i]]で抽出します。[]ではなく、[[]]であることに注意してください。それではList1の1番目の要素を抽出してみましょう。 List1[[1]] ## ID Team Rank Points Prev_Points Confederation ## 1 1 Albania 75 1325 1316 UEFA ## 2 2 Algeria 85 1271 1271 CAF ## 3 3 American Samoa 133 1030 1030 OFC ## 4 4 Andorra 155 749 749 UEFA ## 5 5 Angola 121 1117 1117 CAF ## 6 6 Antigua and Barbuda 153 787 787 CONCACAF ## 7 7 Argentina 32 1659 1659 CONMEBOL ## 8 8 Armenia 126 1103 1104 UEFA ## 9 9 Aruba 157 724 724 CONCACAF ## 10 10 Australia 7 1963 1963 AFC このようにList1内の1番目のデータが抽出されました。こちらのデータ構造は何でしょうか。 class(List1[[1]]) ## [1] &quot;data.frame&quot; 既に予想したかと思いますが、データフレームとして抽出されました。ここから更に、3行目のデータを抽出するには、[[]]の後に[3, ]を付けます。 List1[[1]][3, ] ## ID Team Rank Points Prev_Points Confederation ## 3 3 American Samoa 133 1030 1030 OFC 先ほどリストの要素の抽出には「[]でなく、[[]]です」と申しましたが、実は[]も使用可能です。やってみましょう。 List1[1] ## [[1]] ## ID Team Rank Points Prev_Points Confederation ## 1 1 Albania 75 1325 1316 UEFA ## 2 2 Algeria 85 1271 1271 CAF ## 3 3 American Samoa 133 1030 1030 OFC ## 4 4 Andorra 155 749 749 UEFA ## 5 5 Angola 121 1117 1117 CAF ## 6 6 Antigua and Barbuda 153 787 787 CONCACAF ## 7 7 Argentina 32 1659 1659 CONMEBOL ## 8 8 Armenia 126 1103 1104 UEFA ## 9 9 Aruba 157 724 724 CONCACAF ## 10 10 Australia 7 1963 1963 AFC [[]]を使った抽出とあまり変わらないですね。しかし、重要な違いが一つあります。それはデータ構造です。 class(List1[1]) ## [1] &quot;list&quot; []で抽出したリストの要素のデータ構造もまたリスト型です。この場合、先ほどのように[x, ]を使って、x行目のデータを抽出することはできません。なぜなら、[行, 列]による要素の抽出はデータフレームのためのものであって、リスト型のためのものではないからです。 List1[1][3, ] ## Error in List1[1][3, ]: incorrect number of dimensions このようにエラーが表示されます。 要素の名前を利用する方法 List2のようにリストの要素に名前を付けた場合、これまでの方法に加え[[\"要素名\"]]と$要素名を使った操作が可能です50。List2から男子ランキング (Men)を抽出してみましょう。 List2[[&quot;Men&quot;]] ## ID Team Rank Points Prev_Points Confederation ## 1 1 Afghanistan 149 1052 1052 AFC ## 2 2 Albania 66 1356 1356 UEFA ## 3 3 Algeria 35 1482 1482 CAF ## 4 4 American Samoa 192 900 900 OFC ## 5 5 Andorra 135 1082 1082 UEFA ## 6 6 Angola 124 1136 1136 CAF ## 7 7 Anguilla 210 821 821 CONCACAF ## 8 8 Antigua and Barbuda 126 1127 1127 CONCACAF ## 9 9 Argentina 9 1623 1623 CONMEBOL ## 10 10 Armenia 102 1213 1213 UEFA List2$Men ## ID Team Rank Points Prev_Points Confederation ## 1 1 Afghanistan 149 1052 1052 AFC ## 2 2 Albania 66 1356 1356 UEFA ## 3 3 Algeria 35 1482 1482 CAF ## 4 4 American Samoa 192 900 900 OFC ## 5 5 Andorra 135 1082 1082 UEFA ## 6 6 Angola 124 1136 1136 CAF ## 7 7 Anguilla 210 821 821 CONCACAF ## 8 8 Antigua and Barbuda 126 1127 1127 CONCACAF ## 9 9 Argentina 9 1623 1623 CONMEBOL ## 10 10 Armenia 102 1213 1213 UEFA どれも結果は同じです。また、それぞれのデータ構造もデータフレームです。 class(List2[[&quot;Men&quot;]]) ## [1] &quot;data.frame&quot; class(List2$Men) ## [1] &quot;data.frame&quot; したがって、[行番号, 列番号]のようにデータフレームの操作が可能です。Men要素から10行目のデータを抽出してみましょう。 List2[[&quot;Men&quot;]][10, ] ## ID Team Rank Points Prev_Points Confederation ## 10 10 Armenia 102 1213 1213 UEFA List2$Men[10, ] ## ID Team Rank Points Prev_Points Confederation ## 10 10 Armenia 102 1213 1213 UEFA もちろん、名前を付けた場合であっても、要素の番号を利用した操作も可能です。自分でリスト型を作成する際には各要素に名前を付けた方が分かりやすくて良いでしょう。 9.6 配列 (array) 配列は行列の拡張版であり、行列は配列の特殊な形です。これまでのRでは行列と配列は区別されてきましたが、R 4.0.0以降、行列は配列の属するデータ構造となりました。 配列型は簡単にいうと、同じサイズの行列を数枚重ねたものです。図9.1は配列型のイメージを表したものです。 図 9.1: 配列型データのイメージ したがって、配列型は行と列以外にも、層の要素も持つことになります。複数の行列で構成されている点では、リスト型と類似していますが、配列型は同じサイズの行列のみで構成されている点が特徴です。 配列型は普段、扱う機会があまりありませんが、マルコフ連鎖モンテカルロ法 (MCMC)でベイジアン推定を行った後の事後分布データは配列型で格納される場合があります。 9.6.1 配列型データの作成 各行列は3行4列とし、4層構造とします。まずは、同じサイズの行列を作成し、それぞれMat1、Mat2、Mat3、Mat4と名付けます。 Mat1 &lt;- matrix(sample(1:12, 12, replace = TRUE), byrow = TRUE, nrow = 3) Mat2 &lt;- matrix(sample(1:12, 12, replace = TRUE), byrow = TRUE, nrow = 3) Mat3 &lt;- matrix(sample(1:12, 12, replace = TRUE), byrow = TRUE, nrow = 3) Mat4 &lt;- matrix(sample(1:12, 12, replace = TRUE), byrow = TRUE, nrow = 3) sample()関数は初めてですね。これは与えられたベクトルの要素から無作為に要素を抽出する関数です。sample(1:12, n)ならc(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1 2)から無作為にn個の要素を抽出するという意味です。replace = TRUEを指定すると、反復抽出、つまり、一回抽出された要素であっても抽出される可能性があることを意味します。デフォルトはFALSEですが、この場合、一旦抽出された要素は二度と抽出されません。それではそれぞれの行列の中身を見てみましょう。 Mat1 ## [,1] [,2] [,3] [,4] ## [1,] 6 5 8 3 ## [2,] 10 4 11 6 ## [3,] 5 3 4 10 Mat2 ## [,1] [,2] [,3] [,4] ## [1,] 4 10 11 3 ## [2,] 5 3 4 11 ## [3,] 11 11 3 6 Mat3 ## [,1] [,2] [,3] [,4] ## [1,] 3 8 7 5 ## [2,] 2 3 11 7 ## [3,] 7 1 5 1 Mat4 ## [,1] [,2] [,3] [,4] ## [1,] 3 2 4 3 ## [2,] 7 9 6 10 ## [3,] 8 8 12 7 配列型データを作成するにはarray()関数を使います。引数としては行列名をc()で繋ぎ51、dim =でarrayの大きさを指定するだけです。配列を作成した後はそのデータ構造も確認してみましょう。 Array1 &lt;- array(c(Mat1, Mat2, Mat3, Mat4), dim = c(3, 4, 4)) class(Array1) ## [1] &quot;array&quot; dim = c(m, n, z)の部分ですが、これは「m行n列の行列がz枚重ねる」という意味です。今回は3行4列の行列を4枚重ねるのでdim = c(3, 4, 4)です。それではArray1の中身を見てみます。 Array1 ## , , 1 ## ## [,1] [,2] [,3] [,4] ## [1,] 6 5 8 3 ## [2,] 10 4 11 6 ## [3,] 5 3 4 10 ## ## , , 2 ## ## [,1] [,2] [,3] [,4] ## [1,] 4 10 11 3 ## [2,] 5 3 4 11 ## [3,] 11 11 3 6 ## ## , , 3 ## ## [,1] [,2] [,3] [,4] ## [1,] 3 8 7 5 ## [2,] 2 3 11 7 ## [3,] 7 1 5 1 ## ## , , 4 ## ## [,1] [,2] [,3] [,4] ## [1,] 3 2 4 3 ## [2,] 7 9 6 10 ## [3,] 8 8 12 7 このように一つのオブジェクト内に複数の行列が格納されたオブジェクトが生成されます。 9.6.2 配列型データの操作 配列型データの操作は行列型に似ていますが、層というもう一つの次元があるため、行列名[行番号, 列番号]ではなく、配列名[行番号, 列番号, 層番号]を使います。たとえば、Array1の3番目の行列を抽出したい場合、Array1[, , 3]と入力します。 Array1[, , 3] ## [,1] [,2] [,3] [,4] ## [1,] 3 8 7 5 ## [2,] 2 3 11 7 ## [3,] 7 1 5 1 また、2番目の行列の3行目・1列目の要素を抽出するならArray1[3, 1, 2]と入力します。 Array1[3, 1, 2] ## [1] 11 配列型における操作の特徴の一つは全ての行列が同じ大きさを持つため、層を貫通した操作ができるという点です。たとえば、全ての層の2行目を抽出するなら、層番号を指定せず、行番号のみで抽出します。 Array1[2, , ] ## [,1] [,2] [,3] [,4] ## [1,] 10 5 2 7 ## [2,] 4 3 3 9 ## [3,] 11 4 11 6 ## [4,] 6 11 7 10 ただ、返された結果は配列型でなく行列型であることに注意しましょう。たとえば、1番目の行列の2行目の要素は10, 4, 11, 6ですが、これは先ほど抽出された行列の1列目に該当します。また、2番目の行列の2行目の要素は5, 3, 4, 11であり、これは先ほどの抽出された行列の2列目となります。全層において特定の一列を抽出しても同じです。これは各層において抽出されたデータが行列でなく、ベクトルだからです。 一方、複数の行または列を抽出した場合、結果は配列型です。Array1の各層から1・2行目と1・2列目の要素、つまり大きさが2 \\(\\times\\) 2の行列を抽出してみましょう。 Array1[1:2, 1:2, ] ## , , 1 ## ## [,1] [,2] ## [1,] 6 5 ## [2,] 10 4 ## ## , , 2 ## ## [,1] [,2] ## [1,] 4 10 ## [2,] 5 3 ## ## , , 3 ## ## [,1] [,2] ## [1,] 3 8 ## [2,] 2 3 ## ## , , 4 ## ## [,1] [,2] ## [1,] 3 2 ## [2,] 7 9 このように各層において抽出されたデータが行列だからです。自分の操作から得られた結果がどのようなデータ型・データ構造かを予め知っておくことで分析の効率が上がるでしょう。 行列に名前を付けたい 今回は各行列に1, 2, 3, 4という番号のみ割り当てましたが、実は行列に名前を付けることも可能です。そのためには配列データ作成時、dimnames =引数を指定する必要があります。 Array2 &lt;- array(c(Mat1, Mat2, Mat3, Mat4), dim = c(3, 4, 4), dimnames = list(NULL, NULL, c(&quot;M1&quot;, &quot;M2&quot;, &quot;M3&quot;, &quot;M4&quot;)) ) dimnames =引数は必ず長さ3のリスト型である必要があります。1番目と2番目の要素は行名と列名ですが、行列において一般的に使われないため、ここではNULLにし、3番目の要素、つまり各層の名前だけを指定します。ここではそれぞれの層をM1、M2、M3、M4と名付けました。ここでM4のみを抽出する場合は、以下のように操作します。 Array2[, , &quot;M4&quot;] ## [,1] [,2] [,3] [,4] ## [1,] 3 2 4 3 ## [2,] 7 9 6 10 ## [3,] 8 8 12 7 むろん、これまでと同様、番号で抽出することも可能です。 Array2[, , 4] ## [,1] [,2] [,3] [,4] ## [1,] 3 2 4 3 ## [2,] 7 9 6 10 ## [3,] 8 8 12 7 練習問題 リストと配列は要素の抽出が主な操作となるため、練習問題は掲載しておりません。 9.6.3 ベクトル 問1 1から10までの公差1の等差数列 (1, 2, 3, …, 10)を作成し、myVec1と名付けよ。 問2 myVec1の長さを求めよ。 問3 myVec1から偶数のみを抽出せよ 問4 myVec1をmyVec2という名でコピーし、myVec2の偶数を全て0に置換せよ。 問5 myVec1の全要素から1を引し、myVec3と名付けよ。 問6 myVec1の奇数番目の要素には1を、偶数番目の要素には2を足し、myVec4と名付けよ。 問7 myVec4からmyVec1を引け。 9.6.4 行列 問1 以下のような2つの行列を作成し、それぞれmyMat1、myMat2と名付けよ。 \\[ \\text{myMat1} = \\left[ \\begin{matrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\end{matrix} \\right], \\text{myMat2} = \\left[ \\begin{matrix} 1 &amp; 4 &amp; 7 \\\\ 2 &amp; 5 &amp; 8 \\\\ 3 &amp; 6 &amp; 9 \\end{matrix} \\right] \\] 問2 myMat1とmyMat2の掛け算を行い、myMat3と名付けよ。掛け算はアダマール積でなく、一般的な行列間の積を求めること。 問3 以下のような連立方程式を解くケースを考える。 \\[\\begin{align} 3x - y + 2z &amp; = 12, \\\\ x + 2y + 3z &amp; = 11, \\\\ 2x - y - z &amp; = 2. \\end{align}\\] 以下のような2つの行列を作成し、それぞれmyMat4、myMat5と名付けよ。 \\[ \\text{myMat4} = \\left[ \\begin{matrix} 3 &amp; -1 &amp; 2 \\\\ 1 &amp; 2 &amp; 3 \\\\ 2 &amp; -1 &amp; -1 \\end{matrix} \\right], \\text{myMat5} = \\left[ \\begin{matrix} 12 \\\\ 11 \\\\ 2 \\end{matrix} \\right] \\] myMat4の逆行列を求めよ。 myMat4の逆行列とmyMat5の積を求め、myMat6と名付けよ。 これが連立方程式の解である。 myMat4とmyMat6の積を求めよ。 9.6.5 データフレーム 問1 以下のようなデータフレームを作成し、myDF1と名付けよ52。 ID Name Rank Socre 1 Japan 28 1500 2 Iran 33 1489 3 South Korea 40 1464 4 Australia 42 1457 5 Qatar 55 1396 6 Saudi Arabia 67 1351 7 Iraq 70 1344 8 UAE 71 1334 9 China 76 1323 10 Syria 79 1314 問2 myDF1からName列を抽出せよ。 問3 myDF1のName列から3番目の要素を抽出せよ。 問4 myDF1の3行目を抽出せよ。 問5 FIFA_Women.csvをtibble型として読み込み、myTbl1と名付けよ53。 問6 myTbl1のRank列を抽出し、それぞれの要素が20より小さいかを判定せよ。 問7 myTbl1のRankが20より小さい国名を抽出せよ。 問8 myTbl1からランキングが20より上位の行を抽出せよ。 この章で使うパッケージを読み込む。 pacman::p_load(tidyverse) "],["programming.html", "10. Rプログラミングの基礎 10.1 R言語の基礎概念 10.2 Rのコーディングスタイル 10.3 反復 10.4 条件分岐 練習問題", " 10. Rプログラミングの基礎 この章では統計ソフトウェアではなく、プログラミング言語としてのRについて解説する。プログラミングは難しいというイメージがあるかもしれないが、実は難しい。しかし、プログラミングをする場合にまず覚えるべき重要概念は、 データの読み書き54 条件分岐 反復 の3つだけだ55。この3つだけでほとんどのプログラムが作れる。ただ、この単純さがプログラミングの難しさもあるとも言える。 たとえば、ある数字の列を小さい順（昇順）に並び替えることを考えよう。c(6, 3, 7, 2, 5, 1, 8, 4) という数列が与えられたとき、人間ならあまり苦労することなく、c(1, 2, 3, 4, 5, 6, 7, 8) に並び替えられるだろう。しかし、その手順を「代入」、「条件分岐」、「反復」のみで明確に表現できるだろうか56。もちろん、できる。よって、並べ替えはプログラミングによって実現することができる。Rには、数字を並べ替えるためのsort()関数やorder()関数などが用意されており、それらの組込関数を使えば良いのだが、組込関数は「代入」、「条件分岐」、「反復」を組み合わせて作られたものだ。 「代入」、「条件分岐」、「反復」という3つの概念さえ理解すれば何でもできるるという意味で、プログラミングは簡単だ。しかし、この3つだけで解決しないといけないという意味で、プログラミングは難しい。頻繁に利用する機能については、ほとんどのプログラミング言語があらかじめ作られた関数 (built-in function, 組込関数) を数多く提供しており、ユーザである私たちは組込関数を使うのが賢明である。それでも条件分岐や反復について勉強する必要があるのは、私たち一般ユーザにとってもこれが必要な場面が多いからである。たとえば、同じ分析をデータだけ変えながら複数回実行するために反復を利用する。反復をうまく使えば、コードの量を数十分の一に減らすことも可能である。また、特定の条件に応じてデータを分類するときは条件分岐を使う。条件分岐を使いこなせないと、CalcやExcelなどのスプレッドシートでデータを目でみながら値を入力するという苦行を強いられるが57、条件分岐が使えればそのような作業は必要ない。数行のプログラミングをするだけで、ほんの数秒で分類が終わる。 10.1 R言語の基礎概念 10.1.1 オブジェクト これまで「オブジェクト」や「関数」などという概念を定義せずに使ってきたが、ここではR言語の構成する基本的な概念についてもう少し詳細に解説する。これらは、プログラミングをする上である程度は意識的に使う必要があるものである。 まず、オブジェクト (object) とはメモリに割り当てられた「何か」である。「何か」に該当するのは、ベクトル (vector)、行列 (matrix)、データフレーム (data frame)、リスト (list)、関数 (function) などである。一般的に、オブジェクトにはそれぞれ固有の（つまり、他のオブジェクトと重複しない）名前が付いている。 たとえば、1から5までの自然数の数列を my_vec1 &lt;- c(1, 2, 3, 4, 5) # my_vec1 &lt;- 1:5 でも同じ のようにmy_vec1という名前のオブジェクトに格納する。オブジェクトに名前をつけてメモリに割り当てると、その後 my_vec1 と入力するだけでそのオブジェクトの中身を読み込むことができるようになる。 ここで、次のように my_vec1の要素を2倍にする操作を考えてみよう。 my_vec1 * 2 ## [1] 2 4 6 8 10 my_vec1は、先ほど定義したオブジェクトである。では2はどうだろうか。2はメモリに割り当てられていないので、オブジェクトではないのだろうか。実は、この数字 2 もオブジェクトである。計算する瞬間のみ2がメモリに割り当てられ、計算が終わったらメモリから消されると考えれば良い。「Rに存在するあらゆるものはオブジェクトである (Everything that exists in R is an object)」 (Chambers (2016, 4))。* のような演算子でさえもオブジェクトである。 10.1.2 クラス クラス (class) とはオブジェクトを特徴づける属性である。既に何度か class() 関数を使ってデータ型やデータ構造を確認したが、class()関数でオブジェクトのクラスを確認することができる。先ほど、my_vec1も*も2もオブジェクトであると説明した。これらがすべてオブジェクトであるということは、何らかのクラス属性を持っているというこである。また、class()関数そのものもオブジェクトなので、何らかのクラスをもつ。確認してみよう。 class(my_vec1) ## [1] &quot;numeric&quot; class(`*`) ## [1] &quot;function&quot; class(2) ## [1] &quot;numeric&quot; class(class) ## [1] &quot;function&quot; 統計分析をする際に、Rのクラスを意識することはあまりない。しかし、Rでパッケージを開発したり、複雑な関数を自作する場合、オブジェクト指向プログラミング (Object-oriented Programming; OOP) の考え方が重要で、オブジェクトのクラスを厳密に定義する必要がある58。 自分でパッケージを開発しないとしても、クラスの概念は知っておいたほうが良い。この後説明する関数には引数というものがあるが、引数には特定のクラスのオブジェクトしか指定できない。関数の使い方がわからないときには?関数名 でヘルプを表示するが、ヘルプには各引数に使うべきクラスが書かれている。クラスについて何も知らないと、ヘルプを読んでも意味がわからないかもしれない。 たとえば、Rコンソール上で?meanを入力して実行すると、図10.1のような mean() 関数のヘルプが表示される。ヘルプに示されているとおり、mean()関数に必要な引数は x、trim、na.rmである。仮引数xの説明を読むと、x の実引数にはnumeric または logical のベクトルクラスが使えることが分かる。さらに、date、date-time、time interval が使えることも教えてくれる。 図 10.1: mean()関数のヘルプ画面 回帰分析を行うlm()関数の場合、data という仮引数があるが、dataの実引数に指定できるのは data.frame クラスまたは tibbleクラスのオブジェクトである59。通常はクラスを意識せずにRを使っても問題ないが、 全てのオブジェクトにはクラスが付与されており、 関数 (の引数) ごとに実引数として使えるクラスが異なる という2点は覚えておこう。 10.1.3 関数と引数 関数 (function) は、入力されたデータを内部で決められた手順に従って処理し、その結果を返すものである。「Rで起こるあらゆることは関数の呼び出しである (Everything that happens in R is a function call)」(Chambers (2016, 4))。 関数は 関数名(関数の入力となるオブジェクト) のように使う。たとえば、class(my_vec1)はmy_vec1というオブジェクトのクラスを返す関数である。また、sum(my_vec1)はmy_vec1の要素の総和を計算して返す関数である。 関数は自分で作成することもできる（次章で説明する）。複雑な作業を繰り返す場合、その作業を関数として記述することで、一行でその作業を再現することが可能になる。「2度以上同じことを繰り返すなら関数を作れ」というのが、Rユーザの心得である。 関数を使うためには、 引数 (ひきすう) と呼ばれるものが必要である。例えば、sum() 関数はこれだけだと何もできない。何らかのオブジェクトがが入力として与えられないと、結果を返すことができない。sum(my_vec1)のようにすることではじめて結果が返される。ここでmy_vec1がsum()関数の引数である。 関数は引数は複数持つことができる。たとえば、欠測値を含む以下のmy_vec2を考えてみよう。 my_vec2 &lt;- c(1, 2, 3, NA, 5) この数列の総和を sum()関数で求めようとすると、結果は欠測値 NA になる。 sum(my_vec2) ## [1] NA これはsum()の基本仕様が「入力に欠測値が含まれている場合は欠測値を返す」ことになっているためである。入力されたデータのなかで欠測値を除いたものの総和を求めるために、sum()はもう1つの引数が用意されている。それが na.rm である。na.rm = TRUEを指定すると、欠測値を除外した総和を返す。 sum(my_vec2, na.rm = TRUE) ## [1] 11 第6章で説明したとおり、na.rm などのように引数を区別するために関数によって用意されたものを仮引数 (parameter) と呼び、TRUE のように引数の中身としてユーザが指定するものを実引数 (argument) と呼ぶ。my_vec2 は実引数である。 引数を指定するとき、my_vec2のように仮引数を明示しないこともある。多くの場合、それがなければ関数がそもそも動かないという第1引数の仮引数は明示しないことが多い。そもそも、第1引数には仮引数がない（名前がない）場合もある。sum() 関数の第1引数はnumeric または complex 型のベクトルだが、仮引数がそもそもない（... で定義されている）。 しかし、第1引数以外については、na.rm = TRUE のように仮引数を明示すべきである。関数によっては数十個の引数をとるものもあり、仮引数を明示しないと、どの実引数がどの仮引数に対応するのかわかりにくい。 多くの引数は関数によって定義された既定値 (default value) をもっている。たとえば、sum()関数の na.rm の既定値は FALSE である。既定値が用意されている場合、その引数を指定せずに関数を使うことができる。 ある関数がどのような引数を要求しているか、その既定値は何か、引数として何か決められたデータ型/データ構造があるかを調べたいときは ?関数名 （()がないことに注意）または help(関数名）をコンソールに入力する。多くの関数に詳細なヘルプが付いているので、ネットで検索したり、誰かに質問する前にひとまずヘルプを読むべきである。 10.2 Rのコーディングスタイル Rコードの書き方に唯一の正解はない。文法が正しければ、つまり、Rが意図どおりの実行結果を出してくれさえすれば、それは「正しい」コードである。しかし、コードというのは、一度書けば二度と読まないというものではない。最初に「書く」とき以外に、「修正する」ときや「再利用」するときなどに繰り返し読むことになる。また、共同研究をする場合には共同研究者がコードを読む。さらに、近年では研究成果を報告する際に分析に利用したコードを後悔公開することも当たり前になりつつあり、その場合には自分で書いたコードを世界中の人が読む可能性がある。 ここで大事なのは、Rコードを読むのはRだけではないということである。人間も重要な「読者」である。Rコードを書くときは人間に優しいコードを書くように心がえよう。唯一の正解がなくても、読みやすく、多くの人が採用している標準的な書き方はある。ここでは、人間に優しいコードを書くためのコーディングスタイルについて説明しよう。 10.2.1 オブジェクト名 ベクトル、データフレーム、自作の関数などのすべてのオブジェクトには名前をつける必要がある（ラムダ式などの無名関数を除く）。名前はある程度自由に付けることができるが、大事な原則がある。それは、 オブジェクト名は英数字と限られた記号のみにする 数字で始まる変数名は避ける 1つ目は原則にすぎない。よって、日本語やハングルの変数名をつけることもできる。しかし、それは推奨しない。英数字以外（マルチバイト文字）は文字化けの可能性がある（文字コードの問題が発生する）し、コードを書く際列がずれる原因にもなる var1 &lt;- c(2, 3, 5, 7, 11) # 推奨 変数1 &lt;- c(2, 3, 5, 7, 11) # 非推奨 변수1 &lt;- c(2, 3, 5, 7, 11) # 非推奨 var1 ## [1] 2 3 5 7 11 変数1 ## [1] 2 3 5 7 11 변수1 ## [1] 2 3 5 7 11 2つ目のルールは必ず守る必要がある。つまり、数字で始まるオブジェクト名は作成できない。 100A &lt;- &quot;R&quot; ## Error: &lt;text&gt;:1:4: unexpected symbol ## 1: 100A ## ^ 予約語を避ける Rが提供する組込の関数やオブジェクトと重複する名前を自分で作成するオブジェクトに付けるのは避けよう。例えば、Rには円周率 (\\(\\pi\\)) がpiという名前で用意されている。 pi ## [1] 3.141593 piという名前で新しい変数を作ることはできる。 pi &lt;- 777 しかし、既存のpiが上書きされてしまうので避けたほうが良い。 pi # もはや円周率ではない ## [1] 777 元の円周率を使うこともできるが、手間が増える。 base::pi ## [1] 3.141593 また、ユーザが自由に使えない名前もある。それらの名前を「予約語」と呼ぶ。予約語の使用は禁止されている。 if &lt;- &quot;YY&quot; ## Error: &lt;text&gt;:1:5: unexpected assignment ## 1: if &lt;- ## ^ for &lt;- &quot;JS&quot; ## Error: &lt;text&gt;:1:5: unexpected assignment ## 1: for &lt;- ## ^ TRUE &lt;- &quot;いつもひとつ！&quot; ## Error in TRUE &lt;- &quot;いつもひとつ！&quot;: invalid (do_set) left-hand side to assignment このように、予約語はそもそも使えないので、それほど意識する必要はない。 ただし、以下のコードのようなことが起こるので注意してほしい。 vals &lt;- 1:5 vals[c(TRUE, TRUE, FALSE, FALSE, TRUE)] ## [1] 1 2 5 vals[c(T, T, F, F, T)] ## [1] 1 2 5 ここから、T は TRUE、F は FALSE と同じ働きをしていることがわかる。ここで、次のコードを実行してみよう。 T &lt;- &quot;Taylor&quot; F &lt;- &quot;Fourier&quot; vals[c(T, T, F, F, T)] ## [1] NA NA NA NA NA このように、T とFはあらかじめ使える状態で用意されているものの、予約語ではないので値が代入できてしまう。しかし、T とF を自分で定義したオブジェクトの名前に使うと混乱の元になるので、使用は避けるのが無難である。 また、TRUE と FALSE を T やF で済ませる悪習は廃して常に完全にスペルすべきである。 短さと分かりやすさを重視する オブジェクト名を見るだけでその中にどのようなデータが含まれているか推測できる名前をつけるべきである。たとえば、性別を表す変数を作るなら、 var2 &lt;- c(&quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;female&quot;) ではなく、 gender &lt;- c(&quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;female&quot;) としたほうが良い。gender という名前がついていれば、「この変数には性別に関する情報が入っているだろう」と容易に想像できる。 また、オブジェクト名は、短くて読みやすいほうが良い。数学の成績データをもつ次のオブジェクトについて考えよう。 mathematicsscore &lt;- c(30, 91, 43, 77, 100) オブジェクト名から、中にどのような情報が含まれるか想像することはできる。しかし、この名前は長く、読みにくい。そこで、次のように名前を変えたほうが良い。 MathScore &lt;- c(30, 91, 43, 77, 100) mathScore &lt;- c(30, 91, 43, 77, 100) math_score &lt;- c(30, 91, 43, 77, 100) これらの例では、mathematics を math に縮め、mathとscoreの間に区切りを入れて読みやすくしている。大文字と小文字の組み合わせで区切る方法はキャメルケース (camel case)と呼ばれ、大文字から始まるキャメルケースを大文字キャメルケース (upper camel case)、小文字から始まるキャメルケースを小文字キャメルケース (lower camel case) と呼ぶ。また、_（アンダーバー, アンスコ） で区切る方法はスネークケース (snake case) と呼ばれる。キャメルケースとスネークケースは、一貫した方法で使えばどちらを使っても良いだろう。 かつては “.” を使って単語を繋ぐのが標準的だった時代もあり、組込関数には “.” を使ったものも多い。data.frame() や read.csv() などがその例である。しかし、“.” はクラスのメソッドとして使われることがあり、混乱するので使うのは避けたほうが良い。tidyverse* では、readr::read_csv() のように、スネークケースが採用されている。他にも -（ハイフン）で区切るチェーンケース (chain case)**というのもあるが、Rで-は「マイナス（減算演算子）」であり、チェーンケースは使えない60。 10.2.2 改行 コードは1行が長すぎないように適宜改行する。Rやパッケージなどが提供している関数のなかには10個以上の引数を必要とするものもあり。コードを1行で書こうとするとコードの可読性が著しく低くなってしまう。 1行に何文字入れるべきかについて決まったルールはないが、1行の最大文字数を半角80字にするという基準が伝統的に使われてきた。これま昔のパソコンで使ったパンチカード (図10.2)では1行に80個の穴を開けることができたことに由来する。 図 10.2: パンチカードの例 最近は昔と比べてモニタのサイズが大きく、解像度も高いので、80文字にこだわる必要はない。自分のRStudioのSource Paneに収まるよう、切りがいいところで改行しよう。 10.2.3 スペースとインデント 適切なスペースはコードの可読性を向上させる。以下の2つのコードは同じ内容を実行するが、後者にはスペースがないので読にくい。 # 良い例 sum(my_vec2, na.rm = TRUE) # 悪い例 sum(my_vec2,na.rm=TRUE) どこにスペースを入れるかについてのルールは特になり。Rは「半角スペース」を無視するので、プログラムの動作に関して言えば、半角スペースはあってもなくても同じである。標準的なルールとして、「,の後にスペース」、「演算子の前後にスペース」などが考えらえる。ただし、^の前後にはスペースを入れないことが多い。また、後ほど紹介するfor(){}、while(){}、if(){}などのように、関数以外の ()の前後にはスペースを入れる。それに対し、sum() や read.csv() などのように、関数のかっこの場合には、関数名と()の間にスペースを入れない。 また、スペースを2回以上入れることもある。たとえば、あるデータフレームを作る例を考えよう。 # 良い例 data.frame( name = c(&quot;Song&quot;, &quot;Yanai&quot;, &quot;Wickham&quot;), favorite = c(&quot;Ramen&quot;, &quot;Cat&quot;, &quot;R&quot;), gender = c(&quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;) ) # 悪い例 data.frame( name = c(&quot;Song&quot;, &quot;Yanai&quot;, &quot;Hadley&quot;), favorite = c(&quot;Ramen&quot;, &quot;Cat&quot;, &quot;R&quot;), gender = c(&quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;) ) 上の2つのコードの内容は同じだが、前者のほうが読みやすい。 ここでもう1つ注目してほしいのは、「字下げ (indent)」の使い方である。上のコードは次のように一行にまとめることができるが、読みにくい。 # 邪悪な例 data.frame(name=c(&quot;Song&quot;,&quot;Yanai&quot;,&quot;Hadley&quot;),favorite=c(&quot;Ramen&quot;,&quot;Cat&quot;,&quot;R&quot;),fender=c(&quot;Male&quot;,&quot;Male&quot;,&quot;Male&quot;)) このように1行のコードが長い場合、「改行」が重要である。しかし、Rの最も基本的なルールは「1行に1つのコード」なので、改行するとこのルールを破ることになってしまう。そこで、コードの途中で改行するときは、2行目以降を字下げすることで、1つのコードが前の行から続いていることを明確にしよう。前の行の続きの行は2文字（または4文字）分字下げする。こうすることで、「この行は上の行の続き」ということが「見て」わかるようになる。 # 良い例 data.frame( name = c(&quot;Song&quot;, &quot;Yanai&quot;, &quot;Hadley&quot;), favorite = c(&quot;Ramen&quot;, &quot;Cat&quot;, &quot;R&quot;), gender = c(&quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;) ) # 悪い例 data.frame( name = c(&quot;Song&quot;, &quot;Yanai&quot;, &quot;Hadley&quot;), favorite = c(&quot;Ramen&quot;, &quot;Cat&quot;, &quot;R&quot;), gender = c(&quot;Male&quot;, &quot;Male&quot;, &quot;Male&quot;) ) RStudioは自動的に字下げをしてくれるので、RStudioを使っているならあまり意識する必要はない。自動で字下げしてくれないエディタを使っている場合は、字下げに気をつけよう。 10.2.4 代入 オブジェクトに値を代入する演算子として、これまで &lt;- を使ってきたが、=を使うこともできる。R以外の多くのプログラミング言語では、代入演算子として=を採用している。しかし、引数の指定と代入を区別するためん、本書では&lt;-の使用を推奨する。また、既に説明したとおり、option + -（macOSの場合）または Alt + -（Windows の場合）というショートカットを使うと、&lt;- だけでなく、その前後のスペースを自動的に挿入してくれる。コードが読みやすくなるので、代入演算子は常にショートカットで入力する習慣をつけよう。 この節で説明したコードの書き方は、コーディングスタイルの一部に過ぎない。本書では、できるだけ読みやすいコードを例として示すことを心がけている。最初は本書（あるいは他の本やウェブサイトに掲載されているもののなかで気に入ったもの）のスタイルを真似して書いてみてほしい。コードを書き写しているうちに、自にとって最善の書き方が見えてくるだろう。 コーディングスタイルについては、以下の2つの資料がさらに詳しい。とりわけ、羽鳥先生が書いたThe tidyverse style guide は事実上の業界標準であり、Google’s Style Guide も このガイドをベースにしている。かなりの分量だが、パッケージ開発などを考えているなら一度は目を通しておいたほうが良いだろう。 The tidyverse style guide Google’s Style Guide 10.3 反復 人間があまり得意ではないが、コンピュータが得意とする代表的な作業が「反復作業」である。普通の人間なら数時間から数年かかるような退屈な反復作業でも、コンピュータを使えば数秒で終わることが多い。Rでもさまざまな反復作業を行うことができる。 反復作業を行うときは、反復作業を「いつ終わらせるか」を考えなくてはならない。終わりを規程する方法として、以下の2つが考えられる。 処理を繰り返し回数を指定し、その回数に達したら終了する: for 文を使う 一定の条件を指定し、その条件が満たされるときに処理を終了する: while 文を使う この節では、これら2つのケースのそれぞれについて解説する。 10.3.1 for による反復 forを利用した反復を、forループ と呼ぶ。まず、forループの雛形をみてみよう。 for (任意の変数 in ベクトル) { 処理内容 } 任意の変数の選び方はいろいろ考えられるが、よく使うのはインデクス (index) i である。このインデクスはforループの内部で使うために用いられる変数である。そして、in の後の「ベクトル」には長さ1以上のベクトルを指定する。ベクトルは必ずしもnumeric型である必要はないが、インデクスを利用したforループではインデクスを指定する正の整数を要素にもつベクトルを使う。 また、{}内の内容が1行のみの場合には、{}は省略しても良い。その場合、処理内容を()の直後に書。つまり、以下のような書き方もできる。 for (任意の変数 in ベクトル) 処理内容 これはforだけでなく、ifやfunction()など、{}で処理内容を囲む関数に共通である。処理内容が2行以上の場合は、必ず{}で囲むようにしよう。 例として、インデクス \\(i\\) の内容を画面に表示することをN回繰り返すforループを書いてみよう。繰り返し回数を指定するために、for (i in 1:N)と書く。5回繰り返すならfor (i in 1:5)とする。1:5はc(1, 2, 3, 4, 5)と同じなので、for (i in c(1, 2, 3, 4, 5))でもいいが、1:5 を使って書いたほうが、コードが読みやすい。 以下コードを作成し、実行してみよう。このコードは3行がひとつのかたまりになったコードである。forの行（あるいは最後の}の行）にカーソルを置いた状態で Cmd/Ctrl + Return/Enter を押せば、forループ全体が一挙に実行される。 # 以下のコードはこのように一行でまとめることも可能 # for(i in 1:5) print(i) for (i in 1:5) { print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 1から5までの数字が表示された。 ここで、このforループがどのような順番で処理を実行したのか確認してみよう。上のコードは、次のようなステップを踏んで1から5までの数字を画面に表示している。 iにベクトル1:5の最初の要素を代入 (i &lt;- 1) print(i)を実行 {}中身の処理が終わったらiにベクトル1:5内の次の要素を代入 (i &lt;- 2) print(i)を実行 {}中身の処理が終わったらiにベクトル1:5内の次の要素を代入 (i &lt;- 3) print(i)を実行 {}中身の処理が終わったらiにベクトル1:5内の次の要素を代入 (i &lt;- 4) print(i)を実行 {}中身の処理が終わったらiにベクトル1:5内の次の要素を代入 (i &lt;- 5) print(i)を実行 {}中身の処理が終わったらiにベクトル1:5内の次の要素を代入するが、5が最後の要素なので反復終了 この手順を要約すると、次のようになる。 任意の変数 (ここではi)にベクトル (ここでは1:5)の最初の要素が格納され、{}内の処理を行う。 {}内の処理が終わったら、ベクトル (ここでは1:5)の次の要素を任意の変数 (ここではi)に格納し、{}内の処理を行う。 格納できる要素がなくなったら反復を終了する。 したがって、反復はベクトル (ここでは1:5)の長さだけ実行される (ここでは5回)。 反復回数はベクトルの長さで決まる。既に述べたとおり、1:5のような書き方でなく、普通のベクトルを指定しても問題ない。たとえば、長さ6の dmg_vals というベクトルを作り、その要素を出力するコードを書いてみよう。 dmg_vals &lt;- c(24, 64, 31, 46, 81, 102) for (damage in dmg_vals) { x &lt;- paste0(&quot;トンヌラに&quot;, damage, &quot;のダメージ!!&quot;) print(x) } ## [1] &quot;トンヌラに24のダメージ!!&quot; ## [1] &quot;トンヌラに64のダメージ!!&quot; ## [1] &quot;トンヌラに31のダメージ!!&quot; ## [1] &quot;トンヌラに46のダメージ!!&quot; ## [1] &quot;トンヌラに81のダメージ!!&quot; ## [1] &quot;トンヌラに102のダメージ!!&quot; スライムくらいなら一撃で撃破できそうな立派な勇者である。 ちなみに、paste0()は引数を空白なし61で繋いだ文字列を返す関数である。詳細は第16で解説するが、簡単な例だけ示しておこう。 paste0(&quot;Rは&quot;, &quot;みんなの&quot;, &quot;ともだち&quot;) ## [1] &quot;Rはみんなのともだち&quot; paste0(&quot;私の&quot;, &quot;HP/MPは&quot;, 500, &quot;/&quot;, 400, &quot;です。&quot;) ## [1] &quot;私のHP/MPは500/400です。&quot; 文字列のベクトルを使ったforループもできる。10個の都市名が格納されたcitiesの要素を1つずつ出力するコードは次のように書ける。 cities &lt;- c(&quot;Sapporo&quot;, &quot;Sendai&quot;, &quot;Tokyo&quot;, &quot;Yokohama&quot;, &quot;Nagoya&quot;, &quot;Kyoto&quot;, &quot;Osaka&quot;, &quot;Kobe&quot;, &quot;Hiroshima&quot;, &quot;Fukuoka&quot;) for (i in seq_along(cities)) { x &lt;- paste0(&quot;現在、cityの値は&quot;, cities[i], &quot;です。&quot;) print(x) } ## [1] &quot;現在、cityの値はSapporoです。&quot; ## [1] &quot;現在、cityの値はSendaiです。&quot; ## [1] &quot;現在、cityの値はTokyoです。&quot; ## [1] &quot;現在、cityの値はYokohamaです。&quot; ## [1] &quot;現在、cityの値はNagoyaです。&quot; ## [1] &quot;現在、cityの値はKyotoです。&quot; ## [1] &quot;現在、cityの値はOsakaです。&quot; ## [1] &quot;現在、cityの値はKobeです。&quot; ## [1] &quot;現在、cityの値はHiroshimaです。&quot; ## [1] &quot;現在、cityの値はFukuokaです。&quot; ここでは for (i in 1:10) ではなく、for (i in seq_along(cities))と表記。この例からわかるように、seq_along() を使うと、ベクトルのインデクス自動的に作ってくれる。上の例では、seq_along(ten_cities) が自動的にベクトル長さを計算し、1:length(ten_cities) すなわち 1:10 と同じ処理をしてくれる。ベクトルの長さが自明でないとき（ベクトルが非常に長いとき）には、seq_along() を使うのが便利である。後で cities の中身を書き換えたときに、cities の長さが変わることも考えられるので、ベクトルのインデクス指定には seq_along() を使おう。 また、インデクスを使わないforループも書ける。上と同じ結果は、次のコードで実現することができる。 for (city in cities) { x &lt;- paste0(&quot;現在、cityの値は&quot;, city, &quot;です。&quot;) print(x) } ## [1] &quot;現在、cityの値はSapporoです。&quot; ## [1] &quot;現在、cityの値はSendaiです。&quot; ## [1] &quot;現在、cityの値はTokyoです。&quot; ## [1] &quot;現在、cityの値はYokohamaです。&quot; ## [1] &quot;現在、cityの値はNagoyaです。&quot; ## [1] &quot;現在、cityの値はKyotoです。&quot; ## [1] &quot;現在、cityの値はOsakaです。&quot; ## [1] &quot;現在、cityの値はKobeです。&quot; ## [1] &quot;現在、cityの値はHiroshimaです。&quot; ## [1] &quot;現在、cityの値はFukuokaです。&quot; このように、ベクトルの中身が数字でない場合でも、forループでベクトルの要素を1つずつ順番に利用することができる。 次に、\"1番目の都市名はSapporoです\"、\"2番目の都市名はSendaiです\"、… のように出力する方法を考えよう。これまでは出力する文字列のなかで1箇所（都市名）のみを変えながら表示したが、今回は「i」と「city」の2箇所を同時に変える。これは、インデクス iを使って反復を実行しながら、cities のi番目要素を呼び出すことで実現できる。以下のコードを実行してみよう。 for (i in seq_along(cities)) { msg &lt;- paste0(i, &quot;番目の都市名は&quot;, cities[i], &quot;です。&quot;) print(msg) } ## [1] &quot;1番目の都市名はSapporoです。&quot; ## [1] &quot;2番目の都市名はSendaiです。&quot; ## [1] &quot;3番目の都市名はTokyoです。&quot; ## [1] &quot;4番目の都市名はYokohamaです。&quot; ## [1] &quot;5番目の都市名はNagoyaです。&quot; ## [1] &quot;6番目の都市名はKyotoです。&quot; ## [1] &quot;7番目の都市名はOsakaです。&quot; ## [1] &quot;8番目の都市名はKobeです。&quot; ## [1] &quot;9番目の都市名はHiroshimaです。&quot; ## [1] &quot;10番目の都市名はFukuokaです。&quot; このように、インデクスとそれに対応するベクトルの要素を抽出すれば、望みどおりの処理ができる。 多重forループ forループの中でさらにforループを使うともできる。最初はやや難しいかもしれないが、多重反復はプログラミング技術としてよく使われるので62、この機会に勉強しよう。 多重forループを理解するためにうってつけの例は掛け算九九である。積算演算子 * の「左の数」と「右の数」 のそれぞれに1から9までの数字を代入するすべての組み合わせを考えるためには、2つのforループが必要だ63。i * jでiとjそれぞれに1から9を代入しながら結果を出力するコードは次のように書ける。 for (i in 1:9) { # for (j in 1:9) { print(paste(i, &quot;*&quot;, j, &quot;=&quot;, i * j)) } } ## [1] &quot;1 * 1 = 1&quot; ## [1] &quot;1 * 2 = 2&quot; ## [1] &quot;1 * 3 = 3&quot; ## [1] &quot;1 * 4 = 4&quot; ## [1] &quot;1 * 5 = 5&quot; ## [1] &quot;1 * 6 = 6&quot; ## [1] &quot;1 * 7 = 7&quot; ## [1] &quot;1 * 8 = 8&quot; ## [1] &quot;1 * 9 = 9&quot; ## [1] &quot;2 * 1 = 2&quot; ## [1] &quot;2 * 2 = 4&quot; ## [1] &quot;2 * 3 = 6&quot; ## [1] &quot;2 * 4 = 8&quot; ## [1] &quot;2 * 5 = 10&quot; ## [1] &quot;2 * 6 = 12&quot; ## [1] &quot;2 * 7 = 14&quot; ## [1] &quot;2 * 8 = 16&quot; ## [1] &quot;2 * 9 = 18&quot; ## [1] &quot;3 * 1 = 3&quot; ## [1] &quot;3 * 2 = 6&quot; ## [1] &quot;3 * 3 = 9&quot; ## [1] &quot;3 * 4 = 12&quot; ## [1] &quot;3 * 5 = 15&quot; ## [1] &quot;3 * 6 = 18&quot; ## [1] &quot;3 * 7 = 21&quot; ## [1] &quot;3 * 8 = 24&quot; ## [1] &quot;3 * 9 = 27&quot; ## [1] &quot;4 * 1 = 4&quot; ## [1] &quot;4 * 2 = 8&quot; ## [1] &quot;4 * 3 = 12&quot; ## [1] &quot;4 * 4 = 16&quot; ## [1] &quot;4 * 5 = 20&quot; ## [1] &quot;4 * 6 = 24&quot; ## [1] &quot;4 * 7 = 28&quot; ## [1] &quot;4 * 8 = 32&quot; ## [1] &quot;4 * 9 = 36&quot; ## [1] &quot;5 * 1 = 5&quot; ## [1] &quot;5 * 2 = 10&quot; ## [1] &quot;5 * 3 = 15&quot; ## [1] &quot;5 * 4 = 20&quot; ## [1] &quot;5 * 5 = 25&quot; ## [1] &quot;5 * 6 = 30&quot; ## [1] &quot;5 * 7 = 35&quot; ## [1] &quot;5 * 8 = 40&quot; ## [1] &quot;5 * 9 = 45&quot; ## [1] &quot;6 * 1 = 6&quot; ## [1] &quot;6 * 2 = 12&quot; ## [1] &quot;6 * 3 = 18&quot; ## [1] &quot;6 * 4 = 24&quot; ## [1] &quot;6 * 5 = 30&quot; ## [1] &quot;6 * 6 = 36&quot; ## [1] &quot;6 * 7 = 42&quot; ## [1] &quot;6 * 8 = 48&quot; ## [1] &quot;6 * 9 = 54&quot; ## [1] &quot;7 * 1 = 7&quot; ## [1] &quot;7 * 2 = 14&quot; ## [1] &quot;7 * 3 = 21&quot; ## [1] &quot;7 * 4 = 28&quot; ## [1] &quot;7 * 5 = 35&quot; ## [1] &quot;7 * 6 = 42&quot; ## [1] &quot;7 * 7 = 49&quot; ## [1] &quot;7 * 8 = 56&quot; ## [1] &quot;7 * 9 = 63&quot; ## [1] &quot;8 * 1 = 8&quot; ## [1] &quot;8 * 2 = 16&quot; ## [1] &quot;8 * 3 = 24&quot; ## [1] &quot;8 * 4 = 32&quot; ## [1] &quot;8 * 5 = 40&quot; ## [1] &quot;8 * 6 = 48&quot; ## [1] &quot;8 * 7 = 56&quot; ## [1] &quot;8 * 8 = 64&quot; ## [1] &quot;8 * 9 = 72&quot; ## [1] &quot;9 * 1 = 9&quot; ## [1] &quot;9 * 2 = 18&quot; ## [1] &quot;9 * 3 = 27&quot; ## [1] &quot;9 * 4 = 36&quot; ## [1] &quot;9 * 5 = 45&quot; ## [1] &quot;9 * 6 = 54&quot; ## [1] &quot;9 * 7 = 63&quot; ## [1] &quot;9 * 8 = 72&quot; ## [1] &quot;9 * 9 = 81&quot; 上のコードがどのような処理をしているか考えてみよう。まず、iに1が代入される。次に、jに1から9までの数順番に1つずつ代入され、1 * 1、1 * 2、1 * 3、…、1 * 9が計算される。1 * 9の計算が終わったら、iに2が代入される。そして再び内側のforループが実行され、2 * 1、2 * 2、2 * 3、…、2 * 9が計算される。これを9の段まで繰り返す。段の順番を降順にして9の段を最初に計算し、1の段を最後に計算したい場合は、i in 1:9をi in 9:1に変えればよい。 for (i in 9:1) { for (j in 1:9) { print(paste(i, &quot;*&quot;, j, &quot;=&quot;, i * j)) } } ## [1] &quot;9 * 1 = 9&quot; ## [1] &quot;9 * 2 = 18&quot; ## [1] &quot;9 * 3 = 27&quot; ## [1] &quot;9 * 4 = 36&quot; ## [1] &quot;9 * 5 = 45&quot; ## [1] &quot;9 * 6 = 54&quot; ## [1] &quot;9 * 7 = 63&quot; ## [1] &quot;9 * 8 = 72&quot; ## [1] &quot;9 * 9 = 81&quot; ## [1] &quot;8 * 1 = 8&quot; ## [1] &quot;8 * 2 = 16&quot; ## [1] &quot;8 * 3 = 24&quot; ## [1] &quot;8 * 4 = 32&quot; ## [1] &quot;8 * 5 = 40&quot; ## [1] &quot;8 * 6 = 48&quot; ## [1] &quot;8 * 7 = 56&quot; ## [1] &quot;8 * 8 = 64&quot; ## [1] &quot;8 * 9 = 72&quot; ## [1] &quot;7 * 1 = 7&quot; ## [1] &quot;7 * 2 = 14&quot; ## [1] &quot;7 * 3 = 21&quot; ## [1] &quot;7 * 4 = 28&quot; ## [1] &quot;7 * 5 = 35&quot; ## [1] &quot;7 * 6 = 42&quot; ## [1] &quot;7 * 7 = 49&quot; ## [1] &quot;7 * 8 = 56&quot; ## [1] &quot;7 * 9 = 63&quot; ## [1] &quot;6 * 1 = 6&quot; ## [1] &quot;6 * 2 = 12&quot; ## [1] &quot;6 * 3 = 18&quot; ## [1] &quot;6 * 4 = 24&quot; ## [1] &quot;6 * 5 = 30&quot; ## [1] &quot;6 * 6 = 36&quot; ## [1] &quot;6 * 7 = 42&quot; ## [1] &quot;6 * 8 = 48&quot; ## [1] &quot;6 * 9 = 54&quot; ## [1] &quot;5 * 1 = 5&quot; ## [1] &quot;5 * 2 = 10&quot; ## [1] &quot;5 * 3 = 15&quot; ## [1] &quot;5 * 4 = 20&quot; ## [1] &quot;5 * 5 = 25&quot; ## [1] &quot;5 * 6 = 30&quot; ## [1] &quot;5 * 7 = 35&quot; ## [1] &quot;5 * 8 = 40&quot; ## [1] &quot;5 * 9 = 45&quot; ## [1] &quot;4 * 1 = 4&quot; ## [1] &quot;4 * 2 = 8&quot; ## [1] &quot;4 * 3 = 12&quot; ## [1] &quot;4 * 4 = 16&quot; ## [1] &quot;4 * 5 = 20&quot; ## [1] &quot;4 * 6 = 24&quot; ## [1] &quot;4 * 7 = 28&quot; ## [1] &quot;4 * 8 = 32&quot; ## [1] &quot;4 * 9 = 36&quot; ## [1] &quot;3 * 1 = 3&quot; ## [1] &quot;3 * 2 = 6&quot; ## [1] &quot;3 * 3 = 9&quot; ## [1] &quot;3 * 4 = 12&quot; ## [1] &quot;3 * 5 = 15&quot; ## [1] &quot;3 * 6 = 18&quot; ## [1] &quot;3 * 7 = 21&quot; ## [1] &quot;3 * 8 = 24&quot; ## [1] &quot;3 * 9 = 27&quot; ## [1] &quot;2 * 1 = 2&quot; ## [1] &quot;2 * 2 = 4&quot; ## [1] &quot;2 * 3 = 6&quot; ## [1] &quot;2 * 4 = 8&quot; ## [1] &quot;2 * 5 = 10&quot; ## [1] &quot;2 * 6 = 12&quot; ## [1] &quot;2 * 7 = 14&quot; ## [1] &quot;2 * 8 = 16&quot; ## [1] &quot;2 * 9 = 18&quot; ## [1] &quot;1 * 1 = 1&quot; ## [1] &quot;1 * 2 = 2&quot; ## [1] &quot;1 * 3 = 3&quot; ## [1] &quot;1 * 4 = 4&quot; ## [1] &quot;1 * 5 = 5&quot; ## [1] &quot;1 * 6 = 6&quot; ## [1] &quot;1 * 7 = 7&quot; ## [1] &quot;1 * 8 = 8&quot; ## [1] &quot;1 * 9 = 9&quot; 九九を覚えるときにはこれで良いが、実数どうしの掛け算で i * jとj * i は同じ（交換法則が成り立つ）なので、2つの数字の積を知りたいだけなら片方だけ出力すれば十分だろう。そこで、for (j in 1:9) を for (j in i:9) に変えてみよう。 for (i in 1:9) { for (j in i:9) { print(paste(i, &quot;*&quot;, j, &quot;=&quot;, i * j)) } } ## [1] &quot;1 * 1 = 1&quot; ## [1] &quot;1 * 2 = 2&quot; ## [1] &quot;1 * 3 = 3&quot; ## [1] &quot;1 * 4 = 4&quot; ## [1] &quot;1 * 5 = 5&quot; ## [1] &quot;1 * 6 = 6&quot; ## [1] &quot;1 * 7 = 7&quot; ## [1] &quot;1 * 8 = 8&quot; ## [1] &quot;1 * 9 = 9&quot; ## [1] &quot;2 * 2 = 4&quot; ## [1] &quot;2 * 3 = 6&quot; ## [1] &quot;2 * 4 = 8&quot; ## [1] &quot;2 * 5 = 10&quot; ## [1] &quot;2 * 6 = 12&quot; ## [1] &quot;2 * 7 = 14&quot; ## [1] &quot;2 * 8 = 16&quot; ## [1] &quot;2 * 9 = 18&quot; ## [1] &quot;3 * 3 = 9&quot; ## [1] &quot;3 * 4 = 12&quot; ## [1] &quot;3 * 5 = 15&quot; ## [1] &quot;3 * 6 = 18&quot; ## [1] &quot;3 * 7 = 21&quot; ## [1] &quot;3 * 8 = 24&quot; ## [1] &quot;3 * 9 = 27&quot; ## [1] &quot;4 * 4 = 16&quot; ## [1] &quot;4 * 5 = 20&quot; ## [1] &quot;4 * 6 = 24&quot; ## [1] &quot;4 * 7 = 28&quot; ## [1] &quot;4 * 8 = 32&quot; ## [1] &quot;4 * 9 = 36&quot; ## [1] &quot;5 * 5 = 25&quot; ## [1] &quot;5 * 6 = 30&quot; ## [1] &quot;5 * 7 = 35&quot; ## [1] &quot;5 * 8 = 40&quot; ## [1] &quot;5 * 9 = 45&quot; ## [1] &quot;6 * 6 = 36&quot; ## [1] &quot;6 * 7 = 42&quot; ## [1] &quot;6 * 8 = 48&quot; ## [1] &quot;6 * 9 = 54&quot; ## [1] &quot;7 * 7 = 49&quot; ## [1] &quot;7 * 8 = 56&quot; ## [1] &quot;7 * 9 = 63&quot; ## [1] &quot;8 * 8 = 64&quot; ## [1] &quot;8 * 9 = 72&quot; ## [1] &quot;9 * 9 = 81&quot; このコードは、1の段は1 * 1から1 * 9 までのすべてを計算するが、2の段は2 * 2から、3の段は3 * 3から計算を始めて出力するコードである。2の段の場合、2 * 1は1の段で 1 * 2 が計算済みなのでスキップする。3の段の場合、3 * 1 は1の段で、3 * 2 は2の段でそれぞれ計算済みなのでとばす。 それぞれの段で同様の処理を続け、最後の9の段では9 * 9 のみが計算される。 このように多重forループは複数のベクトルの組み合わせて処理を行う場合に便利である。 複数のベクトルでなく、データフレームなどの2次元以上データにも多重forループは使われる。データフレームは複数のベクトルで構成されている（各列が1つのベクトル）ため、実質的には複数のベクトルを扱うことになる。 例として、FIFA_Men.csv を利用し、それぞれの国のチーム名、FAFAランキング、ポイントをまとめて表示するコードを書いてみよう。すべてのチームを表示すると結果が長くなるので、対象をOFC (オセアニアサッカー連盟) 所属チームに限定する。 # FIFA_Men.csvを読み込み、myDFという名で保存 my_df &lt;- read_csv(&quot;Data/FIFA_Men.csv&quot;) # my_dfのConfederation列がOFCの行だけを抽出 my_df &lt;- my_df[my_df$Confederation == &quot;OFC&quot;, ] my_df ## # A tibble: 10 × 6 ## ID Team Rank Points Prev_Points Confederation ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 4 American Samoa 192 900 900 OFC ## 2 69 Fiji 163 996 996 OFC ## 3 135 New Caledonia 156 1035 1035 OFC ## 4 136 New Zealand 122 1149 1149 OFC ## 5 147 Papua New Guinea 165 991 991 OFC ## 6 159 Samoa 194 894 894 OFC ## 7 171 Solomon Islands 141 1073 1073 OFC ## 8 185 Tahiti 161 1014 1014 OFC ## 9 191 Tonga 203 862 862 OFC ## 10 204 Vanuatu 163 996 996 OFC OFCに10チーム加盟していることがわかる。 以下のような内容が表示されるコードを書きたい。 =====1番目のチーム情報===== Team: American Samoa Rank: 192 Points: 900 =====2番目のチーム情報===== Team: Fiji Rank: 163 Points: 996 =====3番目のチーム情報===== Team: New Caledonia ... これは1つのforループでも作成できるが、勉強のために2つのforループを使って書いてみよう。 for (i in 1:nrow(my_df)) { print(paste0(&quot;=====&quot;, i, &quot;番目のチーム情報=====&quot;)) for (j in c(&quot;Team&quot;, &quot;Rank&quot;, &quot;Points&quot;)) { print(paste0(j, &quot;: &quot;, my_df[i, j])) } } 以上のコードを実行すると以下のような結果が表示される（全部掲載すると長くなるので、ここでは最初の2チームのみ掲載する。 ## [1] &quot;=====1番目のチーム情報=====&quot; ## [1] &quot;Team: American Samoa&quot; ## [1] &quot;Rank: 192&quot; ## [1] &quot;Points: 900&quot; ## [1] &quot;=====2番目のチーム情報=====&quot; ## [1] &quot;Team: Fiji&quot; ## [1] &quot;Rank: 163&quot; ## [1] &quot;Points: 996&quot; このコードについて説明しよう。まず、外側のforループでは任意の変数としてインデクスiを、内側のforループではインデクスjを使っている。Rは、コードを上から順番に処理する（同じ行なら、カッコの中から処理する）。したがって、まず処理されるのは外側のforループである。iにはベクトル1:nrow(my_df)の要素が順番に割り当てられる。nrow() は行列またはデータフレームの行数を求める関数で、my_dfは10行のデータなので1:10になる。つまり、外側のforループはiに1, 2, 3, …, 10の順で値を格納しながらループ内の処理を繰り返す。ここで、外側のforループの中身を見てみよう。まず、print() を使って \"=====i番目のチーム情報=====\" というメッセージを出力している。最初はiが1なので、\"=====1番目のチーム情報=====\"が表示される。 次に実行されるのが内側のforループである。ここではjにc(\"Team\", \"Rank\", \"Points\")を格納しながら内側のforループの内のコードをが3回繰り返し処理される。内側のコードの内容は、たとえば、i = 1の状態で、j = \"Team\"なら、print(paste0(\"Team\", \": \", my_df[1, \"Team\"]))である。第9.4章で説明した通り、my_df[1, \"Team\"]はmy_dfのTeam 列の1番目の要素を意味する。この処理が終わると、次はjに\"Rank\"が代入され、同じコードを処理する。そして、j = \"Points\"まで処理が終わったら、内側のforループは一度終了する。 内側のforループが終わっても、外側のforループはまだ終わっていない。次は、i に 2 が格納され、\"=====2番目のチーム情報=====\" を表示し、再度内側のforループを最初から処理する。 i = 10の状態で内側のforループが終了ると外側のforループも終了する。多重forループはこのように反復処理を実行する。 チーム名の次に所属連盟も表示したいときはどう直せば良いだろうか。正解はc(\"Team\", \"Rank\", \"Points\")のベクトルで、\"Team\"と\"Rank\"の間に\"Confederation\"を追加するだけである。実際にやってみよう (スペースの関係上、最初の2チームの結果のみ掲載する)。 for (i in 1:nrow(my_df)) { print(paste0(&quot;=====&quot;, i, &quot;番目のチーム情報=====&quot;)) for (j in c(&quot;Team&quot;, &quot;Confederation&quot;, &quot;Rank&quot;, &quot;Points&quot;)) { print(paste0(j, &quot;: &quot;, my_df[i, j])) } } ## [1] &quot;=====1番目のチーム情報=====&quot; ## [1] &quot;Team: American Samoa&quot; ## [1] &quot;Confederation: OFC&quot; ## [1] &quot;Rank: 192&quot; ## [1] &quot;Points: 900&quot; ## [1] &quot;=====2番目のチーム情報=====&quot; ## [1] &quot;Team: Fiji&quot; ## [1] &quot;Confederation: OFC&quot; ## [1] &quot;Rank: 163&quot; ## [1] &quot;Points: 996&quot; ちなみに、1つのforループで同じ結果を実現するには次のようにする。結果は掲載しないが、自分で試してみてほしい。また、cat()関数の使い方については?catを参照されたい。ちなみに\\nは改行コードである。 for (i in 1:nrow(my_df)) { cat(paste0(&quot;=====&quot;, i, &quot;番目のチーム情報=====\\n&quot;)) cat(paste0(&quot;Team:&quot;, my_df$Team[i], &quot;\\n&quot;, &quot;Rank:&quot;, my_df$Rank[i], &quot;\\n&quot;, &quot;Points:&quot;, my_df$Points[i], &quot;\\n&quot;)) } リスト型を対象とした多重forループの例も確認しておこう。複数のベクトルを含むリストの場合、3番目のベクトルの5番目の要素を抽出するには、リスト名[[3]][5] のように2つの位置を指定する必要がある。たとえば、3人で構成されたグループが3つあり、それぞれのグループにおける id （例：学籍番号）の順番で名前が格納されている my_listを考えてみよう。 my_list &lt;- list(A = c(&quot;Song&quot;, &quot;Wickham&quot;, &quot;Yanai&quot;), B = c(&quot;Watanabe&quot;, &quot;Toyoshima&quot;, &quot;Fujii&quot;), C = c(&quot;Abe&quot;, &quot;Moon&quot;, &quot;Xi&quot;)) ここで、まず各クラスの出席番号1番の人の名字をすべて出力し、次は2番の人、最後に3番の人を表示するにはどうすれば良いだろうか。以下のコードを見てみよう。 for (i in 1:3) { for (j in names(my_list)) { print(my_list[[j]][i]) } print(paste0(&quot;===ここまでが出席番号&quot;, i, &quot;番の人です===&quot;)) } ## [1] &quot;Song&quot; ## [1] &quot;Watanabe&quot; ## [1] &quot;Abe&quot; ## [1] &quot;===ここまでが出席番号1番の人です===&quot; ## [1] &quot;Wickham&quot; ## [1] &quot;Toyoshima&quot; ## [1] &quot;Moon&quot; ## [1] &quot;===ここまでが出席番号2番の人です===&quot; ## [1] &quot;Yanai&quot; ## [1] &quot;Fujii&quot; ## [1] &quot;Xi&quot; ## [1] &quot;===ここまでが出席番号3番の人です===&quot; このコードは以下のように動く。 1行目: 任意の変数をiとし、1から3までの数字をiに格納しながら、3回反復作業を行う。 3行目: 任意の変数をjとし、ここにはリストの要素名（A, B, C）を格納しながら、リストの長さだけ処理を繰り返す。names(my_list)はc(\"A\", \"B\", \"C\")である。 4行目: my_list[[j]][i]の内容を出力する。最初はi = 1、j = \"A\"なので、print(my_list[[\"A\"]][1])、つまり、my_listから\"A\"を取り出し、そこの1番目の要素を出力する 7行目: 各ベクトルからi番目の要素を出力し、print(paste0(\"===ここまでが出席番号\", i, \"番の人です===\"))を実行する。iに次の要素を入れ、作業を反復する。iに格納する要素がなくなったら、反復を終了する。 多重forループは3重、4重にすることも可能だが、コードの可読性が低下するため、多くても3重、できれば最大二重までにしておいたほうがよい。3重以上にforループを重ねる場合は、内側のforループを後ほど解説する関数でまとめたほうがいいだろう。 上の例では、リストの各要素に名前 (A, B, C) が付けられていることを利用した。リストに名前がない場合はどうすれば良いだろうか（そもそも、名前のないリストなど作らないほうが良いのだが…）。例えば、次のような場合である。 my_list &lt;- list(c(&quot;Song&quot;, &quot;Wickham&quot;, &quot;Yanai&quot;), c(&quot;Watanabe&quot;, &quot;Toyoshima&quot;, &quot;Fujii&quot;), c(&quot;Abe&quot;, &quot;Moon&quot;, &quot;Xi&quot;)) この場合には、次のようにすればよい。 for (i in 1:3) { for (j in seq_along(my_list)) { print(my_list[[j]][i]) } print(paste0(&quot;===ここまでが出席番号&quot;, i, &quot;番の人です===&quot;)) } ## [1] &quot;Song&quot; ## [1] &quot;Watanabe&quot; ## [1] &quot;Abe&quot; ## [1] &quot;===ここまでが出席番号1番の人です===&quot; ## [1] &quot;Wickham&quot; ## [1] &quot;Toyoshima&quot; ## [1] &quot;Moon&quot; ## [1] &quot;===ここまでが出席番号2番の人です===&quot; ## [1] &quot;Yanai&quot; ## [1] &quot;Fujii&quot; ## [1] &quot;Xi&quot; ## [1] &quot;===ここまでが出席番号3番の人です===&quot; 内側のforループでリストの要素名を使う代わりに、リストの要素を位置で指定している。 10.3.2 whileによる反復 forによるループは任意の変数にベクトルの要素を1つずつ代入し、ベクトルの要素を使い尽くすまで反復処理を行う。したがって、ベクトルの長さによってループの回数が決まる。 それに対し、「ある条件が満たされる限り、反復し続ける」あるいは「ある条件が満たされるまで、反復し続ける」ことも可能である。そのときに使うのが、whileによる whileループである。whileループの書き方はforループにとてもよく似ている。 基本的な使い方は、以下のとおりである。 while (条件) { 条件が満たされた場合の処理内容 } forがwhileに変わり、()内の書き方が(任意の変数 in ベクトル)から(条件)に変わった。この()内の条件が満たされる間は{}内の内容を処理が繰り返し実行される。1から5までの整数を表示するコードは、forループを使うと次のように書ける。 for (i in 1:5) { print(i) } これをwhileループを使って書き直すと、次のようになる。 i &lt;- 1 while (i &lt; 6) { print(i) i &lt;- i + 1 } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 whileループを繰り返す条件はi &lt; 6である。これにより、「iが6未満」なら処理が繰り返される。注意すべき点として、i が6未満か否かの判断をループの開始時点で行うので、あらかじめ変数 i を用意する必要があることがあげられる。1行めにある i &lt;- 1 がそれである。そして、{}内の最終行に i &lt;- i + 1 があり、iを1ずつ増やしている。i = 5 の時点では print(i) が実行されるが、i = 6になると、ループをもう1ど実行する条件が満たされないので、反復が停止する。 i &lt;- i + 1のように内容を少しずつ書き換えるさいは、そのコードを置く位置にも注意が必要だ。先ほどのコードのうち、i &lt;- i + 1 を print(i)の前に移動してみよう。 i &lt;- 1 while (i &lt; 6) { i &lt;- i + 1 print(i) } ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 ## [1] 6 2から6までの整数が出力された。これはiを出力する前にiに1が足されるためである。i &lt;- i + 1の位置をこのままにして、先ほどと同じように1から5までの整数を表示するには、次のようにコードを書き換える。 i &lt;- 0 while (i &lt; 5) { i &lt;- i + 1 print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 変更点したのは、 1.iの初期値を0にした 2. ()内の条件を(i &lt; 6)から(i &lt; 5)にした という2点である。 whileループは慣れないとややこしいと感じるだろう。forループで代替できるケースも多い。それでもwhile文が必要になるケースもある。それは先述した通り、「目標は決まっているが、その目標が達成されるまでは処理を何回繰り返せばいいか分からない」場合である。 たとえば、6面のサイコロ投げを考えよう。投げる度に出た目を記録し、その和が30以上に達したときサイコロ投げを中止するにはどうすればいいだろうか。何回サイコロを投げればいいかがあらかじめわからないと、forループは使えない。連続で6が出るなら5回で十分かもしれないが、1が出続けるなら30回投げる必要がある。このように、「反復処理は行うが、何回行えばいいか分からない。ただし、停止条件は知っている」場合にwhileループを使う。 サイコロ投げの例は、以下のコードで実行できる。 total &lt;- 0 trial &lt;- 1 while (total &lt; 30) { die &lt;- sample(1:6, size = 1) total &lt;- total + die print(paste0(trial, &quot;回目のサイコロ投げの結果: &quot;, die, &quot;（これまでの総和: &quot;, total, &quot;）&quot;)) # print()文は以下のような書き方も可能 # Result &lt;- sprintf(&quot;%d回目のサイコロ投げの結果: %d （これまでの総和: %d）&quot;, # trial, die, total) # print(Result) trial &lt;- trial + 1 } ## [1] &quot;1回目のサイコロ投げの結果: 4（これまでの総和: 4）&quot; ## [1] &quot;2回目のサイコロ投げの結果: 2（これまでの総和: 6）&quot; ## [1] &quot;3回目のサイコロ投げの結果: 5（これまでの総和: 11）&quot; ## [1] &quot;4回目のサイコロ投げの結果: 4（これまでの総和: 15）&quot; ## [1] &quot;5回目のサイコロ投げの結果: 2（これまでの総和: 17）&quot; ## [1] &quot;6回目のサイコロ投げの結果: 4（これまでの総和: 21）&quot; ## [1] &quot;7回目のサイコロ投げの結果: 5（これまでの総和: 26）&quot; ## [1] &quot;8回目のサイコロ投げの結果: 4（これまでの総和: 30）&quot; このコードの中身を説明しよう。まず、これまで出た目の和を記録する変数totalを用意し、初期値として0を格納する。また、何回目のサイコロ投げかを記録するためにtrialという変数を用意し、初期値として1を格納する（コードの1、2行目）。 次に、while文を書く。反復する条件はtotalが30未満と設定する。つまり、totalが30以上になったら反復を終了する（コードの4行目）。 続いて、サイコロを投げ、出た目をdieという変数に格納します。サイコロ投げは1から6の間の整数から無作為に1つを値を抽出することでシミュレートできる。そこで使われるのが sample()関数である（コードの5行目）。sample() 関数は与えられたベクトル内の要素を無作為に抽出する。sample(c(1, 2, 3, 4, 5, 6), size = 1)は「c(1, 2, 3, 4, 5, 6)から1つの要素を無作為に抽出せよ」という意味である（乱数生成を利用したシミュレーションについては後の章で詳しく説明する）。サイコロの目が出たら、その目をtotalの値に足す (コードの6行目)。 その後、「1回目のサイコロ投げの結果: 5 (これまでの総和: 5)」のように、1回の処理の結果を表示する。 (コードの8行目)。最後にtrialの値を1増やし (コードの14行目)、1度の処理が終了する。 1度の処理が終わったら、whileループの条件判断に戻り、条件が満たされていれば再び処理を繰り返す。これを条件が満たされなくなるまで繰り返す。 この反復処理は、forループで再現することもできる。次のようにすればよい。 total &lt;- 0 for (trial in 1:30) { die &lt;- sample(1:6, 1) total &lt;- total + die # print()の代わりにsprintf()を使うことも可能 result &lt;- sprintf(&quot;%d回目のサイコロ投げの結果: %d （これまでの総和: %d）&quot;, trial, die, total) print(result) if (total &gt;= 30) break() # ()は省略可能 } ## [1] &quot;1回目のサイコロ投げの結果: 2 （これまでの総和: 2）&quot; ## [1] &quot;2回目のサイコロ投げの結果: 2 （これまでの総和: 4）&quot; ## [1] &quot;3回目のサイコロ投げの結果: 6 （これまでの総和: 10）&quot; ## [1] &quot;4回目のサイコロ投げの結果: 5 （これまでの総和: 15）&quot; ## [1] &quot;5回目のサイコロ投げの結果: 6 （これまでの総和: 21）&quot; ## [1] &quot;6回目のサイコロ投げの結果: 5 （これまでの総和: 26）&quot; ## [1] &quot;7回目のサイコロ投げの結果: 5 （これまでの総和: 31）&quot; このコードの中身を説明しよう。事前にサイコロを投げる回数はわからないが、6面サイコロの場合30回以内には必ず合計が30になるので、trial in 1:30としておく。あとはwhileループの書き方とほぼ同じだが、forループではiが自動的に更新されるのでi &lt;- i + 1は不要である。さらに、一定の条件が満たされるときにループを停止する必要がある。そこで登場するのが条件 if とbreak()である。条件分岐は次節で説明するが、ifから始まる行のコードは、「totalが30以上になったらループから脱出せよ」ということを意味する。このようにループからの脱出を指示する関数が break()だ。break() 関数は()を省略して breakと書いてもよい。 これは余談だが、結果の表示に今回はこれまで使ってきたprint()とpaste0()（またはpaste()）の代わりに、sprintf()を使っている。sprintf() 内の%dはその位置に指定された変数の値を整数として代入することを意味する。sprintf()にの引数にはまず出力する文字列を指定し、次に代入する変数を順番に入力する。%sは文字 (string) 型、%fは実数 (floating-point number) を意味する。%fでは小数の桁数も指定可能であり、小数第2位まで表示させるには %.2f のように表記する。以下のコードは3つの変数の値と文字列を結合する処理をprint(paste0())とsprintf()を用いて書いたもので、同じ結果が得られる。 name &lt;- &quot;Song&quot; bowls &lt;- 50 height &lt;- 176.2 print(paste0(name, &quot;がひと月に食べるラーメンは&quot;, bowls, &quot;杯で、身長は&quot;, height, &quot;cmです。&quot;)) ## [1] &quot;Songがひと月に食べるラーメンは50杯で、身長は176.2cmです。&quot; # %sにnameを、%dにbowlsを、%.1fにheightを小数第1位まで格納し、出力 sprintf(&quot;%sがひと月に食べるラーメンは%d杯で、身長は%.1fcmです。&quot;, name, bowls, height) ## [1] &quot;Songがひと月に食べるラーメンは50杯で、身長は176.2cmです。&quot; ただし、{}内のsprintf()はそのまま出力されないため、一旦、オブジェクトとして保存し、それをprint()を使って出力する必要がある。詳細については、?sprintfを参照されたい。 今回例として挙げたサイコロ投げは「多くても30回以内に終わる」ことが分かっていたの forループで書き換えることができた。しかし、終了までに必要な反復回数は未知であることもある。目的に応じて forとwhileを使い分けることが求められる。 10.4 条件分岐 10.4.1 if、else if、else による条件分岐 この節では条件分岐について説明する。条件分岐は、条件に応じて異なる処理を行いときに利用する。if による条件分岐の基本形は次のとおりである。 if (条件) { 条件が満たされた場合のみ実行される処理の内容 } whileを使ったループによく似ているが、while文は条件が満たされる限り{}の内容を繰り返し実行するのに対し、if 文では条件が満たされれときに{}の内容が1回だけ実行されて処理が終了するという違いがある。たとえば、名前が格納されているオブジェクトnameの中身が\"Song\"なら「ラーメン大好き」と出力されるコードを考えてみよう。 name &lt;- &quot;Song&quot; if (name == &quot;Song&quot;) { print(&quot;ラーメン大好き&quot;) } ## [1] &quot;ラーメン大好き&quot; if文の ()内の条件は、「nameの中身が\"Song\"」の場合のみ{}内の処理を実行せよということを意味する。nameの中身が\"Yanai\"ならどうなるだろうか。 name &lt;- &quot;Yanai&quot; if (name == &quot;Song&quot;) { print(&quot;ラーメン大好き&quot;) } 何も表示されない。このように、if文単体だと、条件が満たされない場合には何も実行されない。 条件にに応じて異なる処理を実行するために、else を使う。これはifとセットで使われるもので、ifの条件が満たされなかった場合の処理内容を指定することができる。elseを加えると、次のようなコードが書ける。 if (条件) { 条件が満たされた場合の処理内容 } else { 条件が満たされなかった場合の処理内容 } else文は、以下のように改行して書くこともできる。 if (条件) { 条件が満たされた場合の処理内容 } else { 条件が満たされなかった場合の処理内容 } しかし、この書き方はあまり良くない。else は必ず if とセットで用いられるので、if の処理の終わりである } の直後に半角スペースを1つ挟んで書くのが標準的なコーディングスタイルである。 それでは nameが\"Song\"でない場合には、「ラーメン好きじゃない」表示されるコードを書いてみよう。 name &lt;- &quot;Song&quot; if (name == &quot;Song&quot;) { print(&quot;ラーメン大好き&quot;) } else { print(&quot;ラーメン好きじゃない&quot;) } ## [1] &quot;ラーメン大好き&quot; nameが\"Song\"の場合、前と変わらず「ラーメン大好き」が出力される。nameを\"Yanai\"に変えてみよう。 name &lt;- &quot;Yanai&quot; if (name == &quot;Song&quot;) { print(&quot;ラーメン大好き&quot;) } else { print(&quot;ラーメン好きじゃない&quot;) } ## [1] &quot;ラーメン好きじゃない&quot; 「ラーメン好きじゃない」が表示される。 しかし、世の中はと「ラーメン大好き」と「ラーメン好きじゃない」のみで構成されているわけではない。「ラーメン大好き」なのはSong と Koike、「ラーメン好きじゃない」のは Yanai のみで、それ以外の人は「ラーメンそこそこ好き」だとしよう。つまり3つのパタンがある。それぞれに別の処理を実行するには、3つ以上の条件に対応できる条件分岐が必要になる。 そのような場合には else ifをifとelseの間に挿入する。 if (条件1) { 条件1が満たされた場合の処理内容 } else if (条件2) { 条件1が満たされず、条件2が満たされた場合の処理内容 } else if (条件3) { 条件1, 2が満たされず、条件3が満たされた場合の処理内容 } else { 条件が全て満たされなかった場合の処理内容 } このように条件分岐を書くと、if文の条件が満たされれば最初の{}内の処理を実行し、満たされなかったら次のelse ifの条件を判定する。その条件が満たされれば{}の処理を実行し、満たされなければ次のelse ifへ移動…を順に実施する。どの条件も満たされないときは、最終的に else の内容が実行される。 それでは実際にコードを書いてみよう。 name &lt;- &quot;Song&quot; if (name == &quot;Song&quot; | name == &quot;Koike&quot;) { # 上の条件は、(name %in% c(&quot;Song&quot;, &quot;Koike&quot;)) でもOK print(&quot;ラーメン大好き&quot;) } else if (name == &quot;Yanai&quot;) { print(&quot;ラーメン好きじゃない&quot;) } else { print(&quot;ラーメンそこそこ好き&quot;) } ## [1] &quot;ラーメン大好き&quot; このコードでは、まずnameが\"Song\" または \"Koike\" か否かを判定し、TRUEなら「ラーメン大好き」を表示する。FALSE なら次の else if文へ移動する。ここではNameが\"Yanai\"かどうかを判定する。 最初の条件に登場する |は「OR （または）」を意味する論理演算子であり、第6章で解説した。このように、条件の中で|や&amp;などの論理演算子を使うことで、複数の条件を指定することができる。また、name == \"Song\" | name == \"Koike\"はname %in% c(\"Song\", \"Koike\")に書き換えることがでる。x %in% yはxがyに含まれているか否かを判定する演算子である。たとえば、\"A\" %in% c(\"A\", \"B\", \"C\")の結果はTRUEだが、\"Z\" %in% c(\"A\", \"B\", \"C\")の結果はFALSEになる。 それではnameを\"Yanai\"、\"Koike\"、\"Shigemura\"、\"Hakiai\"に変えながら結果を確認してみよう。 name &lt;- &quot;Yanai&quot; if (name %in% c(&quot;Song&quot;, &quot;Koike&quot;)) { print(&quot;ラーメン大好き&quot;) } else if (name == &quot;Yanai&quot;) { print(&quot;ラーメン好きじゃない&quot;) } else { print(&quot;ラーメンそこそこ好き&quot;) } ## [1] &quot;ラーメン好きじゃない&quot; name &lt;- &quot;Koike&quot; if (name %in% c(&quot;Song&quot;, &quot;Koike&quot;)) { print(&quot;ラーメン大好き&quot;) } else if (name == &quot;Yanai&quot;) { print(&quot;ラーメン好きじゃない&quot;) } else { print(&quot;ラーメンそこそこ好き&quot;) } ## [1] &quot;ラーメン大好き&quot; name &lt;- &quot;Shigemura&quot; if (name %in% c(&quot;Song&quot;, &quot;Koike&quot;)) { print(&quot;ラーメン大好き&quot;) } else if (name == &quot;Yanai&quot;) { print(&quot;ラーメン好きじゃない&quot;) } else { print(&quot;ラーメンそこそこ好き&quot;) } ## [1] &quot;ラーメンそこそこ好き&quot; name &lt;- &quot;Hakiai&quot; if (name %in% c(&quot;Song&quot;, &quot;Koike&quot;)) { print(&quot;ラーメン大好き&quot;) } else if (name == &quot;Yanai&quot;) { print(&quot;ラーメン好きじゃない&quot;) } else { print(&quot;ラーメンそこそこ好き&quot;) } ## [1] &quot;ラーメンそこそこ好き&quot; if文が単独で使われることもそれほど多くない。if文は主に反復処理を行うforループまたはwhile()ループの中、もしくは次節で説明する自作関数内に使われることが多い。上の例では名前からラーメンに対する情熱を判定するために何度も同じコードを書いてきたが、同じコードを繰り返し書くのは効率が悪い。繰り返し行う作業を関数としてまとめれば便利である。関数の作成については第11章で説明する。 ここではforループと条件分岐の組み合わせについて考えてみよう。学生10人の成績が入っているベクトルscoresがあるとしよう。そして、成績が60点以上なら「合格」を、未満なら「不合格」を返すようなコードを書く。この作業を効率的に行うために、 forループとif文を組み合わせる方法を考える。forループではインデクス変数iに1から10までの数字を代入することを繰り返す。ここでの10はベクトルscoresの長さなので、seq_along() を使う。そして、scoresのi番目要素に対して60点以上か否かの判定を行い、「合格」または「不合格」という結果を返す。 以上の内容を実行するコードは、次のように書ける。 scores &lt;- c(58, 100, 81, 97, 71, 61, 47, 60, 73, 85) for (i in seq_along(scores)) { if (scores[i] &gt;= 60) { print(paste0(&quot;学生&quot;, i, &quot;の判定結果: 合格&quot;)) } else { print(paste0(&quot;学生&quot;, i, &quot;の判定結果: 不合格&quot;)) } } ## [1] &quot;学生1の判定結果: 不合格&quot; ## [1] &quot;学生2の判定結果: 合格&quot; ## [1] &quot;学生3の判定結果: 合格&quot; ## [1] &quot;学生4の判定結果: 合格&quot; ## [1] &quot;学生5の判定結果: 合格&quot; ## [1] &quot;学生6の判定結果: 合格&quot; ## [1] &quot;学生7の判定結果: 不合格&quot; ## [1] &quot;学生8の判定結果: 合格&quot; ## [1] &quot;学生9の判定結果: 合格&quot; ## [1] &quot;学生10の判定結果: 合格&quot; このコードは、以下の処理を行っている。 1行目: まず、ベクトルscoresを定義する。 3行目: for文でループを作る。任意の変数としてインデクスiを使う。ベクトルの各要素をのインデクスを入れ替えながら反復を行います。したがって、i in 1:10でも問題ないが、ここではi in seq_along(scores)を利用する。こうすることで、scoresベクトルの長さが変わっても、forの内容を修正する必要がなくなる。 4, 5行目: scoresのi番目要素が60点以上かどうかを判定し、TRUEなら「学生iの判定結果: 合格」を表示する。 6-8行目: scores のi番目要素が60点以上でない場合、「学生iの判定結果: 不合格」を表示する。 print()内でpaste0()を使うとコードの可読性がやや落ちるので、sprintf()を使ってもよいかもしれない（後で説明するパイプ演算子 %&gt;% を使えば、可読性の問題は解決する）。 scores &lt;- c(58, 100, 81, 97, 71, 61, 47, 60, 73, 85) for (i in seq_along(scores)) { if (scores[i] &gt;= 60) { result &lt;- sprintf(&quot;学生%dの判定結果: 合格&quot;, i) } else { result &lt;- sprintf(&quot;学生%dの判定結果: 不合格&quot;, i) } print(result) } ## [1] &quot;学生1の判定結果: 不合格&quot; ## [1] &quot;学生2の判定結果: 合格&quot; ## [1] &quot;学生3の判定結果: 合格&quot; ## [1] &quot;学生4の判定結果: 合格&quot; ## [1] &quot;学生5の判定結果: 合格&quot; ## [1] &quot;学生6の判定結果: 合格&quot; ## [1] &quot;学生7の判定結果: 不合格&quot; ## [1] &quot;学生8の判定結果: 合格&quot; ## [1] &quot;学生9の判定結果: 合格&quot; ## [1] &quot;学生10の判定結果: 合格&quot; 次に、結果を出力するのではなく、結果を別のベクトルに格納する例を考えてみよう。あらかじめ scores と同じ長さの空ベクトルpfを用意します。ここに各学生について合否判定の結果を「合格」または「不合格」として格納する処理を行う。以下のようなコードが書ける。 scores &lt;- c(58, 100, 81, 97, 71, 61, 47, 60, 73, 85) pf &lt;- rep(NA, length(scores)) for (i in seq_along(scores)) { if (scores[i] &gt;= 60) { pf[i] &lt;- &quot;合格&quot; } else { pf[i] &lt;- &quot;不合格&quot; } } このコードでは、scores を定義した後、中身がNAのみで構成される長さがscores と同じベクトルpfを定義する。rep(NA, length(scores))はNAをlength(Scores)個（ここでは10個）並べたベクトルを生成する。 続いて、点数によって条件分岐を行い、メッセージを出力するのではなく、pfのi番目に\"合格\"か\"不合格\"を入れる。結果を確認してみよう。 pf ## [1] &quot;不合格&quot; &quot;合格&quot; &quot;合格&quot; &quot;合格&quot; &quot;合格&quot; &quot;合格&quot; &quot;不合格&quot; &quot;合格&quot; ## [9] &quot;合格&quot; &quot;合格&quot; このように、if文は反復処理を行うforループまたはwhileループと組み合わせることでその本領を発揮する。実は、今回の例については次に説明するifelse()を使えば1行で処理することができる。しかし、複雑な処理を伴う反復と条件分岐を組み合わせるには、今回のようにforループとif文を組み合わせるのが有効である。 10.4.2 ifelse()による条件分岐 ifelse()は与えられたベクトル内の各要素に対して条件分岐を行い、それをベクトルの全要素について繰り返す関数である。簡単な条件分岐と反復処理を同時に行う非常に便利な関数である。ifelse()の基本的な書き方は以下のとおり。 ifelse(条件, 条件がTRUEの場合の処理、条件がFALSEの場合の処理) たとえば、学生10人の成績が入っているベクトルscoresに対し、60点以上の場合に合格 (\"Pass\")、60点未満の場合に不合格 (\"Fail\") の値を割り当て、pfというベクトルに格納しよう。 scores &lt;- c(58, 100, 81, 97, 71, 61, 47, 60, 73, 85) pf &lt;- ifelse(scores &gt;= 60, &quot;Pass&quot;, &quot;Fail&quot;) pf ## [1] &quot;Fail&quot; &quot;Pass&quot; &quot;Pass&quot; &quot;Pass&quot; &quot;Pass&quot; &quot;Pass&quot; &quot;Fail&quot; &quot;Pass&quot; &quot;Pass&quot; &quot;Pass&quot; 条件はscoresの値が60以上か否かであり、60以上なら\"Pass\"を、それ以外なら\"Fail\"を返す。 返す値として新しい値を与える代わりに、一定の条件が満たされたら現状の値を保持し、それ以外なら指定した値に変更して返すこともできる。たとえば、世論調査では以下のように「答えたくない」または「わからない」を9や99などで記録することが多い。この値はこのままでは分析するのが難しいので、欠損値として扱いたいことがある。例として、次の質問を考えよう。 Q. あなたはラーメンが好きですか。 1.大好き 2.そこそこ好き 3.好きではない 9.答えたくない この質問に対する10人の回答が格納されたデータフレーム (Ramen) があるとしよう。このデータフレームには2つの列があり、id 列は回答者のID（識別番号）、ramen 列にはは上の質問に対する答えが入ってる。 Ramen &lt;- data.frame( id = 1:10, ramen = c(1, 1, 2, 1, 3, 1, 9, 2, 1, 9) ) Ramen ## id ramen ## 1 1 1 ## 2 2 1 ## 3 3 2 ## 4 4 1 ## 5 5 3 ## 6 6 1 ## 7 7 9 ## 8 8 2 ## 9 9 1 ## 10 10 9 このramen列に対し、ramen == 9ならNAを割り当て、それ以外の場合は元の値をそのまま残したいとしよう。そしてその結果をRamenのramen列に上書する。これは次のコードで実行できる。 Ramen$ramen &lt;- ifelse(Ramen$ramen == 9, NA, Ramen$ramen) Ramen ## id ramen ## 1 1 1 ## 2 2 1 ## 3 3 2 ## 4 4 1 ## 5 5 3 ## 6 6 1 ## 7 7 NA ## 8 8 2 ## 9 9 1 ## 10 10 NA 3つ以上のパタンに分岐させたいときは、ifelse()の中でifelse()を使うこともできる。scoresベクトルの例を考えてよう。ここで90点以上ならS、80点以上ならA、70点以上ならB、60点以上ならCを割り当て、それ以外はFを返すことにしよう。そして、その結果をgrade という変数に格納してみよう。 grade &lt;- ifelse(scores &gt;= 90, &quot;S&quot;, ifelse(scores &gt;= 80, &quot;A&quot;, ifelse(scores &gt;= 70, &quot;B&quot;, ifelse(scores &gt;= 60, &quot;C&quot;, &quot;F&quot;)))) このコードでは、ifelse()の条件がFALSEの場合、次のifelse()での判定を行う。結果を確認しておこう。 grade ## [1] &quot;F&quot; &quot;S&quot; &quot;A&quot; &quot;S&quot; &quot;B&quot; &quot;C&quot; &quot;F&quot; &quot;C&quot; &quot;B&quot; &quot;A&quot; この例からもわかるとおり、ifelse()を使いすぎるとコードの可読性が低くなるので、このようなコードはあまり推奨できない。複数の条件に応じて返す値を変える処理は、{dplyr}パッケージのcase_when()関数で行うのがよいだろう。この関数については、13章で詳細に説明するが、ここでは上のコードと同じ処理を実施する例のみ示す。 grade2 &lt;- dplyr::case_when(scores &gt;= 90 ~ &quot;S&quot;, scores &gt;= 80 ~ &quot;A&quot;, scores &gt;= 70 ~ &quot;B&quot;, scores &gt;= 60 ~ &quot;C&quot;, TRUE ~ &quot;F&quot;) grade2 ## [1] &quot;F&quot; &quot;S&quot; &quot;A&quot; &quot;S&quot; &quot;B&quot; &quot;C&quot; &quot;F&quot; &quot;C&quot; &quot;B&quot; &quot;A&quot; 10.4.3 switch()による条件分岐 switch()は、与えられた長さ1の文字列64を用いた条件分岐を行う。これが単体で使われうことはほとんどなく、通常は関数のなかで使われる。したがって、初めて本書を読む場合はこの節を一旦とばし、第11章を読んだ後に必要に応じて戻ってきてほしい。 ここでは2つの数値xとyの加減乗除を行う関数m_calc という名前の関数を作る。この関数はx とy以外にoperationという引数をもち、このoperationの値によって行う処理が変わる。たとえば、operation = \"+\"なら足し算を、operation = \"*\"なら掛け算を行う。 my_calc &lt;- function(x, y, operation) { switch(operation, &quot;+&quot; = x + y, &quot;-&quot; = x - y, &quot;*&quot; = x * y, &quot;/&quot; = x / y, stop(&quot;operation の値に使えるのは +, -, *, / のみです。&quot;) ) } このコードの中身を確認しよう。重要なのは2行目から8行目の部分である。switch()の最初の引数は条件を判定する長さ1のベクトルである。ここではこれがoperationである。そして、operationに指定される実引数の値によって異なる処理を行う。\"+\" = x + yは「operationの値が\"+\"なら、x + yを実行する」ことを意味する。これを他の演算子に対しても指定する。最後の引数は、どの条件にも合わない場合の処理である。ここでは, operation の値に使えるのは +, -, *, / のみです。\"というエラーメッセージを表示し、関数の実行を停止するために stop() 関数を指定している。 上のコードは、if、else if、 elseを使って書き換えることができる。 my_calc2 &lt;- function(x, y, operation = c(&quot;+&quot;, &quot;-&quot;, &quot;*&quot;, &quot;/&quot;)) { operation &lt;- match.arg(operation) if (operation == &quot;+&quot;) { return(x + y) } else if (operation == &quot;-&quot;) { return(x - y) } else if (operation == &quot;*&quot;) { return(x * y) } else { return(x / y) } } 先ほどと異なる点は、function()の中でoperationのデフォルト値をベクトルとしてした与えたことだ。これは「operation引数の値がこれらの値以外になることは許さない」ということを意味する。match.arg()関数は、operation引数が予め指定された引数の値と一致するか否かを判断する。指定された引数と一致しない場合、エラーを表示し、処理を中断する。ちなみに、match.arg()はswith()文と組み合わせて使うこともできる。 今回の例の場合、switch()を使ったほうがコードの内容がわかりやすく、読みやすいが、ifによる条件分岐でも十分に対応可能である。また、条件によって行う処理が複雑な場合にはswitch()よりもifのほうが使いやすい。 作った関数を使ってみよう。 my_calc(5, 3, operation = &quot;+&quot;) ## [1] 8 my_calc(5, 3, operation = &quot;-&quot;) ## [1] 2 my_calc(5, 3, operation = &quot;*&quot;) ## [1] 15 my_calc(5, 3, operation = &quot;/&quot;) ## [1] 1.666667 では\"+\"、\"-\"、\"*\"、\"/\"以外の値をoperationに与えるとうなるだろうか。ためしに\"^\"を入れてみよう。 my_calc(5, 3, operation = &quot;^&quot;) ## Error in my_calc(5, 3, operation = &quot;^&quot;): operation の値に使えるのは +, -, *, / のみです。 stop()内に書いたエラーメッセージが表示され、処理が中止される。 練習問題 問1 3つの6面サイコロ投げを考える。3つの目の和が15になるまでサイコロ投げを繰り返す。どのような目が出て、その合計はいくつか。そして、何回目のサイコロ投げかを表示するコードを forループを用いて書きなさい whileループを用いて書きなさい 上の2つのコードが同じ結果を表示することを確認したうえで、どちらの方法がより効率的か考察しなさい。 ## [1] &quot;1目のサイコロ投げの結果: 4, 2, 6 (合計: 12)&quot; ## [1] &quot;2目のサイコロ投げの結果: 5, 4, 1 (合計: 10)&quot; ## [1] &quot;3目のサイコロ投げの結果: 5, 6, 4 (合計: 15)&quot; 問2 以下のような長さ5の文字型ベクトルcauseがある。「肥満の原因はXXでしょう。」というメッセージを表示するコードを書きなさい。ただし、「XX」の箇所にはベクトルの各要素を代入すること。表示されるメッセージは5個でなければならない。 cause &lt;- c(&quot;喫煙&quot;, &quot;飲酒&quot;, &quot;食べすぎ&quot;, &quot;寝不足&quot;, &quot;ストレス&quot;) ## [1] &quot;肥満の原因は喫煙でしょう。&quot; ## [1] &quot;肥満の原因は飲酒でしょう。&quot; ## [1] &quot;肥満の原因は食べすぎでしょう。&quot; ## [1] &quot;肥満の原因は寝不足でしょう。&quot; ## [1] &quot;肥満の原因はストレスでしょう。&quot; 長さ4の文字型ベクトルeffectを以下のように定義する。このとき、「YYの原因はXXでしょう。」というメッセージを表示するコードを書きなさい。ただし、「YY」にはeffectの要素を、「XX」にはcauseの要素を代入すること。出力されるメッセージは20個でなければならない。 effect &lt;- c(&quot;肥満&quot;, &quot;腹痛&quot;, &quot;不人気&quot;, &quot;金欠&quot;) 長さ3の文字型ベクトルsolutionを以下のように定義する。このとき、「YYの原因はXXですが、ZZ改善されるでしょう。」というメッセージを出力するコードを書きなさい。ただし、「YY」にはeffectの要素を、「XX」にはcauseの要素を、「ZZ」にはsolutionの要素を代入すること。出力されるメッセージは60個でなければならない。 solution &lt;- c(&quot;この薬を飲めば&quot;, &quot;一日一麺すれば&quot;, &quot;神戸大に登山すれば&quot;) 問3 長さ2のnumericベクトルdataについて考える。条件分岐を用いてdataの1番目の要素 (data[1]) が2番目の要素 (data[2]) より大きい場合、1番目の要素と2番目の順番を逆転させる条件分岐を作成せよ。たとえば、data &lt;- c(5, 3)なら、条件分岐後のdataの値がc(3, 5)になるようにするコードを書きなさい。 参考資料 "],["functions.html", "11. 関数の自作 11.1 関数の作成 11.2 ちょっと複雑な関数 11.3 関数 in 関数 練習問題", " 11. 関数の自作 11.1 関数の作成 これまでclass()や、sum()、print()など、様々な関数 (functions) を使ってきた。「Rで起こるあらゆることは関数の呼び出しである (Everything that happens in R is a function call)」(Chambers (2016, 4)) と言われるように、「Rを使う」ということは、「Rの関数を使う」ということである。 関数は関数名() ように括弧とセットで表記されることが多い。1つの関数でも、括弧の中に異なる引数を指定することで、さまざまな結果を出すことができる。例として、第6章でも説明したseq()関数について考えてみよう。この関数を使うと、一連の数字からなるベクトルを作ることができる。from で数列の初項を、to で数列の最終項を指定し、by で要素間の差（第2要素は第1要素に by を加えた値になる ）を指定するか、length.out で最終的にできるベクトルの要素の数を指定する。 Rを含むプログラミングにおける関数は、何かを入力すると何かを出力する箱のようなものである。関数を使うだけなら、関数という箱の中で何が起こっているかを理解する必要はない。例えば、mean() という関数に実数のベクトルを入力すると、平均値を実数として返すということを知っていれば、mean() が具体的にどのような計算を行っているかを知らなくても、実用上は問題ない。つまり、関数をブラックボックスとして扱うことができる。 このように1つの関数でも指定する内容は、by になったりlength.out になったりする。by や length.out、from、to などのように、関数で指定する対象になっているもののことを 仮引数 (parameter) と呼ぶ。また、by = 1 の1や、length.out = 10 の10のように、仮引数に実際に渡される値のことを実引数 (argument) と呼ぶ。特に誤解が生じないと思われる場合には、仮引数と実引数を区別せずに引数（ひきすう）と呼ぶ。 Rでは、1つの関数で使う引数の数が複数あることが多いので、仮引数を明示する習慣を身につけたほうがよい。 ただし、第1引数（関数で最初に指定する引数）として必ず入力すべきものは決められている場合がほとんどなので、第1引数の仮引数は省略されることが多い。仮引数が省略される代わりに、第1引数の実引数はほぼ必ず入力する（いくつかの例外もある）。 関数とは()内の引数のデータを関数内部の手続きに沿って処理し、その結果を返すものです。あるデータを引数として受け付ける関数であれば、その引数を変えるだけで「先ほどとは異なるデータに対し、同じ処理を行う」ことが可能となり、コーディングの労力が省けます。 ここでは、ベクトルc(1, 2, 3, 4, 5)の総和を計算する方法について考えてみましょう。まず、1つ目は単純に足し算をする方法があります。 1 + 2 + 3 + 4 + 5 ## [1] 15 他にも反復処理を使うことも可能です。とりわけ、1:100のようなベクトルを1つ目の方法で記述するのは時間の無駄でしょう。for()文を使った方法は以下のようになります。 Result &lt;- 0 for (i in 1:5) { Result &lt;- Result + i } Result ## [1] 15 数個の数字を足すだけなら方法1の方が楽でしょうし、数百個の数字の場合は方法2の方が効率的です。それでもやはりsum()関数の方が数倍は効率的です。また、関数を使うことで、スクリプトの量をへらすこともできます。1から100までの総和なら、方法2のfor (i in 1:5)をfor (i in 1:100)に変えることで対応可能ですが、それでも全体としては数行のコードで書かなくてもなりません。一方、sum(1:100)なら一行で済みます。 sum()はまだマシな方です。たとえば、回帰分析をしたい場合、毎回回帰分析のコードを一から書くのはあまりにも非効率的です。lm()関数を使うと、データや回帰式などを指定するだけで、一連の作業を全て自動的に行い、その結果を返してくれます。中には回帰式の係数も計算してくれますが、他にも残差や決定係数なども計算してくれます。その意味で、lm()という関数は複数の機能を一つの関数としてまとめたものでもあります。 これらの関数は既にR開発チームが書いた関数ですが、ユーザー側から関数を作成することも可能です。長いコードを書く、同じ作業を繰り返す場合、関数の作成はほぼ必須とも言えます。ここではまず、簡単な関数を作成してみましょう。与えられた数字を二乗し、その結果を返すmyPower()関数を作ってみましょう。 myPower &lt;- function(x) { x^2 } # 引数が一つしかないので、myPower(24)も可能 myPower(x = 24) ## [1] 576 それではコードを解説します。関数は以下のように定義されます。 関数名 &lt;- function (引数名) { 処理内容 } まず、関数名をmyPowerとし、それが関数であることを宣言します。そして、この関数の引数の名前はxとします。それが myPower &lt;- function (x) の部分です。続いて、{}内に処理内容を書きます。今回はx^2であり、これはxの2乗を意味します。そして、関数の処理結果が返されますが、{}内の最後の行が結果として返されます。x^2の部分はreturn(x^2)と書き換えることも可能です。return()は「この結果を返せよ」という意味の関数ですが、返す結果が最後の行である場合、省略可能であり、Hadely先生もこのような書き方を推奨しています。 それでは、もうちょっと複雑な関数を作成してみましょう。ベクトルを引数とし、その和を計算するmySum()という関数です。要するにsum()関数を再現したものです。 # mySum関数を定義し、引数はxのみとする mySum &lt;- function(x) { # 結果を格納するベクトルResultを生成し、0を入れておく Result &lt;- 0 # xの要素をiに一つずつ入れながら反復処理 for (i in x) { # Resultに既存のResultの値にiを足した結果を上書きする Result &lt;- Result + i } # Resultを返す Result } mySum(1:5) ## [1] 15 普通のsum()関数と同じ動きをする関数が出来上がりました。よく見ると、上で説明した総和を計算する方法2のコードを丸ごと関数内に入っているだけです。変わったところがあるとすれば、for()文であり、for (i in 1:5)がfor (i in x)に変わっただけです。ここのxはmySum &lt;- function (x)のxを意味します。このように関数を一回作成しておくと、これからは総和を出す作業を1行に短縮することができます。 このmySum()ですが、一つ問題があります。それはxに欠損値が含まれている場合、結果がNAになることです。 mySum(c(1, 2, 3, NA, 5)) ## [1] NA 実際、R内蔵関数であるsum()も同じですが、sum()にはna.rm =というもう一つの引数があり、これをTRUEにすることで欠損値を除いた総和が計算できます。つまり、関数は複数の引数を持つことができます。それでは、mySum()を改良してみましょう。ここにもna.rmという関数を追加し、na.rm引数がTRUEの場合、xから欠損値を除いた上で総和を計算するようにしましょう。 mySum &lt;- function(x, na.rm = FALSE) { if (na.rm == TRUE) { x &lt;- x[!is.na(x)] } Result &lt;- 0 for (i in x) { Result &lt;- Result + i } Result } mySum(c(1, 2, 3, NA, 5)) ## [1] NA mySum(c(1, 2, 3, NA, 5), na.rm = FALSE) ## [1] NA mySum(c(1, 2, 3, NA, 5), na.rm = TRUE) ## [1] 11 変わったところは、まずfunction (x)がfunction (x, na.rm = FALSE)になりました。これはxとna.rmの引数が必要であるが、na.rmのデフォルト値はFALSEであることを意味します。デフォルト値が指定されている場合、関数を使用する際、その引数は省略できます。実際、sum()関数のna.rm引数もFALSEがデフォルトとなっており、省略可能となっています。 次は最初に条件分岐が追加されました。ここではna.rmがTRUEの場合、xから欠損値を抜いたベクトルをxに上書きするように指定しました。もし、FALSEならこの処理は行いません。 これでR開発チームが作成したsum()関数と同じものが出来上がりました。それでは引数の順番について簡単に解説し、もうちょっと複雑な関数を作ってみましょう。引数の順番は基本的にfunction()の()内で定義した順番であるなら、引数名を省略することも可能です。 mySum(c(1, 2, 3, NA, 5), TRUE) ## [1] 11 ただし、順番を逆にすると、以下のようにわけのわからない結果が返されます。 mySum(TRUE, c(1, 2, 3, NA, 5)) ## Warning in if (na.rm == TRUE) {: the condition has length &gt; 1 and only the first ## element will be used ## [1] 1 任意の順番で引数を指定する場合、引数名を指定する必要があります。 mySum(na.rm = TRUE, x = c(1, 2, 3, NA, 5)) ## [1] 11 自分で関数を作成し、他の人にも使ってもらう場合、引数名、順番、デフォルト値を適切に設定しておくことも大事です。 11.2 ちょっと複雑な関数 それではちょっとした遊び心を込めた関数を作ってみましょう。その名もドラクエ戦闘シミュレーターです。 以下はドラクエ11のダメージ公式です。 ダメージの基礎値 = (攻撃力 / 2) - (守備力 / 4) 0未満の場合、基礎値は0とする ダメージの幅 = (ダメージの基礎値 / 16) + 1 端数は切り捨てます (floor()関数使用) ダメージの最小値は「ダメージの基礎値 - ダメージの幅」、最大値は「ダメージの基礎値 - ダメージの幅」となります。この最小値が負になることもありますが、その場合は0扱いになります。実際のダメージはこの範囲内でランダムに決まります (runif()関数使用)。 # DQ_Attack関数を定義 DQ_Attack &lt;- function(attack, defence, hp, enemy) { # 引数一覧 # attack: 勇者の力 + 武器の攻撃力 (長さ1の数値型ベクトル) # defence: 敵の守備力 (長さ1の数値型ベクトル) # hp: 敵のHP (長さ1の数値型ベクトル) # enemy: 敵の名前 (長さ1の文字型ベクトル) # ダメージの基礎値 DefaultDamage &lt;- (attack / 2) - (defence / 4) # ダメージの基礎値が負の場合、0とする DefaultDamage &lt;- ifelse(DefaultDamage &lt; 0, 0, DefaultDamage) # ダメージの幅 DamageWidth &lt;- floor(DefaultDamage / 16) + 1 # ダメージの最小値 DamageMin &lt;- DefaultDamage - DamageWidth # ダメージの最小値が負の場合、0とする DamageMin &lt;- ifelse(DamageMin &lt; 0, 0, DamageMin) # ダメージの最大値 DamageMax &lt;- DefaultDamage + DamageWidth # 敵の残りHPを格納する CurrentHP &lt;- hp # 残りHPが0より大きい場合、以下の処理を繰り返す while (CurrentHP &gt; 0) { # ダメージの最小値から最大値の間の数値を1つ無作為に抽出する Damage &lt;- runif(n = 1, min = DamageMin, max = DamageMax) # 小数点1位で丸める Damage &lt;- round(Damage, 0) # 残りのHPを更新する CurrentHP &lt;- CurrentHP - Damage # メッセージを表示 print(paste0(enemy, &quot;に&quot;, Damage, &quot;のダメージ!!&quot;)) } # 上記の反復処理が終わったら勝利メッセージを出力 paste0(enemy, &quot;をやっつけた！&quot;) } 初めて見る関数が3つありますね。まず、floor()関数は引数の端数は切り捨てる関数です。たとえば、floor(2.1)もfloor(2.6)も結果は2です。続いて、runif()関数は指定された範囲の一様分布から乱数を生成する関数です。引数は生成する乱数の個数 (n)、最小値 (min)、最大値 (max)の3つです。runif(5, 3, 10)なら最小値3、最大値10の乱数を5個生成するという意味です。正規分布は平均値周辺の値が生成されやすい一方、一様分布の場合、ある値が抽出される確率は同じです。最後にround()関数は四捨五入の関数です。引数は2つあり、1つ目の引数は数値型のベクトルです。2つ目は丸める小数点です。たとえば、round(3.127, 1)の結果は3.1であり、round(3.127, 2)の結果は3.13となります。 それでは「ひのきのぼう」を装備したレベル1の勇者を考えてみましょう。ドラクエ5の場合、Lv1勇者の力は11、「ひのきのぼう」の攻撃力は2ですので、攻撃力は13です。まずは定番のスライムから狩ってみましょう。スライムのHPと守備力は両方7です。 DQ_Attack(13, defence = 7, hp = 7, &quot;スライム&quot;) ## [1] &quot;スライムに4のダメージ!!&quot; ## [1] &quot;スライムに4のダメージ!!&quot; ## [1] &quot;スライムをやっつけた！&quot; まぁ、こんなもんでしょう。それではスライムナイト (=ピエール)はどうでしょう。スライムナイトのHPのは40、守備力は44です。 DQ_Attack(13, defence = 44, hp = 40, &quot;スライムナイト&quot;) ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトに0のダメージ!!&quot; ## [1] &quot;スライムナイトに1のダメージ!!&quot; ## [1] &quot;スライムナイトをやっつけた！&quot; これだと「なんと スライムナイトが おきあがりなかまに なりたそうに こちらをみている！」のメッセージを見る前に勇者ご一行が全滅しますね。エスターク (HP: 9000 / 守備力: 250)は計算するまでもないでしょう… 以上の関数に条件分岐を追加することで「かいしんの いちげき！」を入れることもできますし65、逆に敵からの攻撃を計算して誰が先に倒れるかをシミュレーションすることも可能でしょうね。色々遊んでみましょう。 11.3 関数 in 関数 当たり前かも知れまっせんが、自作関数を他の自作関数に含めることもできます。ここでは乱数を生成する関数を作ってみましょう。パソコンだけだと完全な乱数を作成することは不可能ですが66、乱数に近いものは作れます。このようにソフトウェアで生成された乱数は擬似乱数と呼ばれ、様々なアルゴリズムが提案されています。天才、フォン・ノイマン大先生も乱数生成では天才ではなかったらしく、彼が提案した平方採中法 (middle-square method)は使い物になりませんので、ここではもうちょっとマシな方法である線形合同法 (linear congruential generators; 以下、LCG)を採用します。平方採中法よりは式が複雑ですが、それでも非常に簡単な式で乱数が生成可能であり、Rによる実装に関しては平方採中法より簡単です。ちなみに、線形合同法にも様々な問題があり、Rのデフォルトは広島大学の松本眞先生と山形大学の西村拓士先生が開発しましたメルセンヌ・ツイスタ (Mersenne twister)を採用しています。それでは、LCGのアルゴリズムから見ましょう。 乱数の列があるとし、\\(n\\)番目の乱数を\\(X_n\\)とします。この場合、\\(X_{n+1}\\)は以下のように生成されます。 \\[ X_{n+1} = (aX_n + c) \\text{ mod } m \\] \\(\\text{mod}\\)は余りを意味し、\\(5 \\text{mod} 3\\)は5を3で割った際の余りですので、2となります。\\(a\\)と\\(c\\)、\\(m\\)は以下の条件を満たす任意の数です。 \\[\\begin{align} 0 &lt; &amp; m, \\\\ 0 &lt; &amp; a &lt; m, \\\\ 0 \\leq &amp; c &lt; m. \\end{align}\\] ベストな\\(a\\)、\\(c\\)、\\(m\\)も決め方はありませんが、ここではTurbo Cの設定を真似て\\(a = 22695477\\)、\\(c = 1\\)、\\(m = 2^{32}\\)をデフォルト値として設定します67。そして、もう一つ重要なのが最初の数、つまり\\(X_n\\)をどう決めるかですが、これは自由に決めて問題ありません。最初の数 (\\(X_0\\))はシード (seed)と呼ばれ、最終的には使わない数字となります。それではseedという引数からある乱数を生成する関数rng_number()を作ってみましょう。 rng_number &lt;- function(seed, a = 22695477, c = 1, m = 2^32) { (a * seed + c) %% m } 簡単な四則演算のみで構成された関数ですね。ちなみに%%は余りを計算する演算子です。とりあえず、seedを12345に設定し、一つの乱数を生成してみましょう。 rng_number(12345) ## [1] 1002789326 かなり大きい数字が出ました。ちなみに線形合同法で得られる乱数の最大値は\\(m\\)、最小値は0です。次は、今回得られた乱数1.0027893^{9}を新しいseedとし、新しい乱数を作ってみましょう。 rng_number(1002789326) ## [1] 3785644968 この作業を繰り返すと、(疑似)乱数の数列が得られます。続いて、この作業をn回繰り返し、長さnの乱数ベクトルを返す関数LCGを作ってみましょう。いかがコードになります。 LCG &lt;- function(n, seed, a = 22695477, c = 1, m = 2^32) { rng_vec &lt;- rep(NA, n + 1) # seedも入るので長さn+1の空ベクトルを生成 rng_vec[1] &lt;- seed # 1番目の要素にseedを入れる # iに2からn+1までの値を順次的に投入しながら、反復処理 for (i in 2:(n+1)) { # rng_vecのi番目にi-1番目の要素をseedにした疑似乱数を格納 rng_vec[i] &lt;- rng_number(rng_vec[i - 1], a, c, m) } rng_vec &lt;- rng_vec[-1] # 1番目の要素 (seed)を捨てる rng_vec &lt;- rng_vec / m # 最小値0、最大値1になるように、mで割る rng_vec # 結果を返す } それでは、詳細に解説します。 1行目: 関数LCGを定義し、必要な引数としてnとseedを設定する。 2行目: 結果を格納する空ベクトルrng_vecを生成。ただし、1番目にはseedが入るので、長さをn+1とする。 3行目: rng_vecの1番目にseedを格納する。 6行目: 疑似乱数をn回生成し、格納するように反復作業を行う。任意の変数はiとし、iに代入される値は2からn+1までである。 8行目: rng_vecのi-1番目要素をseedにした疑似乱数を生成し、rng_vecのi番目に格納する。1回目の処理だとi=2であるため、rng_vec[1] (= seed)をseedにした疑似乱数が生成され、rng_vec[2]に格納される。 11行目: rng_vecの1番目の要素はseedであるため、捨てる。 12行目: 乱数が最小値0、最大値1になるように、調整する。具体的には得られた乱数をm (デフォルトは\\(2^{32}\\))で割るだけである。 14行目: 結果ベクトルを返す。 それでは、seedを19861008とした疑似乱数10000個を生成し、LCG_Numbersという名のベクトルに格納してみましょう。結果を全て表示させるのは無理があるので、最初の20個のみを確認してみます。 LCG_Numbers &lt;- LCG(10000, 19861008) head(LCG_Numbers, 20) ## [1] 0.58848246 0.09900449 0.21707060 0.89462981 0.23421890 0.72341249 ## [7] 0.55965400 0.59552685 0.96594972 0.69050965 0.98383344 0.20136551 ## [13] 0.25856502 0.37569497 0.50086451 0.03986446 0.89291806 0.24760102 ## [19] 0.27912510 0.24493750 正直、これが乱数かどうかは見るだけでは分かりませんね。簡単な確認方法としては、これらの乱数列のヒストグラムを見れば分かります。得られた数列が本当に乱数(に近いもの)なら、その分布は一様分布に従っているからです。ただし、一様分布に従っていることが乱数を意味するものではありません。 可視化については第17章以降で解説しますが、ここでは簡単にhist()関数を使ってみましょう。必要な引数はnumeric型のベクトルのみです。以下のコードにあるxlab =などはラベルを指定する引数ですが、省略しても構いません。 hist(LCG_Numbers, xlab = &quot;乱数&quot;, ylab = &quot;度数&quot;, main = &quot;生成された乱数10000個のヒストグラム&quot;) ややギザギザしているように見えますが68、これなら一様分布だと考えて良いでしょう。 練習問題 問1 長さ2のnumericベクトルDataについて考える。条件分岐を用いてDataの1番目の要素 (Data[1])が2番目の要素 (Data[2])より大きい場合、1番目の要素と2番目の順番を逆転させる条件分岐を作成せよ。たとえば、Data &lt;- c(5, 3)なら、条件分岐後のDataの値がc(3, 5)になること。 問2 与えられた正の実数の平方根を求めるmy_sqrt()を作成する。平方根を計算する方法はHero of Alexandriaの近似法69を使用する。 平方根を求めるx、任意の初期値g、非常に小さい正の実数eを入力する。eの既定値は0.001とする。 gの2乗を計算し、x - g^2の絶対値をgapとする（gapの初期値はInfとする）。 gapがeより小さい場合、gをxの平方根として返す。 gapがeより大きい場合、g + (x / g)を新しいgとする。 2へ戻る。 while()関数を使えば簡単である。 # Rのsqrt()関数 sqrt(29) ## [1] 5.385165 # 計算例1 my_sqrt(29, 5) # 29の平方根。初期値は5 ## [1] 5.385185 # 計算例2 my_sqrt(29, 5, e = 0.00001) # 29の平方根。初期値は5。eは0.00001 ## [1] 5.385165 # 計算例3 my_sqrt(-3, 5, e = 0.00001) # あえてエラーを出してみる ## Error in my_sqrt(-3, 5, e = 1e-05): xは正の実数でなければなりません。 問3 問3ではベクトルの1番目要素と2番目の要素を比較し、前者が大きい場合において順番を入れ替える条件分岐を行った。これを長さ3以上のベクトルにも適用したい。長さ4のnumeric型ベクトルDataがある場合の計算手順について考えてみよう。 Data[1]とData[2]の要素を比較し、Data[1] &gt; Data[2]の場合、入れ替える。 Data[2]とData[3]の要素を比較し、Data[2] &gt; Data[3]の場合、入れ替える。 Data[3]とData[4]の要素を比較し、Data[3] &gt; Data[4]の場合、入れ替える。この段階でData[4]はDataの最大値が格納される。 続いて、Data[1]とData[2]の要素を比較し、Data[1] &gt; Data[2]の場合、入れ替える。 Data[2]とData[3]の要素を比較し、Data[2] &gt; Data[3]の場合、入れ替える。この段階でData[3]にはDataの2番目に大きい数値が格納される。 最後にData[1]とData[2]の要素を比較し、Data[1] &gt; Data[2]の場合、入れ替える。ここで並び替えは終了 ヒント: 2つのfor()文が必要となる。これは「バブルソート」と呼ばれる最も簡単なソートアルゴリズムである。イメージとしては、長さNのベクトルの場合、n番目の要素とn+1番目の要素を比較しながら、大きい方を後ろの方に追い込む形である。最初は、Data[4]最後の要素に最大値を格納し、続いて、Data[3]に次に大きい数値を、Data[2]に次に大きい数値を入れる仕組みである。 最初はData[1]とData[2]、Data[2]とData[3]、Data[3]とData[4]の3ペアの比較を行う。 続いて、Data[1]とData[2]、Data[2]とData[3]の2ペアの比較を行う 最後に、Data[1]とData[2]の1ペアの比較を行う つまり、外側のfor()文は「Dataの長さ-1」回繰り返すことになる。 内側のfor()文は3, 2, 1ペアの比較を行うことになる。 問4 「問4」の練習問題で作成したコードを関数化せよ。関数名はmySort()であり、引数は長さ2以上のnumeric型ベクトルのみである。引数名は自由に決めても良いし、dataやxなどを使っても良い。 問5 既に作成したDQ_Attack関数を修正してみよう。今の関数は通常攻撃のみであるが、稀に「会心の一撃」が発生するように修正する。 会心の一撃が発生する確率は1/32とする (Hint: 0から1の間の乱数を生成し、その乱数が1/32以下であるか否かで条件分岐させる)。乱数の生成はrunif()または、自作関数のLCG()でも良い。 会心の一撃のダメージの最小値は攻撃力の95%、最大値は105%とする。 会心の一撃が発生したら、\"かいしんのいちげき! スライムに10のダメージ!!\"のようなメッセージを出力させること。 問6 与えられたベクトルxからn個の要素を無作為に抽出する関数、mySample()を定義せよ。mySample()の引数はxとn、seedとし、xは長さ1以上のベクトルとする。nは長さ1の整数型ベクトルである。 以下の場合、エラーメッセージを出力し、処理を中止させること。 nとseedが長さ1ベクトルでない場合、 seedがnumeric型でない場合 nが整数でない場合 (floor(n) == nで判定) ヒント: LCG()関数を用いて乱数を生成した場合、生成された擬似乱数は0以上1以下である。ベクトルxの長さをlength(x)とした場合、擬似乱数にlength(x)を掛けると、擬似乱数は0以上length(x)以下になる。これらの値を切り上げると (ceiling()関数)、その値は1以上length(x)以下の整数となる。 参考資料 "],["datahandling1.html", "12. データハンドリング [基礎編: 抽出] 12.1 データハンドリングとtidyverse 12.2 パイプ演算子 (%&gt;%) 12.3 列の抽出 12.4 行の抽出 12.5 行のソート 練習問題", " 12. データハンドリング [基礎編: 抽出] ここでは比較的綺麗に整形されているデータフレームを扱う方法について考えます。ここでいう「比較的綺麗なデータ」とは、すぐに分析に使えるレベルのデータを意味します。したがって、ここではデータ内の値を変更するような作業は行いません。基本的に分析しやすくなるように列の順番を替えたり、特定の列や行のみを抽出したり、データの順番を並び替える作業に注目します。 本性では以下の3つの内容を中心に解説します。 パイプ演算子 (%&gt;%)に慣れる 特定の行と列の抽出 データのソート 本章で学習する内容でデータを加工した場合、得られる結果物は元のデータの一部 (subset)となります。データの中身の値を変えたり、新しい列を追加したり、平均値などの記述統計量をまとめたりする方法については次の第13章で解説します。 12.1 データハンドリングとtidyverse The tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. (Tidyverseホームページから) Tidyverseとはデータサイエンスのために考案された、強い信念と思想に基づいたRパッケージの集合です。Tidyverseに属するパッケージは思想、文法およびデータ構造を共有しています。Tidyverseの中核をなすパッケージは{ggplot2} (第17、18、19、20章)、{dplyr} (第12、13章)、{tidyr} (第15章)、{readr} (第7.1章)、{purrr} (第27章)、{tibble} (第9.4章)、{stringr} (第16章)、{forcats} (第14章)があり、このパッケージを支える数十のパッケージが含まれています。これらのパッケージは個別に読み込む必要はなく、{tidyverse}パッケージを読み込むだけで十分です。 pacman::p_load(tidyverse) Rにおけるデータハンドリング (データ操作) の標準が{dplyr}と{tidyr}中心となり、文字列の処理は{stringr}、factor型の操作は{forcats}、大量のモデルを自動的に分析し、結果を処理するためには{tibble}と{purrr}、可視化は{ggplot2}が主に使われています。これらのパッケージ間、あるいはパッケージ内におけるオブジェクトのやり取りは全てパイプ演算子を通じて行われています。また、これらのパッケージは整然データ (tidydata) を想定するか、整然データの作成するに特化しています。 tidyverseの思想に基づいた「tidyverse流のコーディング」は現在のRそのものと言っても過言ではありません。ただし、tidyverseじゃないと出来ないデータハンドリング、可視化などはありません。tidyverseはデータサイエンスの思想に近いものであり、「異なる思想を持っているからこのような分析はできない」といったものはありません。tidyverseという概念が提唱される前にもRは存在し、tidyverse無き世界で今と同じことをやってきました。ただし、tidyverse流で書かれたRコードは可読性が優れ、コードを書く手間も短くなります。tidyverseの考え方がRのける「標準語」として定着しつつあるのは否めない事実であり、学習する誘引としては十分すぎるでしょう。 12.2 パイプ演算子 (%&gt;%) {dplyr}パッケージを利用する前にパイプ演算子について説明します。パイプ演算子は{dplyr}に含まれている演算子ではなく、magrittrという別のパッケージから提供される演算子ですが、{tidyverse}パッケージを読み込むと自動的に読み込まれます。パイプ演算子はx %&gt;% y()のような書き方となりますが、これは「xをy()の第一引数として渡す」ことを意味します。xの部分はベクトルやデータフレームのようなオブジェクトでも、関数でも構いません。なぜなら、関数から得られた結果もまたベクトルやデータフレームといったものになるからです。つまり、x() %&gt;% y()という使い方も可能です。そして、パイプは無限に繋ぐこともできます。「データdfを関数x()で処理をし、その結果をまた関数y()で処理する」ことは、パイプを使うとdf %&gt;% x() %&gt;% y()のような書き方となります。 たとえば、「paste(3, \"+\", 5, \"=\", 8)を実行し、その結果をrep()関数を使って3回複製し、それをprint()を使って出力する」コードを考えてみましょう。方法としては2つ考えられます。まずは、それぞれの処理を別途のオブジェクトに格納する方法です。そして二つ目は関数の中に関数を使う方法です。 # 方法1: 一関数一オブジェクト Result1 &lt;- paste(3, &quot;+&quot;, 5, &quot;=&quot;, 8) Result2 &lt;- rep(Result1, 3) print(Result2) ## [1] &quot;3 + 5 = 8&quot; &quot;3 + 5 = 8&quot; &quot;3 + 5 = 8&quot; # 方法2: 関数の中に関数の中に関数 print(rep(paste(3, &quot;+&quot;, 5, &quot;=&quot;, 8), 3)) ## [1] &quot;3 + 5 = 8&quot; &quot;3 + 5 = 8&quot; &quot;3 + 5 = 8&quot; どれも結果は同じです。コードを書く手間を考えれば、後者の方が楽かも知れませんが、可読性があまりよくありません。一方、前者は可読性は良いものの、コードも長くなり、オブジェクトを2つも作ってしまうのでメモリの無駄遣いになります。 コードの可読性と書く手間、両方を満足する書き方がパイプ演算子%&gt;%です。まずは、例から見ましょう。 # %&gt;%を使う paste(3, &quot;+&quot;, 5, &quot;=&quot;, 8) %&gt;% rep(3) %&gt;% print() ## [1] &quot;3 + 5 = 8&quot; &quot;3 + 5 = 8&quot; &quot;3 + 5 = 8&quot; まず、結果は先ほどと同じです。それではコードの説明をしましょう。まずは、paste(3, \"+\", 5, \"=\", 8)を実行します。そしてその結果をそのままrep()関数の第一引数として渡されます。つまり、rep(paste(3, \"+\", 5, \"=\", 8), 3)になるわけです。ここではrep(3)と書きましたが、第一引数が渡されたため、3は第二引数扱いになります (パイプ演算子前のオブジェクトを第二、三引数として渡す方法は適宜説明します。)。そして、これをまたprint()関数に渡します。結果としてはprint(rep(paste(3, \"+\", 5, \"=\", 8), 3))となります。 関数を重ねると読む順番は「カッコの内側から外側へ」になりますが、パイプ演算子を使うと「左 (上)から右 (下)へ」といったより自然な読み方が可能になります。また、以下のコードのように、パイプ演算子後に改行を行うことでより読みやすいコードになります。これからはパイプ演算子の後は必ず改行をします。 # 改行 (+字下げ)したらもっと読みやすくなる paste(3, &quot;+&quot;, 5, &quot;=&quot;, 8) %&gt;% rep(3) %&gt;% print() パイプ演算子を使わない方法は図12.1のようにイメージできます。一回の処理ごとに結果を保存し、それをまた次の処理時においてデータとして使うイメージです。 図 12.1: パイプ演算子を使わない場合 一方、図12.2はパイプ演算子を使う場合のプロセスです。処理後の結果を保存せず、すぐに次のプロセスに渡すことで、メモリ (図だとボウル)や時間、コードの無駄を減らすことができます。むろん、図12.1の結果1を使って色々試してみたい場合は、一旦結果1までは格納し、適宜引き出して使った方が効率的でしょう。パイプ演算子はたしかに便利で、「今どき」のRの書き方を象徴するようなものですが、一つの結果を出すまであまりにも多くのパイプ演算子を使うことはあ望ましくありません。 図 12.2: パイプ演算子を使う場合 データハンドリングもこれど同様に、様々な作業を順に沿って行う必要があります。例えば、「(1) 列を選択して、(2) 欠損値を含む列を除去して、 (3) ある変数の値を100倍にして、(4) ある変数の値がが小さい行から大きい順へ並び替える」といった手順です。これらの作業はパイプ演算子を使えば、スムーズに行うことが可能です。 12.3 列の抽出 それでは今回の実習用データを読み込みましょう。Ramen.csvには「ぐるなび」から取得したラーメン屋6292店舗の情報が入っています。具体的には東京、神奈川、千葉、埼玉、大阪、京都、兵庫、奈良、和歌山それぞれ都府県にあるラーメン屋の中から最大1000店舗の情報を抽出したものです。東京都は、ぐるなびに登録したラーメン屋が3000店舗以上ですが、1000店舗の基準はぐるなびの「おすすめ」の順で上位1000店舗となります。また、店側またはぐるなびが登録したカテゴリを基準に抽出したため、実際はラーメン屋ではないにもかかわらずラーメン屋としてデータ内に含まれている可能性があります。 まず、このデータを読み込み、dfという名付けます。 df &lt;- read_csv(&quot;Data/Ramen.csv&quot;) データの中身を確認してみましょう。 df ## # A tibble: 6,292 × 14 ## ID Name Pref Zipcode Latitude Longitude Line Station Walk Bus Car ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 e5396… 居酒… 東京… 1040031 35.7 140. 地下… 銀座一… 3 NA NA ## 2 gfeb6… 本格… 東京… 1100005 35.7 140. 地下… 仲御徒… 1 NA NA ## 3 ggt59… 食べ… 東京… 1250041 35.8 140. ＪＲ… 金町駅 2 NA NA ## 4 g1813… 博多… 東京… 1920904 35.7 139. ＪＲ 八王子… 1 NA NA ## 5 ggww1… まさ… 東京… 1500042 35.7 140. 地下… 渋谷駅 7 NA NA ## 6 gdzk5… 完全… 東京… 1000013 35.7 140. 地下… 虎ノ門… 3 NA NA ## 7 ga2g2… 鶏そ… 東京… 1760006 35.7 140. 西武… 江古田… 2 NA NA ## 8 gg9m1… 宴会… 東京… 1010021 35.7 140. ＪＲ 秋葉原… 4 NA NA ## 9 gdvk2… 中国… 東京… 1000006 35.7 140. ＪＲ 有楽町… 1 NA NA ## 10 gggb2… 中国… 東京… 1140002 35.8 140. 地下… 王子駅 2 NA NA ## # … with 6,282 more rows, and 3 more variables: Budget &lt;dbl&gt;, ScoreN &lt;dbl&gt;, ## # Score &lt;dbl&gt; 1行目の# A tibble: 2,000 x 12から、ケース数 (店舗数)は2000、変数は12個あることが分かります。各変数の詳細は以下の通りです。 変数名 説明 ID 店舗ID Name 店舗名 Pref 店舗の所在地 (都府県) Zipcode 店舗の郵便番号 Latitude 緯度 Longitude 経度 Line 最寄りの駅の路線 Station 最寄りの駅 Walk 最寄りの駅からの距離 (徒歩; 分) Bus 最寄りの駅からの距離 (バス; 分) Car 最寄りの駅からの距離 (車; 分) Budget 平均予算 (円) ScoreN 口コミの数 Score 口コミ評価の平均値 それではここからはdfを用いた{dplyr}の様々な機能を紹介していきます。 12.3.1 特定の列を抽出する まずは、データフレームから特定の列のみを残す、除去する方法について紹介します。たとえば、dfからID、Name、Pref、Scoreのみを残すとします。{dplyr}を使わない方法と{dplyr}のselect()関数を使った方法を紹介します。 # dplyrを使わない方法 df[, c(&quot;ID&quot;, &quot;Name&quot;, &quot;Pref&quot;, &quot;Score&quot;)] ## # A tibble: 6,292 × 4 ## ID Name Pref Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 e539604 居酒屋 龍記 京橋店 東京都 NA ## 2 gfeb600 本格上海料理 新錦江 上野御徒町本店 東京都 4.5 ## 3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ） 東京都 NA ## 4 g181340 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル）併設 東京都 NA ## 5 ggww100 まさ屋 渋谷店 東京都 NA ## 6 gdzk500 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店 東京都 NA ## 7 ga2g202 鶏そば きらり 東京都 NA ## 8 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店 東京都 3.33 ## 9 gdvk200 中国料理 宝龍 東京都 2.5 ## 10 gggb200 中国料理 天安門 東京都 NA ## # … with 6,282 more rows # dplyr::select()を使う方法 # select(df, ID, Name, Pref, Score)でもOK df %&gt;% select(ID, Name, Pref, Score) ## # A tibble: 6,292 × 4 ## ID Name Pref Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 e539604 居酒屋 龍記 京橋店 東京都 NA ## 2 gfeb600 本格上海料理 新錦江 上野御徒町本店 東京都 4.5 ## 3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ） 東京都 NA ## 4 g181340 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル）併設 東京都 NA ## 5 ggww100 まさ屋 渋谷店 東京都 NA ## 6 gdzk500 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店 東京都 NA ## 7 ga2g202 鶏そば きらり 東京都 NA ## 8 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店 東京都 3.33 ## 9 gdvk200 中国料理 宝龍 東京都 2.5 ## 10 gggb200 中国料理 天安門 東京都 NA ## # … with 6,282 more rows どれも結果は同じですが、select()関数を使った方がより読みやすいコードになっているでしょう。むろん、select()関数を使わない方がスッキリする方も知るかも知れません。実際、自分でパッケージなどを作成する際はselect()を使わない場合が多いです。ただし、一般的な分析の流れではselect()の方がコードも意味も明確となり、パイプ演算子でつなぐのも容易です。 select()関数の使い方は非常に簡単です。第一引数はデータフレームですが、パイプ演算子を使う場合は省略可能です。第二引数以降の引数はデータフレームの変数名です。つまり、ここには残す変数名のみを書くだけで十分です。 また、select()関数を使って列の順番を変えることもできます。たとえば、ID、Pref、Name、Scoreの順で列を残すなら、この順番で引数を書くだけです。 df %&gt;% select(ID, Pref, Name) ## # A tibble: 6,292 × 3 ## ID Pref Name ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 e539604 東京都 居酒屋 龍記 京橋店 ## 2 gfeb600 東京都 本格上海料理 新錦江 上野御徒町本店 ## 3 ggt5900 東京都 食べ飲み放題×中華ビストロ NOZOMI（のぞみ） ## 4 g181340 東京都 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル）併設 ## 5 ggww100 東京都 まさ屋 渋谷店 ## 6 gdzk500 東京都 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店 ## 7 ga2g202 東京都 鶏そば きらり ## 8 gg9m100 東京都 宴会個室×餃子酒場 北京飯店 秋葉原本店 ## 9 gdvk200 東京都 中国料理 宝龍 ## 10 gggb200 東京都 中国料理 天安門 ## # … with 6,282 more rows 12.3.2 特定の列を抽出し、列名を変更する また、特定の列を残す際、変数名を変更することも可能です。今回もID、Name、Pref、Scoreのみを残しますが、Pref列はPrefectureに変えてみましょう。 df %&gt;% select(ID, Name, Prefecture = Pref, Score) ## # A tibble: 6,292 × 4 ## ID Name Prefecture Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 e539604 居酒屋 龍記 京橋店 東京都 NA ## 2 gfeb600 本格上海料理 新錦江 上野御徒町本店 東京都 4.5 ## 3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ） 東京都 NA ## 4 g181340 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル… 東京都 NA ## 5 ggww100 まさ屋 渋谷店 東京都 NA ## 6 gdzk500 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店 東京都 NA ## 7 ga2g202 鶏そば きらり 東京都 NA ## 8 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店 東京都 3.33 ## 9 gdvk200 中国料理 宝龍 東京都 2.5 ## 10 gggb200 中国料理 天安門 東京都 NA ## # … with 6,282 more rows 抽出する際、変数を新しい変数名 = 既存の変数名にするだけで、変数名が簡単に変更できました。もし、特定の列は抽出しないものの、変数名を変えるにはどうすれば良いでしょうか。ここではdfのPrefをPrefectureに、WalkをDistanceに変更してみます。{dplyr}を使わない場合と{dplyr}のrename()関数を使う場合を両方紹介します。 まずは、name()関数についてですが、これはデータフレームの変数名をベクトルとして出力する関数です。 names(df) ## [1] &quot;ID&quot; &quot;Name&quot; &quot;Pref&quot; &quot;Zipcode&quot; &quot;Latitude&quot; &quot;Longitude&quot; ## [7] &quot;Line&quot; &quot;Station&quot; &quot;Walk&quot; &quot;Bus&quot; &quot;Car&quot; &quot;Budget&quot; ## [13] &quot;ScoreN&quot; &quot;Score&quot; 察しの良い読者は気づいたかも知れませんが、names(データフレーム名)の結果はベクトルであり、上書きも可能です。つまり、names(df)の3番目と9番目の要素を\"Prefecture\"と\"Distance\"に上書きすることができるということです。 # dplyrを使わずに列名を変更する方法 names(df)[c(3, 9)] &lt;- c(&quot;Prefecture&quot;, &quot;Distance&quot;) # dfの中身を出力 df ## # A tibble: 6,292 × 14 ## ID Name Prefecture Zipcode Latitude Longitude Line Station Distance ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 e539604 居酒屋 … 東京都 1040031 35.7 140. 地下… 銀座一… 3 ## 2 gfeb600 本格上… 東京都 1100005 35.7 140. 地下… 仲御徒… 1 ## 3 ggt5900 食べ飲… 東京都 1250041 35.8 140. ＪＲ… 金町駅 2 ## 4 g181340 博多餃… 東京都 1920904 35.7 139. ＪＲ 八王子… 1 ## 5 ggww100 まさ屋 … 東京都 1500042 35.7 140. 地下… 渋谷駅 7 ## 6 gdzk500 完全個… 東京都 1000013 35.7 140. 地下… 虎ノ門… 3 ## 7 ga2g202 鶏そば … 東京都 1760006 35.7 140. 西武… 江古田… 2 ## 8 gg9m100 宴会個… 東京都 1010021 35.7 140. ＪＲ 秋葉原… 4 ## 9 gdvk200 中国料… 東京都 1000006 35.7 140. ＪＲ 有楽町… 1 ## 10 gggb200 中国料… 東京都 1140002 35.8 140. 地下… 王子駅 2 ## # … with 6,282 more rows, and 5 more variables: Bus &lt;dbl&gt;, Car &lt;dbl&gt;, ## # Budget &lt;dbl&gt;, ScoreN &lt;dbl&gt;, Score &lt;dbl&gt; 簡単に変数名の変更ができました。続いて、{dplyr}のrename()関数を使った方法です。今回は、PrefectureをPrefに、DistanceをWalkに戻して見ましょう。そして、出力するだけにとどまらず、dfに上書きしましょう。 # dfのPrefectureをPrefに、DistanceをWalkに変更し、上書きする df &lt;- df %&gt;% rename(Pref = Prefecture, Walk = Distance) これで終わりです。実はselect()関数と使い方がほぼ同じです。ただし、残す変数名を指定する必要がなく、名前を変更する変数名と新しい変数名を入れるだけです。変数が少ないデータならselect()でもあまり不便は感じないかも知れませんが、変数が多くなるとrename()関数は非常に便利です。 12.3.3 特定の列を除外する 逆に、一部の変数をデータフレームから除去したい場合もあるでしょう。たとえば、緯度 (Latitude)と経度 (Longitude)はラーメン屋の情報としては不要かもしれません。この2つの変数を除外するためにはどうすれば良いでしょうか。まず考えられるのは、この2つの変数を除いた変数を指定・抽出する方法です。 df %&gt;% select(ID, Name, Pref, Zipcode, Line, Station, Walk, Bus, Car, Budget, ScoreN, Score) ## # A tibble: 6,292 × 12 ## ID Name Pref Zipcode Line Station Walk Bus Car Budget ScoreN Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 e539… 居酒… 東京… 1040031 地下… 銀座一… 3 NA NA 3000 0 NA ## 2 gfeb… 本格… 東京… 1100005 地下… 仲御徒… 1 NA NA 2000 2 4.5 ## 3 ggt5… 食べ… 東京… 1250041 ＪＲ… 金町駅 2 NA NA 2980 0 NA ## 4 g181… 博多… 東京… 1920904 ＪＲ 八王子… 1 NA NA 2000 0 NA ## 5 ggww… まさ… 東京… 1500042 地下… 渋谷駅 7 NA NA 380 0 NA ## 6 gdzk… 完全… 東京… 1000013 地下… 虎ノ門… 3 NA NA 2980 0 NA ## 7 ga2g… 鶏そ… 東京… 1760006 西武… 江古田… 2 NA NA 850 0 NA ## 8 gg9m… 宴会… 東京… 1010021 ＪＲ 秋葉原… 4 NA NA 2000 3 3.33 ## 9 gdvk… 中国… 東京… 1000006 ＪＲ 有楽町… 1 NA NA 1000 2 2.5 ## 10 gggb… 中国… 東京… 1140002 地下… 王子駅 2 NA NA 2000 0 NA ## # … with 6,282 more rows かなり長いコードになりましたね。しかし、もっと簡単な方法があります。それは-を使う方法です。 df %&gt;% select(-Latitude, -Longitude) # select(-c(Latitude, Longitude)) ## # A tibble: 6,292 × 12 ## ID Name Pref Zipcode Line Station Walk Bus Car Budget ScoreN Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 e539… 居酒… 東京… 1040031 地下… 銀座一… 3 NA NA 3000 0 NA ## 2 gfeb… 本格… 東京… 1100005 地下… 仲御徒… 1 NA NA 2000 2 4.5 ## 3 ggt5… 食べ… 東京… 1250041 ＪＲ… 金町駅 2 NA NA 2980 0 NA ## 4 g181… 博多… 東京… 1920904 ＪＲ 八王子… 1 NA NA 2000 0 NA ## 5 ggww… まさ… 東京… 1500042 地下… 渋谷駅 7 NA NA 380 0 NA ## 6 gdzk… 完全… 東京… 1000013 地下… 虎ノ門… 3 NA NA 2980 0 NA ## 7 ga2g… 鶏そ… 東京… 1760006 西武… 江古田… 2 NA NA 850 0 NA ## 8 gg9m… 宴会… 東京… 1010021 ＪＲ 秋葉原… 4 NA NA 2000 3 3.33 ## 9 gdvk… 中国… 東京… 1000006 ＪＲ 有楽町… 1 NA NA 1000 2 2.5 ## 10 gggb… 中国… 東京… 1140002 地下… 王子駅 2 NA NA 2000 0 NA ## # … with 6,282 more rows 除外したい変数名の前に-を付けただけです。また、-Latitudeと-Longitudeをそれぞれ指定せず、-c(Latitude, Longitude)のようにc()でまとめるのも可能です。 12.3.4 隣接した列を指定する 先ほど、dfから緯度 (Latitude)と経度 (Longitude)を除外する例を考えてみましょう。-を使うと簡単ですが、場合によっては残す変数名を指定する必要もあります。 df %&gt;% select(ID, Name, Pref, Zipcode, Line, Station, Walk, Bus, Car, Budget, ScoreN, Score) よく考えてみれば、IDからZipcodeは隣接した列ですし、LineからScoreまでもそうです。これはnames()関数で確認できます。 names(df) ## [1] &quot;ID&quot; &quot;Name&quot; &quot;Pref&quot; &quot;Zipcode&quot; &quot;Latitude&quot; &quot;Longitude&quot; ## [7] &quot;Line&quot; &quot;Station&quot; &quot;Walk&quot; &quot;Bus&quot; &quot;Car&quot; &quot;Budget&quot; ## [13] &quot;ScoreN&quot; &quot;Score&quot; ここで便利な演算子が:です。これまで、xからyまでの公差1の等差数列を作成する際にx:yを使って来ましたが、これに非常に似ています。データフレームの「x列からy列まで」の表記もselect()関数内では:と書くことができます。したがって、上記のコードは以下のように短縮化可能です。 df %&gt;% select(ID:Zipcode, Line:Score) 「dfのIDからZipcodeまで、そしてLineからScoreまでの列を選択する」という意味です。非常に便利な演算子ですので、-と合わせて覚えておきましょう。 12.3.5 一部の列の順番だけを変える ある列の位置を替えたいとします。たとえば、ScoreとScoreNをそれぞれ1列目、2列目にしたい場合、どうすれば良いでしょうか。これまで勉強したことを考えると、以下のようなコードで問題ないでしょう。 df %&gt;% select(Score, ScoreN, ID:Budget) ## # A tibble: 6,292 × 14 ## Score ScoreN ID Name Pref Zipcode Latitude Longitude Line Station Walk ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 NA 0 e539… 居酒… 東京… 1040031 35.7 140. 地下… 銀座一… 3 ## 2 4.5 2 gfeb… 本格… 東京… 1100005 35.7 140. 地下… 仲御徒… 1 ## 3 NA 0 ggt5… 食べ… 東京… 1250041 35.8 140. ＪＲ… 金町駅 2 ## 4 NA 0 g181… 博多… 東京… 1920904 35.7 139. ＪＲ 八王子… 1 ## 5 NA 0 ggww… まさ… 東京… 1500042 35.7 140. 地下… 渋谷駅 7 ## 6 NA 0 gdzk… 完全… 東京… 1000013 35.7 140. 地下… 虎ノ門… 3 ## 7 NA 0 ga2g… 鶏そ… 東京… 1760006 35.7 140. 西武… 江古田… 2 ## 8 3.33 3 gg9m… 宴会… 東京… 1010021 35.7 140. ＪＲ 秋葉原… 4 ## 9 2.5 2 gdvk… 中国… 東京… 1000006 35.7 140. ＪＲ 有楽町… 1 ## 10 NA 0 gggb… 中国… 東京… 1140002 35.8 140. 地下… 王子駅 2 ## # … with 6,282 more rows, and 3 more variables: Bus &lt;dbl&gt;, Car &lt;dbl&gt;, ## # Budget &lt;dbl&gt; しかし、{dplyr}にはrelocate()というより便利な専用関数を提供しています。relocate()には変数名を指定するだけですが、ここで指定した変数がデータフレームの最初列の方に移動します。 df %&gt;% relocate(Score, ScoreN) ## # A tibble: 6,292 × 14 ## Score ScoreN ID Name Pref Zipcode Latitude Longitude Line Station Walk ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 NA 0 e539… 居酒… 東京… 1040031 35.7 140. 地下… 銀座一… 3 ## 2 4.5 2 gfeb… 本格… 東京… 1100005 35.7 140. 地下… 仲御徒… 1 ## 3 NA 0 ggt5… 食べ… 東京… 1250041 35.8 140. ＪＲ… 金町駅 2 ## 4 NA 0 g181… 博多… 東京… 1920904 35.7 139. ＪＲ 八王子… 1 ## 5 NA 0 ggww… まさ… 東京… 1500042 35.7 140. 地下… 渋谷駅 7 ## 6 NA 0 gdzk… 完全… 東京… 1000013 35.7 140. 地下… 虎ノ門… 3 ## 7 NA 0 ga2g… 鶏そ… 東京… 1760006 35.7 140. 西武… 江古田… 2 ## 8 3.33 3 gg9m… 宴会… 東京… 1010021 35.7 140. ＪＲ 秋葉原… 4 ## 9 2.5 2 gdvk… 中国… 東京… 1000006 35.7 140. ＪＲ 有楽町… 1 ## 10 NA 0 gggb… 中国… 東京… 1140002 35.8 140. 地下… 王子駅 2 ## # … with 6,282 more rows, and 3 more variables: Bus &lt;dbl&gt;, Car &lt;dbl&gt;, ## # Budget &lt;dbl&gt; relocate()を使うとID:Budgetが省略可能となり、より短いコードになります。もう一つの例は、最初に持ってくるのではなく、「ある変数の前」または「ある変数の後」に移動させるケースです。これもrelocate()で可能ですが、もう一つの引数が必要です。PrefとZipcdoeの順番を変えるなら、まずは以下のような方法が考えられます。 df %&gt;% select(ID:Name, Zipcode, Pref, Latitude:Score) ## # A tibble: 6,292 × 14 ## ID Name Zipcode Pref Latitude Longitude Line Station Walk Bus Car ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 e5396… 居酒… 1040031 東京… 35.7 140. 地下… 銀座一… 3 NA NA ## 2 gfeb6… 本格… 1100005 東京… 35.7 140. 地下… 仲御徒… 1 NA NA ## 3 ggt59… 食べ… 1250041 東京… 35.8 140. ＪＲ… 金町駅 2 NA NA ## 4 g1813… 博多… 1920904 東京… 35.7 139. ＪＲ 八王子… 1 NA NA ## 5 ggww1… まさ… 1500042 東京… 35.7 140. 地下… 渋谷駅 7 NA NA ## 6 gdzk5… 完全… 1000013 東京… 35.7 140. 地下… 虎ノ門… 3 NA NA ## 7 ga2g2… 鶏そ… 1760006 東京… 35.7 140. 西武… 江古田… 2 NA NA ## 8 gg9m1… 宴会… 1010021 東京… 35.7 140. ＪＲ 秋葉原… 4 NA NA ## 9 gdvk2… 中国… 1000006 東京… 35.7 140. ＪＲ 有楽町… 1 NA NA ## 10 gggb2… 中国… 1140002 東京… 35.8 140. 地下… 王子駅 2 NA NA ## # … with 6,282 more rows, and 3 more variables: Budget &lt;dbl&gt;, ScoreN &lt;dbl&gt;, ## # Score &lt;dbl&gt; これをrelocate()で書き換えるなら、.afterまたは.before引数が必要になります。relocate(変数名1, .after = 変数名2)は「変数1を変数2の直後に移動させる」 ことを意味します。 df %&gt;% relocate(Pref, .after = Zipcode) ## # A tibble: 6,292 × 14 ## ID Name Zipcode Pref Latitude Longitude Line Station Walk Bus Car ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 e5396… 居酒… 1040031 東京… 35.7 140. 地下… 銀座一… 3 NA NA ## 2 gfeb6… 本格… 1100005 東京… 35.7 140. 地下… 仲御徒… 1 NA NA ## 3 ggt59… 食べ… 1250041 東京… 35.8 140. ＪＲ… 金町駅 2 NA NA ## 4 g1813… 博多… 1920904 東京… 35.7 139. ＪＲ 八王子… 1 NA NA ## 5 ggww1… まさ… 1500042 東京… 35.7 140. 地下… 渋谷駅 7 NA NA ## 6 gdzk5… 完全… 1000013 東京… 35.7 140. 地下… 虎ノ門… 3 NA NA ## 7 ga2g2… 鶏そ… 1760006 東京… 35.7 140. 西武… 江古田… 2 NA NA ## 8 gg9m1… 宴会… 1010021 東京… 35.7 140. ＪＲ 秋葉原… 4 NA NA ## 9 gdvk2… 中国… 1000006 東京… 35.7 140. ＪＲ 有楽町… 1 NA NA ## 10 gggb2… 中国… 1140002 東京… 35.8 140. 地下… 王子駅 2 NA NA ## # … with 6,282 more rows, and 3 more variables: Budget &lt;dbl&gt;, ScoreN &lt;dbl&gt;, ## # Score &lt;dbl&gt; .beforeを使うことできます。この場合は「ZipcodeをPrefの直前に移動させる」 ことを指定する必要があります。結果は省略しますが、自分でコードを走らせ、上と同じ結果が得られるかを確認してみてください。 df %&gt;% relocate(Zipcode, .before = Pref) 12.3.6 select()の便利な機能 select()関数は他にも便利な機能がいくつかあります。ここではいくつの機能を紹介しますが、より詳しい内容は?dplyr::selectを参照してください。 starts_with()とends_with()、contains()、num_range(): 特定の文字を含む変数を選択する まずは、特定の文字を含む変数名を指定する方法です。starts_with(\"X\")、ends_with(\"X\")、contains(\"X\")は変数名が\"X\"で始まるか、\"X\"で終わるか、\"X\"を含むかを判断し、条件に合う変数名を返す関数です。実際の例を見ましょう。 # ID、Nameに続いて、Scoreで始まる変数名を抽出 df %&gt;% select(ID, Name, starts_with(&quot;Score&quot;)) ## # A tibble: 6,292 × 4 ## ID Name ScoreN Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 e539604 居酒屋 龍記 京橋店 0 NA ## 2 gfeb600 本格上海料理 新錦江 上野御徒町本店 2 4.5 ## 3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ） 0 NA ## 4 g181340 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル）併設 0 NA ## 5 ggww100 まさ屋 渋谷店 0 NA ## 6 gdzk500 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店 0 NA ## 7 ga2g202 鶏そば きらり 0 NA ## 8 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店 3 3.33 ## 9 gdvk200 中国料理 宝龍 2 2.5 ## 10 gggb200 中国料理 天安門 0 NA ## # … with 6,282 more rows # eで終わる変数名を除去 df %&gt;% select(-ends_with(&quot;e&quot;)) # !ends_with(&quot;e&quot;)も可能 ## # A tibble: 6,292 × 8 ## ID Pref Station Walk Bus Car Budget ScoreN ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 e539604 東京都 銀座一丁目駅 3 NA NA 3000 0 ## 2 gfeb600 東京都 仲御徒町駅 1 NA NA 2000 2 ## 3 ggt5900 東京都 金町駅 2 NA NA 2980 0 ## 4 g181340 東京都 八王子駅 1 NA NA 2000 0 ## 5 ggww100 東京都 渋谷駅 7 NA NA 380 0 ## 6 gdzk500 東京都 虎ノ門駅 3 NA NA 2980 0 ## 7 ga2g202 東京都 江古田駅 2 NA NA 850 0 ## 8 gg9m100 東京都 秋葉原駅 4 NA NA 2000 3 ## 9 gdvk200 東京都 有楽町駅 1 NA NA 1000 2 ## 10 gggb200 東京都 王子駅 2 NA NA 2000 0 ## # … with 6,282 more rows # reを含む変数名を抽出するが、ScoreNは除去する df %&gt;% select(contains(&quot;re&quot;), -ScoreN) ## # A tibble: 6,292 × 2 ## Pref Score ## &lt;chr&gt; &lt;dbl&gt; ## 1 東京都 NA ## 2 東京都 4.5 ## 3 東京都 NA ## 4 東京都 NA ## 5 東京都 NA ## 6 東京都 NA ## 7 東京都 NA ## 8 東京都 3.33 ## 9 東京都 2.5 ## 10 東京都 NA ## # … with 6,282 more rows 他の使い方としてはX1、X2のような「文字+数字」の変数を選択する際、starts_with()が活躍します。たとえば、以下のようなmyDF1があるとします。 # tibble()でなく、data.frame()も使用可能です。 myDF1 &lt;- tibble( ID = 1:5, X1 = c(2, 4, 6, 2, 7), Y1 = c(3, 5, 1, 1, 0), X1D = c(4, 2, 1, 6, 9), X2 = c(5, 5, 6, 0, 2), Y2 = c(3, 3, 2, 3, 1), X2D = c(8, 9, 5, 0, 1), X3 = c(3, 0, 3, 0, 2), Y3 = c(1, 5, 9, 1, 3), X3D = c(9, 1, 3, 3, 8) ) myDF1 ## # A tibble: 5 × 10 ## ID X1 Y1 X1D X2 Y2 X2D X3 Y3 X3D ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 4 5 3 8 3 1 9 ## 2 2 4 5 2 5 3 9 0 5 1 ## 3 3 6 1 1 6 2 5 3 9 3 ## 4 4 2 1 6 0 3 0 0 1 3 ## 5 5 7 0 9 2 1 1 2 3 8 このmyDF1からID、Y1、Y2、Y3を抽出するにはどうすれば良いでしょうか。これらの変数は隣接していないため、:も使えませんが、starts_with()を使えば簡単です。 myDF1 %&gt;% select(ID, starts_with(&quot;Y&quot;)) ## # A tibble: 5 × 4 ## ID Y1 Y2 Y3 ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 3 3 1 ## 2 2 5 3 5 ## 3 3 1 2 9 ## 4 4 1 3 1 ## 5 5 0 1 3 それでは、ID、X1、X2、X3はどうでしょうか。starts_with(\"X\")だと、X1cなども選択されてしまいますね。ここで-ends_with()の出番です。つまり、「まずはstarts_with(\"X\")でXで始まる変数を選択し、続いて、Dで終わるものを除外すればいいじゃん？」です。それでは、やってみましょうか。 myDF1 %&gt;% select(ID, starts_with(&quot;X&quot;), -ends_with(&quot;D&quot;)) ## # A tibble: 5 × 3 ## X1 X2 X3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 5 3 ## 2 4 5 0 ## 3 6 6 3 ## 4 2 0 0 ## 5 7 2 2 あらら、IDも同時になくなりましたね70。実はこのような時のために用意された関数があり、それがnum_range()です。num_range()の第一引数はstarts_with()関数と同じですが、第二引数も必要です。この第二引数にはnumeric型のベクトルが必要です。1:3でも、c(1, 2, 3)でも構いません。たとえば、ID、X1、X2、X3するには以下のように書きます。 myDF1 %&gt;% select(ID, num_range(&quot;X&quot;, 1:3)) ## # A tibble: 5 × 4 ## ID X1 X2 X3 ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 5 3 ## 2 2 4 5 0 ## 3 3 6 6 3 ## 4 4 2 0 0 ## 5 5 7 2 2 all_of()とany_of(): 文字型ベクトルを用いた変数の選択 all_of()とany_of()はselect()内の変数名として文字型ベクトルを使う際に用いる関数です。これは抽出したい列名が既にcharacter型ベクトルとして用意されている場合、便利な関数です。たとえば、以下のName_Vecを考えてみましょう。 Name_Vec &lt;- c(&quot;X1&quot;, &quot;X2&quot;, &quot;X3&quot;) このName_Vecの要素と同じ列名を持つ列とID列をmyDF1から抽出する方法は以下の2通りです。 myDF1[, c(&quot;ID&quot;, Name_Vec)] ## # A tibble: 5 × 4 ## ID X1 X2 X3 ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 5 3 ## 2 2 4 5 0 ## 3 3 6 6 3 ## 4 4 2 0 0 ## 5 5 7 2 2 myDF1 %&gt;% select(ID, all_of(Name_Vec)) ## # A tibble: 5 × 4 ## ID X1 X2 X3 ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 5 3 ## 2 2 4 5 0 ## 3 3 6 6 3 ## 4 4 2 0 0 ## 5 5 7 2 2 今の例だと、select()を使わない前者の方が便利かも知れませんが、select()内に外の変数名も指定する場合も多いので、後者の方が汎用性は高いです。私から見れば、今の例でも後者の方が読みやすく、使いやすいと思います。 それでは以下のようなName_Vecはどうでしょう。今回は、myDF1に含まれていないX4とX5もあります。 Name_Vec &lt;- c(&quot;X1&quot;, &quot;X2&quot;, &quot;X3&quot;, &quot;X4&quot;, &quot;X5&quot;) myDF1 %&gt;% select(all_of(Name_Vec)) ## Error: Can&#39;t subset columns that don&#39;t exist. ## Columns `X4` and `X5` don&#39;t exist. このようにエラーが出てしまします。つまり、all_of()の場合、引数の要素全てがデータフレームに存在する必要があります。もし、ないものは無視して、合致する列だけ取り出したいはどうすれば良いでしょうか。そこで登場するのがany_of()です。 myDF1 %&gt;% select(any_of(Name_Vec)) ## # A tibble: 5 × 3 ## X1 X2 X3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 5 3 ## 2 4 5 0 ## 3 6 6 3 ## 4 2 0 0 ## 5 7 2 2 any_of()の方がより使いやすいと思う方も多いでしょうが、必ずしもそうとは限りません。たとえば、Name_Vecに誤字などが含まれる場合、any_of()だと誤字が含まれている変数は取り出しません。この場合はむしろちゃんとエラーを表示してくれた方が嬉しいですね。 last_col(): 最後の列を選択する 普段あまり使わない機能ですが、最後の列を選択するlast_col()という関数もあります。たとえば、last_col(0)にすると最後の列を選択し、last_col(1)なら最後から2番目の列を選択します。たとえば、dfからIDと最後の列を取り出してみましょう。 # IDと最後の列のみを抽出 df %&gt;% select(ID, last_col(0)) ## # A tibble: 6,292 × 2 ## ID Score ## &lt;chr&gt; &lt;dbl&gt; ## 1 e539604 NA ## 2 gfeb600 4.5 ## 3 ggt5900 NA ## 4 g181340 NA ## 5 ggww100 NA ## 6 gdzk500 NA ## 7 ga2g202 NA ## 8 gg9m100 3.33 ## 9 gdvk200 2.5 ## 10 gggb200 NA ## # … with 6,282 more rows 最後の2行分を取り出すことも可能です。この場合はlast_col()の引数を長さ1ベクトルでなく、長さ2以上のベクトルにします。最後の行が0、その手前の行が1ですから、中の引数は1:0となります。0:1でも可能ですが、結果が若干異なります。 # IDと最後の2列分を抽出 (引数を1:0と設定) df %&gt;% select(ID, last_col(1:0)) ## # A tibble: 6,292 × 3 ## ID ScoreN Score ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 e539604 0 NA ## 2 gfeb600 2 4.5 ## 3 ggt5900 0 NA ## 4 g181340 0 NA ## 5 ggww100 0 NA ## 6 gdzk500 0 NA ## 7 ga2g202 0 NA ## 8 gg9m100 3 3.33 ## 9 gdvk200 2 2.5 ## 10 gggb200 0 NA ## # … with 6,282 more rows # IDと最後の2列分を抽出 (引数を0:1と設定) df %&gt;% select(ID, last_col(0:1)) ## # A tibble: 6,292 × 3 ## ID Score ScoreN ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 e539604 NA 0 ## 2 gfeb600 4.5 2 ## 3 ggt5900 NA 0 ## 4 g181340 NA 0 ## 5 ggww100 NA 0 ## 6 gdzk500 NA 0 ## 7 ga2g202 NA 0 ## 8 gg9m100 3.33 3 ## 9 gdvk200 2.5 2 ## 10 gggb200 NA 0 ## # … with 6,282 more rows last_col()の引数を1:0にするか0:1にするかによって抽出される順番が異なります。1:0はc(1, 0)、0:1はc(0, 1)と同じであることを考えると理由は簡単です。c(1, 0)の場合、last_col(1), last_col(0)の順番で処理をし、c(0, 1)はlast_col(0)、last_col(1)の順番で処理を行うからです。 このlast_col()の引数を空っぽにするとそれは最後の列を意味します。これを利用すれば、「ある変数の最後の列へ移動させる」こともできます。たとえば、IDを最後の列に移動させたい場合、relocate(ID, .after = last_col())のように書きます。 where(): データ型から変数を選択する 最後に、「numeric型の列のみ抽出したい」、「character型の列だけほしい」場合に便利なwhere()関数を紹介します。where()の中に入る引数は一つだけであり、データ型を判定する関数名が入ります。たとえば、numeric型か否かを判断する関数はis.numericです。dfからnumeric型の変数のみを抽出したい場合は以下のように書きます。 # numeric型の列を抽出する df %&gt;% select(where(is.numeric)) ## # A tibble: 6,292 × 9 ## Zipcode Latitude Longitude Walk Bus Car Budget ScoreN Score ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1040031 35.7 140. 3 NA NA 3000 0 NA ## 2 1100005 35.7 140. 1 NA NA 2000 2 4.5 ## 3 1250041 35.8 140. 2 NA NA 2980 0 NA ## 4 1920904 35.7 139. 1 NA NA 2000 0 NA ## 5 1500042 35.7 140. 7 NA NA 380 0 NA ## 6 1000013 35.7 140. 3 NA NA 2980 0 NA ## 7 1760006 35.7 140. 2 NA NA 850 0 NA ## 8 1010021 35.7 140. 4 NA NA 2000 3 3.33 ## 9 1000006 35.7 140. 1 NA NA 1000 2 2.5 ## 10 1140002 35.8 140. 2 NA NA 2000 0 NA ## # … with 6,282 more rows !を使って条件に合致する列を除外することも可能です。もし、character型の列を除外する場合は以下のように!where(is.character)を指定します。 # character型でない列を抽出する df %&gt;% select(!where(is.character)) ## # A tibble: 6,292 × 9 ## Zipcode Latitude Longitude Walk Bus Car Budget ScoreN Score ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1040031 35.7 140. 3 NA NA 3000 0 NA ## 2 1100005 35.7 140. 1 NA NA 2000 2 4.5 ## 3 1250041 35.8 140. 2 NA NA 2980 0 NA ## 4 1920904 35.7 139. 1 NA NA 2000 0 NA ## 5 1500042 35.7 140. 7 NA NA 380 0 NA ## 6 1000013 35.7 140. 3 NA NA 2980 0 NA ## 7 1760006 35.7 140. 2 NA NA 850 0 NA ## 8 1010021 35.7 140. 4 NA NA 2000 3 3.33 ## 9 1000006 35.7 140. 1 NA NA 1000 2 2.5 ## 10 1140002 35.8 140. 2 NA NA 2000 0 NA ## # … with 6,282 more rows &amp;を使って複数の条件を使うことも可能です。たとえば、ID変数に加えて「\"L\"で始まる変数の中でnumeric型の列を抽出」するコードは以下のようになります。 # IDと、Lで始まるnumeric型の列を抽出する df %&gt;% select(ID, starts_with(&quot;L&quot;) &amp; where(is.numeric)) ## # A tibble: 6,292 × 3 ## ID Latitude Longitude ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 e539604 35.7 140. ## 2 gfeb600 35.7 140. ## 3 ggt5900 35.8 140. ## 4 g181340 35.7 139. ## 5 ggww100 35.7 140. ## 6 gdzk500 35.7 140. ## 7 ga2g202 35.7 140. ## 8 gg9m100 35.7 140. ## 9 gdvk200 35.7 140. ## 10 gggb200 35.8 140. ## # … with 6,282 more rows 12.4 行の抽出 12.4.1 指定した行を抽出する 他にも特定の行を抽出する場合があります。たとえば、「dfの最初の5行」や「dfの8行目のケース」といった場合です。この操作には{dplyr}のslice_*()関数群が便利です。それではそれぞれの関数の使い方について紹介していきます。その前に、実習用データとしてdfから一部の列のみを抽出したselect_dfを作成します。 select_df &lt;- df %&gt;% select(ID, Name, Pref, Budget, Score) slice(): 指定した番号の行のみ抽出する select_dfから2, 8, 9行目の行を抽出したいとします。このような簡単な操作はパッケージを使わず、以下のように抽出することができます。 # select_dfから2, 8, 9行目の行を抽出し、出力する select_df[c(2, 8, 9),] ## # A tibble: 3 × 5 ## ID Name Pref Budget Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 gfeb600 本格上海料理 新錦江 上野御徒町本店 東京都 2000 4.5 ## 2 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店 東京都 2000 3.33 ## 3 gdvk200 中国料理 宝龍 東京都 1000 2.5 しかし、以下のslice()関数を使うとパイプ演算子を前後に付けることが可能であり71、コードの可読性も高いです。slice()関数には以下のように抽出したい行の番号を入れるだけです。 # select_dfから2, 8, 9行目の行を抽出し、出力する select_df %&gt;% slice(2, 8, 9) # slice(c(2, 8, 9))もOK ## # A tibble: 3 × 5 ## ID Name Pref Budget Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 gfeb600 本格上海料理 新錦江 上野御徒町本店 東京都 2000 4.5 ## 2 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店 東京都 2000 3.33 ## 3 gdvk200 中国料理 宝龍 東京都 1000 2.5 slice(2, 8, 9)でもslice(c(2, 8, 9))でも構いません。また、隣接した行でしたら:を使うことも可能です。たとえば、10行目から15行目まで抽出する場合はslice(10:15)のような書き方も出来ます。 slice_head(): 最初のn行を抽出する # select_dfから最初の3行抽出し、出力する select_df %&gt;% slice_head(n = 3) ## # A tibble: 3 × 5 ## ID Name Pref Budget Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 e539604 居酒屋 龍記 京橋店 東京都 3000 NA ## 2 gfeb600 本格上海料理 新錦江 上野御徒町本店 東京都 2000 4.5 ## 3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ） 東京都 2980 NA これはhead(データ名, n = 出力する個数)と同じ動きをする関数です。注意点としては引数n =を必ず付ける点です。たとえば、slice_head(3)にすると、select_dfの3行目のみ抽出されます。 slice_tail(): 最後のn行を抽出する # select_dfから最後の7行を抽出し、出力する select_df %&gt;% slice_tail(n = 7) ## # A tibble: 7 × 5 ## ID Name Pref Budget Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5508852 場鶴 和歌山県 NA NA ## 2 7113351 来来亭 橋本店 和歌山県 NA NA ## 3 6364939 ばり馬 和歌山紀三井寺店 和歌山県 NA NA ## 4 7103349 ramen BIRDMAN 和歌山県 NA NA ## 5 7315303 薩摩ラーメン 斗天王 和歌山県 NA NA ## 6 7703472 まるしげ 和歌山県 NA NA ## 7 6395035 暴豚製麺所 和歌山県 NA NA これはtail(データ名, n = 出力する個数)と同じ動きをする関数です。ちなみに、このn引数もn =を明記する必要があります。 slice_max(): 指定した変数が大きい順でn行抽出する slice_max()は指定した変数が大きい順でn行抽出する関数です。たとえば、Budgetが高い順で4店舗を抽出する場合は以下のように書きます。 # select_dfからScoreの値が高い順で5行を抽出し、出力する select_df %&gt;% slice_max(Budget, n = 4) ## # A tibble: 4 × 5 ## ID Name Pref Budget Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 g670609 横浜ベイシェラトン ホテル＆タワーズ 中国料理 彩龍 神奈川… 8000 NA ## 2 g910420 JASMINE 憶江南 東京都 7000 NA ## 3 7176666 赤坂焼鳥 鳳 東京都 7000 NA ## 4 b612800 羽衣 銀座本店 東京都 6000 NA slice_min(): 指定した変数が小さい順でn行抽出する 一方、slice_min()関数が小さい順で抽出します。 # select_dfからScoreの値が低い順で3行を抽出し、出力する select_df %&gt;% slice_min(Score, n = 3) ## # A tibble: 4 × 5 ## ID Name Pref Budget Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6384909 葛西大勝軒 東京都 NA 1 ## 2 6929243 由丸 アトレヴィ大塚店 東京都 NA 1 ## 3 5816075 ラーメン戯拉戯拉 千葉県 NA 1 ## 4 5495086 らあめん花月嵐 坂戸わかば店 埼玉県 NA 1 ただし、n = 3と指定したはずなのに、4行が抽出されました。これは同点のケースがあるからです。実際、select_dfにはScoreが1のケースが4つあります。もし、同点の存在によりnに収まらない場合、slice_max()、slice_min()関数はnを超える行を出力します。これを強制的にn行に合わせるためにはwith_ties = FALSE引数を付けます。この場合、データで格納されている順でn個のみ出力されます。 select_df %&gt;% slice_min(Score, n = 3, with_ties = FALSE) ## # A tibble: 3 × 5 ## ID Name Pref Budget Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 6384909 葛西大勝軒 東京都 NA 1 ## 2 6929243 由丸 アトレヴィ大塚店 東京都 NA 1 ## 3 5816075 ラーメン戯拉戯拉 千葉県 NA 1 slice_sample(): 無作為にn行を抽出する 最後に無作為にn行を抽出するslice_sample()関数です。引数はnであり、抽出したい行数を指定します。たとえば、select_dfから無作為に10行抽出したい場合は、 # select_dfから無作為に5行を抽出し、出力する select_df %&gt;% slice_sample(n = 10) ## # A tibble: 10 × 5 ## ID Name Pref Budget Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 7665621 博多ラーメン鶴亀堂 三郷店 埼玉県 NA NA ## 2 5508719 サッポロ 和歌山県 NA NA ## 3 7628249 一風堂 湘南シーサイド店 神奈川県 NA 4.5 ## 4 7345157 ラーメン魁力屋 弘明寺店 神奈川県 NA 3 ## 5 7377118 一蘭 京都河原町店 京都府 800 3.75 ## 6 7686737 全国らーめん 東京都 NA NA ## 7 7677045 油そば専門店 ぶらぶら 秋葉原店 東京都 NA NA ## 8 5508023 梁香亭 兵庫県 NA NA ## 9 5495361 横浜家系千種家 千葉県 NA NA ## 10 5506809 但馬ラーメン 春日森店 京都府 NA NA のように書きます。ブートストラップ法や機械学習における交差検証 (cross-validation)の際に有用な関数ですが、ブートストラップや機械学習のパッケージの多くはサンプル分割の関数を提供しているため、あまり使う機会はないでしょう。また、slice_sample()関数をブートストラップ法のために用いる場合は、ケースを反復抽出する必要があり、replace = TRUEを付けると反復抽出を行います。デフォルト値はFALSEです。 12.4.2 条件に合致する行を抽出する これまで見てきたslice()を用いる行の抽出は、実際あまり使う機会がありません。多くの場合、「何かの条件と合致するケースのみ抽出する」または、「何かの条件と合致しないケースのみを抽出する」やこれらの組み合わせで行の抽出を行います。そこで登場するのが{dplyr}パッケージのfilter()関数です。filter()関数の使い方は以下の通りです。 # dplyr::filter()の使い方 filter(データフレーム名, 条件1, 条件2, ...) むろん、第一引数がデータですから、%&gt;%を使うことも可能です。 # dplyr::filter()の使い方 (パイプを使う方法) データフレーム名 %&gt;% filter(条件1, 条件2, ...) まずは、条件が一つの場合を考えてみましょう。ここでは「Prefが\"京都府\"であるケースのみに絞り、NameとStation、Score列のみを出力する」ケースを考えてみましょう。まず、filter()関数で行を抽出し、続いてselect()関数で抽出する列を指定します。むろん、今回の場合、filter()とselect()の順番は替えても構いません。 # dfからPrefが&quot;京都府&quot;であるケースのみ残し、df2という名で保存 df2 &lt;- df %&gt;% filter(Pref == &quot;京都府&quot;) # df2からName, Station, Score列を抽出 df2 %&gt;% select(Name, Station, Score) ## # A tibble: 414 × 3 ## Name Station Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 中国料理 鳳麟 くいな橋駅 NA ## 2 黒毛和牛一頭買い焼肉と 炊き立て土鍋ご飯 市場小路 烏丸店 四条駅 3.19 ## 3 京の中華 ハマムラ みやこみち店 京都駅 NA ## 4 焼肉処 真 桂店 桂駅 NA ## 5 祇園京都ラーメン 祇園四条駅 NA ## 6 創作料理 串カツ トンカツ jiro 新田辺駅 NA ## 7 祇園 晩餐のあと 祇園四条駅 NA ## 8 DETAIL 東山駅 NA ## 9 めんや龍神 北大路駅 NA ## 10 無尽蔵 京都八条家 京都駅 3.5 ## # … with 404 more rows これはdfからPref == \"京都府\"のケースのみ残したものをdf2として格納し、それをまたselect()関数を使って列を抽出するコードです。これでも問題ありませんが、これだとパイプ演算子の便利さが分かりません。パイプ演算子は複数使うことが可能です。 df %&gt;% filter(Pref == &quot;京都府&quot;) %&gt;% select(Name, Station, Score) ## # A tibble: 414 × 3 ## Name Station Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 中国料理 鳳麟 くいな橋駅 NA ## 2 黒毛和牛一頭買い焼肉と 炊き立て土鍋ご飯 市場小路 烏丸店 四条駅 3.19 ## 3 京の中華 ハマムラ みやこみち店 京都駅 NA ## 4 焼肉処 真 桂店 桂駅 NA ## 5 祇園京都ラーメン 祇園四条駅 NA ## 6 創作料理 串カツ トンカツ jiro 新田辺駅 NA ## 7 祇園 晩餐のあと 祇園四条駅 NA ## 8 DETAIL 東山駅 NA ## 9 めんや龍神 北大路駅 NA ## 10 無尽蔵 京都八条家 京都駅 3.5 ## # … with 404 more rows 全く同じ結果ですが、無駄にdf2というデータフレームを作らず済むので、メモリの観点からも嬉しいですし、何よりコードが短く、しかも可読性も上がりました。 今回は==を使って合致するものに絞りましたが、!=を使って合致しないものに絞ることも可能です。または、比較演算子 (&lt;、&gt;、&gt;=、&lt;=など)を使うことも可能です。それでは、組み込み数 (ScoreN)が0ではないケースを取り出し、Name、Station、ScoreN、Score列を出力させてみましょう。 df %&gt;% filter(ScoreN != 0) %&gt;% select(Name, Station, starts_with(&quot;Score&quot;)) ## # A tibble: 1,344 × 4 ## Name Station ScoreN Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 本格上海料理 新錦江 上野御徒町本店 仲御徒町駅 2 4.5 ## 2 宴会個室×餃子酒場 北京飯店 秋葉原本店 秋葉原駅 3 3.33 ## 3 中国料理 宝龍 有楽町駅 2 2.5 ## 4 麺達 うま家 高田馬場駅 2 3 ## 5 刀削麺・火鍋・西安料理 XI’AN（シーアン） 後楽園店 後楽園駅 1 NA ## 6 七志らーめん 渋谷道玄坂店 渋谷駅 7 4.5 ## 7 永楽 京成小岩駅 6 4.42 ## 8 よってこや お台場店 お台場海浜公… 1 4 ## 9 ラーメン武藤製麺所 竹ノ塚駅 4 3.5 ## 10 桂花ラーメン 新宿末広店 新宿三丁目駅 8 3 ## # … with 1,334 more rows これで口コミ数が1以上の店舗のみに絞ることができました。ただし、店によっては口コミはあっても、評価 (Score)が付いていないところもあります。たとえば、「刀削麺・火鍋・西安料理 XI’AN（シーアン） 後楽園店」の場合、口コミはありますが、評価はありません。したがって、今回は評価が付いている店舗に絞ってみましょう。 df %&gt;% filter(Score != NA) %&gt;% select(Name, Station, starts_with(&quot;Score&quot;)) ## # A tibble: 0 × 4 ## # … with 4 variables: Name &lt;chr&gt;, Station &lt;chr&gt;, ScoreN &lt;dbl&gt;, Score &lt;dbl&gt; あらら、何の結果も表示されませんでした。これはfilter()内の条件に合致するケースが存在しないことを意味します。しかし、先ほどの結果を見ても、評価が付いている店はいっぱいありましたね。これはなぜでしょう。 察しの良い読者さんは気づいているかと思いますが、第8.8章で説明した通り、NAか否かを判定する際は==や!=は使えません。is.na()を使います。filter(is.na(Score))なら「ScoreがNAであるケースに絞る」ことを意味しますが、今回は「ScoreがNAでないケースに絞る」ことが目的ですので、is.na()の前に!を付けます。 df %&gt;% filter(!is.na(Score)) %&gt;% select(Name, Station, starts_with(&quot;Score&quot;)) ## # A tibble: 1,134 × 4 ## Name Station ScoreN Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 本格上海料理 新錦江 上野御徒町本店 仲御徒町駅 2 4.5 ## 2 宴会個室×餃子酒場 北京飯店 秋葉原本店 秋葉原駅 3 3.33 ## 3 中国料理 宝龍 有楽町駅 2 2.5 ## 4 麺達 うま家 高田馬場駅 2 3 ## 5 七志らーめん 渋谷道玄坂店 渋谷駅 7 4.5 ## 6 永楽 京成小岩駅 6 4.42 ## 7 よってこや お台場店 お台場海浜公園駅 1 4 ## 8 ラーメン武藤製麺所 竹ノ塚駅 4 3.5 ## 9 桂花ラーメン 新宿末広店 新宿三丁目駅 8 3 ## 10 北斗 新橋店 新橋駅 4 2.5 ## # … with 1,124 more rows これで口コミ評価が登録された店舗に絞ることができました。 続いて、複数の条件を持つケースを考えてみましょう。例えば、「京都府内の店舗で、口コミ評価が3.5以上の店舗」を出力したい場合、以下のようなコードとなります。 df %&gt;% filter(Pref == &quot;京都府&quot;, Score &gt;= 3.5) %&gt;% select(Name, Station, ScoreN, Score) ## # A tibble: 53 × 4 ## Name Station ScoreN Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 無尽蔵 京都八条家 京都駅 2 3.5 ## 2 一蘭 京都河原町店 河原町駅 2 3.75 ## 3 ミスター・ギョーザ 西大路駅 8 4.06 ## 4 一蘭 京都八幡店 樟葉駅 3 4 ## 5 中華料理 清華園 京都駅 3 5 ## 6 まがり &lt;NA&gt; 2 4 ## 7 魁力屋 北山店 北大路駅 2 4.25 ## 8 大中BAL横店 &lt;NA&gt; 7 4.1 ## 9 こうちゃん 西舞鶴駅 1 5 ## 10 大黒ラーメン 伏見桃山駅 4 4.25 ## # … with 43 more rows 条件をfilter()内に追加するだけです。今回は!is.na(Score)は不要です。なぜなら、Score &gt;= 3.5という条件で既に欠損値は対象外になるからです。条件文が複数ある場合、ANDかORかを指定する必要があります。つまり、条件文AとBがある場合、「AとB両方満たすものを出力する」か「AとBどちらかを満たすものを出力するか」を指定する必要があります。今の結果ってANDでしたよね。filter()関数は、別途の指定がない場合、全てAND扱いになります。RのAND演算子は&amp;ですので、以上のコードは以下のコードと同じです。 df %&gt;% filter(Pref == &quot;京都府&quot; &amp; Score &gt;= 3.5) %&gt;% select(Name, Station, ScoreN, Score) ## # A tibble: 53 × 4 ## Name Station ScoreN Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 無尽蔵 京都八条家 京都駅 2 3.5 ## 2 一蘭 京都河原町店 河原町駅 2 3.75 ## 3 ミスター・ギョーザ 西大路駅 8 4.06 ## 4 一蘭 京都八幡店 樟葉駅 3 4 ## 5 中華料理 清華園 京都駅 3 5 ## 6 まがり &lt;NA&gt; 2 4 ## 7 魁力屋 北山店 北大路駅 2 4.25 ## 8 大中BAL横店 &lt;NA&gt; 7 4.1 ## 9 こうちゃん 西舞鶴駅 1 5 ## 10 大黒ラーメン 伏見桃山駅 4 4.25 ## # … with 43 more rows AND演算子 (&amp;)が使えるということはOR演算子 (|)も使えることを意味します。たとえば、Stationが\"高田馬場駅\"か\"三田駅\"の条件を指定したい場合、 df %&gt;% filter(Station == &quot;高田馬場駅&quot; | Station == &quot;三田駅&quot;) %&gt;% select(Name, Station, ScoreN, Score) ## # A tibble: 14 × 4 ## Name Station ScoreN Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 麺達 うま家 高田馬場駅 2 3 ## 2 らぁ麺 やまぐち 高田馬場駅 7 4.08 ## 3 博多一瑞亭 三田店 三田駅 0 NA ## 4 つけ麺屋 ひまわり 高田馬場駅 4 2.75 ## 5 石器ラーメン 高田馬場 高田馬場駅 0 NA ## 6 旨辛らーめん 表裏 高田馬場駅 0 NA ## 7 三歩一 高田馬場駅 8 4.56 ## 8 えぞ菊 戸塚店 高田馬場駅 4 3.62 ## 9 麺屋 宗 高田馬場駅 5 4.2 ## 10 とんこつラーメン 博多風龍 高田馬場店 高田馬場駅 2 3 ## 11 横浜家系ラーメン 馬場壱家 高田馬場駅 0 NA ## 12 らーめん よし丸 高田馬場駅 1 5 ## 13 札幌ラーメン どさん子 三田店 三田駅 0 NA ## 14 天下一品 三田店 三田駅 0 NA のように書きます（ちなみに高田馬場の「やまぐち」は本当に美味しいです）。むろん、複数の変数を用いたORも可能です。たとえば、「Prefが\"京都府\"かScoreが3以上」のような条件も可能ですが (Pref == \"京都府\" | Score &gt;= 3)、実際、このような例はあまりありません。よく使うのは「変数Xがaかbかcか」のような例です。ただし、この場合は|を使わないもっと簡単な方法があります。それは第10.4章で紹介した%in%演算子です。以下のコードは上のコードと同じものです。 df %&gt;% filter(Station %in% c(&quot;高田馬場駅&quot;, &quot;三田駅&quot;)) %&gt;% select(Name, Station, ScoreN, Score) ## # A tibble: 14 × 4 ## Name Station ScoreN Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 麺達 うま家 高田馬場駅 2 3 ## 2 らぁ麺 やまぐち 高田馬場駅 7 4.08 ## 3 博多一瑞亭 三田店 三田駅 0 NA ## 4 つけ麺屋 ひまわり 高田馬場駅 4 2.75 ## 5 石器ラーメン 高田馬場 高田馬場駅 0 NA ## 6 旨辛らーめん 表裏 高田馬場駅 0 NA ## 7 三歩一 高田馬場駅 8 4.56 ## 8 えぞ菊 戸塚店 高田馬場駅 4 3.62 ## 9 麺屋 宗 高田馬場駅 5 4.2 ## 10 とんこつラーメン 博多風龍 高田馬場店 高田馬場駅 2 3 ## 11 横浜家系ラーメン 馬場壱家 高田馬場駅 0 NA ## 12 らーめん よし丸 高田馬場駅 1 5 ## 13 札幌ラーメン どさん子 三田店 三田駅 0 NA ## 14 天下一品 三田店 三田駅 0 NA 結局、|が使われるケースがかなり限定されます。あるとすれば、「変数Xがa以下か、b以上か」のようなケースですね。ただし、&amp;と|を同時に使うケースは考えられます。たとえば、大阪駅と京都駅周辺のうまいラーメン屋を調べるとします。問題は美味しさの基準ですが、3.5点以上としましょう。ただし、京都府民はラーメンに非常に厳しく、3点以上なら美味しいと仮定します。この場合、「(Stationが\"大阪駅\"かつScore &gt;= 3.5)、または(Stationが\"京都駅\"かつScore &gt;= 3)」のような条件が必要になります。()は「()の中から判定せよ」という、普通の算数での使い方と同じです。それでは、実際に検索してみましょう。 df %&gt;% filter((Station == &quot;大阪駅&quot; &amp; Score &gt;= 3.5) | (Station == &quot;京都駅&quot; &amp; Score &gt;= 3)) %&gt;% select(Name, Station, Walk, ScoreN, Score) ## # A tibble: 6 × 5 ## Name Station Walk ScoreN Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Lei can ting 大阪ルクア店 大阪駅 3 3 4 ## 2 神座 ルクア大阪店 大阪駅 1 10 3.94 ## 3 みつか坊主 醸 大阪駅 10 4 5 ## 4 無尽蔵 京都八条家 京都駅 5 2 3.5 ## 5 中華料理 清華園 京都駅 10 3 5 ## 6 ますたに 京都拉麺小路店 京都駅 9 3 3.67 Songが大好きな神座がヒットして嬉しいです。 12.5 行のソート 続いて、行のソートについて解説します。「食べログ」などのレビューサービスを利用する場合、口コミ評価が高い順で見るのが一般的でしょう72。また、サッカーのランキングも多くは1位から下の順位で掲載されるのが一般的です。ここではこのようにある変数の値順に行を並び替える方法について説明します。 ソートには{dplyr}パッケージのarrange()関数を使います。引数は変数名のみです。たとえば、奈良県のラーメン屋を検索してみましょう。並び替える順は駅から近い店舗を上位に、遠い店舗を下位に並べます。このような順は昇順 (ascending)と呼ばれ、ランキング表などでよく見ます。駅から近い順にソートするので、まず最寄りの駅情報が欠損でないことが必要です。また、ラーメン屋の評価も気になるので口コミが1つ以上付いている店舗に絞りましょう。表示する列は店舗名、最寄りの駅、徒歩距離、口コミ数、点数です。 df %&gt;% filter(Pref == &quot;奈良県&quot;, !is.na(Station), ScoreN &gt; 0) %&gt;% select(Name, Station, Walk, ScoreN, Score) %&gt;% arrange(Walk) %&gt;% print(n = Inf) ## # A tibble: 24 × 5 ## Name Station Walk ScoreN Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 麺屋 あまのじゃく 本店 富雄駅 2 2 4.5 ## 2 紀州和歌山らーめんきぶんや 奈良富雄店 富雄駅 4 1 4 ## 3 ラーメン家 みつ葉 富雄駅 4 1 3.5 ## 4 天下一品 新大宮店 新大宮駅 6 1 3 ## 5 麺屋 一徳 天理駅 7 1 3 ## 6 丸源ラーメン 橿原店 金橋駅 8 1 3.5 ## 7 らーめん食堂 よってこや 平群店 元山上口駅 10 1 4 ## 8 天理スタミナラーメン本店 櫟本駅 11 2 3.25 ## 9 博多長浜らーめん夢街道 奈良土橋店 真菅駅 11 1 3.5 ## 10 ぶ～け 奈良駅 11 1 5 ## 11 つけめん らーめん元喜神 押熊店 学研奈良登美ヶ丘駅 12 4 4.12 ## 12 彩華ラーメン 本店 前栽駅 12 5 3.6 ## 13 力皇 天理駅 13 1 3.5 ## 14 らーめん きみちゃん 京終駅 14 2 4.5 ## 15 無鉄砲がむしゃら 帯解駅 15 2 4 ## 16 彩華ラーメン 田原本店 石見駅 15 1 4 ## 17 神座 大和高田店 大和高田駅 17 2 3.75 ## 18 彩華ラーメン 奈良店 尼ヶ辻駅 17 3 4.33 ## 19 彩華ラーメン 桜井店 大福駅 18 1 3 ## 20 天下一品 東生駒店 東生駒駅 19 1 3.5 ## 21 まりお流ラーメン 新大宮駅 20 1 5 ## 22 どうとんぼり神座 奈良柏木店 西ノ京駅 22 1 3 ## 23 河童ラーメン本舗 押熊店 学研奈良登美ヶ丘駅 28 1 4 ## 24 博多長浜らーめん 夢街道 四条大路店 新大宮駅 29 4 2.88 3行まではこれまで習ってきたもので、4行目がソートの関数、arrange()です。引数はソートの基準となる変数で、今回は最寄りの駅からの徒歩距離を表すWalkです。5行目は省略可能ですが、tibbleクラスの場合、10行までしか出力されないので、print(n = Inf)で「すべての行を表示」させます。nを指定することで出力される行数が調整可能です。奈良県のラーメン屋の中で最寄りの駅から最も近い店は「麺屋 あまのじゃく 本店」で徒歩2分でした。京田辺店も駅から約2分ですし、近いですね。ちなみにSongはここの塩とんこつが好きです。世界一こってりなラーメンとも言われる「チョモランマ」で有名な「まりお流ラーメン」は新大宮駅から徒歩20分でかなり遠いことが分かります。 続いて、駅からの距離ではなく、評価が高い順にしてみましょう。評価が高いほど上に来るので、今回は昇順でなく、降順 (descending)でソートする必要があります。arrange()関数は基本的に、指定された変数を基準に昇順でソートします。降順にするためにはdesc()関数を更に用います。たとえば、arrange(desc(変数名))のようにです。それでは実際にやってみましょう。上のコードの4行目をarange(Walk)からarrange(desc(Score))にちょっと修正するだけです。 df %&gt;% filter(Pref == &quot;奈良県&quot;, !is.na(Station), ScoreN &gt; 0) %&gt;% select(Name, Station, Walk, ScoreN, Score) %&gt;% arrange(desc(Score)) %&gt;% print(n = Inf) ## # A tibble: 24 × 5 ## Name Station Walk ScoreN Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 まりお流ラーメン 新大宮駅 20 1 5 ## 2 ぶ～け 奈良駅 11 1 5 ## 3 麺屋 あまのじゃく 本店 富雄駅 2 2 4.5 ## 4 らーめん きみちゃん 京終駅 14 2 4.5 ## 5 彩華ラーメン 奈良店 尼ヶ辻駅 17 3 4.33 ## 6 つけめん らーめん元喜神 押熊店 学研奈良登美ヶ丘駅 12 4 4.12 ## 7 河童ラーメン本舗 押熊店 学研奈良登美ヶ丘駅 28 1 4 ## 8 無鉄砲がむしゃら 帯解駅 15 2 4 ## 9 紀州和歌山らーめんきぶんや 奈良富雄店 富雄駅 4 1 4 ## 10 彩華ラーメン 田原本店 石見駅 15 1 4 ## 11 らーめん食堂 よってこや 平群店 元山上口駅 10 1 4 ## 12 神座 大和高田店 大和高田駅 17 2 3.75 ## 13 彩華ラーメン 本店 前栽駅 12 5 3.6 ## 14 天下一品 東生駒店 東生駒駅 19 1 3.5 ## 15 力皇 天理駅 13 1 3.5 ## 16 博多長浜らーめん夢街道 奈良土橋店 真菅駅 11 1 3.5 ## 17 ラーメン家 みつ葉 富雄駅 4 1 3.5 ## 18 丸源ラーメン 橿原店 金橋駅 8 1 3.5 ## 19 天理スタミナラーメン本店 櫟本駅 11 2 3.25 ## 20 麺屋 一徳 天理駅 7 1 3 ## 21 どうとんぼり神座 奈良柏木店 西ノ京駅 22 1 3 ## 22 彩華ラーメン 桜井店 大福駅 18 1 3 ## 23 天下一品 新大宮店 新大宮駅 6 1 3 ## 24 博多長浜らーめん 夢街道 四条大路店 新大宮駅 29 4 2.88 よく考えてみれば、「評価が同点の場合、どうなるの?」と疑問を抱く方がいるかも知れません。たとえば、7行目の「河童ラーメン本舗 押熊店」と8行目の「無鉄砲がむしゃら」はどれも評価が4点ですが、「河童ラーメン本舗 押熊店」が先に表示されます。そのこれは簡単です。同点の場合、データセット内で上に位置する行が先に表示されます。これを確認するにはwhich()関数を使います。()内に条件文を指定することで、この条件に合致する要素の位置を返します。もし、条件に合致するものが複数あった場合は全ての位置を返します73。 which(df$Name == &quot;河童ラーメン本舗 押熊店&quot;) ## [1] 6021 which(df$Name == &quot;無鉄砲がむしゃら&quot;) ## [1] 6040 データ内に「河童ラーメン本舗 押熊店」がより上に位置することが分かります。「もし同点なら口コミ評価数が多いところにしたい」場合はどうすれば良いでしょうか。これはarrange()内に変数名を足すだけで十分です。 df %&gt;% filter(Pref == &quot;奈良県&quot;, !is.na(Station), ScoreN &gt; 0) %&gt;% select(Name, Station, Walk, ScoreN, Score) %&gt;% arrange(desc(Score), desc(ScoreN)) %&gt;% print(n = Inf) ## # A tibble: 24 × 5 ## Name Station Walk ScoreN Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 まりお流ラーメン 新大宮駅 20 1 5 ## 2 ぶ～け 奈良駅 11 1 5 ## 3 麺屋 あまのじゃく 本店 富雄駅 2 2 4.5 ## 4 らーめん きみちゃん 京終駅 14 2 4.5 ## 5 彩華ラーメン 奈良店 尼ヶ辻駅 17 3 4.33 ## 6 つけめん らーめん元喜神 押熊店 学研奈良登美ヶ丘駅 12 4 4.12 ## 7 無鉄砲がむしゃら 帯解駅 15 2 4 ## 8 河童ラーメン本舗 押熊店 学研奈良登美ヶ丘駅 28 1 4 ## 9 紀州和歌山らーめんきぶんや 奈良富雄店 富雄駅 4 1 4 ## 10 彩華ラーメン 田原本店 石見駅 15 1 4 ## 11 らーめん食堂 よってこや 平群店 元山上口駅 10 1 4 ## 12 神座 大和高田店 大和高田駅 17 2 3.75 ## 13 彩華ラーメン 本店 前栽駅 12 5 3.6 ## 14 天下一品 東生駒店 東生駒駅 19 1 3.5 ## 15 力皇 天理駅 13 1 3.5 ## 16 博多長浜らーめん夢街道 奈良土橋店 真菅駅 11 1 3.5 ## 17 ラーメン家 みつ葉 富雄駅 4 1 3.5 ## 18 丸源ラーメン 橿原店 金橋駅 8 1 3.5 ## 19 天理スタミナラーメン本店 櫟本駅 11 2 3.25 ## 20 麺屋 一徳 天理駅 7 1 3 ## 21 どうとんぼり神座 奈良柏木店 西ノ京駅 22 1 3 ## 22 彩華ラーメン 桜井店 大福駅 18 1 3 ## 23 天下一品 新大宮店 新大宮駅 6 1 3 ## 24 博多長浜らーめん 夢街道 四条大路店 新大宮駅 29 4 2.88 ソートの基準はarrange()内において先に指定された変数の順番となります。「口コミ評価も評価数も同じなら、駅から近いところにしたい」場合は変数が3つとなり、Score、ScoreN、Walkの順で入れます。 df %&gt;% filter(Pref == &quot;奈良県&quot;, !is.na(Station), ScoreN &gt; 0) %&gt;% select(Name, Station, Walk, ScoreN, Score) %&gt;% arrange(desc(Score), desc(ScoreN), Walk) %&gt;% print(n = Inf) ## # A tibble: 24 × 5 ## Name Station Walk ScoreN Score ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ぶ～け 奈良駅 11 1 5 ## 2 まりお流ラーメン 新大宮駅 20 1 5 ## 3 麺屋 あまのじゃく 本店 富雄駅 2 2 4.5 ## 4 らーめん きみちゃん 京終駅 14 2 4.5 ## 5 彩華ラーメン 奈良店 尼ヶ辻駅 17 3 4.33 ## 6 つけめん らーめん元喜神 押熊店 学研奈良登美ヶ丘駅 12 4 4.12 ## 7 無鉄砲がむしゃら 帯解駅 15 2 4 ## 8 紀州和歌山らーめんきぶんや 奈良富雄店 富雄駅 4 1 4 ## 9 らーめん食堂 よってこや 平群店 元山上口駅 10 1 4 ## 10 彩華ラーメン 田原本店 石見駅 15 1 4 ## 11 河童ラーメン本舗 押熊店 学研奈良登美ヶ丘駅 28 1 4 ## 12 神座 大和高田店 大和高田駅 17 2 3.75 ## 13 彩華ラーメン 本店 前栽駅 12 5 3.6 ## 14 ラーメン家 みつ葉 富雄駅 4 1 3.5 ## 15 丸源ラーメン 橿原店 金橋駅 8 1 3.5 ## 16 博多長浜らーめん夢街道 奈良土橋店 真菅駅 11 1 3.5 ## 17 力皇 天理駅 13 1 3.5 ## 18 天下一品 東生駒店 東生駒駅 19 1 3.5 ## 19 天理スタミナラーメン本店 櫟本駅 11 2 3.25 ## 20 天下一品 新大宮店 新大宮駅 6 1 3 ## 21 麺屋 一徳 天理駅 7 1 3 ## 22 彩華ラーメン 桜井店 大福駅 18 1 3 ## 23 どうとんぼり神座 奈良柏木店 西ノ京駅 22 1 3 ## 24 博多長浜らーめん 夢街道 四条大路店 新大宮駅 29 4 2.88 練習問題 "],["datahandling2.html", "13. データハンドリング [基礎編: 拡張] 13.1 記述統計量の計算 13.2 グルーピング 13.3 変数の計算 13.4 行単位の操作 13.5 データの結合 練習問題", " 13. データハンドリング [基礎編: 拡張] 前章ではデータの一部 (subset)を抽出する方法について説明しましたが、本章はデータを拡張する、あるいは全く別のデータが得られるような処理について解説します。後者は主に元のデータを要約し (記述統計量)、その結果を出力する方法で、前者はデータ内の変数に基づき、指定された計算を行った結果を新しい列として追加する方法です。今回も前章と同じデータを使用します。 pacman::p_load(tidyverse) # データのパスは適宜修正すること # 文字化けが生じる場合、以下のコードに書き換える。 # df &lt;- read_csv(&quot;Data/Ramen.csv&quot;, locale = locale(encoding = &quot;utf8&quot;)) df &lt;- read_csv(&quot;Data/Ramen.csv&quot;) データの詳細については第12.3章を参照してください。 13.1 記述統計量の計算 13.1.1 summarise()による記述統計量の計算 ある変数の平均値や標準偏差、最小値、最大値などの記述統計量 (要約統計量)を計算することも可能です。これはsummarize()またはsummarise()関数を使いますが、この関数は後で紹介するgroup_by()関数と組み合わせることで力を発揮します。ここではグルーピングを考えずに、全データの記述統計量を計算する方法を紹介します。 summarise()関数の使い方は以下の通りです。 # summarise()関数の使い方 データフレーム名 %&gt;% summarise(新しい変数名 = 関数名(計算の対象となる変数名)) もし、Score変数の平均値を計算し、その結果をMeanという列にしたい場合は以下のようなコードになります。 df %&gt;% summarise(Mean = mean(Score)) ## # A tibble: 1 × 1 ## Mean ## &lt;dbl&gt; ## 1 NA ただし、mean()関数は欠損値が含まれるベクトルの場合、NAを返します。この場合方法は2つ考えられます。 filter()関数を使ってScoreが欠損しているケースを予め除去する。 na.rm引数を指定し、欠損値を除去した平均値を求める。 ここでは2番目の方法を使います。 df %&gt;% summarise(Mean = mean(Score, na.rm = TRUE)) ## # A tibble: 1 × 1 ## Mean ## &lt;dbl&gt; ## 1 3.66 dfのScore変数の平均値はNAであることが分かります。また、summarise()関数は複数の記述統計量を同時に計算することも可能です。以下はScore変数の平均値、中央値、標準偏差、最小値、最大値、第一四分位点、第三四分位点を計算し、score_descという名のデータフレームに格納するコードです。 score_desc &lt;- df %&gt;% summarize(Mean = mean(Score, na.rm = TRUE), # 平均値 Median = median(Score, na.rm = TRUE), # 中央値 SD = sd(Score, na.rm = TRUE), # 標準偏差 Min = min(Score, na.rm = TRUE), # 最小値 Max = max(Score, na.rm = TRUE), # 最大値 Q1 = quantile(Score, 0.25, na.rm = TRUE), # 第一四分位点 Q3 = quantile(Score, 0.75, na.rm = TRUE)) # 第三四分位点 score_desc ## # A tibble: 1 × 7 ## Mean Median SD Min Max Q1 Q3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3.66 3.58 0.719 1 5 3 4 むろん、複数の変数に対して記述統計量を計算することも可能です。たとえば、平均予算 (Budget)、口コミ数 (ScoreN)、口コミ評価 (Score)の平均値を求めるとしたら、 df %&gt;% summarize(Budget_Mean = mean(Budget, na.rm = TRUE), # 平均予算の平均値 SocreN_Mean = mean(ScoreN, na.rm = TRUE), # 口コミ数の平均値 Score_Mean = mean(Score, na.rm = TRUE)) # 評価の平均値 ## # A tibble: 1 × 3 ## Budget_Mean SocreN_Mean Score_Mean ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1232. 0.537 3.66 のように書きます。実はsummarise()はこれくらいで十分便利です。ただし、以上の操作はもっと簡単なコードに置換できます。ただし、ラムダ式など、やや高度な内容になるため、以下の内容は飛ばして、次の節 (グルーピング)を読んでいただいても構いません。 まずは、複数の変数に対して同じ記述統計量を求める例を考えてみましょう。たとえば、Budget、ScoreN、Scoreに対して平均値を求める例です。これはacross()関数を使うとよりコードが短くなります。まずはacross()関数の書き方から見ましょう。 # across()の使い方 データフレーム名 %&gt;% summarise(across(変数名のベクトル, 記述統計を計算する関数名, 関数の引数)) 変数名のベクトルは長さ1以上のベクトルです。たとえば、Budget、ScoreN、Scoreの場合c(Budget, ScoreN, Score)になります。これはdf内で隣接する変数ですからBudget:Scoreの書き方も使えます。また、where()やany_of()、starts_with()のような関数を使って変数を指定することも可能です。関数名はmeanやsdなどの関数名です。ここは関数名()でななく、関数名であることに注意してください。引数は前の関数に必要な引数です。引数を必要としない関数なら省略可能ですが、na.rm = TRUEなどの引数が必要な場合は指定する必要があります。それではBudget、ScoreN、Scoreの平均値を計算してみましょう。 df %&gt;% summarize(across(Budget:Score, mean, na.rm = TRUE)) ## # A tibble: 1 × 3 ## Budget ScoreN Score ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1232. 0.537 3.66 across()使わない場合、4行必要だったコードが2行になりました。変数が少ない場合はacross()を使わない方が、可読性が高くなる場合もあります。しかし、変数が多くなる場合、可読性がやや落ちてもacross()を使った方が効率的でしょう。 次は、ある変数に対して複数の記述統計量を計算したい場合について考えます。Budget、ScoreN、Score変数の第一四分位点と第三四分位点をacross()を使わずに計算すると家のような7行のコードになります。 df %&gt;% summarize(Budget_Q1 = quantile(Budget, 0.25, na.rm = TRUE), Budget_Q3 = quantile(Budget, 0.75, na.rm = TRUE), ScoreN_Q1 = quantile(ScoreN, 0.25, na.rm = TRUE), ScoreN_Q3 = quantile(ScoreN, 0.75, na.rm = TRUE), Score_Q1 = quantile(Score, 0.25, na.rm = TRUE), Score_Q3 = quantile(Score, 0.75, na.rm = TRUE)) ## # A tibble: 1 × 6 ## Budget_Q1 Budget_Q3 ScoreN_Q1 ScoreN_Q3 Score_Q1 Score_Q3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 800 1000 0 0 3 4 この作業もacross()を使ってより短縮することができます。ここではラムダ式の知識が必要になります。ラムダ関数とは関数名を持たない無名関数 (anonymous functions)を意味しますが、詳細は割愛します。興味のある読者はWikipediaなどを参照してください。簡単にいうとその場で即席に関数を作成し、計算が終わったら破棄する関数です。ただ、Rは基本的にラムダ式を提供しているのではなく、purrrパッケージのラムダ式スタイルを使用します。まずは、書き方から確認します。 # ラムダ式を用いたacross()の使い方 データフレーム名 %&gt;% summarise(across(変数名のベクトル, .fns = list(結果の変数名 = ラムダ式))) 先ほどの書き方と似ていますが、関数を複数書く必要があるため、今回は関数名をlist型にまとめ、.fns引数に指定します。そして、結果の変数名は結果として出力されるデータフレームの列名を指定する引数です。たとえば、Meanにすると結果は元の変数名1_Mean、元の変数名2_Mean…のように出力されます。そして、ラムダ式が実際の関数が入る箇所です。とりあえず今回はコードを走らせ、結果から確認してみましょう。 df %&gt;% summarize(across(Budget:Score, .fns = list(Q1 = ~quantile(.x, 0.25, na.rm = TRUE), Q3 = ~quantile(.x, 0.75, na.rm = TRUE)))) ## # A tibble: 1 × 6 ## Budget_Q1 Budget_Q3 ScoreN_Q1 ScoreN_Q3 Score_Q1 Score_Q3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 800 1000 0 0 3 4 結果の列名がBudget_Q1、Budget_Q3、ScoreN_Q1…のようになり、それぞれの変数の第一四分位点と第三四分位点が出力されます。問題はラムダ式の方ですが、普通の関数に非常に近いことが分かります。across()内のラムダ式は~関数名(.x, その他の引数)のような書き方になります。関数名の前に~が付いていることに注意してください。分位数を求める関数はquantile()であり、quantile(ベクトル, 分位数)であり、必要に応じてna.rmを付けます。この分位数が0.25なら第一四分位点、0.5なら第二四分位点 (=中央値)、0.75なら第三四分位点になります。それではラムダ式~quantile(.x, 0.25, na.rm = TRUE)はどういう意味でしょうか。これは.xの箇所にBudgetやScoreN、Scoreが入ることを意味します。.xという書き方は決まりです。.yとか.Song-san-Daisukiなどはダメです。そして、0.25を付けることによって第一四分位点を出力するように指定します。また、Budget、ScoreN、Scoreに欠損値がある場合、無視するようにna.rm = TRUEを付けます。 ラムダ式を第10章で解説した自作関数で表現すると、以下のようになります。 # 以下の3つは同じ機能をする関数である # ラムダ式 ~quantile(.x, 0.25, na.rm = TRUE) # 一般的な関数の書き方1 名無し関数 &lt;- function(x) { quantile(x, 0.25, na.rm = TRUE) } # 一般的な関数の書き方2 名無し関数 &lt;- function(x) quantile(x, 0.25, na.rm = TRUE) この3つは全て同じですが、ラムダ式は関数名を持たず、その場で使い捨てる関数です。むろん、ラムダ式を使わずに事前に第一四分位点と第三四分位点を求める関数を予め作成し、ラムダ式の代わりに使うことも可能です。まずは第一四分位点と第三四分位点を求める自作関数FuncQ1とFuncQ2を作成します。 # ラムダ式を使わない場合は事前に関数を定義しておく必要がある FuncQ1 &lt;- function(x) { quantile(x, 0.25, na.rm = TRUE) } FuncQ3 &lt;- function(x) { quantile(x, 0.75, na.rm = TRUE) } 後は先ほどのほぼ同じ書き方ですが、今回はラムダ式を使わないため関数名に~を付けず、関数名のみで十分です。()も不要です。 # やっておくと、summarise()文は簡潔になる df %&gt;% summarize(across(Budget:Score, list(Q1 = FuncQ1, Q3 = FuncQ3))) ## # A tibble: 1 × 6 ## Budget_Q1 Budget_Q3 ScoreN_Q1 ScoreN_Q3 Score_Q1 Score_Q3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 800 1000 0 0 3 4 事前に関数を用意するのが面倒ですが、across()の中身はかなりスッキリしますね。もし、このような作業を何回も行うなら、ラムダ式を使わず、自作関数を用いることも可能です。ただし、自作関数であっても引数が2つ以上必要な場合はラムダ式を使います。 13.1.2 summarise()に使える便利な関数 以下の内容は後で説明するgroup_by()関数を使っているため、まだgroup_by()に馴染みのない読者はまずはここを読み飛ばし、グルーピングの節にお進みください。 IQR(): 四分位範囲を求める 四分位範囲は第三四分位点から第一四分位点を引いた値であり、Rの内蔵関数であるIQR()を使えば便利です。この関数はmeanやsd()関数と同じ使い方となります。 df %&gt;% filter(!is.na(Walk)) %&gt;% # 予め欠損したケースを除くと、後でna.rm = TRUEが不要 group_by(Pref) %&gt;% summarise(Mean = mean(Walk), SD = sd(Walk), IQR = IQR(Walk), N = n(), .groups = &quot;drop&quot;) %&gt;% arrange(Mean) ## # A tibble: 9 × 5 ## Pref Mean SD IQR N ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 東京都 4.29 4.49 4 919 ## 2 大阪府 5.92 6.08 6 932 ## 3 神奈川県 8.21 7.91 10 878 ## 4 京都府 8.38 6.95 9 339 ## 5 兵庫県 8.52 7.27 10 484 ## 6 奈良県 10.6 6.59 10 123 ## 7 千葉県 10.6 8.21 12 776 ## 8 埼玉県 11.6 8.99 14 817 ## 9 和歌山県 12.8 6.83 9 107 first()、last()、nth(): n番目の要素を求める 稀なケースかも知れませんが、データ内、またはグループ内のn番目の行を抽出する時があります。たとえば、市区町村の情報が格納されているデータセットで、人口が大きい順でデータがソートされているとします。各都道府県ごとに最も人口が大きい市区町村のデータ、あるいは最も少ない市区町村のデータが必要な際、first()とlast()関数が有効です。 それでは各都道府県ごとに「最も駅から遠いラーメン屋」の店舗名と最寄りの駅からの徒歩距離を出力したいとします。まずは、徒歩距離のデータが欠損しているケースを除去し、データを徒歩距離順でソートします。これはfilter()とarrange()関数を使えば簡単です。続いて、group_by()を使って都府県単位でデータをグループ化します。最後にsummarise()関数内にlast()関数を使います。データは駅から近い順に鳴っているため、各都府県内の最後の行は駅から最も遠い店舗になるからです。 df %&gt;% filter(!is.na(Walk)) %&gt;% arrange(Walk) %&gt;% group_by(Pref) %&gt;% summarise(Farthest = last(Name), Distance = last(Walk)) ## # A tibble: 9 × 3 ## Pref Farthest Distance ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 京都府 熱烈らぁめん 30 ## 2 兵庫県 濃厚醤油 中華そば いせや 玉津店 43 ## 3 千葉県 札幌ラーメン どさん子 佐原51号店 59 ## 4 和歌山県 中華そば まる乃 30 ## 5 埼玉県 札幌ラーメン どさん子 小鹿野店 116 ## 6 大阪府 河童ラーメン本舗 岸和田店 38 ## 7 奈良県 博多長浜らーめん 夢街道 四条大路店 29 ## 8 東京都 てんがら 青梅新町店 30 ## 9 神奈川県 札幌ラーメン どさん子 中津店 73 このlast()をfirst()に変えると、最寄りの駅から最も近い店舗情報が表示されます。また、「n番目の情報」が必要な際はnth()関数を使います。nth(Name, 2)に変えることで2番目の店舗名が抽出できます。 n_distinct(): ユニーク値の個数を求める n_distinct()は何種類の要素が含まれているかを計算する関数であり、length(unique())関数と同じ機能をします。たとえば、以下のmyVec1に対して何種類の要素があるかを確認してみましょう。 myVec1 &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;B&quot;, &quot;D&quot;, &quot;A&quot;, &quot;B&quot;, &quot;D&quot;, &quot;C&quot;, &quot;A&quot;) unique(myVec1) ## [1] &quot;A&quot; &quot;B&quot; &quot;D&quot; &quot;C&quot; myVec1は\"A\"、\"B\"、\"D\"、\"C\"の要素で構成されていることが分かります。これがmyVec1のユニーク値 (unique values)です。そして、このユニーク値の個数を調べるためにlength()を使います。 length(unique(myVec1)) ## [1] 4 これでmyVec1は4種類の値が存在することが分かります。これと全く同じ機能をする関数がn_distinct()です。 n_distinct(myVec1) ## [1] 4 この関数をsummarise()に使うことで、都府県ごとに駅の個数が分かります。あるいは「東京都内の選挙区に、これまでの衆院選において何人の候補者が存在したか」も分かります。ここではdf内の都府県ごとに駅の個数を計算してみましょう。最後の駅数が多い順でソートします。 df %&gt;% filter(!is.na(Station)) %&gt;% # 最寄りの駅が欠損しているケースを除去 group_by(Pref) %&gt;% summarise(N_Station = n_distinct(Station), .groups = &quot;drop&quot;) %&gt;% arrange(desc(N_Station)) ## # A tibble: 9 × 2 ## Pref N_Station ## &lt;chr&gt; &lt;int&gt; ## 1 東京都 368 ## 2 大阪府 341 ## 3 千葉県 241 ## 4 神奈川県 240 ## 5 兵庫県 199 ## 6 埼玉県 185 ## 7 京都府 123 ## 8 奈良県 52 ## 9 和歌山県 46 当たり前かも知れませんが、駅数が最も多いのは東京都で次が大阪府であることが分かります。 any()、all(): 条件に合致するか否かを求める any()とall()はベクトル内の全要素に対して条件に合致するか否かを判定する関数です。ただし、any()は一つの要素でも条件に合致すればTRUEを、全要素が合致しない場合FALSEを返します。一方、all()は全要素に対して条件を満たせばTRUE、一つでも満たさない要素があればFALSEを返します。以下はany()とall()の例です。 myVec1 &lt;- c(1, 2, 3, 4, 5) myVec2 &lt;- c(1, 3, 5, 7, 11) any(myVec1 %% 2 == 0) # myVec1を2で割った場合、一つでも余りが0か ## [1] TRUE all(myVec1 %% 2 == 0) # myVec1を2で割った場合、全ての余りが0か ## [1] FALSE all(myVec2 %% 2 != 0) # myVec2を2で割った場合、全ての余りが0ではないか ## [1] TRUE それでは実際にdfに対してany()とall()関数を使ってみましょう。一つ目は「ある都府県に最寄りの駅から徒歩60分以上の店舗が一つでもあるか」であり、二つ目は「ある都府県の店舗は全て最寄りの駅から徒歩30分以下か」です。それぞれの結果をOver60とWithin30という列で出力してみましょう。 df %&gt;% group_by(Pref) %&gt;% summarise(Over60 = any(Walk &gt;= 60, na.rm = TRUE), Within30 = all(Walk &lt;= 30, na.rm = TRUE), .groups = &quot;drop&quot;) ## # A tibble: 9 × 3 ## Pref Over60 Within30 ## &lt;chr&gt; &lt;lgl&gt; &lt;lgl&gt; ## 1 京都府 FALSE TRUE ## 2 兵庫県 FALSE FALSE ## 3 千葉県 FALSE FALSE ## 4 和歌山県 FALSE TRUE ## 5 埼玉県 TRUE FALSE ## 6 大阪府 FALSE FALSE ## 7 奈良県 FALSE TRUE ## 8 東京都 FALSE TRUE ## 9 神奈川県 TRUE FALSE 埼玉県と神奈川県において、最寄りの駅から徒歩60以上の店がありました。また、京都府、東京都、奈良県、和歌山県の場合、全店舗が最寄りの駅から徒歩30分以下ということが分かります。当たり前ですがOver60がTRUEならWithin30は必ずFALSEになりますね。 13.2 グルーピング 13.2.1 group_by()によるグループ化 先ほどのsummarise()関数は確かに便利ですが、特段に便利とも言いにくいです。dfのScoreの平均値を計算するだけなら、summarise()関数を使わない方が楽です。 # これまでのやり方 df %&gt;% summarise(Mean = mean(Score, na.rm = TRUE)) ## # A tibble: 1 × 1 ## Mean ## &lt;dbl&gt; ## 1 3.66 # 普通にこれでええんちゃう? mean(df$Score, na.rm = TRUE) ## [1] 3.663457 しかし、これをグループごとに計算するならどうでしょう。たとえば、Scoreの平均値を都府県ごとに計算するとします。この場合、以下のようなコードになります。 mean(df$Score[df$Pref == &quot;東京都&quot;], na.rm = TRUE) ## [1] 3.674256 mean(df$Score[df$Pref == &quot;神奈川県&quot;], na.rm = TRUE) ## [1] 3.533931 mean(df$Score[df$Pref == &quot;千葉県&quot;], na.rm = TRUE) ## [1] 3.715983 mean(df$Score[df$Pref == &quot;埼玉県&quot;], na.rm = TRUE) ## [1] 3.641573 mean(df$Score[df$Pref == &quot;大阪府&quot;], na.rm = TRUE) ## [1] 3.765194 mean(df$Score[df$Pref == &quot;京都府&quot;], na.rm = TRUE) ## [1] 3.684976 mean(df$Score[df$Pref == &quot;兵庫県&quot;], na.rm = TRUE) ## [1] 3.543936 mean(df$Score[df$Pref == &quot;奈良県&quot;], na.rm = TRUE) ## [1] 3.854762 mean(df$Score[df$Pref == &quot;和歌山県&quot;], na.rm = TRUE) ## [1] 3.96999 変わったのはdf$Scoreがdf$Score[df$Pref == \"東京都\"]に変わっただけです。df$Prefが\"東京都\"であるか否かをTRUEとFALSEで判定し、これを基準にdf$Scoreを抽出する仕組みです。df$Scoreとdf$Prefは同じデータフレームですから、このような書き方で問題ありません。 これだけでもかなり書くのが面倒ですが、これが47都道府県なら、あるいは200ヶ国ならかなり骨の折れる作業でしょう。ここで大活躍するのが{dplyr}パッケージのgroup_by()関数です。引数はグループ化する変数名だけです。先ほどの作業を{dplyr}を使うならPref変数でグループ化し、summarise()関数で平均値を求めるだけです。今回はScoreだけでなく、ScoreNの平均値も求めてみましょう。そして、評価が高い順にソートもしてみます。 # ScoreNとScoreの平均値をPrefごとに求める df %&gt;% group_by(Pref) %&gt;% summarise(ScoreN_Mean = mean(ScoreN, na.rm = TRUE), Score_Mean = mean(Score, na.rm = TRUE)) %&gt;% arrange(desc(Score_Mean)) ## # A tibble: 9 × 3 ## Pref ScoreN_Mean Score_Mean ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 和歌山県 0.593 3.97 ## 2 奈良県 0.306 3.85 ## 3 大阪府 0.516 3.77 ## 4 千葉県 0.259 3.72 ## 5 京都府 0.522 3.68 ## 6 東京都 1.16 3.67 ## 7 埼玉県 0.278 3.64 ## 8 兵庫県 0.389 3.54 ## 9 神奈川県 0.587 3.53 評判が最も高い都府県は和歌山県、最も低いのは神奈川県ですね。Songも和歌山ラーメンは井出系も車庫前系も好きです。しかし、大事なのは「井出系」と「車庫前系」といった分類が正しいかどうかではありません。コードが非常に簡潔となり、ソートなども自由自在であることです。都府県ごとにScoreNとScoreの平均値を求める場合、dplyr()を使わなかったら18行のコードとなり、ソートも自分でやる必要があります。一方、group_by()関数を使うことによってコードが5行になりました。 また、これは2020年6月に公開された{dplyr}1.0.0からの問題ですが、group_by()の後にsummarise()を使うと以下のようなメッセージが出力されます。 ## `summarise()` ungrouping output (override with `.groups` argument) これはgroup_by()で指定された変数のグループ化が自動的に解除されたことを意味します。なぜならsummarise()をする際はPrefをグループ変数として使いましたが、出力された結果のPref変数はもはやグループとして機能できなくなるからです。元のdfにはPrefが\"東京都\"だったケースが1000行、\"京都府\"だったのが414行あったので、Pref変数でグループ化する意味がありました。しかし、summarise()から得られたデータフレームはPref == \"東京都\"の行が1つしかありません。これはグループ化する意味がなくなったことを意味します。したがって、自動的にグループを解除してくれます。自動的にやってくれるのはありがたいことですが、可能ならば関数内に自分で明記することが推奨されます。そこで使う引数が.groupsであり、\"drop\"を指定すると全てのグループ化変数を解除します。以下のようなコードだと先ほどのメッセージが表示されません。今後、意識的に入れるようにしましょう。 # ScoreNとScoreの平均値をPrefごとに求める df %&gt;% group_by(Pref) %&gt;% summarise(ScoreN_Mean = mean(ScoreN, na.rm = TRUE), Score_Mean = mean(Score, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;% arrange(desc(Score_Mean)) ## # A tibble: 9 × 3 ## Pref ScoreN_Mean Score_Mean ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 和歌山県 0.593 3.97 ## 2 奈良県 0.306 3.85 ## 3 大阪府 0.516 3.77 ## 4 千葉県 0.259 3.72 ## 5 京都府 0.522 3.68 ## 6 東京都 1.16 3.67 ## 7 埼玉県 0.278 3.64 ## 8 兵庫県 0.389 3.54 ## 9 神奈川県 0.587 3.53 続いて、一つ便利な関数を紹介します。それはグループのサイズを計算する関数、n()です。この関数をsummarise()内に使うと、各グループに属するケース数を出力します74。先ほどのコードを修正し、各グループのサイズをNという名の列として追加してみましょう。そしてソートの順番はNを最優先とし、同じ場合はScore_Meanが高い方を上に出力させます。また、ScoreN_Meanの前に、口コミ数の合計も出してみましょう。 # Prefごとに口コミ数の合計、口コミ数の平均値、評価の平均値、店舗数を求める # 店舗数-評価の平均値順でソートする df %&gt;% group_by(Pref) %&gt;% summarise(ScoreN_Sum = sum(ScoreN, na.rm = TRUE), ScoreN_Mean = mean(ScoreN, na.rm = TRUE), Score_Mean = mean(Score, na.rm = TRUE), N = n(), .groups = &quot;drop&quot;) %&gt;% arrange(desc(N), desc(Score_Mean)) ## # A tibble: 9 × 5 ## Pref ScoreN_Sum ScoreN_Mean Score_Mean N ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 大阪府 516 0.516 3.77 1000 ## 2 千葉県 259 0.259 3.72 1000 ## 3 東京都 1165 1.16 3.67 1000 ## 4 埼玉県 278 0.278 3.64 1000 ## 5 神奈川県 587 0.587 3.53 1000 ## 6 兵庫県 230 0.389 3.54 591 ## 7 京都府 216 0.522 3.68 414 ## 8 奈良県 45 0.306 3.85 147 ## 9 和歌山県 83 0.593 3.97 140 記述統計をグループごとに求めるのは普通にあり得るケースですし、実験データの場合はほぼ必須の作業でう。統制群と処置群間においてグループサイズが均一か、共変量のバラツキが十分に小さいかなどを判断する際にgroup_by()とsummarise()関数の組み合わせは非常に便利です。 13.2.2 複数の変数を用いたグループ化 グループ化変数は2つ以上指定することも可能です。たとえば、都府県 (Pref)と最寄りの駅の路線 (Line)でグループ化することも可能です。それではPrefとLineでグループ化し、店舗数と口コミ数、評価の平均値を計算し、ソートの順番は店舗数、店舗数が同じなら評価の平均値が高い順にしましょう。今回もsummarise()内に.group = \"drop\"を指定し、グループ化を解除します。今回はTop 20まで出してみましょう。 # ScoreNとScoreの平均値をPrefごとに求める df %&gt;% filter(!is.na(Line)) %&gt;% # Lineが欠損していないケースのみ残す group_by(Pref, Line) %&gt;% # PrefとLineでグループ化 summarise(N = n(), ScoreN_Sum = sum(ScoreN, na.rm = TRUE), Score_Mean = mean(Score, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;% arrange(desc(N), desc(Score_Mean)) %&gt;% print(n = 20) ## # A tibble: 523 × 5 ## Pref Line N ScoreN_Sum Score_Mean ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 埼玉県 東武東上線 122 27 3.68 ## 2 東京都 ＪＲ 104 231 3.56 ## 3 神奈川県 小田急小田原線 96 31 3.59 ## 4 埼玉県 東武伊勢崎線 96 18 3.51 ## 5 神奈川県 横浜市営ブルーライン 82 77 3.66 ## 6 千葉県 京成本線 82 29 3.34 ## 7 神奈川県 京急本線 68 40 3.33 ## 8 千葉県 東武野田線 63 2 4.75 ## 9 神奈川県 小田急江ノ島線 62 8 3.79 ## 10 大阪府 阪急京都本線 53 32 3.67 ## 11 大阪府 南海本線 52 11 4.22 ## 12 兵庫県 阪神本線 52 23 3.80 ## 13 埼玉県 JR高崎線 51 5 4 ## 14 兵庫県 山陽電鉄本線 51 15 2.98 ## 15 千葉県 JR総武本線（東京-銚子） 47 8 4 ## 16 埼玉県 西武新宿線 45 8 4.17 ## 17 埼玉県 秩父鉄道線 43 10 3.82 ## 18 大阪府 京阪本線 43 10 3.69 ## 19 千葉県 新京成電鉄 43 6 3.6 ## 20 京都府 阪急京都本線 43 27 3.5 ## # … with 503 more rows ぐるなびに登録されているラーメン屋が最も多い路線は埼玉県内の東武東上線で122店舗があります。東武東上線は東京都と埼玉県をまたがる路線ですので、東武東上線だけならもっと多いかも知れませんね。 ここで一つ考えたいのはsummarise()内の.groups引数です。前回はグループ化に使った変数ごとに1行しか残っていなかったのでグループ化を全て解除しました。しかし、今回は状況がやや異なります。グループ化変数に使ったPrefを考えると、まだPref == \"東京都\"であるケースがいくつかあります。やろうとすればまだグループ化出来る状態です。これはLineについても同じです。Line == \"東武東上線\"の行はここには表示されていないものの、まだデータに残っています。もし、これ以上グループ化しないなら今のように.groups = \"drop\"が正しいですが、もしもう一回グループ化したい場合はどうすればよいでしょうか。方法は2つ考えられます。 もう一度パイプ演算子を使ってgroup_by()関数を使う (以下の9行目)。 結果を見ると## # Groups: Pref, Line [523]で、ちゃんとグループ化されていることが分かります。 df %&gt;% filter(!is.na(Line)) %&gt;% group_by(Pref, Line) %&gt;% summarise(N = n(), ScoreN_Sum = sum(ScoreN, na.rm = TRUE), Score_Mean = mean(Score, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;% arrange(desc(N), desc(Score_Mean)) %&gt;% group_by(Pref, Line) %&gt;% # group_by()、もう一度 print(n = 5) ## # A tibble: 523 × 5 ## # Groups: Pref, Line [523] ## Pref Line N ScoreN_Sum Score_Mean ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 埼玉県 東武東上線 122 27 3.68 ## 2 東京都 ＪＲ 104 231 3.56 ## 3 神奈川県 小田急小田原線 96 31 3.59 ## 4 埼玉県 東武伊勢崎線 96 18 3.51 ## 5 神奈川県 横浜市営ブルーライン 82 77 3.66 ## # … with 518 more rows .groups引数を何とかする。 推奨される方法は2番です。具体的には.groups = \"keep\"を指定するだけであり、こっちの方が無駄なコードを省けることができます。 df %&gt;% filter(!is.na(Line)) %&gt;% group_by(Pref, Line) %&gt;% summarise(N = n(), ScoreN_Sum = sum(ScoreN, na.rm = TRUE), Score_Mean = mean(Score, na.rm = TRUE), .groups = &quot;keep&quot;) %&gt;% arrange(desc(N), desc(Score_Mean)) %&gt;% print(n = 5) ## # A tibble: 523 × 5 ## # Groups: Pref, Line [523] ## Pref Line N ScoreN_Sum Score_Mean ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 埼玉県 東武東上線 122 27 3.68 ## 2 東京都 ＪＲ 104 231 3.56 ## 3 神奈川県 小田急小田原線 96 31 3.59 ## 4 埼玉県 東武伊勢崎線 96 18 3.51 ## 5 神奈川県 横浜市営ブルーライン 82 77 3.66 ## # … with 518 more rows .groups引数は\"drop\"と\"keep\"以外にも\"drop_last\"があります。実はsummarise()に.groups引数を指定したい場合のデフォルト値は.groups == \"drop_last\"または\"keep\"ですが、ここがややこしいです。主なケースにおいてデフォルト値は\"drop\"となりますとなります。.groups == \"drop_last\"これは最後のグループ化変数のみ解除する意味です。今回の例だと、2番目のグループ化変数であるLineがグループ化変数から外され、Prefのみがグループ化変数として残る仕組みです。 それではデフォルト値が\"keep\"になるのはいつでしょうか。それは記述統計量の結果が長さ2以上のベクトルである場合です。平均値を求めるmean()、標準偏差を求めるsd()などは、結果として長さ1のベクトルを返します。しかし、長さ2以上ののベクトルを返す関数もあります。たとえば、分位数を求めるquantile()関数があります。quantile(ベクトル名, 0.25)の場合、第一四分位点のみ返すため、結果は長さ1のベクトルです。しかし、quantile(ベクトル名, c(0.25, 0.5, 0.75))のように第一四分位点から第三四分位点を同時に計算し、長さ3のベクトルが返されるケースもありますし、第二引数を省略すると、最小値・第一四分位点・第二四分位点・第三四分位点・最大値、つまり、長さ5のベクトルが返される場合があります。 # 第一四分位点のみを求める (長さ1のベクトル) quantile(df$Walk, 0.25, na.rm = TRUE) ## 25% ## 2 # 引数を省略する (長さ5のベクトル) quantile(df$Walk, na.rm = TRUE) ## 0% 25% 50% 75% 100% ## 1 2 5 12 116 .groupsのデフォルト値が\"keep\"になるのは、このように長さ2以上のベクトルが返されるケースです。たとえば、都府県と最寄りの駅の路線でグループ化し、店舗までの徒歩距離の平均値を求めるとします。デフォルト値の変化を見るために、ここではあえて.groups引数を省略しました。 df %&gt;% filter(!is.na(Walk)) %&gt;% group_by(Pref, Line) %&gt;% summarise(Mean = mean(Walk)) ## `summarise()` has grouped output by &#39;Pref&#39;. You can override using the ## `.groups` argument. ## # A tibble: 509 × 3 ## # Groups: Pref [9] ## Pref Line Mean ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 京都府 ＪＲ 4 ## 2 京都府 ＪＲ京都線 10 ## 3 京都府 JR奈良線 3.33 ## 4 京都府 ＪＲ奈良線 8 ## 5 京都府 JR小浜線 16.5 ## 6 京都府 ＪＲ小浜線 9 ## 7 京都府 ＪＲ山陰本線 19 ## 8 京都府 JR山陰本線（京都-米子） 8.67 ## 9 京都府 ＪＲ山陰本線（京都-米子） 9.23 ## 10 京都府 ＪＲ嵯峨野線 5 ## # … with 499 more rows 最初はPrefとLineでグループ化しましたが、summarise()の後、Lineがグループ化変数から外されました。つまり、引数が\"drop_last\"になっていることです。 それでは、平均値に加えて、第一四分位点と第三四分位点も計算し、Quantileという名で格納してみましょう。 df %&gt;% filter(!is.na(Walk)) %&gt;% group_by(Pref, Line) %&gt;% summarise(Mean = mean(Walk), Quantile = quantile(Walk, c(0.25, 0.75))) ## `summarise()` has grouped output by &#39;Pref&#39;, &#39;Line&#39;. You can override using the ## `.groups` argument. ## # A tibble: 1,018 × 4 ## # Groups: Pref, Line [509] ## Pref Line Mean Quantile ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 京都府 ＪＲ 4 1.25 ## 2 京都府 ＪＲ 4 5 ## 3 京都府 ＪＲ京都線 10 10 ## 4 京都府 ＪＲ京都線 10 10 ## 5 京都府 JR奈良線 3.33 2 ## 6 京都府 JR奈良線 3.33 5 ## 7 京都府 ＪＲ奈良線 8 4 ## 8 京都府 ＪＲ奈良線 8 9 ## 9 京都府 JR小浜線 16.5 9.75 ## 10 京都府 JR小浜線 16.5 23.2 ## # … with 1,008 more rows 同じPref、Lineのケースが2つずつ出来ています。最初に来る数値は第一四分位点、次に来るのが第三四分位点です。そして最初のグループ化変数であったPrefとLineが、summarise()後もグループ化変数として残っていることが分かります。 .groups引数は記述統計量だけを計算する意味ではあまり意識する必要がありません。しかし、得られた記述統計量から何らかの計算をしたり、さらにもう一回記述統計量を求めたりする際、予期せぬ結果が得られる可能性があるため注意する必要があります。出来る限り.groups引数は指定するようにしましょう。 13.3 変数の計算 13.3.1 mutate()関数の使い方 続いて、データフレーム内の変数を用いて計算を行い、その結果を新しい列として格納するmutate()関数について紹介します。mutate()関数は新しい列を追加することが主な目的ですが、既存の列を修正することも可能です。まず、mutate()関数の書き方からです。 # mutate()関数の使い方 データフレーム名 %&gt;% mutate(新しい変数名 = 処理内容) これは何らかの処理を行い、その結果を新しい変数としてデータフレームに追加することを意味します。新しく出来た変数は、基本的に最後の列になります。ここでは分単位であるWalkを時間単位に変換したWalk_Hour変数を作成するとします。処理内容はWalk / 60です。最後に、都府県名、店舗名、徒歩距離 (分)、徒歩距離 (時間)のみを残し、遠い順にソートします。 df %&gt;% filter(!is.na(Walk)) %&gt;% mutate(Walk_Hour = Walk / 60) %&gt;% select(Pref, Name, Walk, Walk_Hour) %&gt;% arrange(desc(Walk_Hour)) ## # A tibble: 5,375 × 4 ## Pref Name Walk Walk_Hour ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 埼玉県 札幌ラーメン どさん子 小鹿野店 116 1.93 ## 2 神奈川県 札幌ラーメン どさん子 中津店 73 1.22 ## 3 千葉県 札幌ラーメン どさん子 佐原51号店 59 0.983 ## 4 神奈川県 札幌ラーメン どさん子 山際店 50 0.833 ## 5 千葉県 札幌ラーメン どさん子 関宿店 49 0.817 ## 6 兵庫県 濃厚醤油 中華そば いせや 玉津店 43 0.717 ## 7 大阪府 河童ラーメン本舗 岸和田店 38 0.633 ## 8 埼玉県 ラーメン山岡家 上尾店 35 0.583 ## 9 兵庫県 濃厚醤油 中華そば いせや 大蔵谷店 35 0.583 ## 10 大阪府 河童ラーメン本舗 松原店 31 0.517 ## # … with 5,365 more rows mutate()は3行目に登場しますが、これはWalkを60に割った結果をWalk_Hourとしてデータフレームの最後の列として格納することを意味します。もし、最後の列でなく、ある変数の前、または後にしたい場合は、.beforeまたは.after引数を追加します。これはselect()関数の.beforeと.afterと同じ使い方です。たとえば、新しく出来たWalk_HourをIDとNameの間に入れたい場合は # コードの3行名を修正 (.before使用) mutate(Walk_Hour = Walk / 60, .before = Name) # コードの3行名を修正 (.after使用) mutate(Walk_Hour = Walk / 60, .after = ID) のようにコードを修正します。 むろん、変数間同士の計算も可能です。たとえば、以下のようなdf2があり、1店舗当たりの平均口コミ数を計算し、ScoreN_Meanという変数名でScoreN_Sumの後に格納うするとします。この場合、ScoreN_Sum変数をNで割るだけです。 df2 &lt;- df %&gt;% group_by(Pref) %&gt;% summarise(Budget_Mean = mean(Budget, na.rm = TRUE), ScoreN_Sum = sum(ScoreN, na.rm = TRUE), Score_Mean = mean(Score, na.rm = TRUE), N = n(), .groups = &quot;drop&quot;) df2 %&gt;% mutate(ScoreN_Mean = ScoreN_Sum / N, .after = ScoreN_Sum) ## # A tibble: 9 × 6 ## Pref Budget_Mean ScoreN_Sum ScoreN_Mean Score_Mean N ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 京都府 1399. 216 0.522 3.68 414 ## 2 兵庫県 1197. 230 0.389 3.54 591 ## 3 千葉県 1124. 259 0.259 3.72 1000 ## 4 和歌山県 1252 83 0.593 3.97 140 ## 5 埼玉県 1147. 278 0.278 3.64 1000 ## 6 大阪府 1203. 516 0.516 3.77 1000 ## 7 奈良県 1169. 45 0.306 3.85 147 ## 8 東京都 1283. 1165 1.16 3.67 1000 ## 9 神奈川県 1239. 587 0.587 3.53 1000 このように、データ内の変数を用いた計算結果を新しい列として追加する場合は、mutate()が便利です。これをmutate()を使わずに処理する場合、以下のようなコードになりますが、可読性が相対的に低いことが分かります。 df2$ScoreN_Mean &lt;- df2$ScoreN_Sum / df2$N df2 &lt;- df2[, c(&quot;Pref&quot;, &quot;Budget_Mean&quot;, &quot;Walk_Mean&quot;, &quot;ScoreN_Sum&quot;, &quot;ScoreN_Mean&quot;, &quot;Score_Mean&quot;, &quot;N&quot;)] むろんですが、計算には+や/のような演算子だけでなく、関数を使うことも可能です。たとえば、Budgetが1000円未満なら\"Cheap\"、1000円以上なら\"Expensive\"と示す変数Budget2を作成する場合はif_else()関数 (または、ifelse()関数) が使えます。 df %&gt;% mutate(Budget2 = if_else(Budget &lt; 1000, &quot;Cheap&quot;, &quot;Expensive&quot;)) %&gt;% filter(!is.na(Budget2)) %&gt;% # Budget2が欠損した店舗を除外 group_by(Pref, Budget2) %&gt;% # PrefとBudget2でグループ化 summarise(N = n(), # 店舗数を表示 .groups = &quot;drop&quot;) ## # A tibble: 18 × 3 ## Pref Budget2 N ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 京都府 Cheap 22 ## 2 京都府 Expensive 28 ## 3 兵庫県 Cheap 39 ## 4 兵庫県 Expensive 27 ## 5 千葉県 Cheap 64 ## 6 千葉県 Expensive 72 ## 7 和歌山県 Cheap 10 ## 8 和歌山県 Expensive 5 ## 9 埼玉県 Cheap 37 ## 10 埼玉県 Expensive 45 ## 11 大阪府 Cheap 104 ## 12 大阪府 Expensive 115 ## 13 奈良県 Cheap 11 ## 14 奈良県 Expensive 10 ## 15 東京都 Cheap 206 ## 16 東京都 Expensive 236 ## 17 神奈川県 Cheap 66 ## 18 神奈川県 Expensive 54 これは各都府県ごとの予算1000円未満の店と以上の店の店舗数をまとめた表となります。もし、500円未満なら\"Cheap\"、500円以上~1000円未満なら\"Reasonable\"、1000円以上なら\"Expensive\"になるBudget3変数を作るにはどうすればよいでしょうか。第10章で紹介しましたif_else()を重ねることも出来ますが、ここではcase_when()関数が便利です。まずは、if_else()を使ったコードは以下の通りです。 # if_else()を使う場合 df %&gt;% mutate(Budget3 = if_else(Budget &lt; 500, &quot;Cheap&quot;, if_else(Budget &gt;= 500 &amp; Budget &lt; 1000, &quot;Reasonable&quot;, &quot;Expensive&quot;))) %&gt;% filter(!is.na(Budget3)) %&gt;% group_by(Pref, Budget3) %&gt;% summarise(N = n(), .groups = &quot;drop&quot;) case_when()を使うと以下のような書き方になります。 # case_when()を使う場合 df %&gt;% mutate(Budget3 = case_when(Budget &lt; 500 ~ &quot;Cheap&quot;, Budget &gt;= 500 &amp; Budget &lt; 1000 ~ &quot;Reasonable&quot;, Budget &gt;= 1000 ~ &quot;Expensive&quot;), # 新しく出来た変数をfactor型にその場で変換することも可能 Budget3 = factor(Budget3, levels = c(&quot;Cheap&quot;, &quot;Reasonable&quot;, &quot;Expensive&quot;))) %&gt;% filter(!is.na(Budget3)) %&gt;% group_by(Pref, Budget3) %&gt;% summarise(N = n(), .groups = &quot;drop&quot;) ## # A tibble: 20 × 3 ## Pref Budget3 N ## &lt;chr&gt; &lt;fct&gt; &lt;int&gt; ## 1 京都府 Reasonable 22 ## 2 京都府 Expensive 28 ## 3 兵庫県 Reasonable 39 ## 4 兵庫県 Expensive 27 ## 5 千葉県 Reasonable 64 ## 6 千葉県 Expensive 72 ## 7 和歌山県 Reasonable 10 ## 8 和歌山県 Expensive 5 ## 9 埼玉県 Reasonable 37 ## 10 埼玉県 Expensive 45 ## 11 大阪府 Reasonable 104 ## 12 大阪府 Expensive 115 ## 13 奈良県 Reasonable 11 ## 14 奈良県 Expensive 10 ## 15 東京都 Cheap 1 ## 16 東京都 Reasonable 205 ## 17 東京都 Expensive 236 ## 18 神奈川県 Cheap 1 ## 19 神奈川県 Reasonable 65 ## 20 神奈川県 Expensive 54 書く手間の観点ではcase_when()はifelse()と大きく違いはないかも知れませんが、コードが非常に読みやすくなっています。case_when()関数の書き方は以下の通りです。 # case_when()の使い方 データフレーム名 %&gt;% mutate(新変数名 = case_when(条件1 ~ 条件1を満たす場合の結果値, 条件2 ~ 条件2を満たす場合の結果値, 条件3 ~ 条件3を満たす場合の結果値, ..., TRUE ~ その他の場合の結果値)) case_when()内部での判定は先に指定された条件から順番に行われます。条件1に満たされない場合は、条件2で判定し、その条件2に満たされない場合は条件3、…、そして全て満たされなかった場合はTRUE ~以降の値を返すといった感覚です。したがって、先ほどのコードにおけるBudget &gt;= 500 &amp; Budget &lt; 1000は効率的ではありません。簡略化すると以下のようになります。 df %&gt;% mutate(Budget3 = case_when(Budget &lt; 500 ~ &quot;Cheap&quot;, Budget &lt; 1000 ~ &quot;Reasonable&quot;, Budget &gt;= 1000 ~ &quot;Expensive&quot;), Budget3 = factor(Budget3, levels = c(&quot;Cheap&quot;, &quot;Reasonable&quot;, &quot;Expensive&quot;))) %&gt;% filter(!is.na(Budget3)) %&gt;% group_by(Pref, Budget3) %&gt;% summarise(N = n(), .groups = &quot;drop&quot;) ## # A tibble: 20 × 3 ## Pref Budget3 N ## &lt;chr&gt; &lt;fct&gt; &lt;int&gt; ## 1 京都府 Reasonable 22 ## 2 京都府 Expensive 28 ## 3 兵庫県 Reasonable 39 ## 4 兵庫県 Expensive 27 ## 5 千葉県 Reasonable 64 ## 6 千葉県 Expensive 72 ## 7 和歌山県 Reasonable 10 ## 8 和歌山県 Expensive 5 ## 9 埼玉県 Reasonable 37 ## 10 埼玉県 Expensive 45 ## 11 大阪府 Reasonable 104 ## 12 大阪府 Expensive 115 ## 13 奈良県 Reasonable 11 ## 14 奈良県 Expensive 10 ## 15 東京都 Cheap 1 ## 16 東京都 Reasonable 205 ## 17 東京都 Expensive 236 ## 18 神奈川県 Cheap 1 ## 19 神奈川県 Reasonable 65 ## 20 神奈川県 Expensive 54 ただし、このTRUEには注意が必要です。たとえば、以下のようなコードを考えてみましょう。 df %&gt;% mutate(Budget3 = case_when(Budget &lt; 500 ~ &quot;Cheap&quot;, Budget &lt; 1000 ~ &quot;Reasonable&quot;, TRUE ~ &quot;Expensive&quot;), Budget3 = factor(Budget3, levels = c(&quot;Cheap&quot;, &quot;Reasonable&quot;, &quot;Expensive&quot;))) %&gt;% filter(!is.na(Budget3)) %&gt;% group_by(Pref, Budget3) %&gt;% summarise(N = n(), .groups = &quot;drop&quot;) ## # A tibble: 20 × 3 ## Pref Budget3 N ## &lt;chr&gt; &lt;fct&gt; &lt;int&gt; ## 1 京都府 Reasonable 22 ## 2 京都府 Expensive 392 ## 3 兵庫県 Reasonable 39 ## 4 兵庫県 Expensive 552 ## 5 千葉県 Reasonable 64 ## 6 千葉県 Expensive 936 ## 7 和歌山県 Reasonable 10 ## 8 和歌山県 Expensive 130 ## 9 埼玉県 Reasonable 37 ## 10 埼玉県 Expensive 963 ## 11 大阪府 Reasonable 104 ## 12 大阪府 Expensive 896 ## 13 奈良県 Reasonable 11 ## 14 奈良県 Expensive 136 ## 15 東京都 Cheap 1 ## 16 東京都 Reasonable 205 ## 17 東京都 Expensive 794 ## 18 神奈川県 Cheap 1 ## 19 神奈川県 Reasonable 65 ## 20 神奈川県 Expensive 934 結果が異なりますね。なぜならBudgetの値が欠損値であっても\"Expensive\"と判定されるからです。対処方法としましてはmutate()の前にfilter()を使ってBudget3が欠損した行を削除するか、Budgetが欠損した場合の値をcase_when()内部に指定するかです。以下の例はBudgetが欠損した場合の処理内容を加えたものです。 df %&gt;% mutate(Budget3 = case_when(is.na(Budget) ~ NA_character_, Budget &lt; 500 ~ &quot;Cheap&quot;, Budget &lt; 1000 ~ &quot;Reasonable&quot;, TRUE ~ &quot;Expensive&quot;), Budget3 = factor(Budget3, levels = c(&quot;Cheap&quot;, &quot;Reasonable&quot;, &quot;Expensive&quot;))) %&gt;% filter(!is.na(Budget3)) %&gt;% group_by(Pref, Budget3) %&gt;% summarise(N = n(), .groups = &quot;drop&quot;) ## # A tibble: 20 × 3 ## Pref Budget3 N ## &lt;chr&gt; &lt;fct&gt; &lt;int&gt; ## 1 京都府 Reasonable 22 ## 2 京都府 Expensive 28 ## 3 兵庫県 Reasonable 39 ## 4 兵庫県 Expensive 27 ## 5 千葉県 Reasonable 64 ## 6 千葉県 Expensive 72 ## 7 和歌山県 Reasonable 10 ## 8 和歌山県 Expensive 5 ## 9 埼玉県 Reasonable 37 ## 10 埼玉県 Expensive 45 ## 11 大阪府 Reasonable 104 ## 12 大阪府 Expensive 115 ## 13 奈良県 Reasonable 11 ## 14 奈良県 Expensive 10 ## 15 東京都 Cheap 1 ## 16 東京都 Reasonable 205 ## 17 東京都 Expensive 236 ## 18 神奈川県 Cheap 1 ## 19 神奈川県 Reasonable 65 ## 20 神奈川県 Expensive 54 Budget3はcharacter型変数となるので、欠損値のタイプもNA_character_にします。もし、numeric型変数を作成するならNA_real_を使います。if_else()やcase_when()など、{dplyr}が提供する関数は欠損値の型にも厳しいので、NAだけだとエラーが帰ってきます。 これまでのcase_when()関数に似たような機能をする関数としてrecode()関数があります75。これは変数の値を単純に置換したい場合に便利な関数です。たとえば、都府県名をローマ字に変換するケースを考えてみましょう。 # recode()を使う場合 df2 %&gt;% mutate(Pref2 = recode(Pref, &quot;東京都&quot; = &quot;Tokyo&quot;, &quot;神奈川県&quot; = &quot;Kanagawa&quot;, &quot;千葉県&quot; = &quot;Chiba&quot;, &quot;埼玉県&quot; = &quot;Saitama&quot;, &quot;大阪府&quot; = &quot;Osaka&quot;, &quot;京都府&quot; = &quot;Kyoto&quot;, &quot;兵庫県&quot; = &quot;Hyogo&quot;, &quot;奈良県&quot; = &quot;Nara&quot;, &quot;和歌山県&quot; = &quot;Wakayama&quot;, .default = &quot;NA&quot;)) ## # A tibble: 9 × 6 ## Pref Budget_Mean ScoreN_Sum Score_Mean N Pref2 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;chr&gt; ## 1 京都府 1399. 216 3.68 414 Kyoto ## 2 兵庫県 1197. 230 3.54 591 Hyogo ## 3 千葉県 1124. 259 3.72 1000 Chiba ## 4 和歌山県 1252 83 3.97 140 Wakayama ## 5 埼玉県 1147. 278 3.64 1000 Saitama ## 6 大阪府 1203. 516 3.77 1000 Osaka ## 7 奈良県 1169. 45 3.85 147 Nara ## 8 東京都 1283. 1165 3.67 1000 Tokyo ## 9 神奈川県 1239. 587 3.53 1000 Kanagawa 使い方は非常に直感的です。 # recode()の使い方 データフレーム名 %&gt;% mutate(新変数名 = recode(元の変数名, 元の値1 = 新しい値1, 元の値2 = 新しい値2, 元の値3 = 新しい値3, ..., .default = 該当しない場合の値)) 最後の.default引数は、もし該当する値がない場合に返す値を意味し、長さ1のベクトルを指定します。もし、指定しない場合はNAが表示されます。また、ここには紹介しておりませんでしたが、.missing引数もあり、これは欠損値の場合に返す値を意味します。 もう一つ注意すべきところは、今回はcharacter型変数をcharacter型へ変換したため、「\"東京都\" = \"Tokyo\"」のような書き方をしました。しかし、numeric型からcharacter型に変換する場合は数字の部分を`で囲む必要があります。たとえば、「`1` = \"Tokyo\"」といった形式です。ただし、character型からnumeric型への場合は「\"東京都\" = 1」で構いません。 recode()は値をまとめる際にも便利です。たとえば、EastJapanという変数を作成し、関東なら1を、それ以外なら0を付けるとします。そして、これはPref変数の後に位置づけます。 # 都府県を関東か否かでまとめる df2 %&gt;% mutate(EastJapan = recode(Pref, &quot;東京都&quot; = 1, &quot;神奈川県&quot; = 1, &quot;千葉県&quot; = 1, &quot;埼玉県&quot; = 1, &quot;大阪府&quot; = 0, &quot;京都府&quot; = 0, &quot;兵庫県&quot; = 0, &quot;奈良県&quot; = 0, &quot;和歌山県&quot; = 0, .default = 0), .after = Pref) ## # A tibble: 9 × 6 ## Pref EastJapan Budget_Mean ScoreN_Sum Score_Mean N ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 京都府 0 1399. 216 3.68 414 ## 2 兵庫県 0 1197. 230 3.54 591 ## 3 千葉県 1 1124. 259 3.72 1000 ## 4 和歌山県 0 1252 83 3.97 140 ## 5 埼玉県 1 1147. 278 3.64 1000 ## 6 大阪府 0 1203. 516 3.77 1000 ## 7 奈良県 0 1169. 45 3.85 147 ## 8 東京都 1 1283. 1165 3.67 1000 ## 9 神奈川県 1 1239. 587 3.53 1000 ただし、関東以外は全て0になるため、以下のように省略することも可能です。 # .default引数を指定する場合 df3 &lt;- df2 %&gt;% mutate(EastJapan = recode(Pref, &quot;東京都&quot; = 1, &quot;神奈川県&quot; = 1, &quot;千葉県&quot; = 1, &quot;埼玉県&quot; = 1, .default = 0), .after = Pref) df3 ## # A tibble: 9 × 6 ## Pref EastJapan Budget_Mean ScoreN_Sum Score_Mean N ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 京都府 0 1399. 216 3.68 414 ## 2 兵庫県 0 1197. 230 3.54 591 ## 3 千葉県 1 1124. 259 3.72 1000 ## 4 和歌山県 0 1252 83 3.97 140 ## 5 埼玉県 1 1147. 278 3.64 1000 ## 6 大阪府 0 1203. 516 3.77 1000 ## 7 奈良県 0 1169. 45 3.85 147 ## 8 東京都 1 1283. 1165 3.67 1000 ## 9 神奈川県 1 1239. 587 3.53 1000 新しく出来たEastJapanのデータ型はなんでしょうか。 class(df3$EastJapan) ## [1] &quot;numeric&quot; EastJapanはnumeric型ですね。もし、これをfactor型にしたい場合はどうすればよいでしょうか。それはmutate()内でEastJapanを生成した後にfactor()関数を使うだけです。 # EastJapan変数をfactor型にする df3 &lt;- df2 %&gt;% mutate(EastJapan = recode(Pref, &quot;東京都&quot; = 1, &quot;神奈川県&quot; = 1, &quot;千葉県&quot; = 1, &quot;埼玉県&quot; = 1, .default = 0), EastJapan = factor(EastJapan, levels = c(0, 1)), .after = Pref) df3$EastJapan ## [1] 0 0 1 0 1 0 0 1 1 ## Levels: 0 1 EastJapanがfactor型になりました。実は、recodeは再コーディングと同時にfactor化をしてくれる機能があります。ただし、recode()関数でなく、recode_factor()関数を使います。 # recode_factor()を使う方法 df3 &lt;- df2 %&gt;% mutate(EastJapan = recode_factor(Pref, &quot;東京都&quot; = 1, &quot;神奈川県&quot; = 1, &quot;千葉県&quot; = 1, &quot;埼玉県&quot; = 1, .default = 0), .after = Pref) df3$EastJapan ## [1] 0 0 1 0 1 0 0 1 1 ## Levels: 1 0 ただし、levelの順番はrecode_factor()内で定義された順番になることに注意してください。factor型のより詳細な扱いについては第14章で解説します。 13.4 行単位の操作 ここでは行単位の操作について考えたいと思います。第12.3章で使ったmyDF1を見てみましょう。 myDF1 &lt;- data.frame( ID = 1:5, X1 = c(2, 4, 6, 2, 7), Y1 = c(3, 5, 1, 1, 0), X1D = c(4, 2, 1, 6, 9), X2 = c(5, 5, 6, 0, 2), Y2 = c(3, 3, 2, 3, 1), X2D = c(8, 9, 5, 0, 1), X3 = c(3, 0, 3, 0, 2), Y3 = c(1, 5, 9, 1, 3), X3D = c(9, 1, 3, 3, 8) ) myDF1 ## ID X1 Y1 X1D X2 Y2 X2D X3 Y3 X3D ## 1 1 2 3 4 5 3 8 3 1 9 ## 2 2 4 5 2 5 3 9 0 5 1 ## 3 3 6 1 1 6 2 5 3 9 3 ## 4 4 2 1 6 0 3 0 0 1 3 ## 5 5 7 0 9 2 1 1 2 3 8 ここでX1とX2とX3の平均値を計算し、X_Meanという名の変数にする場合、以下のような書き方が普通でしょう。 myDF1 %&gt;% mutate(X_Mean = mean(c(X1, X2, X3))) ## ID X1 Y1 X1D X2 Y2 X2D X3 Y3 X3D X_Mean ## 1 1 2 3 4 5 3 8 3 1 9 3.133333 ## 2 2 4 5 2 5 3 9 0 5 1 3.133333 ## 3 3 6 1 1 6 2 5 3 9 3 3.133333 ## 4 4 2 1 6 0 3 0 0 1 3 3.133333 ## 5 5 7 0 9 2 1 1 2 3 8 3.133333 あら、なんかおかしくありませんか。1行目の場合、X1とX2、X3それぞれ2、5、3であり、平均値は3.333であるはずなのに3.133になりました。これは2行目以降も同じです。なぜでしょうか。 実は{dplyr}は行単位の計算が苦手です。実際、データフレームというのは既に説明したとおり、縦ベクトルを横に並べたものです。列をまたがる場合、データ型が異なる場合も多いため、そもそも使う場面も多くありません。したがって、以下のような書き方が必要でした。 myDF1 %&gt;% mutate(X_Mean = (X1 + X2 + X3) / 3) ## ID X1 Y1 X1D X2 Y2 X2D X3 Y3 X3D X_Mean ## 1 1 2 3 4 5 3 8 3 1 9 3.3333333 ## 2 2 4 5 2 5 3 9 0 5 1 3.0000000 ## 3 3 6 1 1 6 2 5 3 9 3 5.0000000 ## 4 4 2 1 6 0 3 0 0 1 3 0.6666667 ## 5 5 7 0 9 2 1 1 2 3 8 3.6666667 先ほどのmean(c(X1, X2, X3))は(X1列とX2列、X3列)の平均値です。X1は長さ1のベクトルではなく、その列全体を指すものです。つまり、mean(c(X1, X2, X3))はmean(c(myD1F$X1, myDF1$X2, myDF1$X3))と同じことになります。だから全て3.133という結果が得られました。ただし、後者はベクトル同士の加減乗除になるため問題ありません。実際c(1, 2, 3) + c(3, 5, 0)は同じ位置の要素同士の計算になることを既に第9.2章で説明しました。 ここでmean()関数を使う場合には全ての演算を、一行一行に分けて行う必要があります。ある一行のみに限定する場合、mean(c(X1, X2, X3))のX1などは長さ1のベクトルになるため、(X1 + X2 + X3) / 3と同じことになります。この「一行単位で処理を行う」ことを指定する関数がrowwise()関数です。これは行単位の作業を行う前に指定するだけです。 myDF1 %&gt;% rowwise() %&gt;% mutate(X_Mean = mean(c(X1, X2, X3))) ## # A tibble: 5 × 11 ## # Rowwise: ## ID X1 Y1 X1D X2 Y2 X2D X3 Y3 X3D X_Mean ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 4 5 3 8 3 1 9 3.33 ## 2 2 4 5 2 5 3 9 0 5 1 3 ## 3 3 6 1 1 6 2 5 3 9 3 5 ## 4 4 2 1 6 0 3 0 0 1 3 0.667 ## 5 5 7 0 9 2 1 1 2 3 8 3.67 これで問題なく行単位の処理ができるようになりました。今回は変数が3つのみだったので、これで問題ありませんが、変数が多くなると:やstarts_with()、num_range()などを使って変数を選択したくなります。この場合は計算する関数内にc_across()を入れます。ここではX1列からX3D列までの平均値を求めてみましょう。 myDF1 %&gt;% rowwise() %&gt;% mutate(X_Mean = mean(X1:X3D)) ## # A tibble: 5 × 11 ## # Rowwise: ## ID X1 Y1 X1D X2 Y2 X2D X3 Y3 X3D X_Mean ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 2 3 4 5 3 8 3 1 9 5.5 ## 2 2 4 5 2 5 3 9 0 5 1 2.5 ## 3 3 6 1 1 6 2 5 3 9 3 4.5 ## 4 4 2 1 6 0 3 0 0 1 3 2.5 ## 5 5 7 0 9 2 1 1 2 3 8 7.5 実はrowwise()関数、2020年6月に公開されたdplyr 1.0.0で注目された関数ですが、昔のdplyrにもrowwise()関数はありました。ただし、purrrパッケージやtidyrパッケージのnest()関数などにより使い道がなくなりましたが、なぜか華麗に復活しました。データ分析に使うデータは基本単位は列であるため、実際にrowwise()が使われる場面は今の段階では多くないでしょう。また、簡単な作業ならX1 + X2のような演算でも対応できます。それでも、覚えておけば便利な関数であることには間違いありません。 13.5 データの結合 13.5.1 行の結合 まずは、複数のデータフレームまたはtibbleを縦に結合する方法について解説します。イメージとしては図13.1のようなものです。 図 13.1: 行の結合 行を結合する際には{dplyr}パッケージのbind_rows()関数を使います。この関数の使い方は以下の通りです。 # 新しいデータ名ではなく、既にあるデータ名にすると上書きとなる 新しいデータ名 &lt;- bind_rows(データ1, データ2, ...) それでは早速実際に使ってみましょう。実習のために、4つのtibbleを作成します (tibbleでなくデータフレームでも問題ありません)。 # tibble()の代わりにdata.frame()も可 rbind_df1 &lt;- tibble(X1 = 1:3, X2 = c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), X3 = c(T, T, F)) # TRUEとFALSEはTはFと省略可能 rbind_df2 &lt;- tibble(X1 = 4:6, X2 = c(&quot;D&quot;, &quot;E&quot;, &quot;F&quot;), X3 = c(F, T, F)) rbind_df3 &lt;- tibble(X1 = 7:9, X3 = c(T, T, T), X2 = c(&quot;G&quot;, &quot;H&quot;, &quot;I&quot;)) rbind_df4 &lt;- tibble(X1 = 10:12, X2 = c(&quot;J&quot;, &quot;K&quot;, &quot;L&quot;), X5 = c(&quot;Song&quot;, &quot;Yanai&quot;, &quot;Hadley&quot;)) rbind_df1 # rbind_df1を出力 ## # A tibble: 3 × 3 ## X1 X2 X3 ## &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; ## 1 1 A TRUE ## 2 2 B TRUE ## 3 3 C FALSE rbind_df2 # rbind_df2を出力 ## # A tibble: 3 × 3 ## X1 X2 X3 ## &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; ## 1 4 D FALSE ## 2 5 E TRUE ## 3 6 F FALSE rbind_df3 # rbind_df3を出力 ## # A tibble: 3 × 3 ## X1 X3 X2 ## &lt;int&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 7 TRUE G ## 2 8 TRUE H ## 3 9 TRUE I rbind_df4 # rbind_df4を出力 ## # A tibble: 3 × 3 ## X1 X2 X5 ## &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 10 J Song ## 2 11 K Yanai ## 3 12 L Hadley まずは、rbind_df1とrbind_df2を結合してみます。この2つのデータは同じ変数が同じ順番で並んでいますね。 Binded_df1 &lt;- bind_rows(rbind_df1, rbind_df2) Binded_df1 ## # A tibble: 6 × 3 ## X1 X2 X3 ## &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; ## 1 1 A TRUE ## 2 2 B TRUE ## 3 3 C FALSE ## 4 4 D FALSE ## 5 5 E TRUE ## 6 6 F FALSE 2つのデータが結合されたことが確認できます。それではrbind_df1とrbind_df2、rbind_df3はどうでしょうか。確かに3つのデータは同じ変数を持ちますが、rbind_df3は変数の順番がX1、X3、X2になっています。このまま結合するとエラーが出るでしょうか。とりあえず、やってみます。 Binded_df2 &lt;- bind_rows(rbind_df1, rbind_df2, rbind_df3) Binded_df2 ## # A tibble: 9 × 3 ## X1 X2 X3 ## &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; ## 1 1 A TRUE ## 2 2 B TRUE ## 3 3 C FALSE ## 4 4 D FALSE ## 5 5 E TRUE ## 6 6 F FALSE ## 7 7 G TRUE ## 8 8 H TRUE ## 9 9 I TRUE このように変数の順番が異なっても、先に指定したデータの変数順で問題なく結合できました。これまでの作業は{dplyr}パッケージのbind_rows()を使わずに、R内蔵関数のrbind()でも同じやり方でできます。bind_rows()の特徴は、変数名が一致しない場合、つまり今回の例だとrbind_df4が含まれる場合です。rbind_df1からrbind_df3までは順番が違ってもX1、X2、X3変数で構成されていました。一方、rbind_dr4にはX3がなく、新たにX4という変数があります。これをrbind()関数で結合するとエラーが出力されます。 # rbind()を使う場合 rbind(rbind_df1, rbind_df2, rbind_df3, rbind_df4) ## Error in match.names(clabs, names(xi)): names do not match previous names 一方、bind_rows()はどうでしょうか。 Binded_df3 &lt;- bind_rows(rbind_df1, rbind_df2, rbind_df3, rbind_df4) Binded_df3 ## # A tibble: 12 × 4 ## X1 X2 X3 X5 ## &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; ## 1 1 A TRUE &lt;NA&gt; ## 2 2 B TRUE &lt;NA&gt; ## 3 3 C FALSE &lt;NA&gt; ## 4 4 D FALSE &lt;NA&gt; ## 5 5 E TRUE &lt;NA&gt; ## 6 6 F FALSE &lt;NA&gt; ## 7 7 G TRUE &lt;NA&gt; ## 8 8 H TRUE &lt;NA&gt; ## 9 9 I TRUE &lt;NA&gt; ## 10 10 J NA Song ## 11 11 K NA Yanai ## 12 12 L NA Hadley X1からX4まで全ての列が生成され、元のデータにはなかった列に関してはNAで埋められています。 ならば、bind_rows()の完全勝利かというと、そうとは限りません。自分で架空した複数のデータフレーム、またはtibbleを結合する際、「このデータは全て同じ変数を持っているはず」と事前に分かっているならrbind()の方が効果的です。なぜなら、変数名が異なる場合、エラーが出力されるからです。bind_rows()を使うと、コーディングミスなどにより、列名の相違がある場合でも結合してくれてしまうので、分析の結果を歪ませる可能性があります。 13.5.2 列の結合 実はデータ分析においてデータの結合といえば、列の結合が一般的です。これは図13.2のような操作を意味します。 図 13.2: 列の結合 まずは、本章で作成したdf2をもう一回作ってみます。 df2 &lt;- df %&gt;% group_by(Pref) %&gt;% summarise(Budget_Mean = mean(Budget, na.rm = TRUE), ScoreN_Sum = sum(ScoreN, na.rm = TRUE), Score_Mean = mean(Score, na.rm = TRUE), N = n(), .groups = &quot;drop&quot;) df2 ## # A tibble: 9 × 5 ## Pref Budget_Mean ScoreN_Sum Score_Mean N ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 京都府 1399. 216 3.68 414 ## 2 兵庫県 1197. 230 3.54 591 ## 3 千葉県 1124. 259 3.72 1000 ## 4 和歌山県 1252 83 3.97 140 ## 5 埼玉県 1147. 278 3.64 1000 ## 6 大阪府 1203. 516 3.77 1000 ## 7 奈良県 1169. 45 3.85 147 ## 8 東京都 1283. 1165 3.67 1000 ## 9 神奈川県 1239. 587 3.53 1000 ラーメン屋の店舗ですが、たしかにデータには埼玉、東京、大阪などは1000店舗しか入っておりません。実はもっと多いですが、ぐるなびAPIの仕様上、最大1000店舗しか情報取得が出来ないからです。ここに実際の店舗数が入っている新しいデータセット、Ramen2.csvがあります。これを読み込み、df3という名で格納しましょう。 df3 &lt;- read_csv(&quot;Data/Ramen2.csv&quot;) df3 ## # A tibble: 47 × 15 ## Pref Pop Area RamenN Turnout LDP CDP DPFP Komei JIP JCP SDP ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 北海道 5.38e6 83424. 1454 53.8 32.3 20.8 6.65 11.7 7.78 11.6 1.31 ## 2 青森県 1.31e6 9646. 336 42.9 39.8 22.0 7.24 11.3 3.4 8.31 2.36 ## 3 岩手県 1.28e6 15275. 285 56.5 35.5 17.8 12.5 8.22 4.36 10.4 3.83 ## 4 宮城県 2.33e6 7282. 557 51.2 39.6 17.8 9.02 11.1 4.6 7.89 2.1 ## 5 秋田県 1.02e6 11638. 301 56.3 44.5 13.5 8.64 10.6 4.48 8.09 3.77 ## 6 山形県 1.12e6 9323. 512 60.7 45.2 14.9 7.37 9.87 4.28 6.51 5.08 ## 7 福島県 1.91e6 13784. 550 52.4 38.2 13.6 12.1 12.8 5.31 7.99 3.01 ## 8 茨城県 2.92e6 6097. 663 45.0 39.3 15.2 7.15 15.1 6.73 7.73 1.46 ## 9 栃木県 1.97e6 6408. 595 44.1 40.3 18.9 9.94 12.8 4.9 5.04 1.03 ## 10 群馬県 1.97e6 6362. 488 48.2 40.6 16.4 9.76 12.4 4.67 7.58 1.87 ## # … with 37 more rows, and 3 more variables: Reiwa &lt;dbl&gt;, NHK &lt;dbl&gt;, HRP &lt;dbl&gt; 変数名 説明 Pref 都道府県名 Pop 日本人人口 (2015年国勢調査) Area 面積 (2015年国勢調査) RamenN ぐるなびに登録されたラーメン屋の店舗数 Turnout 2019年参院選: 投票率 (比例) LDP 2019年参院選: 自民党の得票率 (比例) CDP 2019年参院選: 立憲民主党の得票率 (比例) DPFP 2019年参院選: 国民民主党の得票率 (比例) Komei 2019年参院選: 公明党の得票率 (比例) JIP 2019年参院選: 日本維新の会の得票率 (比例) JCP 2019年参院選: 日本共産党の得票率 (比例) SDP 2019年参院選: 社会民主党の得票率 (比例) Reiwa 2019年参院選: れいわ新選組の得票率 (比例) NHK 2019年参院選: NHKから国民を守る党の得票率 (比例) HRP 2019年参院選: 幸福実現党の得票率 (比例) 本データは都道府県ごとの人口、面積、ぐるなびに登録されたラーメン屋の店舗数、2019年参議院議員通常選挙の結果が格納されています。人口と面積は2015年国勢調査、ぐるなびの情報は2020年6月時点での情報です。 df2にデータ上の店舗数ではなく、実際の店舗数を新しい列として追加したい場合はどうすれば良いでしょうか。簡単な方法としてはdf3から情報を取得し、それを自分で入れる方法です。 df3 %&gt;% # df2のPrefベクトルの要素と一致するものに絞る filter(Pref %in% df2$Pref) %&gt;% # 都道府県名とラーメン屋の店舗数のみ抽出 select(Pref, RamenN) ## # A tibble: 9 × 2 ## Pref RamenN ## &lt;chr&gt; &lt;dbl&gt; ## 1 埼玉県 1106 ## 2 千葉県 1098 ## 3 東京都 3220 ## 4 神奈川県 1254 ## 5 京都府 415 ## 6 大阪府 1325 ## 7 兵庫県 591 ## 8 奈良県 147 ## 9 和歌山県 140 そして、この情報をdf2$RamenN &lt;- c(415, 1106, 1254, ...)のように追加すればいいですね。 しかし、このような方法は非効率的です。そもそもdf3から得られた結果の順番とdf2の順番も一致しないので、一々対照しながらベクトルを作ることになります。ここで登場する関数が{dplyr}の*_join()関数群です。この関数群には4つの関数が含まれており、以下のような使い方になります。 # 新しいデータ名ではなく、データ1またはデータ2の名前に格納すると上書きとなる # 1. データ1を基準に結合 新しいデータ名 &lt;- left_join(データ1, データ2, by = &quot;共通変数名&quot;) # 2. データ2を基準に結合 新しいデータ名 &lt;- right_join(データ1, データ2, by = &quot;共通変数名&quot;) # 3. データ1とデータ2両方に共通するケースのみ結合 新しいデータ名 &lt;- inner_join(データ1, データ2, by = &quot;共通変数名&quot;) # 4. データ1とデータ2、どれかに存在するケースを結合 新しいデータ名 &lt;- full_join(データ1, データ2, by = &quot;共通変数名&quot;) 4つの関数の違いについて説明する前に、by引数について話したいと思います。これは主にキー (key)変数と呼ばれる変数で、それぞれのデータに同じ名前の変数がある必要があります。df2とdf3だとそれがPref変数です。どの*_join()関数でも、Prefの値が同じもの同士を結合することになります。 データのキー変数名が異なる場合もあります。たとえば、データ1の都道府県名はPrefという列に、データ2の都道府県名はPrefectureという列になっている場合、by = \"Pref\"でなく、by = c(\"データ1のキー変数名\" = \"データ2のキー変数名\")、つまり、by = c(\"Pref\" = \"Prefecture\")と指定します。 それでは、df3から都道府県名とラーメン屋の店舗数だけ抽出し、df4として格納しておきます。 df4 &lt;- df3 %&gt;% select(Pref, RamenN) df4 ## # A tibble: 47 × 2 ## Pref RamenN ## &lt;chr&gt; &lt;dbl&gt; ## 1 北海道 1454 ## 2 青森県 336 ## 3 岩手県 285 ## 4 宮城県 557 ## 5 秋田県 301 ## 6 山形県 512 ## 7 福島県 550 ## 8 茨城県 663 ## 9 栃木県 595 ## 10 群馬県 488 ## # … with 37 more rows これから共通変数名の値をキー (key)と呼びます。今回の例だとPrefがdf2とdf4のキー変数であり、その値である\"東京都\"、\"北海道\"などがキーです。 まずは、inner_join()の仕組みについて考えます。これはdf2とdf4に共通するキーを持つケースのみ結合する関数です。df4には\"北海道\"というキーがありますが、df2にはありません。したがって、キーが\"北海道\"のケースは結合から除外されます。これをイメージにしたものが図13.3です76。それぞれ3 \\(\\times\\) 2 (3行2列)のデータですが、キーが一致するケースは2つしかないため、結合後のデータは3 \\(\\times\\) 2となります。 図 13.3: inner_join()の仕組み 実際にやってみましょう。 inner_join(df2, df4, by = &quot;Pref&quot;) ## # A tibble: 9 × 6 ## Pref Budget_Mean ScoreN_Sum Score_Mean N RamenN ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 京都府 1399. 216 3.68 414 415 ## 2 兵庫県 1197. 230 3.54 591 591 ## 3 千葉県 1124. 259 3.72 1000 1098 ## 4 和歌山県 1252 83 3.97 140 140 ## 5 埼玉県 1147. 278 3.64 1000 1106 ## 6 大阪府 1203. 516 3.77 1000 1325 ## 7 奈良県 1169. 45 3.85 147 147 ## 8 東京都 1283. 1165 3.67 1000 3220 ## 9 神奈川県 1239. 587 3.53 1000 1254 共通するキーは9つのみであり、結果として返されたデータの大きさも9 \\(\\times\\) 6です。df2に足されたdf4は2列のデータですが、キー変数であるPrefは共通するため、1列のみ足されました。キー変数を両方残す場合はkeep = TRUE引数を追加してください。 一方、full_join()は、すべてのキーに対して結合を行います (図@ref(fig: handling2-merge-col-10))。たとえば、df2には\"北海道\"というキーがありません。それでも新しく出来上がるデータには北海道の列が追加されます。ただし、道内店舗の平均予算、口コミ数などの情報はないため、欠損値が代入されます。 図 13.4: full_join()の仕組み それでは実際、結果を確認してみましょう。今回は結合後、RamenNが大きい順で出力します。 full_join(df2, df4, by = &quot;Pref&quot;) %&gt;% arrange(desc(RamenN)) # ぐるなびに登録された店舗の多い都道府県から出力 ## # A tibble: 47 × 6 ## Pref Budget_Mean ScoreN_Sum Score_Mean N RamenN ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 東京都 1283. 1165 3.67 1000 3220 ## 2 北海道 NA NA NA NA 1454 ## 3 大阪府 1203. 516 3.77 1000 1325 ## 4 愛知県 NA NA NA NA 1255 ## 5 神奈川県 1239. 587 3.53 1000 1254 ## 6 埼玉県 1147. 278 3.64 1000 1106 ## 7 千葉県 1124. 259 3.72 1000 1098 ## 8 福岡県 NA NA NA NA 985 ## 9 新潟県 NA NA NA NA 705 ## 10 静岡県 NA NA NA NA 679 ## # … with 37 more rows df2にはなかった北海道や愛知県などの行ができました。そして、df2にはない情報はすべて欠損値 (NA)となりました。 続いて、left_join()ですが、これは先に指定したデータに存在するキーのみで結合を行います (図@ref(fig: handling2-merge-col-12))。今回はdf2が先に指定されていますが、df2のキーはdf4のキーの部分集合であるため、inner_join()と同じ結果が得られます。 図 13.5: left_join()の仕組み 一方、right_join()はleft_join()と逆の関数であり、後に指定したデータに存在するキーを基準に結合を行います (図@ref(fig: handling2-merge-col-13))。後に指定されたdf4のキーはdf2のキーを完全に含むので、full_join()と同じ結果が得られます。 図 13.6: right_join()の仕組み これからはdf2とdf4を結合することになりますが、この2つのtibbleの大きさが異なります。df2は9つの都府県のみであるに対し、df4は47都道府県全てのデータが入っているからです。 ここまではキー変数が一つである場合についてのみ考えましたが、複数のキー変数が必要な場合もあります。たとえば、市区町村の人口・面積データと市区町村の投票率データを結合するとします。各自治体に与えられている「全国地方公共団体コード」が両データに含まれている場合は、このコードをキー変数として使えば問題ありませんが、市区町村名をキー変数として使わざる得ないケースもあるでしょう。しかし、キー変数が複数ある場合もあります。たとえば、府中市は東京都と広島県にありますし、太子町は大阪府と兵庫県にあります。この場合、市区町村名のみでケースをマッチングすると、重複されてマッチングされる恐れがあります。この場合はキー変数を増やすことで対処できます。たとえば、同じ都道府県なら同じ市区町村は存在しないでしょう77。キー変数を複数指定する方法は簡単です。たとえば、市区町村名変数がMunip、都道府県名変数がPrefならby = c(\"Munip\", \"Pref\")と指定するだけです。 最後に、キー変数以外の変数名が重複する場合について考えましょう。これはパネルデータを結合する時によく直面する問題です。同じ回答者に2回の調査を行った場合、回答者のIDでデータを結合することになります。ただし、それぞれのデータにおいて回答者の性別に関する変数がF1という名前の場合、どうなるでしょうか。同じデータの同じ名前の変数が複数あると、非常に扱いにくくなります。実際の結果を見てみましょう。 Wave1_df &lt;- tibble(ID = c(1, 2, 3, 4, 5), F1 = c(1, 1, 0, 0, 1), F2 = c(18, 77, 37, 50, 41), Q1 = c(1, 5, 2, 2, 3)) Wave2_df &lt;- tibble(ID = c(1, 3, 4, 6, 7), F1 = c(1, 0, 0, 0, 1), F2 = c(18, 37, 50, 20, 62), Q1 = c(1, 2, 2, 5, 4)) full_join(Wave1_df, Wave2_df, by = &quot;ID&quot;) ## # A tibble: 7 × 7 ## ID F1.x F2.x Q1.x F1.y F2.y Q1.y ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 18 1 1 18 1 ## 2 2 1 77 5 NA NA NA ## 3 3 0 37 2 0 37 2 ## 4 4 0 50 2 0 50 2 ## 5 5 1 41 3 NA NA NA ## 6 6 NA NA NA 0 20 5 ## 7 7 NA NA NA 1 62 4 それぞれの変数名の後に.xと.yが付きます。この接尾辞 (suffix)はsuffix引数を指定することで、分析側からカスタマイズ可能です。たとえば、接尾辞を_W1、_W2にしたい場合は full_join(Wave1_df, Wave2_df, by = &quot;ID&quot;, suffix = c(&quot;_W1&quot;, &quot;_W2&quot;)) ## # A tibble: 7 × 7 ## ID F1_W1 F2_W1 Q1_W1 F1_W2 F2_W2 Q1_W2 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 18 1 1 18 1 ## 2 2 1 77 5 NA NA NA ## 3 3 0 37 2 0 37 2 ## 4 4 0 50 2 0 50 2 ## 5 5 1 41 3 NA NA NA ## 6 6 NA NA NA 0 20 5 ## 7 7 NA NA NA 1 62 4 のように、データ1とデータ2それぞれの接尾辞を指定するだけです。 練習問題 "],["factor.html", "14. データハンドリング [基礎編: factor型] 14.1 名目変数を含むグラフを作成する際の注意点 14.2 {forcats}パッケージについて 練習問題", " 14. データハンドリング [基礎編: factor型] 14.1 名目変数を含むグラフを作成する際の注意点 ここからは楽しい可視化、つまりグラフの作成について解説します。ただし、その前に、名目変数の扱いと簡潔データ構造について話したいと思います。本章では名目変数の扱いについて解説し、次章は簡潔データ構造について解説します。 横軸、または縦軸が気温、成績、身長のような連続変数ではなく、都道府県や国、企業のような名目変数になる場合があります。たとえば、棒グラフの横軸は図14.1のように、一般的に名目変数になる場合が多いです。 図 14.1: 横軸が名目変数の棒グラフ ここでは横軸の順番に注目してください。京都府、埼玉県、神奈川県、…の順番になっていますね。「この順番で大満足だよ!」という方がいるかも知れませんが、そうでない方もおおいでしょう。普通考えられるものとしては、都道府県コードの順か、縦軸が高い順 (低い順)でしょう。都道府県コードの順だと、埼玉県、千葉県、東京都、神奈川県、京都府、大阪府、兵庫県、奈良県、和歌山県の順番になります。または、縦軸 (口コミ評価の平均値)が高い順なら和歌山県、奈良県、大阪府、…の順番になります。あるいは50音順も考えられるでしょう。アメリカの場合、州を並べる際、アルファベット順で並べます。 自分でこの順番をコントロールするには可視化の前の段階、つまりデータハンドリングの段階で順番を決めなくてはなりません。これを決めておかない場合、Rが勝手に順番を指定します。具体的にはロケール (locale)というパソコン内の空間に文字情報が含まれているわけですが、そこに保存されている文字の順番となります。たとえば、日本語ロケールには「京」が「埼」よりも先に保存されているわけです。 したがって、名目変数がグラフに含まれる場合は、名目変数の表示順番を決める必要があり、そこで必要なのがfactor型です。名目変数がcharacter型の場合、ロケールに保存されている順でソートされますが、factor型の場合、予め指定した順番でソートされます。 たとえば、前章で使用したデータを用いて、都道府県ごとの口コミ評価の平均値を計算し、その結果をScore_dfとして保存します。 # tidyverseパッケージの読み込み pacman::p_load(tidyverse) # データの読み込み df &lt;- read_csv(&quot;Data/Ramen.csv&quot;) Score_df &lt;- df %&gt;% group_by(Pref) %&gt;% summarise(Score = mean(Score, na.rm = TRUE), .groups = &quot;drop&quot;) Score_df ## # A tibble: 9 × 2 ## Pref Score ## &lt;chr&gt; &lt;dbl&gt; ## 1 京都府 3.68 ## 2 兵庫県 3.54 ## 3 千葉県 3.72 ## 4 和歌山県 3.97 ## 5 埼玉県 3.64 ## 6 大阪府 3.77 ## 7 奈良県 3.85 ## 8 東京都 3.67 ## 9 神奈川県 3.53 この時点で勝手にロケール順になります。実際、表示されたScore_dfを見るとPrefの下に&lt;chr&gt;と表記されており、Prefはcharacter型であることが分かります。これをこのまま棒グラフに出してみましょう。可視化の方法は第17章以降で詳細に解説するので、ここでは結果だけに注目してください。 Score_df %&gt;% ggplot() + geom_bar(aes(x = Pref, y = Score), stat = &quot;identity&quot;) + labs(x = &quot;都府県&quot;, y = &quot;口コミ評価の平均値 (1~5)&quot;) + theme_gray(base_size = 12) 図 14.2: Prefがcharacter型の場合 (1) 横軸の順番があまり直感的ではありませんね。それでは、Score_dfをScoreが高い順にソートし、Score_df2で保存してから、もう一回試してみます。 Score_df2 &lt;- Score_df %&gt;% arrange(desc(Score)) Score_df2 ## # A tibble: 9 × 2 ## Pref Score ## &lt;chr&gt; &lt;dbl&gt; ## 1 和歌山県 3.97 ## 2 奈良県 3.85 ## 3 大阪府 3.77 ## 4 千葉県 3.72 ## 5 京都府 3.68 ## 6 東京都 3.67 ## 7 埼玉県 3.64 ## 8 兵庫県 3.54 ## 9 神奈川県 3.53 ここでもPrefはcharacter型ですが、とりあえず、これで図を出してみます。 Score_df2 %&gt;% ggplot() + geom_bar(aes(x = Pref, y = Score), stat = &quot;identity&quot;) + labs(x = &quot;都府県&quot;, y = &quot;口コミ評価の平均値 (1~5)&quot;) + theme_gray(base_size = 12) 図 14.3: Prefがcharacter型の場合 (2) 結果は全く変わっておりません。それでは、Score_dfのPref列をfactor型に変換し、順番は口コミ評価の平均値が高い順番にしてみましょう。結果はScore_df_f1という名で保存します。 Score_df_f1 &lt;- Score_df %&gt;% mutate(Pref = factor(Pref, levels = c(&quot;和歌山県&quot;, &quot;奈良県&quot;, &quot;大阪府&quot;, &quot;千葉県&quot;, &quot;京都府&quot;, &quot;東京都&quot;, &quot;埼玉県&quot;, &quot;兵庫県&quot;, &quot;神奈川県&quot;))) Score_df_f1 ## # A tibble: 9 × 2 ## Pref Score ## &lt;fct&gt; &lt;dbl&gt; ## 1 京都府 3.68 ## 2 兵庫県 3.54 ## 3 千葉県 3.72 ## 4 和歌山県 3.97 ## 5 埼玉県 3.64 ## 6 大阪府 3.77 ## 7 奈良県 3.85 ## 8 東京都 3.67 ## 9 神奈川県 3.53 表示される順番はScore_dfとScore_df_f1も同じですが、Prefのデータ型が&lt;fct&gt;、つまりfactor型であることが分かります。実際、Pref列だけ抽出した場合、factor型として、和歌山県から神奈川県の順になっていることが確認できます。 Score_df_f1$Pref ## [1] 京都府 兵庫県 千葉県 和歌山県 埼玉県 大阪府 奈良県 東京都 ## [9] 神奈川県 ## 9 Levels: 和歌山県 奈良県 大阪府 千葉県 京都府 東京都 埼玉県 ... 神奈川県 このScore_df_f1データを使って、図14.2と全く同じコードを実行した結果が図14.4です。 図 14.4: Prefがfactor型の場合 これまでの話をまとめるの以下の2点が分かります。 変数がcharacter型である場合、自動的にロケール順でソートされる。 変数がfactor型である場合、データ内の順番やロケール順と関係なく、指定されたレベル (水準)の順でソートされる。 とくに2番目の点についてですが、これは必ずしも順序付きfactorである必要はありません。順序付きfactor型でなくても、factor()内で指定した順にソートされます。むろん、順序付きfactor型なら指定された順序でソートされます。 これからはfactor型変換の際に便利な関数をいくつか紹介しますが、その前に数値として表現された名目変数について話します。たとえば、Score_df_f1に関東地域なら1を、その他の地域なら0を付けたKantoという変数があるとします。 Score_df_f1 &lt;- Score_df_f1 %&gt;% mutate(Kanto = ifelse(Pref %in% c(&quot;東京都&quot;, &quot;神奈川県&quot;, &quot;千葉県&quot;, &quot;埼玉県&quot;), 1, 0)) Score_df_f1 ## # A tibble: 9 × 3 ## Pref Score Kanto ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 京都府 3.68 0 ## 2 兵庫県 3.54 0 ## 3 千葉県 3.72 1 ## 4 和歌山県 3.97 0 ## 5 埼玉県 3.64 1 ## 6 大阪府 3.77 0 ## 7 奈良県 3.85 0 ## 8 東京都 3.67 1 ## 9 神奈川県 3.53 1 Kanto変数のデータ型は、&lt;dbl&gt;、つまりnumeric型です。しかし、これは明らかに名目変数ですね。これをこのままKantoを横軸にした図を出すと図14.5のようになります。 図 14.5: Kantoがnumeric型の場合 この場合、図の横軸はKantoの値が小さい順でソートされます。ただし、このような図は非常に見にくいため、1に\"関東\"、0に\"関西\"とラベルを付けたfactor型に変換した方が望ましいです。numeric型をラベル付きのfactor型にするためには、levels引数には元の数値を、labels引数にはそれぞれの数値に対応したラベルを指定します。また、関東の方を先に出したいので、factor()内のlevels引数はc(0, 1)でなく、c(1, 0)にします。 Score_df_f1 &lt;- Score_df_f1 %&gt;% mutate(Kanto = factor(Kanto, levels = c(1, 0), labels = c(&quot;関東&quot;, &quot;その他&quot;))) Score_df_f1 ## # A tibble: 9 × 3 ## Pref Score Kanto ## &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 京都府 3.68 その他 ## 2 兵庫県 3.54 その他 ## 3 千葉県 3.72 関東 ## 4 和歌山県 3.97 その他 ## 5 埼玉県 3.64 関東 ## 6 大阪府 3.77 その他 ## 7 奈良県 3.85 その他 ## 8 東京都 3.67 関東 ## 9 神奈川県 3.53 関東 Kanto変数がfactor型に変換されたことが分かります。 Score_df_f1$Kanto ## [1] その他 その他 関東 その他 関東 その他 その他 関東 関東 ## Levels: 関東 その他 また、\"関東\"、\"その他\"の順になっていますね。これを図として出力した結果が図14.6です。 図 14.6: Kantoがfactor型の場合 このように数値型名目変数でも、factor化することによって、自由に横軸の順番を変えることができます。それでは、factor化に使える便利な関数をいくつか紹介します。 14.2 {forcats}パッケージについて 実はfactor型への変換や、順番に変更などは全てR内蔵のfactor()関数で対応可能ですが、ここでは{forcats}パッケージが提供しているfct_*()関数を使用します。{forcats}パッケージは{tidyverse}を読み込む際、自動的に読み込まれるため、既に{tidyverse}を読み込んでいる場合、別途のコードは要りません。 14.2.1 fct_relevel(): 水準の順番を変更する Score_df_f1のf1はScoreが高い順になっています。これを50音順に変更する際、fct_relevel()関数を使います。 # 新しい変数名と元となる変数名が一致すると上書きになる データフレーム名 %&gt;% mutate(新しい変数名 = fct_releve(元となる変数名, &quot;水準1&quot;, &quot;水準2&quot;, &quot;水準3&quot;, ...)) ここでは、Pref変数を再調整したPref2変数を作ってみましょう。 Score_df_f1 &lt;- Score_df_f1 %&gt;% mutate(Pref2 = fct_relevel(Pref, &quot;大阪府&quot;, &quot;神奈川県&quot;, &quot;京都府&quot;, &quot;埼玉県&quot;, &quot;千葉県&quot;, &quot;東京都&quot;, &quot;奈良県&quot;, &quot;兵庫県&quot;, &quot;和歌山県&quot;)) Score_df_f1 ## # A tibble: 9 × 4 ## Pref Score Kanto Pref2 ## &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; ## 1 京都府 3.68 その他 京都府 ## 2 兵庫県 3.54 その他 兵庫県 ## 3 千葉県 3.72 関東 千葉県 ## 4 和歌山県 3.97 その他 和歌山県 ## 5 埼玉県 3.64 関東 埼玉県 ## 6 大阪府 3.77 その他 大阪府 ## 7 奈良県 3.85 その他 奈良県 ## 8 東京都 3.67 関東 東京都 ## 9 神奈川県 3.53 関東 神奈川県 一見、PrefとPref2変数は同じように見えますが、水準はどうなっているでしょうか。 levels(Score_df_f1$Pref) # Prefの水準 ## [1] &quot;和歌山県&quot; &quot;奈良県&quot; &quot;大阪府&quot; &quot;千葉県&quot; &quot;京都府&quot; &quot;東京都&quot; &quot;埼玉県&quot; ## [8] &quot;兵庫県&quot; &quot;神奈川県&quot; levels(Score_df_f1$Pref2) # Pref2の水準 ## [1] &quot;大阪府&quot; &quot;神奈川県&quot; &quot;京都府&quot; &quot;埼玉県&quot; &quot;千葉県&quot; &quot;東京都&quot; &quot;奈良県&quot; ## [8] &quot;兵庫県&quot; &quot;和歌山県&quot; 問題なく50音順になっていることが分かります。他にもfct_relevel()には全ての水準名を指定する必要がありません。一部の水準名も可能です。たとえば、「関東が関西の先に来るなんでけしからん！」と思う読者もいるでしょう。この場合、関西の府県名を入れると、指定した水準が最初に位置するようになります。 Score_df_f1 &lt;- Score_df_f1 %&gt;% mutate(Pref3 = fct_relevel(Pref, &quot;京都府&quot;, &quot;大阪府&quot;, &quot;兵庫県&quot;, &quot;奈良県&quot;, &quot;和歌山県&quot;)) levels(Score_df_f1$Pref3) # Pref3の水準 ## [1] &quot;京都府&quot; &quot;大阪府&quot; &quot;兵庫県&quot; &quot;奈良県&quot; &quot;和歌山県&quot; &quot;千葉県&quot; &quot;東京都&quot; ## [8] &quot;埼玉県&quot; &quot;神奈川県&quot; 一部の水準名のみを指定するとその水準が最初に移動されますが、after引数を指定すると、位置を調整することも可能です。after = 2の場合、元となる変数の1、3番目の水準は維持され、3番目以降に指定した水準、それに続いて指定されていない水準の順番になります。Prefは和歌山、奈良、大阪の順ですが、ここで京都と東京を、奈良と大阪の間に移動するなら、 Score_df_f1 &lt;- Score_df_f1 %&gt;% mutate(Pref4 = fct_relevel(Pref, &quot;京都府&quot;, &quot;東京都&quot;, after = 2)) levels(Score_df_f1$Pref4) # Pref4の水準 ## [1] &quot;和歌山県&quot; &quot;奈良県&quot; &quot;京都府&quot; &quot;東京都&quot; &quot;大阪府&quot; &quot;千葉県&quot; &quot;埼玉県&quot; ## [8] &quot;兵庫県&quot; &quot;神奈川県&quot; のように書きます。afterを指定しない場合のデフォルト値は0であるため、最初に移動します。 14.2.2 fct_recode(): 水準のラベルを変更する fct_recode()は水準のラベルを変更する時に使う関数で、以下のように使います。 # 新しい変数名と元となる変数名が一致すると上書きになる データフレーム名 %&gt;% mutate(新しい変数名 = fct_recode(元となる変数名, 新しいラベル1 = &quot;既存のラベル1&quot;, 新しいラベル2 = &quot;既存のラベル2&quot;, 新しいラベル3 = &quot;既存のラベル3&quot;, ...)) 注意点としては新しいラベルは\"で囲まず、既存のラベルは\"で囲む点です。それでは、Prefのラベルをローマ字に変更してみましょう。 Score_df_f1 &lt;- Score_df_f1 %&gt;% mutate(Pref5 = fct_recode(Pref, Saitama = &quot;埼玉県&quot;, Wakayama = &quot;和歌山県&quot;, Kyoto = &quot;京都府&quot;, Osaka = &quot;大阪府&quot;, Tokyo = &quot;東京都&quot;, Nara = &quot;奈良県&quot;, Kanagawa = &quot;神奈川県&quot;, Hyogo = &quot;兵庫県&quot;, Chiba = &quot;千葉県&quot;)) Score_df_f1 ## # A tibble: 9 × 7 ## Pref Score Kanto Pref2 Pref3 Pref4 Pref5 ## &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; ## 1 京都府 3.68 その他 京都府 京都府 京都府 Kyoto ## 2 兵庫県 3.54 その他 兵庫県 兵庫県 兵庫県 Hyogo ## 3 千葉県 3.72 関東 千葉県 千葉県 千葉県 Chiba ## 4 和歌山県 3.97 その他 和歌山県 和歌山県 和歌山県 Wakayama ## 5 埼玉県 3.64 関東 埼玉県 埼玉県 埼玉県 Saitama ## 6 大阪府 3.77 その他 大阪府 大阪府 大阪府 Osaka ## 7 奈良県 3.85 その他 奈良県 奈良県 奈良県 Nara ## 8 東京都 3.67 関東 東京都 東京都 東京都 Tokyo ## 9 神奈川県 3.53 関東 神奈川県 神奈川県 神奈川県 Kanagawa fct_recode()の中に指定する水準の順番は無視されます。つまり、水準の順番はそのまま維持されるため、好きな順番で結構です。また、全ての水準を指定せず、一部のみ変更することも可能です。それではPref5の順番がPrefの順番と同じかを確認してみましょう。 levels(Score_df_f1$Pref) # Prefの水準 ## [1] &quot;和歌山県&quot; &quot;奈良県&quot; &quot;大阪府&quot; &quot;千葉県&quot; &quot;京都府&quot; &quot;東京都&quot; &quot;埼玉県&quot; ## [8] &quot;兵庫県&quot; &quot;神奈川県&quot; levels(Score_df_f1$Pref5) # Pref5の水準 ## [1] &quot;Wakayama&quot; &quot;Nara&quot; &quot;Osaka&quot; &quot;Chiba&quot; &quot;Kyoto&quot; &quot;Tokyo&quot; &quot;Saitama&quot; ## [8] &quot;Hyogo&quot; &quot;Kanagawa&quot; 14.2.3 fct_rev(): 水準の順番を反転させる 水準の順番を反転することは非常によくあります。たとえば、グラフの読みやすさのために、左右または上下を反転するケースがあります。既に何回も強調しましたように、名目変数は基本的にfactor型にすべきであり、ここでfct_rev()関数が非常に便利です。たとえば、Pref2の水準は50音順でありますが、これを反転し、Pref6という名の列として追加してみましょう。 Score_df_f1 &lt;- Score_df_f1 %&gt;% mutate(Pref6 = fct_rev(Pref2)) levels(Score_df_f1$Pref6) ## [1] &quot;和歌山県&quot; &quot;兵庫県&quot; &quot;奈良県&quot; &quot;東京都&quot; &quot;千葉県&quot; &quot;埼玉県&quot; &quot;京都府&quot; ## [8] &quot;神奈川県&quot; &quot;大阪府&quot; 関数一つで水準の順番が反転されました。 14.2.4 fct_infreq(): 頻度順に順番を変更する 続いて、水準の順番を頻度順に合わせるfct_infreq()関数です。たとえば、Scoreが欠損でないケースのみで構成されたdf2を考えてみましょう。 df2 &lt;- df %&gt;% filter(!is.na(Score)) そして、都府県ごとのケース数を計算します。 table(df2$Pref) ## ## 京都府 兵庫県 千葉県 和歌山県 埼玉県 大阪府 奈良県 東京都 ## 79 85 108 24 118 175 28 298 ## 神奈川県 ## 219 ここでPrefをfactor化しますが、水準の順番を店舗数が多い方を先にするにはどうすれば良いでしょうか。fct_infreq()関数は指定された変数の各値の個数を計算し、多い順にfactorの水準を調整します。 df2 &lt;- df2 %&gt;% # 多く出現した値順でfactor化する mutate(Pref = fct_infreq(Pref)) levels(df2$Pref) # df2のPref変数の水準を出力 ## [1] &quot;東京都&quot; &quot;神奈川県&quot; &quot;大阪府&quot; &quot;埼玉県&quot; &quot;千葉県&quot; &quot;兵庫県&quot; &quot;京都府&quot; ## [8] &quot;奈良県&quot; &quot;和歌山県&quot; \"東京都\"、\"神奈川県\"、\"大阪府\"、…の順で水準の順番が調整され、これはtable(df$Pref2)の順位とも一致します。 14.2.5 fct_inorder(): データ内の出現順番に順番を変更する 続いて、fct_inorder()ですが、これは意外と頻繁に使われる関数です。たとえば、自分でデータフレームなどを作成し、ケースの順番も綺麗に整えたとします。しかし、既に指摘した通り、データフレーム (または、tibble)での順番とグラフにおける順番は一致するとは限りません。データフレームに格納された順番でfactorの水準が設定できれば非常に便利でしょう。そこで使うのがfct_inorder()です。 たとえば、dfのPrefは\"東京都\"が1000個並び、続いて\"神奈川県\"が1000個、\"千葉県\"が1000個、…の順番で格納されています。この順番をそのままfactorの順番にするには以下のように書きます。 df3 &lt;- df %&gt;% # Pref変数をfactor化し、水準は出現順とする # 変換後の結果はPrefに上書きする mutate(Pref = fct_inorder(Pref)) levels(df3$Pref) ## [1] &quot;東京都&quot; &quot;神奈川県&quot; &quot;千葉県&quot; &quot;埼玉県&quot; &quot;大阪府&quot; &quot;京都府&quot; &quot;兵庫県&quot; ## [8] &quot;奈良県&quot; &quot;和歌山県&quot; 14.2.6 fct_shift(): 水準の順番をずらす 続いて、水準の順番をずらすfct_shift()関数を紹介します。たとえば、「1:そう思う」〜「5:そう思わない」、「9:答えたくない」の6水準で構成された変数があるとします。 df4 &lt;- tibble( ID = 1:10, Q1 = c(1, 5, 3, 2, 9, 2, 4, 9, 5, 1) ) df4 &lt;- df4 %&gt;% mutate(Q1 = factor(Q1, levels = c(1:5, 9), labels = c(&quot;そう思う&quot;, &quot;どちらかと言えばそう思う&quot;, &quot;どちらとも言えない&quot;, &quot;どちらかと言えばそう思わない&quot;, &quot;そう思わない&quot;, &quot;答えたくない&quot;))) df4 ## # A tibble: 10 × 2 ## ID Q1 ## &lt;int&gt; &lt;fct&gt; ## 1 1 そう思う ## 2 2 そう思わない ## 3 3 どちらとも言えない ## 4 4 どちらかと言えばそう思う ## 5 5 答えたくない ## 6 6 どちらかと言えばそう思う ## 7 7 どちらかと言えばそう思わない ## 8 8 答えたくない ## 9 9 そう思わない ## 10 10 そう思う 水準の順番も「そう思う」〜「答えたくない」順で綺麗に整っています。この水準を反転するにはfct_rev()関数が便利です。Q1の水準を反転した変数をQ1_Rという新しい列として追加し、水準を確認してみましょう。 df4 &lt;- df4 %&gt;% mutate(Q1_R = fct_rev(Q1)) df4 ## # A tibble: 10 × 3 ## ID Q1 Q1_R ## &lt;int&gt; &lt;fct&gt; &lt;fct&gt; ## 1 1 そう思う そう思う ## 2 2 そう思わない そう思わない ## 3 3 どちらとも言えない どちらとも言えない ## 4 4 どちらかと言えばそう思う どちらかと言えばそう思う ## 5 5 答えたくない 答えたくない ## 6 6 どちらかと言えばそう思う どちらかと言えばそう思う ## 7 7 どちらかと言えばそう思わない どちらかと言えばそう思わない ## 8 8 答えたくない 答えたくない ## 9 9 そう思わない そう思わない ## 10 10 そう思う そう思う levels(df4$Q1_R) ## [1] &quot;答えたくない&quot; &quot;そう思わない&quot; ## [3] &quot;どちらかと言えばそう思わない&quot; &quot;どちらとも言えない&quot; ## [5] &quot;どちらかと言えばそう思う&quot; &quot;そう思う&quot; 「答えたくない」が最初の順番に来ましてね。できれば、「そう思わない」〜「そう思う」、「答えたくない」の順番にしたいところです。ここで使うのがfct_shift()ですが、書き方がややこしいので、噛み砕いて解説します。 # fct_shift()の使い方 データ名 %&gt;% mutate(新しい変数名 = fct_shift(元の変数名, n = 左方向へずらす個数)) 問題はn =引数ですが、その挙動については以下の表を参照してください。 水準の順番 1番目 2番目 3番目 4番目 5番目 6番目 n = -2 “E” “F” “A” “B” “C” “D” n = -1 “F” “A” “B” “C” “D” “E” n = 0 “A” “B” “C” “D” “E” “F” n = 1 “B” “C” “D” “E” “F” “A” n = 2 “C” “D” “E” “F” “A” “B” 具体的には水準は左方向へn個移動します。元の水準がA, B, C, …, Fの順で、n = 1の場合、AがFの後ろへ移動し、B, C, D, E, Fが前の方へ1つずつ移動します。逆に右側へ1つ移動したい場合はn = -1のように書きます。今回は最初の水準を最後に移動させたいので、n = 1と指定します。 df4 &lt;- df4 %&gt;% # Q1_Rの水準を左方向で1ずらす mutate(Q1_R = fct_shift(Q1_R, n = 1)) levels(df4$Q1_R) ## [1] &quot;そう思わない&quot; &quot;どちらかと言えばそう思わない&quot; ## [3] &quot;どちらとも言えない&quot; &quot;どちらかと言えばそう思う&quot; ## [5] &quot;そう思う&quot; &quot;答えたくない&quot; これで水準の反転が完了しました。fct_shift()はこのように世論調査データの処理に便利ですが、他にも曜日の処理に使えます。例えば、1週間の始まりを月曜にするか日曜にするかによって、fct_shift()を使うケースがあります。 14.2.7 fct_shuffle(): 水準の順番をランダム化する あまり使わない機能ですが、水準の順番をランダム化することも可能です。使い方は非常に簡単で、fct_shuffle()に元の変数名を入れるだけです。たとえば、Score_dfのPrefの順番をランダム化し、Pref2として追加します。同じことをもう2回繰り返し、それぞれPref3とPref4という名前で追加してみましょう。 Score_df &lt;- Score_df %&gt;% mutate(Pref2 = fct_shuffle(Pref), Pref3 = fct_shuffle(Pref), Pref4 = fct_shuffle(Pref)) Score_df ## # A tibble: 9 × 5 ## Pref Score Pref2 Pref3 Pref4 ## &lt;chr&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; ## 1 京都府 3.68 京都府 京都府 京都府 ## 2 兵庫県 3.54 兵庫県 兵庫県 兵庫県 ## 3 千葉県 3.72 千葉県 千葉県 千葉県 ## 4 和歌山県 3.97 和歌山県 和歌山県 和歌山県 ## 5 埼玉県 3.64 埼玉県 埼玉県 埼玉県 ## 6 大阪府 3.77 大阪府 大阪府 大阪府 ## 7 奈良県 3.85 奈良県 奈良県 奈良県 ## 8 東京都 3.67 東京都 東京都 東京都 ## 9 神奈川県 3.53 神奈川県 神奈川県 神奈川県 levels(Score_df$Pref2) ## [1] &quot;神奈川県&quot; &quot;奈良県&quot; &quot;京都府&quot; &quot;東京都&quot; &quot;兵庫県&quot; &quot;大阪府&quot; &quot;千葉県&quot; ## [8] &quot;埼玉県&quot; &quot;和歌山県&quot; levels(Score_df$Pref3) ## [1] &quot;埼玉県&quot; &quot;東京都&quot; &quot;神奈川県&quot; &quot;千葉県&quot; &quot;兵庫県&quot; &quot;京都府&quot; &quot;大阪府&quot; ## [8] &quot;和歌山県&quot; &quot;奈良県&quot; levels(Score_df$Pref4) ## [1] &quot;大阪府&quot; &quot;奈良県&quot; &quot;埼玉県&quot; &quot;兵庫県&quot; &quot;東京都&quot; &quot;千葉県&quot; &quot;京都府&quot; ## [8] &quot;和歌山県&quot; &quot;神奈川県&quot; PrefからPref4まで同じように見えますが、水準の順番が異なります (Prefはcharacter型だから水準がありません)。 14.2.8 fct_reorder(): 別の1変数の値を基準に水準の順番を変更する fct_infreq()は出現頻度順に並び替える関数でしたが、それと似たような関数としてfct_reorder()があります。ただし、これは出現頻度を基準にするのではなく、ある変数の平均値が低い順、中央値が高い順などでソートされます。まずは使い方から確認します。 データ名 %&gt;% mutate(新しい変数名 = fct_reorder(元の変数名, 基準となる変数, 関数名, 関数の引数)) 必要な引数が多いですね。解説よりも実際の例を見ながら説明します。今回もPrefをfactor変数にし、Pref_Rという列で格納しますが、平均予算が安い順でfactorの水準を決めたいと思います。 df &lt;- df %&gt;% mutate(Pref_R = fct_reorder(Pref, Budget, mean, na.rm = TRUE)) levels(df$Pref_R) ## [1] &quot;千葉県&quot; &quot;埼玉県&quot; &quot;奈良県&quot; &quot;兵庫県&quot; &quot;大阪府&quot; &quot;神奈川県&quot; &quot;和歌山県&quot; ## [8] &quot;東京都&quot; &quot;京都府&quot; Pref_Rの水準は千葉県、埼玉県、奈良県、…の順ですが、本当にそうでしょうか。group_by()とsummarise()などを使って確認してみましょう。 df %&gt;% group_by(Pref) %&gt;% summarise(Budget = mean(Budget, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;% arrange(Budget) ## # A tibble: 9 × 2 ## Pref Budget ## &lt;chr&gt; &lt;dbl&gt; ## 1 千葉県 1124. ## 2 埼玉県 1147. ## 3 奈良県 1169. ## 4 兵庫県 1197. ## 5 大阪府 1203. ## 6 神奈川県 1239. ## 7 和歌山県 1252 ## 8 東京都 1283. ## 9 京都府 1399. 問題なくソートされましたね。注意点としてはfct_reorder()内に関数名を書く際、()は不要という点です。関数名の次の引数としてはその関数に別途必要な引数を指定します。引数が省略可能、あるいは不要な関数を使う場合は、省略しても構いませんし、数に制限はありません。 また、低い順ではなく、高い順にすることも可能です。次はScoreの中央値が高い順に水準を設定したPref_R2を作ってみましょう。 df &lt;- df %&gt;% mutate(Pref_R2 = fct_reorder(Pref, Score, median, na.rm = TRUE, .desc = TRUE)) levels(df$Pref_R2) ## [1] &quot;和歌山県&quot; &quot;奈良県&quot; &quot;千葉県&quot; &quot;大阪府&quot; &quot;東京都&quot; &quot;埼玉県&quot; &quot;京都府&quot; ## [8] &quot;兵庫県&quot; &quot;神奈川県&quot; 変わったのはmeanの代わりにmedianを使ったこと、そして.desc引数が追加された点です。fct_reorder()には.desc = FALSEがデフォルトとして指定されており、省略した場合は昇順でfactorの水準が決まります。ここで.desc = TRUEを指定すると、降順となります。実際、Scoreの中央値順になっているかを確認してみましょう。 df %&gt;% group_by(Pref) %&gt;% summarise(Score = median(Score, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;% arrange(desc(Score)) ## # A tibble: 9 × 2 ## Pref Score ## &lt;chr&gt; &lt;dbl&gt; ## 1 和歌山県 4 ## 2 奈良県 3.88 ## 3 千葉県 3.75 ## 4 大阪府 3.75 ## 5 東京都 3.64 ## 6 埼玉県 3.61 ## 7 京都府 3.5 ## 8 兵庫県 3.5 ## 9 神奈川県 3.5 14.2.9 fct_reorder2(): 別の2変数の値を基準に水準の順番を変更する この関数は別の変数を基準に水準が調整される点ではfct_reorder()と類似しています。ただし、よく誤解されるのは「変数Aの値が同じなら変数Bを基準に…」といったものではありません。たとえば、fct_reorder(x, y, mean)の場合、yの平均値 (mean())の順でxの水準を調整するという意味です。このmean()関数に必要なデータはベクトル1つです。しかし、関数によっては2つの変数が必要な場合があります。 これは頻繁に直面する問題ではありませんが、このfct_reorder2()関数が活躍するケースを紹介します。以下は6月27日から7月1日までの5日間、5地域におけるCOVID-19新規感染者数を表したデータです78。入力が面倒な方はここからダウンロードして読み込んでください。 # 入力が面倒ならデータをダウンロードし、 # Reorder2_df &lt;- read_csv(&quot;Data/COVID19.csv&quot;) Reorder2_df &lt;- tibble( Country = rep(c(&quot;日本&quot;, &quot;韓国&quot;, &quot;中国 (本土)&quot;, &quot;台湾&quot;, &quot;香港&quot;), each = 5), Date = rep(c(&quot;2020/06/27&quot;, &quot;2020/06/28&quot;, &quot;2020/06/29&quot;, &quot;2020/06/30&quot;, &quot;2020/07/01&quot;), 5), NewPat = c(100, 93, 86, 117, 130, 62, 42, 43, 50, 54, 17, 12, 19, 3, 5, 0, 0, 0, 0, 0, 1, 2, 4, 2, 28) ) Reorder2_df &lt;- Reorder2_df %&gt;% mutate(Date = as.Date(Date)) Reorder2_df ## # A tibble: 25 × 3 ## Country Date NewPat ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 日本 2020-06-27 100 ## 2 日本 2020-06-28 93 ## 3 日本 2020-06-29 86 ## 4 日本 2020-06-30 117 ## 5 日本 2020-07-01 130 ## 6 韓国 2020-06-27 62 ## 7 韓国 2020-06-28 42 ## 8 韓国 2020-06-29 43 ## 9 韓国 2020-06-30 50 ## 10 韓国 2020-07-01 54 ## # … with 15 more rows 可視化のコードはとりあえず無視し、グラフを出力してみましょう。 Reorder2_df %&gt;% ggplot() + geom_line(aes(x = Date, y = NewPat, color = Country), size = 1) + scale_x_date(date_labels = &quot;%Y年%m月%d日&quot;) + labs(x = &quot;年月日&quot;, y = &quot;新規感染者数 (人)&quot;, color = &quot;&quot;) + theme_gray(base_size = 12) 図 14.7: 国名の順番を変更した前 このグラフに違和感はあまりありませんが、「読みやすさ」の麺では改善の余地があります。たとえば、7月1日の時点で、新規感染者数が多いのは日本、韓国、香港、中国 (本土)、台湾の順です。しかし、右側の凡例の順番はそうではありません。この順番が一致すれば、更に図は読みやすくなるでしょう。 factor(Reorder2_df$Country) ## [1] 日本 日本 日本 日本 日本 韓国 ## [7] 韓国 韓国 韓国 韓国 中国 (本土) 中国 (本土) ## [13] 中国 (本土) 中国 (本土) 中国 (本土) 台湾 台湾 台湾 ## [19] 台湾 台湾 香港 香港 香港 香港 ## [25] 香港 ## Levels: 中国 (本土) 台湾 日本 韓国 香港 実際、何も指定せずにReorder2_dfのCountryをfactor化すると、韓国、香港、台湾、…の順であり、これは上のグラフと一致します。これをグラフにおける7月1日の新規感染者数の順で並べるためには、Dateを昇順にソートし、そして最後の要素 (\"2020/07/01\")内で新規感染者数 (NewPat)を降順に並べ替えた場合の順番にする必要があります。実際、Reorder2_dfをDateで昇順、NewPatで降順にソートし、最後の5行を抽出した結果が以下のコードです。 Reorder2_df %&gt;% arrange(Date, desc(NewPat)) %&gt;% slice_tail(n = 5) ## # A tibble: 5 × 3 ## Country Date NewPat ## &lt;chr&gt; &lt;date&gt; &lt;dbl&gt; ## 1 日本 2020-07-01 130 ## 2 韓国 2020-07-01 54 ## 3 香港 2020-07-01 28 ## 4 中国 (本土) 2020-07-01 5 ## 5 台湾 2020-07-01 0 このように、水準を調整する際に2つの変数 (DateとNewPat)が使用されます。fct_reorder2()はfct_reorder()と買い方がほぼ同じですが、基準となる変数がもう一つ加わります。 データ名 %&gt;% mutate(新しい変数名 = fct_reorder2(元の変数名, 基準となる変数1, 基準となる変数2, 関数名, 関数の引数)) 重要なのはここの関数のところですが、fct_reorder2()はデフォルトでlast2()という関数が指定されており、まさに私たちに必要な関数です。したがって、ここでは関数名も省略できますが、ここでは一応明記しておきます。 Reorder2_df &lt;- Reorder2_df %&gt;% mutate(Country2 = fct_reorder2(Country, Date, NewPat, last2)) それでは新しく出来たCountry2の水準を確認してみましょう。 levels(Reorder2_df$Country2) ## [1] &quot;日本&quot; &quot;韓国&quot; &quot;香港&quot; &quot;中国 (本土)&quot; &quot;台湾&quot; ちゃんと7月1日の新規感染者数基準で水準の順番が調整されましたので、これを使ってグラフをもう一回作ってみます。 Reorder2_df %&gt;% ggplot() + geom_line(aes(x = Date, y = NewPat, color = Country2), size = 1) + scale_x_date(date_labels = &quot;%Y年%m月%d日&quot;) + labs(x = &quot;年月日&quot;, y = &quot;新規感染者数 (人)&quot;, color = &quot;&quot;) + theme_gray(base_size = 12) 図 14.8: 国名の順番を変更した後 これで図がさらに読みやすくなりました。ちなみに、{forcats}パッケージはlast2()以外にもfirst2()という関数も提供しております。これを使うと、7月1日でなく、6月27日の新規感染者数の降順で水準の順番が調整されます。他にも引数を2つ使用する自作関数も使えますが、fct_reorder2()の主な使いみちはlast2()で十分でしょう。 14.2.10 fct_collapse(): 水準を統合する 水準数をより水準数に減らすためには、fct_recode()を使います。先ほど、fct_shift()で使ったdf4の例を考えてみましょう。df4のQ1の水準数は6つです。 levels(df4$Q1) ## [1] &quot;そう思う&quot; &quot;どちらかと言えばそう思う&quot; ## [3] &quot;どちらとも言えない&quot; &quot;どちらかと言えばそう思わない&quot; ## [5] &quot;そう思わない&quot; &quot;答えたくない&quot; これを4つに減らして見ましょう。具体的には「そう思う」と「どちらかと言えばそう思う」を「そう思う」に、「そう思わない」と「どちらかと言えばそう思わない」を「そう思わない」に統合します。これをfct_recode()で処理したのが以下のコードです。 # fct_recode()を使った例 df4 &lt;- df4 %&gt;% mutate(Q1_R2 = fct_recode(Q1, そう思う = &quot;そう思う&quot;, そう思う = &quot;どちらかと言えばそう思う&quot;, どちらとも言えない = &quot;どちらとも言えない&quot;, そう思わない = &quot;どちらかと言えばそう思わない&quot;, そう思わない = &quot;そう思わない&quot;, 答えたくない = &quot;答えたくない&quot;)) df4 ## # A tibble: 10 × 4 ## ID Q1 Q1_R Q1_R2 ## &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; ## 1 1 そう思う そう思う そう思う ## 2 2 そう思わない そう思わない そう思わない ## 3 3 どちらとも言えない どちらとも言えない どちらとも言… ## 4 4 どちらかと言えばそう思う どちらかと言えばそう思う そう思う ## 5 5 答えたくない 答えたくない 答えたくない ## 6 6 どちらかと言えばそう思う どちらかと言えばそう思う そう思う ## 7 7 どちらかと言えばそう思わない どちらかと言えばそう思わない そう思わない ## 8 8 答えたくない 答えたくない 答えたくない ## 9 9 そう思わない そう思わない そう思わない ## 10 10 そう思う そう思う そう思う levels(df4$Q1_R2) ## [1] &quot;そう思う&quot; &quot;どちらとも言えない&quot; &quot;そう思わない&quot; ## [4] &quot;答えたくない&quot; しかし、水準を統合するに特化したfct_collapse()を使えばより便利です。使い方は、fct_recode()に非常に似ているため省略しますが、=の右側をc()でまとめることが出来ます。 # fct_collapse()を使った例 df4 &lt;- df4 %&gt;% mutate(Q1_R3 = fct_collapse(Q1, そう思う = c(&quot;そう思う&quot;, &quot;どちらかと言えばそう思う&quot;), どちらとも言えない = &quot;どちらとも言えない&quot;, そう思わない = c( &quot;どちらかと言えばそう思わない&quot;, &quot;そう思わない&quot;), 答えたくない = &quot;答えたくない&quot;)) df4 ## # A tibble: 10 × 5 ## ID Q1 Q1_R Q1_R2 Q1_R3 ## &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; ## 1 1 そう思う そう思う そう思… そう… ## 2 2 そう思わない そう思わない そう思… そう… ## 3 3 どちらとも言えない どちらとも言えない どちら… どち… ## 4 4 どちらかと言えばそう思う どちらかと言えばそう思う そう思… そう… ## 5 5 答えたくない 答えたくない 答えた… 答え… ## 6 6 どちらかと言えばそう思う どちらかと言えばそう思う そう思… そう… ## 7 7 どちらかと言えばそう思わない どちらかと言えばそう思わない そう思… そう… ## 8 8 答えたくない 答えたくない 答えた… 答え… ## 9 9 そう思わない そう思わない そう思… そう… ## 10 10 そう思う そう思う そう思… そう… levels(df4$Q1_R3) ## [1] &quot;そう思う&quot; &quot;どちらとも言えない&quot; &quot;そう思わない&quot; ## [4] &quot;答えたくない&quot; fct_recode()の結果と同じ結果が得られました。元の水準数や、減らされる水準数などによっては書く手間があまり変わらないので、好きな方を使っても良いでしょう。 14.2.11 fct_drop(): 使われていない水準を除去する 水準としては存在するものの、データとしては存在しないケースもあります。これをここでは「空水準 (empty levels)」と呼びます。たとえば、以下のコードはPrefをfactor化してからPref == \"奈良県\"のケースを落としたものです。 Score_df_f2 &lt;- df %&gt;% mutate(Pref = fct_inorder(Pref)) %&gt;% filter(Pref != &quot;奈良県&quot;) %&gt;% group_by(Pref) %&gt;% summarise(Score = mean(Score, na.rm = TRUE), .groups = &quot;drop&quot;) Score_df_f2 ## # A tibble: 8 × 2 ## Pref Score ## &lt;fct&gt; &lt;dbl&gt; ## 1 東京都 3.67 ## 2 神奈川県 3.53 ## 3 千葉県 3.72 ## 4 埼玉県 3.64 ## 5 大阪府 3.77 ## 6 京都府 3.68 ## 7 兵庫県 3.54 ## 8 和歌山県 3.97 このように結果としては、奈良県のデータを除外したため空水準である奈良県は表示されませんが、Pref変数はどうでしょうか。 levels(Score_df_f2$Pref) ## [1] &quot;東京都&quot; &quot;神奈川県&quot; &quot;千葉県&quot; &quot;埼玉県&quot; &quot;大阪府&quot; &quot;京都府&quot; &quot;兵庫県&quot; ## [8] &quot;奈良県&quot; &quot;和歌山県&quot; このように水準としては残っていることが分かります。使われていない水準が分析や可視化に影響を与えないケースもありますが、与えるケースもあります。これもこれまで勉強してきたfct_*()関数群で対応可能ですが、fct_drop()関数を使えば一発で終わります。実際にやってみましょう。 Score_df_f2 &lt;- Score_df_f2 %&gt;% mutate(Pref = fct_drop(Pref)) levels(Score_df_f2$Pref) ## [1] &quot;東京都&quot; &quot;神奈川県&quot; &quot;千葉県&quot; &quot;埼玉県&quot; &quot;大阪府&quot; &quot;京都府&quot; &quot;兵庫県&quot; ## [8] &quot;和歌山県&quot; 水準から奈良県が消えました。同じ機能をする関数としてはR内蔵関数であるdroplevels()関数があり、使い方はfct_drop()と同じです。 14.2.12 fct_expand(): 水準を追加する 一方、空水準を追加することも可能です。fct_expand()関数には元の変数名に加え、追加する水準名を入れるだけです。たとえば、dfのPrefの水準は関東と関西の9都府県名となっていますが、ここに\"滋賀県\"という水準を追加してみます。。 df5 &lt;- df %&gt;% mutate(Pref = fct_expand(Pref, &quot;滋賀県&quot;)) levels(df5$Pref) ## [1] &quot;京都府&quot; &quot;兵庫県&quot; &quot;千葉県&quot; &quot;和歌山県&quot; &quot;埼玉県&quot; &quot;大阪府&quot; ## [7] &quot;奈良県&quot; &quot;東京都&quot; &quot;神奈川県&quot; &quot;滋賀県&quot; \"滋賀県\"という新しい水準が出来ましたね。ただし、新しく追加された水準は最後の順番になりますので、修正が必要な場合はfct_relevel()などを使って適宜修正してください。 新しく水準が追加されることによって、何かの変化はあるでしょうか。まずは都府県ごとにScoreの平均値とケース数を計算してみましょう。 df5 %&gt;% group_by(Pref) %&gt;% summarise(Score = mean(Score, na.rm = TRUE), N = n(), .groups = &quot;drop&quot;) ## # A tibble: 9 × 3 ## Pref Score N ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; ## 1 京都府 3.68 414 ## 2 兵庫県 3.54 591 ## 3 千葉県 3.72 1000 ## 4 和歌山県 3.97 140 ## 5 埼玉県 3.64 1000 ## 6 大阪府 3.77 1000 ## 7 奈良県 3.85 147 ## 8 東京都 3.67 1000 ## 9 神奈川県 3.53 1000 見た目は全く変わらず、滋賀県の行が新しく出来たわけでもありません。dplyrのgroup_by()の場合、空水準はグループ化の対象になりません。一方、多くのR内蔵関数はケースとして存在しなくても計算の対象となります。たとえば、ベクトル内のある値が何個格納されているか確認するtable()関数の例を見てみましょう。 table(df5$Pref) ## ## 京都府 兵庫県 千葉県 和歌山県 埼玉県 大阪府 奈良県 東京都 ## 414 591 1000 140 1000 1000 147 1000 ## 神奈川県 滋賀県 ## 1000 0 \"滋賀県\"という列があり、合致するケースが0と表示されます。group_by()でも空の水準まで含めて出力する引数.dropがあります。デフォルトはTRUEですが、これをFALSEに指定してみます。 df5 %&gt;% group_by(Pref, .drop = FALSE) %&gt;% summarise(Score = mean(Score, na.rm = TRUE), N = n(), .groups = &quot;drop&quot;) ## # A tibble: 10 × 3 ## Pref Score N ## &lt;fct&gt; &lt;dbl&gt; &lt;int&gt; ## 1 京都府 3.68 414 ## 2 兵庫県 3.54 591 ## 3 千葉県 3.72 1000 ## 4 和歌山県 3.97 140 ## 5 埼玉県 3.64 1000 ## 6 大阪府 3.77 1000 ## 7 奈良県 3.85 147 ## 8 東京都 3.67 1000 ## 9 神奈川県 3.53 1000 ## 10 滋賀県 NaN 0 空水準も出力され、Scoreの平均値は計算不可 (NaN)、ケース数は0という結果が得られました。 14.2.13 fct_explicit_na(): 欠損値に水準を与える まずは、実習用データdf6を作ってみまます。X1はnumeric型変数ですが、これをfactor化します。最初からtibble()内でfactor化しておいても問題ありませんが、練習だと思ってください。 df6 &lt;- tibble( ID = 1:10, X1 = c(1, 3, 2, NA, 2, 2, 1, NA, 3, NA) ) df6 &lt;- df6 %&gt;% mutate(X1 = factor(X1, levels = c(1, 2, 3), labels = c(&quot;ラーメン&quot;, &quot;うどん&quot;, &quot;そば&quot;))) df6 ## # A tibble: 10 × 2 ## ID X1 ## &lt;int&gt; &lt;fct&gt; ## 1 1 ラーメン ## 2 2 そば ## 3 3 うどん ## 4 4 &lt;NA&gt; ## 5 5 うどん ## 6 6 うどん ## 7 7 ラーメン ## 8 8 &lt;NA&gt; ## 9 9 そば ## 10 10 &lt;NA&gt; それではX1をグループ化変数とし、ケース数を計算してみましょう。 df6 %&gt;% group_by(X1) %&gt;% summarise(N = n(), .groups = &quot;drop&quot;) ## # A tibble: 4 × 2 ## X1 N ## &lt;fct&gt; &lt;int&gt; ## 1 ラーメン 2 ## 2 うどん 3 ## 3 そば 2 ## 4 &lt;NA&gt; 3 NAもグループ化の対象となります。以下はこの欠損値も一つの水準として指定する方法について紹介します。欠損値を欠損値のままにするケースが多いですが、欠損値が何らかの意味を持つ場合、分析の対象になります。たとえば、多項ロジスティック回帰の応答変数として「分からない/答えたくない」を含めたり、「分からない/答えたくない」を選択する要因を分析したい場合は、欠損値に値を与える必要があります。なぜなら、一般的な分析において欠損値は分析対象から除外されるからです。 まずは、これまで紹介した関数を使ったやり方から紹介します。 df6 %&gt;% # まず、X1をcharacter型に変換し、X2という列に保存 mutate(X2 = as.character(X1), # X2がNAなら&quot;欠損値&quot;、それ以外なら元のX2の値に置換 X2 = ifelse(is.na(X2), &quot;欠損値&quot;, X2), # X2を再度factor化する X2 = factor(X2, levels = c(&quot;ラーメン&quot;, &quot;うどん&quot;, &quot;そば&quot;, &quot;欠損値&quot;))) ## # A tibble: 10 × 3 ## ID X1 X2 ## &lt;int&gt; &lt;fct&gt; &lt;fct&gt; ## 1 1 ラーメン ラーメン ## 2 2 そば そば ## 3 3 うどん うどん ## 4 4 &lt;NA&gt; 欠損値 ## 5 5 うどん うどん ## 6 6 うどん うどん ## 7 7 ラーメン ラーメン ## 8 8 &lt;NA&gt; 欠損値 ## 9 9 そば そば ## 10 10 &lt;NA&gt; 欠損値 X1をcharacter型に戻す理由79は、水準にない値が入るとfactor化が解除されるからです。factor型をcharacter型に戻さずにdf6$X1のNAを\"欠損値\"に置換すると、以下のようになります。 # df6のX1がNAなら&quot;欠損&quot;、それ以外なら元のX1の値を返す ifelse(is.na(df6$X1), &quot;欠損値&quot;, df6$X1) ## [1] &quot;1&quot; &quot;3&quot; &quot;2&quot; &quot;欠損値&quot; &quot;2&quot; &quot;2&quot; &quot;1&quot; &quot;欠損値&quot; ## [9] &quot;3&quot; &quot;欠損値&quot; \"ラーメン\"と\"うどん\"、\"そば\"がfactor化前の1, 2, 3に戻っただけでなく、NAが\"欠損値\"というcharacter型に置換されたため、全体がcharacter型に変換されました。このように欠損値に水準を与える作業は難しくはありませんが、面倒な作業です。そこで登場する関数がfct_exlpicit_na()関数です。使い方は、元の変数に加え、欠損値の水準名を指定するna_levelです。 df6 &lt;- df6 %&gt;% # na_levelのデフォルト値は&quot;(Missing)&quot; mutate(X2 = fct_explicit_na(X1, na_level = &quot;欠損値&quot;)) df6 ## # A tibble: 10 × 3 ## ID X1 X2 ## &lt;int&gt; &lt;fct&gt; &lt;fct&gt; ## 1 1 ラーメン ラーメン ## 2 2 そば そば ## 3 3 うどん うどん ## 4 4 &lt;NA&gt; 欠損値 ## 5 5 うどん うどん ## 6 6 うどん うどん ## 7 7 ラーメン ラーメン ## 8 8 &lt;NA&gt; 欠損値 ## 9 9 そば そば ## 10 10 &lt;NA&gt; 欠損値 欠損値が一つの水準になったことが分かります。 df6 %&gt;% group_by(X2) %&gt;% summarise(N = n(), .groups = &quot;drop&quot;) ## # A tibble: 4 × 2 ## X2 N ## &lt;fct&gt; &lt;int&gt; ## 1 ラーメン 2 ## 2 うどん 3 ## 3 そば 2 ## 4 欠損値 3 むろん、group_by()を使ってもちゃんと出力されます。 練習問題 "],["tidydata.html", "15. 整然データ構造 15.1 整然データ (tidy data)とは 15.2 Wide型からLong型へ 15.3 Long型からWide型へ 15.4 列の操作", " 15. 整然データ構造 本章ではグラフの作成に適した形へデータを整形することについて学習します。ただし、これはグラフに限られた話ではありません。作図に適したデータは分析にも適します。 15.1 整然データ (tidy data)とは 分析や作図に適したデータの形は整然データ、または簡潔データ (tidy data)と呼ばれます。整然データの概念はtidyverse世界の産みの親であるHadely Wickham先生が提唱した概念であり、詳細は Wickham (2014) を参照してください。 整然データは目指す到達点は非常に単純です。それは「データの構造 (structure)と意味 (semantic)を一致させる」ことです。そして、この「意味」を出来る限り小さい単位で分解します。 例えば、3人で構成されたあるクラス内の被験者に対し、投薬前後に測定した数学成績があるとします。投薬前の成績は\"Control\"、投薬後の状況を\"Treatment\"とします。これをまとめたのが表15.1です。 表 15.1: Messy Dataの例 (1) Name Control Treatment Hadley 90 90 Song 80 25 Yanai 100 95 また、以上の表は転置も可能であり、以下のように表現することが可能です (表15.2)。 表 15.2: Messy Dataの例 (2) Treat Hadely Song Yanai Control 90 80 100 Treatment 90 25 95 2つのデータが持つ情報は全く同じです。これは「同じ意味を持つが、異なる構造を持つ」とも言えます。このような多様性が生じる理由は行と列のあり方が各値を説明するに十分ではないからです。異なるデータ構造として表現される余地があるということです。 たとえば、表15.1の場合、各列は以下のような3つの情報があります。 Name: 被験者名 Control: 投薬前の数学成績 Treatment: 投薬後の数学成績 このデータの問題は「投薬有無」と「数学成績」が2回登場したという点です。1は問題ありませんが、2と3の値は「投薬有無 \\(\\times\\) 数学成績」の組み合わせです。一つの変数に2つの情報が含まれていますね。これによって、投薬有無を行にしても列にしてもいいわけです。「ならばこっちの方が柔軟だしいいのでは?」と思う方もいるかも知れません。しかし、パソコンはこの曖昧さが嫌いです。なぜなら、人間のような思考ができないからです。データフレームは縦ベクトルの集合であるから、各列には一つの情報のみ格納する必要があります。たとえば、以下のように列を変更するとしましょう。 Name: 被験者名 Treat: 投薬有無 Math_Score: 数学成績 Treatは投薬前なら\"Control\"の値を、投薬後なら\"Treatment\"の値が入ります。Math_Socreには数学成績が入ります。これに則って表に直したのが表15.3です。 表 15.3: 整然データの例 Name Treat Math_Score Hadley Control 90 Hadley Treatment 90 Song Control 80 Song Treatment 25 Yanai Control 100 Yanai Treatment 95 表が長くなりましたが、これなら一つの列に2つ以上の情報が含まれることはありません。この場合、表15.1と表15.2のように、行と列を転置することができるでしょうか。 表 15.4: 表15.3を転置した場合 Name Hadley Hadley Song Song Yanai Yanai Treat Control Treatment Control Treatment Control Treatment Math_Score 90 90 80 25 100 95 その結果が表15.4ですが、いかがでしょうか。まず、列名が重複している時点でアウトですし、人間が見ても非常に分かりにくい表になりました。また、一つの列に異なるデータ (この場合、character型とnumeirc型)が混在しています。パソコンから見てはわけのわからないデータになったわけです。 ここまで来たら整然データのイメージはある程度掴めたかも知れません。具体的に整然データとは次の4つの条件を満たすデータです(Wickham 2014)。 1つの列は、1つの変数を表す。 1つの行は、1つの観測を表す。 1つのセル（特定の列の特定の行）は、1つの値を表す。 1つの表は、1つの観測単位 (unit of observation)をもつ（異なる観測単位が混ざっていない）。 以下でも、表15.1と表15.3を対比しながら、以上の4条件をより詳しく説明します。 15.1.1 1つの列は、1つの変数を表す 表15.1と表15.3に含まれる情報は以下の3つで共通しています。 被験者名 投薬有無 数学成績 これらの情報がそれぞれデータの変数になるわけですが、整然データは一つの列が一つの変数を表します。それではまず、表15.1 (図15.1の左)から考えてみましょう。この図には3つの情報が全て含まれています。しかし、数学成績は2列に渡って格納されており、「1列1変数」の条件を満たしておりません。一方、表15.3 (図15.1の右)は投薬前後を表すTreat変数を作成し、その値に応じた数学成績が格納されており、「1列1変数」の条件を満たしています。 図 15.1: 1つの列は、1つの変数を表す 「1列1変数」は整然データの最も基本となる条件であり、整然データ作成の出発点とも言えます。 15.1.2 1つの行は、1つの観測を表す 図15.2の左は一行当たり、いくつの観察が含まれているでしょうか。そのためにはこのデータが何を観察しているかを考える必要があります。このデータは投薬前後の数学成績を観察し、量的に測定したものです。つまり、同じ人に対して2回観察を行ったことになります。したがって、投薬前の数学成績と投薬後の数学成績は別の観察であり、図15.2の左は3行の表ですが、実は6回分の観察が含まれていることになります。1行に2つの観察が載っていることですね。 図 15.2: 1つの行は、1つの観測を表す 一方、図15.2の右は6行のデータであり、観察回数とデータの行数が一致しています。つまり、1行に1観察となります。 今回は数学成績しか測っていたいので、簡単な例ですが、実際のデータには曖昧な部分があります。たとえば、投薬によって血圧が変化する可能性があるため、最高血圧もまた投薬前後に測定したとします。それが表15.5の左です。 表 15.5: 1行1観察の例 Name Treat Math Blood Hadley Control 90 110 Hadley Treatment 90 115 Song Control 80 95 Song Treatment 25 110 Yanai Control 100 100 Yanai Treatment 95 95 Name Treat Type Value Hadley Control Math 90 Hadley Control Blood 110 Hadley Treatment Math 90 Hadley Treatment Blood 115 Song Control Math 80 Song Control Blood 95 Song Treatment Math 25 Song Treatment Blood 110 Yanai Control Math 100 Yanai Control Blood 100 Yanai Treatment Math 95 Yanai Treatment Blood 95 3人に投薬前後に数学成績と最高血圧を測定した場合の観察回数は何回でしょう。3人 \\(\\times\\) 2時点 \\(\\times\\) 2指標の測定だから12回の測定でしょうか。ならば、表15.5の右が整然データでしょう。しかし、この場合、1列1変数という条件が満たされなくなります。Value列には数学成績と血圧が混在しており、2つの変数になります。ならば、どれも整然データではないということでしょうか。実は整然データは表15.5の左です。なぜなら、「1観察=1値」ではないからです。データにおける観察とは観察単位ごとに測定された値の集合です。観察対象とは人や自治体、企業、国などだけでなく、時間も含まれます。たとえば、人の特徴 (性別、身長、所得、政治関心など)を測定しもの、ある日の特徴 (気温、株価など)を測定したもの全てが観察です。むろん、人 \\(\\times\\) 時間のような組み合わせが観察単位ともなり得ます。この一つ一つの観察単位から得られた値の集合が観察です。表15.5の分析単位は「人 \\(\\times\\) 時間」です。成績や最高血圧は分析単位が持つ特徴や性質であって、分析単位ではありません。 15.1.3 1つのセルは、1つの値を表す この条件に反するケースはあまりないかも知れません。たとえば、「Hadleyは処置前後の数学成績が同じだし、一行にまとめよう」という意味で図15.3の左のような表を作る方もいるかも知れませんが、あまりいないでしょう。 図 15.3: 1つのセルは、1つの値を表す 図15.3の例は「1セル1値」の条件に明らかに反します。しかし、基準が曖昧な変数もあり、その一つが日付です。 表 15.6: 日付の扱い方 Date Stock 2020/06/29 100 2020/06/30 105 2020/07/01 110 2020/07/02 85 2020/07/03 90 Year Month Date Stock 2020 6 29 100 2020 6 30 105 2020 7 1 110 2020 7 2 85 2020 7 3 90 表15.6の左側の表はどうでしょうか。5日間の株価を記録した架空のデータですが、たしかにDate列には日付が1つずつ、Stockには株価の値が1つずつ格納されています。しかし、解釈によっては「Dateに年、月、日といった3つの値が含まれているぞ」と見ることもできます。この解釈に基づく場合、表15.6の右側の表が整然データとなり、左側は雑然データとなります。このケースは第一条件であった「一列一変数」とも関係します。なぜなら、Dateという列が年・月・日といった3変数で構成されているとも解釈できるからです。 分析によっては左側のような表でも全く問題ないケースもあります。時系列分析でトレンド変数のみ必要ならこれでも十分に整然データと呼べます。しかし、季節変動などの要素も考慮するならば、左側は雑然データになります。データとしての使い勝手は右側の方が優れているのは確かです。 データを出来る限り細かく分解するほど情報量が豊かになりますが、それにも限度はあるでしょう。たとえば、「Yearは実は世紀の情報も含まれているのでは…?」という解釈もできますが、これを反映してデータ整形を行うか否かは分析の目的と分析モデルによって異なります。この意味で、明らかな雑然データはあり得ますが、明らかな整然データは存在しないでしょう。どちらかといえば、整然さの度合いがあり、「これなら十分に整然データと言えないだろうか」と判断できれば十分ではないかと筆者 (Song)は考えます。 15.1.4 1つの表は、1つの観測単位をもつ e-statなどから国勢調査データをダウンロードした経験はあるでしょうか。以下の図15.4は2015年度国勢調査データの一部です。 図 15.4: 国勢調査データ このデータの観察単位はなんでしょうか。データのの1行目は全国の人口を表しています。つまり、単位は国となります。しかし、2行目は北海道の人口です。この場合の観測単位は都道府県となります。つづいて、3行目は札幌市なので単位は市区町村になります。4行目は札幌市中央区、つまり観測単位が行政区になっています。そして14行目は函館市でまた単位は市区町村に戻っています。実際、会社や政府が作成するデータには図15.4や図15.5のようなものが多いです。とりわけ、図15.5のように、最後の行に「合計」などが表記されている場合が多いです。 図 15.5: 1つの表は、1つの観測単位をもつ このような表・データを作成することが悪いことではありません。むしろ、「読む」ための表ならこのような書き方が一般的でしょう。しかし、「分析」のためのデータは観察の単位を統一する必要があります。 15.2 Wide型からLong型へ 以下では「1列1変数」の条件を満たすデータの作成に便利なpivot_longer()とpivot_wider()関数について解説します。この関数群はおなじみの{dplyr}でなく、{tidyr}パッケージが提供している関数ですが、どれも{tidyverse}パッケージ群に含まれているため、{tidyverse}パッケージを読み込むだけで十分です。本節ではpivot_longer()を、次節ではpivot_wider()を取り上げます。 まず、pivot_longer()ですが、この関数は比較的に新しい関数であり、これまでは{tidyr}のgather()関数が使われてきました。しかし、gahter()関数は将来、なくなる予定の関数であり、今から{tidyr}を学習する方はpivot_*()関数群に慣れておきましょう。 まずは{tidyverse}パッケージを読み込みます。 pacman::p_load(tidyverse) 今回は様々な形のデータを変形する作業をするので、あるデータセットを使うよりも、架空の簡単なデータを使います。 df1 &lt;- tibble( Name = c(&quot;Hadley&quot;, &quot;Song&quot;, &quot;Yanai&quot;), Control = c(90, 80, 100), Treatment = c(90, 25, 95), Gender = c(&quot;Male&quot;, &quot;Female&quot;, &quot;Female&quot;) ) df1 ## # A tibble: 3 × 4 ## Name Control Treatment Gender ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 Hadley 90 90 Male ## 2 Song 80 25 Female ## 3 Yanai 100 95 Female このデータは既に指摘した通り「1列1変数」の条件を満たしております。この条件を満たすデータは以下のような形となります。 ## # A tibble: 6 × 4 ## Name Gender Treat Math_Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Hadley Male Control 90 ## 2 Hadley Male Treatment 90 ## 3 Song Female Control 80 ## 4 Song Female Treatment 25 ## 5 Yanai Female Control 100 ## 6 Yanai Female Treatment 95 Treat変数が作成され、元々は変数名であった\"Control\"と\"Treatment\"が値として格納されます。この変数をキー変数と呼びます。そして、キー変数の値に応じた数学成績がMath_Scoreという変数でまとめられました。この変数を値変数と呼びます。 「1列1変数」を満たさなかった最初のデータは「Wide型データ」、これを満たすようなデータは「Long型データ」と呼ばれます。これは相対的に最初のデータが横に広いから名付けた名前であって、「Wide型=雑然データ」もしくは「Long型=雑然データ」ではないことに注意してください80。 Wide型データをLong型へ変換する関数がpivot_longer()であり、基本的な使い方は以下の通りです。 # pivot_longer()の使い方 データ名 %&gt;% pivot_longer(cols = c(まとめる変数1, まとめる変数2, ...), names_to = &quot;キー変数名&quot;, values_to = &quot;値変数名&quot;) ここでは同じ変数がControlとTreatment変数で分けられているため、まとめる変数はこの2つであり、cols = c(Control, Treatment)と指定します。ControlとTreatmentは\"で囲んでも、囲まなくても同じです。また、{dplyr}のselect()関数で使える変数選択の関数 (starts_with()、where()など)や:演算子も使用可能です。また、cols引数はpivot_longer()の第2引数であるため、cols =は省略可能です（第一引数はパイプにより既に渡されています）。 names_toとvalues_to引数はそれぞれキー変数名と値変数名を指定する引数で、ここは必ず\"で囲んでください。このdf1をLong型へ変換し、df1_Lと名付けるコードが以下のコードです。 df1_L &lt;- df1 %&gt;% pivot_longer(Control:Treatment, names_to = &quot;Treat&quot;, values_to = &quot;Math_Score&quot;) df1_L ## # A tibble: 6 × 4 ## Name Gender Treat Math_Score ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Hadley Male Control 90 ## 2 Hadley Male Treatment 90 ## 3 Song Female Control 80 ## 4 Song Female Treatment 25 ## 5 Yanai Female Control 100 ## 6 Yanai Female Treatment 95 これだけでもpivot_longer()関数を使ってWide型からLong型への変換は問題なくできますが、以下ではもうちょっと踏み込んだ使い方について解説します。「ここまでで十分だよ」という方は、ここを飛ばしても構いません。 今回の実習データdf3は3人の体重を3日間に渡って計測したものです。ただし、ドジっ子のSongは2日目にうっかり測るのを忘れており、欠損値となっています。 df2 &lt;- tibble( Name = c(&quot;Hadley&quot;, &quot;Song&quot;, &quot;Yanai&quot;), Day1 = c(75, 120, 70), Day2 = c(73, NA, 69), Day3 = c(71, 140, 71) ) df2 ## # A tibble: 3 × 4 ## Name Day1 Day2 Day3 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Hadley 75 73 71 ## 2 Song 120 NA 140 ## 3 Yanai 70 69 71 まず、これをこれまでのやり方でLong型へ変形し、df2_Lと名付けます。 df2_L &lt;- df2 %&gt;% pivot_longer(starts_with(&quot;Day&quot;), names_to = &quot;Days&quot;, values_to = &quot;Weight&quot;) df2_L ## # A tibble: 9 × 3 ## Name Days Weight ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Hadley Day1 75 ## 2 Hadley Day2 73 ## 3 Hadley Day3 71 ## 4 Song Day1 120 ## 5 Song Day2 NA ## 6 Song Day3 140 ## 7 Yanai Day1 70 ## 8 Yanai Day2 69 ## 9 Yanai Day3 71 これでも問題ないかも知れませんが、以下のような操作を追加に行うとします。 Weightが欠損している行を除去する Days列の値から\"Day\"を除去し、numeric型にする 以上の作業を行うには、dplyrが便利でしょう。ちなみにstr_remove()関数が初めて登場しましたが、これについては第16章で詳細に解説します。簡単に説明しますと、str_remove(\"X123\", \"X\")は\"X123\"から\"X\"を除去し、\"123\"のみ残す関すです。残された値が数字のみであってもデータ型はcharacter型なので、もう一回、numeric型に変換する必要があります81。dplyrを使ったコードは以下の通りです。 # 1. WeightがNAのケースを除去 # 2. Days変数の値から&quot;Day&quot;を除去 # 3. Days変数をnumeric型へ変換 df2_L %&gt;% filter(!is.na(Weight)) %&gt;% # 1 mutate(Days = str_remove(Days, &quot;Day&quot;), # 2 Days = as.numeric(Days)) # 3 ## # A tibble: 8 × 3 ## Name Days Weight ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Hadley 1 75 ## 2 Hadley 2 73 ## 3 Hadley 3 71 ## 4 Song 1 120 ## 5 Song 3 140 ## 6 Yanai 1 70 ## 7 Yanai 2 69 ## 8 Yanai 3 71 実はこの作業、pivot_longer()内で行うことも可能です。たとえば、values_toで指定した変数の値が欠損しているケースを除去するにはvalues_drop_na引数をTRUEに指定するだけです。 # Weight変数がNAのケースを除去する df2 %&gt;% pivot_longer(starts_with(&quot;Day&quot;), names_to = &quot;Days&quot;, values_to = &quot;Weight&quot;, values_drop_na = TRUE) ## # A tibble: 8 × 3 ## Name Days Weight ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Hadley Day1 75 ## 2 Hadley Day2 73 ## 3 Hadley Day3 71 ## 4 Song Day1 120 ## 5 Song Day3 140 ## 6 Yanai Day1 70 ## 7 Yanai Day2 69 ## 8 Yanai Day3 71 それでは、キー変数から共通する文字列を除去するにはどうすれば良いでしょうか。この場合、names_prefix引数を使います。これはnames_toで指定した新しく出来る変数の値における接頭詞を指定し、それを除去する引数です。今回は\"Day1\"、\"Day2\"、\"Day3\"から\"Day\"を除去するので、names_prefix = \"Day\"と指定します。こうすることで、Days列から\"Day\"が除去されます。ただし、数字だけ残っても、そのデータ型はcharacter型ですので、このデータ型を変換する必要があります。ここで使うのがnames_transform引数であり、これはlist型のオブジェクトを渡す必要があります。Days列をnumeric型にする場合はlist(Days = as.numeric)です。複数の列のデータ型を変える場合、list()の中に追加していきます。それでは実際に走らせてみましょう。 # 1. Day変数の値から&quot;Day&quot;を除去する # 2. Day変数をinteger型に変換 # 3. Weight変数がNAのケースを除去する df2 %&gt;% pivot_longer(starts_with(&quot;Day&quot;), names_to = &quot;Days&quot;, names_prefix = &quot;Day&quot;, # 1 names_transform = list(Days = as.numeric), # 2 values_to = &quot;Weight&quot;, values_drop_na = TRUE) # 3 ## # A tibble: 8 × 3 ## Name Days Weight ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Hadley 1 75 ## 2 Hadley 2 73 ## 3 Hadley 3 71 ## 4 Song 1 120 ## 5 Song 3 140 ## 6 Yanai 1 70 ## 7 Yanai 2 69 ## 8 Yanai 3 71 これでWide型をLong型が変換され、整然でありながら、より見栄の良いデータが出来上がりました。他にもpivot_longer()は様々な引数に対応しており、詳細は?pivot_longerやレファレンスページを参照してください。 15.3 Long型からWide型へ ご存知の通り、「Long型データ=整然データ」ではありません。実際、表15.5の右はLong型データですが、1列に2つの変数が含まれており、整然データとは言えません。このようなデータはいくらでもあります。とりわけ、「分析」のためじゃなく、「読む」ための表の場合において多く発見されます。 表 15.7: Long型データの例 都道府県 区分 人口 面積 北海道 総人口 5381733 83424.31 外国人 21676 83424.31 青森県 総人口 1308265 9645.59 外国人 3447 9645.59 岩手県 総人口 1279594 15275.01 外国人 5017 15275.01 宮城県 総人口 2333899 7282.22 外国人 13989 7282.22 都道府県 総人口 外国人 面積 北海道 5381733 21676 83424.31 青森県 1308265 3447 9645.59 岩手県 1279594 5017 15275.01 宮城県 2333899 13989 7282.22 変数名が日本語になっていますが、これは「読むための表」を読み込むことを仮定しています。このように変数名として日本語は使えますが、自分でデータセットを作成する際、変数名はローマ字にすることを強く推奨します。 表15.7の左の場合、人口列に総人口と外国人人口といった2つの変数の値が格納されているため、整然データではありません。これを整然データにしたものが右の表です。本節ではLong型データをWide型データへ変換するpivot_wider()関数を紹介します。この関数は同じく{tidyr}が提供しているspread()関数とほぼ同じ関数ですが、今はpivot_wider()の使用が推奨されており、spread()はいずれか{tidyr}から外される予定です。 まずは、実習用データを読み込みます。 df3 &lt;- read_csv(&quot;Data/Population2015.csv&quot;) ## Rows: 94 Columns: 4 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (2): 都道府県, 区分 ## dbl (2): 人口, 面積 ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. df3 ## # A tibble: 94 × 4 ## 都道府県 区分 人口 面積 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 北海道 総人口 5381733 83424. ## 2 &lt;NA&gt; 外国人 21676 83424. ## 3 青森県 総人口 1308265 9646. ## 4 &lt;NA&gt; 外国人 3447 9646. ## 5 岩手県 総人口 1279594 15275. ## 6 &lt;NA&gt; 外国人 5017 15275. ## 7 宮城県 総人口 2333899 7282. ## 8 &lt;NA&gt; 外国人 13989 7282. ## 9 秋田県 総人口 1023119 11638. ## 10 &lt;NA&gt; 外国人 2914 11638. ## # … with 84 more rows このデータは2015年国勢調査から抜粋したデータであり、各変数の詳細は以下の通りです。 変数名 説明 都道府県 都道府県名 区分 総人口/外国人人口の区分 人口 人口 (人) 面積 面積 (km\\(^2\\)) まずは変数名が日本語になっているので、rename()関数を使ってそれぞれPref、Type、Population、Areaに変更します。 df3 &lt;- df3 %&gt;% rename(&quot;Pref&quot; = 都道府県, &quot;Type&quot; = 区分, &quot;Population&quot; = 人口, &quot;Area&quot; = 面積) df3 ## # A tibble: 94 × 4 ## Pref Type Population Area ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 北海道 総人口 5381733 83424. ## 2 &lt;NA&gt; 外国人 21676 83424. ## 3 青森県 総人口 1308265 9646. ## 4 &lt;NA&gt; 外国人 3447 9646. ## 5 岩手県 総人口 1279594 15275. ## 6 &lt;NA&gt; 外国人 5017 15275. ## 7 宮城県 総人口 2333899 7282. ## 8 &lt;NA&gt; 外国人 13989 7282. ## 9 秋田県 総人口 1023119 11638. ## 10 &lt;NA&gt; 外国人 2914 11638. ## # … with 84 more rows 次は、Pref列の欠損値を埋めましょう。ここの欠損値は、当該セルの一つ上のセルの値で埋まりますが、これはfill()関数で簡単に処理できます。欠損値を埋めたい変数名をfill()の引数として渡すだけです。 df3 &lt;- df3 %&gt;% fill(Pref) df3 ## # A tibble: 94 × 4 ## Pref Type Population Area ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 北海道 総人口 5381733 83424. ## 2 北海道 外国人 21676 83424. ## 3 青森県 総人口 1308265 9646. ## 4 青森県 外国人 3447 9646. ## 5 岩手県 総人口 1279594 15275. ## 6 岩手県 外国人 5017 15275. ## 7 宮城県 総人口 2333899 7282. ## 8 宮城県 外国人 13989 7282. ## 9 秋田県 総人口 1023119 11638. ## 10 秋田県 外国人 2914 11638. ## # … with 84 more rows そして、いよいよpivot_wider()関数の出番ですが、基本的に使い方は以下の通りです。 # pivot_wider()の使い方 データ名 %&gt;% pivot_wider(names_from = キー変数名, values_from = 値変数名) まず、キー変数名は列として展開する変数名であり、ここではTypeになります。そして、値変数名は展開される値の変数であり、ここではPopulationになります。つまり、「PopulationをTypeごとに分けて別の列にする」ことになります。また、values_from引数は長さ2以上のベクトルを指定することで、複数の値変数を指定することも可能です。たとえば、df3にIncomeという平均所得を表す列があり、これらも総人口と外国人それぞれ異なる値を持っているとしたら、values_from = c(Population, Income)のように複数の値変数を指定することが出来ます。今回は値変数が1つのみですが、早速やってみましょう。 df3_W &lt;- df3 %&gt;% pivot_wider(names_from = Type, values_from = Population) df3_W ## # A tibble: 47 × 4 ## Pref Area 総人口 外国人 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 北海道 83424. 5381733 21676 ## 2 青森県 9646. 1308265 3447 ## 3 岩手県 15275. 1279594 5017 ## 4 宮城県 7282. 2333899 13989 ## 5 秋田県 11638. 1023119 2914 ## 6 山形県 9323. 1123891 5503 ## 7 福島県 13784. 1914039 8725 ## 8 茨城県 6097. 2916976 41310 ## 9 栃木県 6408. 1974255 26494 ## 10 群馬県 6362. 1973115 37126 ## # … with 37 more rows また、日本語の変数名が出来てしまったので、それぞれTotalとForeignerに変更し、relocate()関数を使ってAreaを最後の列に移動します。 df3_W &lt;- df3_W %&gt;% rename(&quot;Total&quot; = 総人口, &quot;Foreigner&quot; = 外国人) %&gt;% relocate(Area, .after = last_col()) df3_W ## # A tibble: 47 × 4 ## Pref Total Foreigner Area ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 北海道 5381733 21676 83424. ## 2 青森県 1308265 3447 9646. ## 3 岩手県 1279594 5017 15275. ## 4 宮城県 2333899 13989 7282. ## 5 秋田県 1023119 2914 11638. ## 6 山形県 1123891 5503 9323. ## 7 福島県 1914039 8725 13784. ## 8 茨城県 2916976 41310 6097. ## 9 栃木県 1974255 26494 6408. ## 10 群馬県 1973115 37126 6362. ## # … with 37 more rows これで整然データの出来上がりです。 このpivot_wider()関数はpivot_longer()関数同様、様々な引数を提供しておりますが、主に使う機能は以上です。他にはpivot_wider()によって出来た欠損値を埋める引数であるvalues_fillがあり、デフォルト値はNULLです。ここに0や\"Missing\"などの長さ1のベクトルを指定すれば、指定した値で欠損値が埋まります。 pivot_wider()関数の詳細は?pivot_widerもしくは、レファレンスページを参照してください。 15.4 列の操作 他にも「1列1変数」の条件を満たさないケースを考えましょう。pivot_longer()は1つの変数が複数の列に渡って格納されている際に使いましたが、今回は1つの列に複数の変数があるケースを考えてみましょう。たとえば、年月日が1つの列に入っている場合、これを年、月、日の3列で分割する作業です。また、これと関連して、列から文字列を除去し、数値のみ残す方法についても紹介します。 実習用データを読み込んでみましょう。 df4 &lt;- read_csv(&quot;Data/COVID19_JK.csv&quot;) df4 ## # A tibble: 172 × 5 ## ID Date Week Confirmed_Japan Confirmed_Korea ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 2020/1/16 木 1人 &lt;NA&gt; ## 2 2 2020/1/17 金 0人 &lt;NA&gt; ## 3 3 2020/1/18 土 0人 &lt;NA&gt; ## 4 4 2020/1/19 日 0人 &lt;NA&gt; ## 5 5 2020/1/20 月 0人 1人 ## 6 6 2020/1/21 火 0人 0人 ## 7 7 2020/1/22 水 0人 0人 ## 8 8 2020/1/23 木 0人 0人 ## 9 9 2020/1/24 金 2人 1人 ## 10 10 2020/1/25 土 0人 0人 ## # … with 162 more rows このデータは2020年1月16日から2020年7月5日まで、COVID-19 (新型コロナ)の新規感染者数を日本と韓国を対象に収集したものです。データはWikipedia (日本 / 韓国)から収集しました。韓国の新規感染者数は最初の4日分が欠損値のように見えますが、最初の感染者が確認されたのが1月20日のため、1月19日までは欠損となっています。 変数名 説明 ID ケースID Date 年月日 Week 曜日 Confirmed_Japan 新規感染者数 (日本) Confirmed_Korea 新規感染者数 (韓国) このデータの場合、観察単位は「国 \\(\\times\\) 日」です。しかし、df4は1行に日本と韓国の情報が格納されており「1行1観察」の条件を満たしておりません。したがって、pivot_longer()を使ってLong型へ変換し、新しいデータの名前をdf4_Lと名付けます。 df4_L &lt;- df4 %&gt;% pivot_longer(cols = starts_with(&quot;Confirmed&quot;), names_to = &quot;Country&quot;, names_prefix = &quot;Confirmed_&quot;, values_to = &quot;Confirmed&quot;) df4_L ## # A tibble: 344 × 5 ## ID Date Week Country Confirmed ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 2020/1/16 木 Japan 1人 ## 2 1 2020/1/16 木 Korea &lt;NA&gt; ## 3 2 2020/1/17 金 Japan 0人 ## 4 2 2020/1/17 金 Korea &lt;NA&gt; ## 5 3 2020/1/18 土 Japan 0人 ## 6 3 2020/1/18 土 Korea &lt;NA&gt; ## 7 4 2020/1/19 日 Japan 0人 ## 8 4 2020/1/19 日 Korea &lt;NA&gt; ## 9 5 2020/1/20 月 Japan 0人 ## 10 5 2020/1/20 月 Korea 1人 ## # … with 334 more rows 続いて、新規感染者数を表すConfirmed列から「人」を除去しましょう。人間にとってはなんの問題もありませんが、パソコンにとって1人や5人は文字列に過ぎず、分析ができる状態ではありません。ここで使う関数がparse_number()です。引数として指定した列から数値のみ抽出します。\"$1000\"や\"1, 324, 392\"のような数値でありながら、character型として保存されている列から数値のみを取り出す際に使う関数です。使い方は以下の通りです。 データ名 %&gt;% mutate(新しい変数名 = parse_number(数値のみ抽出する変数名)) 似たようなものとしてparse_character()があり、これは逆に文字列のみ抽出する関数です。 ここではConfimedから数値のみ取り出し、Confrimed列に上書きし、それをdf4_Sと名付けます。 df4_S &lt;- df4_L %&gt;% mutate(Confirmed = parse_number(Confirmed)) df4_S ## # A tibble: 344 × 5 ## ID Date Week Country Confirmed ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 2020/1/16 木 Japan 1 ## 2 1 2020/1/16 木 Korea NA ## 3 2 2020/1/17 金 Japan 0 ## 4 2 2020/1/17 金 Korea NA ## 5 3 2020/1/18 土 Japan 0 ## 6 3 2020/1/18 土 Korea NA ## 7 4 2020/1/19 日 Japan 0 ## 8 4 2020/1/19 日 Korea NA ## 9 5 2020/1/20 月 Japan 0 ## 10 5 2020/1/20 月 Korea 1 ## # … with 334 more rows それでは国、曜日ごとの新規感染者数を調べてみます。求める統計量は曜日ごとの新規感染者数の合計、平均、標準偏差です。まず、曜日は月から日の順になるよう、factor型に変換します。そして、国と曜日ごとに記述統計量を計算し、df4_S_Summary1という名で保存します。 df4_S &lt;- df4_S %&gt;% mutate(Week = factor(Week, levels = c(&quot;月&quot;, &quot;火&quot;, &quot;水&quot;, &quot;木&quot;, &quot;金&quot;, &quot;土&quot;, &quot;日&quot;))) df4_S_Summary1 &lt;- df4_S %&gt;% group_by(Country, Week) %&gt;% summarise(Sum = sum(Confirmed, na.rm = TRUE), Mean = mean(Confirmed, na.rm = TRUE), SD = sd(Confirmed, na.rm = TRUE), .groups = &quot;drop&quot;) df4_S_Summary1 ## # A tibble: 14 × 5 ## Country Week Sum Mean SD ## &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Japan 月 2540 106. 156. ## 2 Japan 火 2093 87.2 111. ## 3 Japan 水 2531 105. 133. ## 4 Japan 木 2704 108. 151. ## 5 Japan 金 3083 123. 172. ## 6 Japan 土 3327 133. 189. ## 7 Japan 日 3244 130. 179. ## 8 Korea 月 1609 67.0 126. ## 9 Korea 火 1641 68.4 111. ## 10 Korea 水 1626 67.8 102. ## 11 Korea 木 1883 78.5 137. ## 12 Korea 金 2099 87.5 143. ## 13 Korea 土 2194 91.4 174. ## 14 Korea 日 2088 87 215. df4_S_Summary1はこの状態で整然データですが、もし人間が読むための表を作るなら、韓国と日本を別の列に分けた方が良いかも知れません。pivot_wider()を使って、日本と韓国のの新規感染者数を2列に展開します。 df4_S_Summary1 %&gt;% pivot_wider(names_from = Country, values_from = Sum:SD) ## # A tibble: 7 × 7 ## Week Sum_Japan Sum_Korea Mean_Japan Mean_Korea SD_Japan SD_Korea ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 月 2540 1609 106. 67.0 156. 126. ## 2 火 2093 1641 87.2 68.4 111. 111. ## 3 水 2531 1626 105. 67.8 133. 102. ## 4 木 2704 1883 108. 78.5 151. 137. ## 5 金 3083 2099 123. 87.5 172. 143. ## 6 土 3327 2194 133. 91.4 189. 174. ## 7 日 3244 2088 130. 87 179. 215. これで人間にとって読みやすい表が出来ました。今は「日本の合計」、「韓国の合計」、「日本の平均」、…の順番ですが、これを日本と韓国それぞれまとめる場合は、relocate()を使います。 df4_S_Summary1 %&gt;% pivot_wider(names_from = Country, values_from = Sum:SD) %&gt;% relocate(Week, ends_with(&quot;Japan&quot;), ends_with(&quot;Korea&quot;)) ## # A tibble: 7 × 7 ## Week Sum_Japan Mean_Japan SD_Japan Sum_Korea Mean_Korea SD_Korea ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 月 2540 106. 156. 1609 67.0 126. ## 2 火 2093 87.2 111. 1641 68.4 111. ## 3 水 2531 105. 133. 1626 67.8 102. ## 4 木 2704 108. 151. 1883 78.5 137. ## 5 金 3083 123. 172. 2099 87.5 143. ## 6 土 3327 133. 189. 2194 91.4 174. ## 7 日 3244 130. 179. 2088 87 215. 新規感染者が確認されるのは金〜日曜日が多いことが分かります。 曜日ではなく、月ごとに記述統計料を計算する場合は、まずDate列を年、月、日に分割する必要があります。具体的にはDateを\"/\"を基準に別ければいいです。そこで登場するのはseparate()関数であり、使い方は以下の通りです。 # separate()の使い方 データ名 %&gt;% separate(cols = 分割する変数名 into = 分割後の変数名, sep = &quot;分割する基準&quot;) colsにはDateを指定し、intoは新しく出来る列名を指定します。今回はDateが3列に分割されるので、長さ3のcharacter型ベクトルを指定します。ここではYear、Month、Dayとしましょう。最後のsep引数は分割する基準となる文字を指定します。df4のDateは\"2020/06/29\"のように年月日が\"/\"で分けられているため、\"/\"を指定します。実際にやってみましょう。 df4_S &lt;- df4_S %&gt;% separate(col = Date, into = c(&quot;Year&quot;, &quot;Month&quot;, &quot;Day&quot;), sep = &quot;/&quot;) df4_S ## # A tibble: 344 × 7 ## ID Year Month Day Week Country Confirmed ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 2020 1 16 木 Japan 1 ## 2 1 2020 1 16 木 Korea NA ## 3 2 2020 1 17 金 Japan 0 ## 4 2 2020 1 17 金 Korea NA ## 5 3 2020 1 18 土 Japan 0 ## 6 3 2020 1 18 土 Korea NA ## 7 4 2020 1 19 日 Japan 0 ## 8 4 2020 1 19 日 Korea NA ## 9 5 2020 1 20 月 Japan 0 ## 10 5 2020 1 20 月 Korea 1 ## # … with 334 more rows 新しく出来た変数は元の変数があった場所になります。ここまで来たら月ごとに新規感染者の記述統計量は計算できます。曜日ごとに行ったコードのWeekをMonthに変えるだけです。また、Monthは数字のみで構成されたcharacter型であるため、このままでも問題なくソートされます。したがって、別途factor化の必要もありません（むろん、してもいいですし、むしろ推奨されます）。 df4_S_Summary2 &lt;- df4_S %&gt;% group_by(Country, Month) %&gt;% summarise(Sum = sum(Confirmed, na.rm = TRUE), Mean = mean(Confirmed, na.rm = TRUE), SD = sd(Confirmed, na.rm = TRUE), .groups = &quot;drop&quot;) df4_S_Summary2 ## # A tibble: 14 × 5 ## Country Month Sum Mean SD ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Japan 1 17 1.06 1.34 ## 2 Japan 2 213 7.34 7.81 ## 3 Japan 3 1723 55.6 42.4 ## 4 Japan 4 12135 404. 146. ## 5 Japan 5 2763 89.1 73.0 ## 6 Japan 6 1742 58.1 23.0 ## 7 Japan 7 929 186. 45.1 ## 8 Korea 1 11 0.917 1.44 ## 9 Korea 2 3139 108. 203. ## 10 Korea 3 6737 217. 222. ## 11 Korea 4 887 29.6 26.6 ## 12 Korea 5 729 23.5 16.2 ## 13 Korea 6 1348 44.9 10.4 ## 14 Korea 7 289 57.8 6.61 df4_S_Summary2 %&gt;% pivot_wider(names_from = Country, values_from = Sum:SD) %&gt;% relocate(Month, ends_with(&quot;Japan&quot;), ends_with(&quot;Korea&quot;)) ## # A tibble: 7 × 7 ## Month Sum_Japan Mean_Japan SD_Japan Sum_Korea Mean_Korea SD_Korea ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 17 1.06 1.34 11 0.917 1.44 ## 2 2 213 7.34 7.81 3139 108. 203. ## 3 3 1723 55.6 42.4 6737 217. 222. ## 4 4 12135 404. 146. 887 29.6 26.6 ## 5 5 2763 89.1 73.0 729 23.5 16.2 ## 6 6 1742 58.1 23.0 1348 44.9 10.4 ## 7 7 929 186. 45.1 289 57.8 6.61 平均値から見ると、日本は7都道府県を対象に緊急事態宣言が行われた4月がピークで緩やかに減少していますが、7月になって上がり気味です。韓国はカルト宗教団体におけるクラスターが発生した3月がピークで、6月からまた上がり気味ですね。傾向としては韓国が日本に1ヶ月先行しているように見えます。 それではseparate()関数の他の引数についても簡単に紹介します。まず、sep引数はnumeric型でも可能です。この場合、文字列内の位置を基準に分割されます。年月日が20200629のように保存されている場合は、何らかの基準となる文字がありません。この場合、sep = c(4, 6)にすると、「\"20200629\"の4文字目と5文字目の間で分割、6文字目と7文字目の間で分割」となります。また、sep = c(-4, -2)のように負の値も指定可能であり、この場合は右からの位置順で分割します。 また、separate()後は元の変数がなくなりますが、remove = FALSEの場合、元の変数 (ここではDate)が残ります。他にもconvert引数もあります。convert = TRUEの場合、適切なデータ型へ変換してくれます。デフォルト値はFALSEであり、この場合、character型として分割されます。先ほどの例だとYearもMonthもDayも現在はcharacter型です。separate()内でconvert = TRUEを追加すると、分割後のYear、Month、Dayはnumeric型として保存されます。 separate()の詳細は?separateまたは、レファレンスページを参照してください。 参考資料 "],["string.html", "16. 文字列の処理", " 16. 文字列の処理 "],["visualization1.html", "17. 可視化[理論] 17.1 可視化のためのパッケージ 17.2 グラフィックの文法 17.3 グラフィックの構成要素 17.4 良いグラフとは", " 17. 可視化[理論] 17.1 可視化のためのパッケージ Rによる可視化は様々な方法がありますが、可視化のために使うパッケージとして代表的なものは (1) パッケージを使わない方法、(2) {lattice}パッケージ、(3) {ggplot2}パッケージがあります。ここでは、以下のデータ (表17.1)を可視化しながら、それぞれの特徴について簡単に解説します。 表 17.1: サンプルデータの最初の10行 Country PPP HDI OECD Afghanistan 2125 0.496 非加盟国 Albania 13781 0.791 非加盟国 Algeria 11324 0.759 非加盟国 Angola 6649 0.574 非加盟国 Argentina 22938 0.830 非加盟国 Armenia 12974 0.760 非加盟国 Australia 50001 0.938 加盟国 Austria 55824 0.914 加盟国 Azerbaijan 14257 0.754 非加盟国 Bahrain 43624 0.838 非加盟国 このデータは各国 (Country) の一人当たり購買力平価基準GDP (PPP)、人間開発指数 (HDI)、OECD加盟有無 (OECD)の変数で構成されています。このデータを使って横軸はPPP、縦軸はHDIとし、OECDの値によって色分けしたグラフを作成します。 17.1.1 Base R Rは統計学、データ分析に特化したプログラミング言語であるため、別途のパッケージなしで作図が可能です。後ほど紹介する{lattice}や{ggplot2}を用いた作図とは違って、Base Rによる作図は、紙にペンでグラフを書くイメージに近いです。キャンバスを用意し、そこにペンで点や線を描く感じです。これはレイヤーという概念を導入した{ggplot2}に近いかも知れませんが、{ggplot2}はレイヤーを変更出来る一方、Base Rは図が気に入らない場合、一からやり直しです。つまり、キャンバスに引いた線や点は消すことができません。また、作成した図はオブジェクトとして保存することが出来ないため、もう一度図示するためには一から書く必要があります。Base Rによる作図は短所だけでなく、メリットもあります。まず、パッケージを必要としないため、Rインストール直後から使える点です。そして、{lattice}や{ggplot2}よりも速いです。他にも人によってはBase Rの方がシンプルでかっこいいという方もいますが、これは好みの問題でしょう。 以下の図17.1はBase Rを使った散布図の例です。 # Base Rを用いた作図の例 plot(x = Country_df$PPP, y = Country_df$HDI, pch = 19, col = ifelse(Country_df$OECD == &quot;加盟国&quot;, &quot;red&quot;, &quot;blue&quot;), xlab = &quot;一人当たり購買力平価GDP (USD)&quot;, ylab = &quot;人間開発指数&quot;) legend(&quot;bottomright&quot;, pch = 19, legend = c(&quot;OECD加盟国&quot;, &quot;OECD非加盟国&quot;), col = c(&quot;red&quot;, &quot;blue&quot;)) 図 17.1: Base Rによるグラフ 17.1.2 {lattice}パッケージ {lattice}はDeepayan Sarkarによって開発された可視化パッケージです。このパッケージの最大特徴は「1つの関数で可視化が出来る」点です。作図に必要な様々な情報が1つの関数内に全て入ります。むろん、指定しない情報に関しては多くの場合、自動的に処理してくれます。 図17.1を{lattice}を使って作る場合は以下のようなコードになります。 # latticeを用いた作図の例 xyplot(HDI ~ PPP, data = Country_df, group = OECD, pch = 19, grid = TRUE, auto.key = TRUE, key = list(title = &quot;OECD加盟有無&quot;, cex.title = 1, space = &quot;right&quot;, points = list(col = c(&quot;magenta&quot;, &quot;cyan&quot;), pch = 19), text = list(c(&quot;加盟国&quot;, &quot;非加盟国&quot;))), xlab = &quot;一人当たり購買力平価GDP (USD)&quot;, ylab = &quot;人間開発指数&quot;) 図 17.2: {lattice}によるグラフ 1つの関数で全てを処理するので、関数が非常に長くなり、人間にとって読みやすいコードにはなりにくいのが短所です。しかし、{lattice}はBase Rでは出来ない、プロットのオブジェクトとしての保存ができます。Base Rは出来上がったプロットをオブジェクトとして保存することが出来ず、同じ図をもう一回出力するためには、改めてコードを書く必要があります。しかし、{lattice}はオブジェクトとして保存ができるため、いつでもリサイクルが可能です。他にも、{lattice}は条件付きプロットの作成において非常に強力です。しかし、これらの特徴は今は{ggplot2}も共有しているため、{lattice}独自の長所とは言いにくいです。 17.1.3 {ggplot2}パッケージ {ggplot2}はHadely Wickhamが大学院生の時に開発した可視化パッケージであり82、 Wilkinson (2005) の「グラフィックの文法 (grammer of graphics)」の思想をR上で具現化したものです。グラフィックの文法という思想は今は{ggplot2}以外にもPlotlyやTableauなどでも採用されています。 グラフィックの文法は後ほど詳細に解説しますが、{ggplot2}による作図の特徴は「レイヤーを重ねる」ことです。グラフの様々な要素をそれぞれ1つの層 (layer)と捉え、これを重ねられていくことでグラフが出来上がる仕組みです。これはBase Rの書き方に似ています。たとえば、{ggplot2}を使って図17.1を作る場合、以下のようなコードになります。 # ggplot2を用いた作図の例 ggplot(data = Country_df) + geom_point(aes(x = PPP, y = HDI, color = OECD)) + labs(x = &quot;一人あたり購買力平価GDP (USD)&quot;, y = &quot;人間開発指数&quot;, color = &quot;OECD加盟有無&quot;) + theme_bw() 図 17.3: {ggplot2}によるグラフ このように{ggplot2}による作図コードはBase Rや{lattice}に比べ、読みやすいのが特徴です。また、書く手間も大きく省かれる場合が多く、結果として出力されるグラフも綺麗です（これは好みによりますが）。しかし、{ggplot2}にも限界はあり、代表的なものとして (1) 3次元グラフが作成でないこと、(2) 処理速度が遅い点があります。後者は多くの場合においてあまり気にならない程度ですが、3次元プロットが必要な場合は{lattice}や別途のパッケージを使う必要があります。しかし、社会科学において3次元プロットが使われる機会は少なく、2次元平面であっても3次元以上のデータを表現することも可能です。本書では{ggplot2}を用いた可視化方法のみについて解説していきます。 17.2 グラフィックの文法 17.2.1 グラフィックの文法 本書では特別な事情がない限り、{ggplot2}による可視化のみを扱います。既に{ggplot2}のggが「グラフィックの文法 (grammar of graphics)」だと説明しましたが、この概念は Wilkinson (2005) によって提唱された比較的新しいものであり、{ggplot2}はHadley先生がグラフィックの文法に則った作図のプロセスをRで具現化したものです。 グラフィックスの文法とは、グラフを構造化された方法で記述し、レイヤーを積み重ねることによってグラフを構築するフレームワークです。グラフは様々な要素で構成されています。横軸と縦軸、点、線、グラフ、凡例、図のタイトルなどがあります。横軸や縦軸は線の太さ、目盛りの間隔、数字の大きさなどに分割することも可能です。このように1つのグラフは数十、数百以上の要素の集合です。これら一つ一つの要素をレイヤーとして捉え、それを積み重ねることでグラフを作成します。これが簡単な{ggplot2}による作図のイメージですが、以下でもうちょっと目に見える形でこれを解説していきます。 17.2.2 ggplot2のイメージ それでは{ggplot2}によるグラフが出来上がる過程を見ていきます。例えば、以下のようなデータセットdfがあるとします。変数は年度を表すYear、鉄道事業者のタイプを表すCompany_Type1、一日利用者数の平均値を表すPがあります。例えば、2行目は2011年度におけるJRが管理する駅の一日平均利用者数が約7399名であることを意味します。 ## # A tibble: 28 × 3 ## Year Company_Type1 P ## &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 2011 その他 4769 ## 2 2011 JR 7399 ## 3 2011 大手私鉄 19421 ## 4 2011 準大手私鉄 7683 ## 5 2012 その他 5014 ## 6 2012 JR 7289 ## 7 2012 大手私鉄 21286 ## 8 2012 準大手私鉄 10471 ## 9 2013 その他 5154 ## 10 2013 JR 7383 ## # … with 18 more rows このデータdfを使って図17.4のようなグラフを作成します。以下では作図のコードも載っていますが、詳しく理解しなくても結構です。理解しなくてもいいですが、必ずコードには目を通し、説明文との対応を自分で考えてください。 図 17.4: 鉄道駅の事業者区分による平均利用者数の推移 まずは、グラフに使用するデータを指定し、空のキャンバスを用意します。 図 17.5: 第1層: データとキャンバスの用意 折れ線グラフを作成します。折れ線グラフは点の位置を指定すると、勝手に点と点の間を線で繋いでぐれます。したがって、必要な情報は点の情報ですが、横軸 (X軸)はYear、縦軸 (Y軸)はPにした点を出力します。この点をCompany_Type1ごとに色分けします。これで折れ線グラフが出来上がります。線の太さは1にします。 図 17.6: 第2層: 幾何オブジェクト (折れ線グラフ) の指定とマッピング 続いて、折れ線グラフに散布図を載せます。これは線が引かれていない折れ線グラフと同じです。したがって、横軸、縦軸、色分けの情報は同じです。しかし、点と線が重なると点がよく見えないこともあるので、点の大きさを3にし、形は枠線付きの点にします。点の中身は白塗りをします。つまり、Company_Type1によって変わるのは、点の枠線です。 図 17.7: 第3層: 幾何オブジェクト (散布図) の指定とマッピング 横軸と縦軸、そして凡例のタイトルを日本語に直します。日本語のレポート、論文なら図表も日本語にすべきです。横軸のラベルは\"年度\"、縦軸のラベルは\"平均利用者数 (人/日)\"にします。色の凡例タイトルは\"事業者区分\"にします。 図 17.8: ラベルの修 横軸のスケールを修正します。横軸は連続 (continuous)変数です。今の目盛りは2012、2014、2016になっていますが、これを1年刻みにし、それぞれの目盛りのラベルも2011、2012、2013、…にします。 図 17.9: スケールの修正 グラフのテーマを{ggplot2}が基本的に提供しているminimalに変更し、フォントサイズを12に変更します。 図 17.10: 見た目の調整 これで図が出来上がりました。このように{ggplot2}では図の要素をレイヤーと捉えます。このレイヤーを生成する関数がggplot()、geom_line()、lab()などであり、これらを+演算子を用いて重ねていきます。このイメージを図にすると図17.11のように表現できます。 図 17.11: {ggplot2}の図が出来上がるまで (全体像) それでは、グラフは具体的にどのような要素で構成されているかを以下で解説します。 17.3 グラフィックの構成要素 {ggplot2}におけるプロット (plot)は「データ + 幾何オブジェクト + 座標系」で構成されます。 ここでいうデータは主にデータフレームまたはtibbleです。これは主にggplot()関数の第一引数と指定するか、パイプで渡すのが一般的です。ただし、{ggplot2}で作図するためには、データを予め整然データに整形する必要があります。 幾何オブジェクト (geometry object)とは簡単に言うと図の種類です。散布図、折れ線グラフ、棒グラフ、ヒストグラムなど、{ggplot2}は様々なタイプの幾何オブジェクトを提供しており、ユーザー自作の幾何オブジェクトもRパッケージとして多く公開されています。幾何オブジェクトは関数の形で提供されており、geom_で始まるといった共通点があります。散布図はgeom_point()、折れ線グラフはgeom_line()のような関数を使います。 この幾何オブジェクトに線や点、棒などを表示する際には、どの変数が横軸で、どの変数が縦軸かを明記する必要があります。また、変数によって点や線の色が変わったりする場合も、どの変数によって変わるかを明記します。これを マッピング (mapping)と呼びます。また、必要に応じて位置 (position)と統計量 (stat)を明記する必要がありますが、これは指定しなくてもとりあえず何らかの図は出力されます。 最後に座標系 (coordinate system)は幾何オブジェクトが表示される空間の特徴を定義します。最も重要な特徴は横軸と縦軸の下限と上限です。または、空間を回転することなどもできます。 {ggplot2}の図は以上の3つ要素を重ねることで出来ます。 図 17.12: {ggplot2}の構造の例 ただし、この中で座標系は適切だと判断される座標系に設定してくれるため、ユーザーが必ず指定すべきものはデータと幾何オブジェクトのみです。また、幾何オブジェクトはマッピングを含んでおり、これも必ず指定する必要があります。したがって、{ggplot2}で作図するための最小限のコードは以下のようになります。 # ggplot2におけるプロットの基本形 # データはggplotの第一引数と使う場合が多いため、「data =」は省略可能 # マッピングは主に幾何オブジェクトの第一引数として使うため、「mapping =」は省略可能 ggplot(data = データ名) + 幾何オブジェクト関数(mapping = aes(マッピング)) # パイプを使う場合 データ名 %&gt;% ggplot() + 幾何オブジェクト関数(mapping = aes(マッピング)) 注意すべき点は{ggplot2}においてレイヤーを重ねる際は%&gt;%でなく、+を使う点です。パイプ演算子は左側の結果を右に渡す意味を持ちますが、{ggplot2}はデータを渡すよりも、レイヤーを足していくイメージですから、+を使います。 以下は{ggplot2}の必須要素であるデータと幾何オブジェクト、マッピングなどについて解説し、続いて図は見栄を調整するための関数群を紹介します。 17.3.1 データ 作図のためにはデータはなくてはなりません。データはdata.frmae型、またはtibble型であり、一般的にはggplot()関数の第一引数として指定します。例えば、ggplot(data = データ名)のように書いてもいいですし、data =は省略して、ggplot(データ名)でも構いません。 データを指定するもう一つの方法はパイプ演算子を使うことです。この場合、データ名 %&gt;% ggplot()のように書きます。書く手間はほぼ同じですが、dplyrやtidyrなどでデータを加工し、それをオブジェクトとして保存せずにすぐ作図に使う場合は便利です。 実際、使う機会は少ないですが、1つのグラフに複数のデータを使う場合もあります。{ggplot2}は複数のデータにも対応していますが、とりあえずメインとなるデータをggplot()に指定し、追加的に必要なデータは今度説明する幾何オブジェクト関数内で指定します。この方法については適宜必要に応じて説明します。 17.3.2 幾何オブジェクト しかし、データを指定しただけで図が出来上がるわけではありません。指定したデータを使ってどのような図を作るかも指定する必要があります。この図のタイプが幾何オブジェクト (geometry object)であり、geom_*()関数で表記します。たとえば、散布図を作る場合、 データ名 %&gt;% ggplot() + geom_point() のように指定します。以上のコードは「あるデータを使って (データ名 %&gt;%)、キャンバスを用意し (ggplot() +)、散布図を作成する (geom_point())。」と読むことが出来ます。 また、この幾何オブジェクトは重ねることも可能です。よく見る例としては、散布図の上に回帰曲線 (geom_smooth())や折れ線グラフ (geom_line())を重ねたものであり、これらの幾何オブジェクトは+で繋ぐことが可能です。 {ggplot2}が提供する幾何オブジェクト関数は散布図だけでなく、棒グラフ (geom_bar())、ヒストグラム (geom_histogram())、折れ線グラフ (geom_line())、ヒートマップ (geom_tile())など、データ分析の場面で使われるほとんどの種類が含まれています。他にもユーザーが作成した幾何オブジェクトもパッケージとして多く公開されています（たとえば、非巡回有向グラフ作成のための{ggdag}、ネットワークの可視化のための{ggnetwork}など）。 17.3.3 マッピング どのようなデータを使って、どのような図を作るかを指定した後は、変数を指定します。たとえば、散布図の場合、各点の横軸と縦軸における位置情報が必要です。ヒストグラムならヒストグラムに必要な変数を指定する必要があります。このようにプロット上に出力されるデータの具体的な在り方を指定するのをマッピング (mapping)と呼びます。 マッピングは幾何オブジェクト関数内で行います。具体的にはgeom_*()内にmapping = aes(マッピング)で指定します。aes()も関数の一種です。散布図ならgeom_point(mapping = aes(x = X軸の変数, y = Y軸の変数))です。ヒストグラムなら横軸のみを指定すればいいのでgeom_histogram(mapping = aes(x = 変数名))で十分です。マッピングは一般的にはgeom_*()の第一引数として渡しますが、この場合、mapping =は省略可能です。 マッピングに必要な変数、つまりaes()に必要な引数は幾何オブジェクトによって異なります。散布図や折れ線グラフならX軸とY軸の情報が必須であるため、2つ必要です (xとy)。ヒストグラムは連続変数の度数分布表を自動的に作成してからグラフが作られるから1つが必要です (x)。また、等高線図の場合、高さの情報も必要なので3つの変数が必要です (xとy、z)。これらの引数は必ず指定する必要があります。 以上の引数に加え、追加のマッピング情報を入れることも可能です。たとえば、鉄道事業者ごとの平均利用者数を時系列で示した最初の例を考えてみましょう。これは折れ線グラフですので、mapping = aes(x = 年度, y = 利用者数)までは必須です。しかし、この図にはもう一つの情報がありますね。それは事業者のタイプです。事業者のタイプごとに線の色を変えたい場合は、aes()内にcolor = 事業者のタイプを、線の種類を変えたい場合は、linetype = 事業者のタイプのように引数を追加します。こうすると2次元のプロットに3次元の情報 (年度、利用者数、事業者タイプ)を乗せることが可能です。むろん、4次元以上にすることも可能です。たとえば、地域ごとに異なる色を、事業者タイプごとに異なる線のタイプを指定する場合は、mapping = aes(x = 年度, y = 利用者数, color = 地域, linetype = 事業者のタイプ)のように指定します。colorやlinetype以外にも大きさ (size)、透明度 (alpha)、点のタイプ (shape)、面の色 (fill)などを指定することができます。 それでは、最初にお見せした図17.10のマッピングはどうなるでしょうか。図17.10の幾何オブジェクトは折れ線グラフ (geom_line())と散布図 (geom_point())の2つです。それぞれの幾何オブジェクトのマッピング情報をまとめたのが表17.2です。 表 17.2: 図17.10のマッピング情報 幾何オブジェクト マッピング要素 変数 引数 geom_line X軸 Year x geom_line Y軸 P y geom_line 線の色 Company_Type1 color geom_point X軸 Year x geom_point Y軸 P y geom_point 枠線の色 Company_Type1 color 先ほどマッピング引数は幾何オブジェクト関数内で指定すると言いましたが、実はggplot()内に入れ、geom_*()内では省略することも可能です。幾何オブジェクトが1つのみならどっちでも問題ありません。しかし、幾何オブジェクトが2つ以上の場合は注意が必要です。全ての幾何オブジェクトがマッピングを共有する場合はggplot()の方が書く手間が省きます。たとえば、表17.2を見ると、geom_line()とgeom_point()はx、y、color引数の値が同じですから、ggplot()内にaes()を入れることも可能です。しかし、幾何オブジェクトがマッピングを共有しない場合は幾何オブジェクト関数内に別途指定する必要があります。あるいは、共有するところだけ、ggplot()に書いて、共有しない部分だけ幾何オブジェクトで指定することも可能です。したがって、上の図は以下のコードでも作成することができます。 # geom_line()とgeom_point()はマッピング情報を共有しているため、 # ggplot()内に指定 df %&gt;% ggplot(aes(x = Year, y = P, color = Company_Type1)) + geom_line(size = 1) + geom_point(size = 3, shape = 21, fill = &quot;white&quot;) + labs(x = &quot;年度&quot;, y = &quot;平均利用者数 (人/日)&quot;, color = &quot;事業者区分&quot;) + scale_x_continuous(breaks = 2011:2017, labels = 2011:2017) + theme_bw() 17.3.4 マッピング: その他 以上のことさえ覚えれば、とりあえず図は作れます。最後に、必須要素ではありませんが、幾何オブジェクトに使う引数について説明します。先ほど説明しましたcolorやlinetype、sizeなどはマッピングの情報として使うことも可能ですが、aes()の外側に置くことも可能です。しかし、その挙動はかなり異なります。colorがaes()の外側にある場合は、幾何オブジェクトの全要素に対して反映されます。 たとえば、横軸が「ゲームのプレイ時間」、縦軸が「身長」の散布図を作成しるとします (図17.13)。ここでcolor引数を追加しますが、まずはaes()の外側に入れます。 # 例1: 全ての点の色が赤になる データ %&gt;% ggplot() + geom_point(aes(x = ゲームのプレイ時間, y = 身長), color = &quot;red&quot;) 図 17.13: colorをaes()外側に置いた場合 ここで注目する点は 散布図におけるすべての点の色がcolorで指定した色 (\"red\" = 赤)に変更された点 colorの引数は変数名でなく、具体的な色を指定する点 以上の2点です。aes()の内側にcolorを指定する場合 (図17.14) は、以下のように変数名を指定します。たとえば、性別ごとに異なる色を付けるとしたら、 # 例2: 性別ごとに点の色が変わる データ %&gt;% ggplot() + geom_point(aes(x = ゲームのプレイ時間, y = 身長, color = 性別)) 図 17.14: colorをaes()内側に置いた場合 以上のように書きます。aes()の内部はマッピングの情報が含まれています。言い換えると、aes()の中はある変数がグラフ上においてどのような役割を果たしているかを明記するところです。2つ目の例では性別という変数が色分けをする役割を果たすため、aes()の内側に入ります。一方、1つ目の例では色分けが行われておりません。 17.3.5 座標系 座標系はデータが点や線、面などで出力される空間を意味し、coord_*()関数群を用いて操作します。 座標系のズームイン (zoom-in) やズームアウト (zoom-out) を行うcoord_cartesian()、横軸と縦軸を交換するcoord_flip()、横軸と縦軸の比率を固定するcoord_fixed()がよく使われます。座標系の説明は次章以降で詳しく解説しますが、ここでは座標系のズームインを見てみましょう。以下の図17.15は各国のCOVID19の感染者数を時系列で示したものです。これを見るとアメリカ、ブラジル、インドは大変だなーくらいしかわかりません。感染者数が比較的に少ない国のデータは線としては存在しますが、なかなか区別ができません。 図 17.15: ズームイン前 ここで座標系をズームインすると、一部の情報は失われますが、ズームインされた箇所はより詳細にグラフを観察できます。ズームインと言っても難しいものではありません。単に、軸の上限、下限を調整するだけです。たとえば、縦軸の上限を10万人に変更したのが図17.16です。アメリカなど感染者数が10万人を超える国家の時系列情報の一部は失われましたが、日中韓などのデータはより見やすくなったかと思います83。 図 17.16: ズームイン後 また、同じ棒グラフや散布図、折れ線グラフでも座標系を変えることによって図の見方が劇的に変わることもあります。我々にとって最も馴染みのある座標系はデカルト座標系 (直交座標系)です。このデカルト座標系に切片0、傾き1の直線を引きます。そして同じ図に対して座標系のみを極座標系 (polar coordinates system)に変更します。この2つを比較したのが図17.17です。この2つの図は同じデータ、同じ変数、同じ幾何オブジェクトで構成されています。異なるのは座標系ですが、見方が劇的に変わります。 図 17.17: 直交座標系と極座標系の比較 (1) こんな座標系を実際に使う機会は多くないかも知れませんが、極座標系は割と身近なところで見ることができます。それは積み上げ棒グラフと円グラフの関係です。図17.18はデカルト座標系上の積み上げ棒グラフを極座標系に変換したものです。 図 17.18: 直交座標系と極座標系の比較 (2) 他にも軸を対数スケールなどに変換する coord_trans() 、地図の出力に使われる coord_map() や coord_sf() などがあり、適宜紹介していきます。 17.3.6 スケール 既に説明しました通り、{ggplot2}は様々な幾何オブジェクトがあり、これによってグラフ上におけるデータの示し方が変わります。例えば、散布図だとデータは点として表現され、折れ線グラフだと線、棒グラフやヒストグラムだと面で表現されます。これらの点、線、面などが持つ情報がスケール (scale)です。点だと縦軸上の位置、横軸上の位置が必ず含まれ、他にも点の形、点の大きさ、点の色、枠線の色、透明度などの情報を含むことが可能です。線も線が折れるポイントの横軸・縦軸上の位置、線の太さ、線の色などがあります。 この形、色、大きさ、太さなどを調整するためにはscale_*_*()関数群を使います。例えば、図17.13の場合、点は横軸上の位置、縦軸上の位置、色の3つのスケールを持っています。横軸と縦軸は連続変数 (時間と身長)、色は名目変数 (性別)です。ここで横軸のスケールを調整するためにはscale_x_continuous()レイヤーを追加します。縦軸も同様にscale_y_continuous()を使います。ここのxとyはスケール、continuousは連続変数であることを意味します。それでは、色を調整するためにはどうすれば良いでしょうか。それはscale_color_manual()です。colorは色を、manualは手動調整を意味しますが、主に性別や都道府県のような名目変数のスケール調整に使います。 これらのscale_*_*()関数群は点、線、面が持つ位置情報や性別を変更することではなく、その見せ方を変更するだけです。図17.14の縦軸の目盛りは「150、160、170、180」となっていますが、scale_y_continuous()を使うとこの目盛りが変わります。点の位置が変わることはありません。たとえば、以下のコードはscale_y_continuous()を使って縦軸の目盛りを5cm刻みに変更するためのコードであり、図17.19はその結果です。 # scale_y_continuous()の例 データ %&gt;% ggplot() + geom_point(aes(x = ゲームのプレイ時間, y = 身長, color = 性別)) + scale_y_continuous(breaks = c(145, 150, 155, 160, 165, 170, 175, 180), labels = c(145, 150, 155, 160, 165, 170, 175, 180)) 図 17.19: scale_y_continuous()を使って縦軸を5cm刻みに変更 また、性別ごとの色を変更する際はscale_color_manual()を使います（図17.20）。 # scale_color_manual()の例 データ %&gt;% ggplot() + geom_point(aes(x = ゲームのプレイ時間, y = 身長, color = 性別)) + scale_y_continuous(breaks = c(145, 150, 155, 160, 165, 170, 175, 180), labels = c(145, 150, 155, 160, 165, 170, 175, 180)) + scale_color_manual(values = c(&quot;男性&quot; = &quot;#ff9900&quot;, &quot;女性&quot; = &quot;#339900&quot;)) 図 17.20: さらにscale_color_manual()を使って色を指定 scale_*_*()関数群は以上のように、scale_スケールのタイプ_変数のタイプ()です。つまり、scale_x_date()、scale_y_discrete()やscale_color_contiuous()など様々な組み合わせが可能であり、{ggplot2}は様々なタイプのスケールと変数のための関数群を提供しています。むろん、ユーザーから独自のスケール関数を作ることも可能であり、パッケージとして公開することも可能です。 17.3.7 ファセット ファセット (facet)は日本語では「面」、「切子面」などで訳されますが、誤解を招く可能性があるため、本書ではそのままファセットと訳します。ファセットとはデータの部分集合 (subset)を対象にしたグラフを意味します。 たとえば、フリーダムハウスでは毎年、各国を「自由」、「部分的に自由」、「不自由」と格付けをし、結果を公表しています。世界に自由な国、部分的に自由な国、不自由な国が何カ国あるかを大陸ごとに示したいとします。カテゴリごとの個数を示すには棒グラフが効果的であり、図17.21のように示すことができます。 図 17.21: ファセットを分けないグラフの例 このグラフを見ると各大陸に自由な国がどれほどあるかが分かりますが、人によっては読みにくいかも知れません。できれば大陸ごとに分けたグラフの方が見やすいでしょう。そのためにはデータを特定の大陸に絞って、そのデータを用いた棒グラフを作り、最終的には出来上がったグラフたちを結合する必要があります。 しかし、{ggplot2}のファセットを指定するとそのような手間が省けます。これはデータを大陸ごとの部分集合に分割し、1つのプロット上に小さい複数のプロットを出力します。 図 17.22: 大陸ごとにファセットを分けたグラフの例 ファセットを指定するには facet_*() 関数群を使います。具体的には facet_wrap() と facet_grid() がありますが、今回のように1つの変数 (ここでは「大陸」)でファセットを分割する場合は主に facet_wrap() を、2つの変数で分割する場合は facet_grid() を使います。 ここまでが{ggplot2}の入門の入門の入門です。韓国旅行に例えると、やっと仁川国際空港の入国審査を通ったところです。The R Graph Galleryを見ると、主に{ggplot2}で作成された綺麗な図がいっぱいあります。しかし、ここまで勉強してきたものだけでは、このような図を作るのは難しいです。そもそもサンプルコードを見ても理解するのが難しいかも知れません。次章では本格的な{ggplot2}の使い方を解説します。到達目標は(1)「よく使う」グラフが作成できること、そして(2)The R Graph Galleryのサンプルコードを見て自分で真似できるようになることです。 17.4 良いグラフとは 本格的な作図に入る前に、「優れたグラフとは何か」について考えてみましょう。しかし、優れたグラフの条件を数ページでまとめるのは難しいです。筆者らがいつか暇になったら、これに関しても詳細に1つの章として解説しますが、ここでは参考になる資料をいくつかリストアップします。 Yau, Nathan. 2011. Visualize This: The FlowingData Guide to Design, Visualization, and Statistics. Wiley Cairo, Alberto. 2016. The Truthful Art: Data, Charts, and Maps for Communication. New Riders. Healy, Kieran. 2018. Data Visualization: A Practical Introduction. New Riders. Princeton University Press. 藤俊久仁・渡部良一. 2019. 『データビジュアライゼーションの教科書』秀和システム. (第5章以降) 永田ゆかり. 2020. 『データ視覚化のデザイン』SBクリエイティブ. BBC Visual and Data Journalism cookbook for R graphics 17.4.1 データ・インク比 可視化が本格的に注目を浴びるようになったのはEdward R. Tufteの1983年著作、The Visual Display of Quantitative Informationからですが、この本のメッセージは単純で、「データ・インク比 (Data-ink ratio) を最大化せよ」の一言に要約できます。データ・インク比は以下のように定義されます (Tufte 2001)。 \\[\\begin{align} \\text{Data-ink ratio} = &amp; \\frac{\\text{data-ink}}{\\text{total ink used to print the graphic}} \\\\ = &amp; \\text{proportion of a graphic&#39;s ink devoted to the} \\\\ &amp; \\text{non-redundant display of data-information} \\\\ = &amp; \\text{1.0 - proportion of a graphic that can be earase} \\\\ &amp; \\text{without loss of data-information.} \\end{align}\\] データ・インク比は「データ・インク」を「グラフの出力に使用されたインクの総量」で割ったものです。データ・インクとはデータの情報を含むインクの量を意味します。これを言い換えると、グラフにおいて情報損失なしに除去できるグラフの要素が占める割合を1から引いたものです。 ここで1つの例を紹介します。たとえば、G20加盟国におけるCOVID19の累積感染者数を時系列で示すとします。そこで最近、インドにおいて感染者数が急増していることを示したいとします。まず、図17.23から見ましょう。 図 17.23: データ・インク比の例 (改善前) そもそもどの線がインドを表しているのかが分かりにくいです。カテゴリが増えると使える色に制約が生じてしまうからです。実際、図からフランス、ドイツ、インド、インドネシアを区別するのは非常に難しいでしょう。現実に色分けが出来る天才的な色覚を持つ読者ならこちらの方が情報も豊富であり、いいかも知れません。しかし、インドにおける感染者数の急増を示すには無駄な情報が多すぎます。そこでインドを除く国の色をグレーにまとめたものが図17.24です。 図 17.24: データ・インク比の例 (改善後) こちらの方は多くの情報が失われています。アメリカや日本、韓国がどの線に該当するかが分かりません。しかし、図で示したいメッセージとは無関係でしょう。ここからもう一歩踏み込んで、「ならばインド以外の線を消せばいいじゃん」と思う方もいるかも知れません。しかし、インドの線のみ残している場合、比較対象がなくなるため、急増していることを示しにくくなります。この場合、示したい情報の損失が生じるため、インド以外の国の線はデータ・インクに含まれます。 しかし、このデータ・インク比に基づく可視化は常に正しいとは言えません。そこでもう一つの例を紹介します。図17.25の左は Kuznicki and McCutcheon (1979) の論文に掲載された図であり、右はTufteによる改善案です。 図 17.25: データ・インク比改善の例 確かに棒グラフは面を使用しており、高さを示すには線のみで十分かも知れません。また、エラー・バーも線の位置を若干ずらすことによって表現できます。それでは、読者の皆さんから見て、どのグラフが見やすいと思いますか。これについて興味深い研究結果があります。Inbar, Tractinsky, and Meyer (2007) は87人の学部生を対象に3つのグループに分けました。そして、学生たちは図17.26を「美しさ」、「明瞭さ」、「簡潔さ」の3つの面で評価し、最後にどの図が最も好きかを尋ねました。 グループ1: 図17.26のAとDを評価 グループ2: 図17.26のAとDを評価。 ただし、事前にTufteスタイル (図17.26のD)の読み方について学習させる。 グループ3: 図17.26のA、B、C、Dを評価 図 17.26: Inbar, Tractinsky, and Meyer (2007) から抜粋 皆さんもある程度は結果が予想できたかと思いますが、いずれのグループにおいても、Tufteが推奨する図17.26のDが「美しさ」、「明瞭さ」、「簡潔さ」のすべての点において最下位でした。また、どの図が最も好きかに対しても表17.3のような結果が得られました。 表 17.3: Inbar, Tractinsky, and Meyer (2007)の実験結果 Group Graph A Graph B Graph C Graph D Group 1 24 3 Group 2 29 2 Group 3 14 3 12 0 図17.26のDはデータ・インク比の観点から見れば最も優れた図ですが、それが分かりやすさを意味するわけではありません。今は、人々の認知の観点からも図を評価するようになり、近年の可視化の教科書ではこれらに関しても詳しく触れているものが多いです。Tufte (2001) の本は可視化を勉強する人にとって必読の書かも知れませんが、これだけでは十分ではなく、近年の教科書も合わせて読むことをおすすめします。 17.4.2 3次元プロット これまで見てきた全ての図は縦軸と横軸しか持たない2次元プロットです。しかし、実際の生活において3次元プロットを見にすることは珍しくないでしょう。3次元プロットの場合、縦軸と横軸以外に、高さ (深さ)といったもう一つの軸が含まれます。しかし、多くの場合、このもう一つの軸はグラフにおいて不要な場合が多いです。たとえば、図17.27をを見てみましょう84。これはCOVID19による定額給付金の給付済み金額を時系列で並べたものです。 図 17.27: 3次元プロットの例 (1) この図の目的は筆者にとってはよく分かりませんが、少なくとも給付金が順調（？）に配られているということですかね。その傾向を見るにはこの図は大きな問題はありません。しかし、細かい数値を見ようとすると誤解が生じる可能性があります。たとえば、7月22日の給付済み額は12.12兆円です。しかし、図17.28を見ると、7月22日の棒は12兆円に達しておりません。なぜでしょうか。 これは棒と壁（？）との間隔が理由です。図17.28の右下にある青い円を見ればお分かりかと思いますが、棒が浮いています。この棒を壁（？）側に密着すると12の線を超えると考えられますが、このままだと12兆円に達していないのに12兆円超えてると、何かの入力ミスじゃないかと考えさせるかも知れません。 図 17.28: 3次元プロットの罠 この図において3D要素の必要性は0と言えます。2次元の棒グラフ (図17.29)、または折れ線グラフ (図17.30)の方がデータ・インク比の観点からも、分かりやすさからも優れていると言えるでしょう。 図 17.29: 図17.27を2次元プロットに再構成した例 (棒グラフ) 図 17.30: 図17.27を2次元プロットに再構成した例 (折れ線グラフ) ただ、総務省の図はまだマシかも知れません。世の中には誤解を招かすために作成された3次元プロットもあります。以下の図は早稲田アカデミーが作成した早慶高の合格者数を年度ごとに示した図です。2001年は754人で2012年は1494人です。比較対象がないので本当に12年連続全国No.1かどうかは判断できませんが、2倍近く増加したことは分かります。ただし、棒グラフの高さを見ると、2倍どころか3倍程度に見えます。他にも一時期、合格者が減少した時期 (2002、2003年)があるにもかかわらず、あまり目立ちません。これには2つの原因があります。それは(1)多分、ベースラインが0人ではない、(2) 遠近法により遠いものは小さく見えることです。 図 17.31: 3次元プロットの例 (2) これを2次元棒グラフに直してものが図17.32です。こちらの方が合格者をより客観的に確認することができるでしょう。 図 17.32: 図17.31を2次元プロットに再構成した例 むろん、3次元プロットそのものが悪いわけではありません。むしろ、3次元の方が解釈しやすい、見やすいケースもあるでしょう。それには共通点があり、深さというもう一つの軸も何らかの情報があるという点です。一方、ここでお見せしました2つの例の場合、深さは何の情報も持ちません。つまり、データ・インク比の観点から見れば望ましくない図です。 参考資料 "],["visualization2.html", "18. 可視化[基礎] 18.1 本章の内容 18.2 実習用データ 18.3 棒グラフ 18.4 ヒストグラム 18.5 箱ひげ図 18.6 散布図 18.7 折れ線グラフ 18.8 日本語が含まれた図について 18.9 図の保存 18.10 まとめ 練習問題", " 18. 可視化[基礎] 18.1 本章の内容 前章では{ggplot2}の仕組みおよびグラフィックの文法と良いグラフについて説明しました。本章では実際に簡単なグラフを作りながら{ggplot2}に慣れて頂きたいと思います。{ggplot2}で作れる図の種類は非常に多いですが、本章では、データサイエンスで頻繁に利用される以下の5つのプロットの作り方を紹介します。 棒グラフ ヒストグラム 箱ひげ図 散布図 折れ線グラフ その他の図や、図の細かい修正については第19章で解説します。また、使用するPCの環境によっては図の文字化けが生じる可能性があります。この場合は第18.8章を参照してください。 18.2 実習用データ 実習の前に本章で使用するデータと{ggplot2}パッケージが含まれているtidyverseを読み込みます。 データ1: 国家別民主主義および政治的自由データ データ2: COVID-19データ COVID19_Worldwide.csvの場合、普通に読み込むとTest_DayとTest_Totalが数値型であるにも関わらず、logical型変数として読み込まれます。read_csvはデフォルトだと最初の100行までのデータからデータ型を判断しますが、COVID19_Worldwide.csvの場合、Test_DayとTest_Totalの最初の100要素は全て欠損しており、判断不可となるため、自動的にlogical型として判断します。これを避けるために、guess_max = 10000を追加します。これは「データ型を判断するなら10000行までは読んでから判断しろ」という意味です。 pacman::p_load(tidyverse) Country_df &lt;- read_csv(&quot;Data/Countries.csv&quot;) COVID19_df &lt;- read_csv(&quot;Data/COVID19_Worldwide.csv&quot;, guess_max = 10000) これらの変数はSONGが適当にインターネットなどで集めたデータであり、あくまでも実習用データとしてのみお使い下さい。各変数の詳細は以下の通りです。 表 18.1: 国家別民主主義および政治的自由データの詳細 変数名 説明 備考 Country 国名 Population 人口 人 Area 面積 km\\(^2\\) GDP 国内総生産 (GDP) 100万米ドル PPP GDP (購買力平価): 100万米ドル GDP_per_capita 一人あたりGDP 米ドル PPP_per_capita 一人あたりGDP (購買力平価) 米ドル G7 G7構成国 1:構成国, 0:構成国以外 G20 G20構成国 1:構成国, 0:構成国以外 OECD OECD構成国 1:構成国, 0:構成国以外 HDI_2018 人間開発指数 2018年基準 Polity_Score 民主主義の程度 Polity IVから; -10:権威主義〜10:民主主義 Polity_Type 民主主義の程度 (カテゴリ) FH_PR 政治的自由の指標 2020年基準; Freedom Houseから FH_CL 市民的自由の指標 2020年基準; Freedom Houseから FH_Total 政治的自由と市民的自由の合計 2020年基準; Freedom Houseから FH_Status 総合評価 F:完全な自由; PF:一部自由; NF:不自由 Continent 大陸 表 18.2: COVID-19データの詳細 変数名 説明 ID ID Country 国名 Date 年月日 Confirmed_Day COVID-19 新規感染者数（人） Confirmed_Total COVID-19 累積感染者数（人） Death_Day COVID-19 新規死亡者数（人） Death_Total COVID-19 累積死亡者数（人） Test_Day COVID-19 新規検査数（人） Test_Total COVID-19 累積検査数（人） 18.3 棒グラフ 棒グラフについては以下の2つのタイプについて説明します。 ある変数の数の表す棒グラフ 各グループの統計量を表す棒グラフ 前者は「データ内にアフリカのケースはいくつあるか、アジアの行はいくつあるか」のようなものであり、後者は「大陸ごとの民主主義の度合いの平均値はいくつか」を出力するグラフです。 18.3.1 ケース数のグラフ まず、Country_dfのContinent変数における各値の頻度数を棒グラフとして出してみましょう。表としてまとめる簡単な方法はtable()関数があります。 table(Country_df$Continent) ## ## Africa America Asia Europe Oceania ## 54 36 42 50 4 ケース数の棒グラフは、大陸名を横軸に、ケース数を縦軸にしたグラフです。それではグラフを作ってみます。データはCountry_dfであり、使う幾何オブジェクトはgeom_bar()です。ここで必要な情報は横軸、つまり大陸 (Continent)のみです。縦軸も「ケース数」という情報も必要ですが、{ggplot2}が勝手に計算してくれるので、指定しません。また、labs()レイヤーを追加します。labs()レイヤーはマッピング要素のラベルを指定するものです。これを指定しない場合、aes()内で指定した変数名がそのまま出力されます。 Country_df %&gt;% ggplot() + geom_bar(aes(x = Continent)) + labs(x = &quot;大陸&quot;, y = &quot;ケース数&quot;) これで初めての{ggplot2}を用いたグラフが完成しましたね！ 18.3.2 記述統計量のグラフ 次は記述統計量のグラフを出してみます。たとえば、大陸ごとに民主主義の指標の1つであるPolity Scoreの平均値を図示するとします。まずは、dplyrを使って、大陸ごとにPolity Score (Polity_Score)の平均値を計算し、Bar_df1という名で保存します。 Bar_df1 &lt;- Country_df %&gt;% group_by(Continent) %&gt;% summarise(Democracy = mean(Polity_Score, na.rm = TRUE), .groups = &quot;drop&quot;) Bar_df1 ## # A tibble: 5 × 2 ## Continent Democracy ## &lt;chr&gt; &lt;dbl&gt; ## 1 Africa 2.48 ## 2 America 6.93 ## 3 Asia 0.342 ## 4 Europe 7.93 ## 5 Oceania 7.25 それでは、このBar_df1を基にグラフを作りますが、今回は縦軸の情報も必要です。横軸はContinent、縦軸はDemocracy変数に指定します。そして、重要なものとしてstat引数を指定します。これはマッピングと関係なく、棒グラフの性質に関係するものなので、aes()の外側に位置します。これを指定しない場合、geom_bar()は基本的にはケース数を計算し、図示します。Passengerの値そのものを縦軸にしたい場合はstat = \"identity\"を指定します。後は、先ほどの棒グラフと同じです。 Bar_df1 %&gt;% ggplot() + geom_bar(aes(x = Continent, y = Democracy), stat = &quot;identity&quot;) + labs(x = &quot;大陸&quot;, y = &quot;Polity IV スコアの平均値&quot;) + theme_minimal() 考えてみれば、大陸名が英語になっていますね。図内の言語は統一するのが原則であり、図の言語は論文やレポート、報告書の言語とも一致させるべきです。ここはBar_df1のContinent列の値を日本語に置換するだけでいいので、recode()関数を使います。recode()の使い方は第13.3章を参照してください。また、順番はローマ字順にしたいので、fct_inorder()を使って、Bar_df1における表示順でfactor化を行います。 Bar_df1 %&gt;% mutate(Continent = recode(Continent, &quot;Africa&quot; = &quot;アフリカ&quot;, &quot;America&quot; = &quot;アメリカ&quot;, &quot;Asia&quot; = &quot;アジア&quot;, &quot;Europe&quot; = &quot;ヨーロッパ&quot;, .default = &quot;オセアニア&quot;), Continent = fct_inorder(Continent)) %&gt;% ggplot() + geom_bar(aes(x = Continent, y = Democracy), stat = &quot;identity&quot;) + labs(x = &quot;大陸&quot;, y = &quot;Polity IV スコアの平均値&quot;) + theme_minimal() 18.3.3 次元を追加する 記述統計量のグラフを見るとマッピング要素は2つであり、これは図が2つの次元、つまり大陸とPolity IVスコアの平均値で構成されていることを意味します。記述統計量のグラフはマッピング要素は1つですが、ケース数という次元が自動的に計算されるため2次元です。ここにもう一つの次元を追加してみましょう。たとえば、大陸ごとのPolity IVスコアの平均値を出しますが、これを更にOECD加盟有無で分けてみましょう。そのためには、まず大陸とOECD加盟有無でグループを分けてPolity IVスコアの平均値を計算する必要があります。 Bar_df2 &lt;- Country_df %&gt;% group_by(Continent, OECD) %&gt;% summarise(Democracy = mean(Polity_Score, na.rm = TRUE), .groups = &quot;drop&quot;) Bar_df2 ## # A tibble: 9 × 3 ## Continent OECD Democracy ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Africa 0 2.48 ## 2 America 0 6.55 ## 3 America 1 8.6 ## 4 Asia 0 -0.314 ## 5 Asia 1 8 ## 6 Europe 0 5.87 ## 7 Europe 1 9.12 ## 8 Oceania 0 4.5 ## 9 Oceania 1 10 続いて、ContinentとOECD列を日本語に直します。また、順番を指定するためにfactor化しましょう。 Bar_df2 &lt;- Bar_df2 %&gt;% mutate(Continent = recode(Continent, &quot;Africa&quot; = &quot;アフリカ&quot;, &quot;America&quot; = &quot;アメリカ&quot;, &quot;Asia&quot; = &quot;アジア&quot;, &quot;Europe&quot; = &quot;ヨーロッパ&quot;, .default = &quot;オセアニア&quot;), Continent = fct_inorder(Continent), OECD = recode(OECD, &quot;0&quot; = &quot;OECD非加盟国&quot;, &quot;1&quot; = &quot;OECD加盟国&quot;), OECD = fct_inorder(OECD)) Bar_df2 ## # A tibble: 9 × 3 ## Continent OECD Democracy ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 アフリカ OECD非加盟国 2.48 ## 2 アメリカ OECD非加盟国 6.55 ## 3 アメリカ OECD加盟国 8.6 ## 4 アジア OECD非加盟国 -0.314 ## 5 アジア OECD加盟国 8 ## 6 ヨーロッパ OECD非加盟国 5.87 ## 7 ヨーロッパ OECD加盟国 9.12 ## 8 オセアニア OECD非加盟国 4.5 ## 9 オセアニア OECD加盟国 10 これで作図の準備ができました。それではこの新しい次元であるOECDをどのように表現すれば良いでしょうか。Continentは横軸の位置で表現され、Democracyは縦軸の位置として表現されているため、xとy以外の要素を考えてみましょう。棒グラフの場合、もう一つの軸が追加されるとしたらそれは、棒の色です。棒の色はfillで指定できます。colorでないことに注意してください。colorも指定可能ですが、これは棒の色ではなく、棒を囲む線の色であり、通常は「なし」となっています。それではfillをaes()内に書き加えます。 Bar_df2 %&gt;% ggplot() + geom_bar(aes(x = Continent, y = Democracy, fill = OECD), stat = &quot;identity&quot;) + labs(x = &quot;大陸&quot;, y = &quot;Polity IV スコアの平均値&quot;) + theme_minimal() なんか思ったものと違うものが出てきました。たとえば、アメリカ大陸の場合、Polity IVスコアの平均値が約15ですが、明らかにおかしいです。なぜならPolity IVスコアの最大値は10だからです。これは2つの棒が積み上げられているからです。アメリカ大陸においてOECD加盟国の平均値は8.6、非加盟国のそれは6.55であり、足したら15.15になります。これをずらすためにはpositionを設定する必要があります。しかし、positionというのはBar_df2の何かと変数の値を表すわけではないため、aes()の外側に入れます。そして、その値ですが、ここでは\"dodge\"を指定します。これは棒の位置が重ならないように調整することを意味します。このpositionのデフォルト値は\"stack\"であり、言葉通り「積み上げ」です。 Bar_df2 %&gt;% ggplot() + geom_bar(aes(x = Continent, y = Democracy, fill = OECD), stat = &quot;identity&quot;, position = &quot;dodge&quot;) + labs(x = &quot;大陸&quot;, y = &quot;Polity IV スコアの平均値&quot;) + theme_minimal() これで私たちが期待した図が出来上がりました。「\"dodge\"の方が普通なのになぜデフォルトが\"stack\"か」と思う方もいるかも知れませんが、実は\"stack\"も頻繁に使われます。それはケース数のグラフにおいてです。 たとえば、大陸ごとにOECD加盟/非加盟国を計算してみましょう。 Bar_df3 &lt;- Country_df %&gt;% group_by(Continent, OECD) %&gt;% summarise(N = n(), .groups = &quot;drop&quot;) %&gt;% mutate(Continent = recode(Continent, &quot;Africa&quot; = &quot;アフリカ&quot;, &quot;America&quot; = &quot;アメリカ&quot;, &quot;Asia&quot; = &quot;アジア&quot;, &quot;Europe&quot; = &quot;ヨーロッパ&quot;, .default = &quot;オセアニア&quot;), Continent = fct_inorder(Continent), OECD = recode(OECD, &quot;0&quot; = &quot;OECD非加盟国&quot;, &quot;1&quot; = &quot;OECD加盟国&quot;), OECD = fct_inorder(OECD)) Bar_df3 ## # A tibble: 9 × 3 ## Continent OECD N ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 アフリカ OECD非加盟国 54 ## 2 アメリカ OECD非加盟国 31 ## 3 アメリカ OECD加盟国 5 ## 4 アジア OECD非加盟国 39 ## 5 アジア OECD加盟国 3 ## 6 ヨーロッパ OECD非加盟国 23 ## 7 ヨーロッパ OECD加盟国 27 ## 8 オセアニア OECD非加盟国 2 ## 9 オセアニア OECD加盟国 2 これを可視化したのが以下の図です。 Bar_df3 %&gt;% ggplot() + geom_bar(aes(x = Continent, y = N, fill = OECD), stat = &quot;identity&quot;) + labs(x = &quot;大陸&quot;, y = &quot;国家数&quot;) + theme_minimal() この図はposition = \"dodge\"でも良いと思いますが、大陸内の比率を考えるならposition = \"stack\"でも問題ないでしょう。また、積み上げグラフの特性上、大陸ごとの国数の合計も一瞬で判別できるといった長所もあります。position = \"dodoge\"だと、それが難しいですね。むろん、積み上げ棒グラフはベースラインが一致したいため、避けるべきという人も多いですし、著者 (SONG)も同意見です。どの図を作成するかは分析者の責任で判断しましょう。 18.4 ヒストグラム ヒストグラムは棒グラフと非常に形が似ていますが、横軸が大陸のような離散変数でなく、連続変数であるのが特徴です。連続変数をいくつの区間 (階級)に分け、その区間内に属するケース数 (度数)を示したのが度数分布表、そして度数分布表をかしかしたものがヒストグラムです。連続変数を扱っているため、棒間に隙間がありません。それでもケース数の棒グラフと非常に似通っているため、マッピングの仕方も同じです。異なるのは幾何オブジェクトがgeom_bar()でなく、geom_histogram()に変わるくらいです。世界の富がどのように分布しているかを確認するために、Country_dfのGDPのヒストグラムを作ってみます。 Country_df %&gt;% ggplot() + geom_histogram(aes(x = GDP)) + labs(x = &quot;国内総生産 (100万米ドル)&quot;, y = &quot;度数&quot;) + theme_minimal() ケース数の棒グラフのコードとほぼ同じです。横軸の数値が2.0e+07になっているのは2 \\times 10^7、つまり2千万を意味します。普通に表記すると20000000になりますね。また、GDPの単位は100万ドルであるため、実際のGDPは20兆ドルになります。つまり、今のヒストグラムにおいて横軸の目盛りは5兆ドルになっています。この軸の数値を「0, 5e+06, 1e+07, 1.5e+07, 2e+07」から「0, 5, 10, 15, 20」 にし、X軸のラベルを「国内総生産 (100万米ドル)」から「国内総生産 (兆米ドル)」に替えてみましょう。ここで使うのはscale_x_continuous()関数です。これは横軸 (X軸)が連続変数 (continuous)の場合のスケール調整関数です。目盛りの再調整にはbreaksとlabels引数が必要です。breaksは新しい目盛りの位置、labelsは目盛りに表記する値です。それぞれベクトルが必要であり、breaksとlabelsの実引数の長さは必ず一致する必要があります。また、breaksは数値型ベクトルですが、labelsは数値型でも文字型でも構いません。 Country_df %&gt;% ggplot() + geom_histogram(aes(x = GDP)) + labs(x = &quot;国内総生産 (兆米ドル)&quot;, y = &quot;度数&quot;) + scale_x_continuous(breaks = c(0, 5000000, 10000000, 15000000, 20000000), labels = c(0, 5, 10, 15, 20)) + theme_minimal() これで一通りヒストグラムが完成しました。ほんの一部の国は非常に高いGDPを誇っていることが分かります。GDPが10兆ドル以上の国はアメリカと中国のみであり、5兆ドルを国まで拡大しても日本が加わるだけです。そもそも1兆ドルを超える国はデータには16カ国しかなく、90%以上の国が図の非常に狭い範囲内 (0~1兆ドル)に集まっていることが分かります。 この場合、2つの方法が考えられます。1つ目は方法は情報の損失を覚悟した上で、GDPが1兆ドル未満の国でヒストグラムを書く方法です。これはデータをggplot()関数を渡す前にfilter()を使って、GDPが100万未満のケースに絞るだけで出来ます。ただし、横軸の最大値が2000万でなく、100万になるため、目盛りを調整した方が良いでしょう。 Country_df %&gt;% filter(GDP &lt; 1000000) %&gt;% ggplot() + geom_histogram(aes(x = GDP)) + labs(x = &quot;国内総生産 (兆米ドル)&quot;, y = &quot;度数&quot;) + scale_x_continuous(breaks = seq(0, 1000000, 100000), labels = seq(0, 1, 0.1)) + theme_minimal() 2つ目の方法は横軸を対数化することです。GDPを底10の対数化 (常用対数)をすると、10兆のような非常に大きい値があっても比較的に狭い範囲内にデータを収めることが出来ます。たとえば、10を常用対数化すると1, 1000は3, 10000000は7になります。自然対数 (底が\\(e\\))も可能ですが、「読む」ためのグラフとしては底が10の方が読みやすいでしょう。横軸の変数が対数化されるということは、横軸のスケールを対数化することと同じです。そのためにはscale_x_continuous()内にtrans引数を指定し、\"log10\"を渡します。 Country_df %&gt;% ggplot() + geom_histogram(aes(x = GDP)) + labs(x = &quot;国内総生産 (兆米ドル)&quot;, y = &quot;度数&quot;) + scale_x_continuous(breaks = seq(0, 20000000, by = 5000000), labels = seq(0, 20, by = 5), trans = &quot;log10&quot;) + theme_minimal() 対数化することによってGDPの分布が綺麗な形になりました。対数化すると横軸における目盛りの間隔が等間隔でないことに注意すべきです。0から5兆ドルの距離はかなり広めですが、5兆から10兆までの距離は短くなり、10兆から15兆までの距離は更に短くなります。したがって、この図から「世界のGDPは鐘型に分布している」と解釈することは出来ません。分布を可視化するには対数化する前の図が適します。 対数化のもう一つの方法はscale_x_continuous()の代わりにscale_x_log10()を使うことです。使い方はscale_x_continuous()と同じですが、trans = \"log10\"の指定は不要です。 Country_df %&gt;% ggplot() + geom_histogram(aes(x = GDP)) + labs(x = &quot;国内総生産 (兆米ドル)&quot;, y = &quot;度数&quot;) + scale_x_log10() + theme_minimal() 横軸を修正するにはscale_x_continuous()と同様、breaksとlabels引数を指定します。 Country_df %&gt;% ggplot() + geom_histogram(aes(x = GDP)) + labs(x = &quot;国内総生産 (兆米ドル)&quot;, y = &quot;度数&quot;) + scale_x_log10(breaks = c(0, 1000, 10000, 100000, 1000000, 10000000), labels = c(0, 0.001, 0.01, 0.1, 1, 10)) + theme_minimal() 他にもcoord_*()関数群、つまり座標系の操作を用いて軸を対数化することも可能です。他にも、データをggplot()を渡す前に変数を対数化するのもありでしょう。プログラミングにおいてある結果にたどり着く方法は複数あるので、色々試してみるのも良いでしょう。 18.4.1 ヒストグラムの棒の大きさを調整する 棒グラフのようにもう一つの次元を追加してみましょう。まず、人間開発指数 (HDI_2018)の分布を示してみましょう。 Country_df %&gt;% ggplot() + geom_histogram(aes(x = HDI_2018)) + labs(x = &quot;人間開発指数 (2018)&quot;, y = &quot;ケース数&quot;) + scale_x_continuous(breaks = seq(0, 1, 0.1), labels = seq(0, 1, 0.1)) + theme_bw() これでもヒストグラムとしては十分すぎるかも知れませんが、色々調整してみましょう。まずは、棒の枠線を白にしてみましょう。枠線はデータ内の変数に対応していないため、aes()の外側に入れます。枠線を指定する引数はcolorです。ちなみに棒の色を指定する引数はfillです。また、警告メッセージも気になるので、HDI_2018が欠損している行を除外します。 Country_df %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot() + geom_histogram(aes(x = HDI_2018), color = &quot;white&quot;) + labs(x = &quot;人間開発指数 (2018)&quot;, y = &quot;ケース数&quot;) + scale_x_continuous(breaks = seq(0, 1, 0.1), labels = seq(0, 1, 0.1)) + theme_bw() 人によってはこちらの方が見やすかも知れません。 これで一通りの作図は出来ましたが、これまで無視してきたメッセージについて考えてみましょう。 ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. これは「連続変数HDI_2018を30区間 (=階級)に分けました」という意味です。この区間数を調整する方法は2つあり、(1) 区間数を指定する、(2) 区間の幅を指定する方法があります。 区間数を指定することはすなわちヒストグラムの棒の数を指定することであり、bins引数で調整可能です。たとえば、棒の数を10個にするためにはgeom_histogram()内にbins = 10を指定します。むろん、棒の数もデータとは無関係であるため、aes()の外側に位置します。 Country_df %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot() + geom_histogram(aes(x = HDI_2018), color = &quot;white&quot;, bins = 10) + labs(x = &quot;人間開発指数 (2018)&quot;, y = &quot;ケース数&quot;) + scale_x_continuous(breaks = seq(0, 1, 0.1), labels = seq(0, 1, 0.1)) + theme_bw() 数えてみると棒が10個だということが分かります。 他にも区間の幅を指定することも可能です。区間の幅は棒の幅と一致します。たとえば、棒の幅を0.1にしてみましょう。棒の幅はbinwidthで調整可能です。 Country_df %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot() + geom_histogram(aes(x = HDI_2018), color = &quot;white&quot;, binwidth = 0.1) + labs(x = &quot;人間開発指数 (2018)&quot;, y = &quot;ケース数&quot;) + scale_x_continuous(breaks = seq(0, 1, 0.1), labels = seq(0, 1, 0.1)) + theme_bw() ヒストグラムが出力されましたが、棒の幅がbinwidthで指定した0.1と一致することが分かります。たとえば、一番左の棒は0.35から0.45まで、つまり幅が0.1です。そして、一番右の棒は0.95から1.05に渡って位置します。ただし、ここでに疑問を持つ読者もいるでしょう「。なぜ0.3から0.4、0.4から0.5、…ではなく、0.35から0.45、0.45から0.55なのか」です。これは{ggplot2}の基本仕様です。ヒストグラムは度数分布表を基に作成されますが、本グラフの度数分布表は以下のようになります。 から まで 度数 0.35 0.45 10 0.45 0.55 26 0.55 0.65 22 0.65 0.75 37 0.75 0.85 47 0.85 0.95 37 0.95 1.05 1 簡単に言うと、ヒストグラムの最初の棒は0を中央にした上で、棒の幅を0.1にしたとも言えます。これによってヒストグラムの境界線 (boundary)が、データより左右に0.05 (binwidthの半分)ずつ広くなります。もし、これを調整したい場合は、boundary引数を指定します。指定しない場合、boundaryは「棒の広さ / 2」となります。棒がデータの範囲を超えないようにするためには、geom_histogram()内にboundary = 0を指定します。 Country_df %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot() + geom_histogram(aes(x = HDI_2018), color = &quot;white&quot;, binwidth = 0.1, boundary = 0) + labs(x = &quot;人間開発指数 (2018)&quot;, y = &quot;ケース数&quot;) + scale_x_continuous(breaks = seq(0, 1, 0.1), labels = seq(0, 1, 0.1)) + theme_bw() ここまで抑えとけば、普段使われるヒストグラムは問題なく作れるでしょう。 18.4.2 密度を追加する ヒストグラムには以下のように密度の表す線を同時に載せるケースもあります。 この密度の線を追加するにはgeom_density()という幾何オブジェクトを追加する必要があります。密度の線を示すには、横軸と縦軸両方の情報が必要です。横軸はHDI_2018で問題ないですが、縦軸はどうでしょう。縦軸には密度の情報が必要ですが、Country_dfにそのような情報はありません。幸い、{ggplot2}はy = ..density..と指定するだけで、自動的にHDI_2018のある時点における密度を計算してくれます。したがって、マッピングはaes(x = HDI_2018, y = ..density..)のように書きます。こうなるとマッピング要素xはgeom_histogram()とgeom_density()に共通するため、ggplot()に入れても問題ありません。 Country_df %&gt;% filter(!is.na(HDI_2018)) %&gt;% # 全幾何オブジェクトにおいてxを共有するため、ここでマッピング指定 ggplot(aes(x = HDI_2018)) + geom_histogram(color = &quot;white&quot;, binwidth = 0.05, boundary = 0) + geom_density(aes(y = ..density..), size = 1) + labs(x = &quot;人間開発指数 (2018)&quot;, y = &quot;密度&quot;) + scale_x_continuous(breaks = seq(0, 1, 0.1), labels = seq(0, 1, 0.1)) + theme_bw() なんとも言えない微妙なグラフが出来ました。考えたものと全然違いますね。これはなぜでしょうか。それはgeom_density()は密度を表す一方、geom_histogram()は度数を表すからです。2つは単位が全然違います。したがって、どちらかに単位を合わせる必要があり、この場合はヒストグラムの縦軸を度数でなく、密度に調整する必要があります。ヒストグラムの縦軸を密度にするためには、y = ..density..を指定するだけです。こうなると、geom_histogram()とgeom_density()はxとyを共有するため、全部ggplot()内で指定しましょう。 Country_df %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot(aes(x = HDI_2018, y = ..density..)) + geom_histogram(color = &quot;white&quot;, binwidth = 0.05, boundary = 0) + geom_density(size = 1) + labs(x = &quot;人間開発指数 (2018)&quot;, y = &quot;密度&quot;) + scale_x_continuous(breaks = seq(0, 1, 0.1), labels = seq(0, 1, 0.1)) + theme_bw() これで密度を表す線が出来ました。 18.4.3 次元を追加する 次元を追加するには棒グラフと同様、aes()内にマッピング要素を追加します。たとえば、OECD加盟有無によって人間開発指数の分布がどう異なるかを確認してみましょう。OECD変数は0/1であり、Rでは連続変数扱いになっているため、これを離散変数化するためには文字型かfactor型にする必要があります。ifelse()を使って、OECD == 1なら「OECD加盟国」、OECD == 0なら「OECD非加盟国」と置換したものをOECD2という列として追加します。そして、OECD2ごとに棒の色を変えるために、マッピング要素としてfillを追加します。 Country_df %&gt;% mutate(OECD2 = ifelse(OECD == 1, &quot;加盟国&quot;, &quot;非加盟国&quot;)) %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot() + geom_histogram(aes(x = HDI_2018, fill = OECD2), color = &quot;white&quot;, binwidth = 0.05, boundary = 0) + # fill要素のラベルをOECDに変更 labs(x = &quot;人間開発指数 (2018)&quot;, y = &quot;ケース数&quot;, fill = &quot;OECD&quot;) + scale_x_continuous(breaks = seq(0, 1, 0.1), labels = seq(0, 1, 0.1)) + theme_bw() ヒストグラムが出来上がりました。OECD加盟国の場合、人間開発指数が相対的に高いことが分かります。しかし、積み上げヒストグラムになっています。これはある階級においてOECD加盟国と非加盟国の比率を比較する際に有効ですが、OECD加盟国と非加盟国の分布の違いを見るにはやや物足りません。したがって、棒グラフ同様、position引数で棒の位置を調整します。ただし、ヒストグラムの場合、postion = \"dodge\"は向いていないので、ここではposition = \"identity\"を指定します。しかし、この場合、棒が重なってしまうと、一方の棒が見えなくなる可能性もあるので、alpha引数で棒の透明度を調整します。alphaの値は0から1までであり、0になると、完全透明になります。ここでは0.5くらいにしてみましょう。 Country_df %&gt;% mutate(OECD2 = ifelse(OECD == 1, &quot;OECD加盟国&quot;, &quot;OECD非加盟国&quot;)) %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot() + geom_histogram(aes(x = HDI_2018, fill = OECD2), color = &quot;white&quot;, alpha = 0.5, position = &quot;identity&quot;, binwidth = 0.05, boundary = 0) + labs(x = &quot;人間開発指数 (2018)&quot;, y = &quot;ケース数&quot;, fill = &quot;OECD&quot;) + scale_x_continuous(breaks = seq(0, 1, 0.1), labels = seq(0, 1, 0.1)) + theme_bw() これで2つのヒストグラムを綺麗にオーバーラッピングできました。また、先ほど紹介しましたgeom_density()オブジェクトを重ねることも可能です。 Country_df %&gt;% mutate(OECD2 = ifelse(OECD == 1, &quot;OECD加盟国&quot;, &quot;OECD非加盟国&quot;)) %&gt;% filter(!is.na(HDI_2018)) %&gt;% # xはHDI_2018、yは密度 (..density..)とする ggplot(aes(x = HDI_2018, y = ..density..)) + geom_histogram(aes(fill = OECD2), color = &quot;white&quot;, alpha = 0.5, position = &quot;identity&quot;, binwidth = 0.05, boundary = 0) + # OECD2ごとに異なる色を付ける。線の太さは1、凡例には表示させない geom_density(aes(color = OECD2), size = 1, show.legend = FALSE) + # 縦軸のラベルを「密度」に変更 labs(x = &quot;人間開発指数 (2018)&quot;, y = &quot;密度&quot;, fill = &quot;OECD&quot;) + scale_x_continuous(breaks = seq(0, 1, 0.1), labels = seq(0, 1, 0.1)) + theme_bw() この場合、OECD加盟国と非加盟国の密度をそれぞれ計算するため、ヒストグラムの見た目がこれまでのものと変わることに注意してください。 ここまで、次元拡張の方法としてヒストグラムのオーバーラッピングについて紹介しました。しかし、ヒストグラムを重なってしまうと、読みにくい人もいるかも知れません。オーバーラップ以外の方法はプロットを2つに分けることです。つまり、1つのプロットに小さいブロットを複数載せることであり、この小さいプロットをファセット (facet)と呼びます。これにはfacet_*()関数群の中の、facet_wrap()関数を使います。facet_wrap(~ 分ける変数名)を追加すると変数ごとにプロットを分割してくれます。ncolやnrow引数を指定すると、ファセットの列数や行数も指定可能です。 それではやってみましょう。facet_wrap(~ OECD2)を追加するだけです。2つのファセットを縦に並べるために、ncol = 1を追加します。2つのファセットを1列に並べるという意味です。 Country_df %&gt;% mutate(OECD2 = ifelse(OECD == 1, &quot;OECD加盟国&quot;, &quot;OECD非加盟国&quot;)) %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot() + geom_histogram(aes(x = HDI_2018), color = &quot;white&quot;, binwidth = 0.05, boundary = 0) + labs(x = &quot;人間開発指数 (2018)&quot;, y = &quot;ケース数&quot;, fill = &quot;OECD&quot;) + scale_x_continuous(breaks = seq(0, 1, 0.1), labels = seq(0, 1, 0.1)) + facet_wrap(~ OECD2, ncol = 1) + theme_bw() OECDは加盟/非加盟だけですから、オーバーラッピングされたヒストグラムで十分かも知れません。しかし、大陸のように、3つ以上のグループになると、オーバーラッピングよりもファセットで分けた方が効率的です。たとえば、大陸ごとの人間開発指数のヒストグラムを作ってみましょう。 Country_df %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot() + geom_histogram(aes(x = HDI_2018), color = &quot;white&quot;, binwidth = 0.1, boundary = 0) + labs(x = &quot;人間開発指数 (2018)&quot;, y = &quot;ケース数&quot;, fill = &quot;OECD&quot;) + scale_x_continuous(breaks = seq(0, 1, 0.1), labels = seq(0, 1, 0.1)) + facet_wrap(~ Continent, ncol = 3) + theme_bw() 18.5 箱ひげ図 データの分布を示す際には、離散変数ならケース数 (度数)の棒グラフ、連続変数ならヒストグラムがよく使われますが、連続変数の場合、もう一つの方法があります。それが箱ひげ図です。箱ひげ図はヒストグラムより情報量がやや損なわれますが、データの中央値、四分位点（四分位範囲）、最小値と最大値の情報を素早く読み取れます。また、複数の変数、またはグループの分布を1つのプロットに示すにはヒストグラムより優れています。 まずは人間開発指数の箱ひげ図を出してみます。使用する幾何オブジェクトはgeom_boxplot()です。そして、指定するマッピング要素はyのみです。箱ひげ図から読み取れる情報は最小値・最大値、中央値、第1四分位点、第3四分位点ですが、これらの情報は縦軸として表現されます。それでは、とりあえず実際に作ってみましょう。 Country_df %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot() + geom_boxplot(aes(y = HDI_2018)) + labs(y = &quot;人間開発指数 (2018)&quot;) 箱ひげ図の読み方は以下の通りです。 これで箱ひげ図は完成ですが、人間開発指数は0から1の相対を取るので、座標系の縦軸を調整してみましょう。座標系の操作はcoord_*()関数群を使いますが、現在使っているのは直交座標系（デカルト座標系）ですのでcoord_cartesian()を使います。ここで縦軸の上限と下限を指定する引数がylimであり、長さ2の数値型ベクトルが必要です。下限0、上限1ですので、ylim = c(0, 1)とします。 Country_df %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot() + geom_boxplot(aes(y = HDI_2018)) + labs(y = &quot;人間開発指数 (2018)&quot;) + coord_cartesian(ylim = c(0, 1)) まだまだ改善の余地はありますが、それなりの箱ひげ図の出来上がりです。しかし、一変数の箱ひげ図はあまり使われません。変数が1つだけならヒストグラムの方がより情報量は豊富でしょう。情報量が豊富ということはヒストグラムから（完璧には無理ですが）箱ひげ図を作ることは可能である一方、その逆は不可能か非常に難しいことを意味します。 ヒストグラムが力を発揮するのは複数の変数、または複数のグループごとの分布を比較する際です。先ほど、大陸ごとの人間開発指数の分布を確認するためにヒストグラムを5つのファセットで分割しました。箱ひげ図なら1つのグラフに5つの箱を並べるだけです。これは横軸を大陸 (Continent)にすることを意味します。先ほどのコードのマッピングにx引数を追加してみましょう。 Country_df %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot() + geom_boxplot(aes(x = Continent, y = HDI_2018)) + labs(x = &quot;大陸&quot;, y = &quot;人間開発指数 (2018)&quot;) + coord_cartesian(ylim = c(0, 1)) いかがでしょうか。5大陸の分布を素早く確認することができました。ヨーロッパの場合、人間開発指数が高く、バラツキも小さいことが分かります。一方、アジアとアフリカはバラツキが非常に大きいですね。アメリカ大陸はバラツキは非常に小さいですが、極端に高い国や低い国が含まれています。このアメリカ大陸に3つの点がありますが、これは外れ値です。つまり、最小値より小さい、または最大値より大きいケースを表します。最小値より小さい、または最大値より大きいという表現に違和感を感じるかも知れません。実は一般的な箱ひげ図の最小値は「第1四分位点 - 1.5 \\(\\times\\) 四分位範囲」より大きい値の中での最小値です。同じく最大値は「第3四分位点 + 1.5 \\(\\times\\) 四分位範囲」より小さい値の中での最大値です。普通に分布している場合、ほとんどのケースは箱ひげ図の最小値と最大値の範囲内に収まりますが、極端に大きい値、小さい値が含まれる場合は箱ひげ図の最小値と最大値の範囲からはみ出る場合があります。 また、複数の箱を並べる際、それぞれの箱に異なる色を付ける場合があります。これはデータ・インク比の観点から見れば非効率的ですが、可読性を落とすこともないのでさほど問題はないでしょう。先ほどの箱ひげ図の場合、大陸ごとに異なる色を付けるにはマッピング要素としてfill = Continentを追加するだけです。この場合、色に関する凡例が自動的に出力されますが、既に横軸で大陸の情報が分かるため、この判例は不要でしょう。したがって、aes()の外側にshow.legned = FALSEを付けます。これは当該幾何オブジェクトに関する凡例を表示させないことを意味します。 Country_df %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot() + geom_boxplot(aes(x = Continent, y = HDI_2018, fill = Continent), show.legend = FALSE) + labs(x = &quot;大陸&quot;, y = &quot;人間開発指数 (2018)&quot;) + coord_cartesian(ylim = c(0, 1)) 彩りどりでちょっとテンションが上がる箱ひげ図ができました。 18.5.1 個別のデータを表示する 箱ひげ図は複数のグループや変数の分布を素早く比較できる長所がありますが、中央値、最小値、最大値、第1・3四分位点、外れ値の情報しか持ちません。人によってはもうちょっと情報量を増やすために個々の観測値を点として示す場合もあります。点を出力する幾何オブジェクトは次節で紹介するgeom_point()です。以下の内容は散布図の節を一読してから読むのをおすすめします。 点の幾何オブジェクトにおける必須マッピング要素は点の横軸の位置と縦軸の位置、つまりxとyです。今回の場合、点の横軸が大陸（Continent）、縦軸は人間開発指数（HDI_2018）です。つまり、geom_boxplot()のマッピングと同じです。したがって、xとyはggplot()に入れておきます。あとは大陸ごとに店の色分けをしたいので、color引数をaes()内に指定します。また、点が重なる場合、読みづらくなる可能性があるため、alpha引数をaes()外に指定して透明度を調整します。また、箱ひげ図もある程度は透明にしないと、裏にある点が見えないため、こちらもalphaを調整します。 Country_df %&gt;% filter(!is.na(HDI_2018)) %&gt;% # 全幾何オブジェクトにおいてxとyは共有されるため、ここで指定 ggplot(aes(x = Continent, y = HDI_2018)) + geom_point(aes(color = Continent), alpha = 0.5, show.legend = FALSE) + geom_boxplot(aes(fill = Continent), alpha = 0.5, show.legend = FALSE) + labs(x = &quot;大陸&quot;, y = &quot;人間開発指数 (2018)&quot;) + coord_cartesian(ylim = c(0, 1)) 点が透明ではあるものの、それでも重なっている箇所は相変わらず読みにくいです。この場合有効な方法がジッター（jitter）です。これは点の位置に若干のノイズを付けることによって、点が重ならないようにすることです。ジッターの方法は2つありますが、ここではジッター専用の幾何オブジェクトgeom_jitter()を使います85。geom_jitter()はノイズが追加された散布図ですので、geom_point()と使い方はほぼ同じです。 Country_df %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot(aes(x = Continent, y = HDI_2018)) + geom_jitter(aes(color = Continent), show.legend = FALSE) + geom_boxplot(aes(fill = Continent), alpha = 0.5, show.legend = FALSE) + labs(x = &quot;大陸&quot;, y = &quot;人間開発指数 (2018)&quot;) + coord_cartesian(ylim = c(0, 1)) これで点が重ならなくなりましたが、ちょっと散らばりすぎるという印象もあります。この散らばり具合を調整する引数がwidthとheightです。もちろん、これはデータの中身に対応する要素ではないため、aes()の外側にいれます。それぞれの実引数は0から1の間の数値になりますが、数字が大きいほど散らばり具合が大きくなり、0になるとジッター無しの散布図と同じものになります。ここでは横の散らばり具合を0.15（width = 0.15）、縦の散らばり具合は0（height = 0）にしてみましょう。そして、横軸が英語のままなので、これも日本語に直します。 Country_df %&gt;% mutate(Continent2 = factor(Continent, levels = c(&quot;Africa&quot;, &quot;America&quot;, &quot;Asia&quot;, &quot;Europe&quot;, &quot;Oceania&quot;), labels = c(&quot;アフリカ&quot;, &quot;アメリカ&quot;, &quot;アジア&quot;, &quot;ヨーロッパ&quot;, &quot;オセアニア&quot;))) %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot(aes(x = Continent2, y = HDI_2018)) + geom_jitter(aes(color = Continent2), width = 0.15, height = 0, show.legend = FALSE) + geom_boxplot(aes(fill = Continent2), alpha = 0.5, show.legend = FALSE) + labs(x = &quot;大陸&quot;, y = &quot;人間開発指数 (2018)&quot;) + coord_cartesian(ylim = c(0, 1)) 18.5.2 次元を追加する 箱ひげ図に次元を追加する方法はこれまで見てきたように、1つのグラフに次元を追加するか、次元でファセットを分割するかの問題になります。まずは、簡単なファセット分割からやってみます。追加する次元は先進国か否かです。先進国の基準は不明瞭ですが、ここではG7、G20、OECDいずれかに加盟していれば先進国と定義しましょう。そのためにCountry_dfにDeveloped変数を追加します。この変数はG7、G20、OECDの合計が1以上の場合は1、0の場合は0とします。そして、このDeveloped変数をfactor化します。具体的にはDevelopedが1だと\"先進国\"、0だと\"その他\"にします。あとはfacet_wrap()でファセットを分割します。 Country_df %&gt;% mutate(Continent2 = factor(Continent, levels = c(&quot;Africa&quot;, &quot;America&quot;, &quot;Asia&quot;, &quot;Europe&quot;, &quot;Oceania&quot;), labels = c(&quot;アフリカ&quot;, &quot;アメリカ&quot;, &quot;アジア&quot;, &quot;ヨーロッパ&quot;, &quot;オセアニア&quot;)), # G7 + G20 + OECDが1以上なら1、0なら0とするDeveloped変数作成 Developed = ifelse(G7 + G20 + OECD &gt;= 1, 1, 0), # Developed変数のfactor化 Developed = factor(Developed, levels = c(1, 0), labels = c(&quot;先進国&quot;, &quot;その他&quot;), ordered = TRUE)) %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot(aes(x = Continent2, y = HDI_2018)) + geom_jitter(aes(color = Continent2), alpha = 0.5, width = 0.15, height = 0, show.legend = FALSE) + geom_boxplot(aes(fill = Continent2), alpha = 0.5, show.legend = FALSE) + # caption引数で図の右下にテキストを入れる labs(x = &quot;大陸&quot;, y = &quot;人間開発指数 (2018)&quot;, caption = &quot;先進国: G7, G20, OECDのいずれかに加盟している国&quot;) + # ファセット分割 facet_wrap(~ Developed) + coord_cartesian(ylim = c(0, 1)) + theme_bw() 次の方法はファセットを分割せずに次元を追加する方法です。ファセットに分ける場合、「先進国における大陸別人間開発指数の分布」、「先進国外における大陸別人間開発指数の分布」は素早く読み取れますが、「ある大陸における先進国/その他の国の人間開発指数の分布」を比較するにはあまり向いておりません。なぜなら目の動線が長いからです。先進国とその他の国を大陸ごとに横に並べると視線の動線が短くなり比較しやすくなります。 やり方はあまり変わりませんが、今回は色分けをContinentでなくDevelopedでする必要があります。1つの画面に先進国とその他の国の情報が同時に出力されるため、この2つを見分けるためには色分けが有効です。したがって、geom_jitter()とgeom_boxplot()のcolorとfillをContinentからDevelopedへ変更します。 そしてもう一つ重要なことがあります。それはgeom_jitter()の位置です。次元ごとに横軸の位置をずらす場合、geom_bar()はposition = \"dodge\"を使いました。しかし、geom_jitter()では\"dodge\"が使えません。その代わりにpositonの実引数としてposition_jitterdodge()を指定します。この中には更にjitter.widthとjitter.height引数があり、散らばりの具合をここで調整します。なぜ、geom_jitter()でwidthとheightを指定するのではなく、position_jitter()内で指定するかですが、これはgeom_jitter()関数の仕様です。geom_jitter()の場合、positionとwidthまたはheightを同時に指定することは出来ません。 それでは早速やってみましょう。 Country_df %&gt;% mutate(Continent2 = factor(Continent, levels = c(&quot;Africa&quot;, &quot;America&quot;, &quot;Asia&quot;, &quot;Europe&quot;, &quot;Oceania&quot;), labels = c(&quot;アフリカ&quot;, &quot;アメリカ&quot;, &quot;アジア&quot;, &quot;ヨーロッパ&quot;, &quot;オセアニア&quot;)), Developed = ifelse(G7 + G20 + OECD &gt;= 1, 1, 0), Developed = factor(Developed, levels = c(1, 0), labels = c(&quot;先進国&quot;, &quot;その他&quot;), ordered = TRUE)) %&gt;% filter(!is.na(HDI_2018)) %&gt;% ggplot(aes(x = Continent2, y = HDI_2018)) + # jitterでdodgeを使うためにはposition_jitterdodgeを使う geom_jitter(aes(color = Developed), alpha = 0.5, position = position_jitterdodge(jitter.width = 0.5, jitter.height = 0), show.legend = FALSE) + geom_boxplot(aes(fill = Developed), alpha = 0.5) + labs(x = &quot;大陸&quot;, y = &quot;人間開発指数 (2018)&quot;, fill = &quot;&quot;, caption = &quot;先進国: G7, G20, OECDのいずれかに加盟している国&quot;) + coord_cartesian(ylim = c(0, 1)) + theme_bw() ファセット分割と色分け、どれが良いかという正解はありません。分析者の目的に依存するものです。もし、先進国の中での比較を強調したい場合はファセット分割が有効でしょう。しかし、同じ大陸内で先進国とその他の国の比較なら色分けの方が適切です。 18.5.3 複数の変数の場合 箱ひげ図はグループごとにある変数の分布を比較することもできますが、複数の変数の比較も可能です。そのためにはデータの形を変形する必要があります。たとえば、Polity IVの民主主義指標（Polity_Score）とFreedom Houseの民主主義指標（FH_Total）の分布を、大陸ごとに示したいとします。Country_dfの場合、Polity_ScoreとFH_Totalは別々の変数になっていますが、pivot_longer()を使って、これらを1つの変数にまとめる必要があります。 Democracy_df &lt;- Country_df %&gt;% select(Country, Continent, Polity_Score, FH_Total) %&gt;% filter(!is.na(Polity_Score), !is.na(FH_Total)) %&gt;% pivot_longer(cols = contains(&quot;_&quot;), names_to = &quot;Type&quot;, values_to = &quot;Value&quot;) %&gt;% mutate(Type = recode(Type, &quot;FH_Total&quot; = &quot;Freedom House&quot;, &quot;Polity_Score&quot; = &quot;Polity IV&quot;)) Democracy_df ## # A tibble: 316 × 4 ## Country Continent Type Value ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Afghanistan Asia Polity IV -1 ## 2 Afghanistan Asia Freedom House 27 ## 3 Albania Europe Polity IV 9 ## 4 Albania Europe Freedom House 67 ## 5 Algeria Africa Polity IV 2 ## 6 Algeria Africa Freedom House 34 ## 7 Angola Africa Polity IV -2 ## 8 Angola Africa Freedom House 32 ## 9 Argentina America Polity IV 9 ## 10 Argentina America Freedom House 85 ## # … with 306 more rows 続いて、箱ひげ図の作成ですが、これは次元の追加と全く同じやり方になります。fillで色分けをするか、ファセット分割をするかですね。ここでは箱の色分けをします。 Democracy_df %&gt;% ggplot() + geom_boxplot(aes(x = Continent, y = Value, fill = Type)) + labs(x = &quot;大陸&quot;, y = &quot;民主主義の程度&quot;, fill = &quot;指標&quot;) + scale_x_discrete(breaks = c(&quot;Africa&quot;, &quot;America&quot;, &quot;Asia&quot;,&quot;Europe&quot;, &quot;Oceania&quot;), labels = c(&quot;アフリカ&quot;, &quot;アメリカ&quot;, &quot;アジア&quot;, &quot;ヨーロッパ&quot;, &quot;オセアニア&quot;)) しかし、1つ問題があります。それはPolity IVは-10から10までの指標なのに対して、Freedom Houseは0から100までの指標になっている点です。この場合、正確な比較が出来ません。複数の変数を1つの箱ひげ図に出す際は、変数のスケールが一致させた方が良いでしょう。たとえば、複数の人、または団体に対する感情温度はスケールが0から100であるため、使えます。しかし、今回の場合はあまり良いケースではありません。 もし、スケールが異なるものを示すためにはスケールを調整する必要があります。よく使われるのはスケールを平均0、標準偏差1にする「標準化」ですが、変数の分布を似通ったものにするため、あまり良くないかも知れません。ここではFreedom House指標から50を引き、そこから5で割った値を使います。こうすることで、Freedom House指標が100なら10、0なら-10になり、最小値と最大値のスケールをPolity IVに合わせることが可能です。 Democracy_df &lt;- Country_df %&gt;% select(Country, Continent, Polity_Score, FH_Total) %&gt;% # FH_Totalのすケース調整 mutate(FH_Total = (FH_Total - 50) / 5) %&gt;% filter(!is.na(Polity_Score), !is.na(FH_Total)) %&gt;% pivot_longer(cols = contains(&quot;_&quot;), names_to = &quot;Type&quot;, values_to = &quot;Value&quot;) %&gt;% mutate(Type2 = recode(Type, &quot;FH_Total&quot; = &quot;Freedom House&quot;, &quot;Polity_Score&quot; = &quot;Polity IV&quot;)) Democracy_df %&gt;% ggplot() + geom_boxplot(aes(x = Continent, y = Value, fill = Type2)) + labs(x = &quot;大陸&quot;, y = &quot;民主主義の程度&quot;, fill = &quot;指標&quot;) + scale_x_discrete(breaks = c(&quot;Africa&quot;, &quot;America&quot;, &quot;Asia&quot;,&quot;Europe&quot;, &quot;Oceania&quot;), labels = c(&quot;アフリカ&quot;, &quot;アメリカ&quot;, &quot;アジア&quot;, &quot;ヨーロッパ&quot;, &quot;オセアニア&quot;)) 先よりは比較可能な図のように見えますが、あくまでも最小値と最大値を一致させたものであるため、厳密な意味ではこれもよくありません。複数の変数を1つの箱ひげ図としてまとめる場合は、スケールが一致するもののみを使うことを推奨します。 18.6 散布図 続いて、散布図の作成について解説します。散布図においてデータは点で表現され、点を表示するためには、少なくとも横軸と縦軸といった2つの情報が必要です。したがって、マッピングに使う変数は最低2つであり、横軸はx、縦軸はyで指定します。今回はCountry_dfを使って、一人当たりGDP (購買力平価基準)と人間開発指数の関係を調べてみましょう。散布図の幾何オブジェクト関数はgeom_point()です。そして、それぞれの変数はPPP_per_capita、HDI_2018であるから、マッピングはaes(x = PPP_per_capita, y = HDI_2018)になります。 Country_df %&gt;% ggplot() + geom_point(aes(x = PPP_per_capita, y = HDI_2018)) + labs(x = &quot;一人当たり購買力平価GDP (USD)&quot;, y = &quot;人間開発指数&quot;) + theme_bw() ## Warning: Removed 11 rows containing missing values (geom_point). 以下のメッセージが表示されますが、これは一人当たりGDP (購買力平価基準)または人間開発指数が欠損しているケースが11カ国あることを意味します。たとえば、教皇聖座 (Holy See; いわゆるバチカン)や西サハラ、ソマリアなどの国があります。 ## Warning: Removed 11 rows containing missing values (geom_point). どのようなケースが除外されたかはdplyr::filter()関数を使えば簡単に調べられます。 Country_df %&gt;% filter(is.na(PPP_per_capita) | is.na(HDI_2018)) %&gt;% select(Country, PPP_per_capita, HDI_2018) ## # A tibble: 11 × 3 ## Country PPP_per_capita HDI_2018 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Andorra NA 0.857 ## 2 Cuba NA 0.778 ## 3 Holy See NA NA ## 4 Kosovo 11078. NA ## 5 Liechtenstein NA 0.917 ## 6 Monaco NA NA ## 7 San Marino 62554. NA ## 8 Somalia NA 0.557 ## 9 Syria NA 0.549 ## 10 Taiwan 46145. NA ## 11 Western Sahara NA NA このように何らかのケースが除外されたとメッセージが出力された場合、ちゃんとどのケースが除外されたかを確認することは重要です。この11カ国は未承認国や国内政治の不安定によりデータが正確に把握できないところがほとんどですね。 散布図を見ると経済力と人間開発指数の間には正の関係が確認できます。ただし、経済力が高くなるにつれ、人間開発指数の増加幅は減少していきます。どちらかと言えば対数関数のような関係でしょう。実際、scale_x_log10()や、scale_x_continuous(trans = \"log10\")などで横軸を対数化するとほぼ線形の関係が観察できます。今回は座標系を変換して横軸を対数化してみます。座標系の調整はcoord_*()関数群を使いますが、対数化にはcoord_trans()を使います。ここで変換する軸と変換方法を指定します。今回は横軸を底10の対数化を行うからx = \"log10\"と指定します。これはscale_x_log10()と全く同じですが、縦軸も対数化するなどの場面においてはcoord_trans()の方が便利でしょう。 Country_df %&gt;% ggplot() + geom_point(aes(x = PPP_per_capita, y = HDI_2018)) + labs(x = &quot;一人当たり購買力平価GDP (USD)&quot;, y = &quot;人間開発指数&quot;) + coord_trans(x = &quot;log10&quot;) + theme_bw() 対数化してみたら、かなり綺麗な線形関係が確認できます。事実を言うと、そもそも人間開発指数は所得も評価項目であるため、線形関係があるのは当たり前です。 18.6.1 次元を追加する 散布図の点は横軸の数値と縦軸の数値を持っています。2次元平面で表現できる散布図は少なくとも2つの情報を持つことになります。しかし、2次元平面であっても、3つ以上の情報、つまり3次元以上の情報を示すことが可能です。たとえば、点ごとに色を変更することもできます。OECD加盟国と非加盟国に異なる色を与えると、2次元平面上であっても、3つの情報を含む散布図が作れます。他にも透明度（alpha）、点の形（shape）、大きさ（size）などで点に情報を持たせることが可能です。たとえば、国の面積に応じて点の大きさが変わる散布図を作成するならaes()内にsize = Areaを追加するだけです。面積の単位は非常に大きいので、Areaを100万で割った値を使います。また、点が大きくなると重なりやすくなるため、半透明（alpha = 0.5）にします。 Country_df %&gt;% mutate(Area2 = Area / 1000000) %&gt;% ggplot() + geom_point(aes(x = PPP_per_capita, y = HDI_2018, size = Area2), alpha = 0.5) + labs(x = &quot;一人あたり購買力平価GDP (USD)&quot;, y = &quot;人間開発指数&quot;, size = &quot;面積 (100万km2)&quot;) + theme_bw() 一人当たりGDPが非常に高い国の多くは面積が小さい国が多いですね。 以上のコードでは、aes()だけでなく、labs()内にもsize引数を指定しました。labs()内にxとy以外の引数を指定することはヒストグラムのところでもしましたが、説明はしませんでした。ここで詳しく説明します。labs()内の引数はマッピング要素と対応します。今回はgeom_point()幾何オブジェクト内にx、y、sizeがあり、それぞれにラベルを付けることになります。これを指定しない場合、変数名がデフォルト値として出力されます。xとyは縦軸と横軸のラベルですが、その他のマッピング要素は凡例として出力される場合が多いです。凡例のラベルを修正したい時にはとりあえずlabs()から覗いてみましょう。 続きまして、もう一つ次元を追加してみましょう。散布図は他のグラフに比べ次元拡張が容易なグラフです。ここでは色分けをしてみましょう。たとえば、OECD加盟有無（OECD）で色分けする場合、これまでと同様、colorをaes()内に加えるだけです。 Country_df %&gt;% mutate(Area2 = Area / 1000000) %&gt;% ggplot() + geom_point(aes(x = PPP_per_capita, y = HDI_2018, size = Area, color = OECD)) + labs(x = &quot;一人あたり購買力平価GDP (USD)&quot;, y = &quot;人間開発指数&quot;, size = &quot;面積 (100万km2)&quot;, color = &quot;OECD加盟有無&quot;) + theme_bw() 色分けはされていますが、凡例を見ると想像したものとやや違いますね。なぜならOECD変数が数値型になっているからです。実際のデータにはOECD = 0.5やOECD = 0.71のような値は存在しませんが、数値型である以上、その値をとること自体は出来ます。したがって、0から1までの数値に対応できるように、色分けもグラデーションになっています。これを見やすく二分するためには、OECD変数をfactor型か文字型に変換する必要があります。 Country_df %&gt;% mutate(Area2 = Area / 1000000, OECD2 = factor(OECD, levels = 0:1, labels = c(&quot;非加盟国&quot;, &quot;加盟国&quot;))) %&gt;% ggplot() + geom_point(aes(x = PPP_per_capita, y = HDI_2018, size = Area2, color = OECD2)) + labs(x = &quot;一人あたり購買力平価GDP (USD)&quot;, y = &quot;人間開発指数&quot;, size = &quot;面積 (100万km2)&quot;, color = &quot;OECD加盟有無&quot;) + theme_bw() これで散布図の出来上がりです。2次元座標系で表現された散布図ですが、この図から分かる情報は何があるでしょうか。 一人当たり購買力平価GDP 人間開発指数 面積 OECD加盟有無 1つの図から4つの情報が読み取れます。つまり、4次元グラフと言えます。ここにファセット分割、透明度の調整、点の形の変更まですると7次元のグラフもできます。ただし、あまりにも次元数の多いグラフは読みにくくなるため、必要だと思う変数のみマッピングしましょう。 18.6.2 一部の点をハイライトする これまでの図と比べ、散布図は一般的に表示される情報が多いです。棒グラフ、箱ひげ図の場合、数個、あるいは十数個程度の項目ごとに棒や箱が出力されますが、散布図の場合、データのサイズだけ点が出力されます。むろん、散布図というのは個々の点の情報よりも二変数間の関係を確認するために使われるため、これは短所ではありません。 しかし、散布図の中で一部の点をハイライトしたい場合もあるでしょう。たとえば、先ほどの図において日中韓だけハイライトするためにはどうすれば良いでしょうか。まず、考えられるのはcolorによるマッピングでしょう。Country変数を日本、韓国、中国、その他の4つの水準にまとめ、この値によって色分けをすればいいでしょう。実際にやってみましょう。 Country_df %&gt;% mutate(Area2 = Area / 1000000, Country2 = case_when(Country == &quot;Japan&quot; ~ &quot;Japan&quot;, Country == &quot;South Korea&quot; ~ &quot;South Korea&quot;, Country == &quot;China&quot; ~ &quot;China&quot;, TRUE ~ &quot;Other&quot;), Country2 = factor(Country2, levels = c(&quot;Japan&quot;, &quot;South Korea&quot;, &quot;China&quot;, &quot;Other&quot;), labels = c(&quot;Japan&quot;, &quot;South Korea&quot;, &quot;China&quot;, &quot;Other&quot;))) %&gt;% ggplot() + geom_point(aes(x = PPP_per_capita, y = HDI_2018, size = Area2, color = Country2)) + labs(x = &quot;一人あたり購買力平価GDP (USD)&quot;, y = &quot;人間開発指数&quot;, size = &quot;面積 (100万km2)&quot;, color = &quot;国家&quot;) + theme_bw() 日本と韓国を見つけるのは大変ですが、目的達成と言えるでしょう。ただ、もっと楽な方法があります。それが湯谷啓明さんが開発した{gghighlight}パッケージです。詳しい使い方は湯谷さんによる解説ページを参照して頂きますが、ここでは簡単な使い方のみ紹介します。まずは、install.packages(\"gghighlight\")でパッケージをインストールし、読み込みます。 pacman::p_load(gghighlight) 続いてですが、国ごとに色分けする予定ですので、散布図のcolorはCountry変数でマッピングします。そして、{gghighlight}幾何オブジェクトを追加します。まずは使い方からです。 # gghighlight()の使い方 gghighlight(条件式, label_params = list(引数1, 引数2, ...)) 第一引数は条件式であり、これはdplyr::filter()の条件式をそのまま使えます。そして、label_parmsを指定しますが、実引数はリスト型です。中にはgeom_labels()幾何オブジェクトに使用する引数が使えます。たとえば、ハイライトされた点にはラベルが付きますが、size引数を入れてラベルの大きさを指定できます。それでは実際にやってみましょう。条件式はCountry %in% c(\"Japan\", \"South Korea\", \"China\")であり、ラベルの大きさは3にします。 Country_df %&gt;% mutate(Area2 = Area / 1000000) %&gt;% ggplot() + geom_point(aes(x = PPP_per_capita, y = HDI_2018, size = Area2, color = Country)) + gghighlight(Country %in% c(&quot;Japan&quot;, &quot;South Korea&quot;, &quot;China&quot;), label_params = list(size = 3)) + labs(x = &quot;一人あたり購買力平価GDP (USD)&quot;, y = &quot;人間開発指数&quot;, size = &quot;面積 (100万km2)&quot;, color = &quot;OECD加盟有無&quot;) + theme_bw() ## label_key: Country 非常に簡単なやり方で点のハイライトが出来ました。これは後ほど紹介する折れ線グラフだけでなく、様々な幾何オブジェクトにも対応しています。湯谷さんの解説ページを参照して下さい。 18.7 折れ線グラフ 続きまして、折れ線グラフについて解説します。折れ線グラフは横軸が順序付き変数、縦軸は連続変数になります。横軸は順序付きであれば、年月日のような離散変数でも、連続変数でも構いません。注意すべき点は横軸上の値はグループ内において1回のみ登場するという点です。たとえば、株価のデータなら「2020年8月8日」はデータは1回だけ登場します。世界各国の株価データなら、グループ（国）内において「2020年8月8日」は一回のみ登場することになります。 必要なマッピング要素は線の傾きが変化しうるポイントの横軸上の位置（x）と縦軸上の位置（y）です。ここではCOVID-19の新規感染者数データを使用します。まず、Date変数が文字型になっているため、これをDate型に変換します。文字型の場合、順序関係がないからです。基本的に折れ線グラフの横軸になり得るデータ型はnumeric、順序付きfactor、Date、complex型だと考えていただいても結構です。 COVID19_df &lt;- COVID19_df %&gt;% mutate(Date = as.Date(Date)) それでは図を作成してみましょう。横軸は日付（Date）、縦軸は累積感染者数（Confirmed_Total）にしましょう。また、縦軸のスケールは底10の対数を取ります。感染者数が数百万人となるアメリカと、数万人の国が同じグラフになると、見にくくなるからです。 COVID19_df %&gt;% ggplot() + geom_line(aes(x = Date, y = Confirmed_Total)) + scale_y_continuous(breaks = c(10, 100, 1000, 10000, 100000, 1000000), labels = c(&quot;10&quot;, &quot;100&quot;, &quot;1000&quot;, &quot;10000&quot;, &quot;100000&quot;, &quot;1000000&quot;), trans = &quot;log10&quot;) + labs(x = &quot;月&quot;, y = &quot;累積感染者数 (人)&quot;) + theme_minimal() ## Warning: Transformation introduced infinite values in continuous y-axis ?????????????????? なんでしょう…。想像したものと違いますね。また、警告メッセージも出力されますが、これは0を対数化すると-Infになるから出力されるものです。大きな問題はないので、ここでは無視しましょう。 先ほど申し上げた通り、横軸の値はデータ内に1回のみ登場すべきです。しかし、COVID19_dfの場合、（たとえば）2020年5月1日の行が国の数だけあります。この場合は、ちゃんと国（Country）ごとに線を分けるように指定する必要があります。ここで使うマッピング要素がgroupです。groupで指定した変数の値ごとに異なる折れ線グラフを出力してくれます。 COVID19_df %&gt;% ggplot() + geom_line(aes(x = Date, y = Confirmed_Total, group = Country)) + scale_y_continuous(breaks = c(10, 100, 1000, 10000, 100000, 1000000), labels = c(&quot;10&quot;, &quot;100&quot;, &quot;1000&quot;, &quot;10000&quot;, &quot;100000&quot;, &quot;1000000&quot;), trans = &quot;log10&quot;) + labs(x = &quot;月&quot;, y = &quot;累積感染者数 (人)&quot;) + theme_minimal() これで折れ線グラフは出力されましたが、どの線がどの国かが分かりませんね。groupの場合、凡例が表示されないので、groupでなく、colorで色分けしてみましょう。 COVID19_df %&gt;% ggplot() + geom_line(aes(x = Date, y = Confirmed_Total, color = Country)) + scale_y_continuous(breaks = c(10, 100, 1000, 10000, 100000, 1000000), labels = c(&quot;10&quot;, &quot;100&quot;, &quot;1000&quot;, &quot;10000&quot;, &quot;100000&quot;, &quot;1000000&quot;), trans = &quot;log10&quot;) + labs(x = &quot;月&quot;, y = &quot;累積感染者数 (人)&quot;) + theme_minimal() ??????????????????? なんか出ましたが、国数が多すぎて凡例だけで図が埋め尽くされています。この場合、方法は3つあります。1つ目の方法は図のサイズを大きくする方法です。これは保存の際、サイズを再調整するだけですので、ここでは割愛します。また、それでも凡例内の項目が非常に多いグラフをグラフの種類と関係なく推奨されません。2つ目は国を絞る方法であり、3つ目はgghighlight()で一部の国のみハイライトする方法です。まずは、G7（カナダ、フランス、ドイツ、イタリア、日本、イギリス、アメリカ）のみデータを絞って折れ線グラフを作ってみましょう。 G7 &lt;- c(&quot;Cananda&quot;, &quot;France&quot;, &quot;Germany&quot;, &quot;Italy&quot;, &quot;Japan&quot;, &quot;United Kingdom&quot;, &quot;United States&quot;) COVID19_df %&gt;% filter(Country %in% G7) %&gt;% ggplot() + geom_line(aes(x = Date, y = Confirmed_Total, color = Country)) + scale_y_continuous(breaks = c(10, 100, 1000, 10000, 100000, 1000000), labels = c(&quot;10&quot;, &quot;100&quot;, &quot;1000&quot;, &quot;10000&quot;, &quot;100000&quot;, &quot;1000000&quot;), trans = &quot;log10&quot;) + labs(x = &quot;月&quot;, y = &quot;累積感染者数 (人)&quot;, color = &quot;国&quot;) + theme_minimal() これだけでもG7国のCOVID-19の状況が比較可能ですが、この図は改善の余地があります。それは凡例の順番です。できれば、一番最新の日付のデータを基準に凡例の順番を揃えることが出来たら、どの線がどの国かが分かりやすくなります。そこで登場するのは第14章で紹介しましたfct_reorder2関数です。実際にやってみましょう。 COVID19_df %&gt;% filter(Country %in% G7) %&gt;% mutate(Country = fct_reorder2(Country, Date, Confirmed_Total, last2)) %&gt;% ggplot() + geom_line(aes(x = Date, y = Confirmed_Total, color = Country)) + scale_y_continuous(breaks = c(10, 100, 1000, 10000, 100000, 1000000), labels = c(&quot;10&quot;, &quot;100&quot;, &quot;1000&quot;, &quot;10000&quot;, &quot;100000&quot;, &quot;1000000&quot;), trans = &quot;log10&quot;) + labs(x = &quot;月&quot;, y = &quot;累積感染者数 (人)&quot;, color = &quot;国&quot;) + theme_minimal() これでより読みやすい図が出来上がりました。 18.7.1 一部の線をハイライトする グループが多すぎる場合の対処法、その2つ目はデータを全て使い、一部の国のみハイライトする方法です。線のハイライトにもgghighlight()が使えます。同じく日米中韓の線のみハイライトしてみましょう。 COVID19_df %&gt;% ggplot() + geom_line(aes(x = Date, y = Confirmed_Total, color = Country)) + gghighlight(Country %in% c(&quot;Japan&quot;, &quot;China&quot;, &quot;South Korea&quot;, &quot;United States&quot;)) + scale_y_continuous(breaks = c(10, 100, 1000, 10000, 100000, 1000000), labels = c(&quot;10&quot;, &quot;100&quot;, &quot;1000&quot;, &quot;10000&quot;, &quot;100000&quot;, &quot;1000000&quot;), trans = &quot;log10&quot;) + labs(x = &quot;月&quot;, y = &quot;累積感染者数 (人)&quot;) + theme_minimal() 情報量の損失を最小化しながら、一部の国のみをハイライトすることによって世界における日米中韓のトレンドが確認出来ました。 18.8 日本語が含まれた図について (以下は作成中の内容) {ggplot2}で作成した図に日本語が含まれている場合、日本語が正しく表示されない場合があります。また、RStudioのPlotsペインには日本語が表示されていても、PDF/PNG/JPGなどのファイルとして出力した場合、表示されないケースもあります。{ggplot2}の使い方を解説する前に、ここでは日本語が正しく表示/出力されない場合の対処法について紹介します。 18.8.1 macOSの場合 今後紹介する{ggplot2}の図の最後に以下のようなレイヤーを追加すればヒラギノフォントを使用することができます。 theme(text = element_text(family = &quot;HiraginoSans-W3&quot;)) または、theme_bw()やtheme_minimal()など、特定のテーマを使用するのであればそのテーマのレイヤーにフォントを指定することもできます。たとえば、{ggplot2}のデフォルトテーマであるgrayテーマを使用するなら、{ggplot2}のオブジェクトに以下のようなレイヤーを追加する。 theme_gray(base_familiy = &quot;HiraginoSans-W3&quot;) もう一つの方法としましては、コードの最初に以下のようなコードを追加します。このコードが実行された以降の図には全てヒラギノフォントが適用されます。 theme_update(text = element_text(family = &quot;HiraginoSans-W3&quot;)) ただし、いずれの方法でも、geom_text()、geom_label()、annotate()のような文字列を出力する幾何オブジェクトを使用する際は、各レイヤーごとにフォント族を指定する必要があります (幾何オブジェクト内にfamily = \"HiraginoSans-W3\"を追加)。 作成した図ファイル (PDF) として出力 (保存) する際はquartz()関数とdev.off()関数の間に{ggplot2}で作成したオブジェクト名を入れるだけです。図でフォントが正しく指定されていれば、問題なく日本語を含まれたPDF形式の図が保存できます。 quartz(file = &quot;出力するファイル名&quot;, type = &quot;pdf&quot;, width = 幅, height = 高さ) {ggplot2}で作成した図のオブジェクト名 dev.off() PNG形式の図を保存する場合は、後述する{ragg}パッケージの仕様をおすすめします。 18.8.2 Windowsの場合 ??? 18.8.3 {ragg}の使用 {ragg}パッケージを使用すると、使用するOSと関係なくRStudioのPlotsペイン、R Markdown (HTML出力)の文字化けを回避することができます。{ragg}はインストールのみで十分であり、別途読み込む必要がないため、インストールだけします。 pacman::p_install(ragg) RStudio上の文字化けを回避するためには、RStudioの設定を以下のように変更します。 RStudioのTools&gt;Global Options… 左のGeneral&gt;右側上段のGraphicsタブ Graphic DeviceのBackendでAGGを選択 R Markdown (HTML出力)の場合、YAMLヘッダーの直後に以下のようなチャンクを追加します。チャンクのオプションとしてinclude = FALSEを指定しておけば、出力結果にコードが表示されなくなるため、指定するのを推奨します。dpiは任意の値で良いですが、PNG形式の場合、解像度が低いと見た目があまり良くないため、150以上に設定することをおすすめします。Web表示だけなら150でも良いですが、印刷を考えると300がおすすめです。 knitr::opts_chunk$set(dev = &quot;ragg_png&quot;, dpi = 300) 18.9 図の保存 綺麗な図も出来上がりましたので、みんなに自慢してみましょう。ただ、自慢のためにパソコンを持ち歩くのは大変なので、ファイルと保存してみんなに配りましょう。自慢する相手がいないならSONGに自慢しても結構です。図のフォーマットはPNGかPDFが一般的です。JPEGなど圧縮フォーマットは絶対にダメです。PNGとPDFは前者はピクセルベース、後者がベクトルベースで、PDFの方が拡大してもカクカクせず綺麗です。ただし、一部の文書作成ソフトウェアでPDFを図として扱えない点や、サイズの問題 (複雑な図になるほど、PDFの方がサイズが大きくなる)もあるので、PNGを使うケースも多いです。むろん、LaTeXで文章を作成するなら、PDF一択です。 保存方法として以下の3つを紹介します。 18.9.1 ggsave()を利用した図の保存 ggsave()が{ggplot2}が提供する図の保存関数です。まずは、使い方から紹介します。 # ggsave()を利用した保存方法 ggsave(filename = &quot;ファイル名&quot;, plot = 図のオブジェクト名, device = &quot;pdf&quot;や&quot;png&quot;など, width = 図の幅, height = 図の高さ、 units = &quot;in&quot;や&quot;cm&quot;など、幅/高さの単位, dpi = 図の解像度) deviceで指定可能なフォーマットとしては\"png\"、\"eps\"、\"ps\"、\"tex\"、\"pdf\"、\"jpeg\"、\"tiff\"、\"bmp\"、\"svg\"、\"wmf\"があります。また、unitsは\"in\" (インチ)、\"cm\"、\"mm\"が指定可能です。他にもdpi引数でdpi (dots per inch; 1平方インチにどれだけのドットの表現ができるか)の指定も可能ですが、デフォルトは300となっており、出版用としては一般的なdpiとなっています。それでは、本章の最初に作成した棒グラフをBarPlot1という名で保存し、Figsフォルダー内にBarPlot1.pngとして保存してみます。幅と高さは5インチにします。 BarPlot1 &lt;- Country_df %&gt;% ggplot() + geom_bar(aes(x = Continent)) + labs(x = &quot;大陸&quot;, y = &quot;ケース数&quot;) + theme_bw() ggsave(filename = &quot;Figs/BarPlot.png&quot;, plot = BarPlot1, device = &quot;png&quot;, width = 5, height = 5, units = &quot;in&quot;) 18.9.2 quartz()を利用した図の保存 macOSを使用し、日本語などのマルチバイトの文字が含まれる図の場合、ggsave()が正しく作動しません。この場合はquartz()とdev.off()関数を利用して図を保存します。この関数の使い方は以下の通りです。 # quartz()を利用した保存方法 quartz(type = &quot;pdf&quot;, file = &quot;ファイル名&quot;, width = 図の幅, height = 図の高さ) 作図のコード、または図オブジェクトの呼び出し dev.off() quartz()のwidthとheight引数の場合、単位はインチ (=2.54cm)です。 たとえば、最初に作成した図をFigsフォルダーのBarPlot1.pdfという名で保存し、幅と高さを5インチにするなら以下のようなコードになります。 # 方法1 quartz(type = &quot;pdf&quot;, file = &quot;Figs/BarPlot1.pdf&quot;, width = 5, height = 5) Country_df %&gt;% ggplot() + geom_bar(aes(x = Continent)) + labs(x = &quot;大陸&quot;, y = &quot;ケース数&quot;) + theme_bw() dev.off() または、予め図をオブジェクトとして保存しておいたなら (先ほどのBarPlot1オブジェクトのように)、以下のようなコードも可能です。 # 方法2 quartz(type = &quot;pdf&quot;, file = &quot;Figs/BarPlot1.pdf&quot;, width = 5, height = 5) BarPlot1 dev.off() {ragg}が導入されている状態で、図をPNG形式のファイルとして保存 (出力) したい場合は、2つの方法があります。 18.9.3 {ragg}が導入済みの場合 PNG形式限定 方法1: ragg::agg_png()を使用する。 これはragg::agg_png()関数とdev.off()関数の間に{ggplot2}で作成したオブジェクト名を入れる方法でmacOSのquartz()関数とほぼ同じ使い方です。ただし、仮引数名が異なるため、注意してください。また、dpiの仮引数は存在せず、代わりにresを使います。 ragg::agg_png(filename = &quot;出力するファイル名&quot;, res = 300, width = 幅, height = 高さ) {ggplot2}で作成した図のオブジェクト名 dev.off() 方法2: ggsave()にdevice = ragg::agg_pngを指定する。 この方法は{ggplot2}が提供するggsave()関数を使用する方法です。ここではdeviceにragg:agg_pngを指定すれば、日本語が文字化けせずPNG形式のファイルとして保存されます。 ggsave(filename = &quot;出力するファイル名&quot;, plot = 図のオブジェクト名, device = ragg::agg_png, dpi = 150, width = 幅, height = 高さ) PDFファイルとして出力したい場合は各OSごとの説明を参照してください。 18.10 まとめ 以上の話をまとめると、データが与えられた場合、ある図を作成するためには少なくとも以下の情報が必要です。 どの幾何オブジェクトを使用するか その幾何オブジェクトに必要なマッピング要素は何か 座標系や、スケール、ラベルの設定なども最終的には必要ですが、これらは設定しなくても{ggplot2}自動的に生成してくれます。しかし、幾何オブジェクトとマッピングは必須です。幾何オブジェクトはグーグルで「ggplot 棒グラフ」や「ggplot 等高線図」などで検索すれば、どのような幾何オブジェクトが必要化が分かります。問題はマッピングです。この幾何オブジェクトに使える引数は何か、そしてどの引数をaes()の中に入れるべきかなどはコンソールで?geom_barplotなどで検索すれば分かります。 筆者のオススメは以下のチートシートを印刷し、手元に置くことです。 ggplot2 cheatsheet ggplot2 aesthetics cheatsheet 2番目の資料は非常に分かりやすい資料ですが、Google Drive経由で公開されているため、いつリンクが切れかが不明です。念の為に本ページにも資料を転載します。 図 18.1: ggplot2 aesthetics cheatsheet 青い点は「ほとんど」のケースにおいてaes()の中に位置する引数です。ただし、geom_bar()とgeom_histogram()は自動的に度数を計算してくれるため、xとy一方だけでも可能です。黄色い資格はaes()の中でも、外でも使うことが可能な引数です。aes()の中ならマッピング要素となるため、データの変数と対応させる必要があります。ピンク色のひし形四角形は必ずaes()の外に位置する引数です。 練習問題 "],["visualization3.html", "19. 可視化[応用] 19.1 labs(): ラベルの修正 19.2 coord_*(): 座標系の調整 19.3 scale_*_*(): スケールの調整 19.4 theme_*()とtheme(): テーマの指定 19.5 図の結合", " 19. 可視化[応用] 第17章と第18章では{ggplot2}の概念と5つの代表的なグラフ（棒、ヒストグラム、箱ひげ図、散布図、折れ線）の作り方について説明しました。本章では軸の調整、座標系の調整など、幾何オブジェクト以外のレイヤーについて説明します。第18章で紹介しなかった図の作成方法については第20章で解説します。 ラベル 座標系 スケール テーマ 図の結合 本章で使用するデータは第18章で使用したものと同じデータを使います。データの詳細については第18章を参照してください。 pacman::p_load(tidyverse) Country_df &lt;- read_csv(&quot;Data/Countries.csv&quot;) COVID19_df &lt;- read_csv(&quot;Data/COVID19_Worldwide.csv&quot;, guess_max = 10000) 19.1 labs(): ラベルの修正 既にlabs()レイヤーは第18章で使ったことがあるでしょう。ここではlabs()の仕組みについて簡単に解説します。 labs()関数は軸、凡例、プロットのラベル（タイトルなど）を修正する際に使用する関数です。軸ラベルは横軸（x）と縦軸（y）のラベルを意味します。指定しない場合は、マッピングで指定した変数名がそのまま出力されます。これは凡例ラベルも同じです。{ggplot2}は2次元のグラフの出力に特化したパッケージであるため、出力される図には必ず横軸と縦軸があります。したがって、引数としてxとyは常に指定可能です。 一方、凡例はマッピングされない場合、表示されません。幾何オブジェクトのaes()内にcolor、size、linetypeなどの要素がマッピングされてから初めて凡例で表示されます。凡例が存在することは何かの要素にマッピングがされていることを意味します。このマッピング要素名（color、size、linetypeなど）をlabs()の引数として使うことで凡例のラベルが修正されます。マッピングされていない要素に対してラベルを指定しても、図に影響はありません。たとえば、Country_dfの一人あたりGDP（GDP_per_capita）を横軸、フリーダムハウスのスコア（FH_Total）を縦軸にした散布図を作成します。 Country_df %&gt;% ggplot() + geom_point(aes(x = FH_Total, y = GDP_per_capita)) + labs(x = &quot;フリーダムハウススコア&quot;,y = &quot;一人あたりGDP (USD)&quot;, color = &quot;大陸&quot;) + theme_bw(base_size = 12) geom_point()は横軸と縦軸のみにマッピングをしているため、labs()にcolor =を指定しても何の変化もありません。そもそも凡例が存在しないからです。それでは大陸ごとに色分けした散布図に修正してみましょう。 Country_df %&gt;% ggplot() + geom_point(aes(x = FH_Total, y = GDP_per_capita, color = Continent)) + labs(x = &quot;フリーダムハウススコア&quot;,y = &quot;一人あたりGDP (USD)&quot;, color = &quot;大陸&quot;) + theme_bw(base_size = 12) colorにContinent変数をマッピングすることによって、各点の色は何らかの情報を持つようになりました。そして各色がContinentのどの値に対応しているかを示すために凡例が表示されます。凡例のラベルはデフォルトは変数名（この例の場合、「Continent」）ですが、ここでは「大陸」と修正されました。 ここまでが第18章で使用しましたlabs()レイヤーの使い方です。他にもlabs()はプロットのラベルを指定することもできます。ここでいう「プロットのラベル」とはプロットのタイトルとほぼ同じです。使用可能な引数はtitle、subtitle、tagです。 Country_df %&gt;% ggplot() + geom_point(aes(x = FH_Total, y = GDP_per_capita, color = Continent)) + labs(x = &quot;フリーダムハウススコア&quot;,y = &quot;一人あたりGDP (USD)&quot;, color = &quot;大陸&quot;, title = &quot;民主主義の度合いと所得の関係&quot;, subtitle = &quot;大陸別の傾向&quot;, tag = &quot;(a)&quot;) + theme_bw(base_size = 12) titleは図のメインタイトルとおり、プロットのタイトルを意味します。上の図だと「民主主義の度合いと所得の関係」です。また、subtitle引数を指定することでサブタイトルを付けることも可能です。上の図の「大陸別の傾向」がサブタイトルです。最後のtagは複数の図を並べる際に便利な引数です。図が横に2つ並んでいる場合、それぞれ(a)と(b)という識別子を付けると、文中において「図3(a)は…」のように、引用しやすくなります。この「(a)」がtag引数に対応します。複数の図を並べる方法は本章の後半にて説明します。 最後にキャプションの付け方について説明します。たとえば、外部のデータを利用して作図を行った場合、図の右下に「データ出典：〜〜」や「Source: https://www.jaysong.net 」などを付ける場合があります。このキャプションはlabs()関数内にcaption引数を指定するだけで付けることができます。たとえば、先程の図に「Source: Freedom House」を付けてみましょう。 Country_df %&gt;% ggplot() + geom_point(aes(x = FH_Total, y = GDP_per_capita, color = Continent)) + labs(x = &quot;フリーダムハウススコア&quot;,y = &quot;一人あたりGDP (USD)&quot;, color = &quot;大陸&quot;, title = &quot;民主主義の度合いと所得の関係&quot;, subtitle = &quot;大陸別の傾向&quot;, tag = &quot;(a)&quot;, caption = &quot;Source: Freedom House&quot;) + theme_bw(base_size = 12) 19.2 coord_*(): 座標系の調整 {ggplot2}はいくつかの座標系を提供しています。円グラフを作成する際に使われる極座標系（coord_polar()）や地図の出力によく使われるcoord_map()やcoord_sf()がその例です。中でも最も頻繁に使われる座標系はやはり縦軸と横軸は直交する直交座標系（デカルト座標系）でしょう。ここでは直交座標系の扱い方について解説します。 19.2.1 直交座標系の操作 まずは座標系の上限と下限を指定する方法から考えましょう。日米中間のCOVID-19累積感染者数の折れ線グラフを作成してみましょう。 Fig1 &lt;- COVID19_df %&gt;% mutate(Date = as.Date(Date)) %&gt;% filter(Country %in% c(&quot;Japan&quot;, &quot;South Korea&quot;, &quot;China&quot;, &quot;United States&quot;)) %&gt;% ggplot() + geom_line(aes(x = Date, y = Confirmed_Total, color = Country)) + labs(x = &quot;月&quot;, y = &quot;累積感染者数 (人)&quot;) + theme_minimal(base_size = 12) print(Fig1) アメリカの感染者が圧倒的に多いこともあり、日韓がほぼ同じ線に見えます。これを是正するために対数変換などを行うわけですが、対数変換したグラフは直感的ではないというデメリットがあります。それでもう一つの方法として、アメリカに関する情報は一部失われますが、縦軸の上限を10万にすることが考えられます。直交座標系の上限・下限を調整する関数がcoord_cartesian()です。横軸はxlim、縦軸はylim引数を指定し、実引数としては長さ2のnumericベクトルを指定します。たとえば、縦軸の下限を0、上限を10万にするなら、ylim = c(0, 100000)となります。先ほどの図は既にFig1という名のオブジェクトとして保存されているため、ここにcoord_cartesian()レイヤーを追加してみましょう。 Fig1 + coord_cartesian(ylim = c(0, 100000)) 3月下旬以降、アメリカの情報は図から失われましたが、日中韓についてはよりトレンドの差が区別できるようになりました。{ggplot2}は座標系の上限と下限をデータの最小値と最大値に合わせて自動的に調整してくれます。たとえば、以下のような例を考えてみましょう。 Fig2 &lt;- tibble(Class = paste0(LETTERS[1:5], &quot;組&quot;), Score = c(78, 80, 85, 77, 70)) %&gt;% ggplot() + geom_bar(aes(x = Class, y = Score), stat = &quot;identity&quot;) + labs(x = &quot;クラス&quot;, y = &quot;数学成績の平均 (点)&quot;) + theme_minimal(base_size = 12) print(Fig2) 数学成績平均値は最大100点までありえますが、手元のデータにおける最高得点が85店であるため、棒グラフの縦軸の上限が85点程度となります。この場合、上限は満点である100点に調整した方が良いでしょう。 Fig2 + coord_cartesian(ylim = c(0, 100)) このように上限を調整すると、成績の満点が何点かに関する情報が含まれ、グラフにより豊富な情報を持たせることが可能です。 19.2.2 座標系の変換 続きまして座標系の変換について説明します。座標系の変換については実は第18章でも取り上げました。対数化がその例です。例えば、連続型変数でマッピングされた横軸を底が10の対数化する場合、以下のような方法が考えれます。 log10()関数を使用し、データレベルで値を対数化する scale_x_continuous()レイヤーを重ね、trans = \"log10\"引数を指定する scale_x_log10()レイヤーを重ねる coord_trans()レイヤーを重ね、x = \"log10\"引数を指定する どの方法でも得られる結果はさほど変わりませんが、coord_trans()は座標系全般を調整することができます。たとえば、xlimやylim引数を使って座標系の上限と下限を同時に指定することも可能です。たとえば、座標系の上限を横軸は[0, 100]、縦軸は[-100, 100]とし、全て対数化を行うとします。方法はいくつか考えられます。たとえば、scale_*_log10()とcoord_cartesian()を組み合わせることもできます。 # coord_trans()を使用しない場合 ggplotオブジェクト + scale_x_log10() + scale_y_log10() + coord_cartesian(xlim = c(0, 100), ylim = c(-100, 100)) しかし、上のコードはcoord_trans()を使うと一行にまとめることができます。 # coord_trans()を使用する場合 ggplotオブジェクト + coord_trans(x = &quot;log10&quot;, y = &quot;log10&quot;, xlim = c(0, 100), ylim = c(-100, 100)) coord_trans()のx、y引数は\"log10\"以外にもあります。自然対数変換の\"log\"、反転を意味する\"reverse\"、平方根へ変換する\"sqrt\"などがあります。グラフを上下、または左右に反転する\"reverse\"は覚えておいて損はないでしょう。こちらは具体的には{tidyverse}パッケージ群に含まれている{scales}パッケージにある*_trans()関数に対応することになります。詳細は{scales}パッケージのヘルプを参照してください。 19.2.3 座標系の回転 続きまして座標系を反時計方向回転するcoord_flip()について紹介します。以下はCountry_dfを用い、大陸（Continent）ごとにPolity IVスコア（Polity_Score）の平均値を示した棒グラフです。 Flip_Fig &lt;- Country_df %&gt;% group_by(Continent) %&gt;% summarise(Democracy = mean(Polity_Score, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;% ggplot() + geom_bar(aes(x = Continent, y = Democracy), stat = &quot;identity&quot;) + labs(x = &quot;大陸&quot;, y = &quot;Polity IV スコアの平均値&quot;) + theme_minimal(base_size = 12) print(Flip_Fig) この図を反時計方向回転する場合は以上のプロットにcoord_flip()レイヤーを追加します。 Flip_Fig + coord_flip() # 座標系の回転 非常に簡単な方法で図を回転させることができました。しかし、実はこのcoord_flip()関数、最近になって使う場面がどんどん減っています。たとえば、先ほどのgeom_bar()幾何オブジェクトの場合、xをPolity IVスコアの平均値で、yを大陸名でマッピングすることが可能です。昔の{ggplot2}は横軸と縦軸にマッピングでいるデータ型が厳格に決まっていましたが、最近になってはますます柔軟となってきました86。coord_flip()を使用する前に、各幾何オブジェクトのヘルプを確認し、coord_flip()を用いた回転が必要か否かを予め調べておくのも良いでしょう。 19.2.4 座標系のアスペクト比の固定 他にも地味に便利な機能として座標系比を固定するcoord_fixed()を紹介します。これは出力される座標系の「横:縦」を調整するレイヤーです。たとえば、以下のような散布図を考えてみましょう。 ggplot() + geom_point(aes(x = 1:10, y = 1:10)) こちらは横と縦が同じスケールでありますが、図の大きさに応じて、見た目が変わってきます。たとえば、上の図だと、横軸における1間隔は縦軸のそれの約2倍です。もし、図を上下に大きくし、左右を縮小したら同じ図でありながら随分と見た目が変わってきます。 ggplot() + geom_point(aes(x = 1:10, y = 1:10)) 2つの図は本質的に同じですが、図の見せ方によって、傾きが緩やかに見せたり、急に見せたりすることができます。ここで活躍するレイヤーがcoord_fixed()です。これを追加すると横を1とした場合の縦の比率を指定することができます。 ggplot() + geom_point(aes(x = 1:10, y = 1:10)) + coord_fixed(ratio = 1) ratio = 1を指定すると縦横比は1:1となり、図の高さや幅を変更してもこの軸は変わりません。たとえば、RStudioのPlotsペインの大きさを変更すると図の大きさが変わりますが、coord_fixed(ratio = 1)を指定すると1:1の比率は維持されるまま図が拡大・縮小されます。直接やってみましょう。 19.3 scale_*_*(): スケールの調整 続いてscale_*_*()関数群を用いたスケールを解説しますが、こちらの関数は非常に多く、全てのスケールレイヤーについて解説すことは難しいです。しかし、共通する部分も非常に多いです。本説ではこの共通項に注目します。 連続変数でマッピングされた横軸のスケールを調整する関数ははscale_x_continuous()です。ここでxが横軸を意味し、continuousが連続であることを意味します。このxの箇所は幾何オブジェクトのaes()内で指定した仮引数と一致します。つまり、scale_x_continuous()のxの箇所にはy、alpha、linetype、sizeなどがあります。そして、実引数として与えられた変数のデータ型がcontinuousの箇所に相当します。もし、離散変数ならdiscrete、時系列ならtime、全て手動で調整する場合はmanualを使います。他にも2020年10月現在、最近追加されたものとしてbinnedがあり、こちらはヒストグラムに特化したものです（scale_x_binned()とscale_y_binned()）。つまり、スケール調整関数はaes()内に登場した仮引数名とそのデータ型の組み合わせで出来ています。 たとえば、時系列の折れ線グラフにおいて横軸のスケールを調整するなら、sacle_x_time()を使います。また、棒グラフのように横軸が名目変数ならscale_x_manual()、順序変数のような離散変数ならscale_x_discrete()を使います。また、連続変数の縦軸のスケール調整ならscale_y_continuous()を使います。グラフによってはaes()内にxまたはyを指定しないケースもあります。前章において度数の棒グラフや1つの箱ひげ図を出す場合、前者はx、後者はyのみを指定しました。これは指定されていないyやxが存在しないことを意味しません。{ggplot2}が自動的に計算しマッピングを行ってくれることを意味します。{ggplot2}で出来上がった図は2次元座標系を持つため、横軸と縦軸は必ず存在します。したがって、aes()内の引数と関係なくscale_x_*()とscale_y_*()関数群は使用することが出来ます。 19.3.1 横軸・縦軸スケールの調整 軸のスケールを調整する目的は1) 目盛りの調整、2) 目盛りラベルの調整、3) 第2軸の追加などがありますが、主な目的は1と2です。第2軸の追加はスケールが異なるグラフが重なる場合に使用しますが、一般的に推奨されません。したがって、ここでは1と2について説明します。 19.3.1.1 連続変数の場合 軸に連続変数がマッピングされている場合はscale_*_continuous()レイヤーを追加します。*の箇所は横軸の場合はx、縦軸の場合はyとなります。それではCountry_dfのFH_Totalを横軸、GDP_per_capitaを縦軸にした散布図を作成し、Scale_Fig1という名のオブジェクトに格納します。 Scale_Fig1 &lt;- Country_df %&gt;% ggplot() + geom_point(aes(x = FH_Total, y = GDP_per_capita)) + labs(x = &quot;フリーダムハウススコア&quot;,y = &quot;一人あたりGDP (USD)&quot;) + theme_bw(base_size = 12) print(Scale_Fig1) Scale_Fig1の横軸の場合、最小値0、最大値100であり、目盛りは25間隔となっております。ここではこの横軸を調整したいと思います。まず、プロットにおける最小値と最大値はスケールではなく座標系の問題ですので、coord_*()を使用します。ここでは目盛りを修正してみましょう。たとえば、目盛りを10間隔にし、そのラベルも0、10、20、…、100にします。FH_Totalは連続変数ですので、scale_x_continuous()を使います。使い方は以下の通りです。 Scale_Fig1 + scale_x_continuous(breaks = 目盛りの位置, labels = 目盛りのラベル) breaksとlabelsの実引数としては数値型ベクトルを指定します。0から100まで10刻みの目盛りとラベルなら、seq(0, 100, by = 10)、またはc(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100)と指定します。 Scale_Fig1 + scale_x_continuous(breaks = seq(0, 100, by = 10), labels = seq(0, 100, by = 10)) 目盛りのラベルを文字型にすることも可能です。例えば、目盛りを0、50、100にし、それぞれ「最低」、「中間」、「最高」としたい場合は以下のようにします。 Scale_Fig1 + scale_x_continuous(breaks = c(0, 50, 100), labels = c(&quot;最低&quot;, &quot;中間&quot;, &quot;最高&quot;)) scale_x_continuous()は目盛りの調整が主な使い道ですが、他にも様々な機能を提供しています。たとえば、座標系の最小値と最大値の指定はcoord_*()を使うと説明しましたが、実はscale_*_continuous()でもlimits引数で指定することも可能です。たとえば、縦軸の範囲を0ドルから10万ドルにしたい場合はscale_y_continuous()の中にlimits = c(0, 100000)を指定します。 Scale_Fig1 + scale_x_continuous(breaks = seq(0, 100, by = 10), labels = seq(0, 100, by = 10)) + scale_y_continuous(limits = c(0, 100000)) 他にも目盛りと目盛りラベルの位置を変更することも可能です。これはposition引数を使います。基本的に横軸の目盛りは下（\"bottom\"）、縦軸は左（\"left\"）ですが、\"top\"や\"right\"を使うことも可能です。もし、縦軸の目盛りとラベル、軸のラベルを右側にしたい場合はscale_y_continuous()の中にposition = \"right\"を指定します。 Scale_Fig1 + scale_y_continuous(position = &quot;right&quot;) 19.3.1.2 離散変数の場合 もし、軸が名目変数や順序変数のような離散変数でマッピングされている場合は、scale_*_discrete()を使います。たとえば、座標系の回転の例で使いましたFlip_Figの場合、横軸の大陸名が英語のままになっています。これを日本語にする場合、データレベルで大陸名を日本語で置換することも可能ですが、scale_x_discrete()を使うことも可能です。使い方はscale_*_continuous()と同じであり、breaksとlabels引数を指定するだけです。 Flip_Fig + scale_x_discrete(breaks = c(&quot;Africa&quot;, &quot;America&quot;, &quot;Asia&quot;, &quot;Europe&quot;, &quot;Oceania&quot;), labels = c(&quot;アフリカ&quot;, &quot;アメリカ&quot;, &quot;アジア&quot;, &quot;ヨーロッパ&quot;, &quot;オセアニア&quot;)) 今回は大陸名が文字型の列でしたが、factor型の場合、いくつか便利な機能が使えます。たとえば、Polity_Typeごとに国数を計算し、棒グラフを作成するとします。 Scale_df1 &lt;- Country_df %&gt;% group_by(Polity_Type) %&gt;% summarise(N = n(), .groups = &quot;drop&quot;) Scale_df1 ## # A tibble: 6 × 2 ## Polity_Type N ## &lt;chr&gt; &lt;int&gt; ## 1 Autocracy 19 ## 2 Closed Anocracy 23 ## 3 Democracy 65 ## 4 Full Democracy 31 ## 5 Open Anocracy 20 ## 6 &lt;NA&gt; 28 続きまして、Polity_Type列をfactor型にします。最もスコアの低い独裁（Autocracy）から最もスコアの高い完全な民主主義（Full Democracy）の順番のfactorにします。 Scale_df1 &lt;- Scale_df1 %&gt;% mutate(Polity_Type = factor(Polity_Type, ordered = TRUE, levels = c(&quot;Autocracy&quot;, &quot;Closed Anocracy&quot;, &quot;Open Anocracy&quot;, &quot;Democracy&quot;, &quot;Full Democracy&quot;))) Scale_df1$Polity_Type ## [1] Autocracy Closed Anocracy Democracy Full Democracy ## [5] Open Anocracy &lt;NA&gt; ## 5 Levels: Autocracy &lt; Closed Anocracy &lt; Open Anocracy &lt; ... &lt; Full Democracy 問題なくfactor化も出来たので、それでは作図をしてみましょう。 Scale_df1 %&gt;% ggplot() + geom_bar(aes(x = Polity_Type, y = N), stat = &quot;identity&quot;) Polityプロジェクトの対象外があり、この場合は欠損値（NA）になります。そして、問題はこの欠損値も表示されることです。むろん、欠損値のカテゴリも出力したいケースもありますが、もし欠損値カテゴリの棒を消すにはどうすれば良いでしょうか。1つ目の方法はScale_df1 %&gt;% drop_na()で欠損値を含む行を除去してから作図する方法です。2つ目の方法はscale_x_discrete()でna.translate = FALSEを指定する方法です。ここでは横軸の目盛りラベルも日本語に変更し、欠損値のカテゴリを除外してみましょう。また、地味に便利な機能として、軸ラベルもscale_*_*()で指定可能です。第1引数として長さ1の文字ベクトルを指定すると、自動的に軸ラベルが修正され、labs()が不要となります。 Scale_df1 %&gt;% ggplot() + geom_bar(aes(x = Polity_Type, y = N), stat = &quot;identity&quot;) + scale_x_discrete(&quot;Polity IV スコア&quot;, # 第1引数で軸ラベルも指定可能 breaks = c(&quot;Autocracy&quot;, &quot;Closed Anocracy&quot;, &quot;Open Anocracy&quot;, &quot;Democracy&quot;, &quot;Full Democracy&quot;), labels = c(&quot;独裁&quot;, &quot;閉じられたアノクラシー&quot;, &quot;開かれたアノクラシー&quot;, &quot;民主主義&quot;, &quot;完全な民主主義&quot;), na.translate = FALSE) + scale_y_continuous(&quot;国数&quot;) + theme_minimal(base_size = 12) これで欠損値を除外することができました。目盛りラベルが重なる箇所があり、多少気になりますが、この問題に関しては第19.4節で取り上げます。 19.3.2 colorスケールの調整 グラフの次元を増やす際において広く使われている方法は変数の値に応じて色分けをすることでした。この場合、幾何オブジェクトのaes()内にcolor = マッピングする変数名を指定することになります。このように色が変数でマッピングされている場合は、色分けのスケールも調整可能です。たとえば、折れ線グラフにおいて日本が赤い線だったのを青い線に変更することが考えられます。ここでもcolorにマッピングされている変数のデータ型によって使用する関数が変わります。ここでは連続変数、順序付き離散変数、順序なし離散変数について説明します。 19.3.2.1 color引数が連続変数でマッピングされている場合 まずは、連続変数からです。横軸は底10の対数変換した一人あたりGDP（GDP_per_capita）、縦軸は人間開発指数（HDI_2018）にした散布図を作成し、Polity IVスコア（Polity_Score）で点の色分けをしてみましょう。 Scale_Fig2 &lt;- Country_df %&gt;% ggplot() + geom_point(aes(x = GDP_per_capita, y = HDI_2018, color = Polity_Score)) + labs(x = &quot;一人あたりGDP (USD)&quot;,y = &quot;人間開発指数&quot;, color = &quot;Polity IVスコア&quot;) + scale_x_log10() + theme_bw(base_size = 12) Scale_Fig2 これまではcolor引数を離散変数でしかマッピングしませんでしたが、このように連続変数でマッピングすることも可能です。ただし、この場合は値に応じてはっきりした色分けがされるのではなく、グラデーションで色分けされます。この例だと、青に近いほどPolity IVスコアが高く、黒に近いほど低いことが分かります。この場合、colorのスケール調整は最小値と最大値における色を指定するだけです。その間の色については{ggplot2}が自動的に計算してくれます。 今回使用する関数はscale_color_gradient()です。これまでの例だとscale_color_continuous()かと思う方も多いでしょう。実際、scale_color_continuous()関数も提供されており、使い方もほぼ同じです。ただし、scale_color_continuous()を使う際は引数としてtype = \"gradient\"を指定する必要があります。scale_color_gradient()の場合、最小値における色をlow、最大値のそれをhighで指定します。数値は\"red\"や\"blue\"なども可能であり、\"#132B43\"のような書き方も使えます。たとえば、先ほどのScale_Fig2においてPolity IVスコアが高いほどbrown3、低いほどcornflowerblueになるようにする場合は以下のように書きます。 Scale_Fig2 + scale_color_gradient(high = &quot;brown3&quot;, low = &quot;cornflowerblue&quot;) このような書き方だとどのような色名で使えるかを事前に知っておく必要があります。使える色名のリストはcolors()から確認できます。全部で657種類がありますが、ここでは最初の50個のみを出力します。 head(colors(), 50) ## [1] &quot;white&quot; &quot;aliceblue&quot; &quot;antiquewhite&quot; &quot;antiquewhite1&quot; ## [5] &quot;antiquewhite2&quot; &quot;antiquewhite3&quot; &quot;antiquewhite4&quot; &quot;aquamarine&quot; ## [9] &quot;aquamarine1&quot; &quot;aquamarine2&quot; &quot;aquamarine3&quot; &quot;aquamarine4&quot; ## [13] &quot;azure&quot; &quot;azure1&quot; &quot;azure2&quot; &quot;azure3&quot; ## [17] &quot;azure4&quot; &quot;beige&quot; &quot;bisque&quot; &quot;bisque1&quot; ## [21] &quot;bisque2&quot; &quot;bisque3&quot; &quot;bisque4&quot; &quot;black&quot; ## [25] &quot;blanchedalmond&quot; &quot;blue&quot; &quot;blue1&quot; &quot;blue2&quot; ## [29] &quot;blue3&quot; &quot;blue4&quot; &quot;blueviolet&quot; &quot;brown&quot; ## [33] &quot;brown1&quot; &quot;brown2&quot; &quot;brown3&quot; &quot;brown4&quot; ## [37] &quot;burlywood&quot; &quot;burlywood1&quot; &quot;burlywood2&quot; &quot;burlywood3&quot; ## [41] &quot;burlywood4&quot; &quot;cadetblue&quot; &quot;cadetblue1&quot; &quot;cadetblue2&quot; ## [45] &quot;cadetblue3&quot; &quot;cadetblue4&quot; &quot;chartreuse&quot; &quot;chartreuse1&quot; ## [49] &quot;chartreuse2&quot; &quot;chartreuse3&quot; scale_color_gradient()から派生した関数としてscale_color_gradient2()というものもあります。これは最小値と最大値だけでなく、mid引数を使って中間における色も指定可能な関数です。例えば、先ほどの例で真ん中をseagreenにしてみましょう。 Scale_Fig2 + scale_color_gradient2(high = &quot;brown3&quot;, mid = &quot;seagreen&quot;, low = &quot;cornflowerblue&quot;) 色は\"seagreen\"、\"red\"でなく、\"#00AC97\"、\"#FF0000\"のように具体的なRGB値で指定することもできます。これは色を赤（R）、緑（G）、青（B）の3つの原色を混ぜて様々な色を表現する方法です。\"#FF0000\"の場合、最初の#はRGB表記であることを意味し、FFは赤が255であることの16進法表記、次の00と最後の00は緑と青が0であることの16進法表記です。各原色は0から255までの値を取ります。{ggplot2}でよく見る色としては#F8766D、#00BFC4、#C77CFF、#7CAE00があります。他にもGoogleなどで「RGB color list」などを検索すれば様々な色を見ることができます。 他にも{ggplot2}は様々なユーザー指定のパレットが使用可能であり、実際、パッケージの形式として提供される場合もあります。たとえば、ジブリ風のカラーパレットが{ghibli}パッケージとして提供されており、install.packages(\"ghibli\")でインストール可能です。 pacman::p_load(ghibli) Scale_Fig2 + # 連続変数（_c）用の「もののけ姫」パレット（medium） scale_color_ghibli_c(&quot;MononokeMedium&quot;) 19.3.2.2 color引数が順序付き離散変数でマッピングされている場合 連続変数のようにグラデーションではあるものの、それぞれの値に対して具体的な色が指定されます。まずは先ほど作成しましたScale_Fig2の色分けを連続変数であるPolity_Scoreでなく、順序付き離散変数であるPolity_Typeにします。Polity_Typeの順序は独裁（Autocracy）、閉じられたアノクラシー（Closed Anocracy）、開かれたアノクラシー（Open Anocracy）、民主主義（Democracy）、完全な民主主義（Full Democracy）にします。また、Polity_Typeが定義されていない国もデータセットに含まれているため、drop_na(Polity_Type)を追加し、Polity_Typeが欠損している行を除去します。 Scale_Fig3 &lt;- Country_df %&gt;% mutate(Polity_Type = factor(Polity_Type, ordered = TRUE, levels = c(&quot;Autocracy&quot;, &quot;Closed Anocracy&quot;, &quot;Open Anocracy&quot;, &quot;Democracy&quot;, &quot;Full Democracy&quot;))) %&gt;% drop_na(Polity_Type) %&gt;% ggplot() + geom_point(aes(x = GDP_per_capita, y = HDI_2018, color = Polity_Type)) + labs(x = &quot;一人あたりGDP (USD)&quot;,y = &quot;人間開発指数&quot;, color = &quot;Polity IVタイプ&quot;) + scale_x_log10() + theme_bw(base_size = 12) Scale_Fig3 今回は紫（独裁）から黄色（完全な民主主義）の順で色分けがされ、その間のカテゴリーも紫と黄色の間の値をとります。実は順序付き離散変数の場合、色のスケールを調整することはあまりありませんし、これまでの方法に比べてやや複雑です。ここでは色相（Hue）の範囲と強度、明るさを調整する方法について紹介します。 まずは、色相について知る必要があります。{ggplot2}において色相の範囲は0から360です。そして、色には強度（intensity）、または彩度という概念があり、0に近いほどグレイへ近づき、色間の区別がしにくくなります。{ggplot2}では彩度のデフォルト値は100であり、我々が普段{ggplot2}で見る図の色です。最後に明るさ（luminance）があり、0から100までの値を取ります。値が大きいほど明るくなり、{ggplot2}のデフォルト値は65です。重要なのは色相のところであり、Hueの具体的な数値がどの色なのかを確認する必要があります。そのためには、{scales}パッケージのhue_pal()とshow_col()関数を使用します。 左上が0、右下が360の色を意味します。順序変数でマッピングされた色スケールを色相に基づいて調整する際は、scale_color_hue()レイヤーを追加し、色相の範囲、彩度、明るさを指定します。たとえば、0から300までの範囲の色を使用し87、再度と明るさはデフォルトにしたい場合、以下のように書きます。 Scale_Fig3 + scale_color_hue(h = c(0, 360), c = 100, l = 65) また、direction = -1を追加することで、色の順番を逆にすることも可能です。 Scale_Fig3 + scale_color_hue(h = c(0, 360), c = 100, l = 65, direction = -1) 他にもmpl colormapsというカラーマップを使うことも可能です。この場合はscale_color_hue()ではなく、scale_color_viridis_d()を使用します。具体的な色の情報はmpl colormapsを参照してください。必要な引数は色のスタート地点（begin）と終了地点（end）です。そして、optionの引数のデフォルト値は\"D\"であり、これはVIRIDIS colormapを意味します。実はscale_color_*()を付けなかった場合の色分けがこれです。たとえば、VIRIDIS colormapでなく、PLASMA colormapを使うならoption = \"C\"を付けます。 Scale_Fig3 + # PLASMA colormapを使用する（option = &quot;C&quot;） scale_color_viridis_d(begin = 0, end = 1, option = &quot;C&quot;) 19.3.2.3 color引数が順序なし離散変数でマッピングされている場合 最後に順序なし離散変数の場合について解説します。ここではscale_color_manual()関数を使用し、マッピングされている変数のそれぞれ値に対して具体的な色を指定する方法です。以下で説明する方法は、順序付き離散変数でも使用可能であるため、Scale_Fig3の図をそのまま利用してみたいと思います。 scale_color_manual()の核心となる引数はvaluesであり、ここに\"変数の値\" = \"色\"で指定します。この色は\"red\"のような具体的な色名でも、\"#FF0000\"のようなRGB表記でも構いません。 ggplot2オブジェクト + scale_color_manual(values = c(&quot;変数の値1&quot; = &quot;色1&quot;, &quot;変数の値2&quot; = &quot;色2&quot;, &quot;変数の値3&quot; = &quot;色3&quot;, ...)) それではPolity_Typeの値が\"Autocracy\"の場合はdarkred、\"Closed Anocracy\"はseagreen、\"Open Anocracy\"はcornflowerblue、\"Democracy\"はorchid、\"Full Democracy\"はorangeにしてみましょう。 Scale_Fig3 + scale_color_manual(values = c(&quot;Autocracy&quot; = &quot;darkred&quot;, &quot;Closed Anocracy&quot; = &quot;seagreen&quot;, &quot;Open Anocracy&quot; = &quot;cornflowerblue&quot;, &quot;Democracy&quot; = &quot;orchid&quot;, &quot;Full Democracy&quot; = &quot;orange&quot;)) 色を決める際は色覚多様性に気をつけるべきです。誰にとっても見やすい図にはUniversal Designが必要です。特によくある例が「緑と赤」の組み合わせです。緑も赤も暖色系であり、P型およびD型色弱の場合、両者の区別が難しいと言われています。しかも、色弱の方は意外と多いです。日本の場合、男性の5%、女性の0.2%と言われております。これには人種差もありまして、フランスや北欧の男性の場合は約10%です。一通り図を作成しましたら、色覚シミュレーターなどを使用して、誰にとっても見やすい色であるかを確認することも良いでしょう。また、{ggplot2}がデフォルトで採用しているVIRIDISは色弱に優しいカラーパレットと言われています。一般的に二色の組み合わせの場合、最も区別しやすい色は青とオレンジと言われいます。 {ggplot2}におけるcolorスケールは非常に細かく調整可能であり、関連関数やパッケージも多く提供されています。本書では全てを紹介することはできませんが、ここまで紹介してきました例だけでも、自分好みに色を調整できるでしょう。 19.3.3 alphaスケールの調整 次は点・線・面の透明度を指定するalphaスケールの調整です。もし、alphaに連続変数をマッピングすれば、マッピングした変数の値に応じて透明度が変わります。一般的に、値が大きいほど不透明となり、小さいほど透明になります。しかし、このような使い方はあまり見られません。プロット上のオブジェクトを透明度を指定するのは 特定箇所にオブジェクトが密集し、重なるオブジェクトの区別がつきにくい場合 特定の点・線・面を強調するため 以上の2ケースでしょう。また、ケース1の場合、alpha引数をaes()の内部ではなく、外側に指定し、具体的な数値を指定することになります。ここで注目するのはケース2です。たとえば、横軸に一人あたりGDP、縦軸に人間開発指数をマッピングした散布図を作成し、アジアの国のみハイライトしたいとします。この場合、アジアとその他の国で色分けしたり、丸と四角といった形で分けるのも可能ですが、「強調」が目的であれば、その他の国をやや透明にすることも可能でしょう。まず、Asiaという変数を作成し、Continentの値が\"Asia\"なら\"Asia\"、その他の値なら\"Other\"の値を入れます。そして、geom_point()のaes()内にalpha引数を追加し、Asia変数でマッピングします。 Country_df %&gt;% mutate(Asia = if_else(Continent == &quot;Asia&quot;, &quot;Asia&quot;, &quot;Other&quot;)) %&gt;% ggplot() + geom_point(aes(x = GDP_per_capita, y = HDI_2018, alpha = Asia), size = 2) + labs(x = &quot;一人あたりGDP (USD)&quot;,y = &quot;人間開発指数&quot;, alpha = &quot;大陸&quot;) + scale_x_log10() + theme_bw(base_size = 12) Asiaの値によって透明度が異なりますが、私たちの目的はAsiaを不透明にし、その他の点を透明にすることです。ここで登場するのがscale_alpha_manual()です。使い方はこれまで見てきたscale_*_manual()と非常に似ています。values引数にそれぞれの値と透明度を指定するだけです。透明度は1が不透明、0が透明です。アジアの透明度を1.0、その他の透明度を0.15とするなら、以下のように書きます。 Country_df %&gt;% mutate(Asia = if_else(Continent == &quot;Asia&quot;, &quot;Asia&quot;, &quot;Other&quot;)) %&gt;% ggplot() + geom_point(aes(x = GDP_per_capita, y = HDI_2018, alpha = Asia), size = 2) + labs(x = &quot;一人あたりGDP (USD)&quot;,y = &quot;人間開発指数&quot;, alpha = &quot;大陸&quot;) + scale_x_log10() + scale_alpha_manual(values = c(&quot;Asia&quot; = 1.0, &quot;Other&quot; = 0.15)) + theme_bw(base_size = 12) これでアジアの国々がプロット上で強調されました。透明度スケールは連続変数（scale_alpha_continuous()）や離散変数（scale_alpha_discrete()）に使うことも可能ですが、透明度を「区別」でなく「強調」の目的で使うならば、scale_alpha_manual()でも十分だと考えられます。 一つ注意して頂きたいのは、図をPDFで出力する際、半透明なオブジェクトが見えなかったり、逆に透明度が全く適用されない場合があります。PNGなどのビットマップ画像ならこのような問題は生じませんが、PDFの場合は注意が必要です88。この場合、画像をPNGなどの形式にするか、半透明でなく「グレーと黒」のような組み合わせで作図した方が良いかも知れません。 19.3.4 sizeスケールの調整 大きさに関するマッピングは幾何オブジェクトのaes()内にsize引数を使用します。ここでの大きさというのは点の大きさと線の太さを意味します。geom_point()内のsizeは点の大きさ、geom_line()やgeom_segment()のsizeは線の太さ、geom_pointrange()では両方を意味します。ただし、実質的に変数の値に応じて線の太さを変えることは強調89を除けばあまり見られません。ここでは点の大きさに焦点を当てて解説します。 それでは、横軸はフリーダム・ハウスのスコア（FH_Total）、縦軸は2018年人間開発指数（HDI_2018）として散布図を作成し、一人当たり購買力平価GDP（PPP_per_capita）に応じて点の大きさを指定します。 Country_df %&gt;% ggplot() + geom_point(aes(x = FH_Total, y = HDI_2018, size = PPP_per_capita)) + labs(x = &quot;フリーダムハウススコア&quot;,y = &quot;2018年人間開発指数&quot;, size = &quot;一人あたり購買力平価GDP（USD）&quot;) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) # 凡例の図の下段にする フリーダム・ハウススコアと人間開発指数は全般的には正の相関を示しています。そして、両指標が高い国（図の右上）は所得水準も高いことが分かります。ただし、フリーダム・ハウススコアが低くても人間開発指数が高い国（図の左上）もかなり見られますが、これらの国の共通点は所得水準が高いことです。つまり、人間開発指数と所得水準には強い相関関係があると考えられます（人間開発指数には所得水準も含まれるため、当たり前です）。 大きさをマッピングすると、点が重なる箇所が広くなりますので、alpha引数で半透明にすることも有効でしょう。 Country_df %&gt;% ggplot() + geom_point(aes(x = FH_Total, y = HDI_2018, size = PPP_per_capita), alpha = 0.5) + # 透明度の指定 labs(x = &quot;フリーダムハウススコア&quot;,y = &quot;2018年人間開発指数&quot;, size = &quot;一人あたり購買力平価GDP（USD）&quot;) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) この大きさのスケール調整はマッピングされた変数の尺度によって、scale_size_continuous()、sclae_size_discrete()、scale_size_ordinal()などを使用し、すべてマニュアルで調整したい場合はscale_size_manual()を使います。使い方はこれまでのスケール調整とほぼ同様です。たとえば、上記の図だと、大きさの凡例が3万、6万、9万となっていますが、これを1000, 10000, 100000といった対数スケールに変更してみましょう。 Country_df %&gt;% ggplot() + geom_point(aes(x = FH_Total, y = HDI_2018, size = PPP_per_capita), alpha = 0.5) + labs(x = &quot;フリーダムハウススコア&quot;,y = &quot;2018年人間開発指数&quot;, size = &quot;一人あたり購買力平価GDP（USD）&quot;) + scale_size_continuous(breaks = c(1000, 10000, 100000), labels = c(&quot;1000&quot;, &quot;10000&quot;, &quot;100000&quot;)) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) この場合、図内の点の大きさに変化はありません。変わるのは凡例のみであり、値に応じた点のサイズに調整されます。連続変数でマッピングされている場合、一つ一つの値に応じてサイズを指定するのは非現実的であります。この場合、点の大きさ調整は{ggplot2}に任せて、凡例のサイズを調整するのが無難でしょう。 ただし、点の最小サイズと最大サイズを調整したいケースもあるでしょう。最も小さい点のサイズを0.1に、最も大きい点のサイズを10にする場合、range引数を指定します。range引数の実引数は長さ2の数値型ベクトルです。 Country_df %&gt;% ggplot() + geom_point(aes(x = FH_Total, y = HDI_2018, size = PPP_per_capita), alpha = 0.5) + labs(x = &quot;フリーダムハウススコア&quot;,y = &quot;2018年人間開発指数&quot;, size = &quot;一人あたり購買力平価GDP（USD）&quot;) + scale_size_continuous(breaks = c(1000, 10000, 100000), labels = c(&quot;1000&quot;, &quot;10000&quot;, &quot;100000&quot;), range = c(0.1, 10)) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) このように範囲が広がるほど、所得水準の差がより見やすくなります。他にもsizeは離散変数でマッピングさることも可能ですが、あまり相性は良くありません。離散変数でのマッピングはこれまで紹介しましたcolorやsizeの方を参照してください。使い方は同じです。 19.3.5 shape、linetypeスケールの調整 sizeは連続変数と相性が良いですが、点や線の形であるshapeとlinetypeは離散変数、とりわけ順序なし離散変数（名目変数）と相性が良いです。なぜなら、点や線の形は高低・大小の情報を持たないからです。たとえば、丸の点は四角の点より大きいとか実線は破線より小さいといった情報はありません。したがって、sizeやlinetypeは名目変数に使うのが一般的です。たとえば、フリーダムハウスのスコアを横軸、人間開発指数を縦軸とし、G20加盟有無によって点の形が異なる散布図を作成するとします。G20をcharacter型、あるいはfactor型に変換し、geom_point()の幾何オブジェクトのaes()内にshape引数を指定します。 Country_df %&gt;% mutate(G20 = if_else(G20 == 1, &quot;加盟国&quot;, &quot;非加盟国&quot;)) %&gt;% ggplot() + geom_point(aes(x = FH_Total, y = HDI_2018, shape = G20), size = 2) + labs(x = &quot;フリーダムハウススコア&quot;,y = &quot;2018年人間開発指数&quot;, shape = &quot;G20&quot;) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) 加盟国を丸（16または19）、非加盟国をダイヤモンド型（18）にするにはscale_shape_manual()を使います。 Country_df %&gt;% mutate(G20 = if_else(G20 == 1, &quot;加盟国&quot;, &quot;非加盟国&quot;)) %&gt;% ggplot() + geom_point(aes(x = FH_Total, y = HDI_2018, shape = G20), size = 2) + scale_shape_manual(values = c(&quot;加盟国&quot; = 19, &quot;非加盟国&quot; = 18)) + labs(x = &quot;フリーダムハウススコア&quot;,y = &quot;2018年人間開発指数&quot;, shape = &quot;G20&quot;) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) ただし、各数字がどの形に対応しているかを事前に知っておく必要があります。よく使うのは0から25までであり、それぞれ対応するshapeを示したのが以下の図です。必要に応じてこのページを参照しても良いですし、Rコンソール上で?pchを入力しても0から23までの例を見ることが出来ます。 注意していただきたいのは、shapeのマッピングが有効でない状況があるという点です。それが先ほどの例です。先ほどの散布図の場合、次元を増やすことは、新しい次元で条件づけた場合の変数の関係性を調べることとなります。しかし、新しい次元による条件付き関連性があまり見られない場合、あるいは二種類以上の点の形があまり分離されていない場合は、次元の追加がもたらす恩恵が感じにくくなるでしょう。例えば以下のような散布図を比較してみましょう。図(A)の場合、縦軸の変数が閾値を超えるともう一つの変数との関係が弱まるということが分かります。たとえば、三角の点において両変数は正の相関を持ち、丸の点においては無相関に近いことが分かります。この場合、点の形は非常に有用な情報を含んでいると判断できます。一方、図(B)の場合、点の形から読み取れる情報が少ないですね。あえて言えば、グループ間の違いがあまりないことくらいでしょう。 白黒のグラフの場合、色分けが出来ないため、次元拡張には点の形を変えることになります。しかし、色に来れば形は読み手にとって認知の負荷がかかりやすいです。下の図を見てください。100個の点がありますが、三角の点はいくつでしょうか。 正解は5つです。あまり難しい問題ではないでしょう。一方、下の図はいかがでしょうか。 どれも正解は5つです。本質的には同じ問題ですが、どの図の方が読みやすかったでしょうか。個人差はあるかも知れませんが、多くの方にとって後者の方が読みやすかったでしょう。最近、海外のジャーナルはカラーの図を使うことも可能ですので、色分けを優先的に考えましょう。白黒のみ受け付けられる場合でも、グループ数やサンプルサイズによっては点の形より、彩度や明るさの方が効果的な場合もあります。 続きまして、linetypeについて解説します。線の形も色分けができない場合、よく使われる次元の増やし方です。ここでは日中韓台における人口1万人あたりCOVID-19新規感染者数の折れ線グラフを作成します。COVID19_dfには人口のデータがないため、left_join()を使ってCountry_dfと結合します。left_join()の使い方に関しては第13章を参照してください。続いて、Character型であるDate変数をas.Date()関数を使ってDate型へ変換します。1万人あたり新規感染者数は新規感染者数（Confirmed_Day）を人口（Population）で割り、1万をかけます。最後にCountry列を基準にfilter()を使用し、日中韓台のデータのみ残します。後は折れ線グラフを作成しますが、geom_line()内のaes()内にlinetype引数をCountry変数でマッピングします。 left_join(COVID19_df, Country_df, by = &quot;Country&quot;) %&gt;% mutate(Date = as.Date(Date), Confirmed_per_capita = Confirmed_Day / Population * 10000) %&gt;% filter(Country %in% c(&quot;Japan&quot;, &quot;China&quot;, &quot;Taiwan&quot;, &quot;South Korea&quot;)) %&gt;% ggplot() + geom_line(aes(x = Date, y = Confirmed_per_capita, linetype = Country)) + labs(x = &quot;月&quot;, y = &quot;1万人当たり新規感染者数&quot;,linetype = &quot;国&quot;) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) いかがでしょうか。linetypeはcolorよりも識別性が非常に低いことが分かるでしょう。個人差もあるかも知れませんが、shapeよりも低いのではないでしょうか。実線の中国を除けば、日本、韓国、台湾の線はなかなか区別できません。したがって、linetypeは2つ、3つまでが限界だと考えられます。3つまででしたら、実線、破線、点線に分けることができるでしょう。ここでは、日本のみを実線とし、他の3カ国は「その他」として破線にしてみましょう。そのためには、日本か否かを示すJapan変数を作成します。また、geom_line()のaes()内にはgroups引数を追加し、linetypeはJapan変数でマッピングします。 left_join(COVID19_df, Country_df, by = &quot;Country&quot;) %&gt;% mutate(Date = as.Date(Date), Confirmed_per_capita = Confirmed_Day / Population * 10000, Japan = if_else(Country == &quot;Japan&quot;, &quot;日本&quot;, &quot;その他&quot;)) %&gt;% filter(Country %in% c(&quot;Japan&quot;, &quot;China&quot;, &quot;Taiwan&quot;, &quot;South Korea&quot;)) %&gt;% ggplot() + geom_line(aes(x = Date, y = Confirmed_per_capita, group = Country, linetype = Japan)) + labs(x = &quot;月&quot;, y = &quot;1万人当たり新規感染者数&quot;, linetype = &quot;国&quot;) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) その他の国が実線となっているので、scale_linetype_manual()でJapanの値ごとに線のタイプを指定します。 left_join(COVID19_df, Country_df, by = &quot;Country&quot;) %&gt;% mutate(Date = as.Date(Date), Confirmed_per_capita = Confirmed_Day / Population * 10000, Japan = if_else(Country == &quot;Japan&quot;, &quot;日本&quot;, &quot;その他&quot;)) %&gt;% filter(Country %in% c(&quot;Japan&quot;, &quot;China&quot;, &quot;Taiwan&quot;, &quot;South Korea&quot;)) %&gt;% ggplot() + geom_line(aes(x = Date, y = Confirmed_per_capita, group = Country, linetype = Japan)) + scale_linetype_manual(values = c(&quot;日本&quot; = 1, &quot;その他&quot; = 2)) + labs(x = &quot;月&quot;, y = &quot;1万人当たり新規感染者数&quot;, linetype = &quot;国&quot;) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) できれば、日本とその他の順番も逆にしたいですね。こちらはJapan変数をfactor化することで対応可能です。 left_join(COVID19_df, Country_df, by = &quot;Country&quot;) %&gt;% mutate(Date = as.Date(Date), Confirmed_per_capita = Confirmed_Day / Population * 10000, Japan = if_else(Country == &quot;Japan&quot;, &quot;日本&quot;, &quot;その他&quot;), Japan = factor(Japan, levels = c(&quot;日本&quot;, &quot;その他&quot;))) %&gt;% filter(Country %in% c(&quot;Japan&quot;, &quot;China&quot;, &quot;Taiwan&quot;, &quot;South Korea&quot;)) %&gt;% ggplot() + geom_line(aes(x = Date, y = Confirmed_per_capita, group = Country, linetype = Japan)) + scale_linetype_manual(values = c(&quot;日本&quot; = 1, &quot;その他&quot; = 2)) + labs(x = &quot;月&quot;, y = &quot;1万人当たり新規感染者数&quot;, linetype = &quot;国&quot;) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) これで完成ですがいかがでしょうか。複数の線を識別するという意味では色分け（color）が優れていますし、ハイライトなら透明度（alpha）か線の太さ（size）の方が良いでしょう。筆者（SONG）としましてはlinetypeによる次元の追加はあまりオススメしませんが、知っといて損はないでしょう。 19.4 theme_*()とtheme(): テーマの指定 続いて図全体の雰囲気を決めるtheme_*()レイヤーについて解説します。これらの使い方は非常に簡単であり、ggplotオブジェクトにtheme_*()レイヤーを+で繋ぐだけです。もし、こちらのレイヤーを追加しない場合、デフォルトテーマとしてtheme_gray()が適用されます。{ggplot2}はいくつかのテーマを提供しており、以下がその例です。 他にも{ggplot2}用のテーマをパッケージとしてまとめたものもあります。興味のある方はggthemeやggthemrページを確認してみてください。 theme_*()内部ではいくつかの引数を指定することができます。最もよく使われるのがbase_family引数であり、図で使用するフォントを指定する引数です。macOSユーザーだとヒラギノ角ゴジックW3が良く使われており、base_family = \"HiraginoSans-W3\"で設定可能です。他にも全体の文字サイズを指定するbase_sizeなどがあります。 テーマの微調整は主にtheme()レイヤーで行います。こちらでは図の見た目に関する細かい調整ができます。実はtheme_*()関数群は調整済みtheme()レイヤーとして捉えることも出来ます。theme_*()とtheme()を同時に使うことも可能であり、「全般的にはminimalテーマ（theme_minimal()）が好きだけど、ここだけはちょっと修正したい」場合に使用します。theme()では図の見た目に関する全ての部分が設定可能であるため、引数も膨大です。詳しくはコンソール上で?themeを入力し、ヘルプを確認してください。ここではいくつかの例のみを紹介します。 まずは実習用データとして任意の棒グラフを作成し、Theme_Figという名のオブジェクトとして保存しておきます。 Theme_Fig &lt;- Country_df %&gt;% # Freedom HouseのStatus、Continentでグループ化 group_by(FH_Status, Continent) %&gt;% # 欠損値のある行を除き、PPP_per_capitaの平均値を計算 summarise(PPP = mean(PPP_per_capita, na.rm = TRUE), .groups = &quot;drop&quot;) %&gt;% # 欠損値の行を除去 drop_na() %&gt;% # Freedom HouseのStatusを再ラベリングし、factor化 mutate(FH_Status = case_when(FH_Status == &quot;F&quot; ~ &quot;Free&quot;, FH_Status == &quot;PF&quot; ~ &quot;Partially Free&quot;, FH_Status == &quot;NF&quot; ~ &quot;Not Free&quot;), FH_Status = factor(FH_Status, levels = c(&quot;Free&quot;, &quot;Partially Free&quot;, &quot;Not Free&quot;))) %&gt;% ggplot() + geom_bar(aes(x = FH_Status, y = PPP, fill = Continent), stat = &quot;identity&quot;, position = position_dodge(width = 1)) + labs(x = &quot;Polity IV Score&quot;, y = &quot;PPP per capita (USD)&quot;) Theme_Fig 19.4.1 文字の大きさ 図全体における文字の大きさはtheme_*()レイヤーのbase_sizeから調整することもできますが、theme()からも可能です。文字に関する調整はtext引数に対してelement_text()実引数を指定します。大きさの場合、element_text()内にsize引数を指定します。 Theme_Fig + theme(text = element_text(size = 16)) element_text()では文字の大きさ以外にも色（color）、回転の度合い（angle）などを指定することもできます。詳しくはRコンソール上で?element_textを入力し、ヘルプを確認してください。 19.4.2 背景のグリッド 背景のグリッドを調整する際はpanel.gird.*引数を使います。主に使用する場面はグリッドの除去する場合ですが、この場合は実引数としてelement_blank()を使います。もし、グリッドの色や太さなどを変更したい場合はelement_line()を使用します。ここではグリッドを除去する方法について紹介します。 グリッドを除去する場合、どのグリッドを除去するかを決めないといけません。例えば、すべてのグリッドを除去するためにはpanel.grid = element_blank()を使います。また、メジャーグリッドの除去にはpanel.grid.major（すべて）、panel.grid.major.x（横軸のみ）、panel.grid.major.y（縦軸のみ）を指定します。マイナーグリッドの場合はmajorをminorに替えてください。以下にはいくつかの例をお見せします。 # すべてのグリッドを除去 Theme_Fig + theme(panel.grid = element_blank()) # x軸のメジャーグリッドを除去 Theme_Fig + theme(panel.grid.major.x = element_blank()) # y軸のマイナーグリッドのみ除去 Theme_Fig + theme(panel.grid.minor.y = element_blank()) 19.4.3 目盛りラベルの回転 横軸の目盛りラベルが長すぎるか大きすぎると、ラベルが重なる場合があります。この場合の対処方法としてはラベルの長さを短くしたり、改行（\\n）を入れることが考えられますが、ラベルを若干回転することでも対処可能です。たとえば、横軸の目盛りラベルを調整する場合はaxis.text.x = element_text()を指定し、element_text()内にangle引数を指定します。例えば、 反時計回りで25度回転させる場合はangle = 25と指定します。 Theme_Fig + theme(text = element_text(size = 16), axis.text.x = element_text(angle = 25)) この場合、ラベルは目盛りのすぐ下を基準に回転することになります。もし、ラベルの最後の文字を目盛りの下に移動させる場合はhjust = 1を追加します。 Theme_Fig + theme(text = element_text(size = 16), axis.text.x = element_text(angle = 25, hjust = 1)) ちなみに、angle = 90などで指定するとラベルが重なる問題はほぼ完全に解決されますが、かなり読みづらくなるので、できればangleの値は小さめにした方が読みやすくなります。 19.4.4 scale_*_*()を用いたラベル重複の回避 ラベルの重複を回避するもう一つの方法は「ラベルの位置をずらす」ことです。これは{ggplot2}3.3.0以降追加された機能であり、theme()でなく、scale_*_*()関数のguide引数で指定することが出来ます。使い方は以下の通りです。たとえば、横軸（x軸）のラベルを2行構成にしたい場合は以下のように指定します。 ggplot2オブジェクト名 + scale_x_discrete(guide = guide_axis(n.dodge = 2)) 実際の結果を確認してみましょう。 Theme_Fig + scale_x_discrete(guide = guide_axis(n.dodge = 2)) + theme(text = element_text(size = 16)) 横軸のラベルが2行構成になりました。左から最初のラベルは1行目に、2番目のラベルは2行目に、3番目のラベルは1行目になります。実際、ラベルをずらすだけならn.dodge = 2で十分ですが、この引数の挙動を調べるためにn.dodge = 3に指定してみましょう。 Theme_Fig + scale_x_discrete(guide = guide_axis(n.dodge = 3)) + theme(text = element_text(size = 16)) 3番目のラベルが3行目に位置することになります。もし、4つ目のラベルが存在する場合、それは1行目に位置するでしょう。 19.4.5 凡例の表示/非表示 凡例を無くす方法はいくつかありますが、まずはすべての凡例を非表示する方法について紹介します。それは後ほど紹介しますlegend.positionの実引数として\"none\"を指定する方法です。 # 凡例を非表示にする Theme_Fig + theme(legend.position = &quot;none&quot;) Theme_Figはxとy以外にfillにマッピングをしたため、凡例は一つのみとなります。ただし、場合によってはもっと次元を増やすことによって2つ以上の凡例が表示されるケースがあります。別途の説明なくても図だけで理解するのが理想なので凡例は出来る限り温存させた方が良いでしょう。しかし、実例はあまり多く見られないと思いますが、凡例がなくても理解に問題がないと判断される場合は一部の凡例を非表示することも考えられます。 たとえば、以下のようなTheme_Fig2の例を考えてみましょう。 Theme_Fig2 &lt;- Country_df %&gt;% mutate(OECD = if_else(OECD == 1, &quot;OECD&quot;, &quot;non-OECE&quot;)) %&gt;% ggplot(aes(x = FH_Total, y = GDP_per_capita)) + geom_point(aes(color = OECD)) + stat_ellipse(aes(fill = OECD), geom = &quot;polygon&quot;, level = 0.95, alpha = 0.2) + labs(x = &quot;Freedom House Score&quot;, y = &quot;GDP per capita (USD)&quot;, color = &quot;OECD&quot;, fill = &quot;Cluster&quot;) Theme_Fig2 colorとfillがそれぞれ別の凡例として独立しています。この例の場合、fillの凡例はなくても、図を理解するのは難しくないかも知れません。ここで考えられる一つの方法はcolorとfillの凡例をオーバラップさせる方法です。{ggplot2}の場合、同じ変数がマッピングされていれば凡例をオーバーラップさせることも可能です。ただし、凡例のタイトルが同じである必要があります。ここではcolorとfillのタイトルを\"OECD\"に統一してみましょう。 Theme_Fig2 + labs(color = &quot;OECD&quot;, fill = &quot;OECD&quot;) これで十分でしょう。しかし、凡例からfillの情報を完全に消したい場合はどうすれば良いでしょうか。その時に登場するのがguides()関数です。関数の中でマッピング要素 = \"none\"を指定すると、当該凡例が非表示となります。 Theme_Fig2 + guides(fill = &quot;none&quot;) guides()関数は凡例を細かく調整できる様々な機能を提供しています。興味のある方はヘルプ（?guides）を参照してください。 19.4.6 凡例の位置 凡例を図の下段に移動させる場合はlegend.position引数に\"bottom\"を指定するだけです。他にも\"top\"や\"left\"も可能ですが、凡例は一般的に図の右か下段に位置しますので、デフォルトのままに置くか、\"bottom\"くらいしか使わないでしょう。 # 凡例を図の下段へ移動 Theme_Fig + theme(legend.position = &quot;bottom&quot;) もし、凡例を図の内部に置く場合は、長さ2のnumeric型ベクトルを指定します。図の左下ならc(0, 0)、左上ならc(0, 1)、右上はc(1, 1)、右下はc(1, 0)となります。これは図の大きさを横縦それぞれ1とした場合の位置を意味します。ここでは凡例を右上へ置いてみましょう。 # 凡例をプロットの右上へ Theme_Fig + theme(legend.position = c(1, 1)) これは凡例の中央が右上に来るようになります。これを是正するためにはlegend.justification引数を更に指定する必要があります。これにも長さ2のnumeric型ベクトルを指定しますが、これは凡例の中心をどこにするかを意味します。今回の例だと、凡例の右上をc(1, 1)に位置させたいので、ここもc(1, 1)と指定します。基本的にlegend.positionとlegend.justificationは同じ値にすれば問題ないでしょう。 # 凡例の中心を凡例の右上と指定 Theme_Fig + theme(legend.position = c(1, 1), legend.justification = c(1, 1)) また、凡例の背景を透明にしたい場合はlegend.background = element_blank()を指定します。 # 凡例を背景を透明に Theme_Fig + theme(legend.position = c(1, 1), legend.justification = c(1, 1), legend.background = element_blank()) theme()関数が提供している昨日は非常に多く、それぞれの実引数として用いられるelement_text()やelement_line()、element_rect()にも様々な引数が提供されております。図を自分好みに微調整したい方はそれぞれの関数のヘルプを参照してください。 19.5 図の結合 {ggplot2}で作成した複数の図を一つの図としてまとめる場合、昔は{gridExtra}一択でした。しかし、今はもっと使いやすいパッケージがいくつか公開されており、ここでは{ggpubr}のggarrange()を紹介します。使い方を紹介する前に、結合する図をいくつか用意し、それぞれGrid_Fig1、Gird_Fig2、…Grid_Fig4と名付けます。 # Grid_Fig1: 散布図 # X軸: フリーダムハウス・スコア / Y軸: 一人あたり購買力平価GDP（対数） Grid_Fig1 &lt;- Country_df %&gt;% ggplot() + geom_point(aes(x = FH_Total, y = PPP_per_capita)) + scale_y_log10() + labs(x = &quot;フリーダムハウススコア&quot;, y = &quot;一人あたり購買力平価GDP（対数）&quot;) + theme_bw(base_size = 12) # Grid_Fig2: 散布図 # X軸: フリーダムハウス・スコア / Y軸: 2018年人間開発指数 Grid_Fig2 &lt;- Country_df %&gt;% ggplot() + geom_point(aes(x = FH_Total, y = HDI_2018)) + labs(x = &quot;フリーダムハウススコア&quot;, y = &quot;人間開発指数（2018年）&quot;) + theme_bw(base_size = 12) # Grid_Fig4: ヒストグラム # X軸: フリーダムハウス・スコア Grid_Fig3 &lt;- Country_df %&gt;% ggplot() + geom_histogram(aes(x = FH_Total), color = &quot;white&quot;, binwidth = 5, boundary = 0) + labs(x = &quot;フリーダムハウススコア&quot;, y = &quot;国数&quot;) + theme_bw(base_size = 12) # Grid_Fig4: ヒストグラム # Y軸: 一人あたり購買力平価GDP（対数） # 時計回りで90度回転したヒストグラムを作成するために、yにマッピング Grid_Fig4 &lt;- Country_df %&gt;% ggplot() + geom_histogram(aes(y = PPP_per_capita), color = &quot;white&quot;, boundary = 0, bins = 15) + scale_y_log10() + labs(x = &quot;国数&quot;, y = &quot;一人あたり購買力平価GDP（対数）&quot;) + theme_bw(base_size = 12) それぞれの図は以下の通りです。左上、右上、左下、右下の順でそれぞれGrid_Fig1、Grid_Fig2、Grid_Fig3、Grid_Fig4です。 まずはGrid_Fig1とGrid_Fig2を横に並べてみましょう。まずは{ggpubr}を読み込みます。 pacman::p_load(ggpubr) 図を並べる際はggarrange()関数を使用し、まず、結合したい図のオブジェクトを入力します。また、2つの図を横に並べることは1行2列のレイアウトであることを意味するため、nrowとncol引数の実引数としてそれぞれ1と2を指定します。 ggarrange(Grid_Fig1, Grid_Fig2, nrow = 1, ncol = 2) 右側にあるGrid_Fig2の幅が若干広いような気がします。この場合、aling = \"hv\"を入れると綺麗に揃えられます。 ggarrange(Grid_Fig1, Grid_Fig2, nrow = 1, ncol = 2, align = &quot;hv&quot;) 続きまして、3つの図を以下のように並べるとします。 Grid_Fig3 Grid_Fig1 Grid_Fig4 今回は3つの図オブジェクトを入れるだけでは不十分です。なぜなら、ggarrange()関数は左上から右下の順番へ一つずつ図を入れるからです。もし、3つの図オブジェクトのみを入れると、以下のように配置されます。 Grid_Fig3 Grid_Fig1 Grid_Fig4 これを回避するためには空欄とするグリッドにNULLを指定する必要があります。 ggarrange(Grid_Fig3, # 1行1列目 NULL, # 1行2列目 Grid_Fig1, # 2行1列目 Grid_Fig4, # 2行2列目 nrow = 2, ncol = 2, align = &quot;hv&quot;) 次はヒストグラムを小さく調整します。左上のGrid_Fig3の上下の幅を、右下のGrid_Fig4は左右の幅を狭くします。このためにはwidthsとheights引数が必要です。たとえば、heights = c(0.3, 0.7)だと1行目は全体の30%、2行目は全体の70%になります。今回は1行目と2行目の比率は3:7に、1列目と2列目の比は7:3とします。また、それぞれの図に(a)、(b)、(c)を付けます。空欄となるグリッドのラベルはNAか\"\"にします。NULLではないことに注意してください。 ggarrange(Grid_Fig3, NULL, Grid_Fig1, Grid_Fig4, nrow = 2, ncol = 2, align = &quot;hv&quot;, # グリットの大きさを調整 widths = c(0.7, 0.3), heights = c(0.3, 0.7), # 各図にラベルを付ける labels = c(&quot;(a)&quot;, NA, &quot;(b)&quot;, &quot;(c)&quot;)) 左上のGrid_Fig3と左下のGrid_Fig1は横軸のラベルを共有しており、左下のGrid_Fig1と右下のGrid_Fig4は縦軸のラベルを共有しています。以下ではGrid_Fig3の横軸ラベル、Grid_Fig4の縦軸ラベルを消します。ggplotオブジェクトにtheme(axis.title.x = element_blank())を+で繋ぐと横軸のラベルが表示されなくなります。ggarrange()に入れるオブジェクトに直接アクセスし、それぞれの軸ラベルを消してみましょう90。 ggarrange(Grid_Fig3 + theme(axis.title.x = element_blank()), NULL, Grid_Fig1, Grid_Fig4 + theme(axis.title.y = element_blank()), nrow = 2, ncol = 2, align = &quot;hv&quot;, widths = c(0.7, 0.3), heights = c(0.3, 0.7), labels = c(&quot;(a)&quot;, NA, &quot;(b)&quot;, &quot;(c)&quot;)) これで完成です。ggarrange()には他にもカスタマイズ可能な部分がいっぱいあります。詳細はコンソール上で?ggarrangeを入力し、ヘルプを参照してください。 他にも{egg}パッケージのggarrange()、{cowplot}のplot_grid()、{patchwork}の+、|、/演算子などがあります。それぞれ強みがあり、便利なパッケージです。興味のある読者は以下のページで使い方を確認してみてください。 egg cowplot patchwork "],["visualization4.html", "20. 可視化[発展] 20.1 概要 20.2 バイオリンプロット 20.3 ラグプロット 20.4 リッジプロット 20.5 エラーバー付き散布図 20.6 ロリーポップチャート 20.7 平滑化ライン 20.8 ヒートマップ 20.9 等高線図 20.10 地図 20.11 非巡回有向グラフ 20.12 バンプチャート 20.13 沖積図 20.14 ツリーマップ 20.15 モザイクプロット 20.16 その他のグラフ", " 20. 可視化[発展] 20.1 概要 第17章では{ggplot2}の仕組みについて、第18章ではよく使われる5種類のプロット（棒グラフ、散布図、折れ線グラフ、箱ひげ図、ヒストグラム）の作り方を、第19章ではスケール、座標系などの操作を通じたグラフの見た目調整について解説しました。本章では第18章の延長線上に位置づけることができ、紹介しきれなかった様々なグラフの作り方について簡単に解説します。本章で紹介するグラフは以下の通りです。 バイオリンプロット ラグプロット リッジプロット エラーバー付き散布図 ロリーポップチャート 平滑化ライン ヒートマップ 等高線図 地図 非巡回有向グラフ バンプチャート 沖積図 ツリーマップ モザイクプロット pacman::p_load(tidyverse) Country_df &lt;- read_csv(&quot;Data/Countries.csv&quot;) COVID19_df &lt;- read_csv(&quot;Data/COVID19_Worldwide.csv&quot;, guess_max = 10000) 20.2 バイオリンプロット バイオリンプロットは連続変数の分布を可視化する際に使用するプロットの一つです。第17章で紹介しましたヒストグラムや箱ひげ図と目的は同じです。それではバイオリンプロットとは何かについて例を見ながら解説します。 以下の図は対数化した一人当たり購買力平価GDP（PPP_per_capita）のヒストグラムです。 このヒストグラムをなめらかにすると以下のような図になります。 この密度曲線を上下対称にすると以下のような図となり、これがバイオリンプロットです。ヒストグラムのようにデータの分布が分かりやすくなります。 しかし、この図の場合、ヒストグラムと同様、中央値や四分位数などの情報が含まれておりません。これらの箱ひげ図を使用した方が良いでしょう。バイオリンプロットの良い点はバイオリンの中に箱ひげ図を入れ、ヒストグラムと箱ひげ図両方の長所を取ることができる点です。たとえば、バイオリンプロットを90度回転させ、中にバイオリン図を入れると以下のようになります。 それでは実際にバイオリンプロットを作ってみましょう。使い方は箱ひげ図（geom_boxplot()）と同じです。たとえば、横軸は大陸（Continent）に、縦軸は対数化した一人当たり購買力平価GDP（PPP_per_capita）にしたバイオリンプロットを作るには作るにはgeom_violin()幾何オブジェクトの中にマッピングするだけです。大陸ごとに色分けしたい場合はfill引数にContinentをマッピングします。 Country_df %&gt;% ggplot() + geom_violin(aes(x = Continent, y = PPP_per_capita, fill = Continent)) + labs(x = &quot;大陸&quot;, y = &quot;一人当たり購買力平価GDP (対数)&quot;) + scale_y_continuous(breaks = c(0, 1000, 10000, 100000), labels = c(0, 1000, 10000, 100000), trans = &quot;log10&quot;) + # y軸を対数化 guides(fill = &quot;none&quot;) + # fillのマッピング情報の凡例を隠す theme_minimal(base_size = 16) ここに箱ひげ図も載せたい場合は、geom_violin()オブジェクトの後にgeom_boxplot()オブジェクトを入れるだけで十分です。 Country_df %&gt;% ggplot() + geom_violin(aes(x = Continent, y = PPP_per_capita, fill = Continent)) + geom_boxplot(aes(x = Continent, y = PPP_per_capita), width = 0.2) + labs(x = &quot;大陸&quot;, y = &quot;一人当たり購買力平価GDP (対数)&quot;) + scale_y_continuous(breaks = c(0, 1000, 10000, 100000), labels = c(0, 1000, 10000, 100000), trans = &quot;log10&quot;) + guides(fill = &quot;none&quot;) + theme_minimal(base_size = 16) 箱ひげ図は四分位範囲、四分位数、最小値、最大値などの情報を素早く読み取れますが、どの値当たりが分厚いかなどの情報が欠けています。これをバイオリンプロットで補うことで、よりデータの分布を的確に把握することができます。 20.3 ラグプロット ラグプロット（rug plot）は変数の分布を示す点ではヒストグラム、箱ひげ図、バイオリンプロットと同じ目的を持ちますが、大きな違いとしてはラグプロット単体で使われるケースがない（または、非常に稀）という点です。ラグプロットは上述しましたヒストグラムや箱ひげ図、または散布図などと組み合わせて使うのが一般的です。 以下はCountry_dfのPPP_per_capita（常用対数変換）のヒストグラムです。 一変数の分布を確認する場合、ヒストグラムは情報量の損失が少ない方です。それでも値一つ一つの情報は失われますね。例えば、上記のヒストグラムで左端の度数は1です。左端の棒の区間はおおよそ500から780であり、一人当たりPPPがこの区間に属する国は1カ国ということです。ちなみに、その国はブルンジ共和国ですが、ブルンジ共和国の具体的な一人当たりPPPはヒストグラムから分かりません。情報量をより豊富に持たせるためには区間を細かく刻むことも出来ますが、逆に分布の全体像が読みにくくなります。 ここで登場するのがラグプロットです。これは座標平面の端を使ってデータを一時現状に並べたものです。多くの場合、点ではなく、垂直線（｜）を使います。ラグプロットの幾何オブジェクトは{ggplot2}でデフォルトで提供されており、geom_rug()を使います。マッピングはxまたはyに対して行いますが、座標平面の下段にラグプロットを出力する場合はxに変数（ここではPPP_per_capita）をマッピングします。 ラグプロットを使うと本来のヒストグラムの外見にほぼ影響を与えず、更に情報を付け加えることが可能です。点（｜）の密度でデータの分布を確認することもできますが、その密度の相対的な比較に関してはヒストグラムの方が良いでしょう。 ラグプロットは散布図に使うことも可能です。散布図は一つ一つの点が具体的な値がマッピングされるため、情報量の損失はほぼないでしょう。それでも散布図にラグプロットを加える意味はあります。まず、Country_dfのフリーダムハウス指数（FH_Total）と一人当たりPPP（PPP_per_capita）の散布図を作ってみましょう。 散布図の目的は二変量間の関係を確認することであって、それぞれの変数の分布を確認することではありません。もし、FH_TotalとPPP_per_capitaの分布が確認したいなら、それぞれのヒストグラムや箱ひげ図を作成した方が良いでしょう。しかし、ラグプロットを使えば、点（｜）の密度で大まかな分布は確認出来ますし、図の見た目にもほぼ影響を与えません。 横軸と縦軸両方のラグプロットは、geom_rug()にxとy両方マッピングするだけです。 これでFH_Totalはほぼ均等に分布していて、PPP_per_capitaは2万ドル以下に多く密集していることが確認できます。 {ggExtra}のggMarginal()を使えば、ラグプロットでなく、箱ひげ図やヒストグラムを付けることも可能です。{ggplot2}で作図した図をオブジェクトとして格納し、ggMarginal()の第一引数として指定します。第一引数のみだと密度のだけ出力されるため、箱ひげ図を付けるためにはtype = \"boxplot\"を指定します（既定値は\"density\"）。ヒストグラムを出力する場合は\"histogram\"と指定します。 20.4 リッジプロット リッジプロット（ridge plot）はある変数の分布をグループごとに出力する図です。大陸ごとの人間開発指数の分布を示したり、時系列データなら分布の変化を示す時にも使えます。ここでは大陸ごとの人間開発指数の分布をリッジプロットで示してみましょう。 リッジプロットを作成する前に、geom_density()幾何オブジェクトを用い、変数の密度曲線（density curve）を作ってみます。マッピングはxに対し、分布を出力する変数名を指定します。また、密度曲線内部に色塗り（fill）をし、曲線を計算する際のバンド幅（bw）は0.054にします。bwが大きいほど、なめらかな曲線になります。 Country_df %&gt;% ggplot() + geom_density(aes(x = HDI_2018), fill = &quot;gray70&quot;, bw = 0.054) + labs(x = &quot;2018年人間開発指数&quot;, y = &quot;大陸&quot;) + theme_minimal(base_size = 12) ## Warning: Removed 6 rows containing non-finite values (stat_density). これを大陸ごとに出力する場合、ファセット分割を行います。今回は大陸ごとに1列（ncol = 1）でファセットを分割します。 Country_df %&gt;% ggplot() + geom_density(aes(x = HDI_2018), fill = &quot;gray70&quot;, bw = 0.054) + labs(x = &quot;2018年人間開発指数&quot;, y = &quot;大陸&quot;) + facet_wrap(~Continent, ncol = 1) + theme_minimal(base_size = 12) ## Warning: Removed 6 rows containing non-finite values (stat_density). それでは上のグラフをリッジプロットとして作図してみましょう。今回は{ggridges}パッケージを使います。 pacman::p_load(ggridges) 使用する幾何オブジェクトはgeom_density_ridges()です。似たような幾何オブジェクトとしてgeom_ridgeline()がありますが、こちらは予め密度曲線の高さを計算しておく必要があります。一方、geom_density_ridges()は変数だけ指定すれば密度を自動的に計算してくれます。マッピングはxとyに対し、それぞれ分布を出力する変数名とグループ変数名を指定します。また、密度曲線が重なるケースもあるため、透明度（alpha）も0.5にしておきましょう。ここでは別途指定しませんが、ハンド幅も指定可能であり、aes()の外側にbandwidthを指定するだけです。 Country_df %&gt;% ggplot() + geom_density_ridges(aes(x = HDI_2018, y = Continent), alpha = 0.5) + labs(x = &quot;2018年人間開発指数&quot;, y = &quot;大陸&quot;) + theme_minimal(base_size = 12) ## Picking joint bandwidth of 0.054 ## Warning: Removed 6 rows containing non-finite values (stat_density_ridges). 先ほど作図した図と非常に似た図が出来上がりました。ファセット分割に比べ、空間を最大限に活用していることが分かります。ファセットラベルがなく、グループ名が縦軸上に位置するからです。また、リッジプロットの特徴は密度曲線がオーバラップする点ですが、以下のようにscale = 1を指定すると、オーバラップなしで作成することも可能です。もし、scale = 3にすると最大2つの密度曲線が重なることになります。たとえば最下段のアフリカはアメリカの行と若干オーバラップしていますが、scale = 3の場合、アジアの行までオーバーラップされうることになります。 Country_df %&gt;% ggplot() + geom_density_ridges(aes(x = HDI_2018, y = Continent), scale = 1, alpha = 0.5) + labs(x = &quot;2018年人間開発指数&quot;, y = &quot;大陸&quot;) + theme_minimal(base_size = 12) ## Picking joint bandwidth of 0.054 ## Warning: Removed 6 rows containing non-finite values (stat_density_ridges). また、横軸の値に応じて背景の色をグラデーションで表現することも可能です。この場合、geom_density_ridges()幾何オブジェクトでなく、geom_density_ridges_gradient()を使い、fillにもマッピングをする必要があります。横軸（x）の値に応じて色塗りをする場合、fill = stat(x)とします。デフォルトでは横軸の値が高いほど空色、低いほど黒になります。ここでは高いほど黄色、低いほど紫ににするため、色弱にも優しいscale_fill_viridis_c()を使い91、カラーオプションはplasmaにします（option = \"c\"）。 Country_df %&gt;% ggplot() + geom_density_ridges_gradient(aes(x = HDI_2018, y = Continent, fill = stat(x)), alpha = 0.5) + scale_fill_viridis_c(option = &quot;C&quot;) + labs(x = &quot;2018年人間開発指数&quot;, y = &quot;大陸&quot;, fill = &quot;2018年人間開発指数&quot;) + theme_minimal(base_size = 12) + theme(legend.position = &quot;bottom&quot;) ## Picking joint bandwidth of 0.054 密度曲線は基本的にはなめらかな曲線であるため、データが存在しない箇所にも密度が高く見積もられるケースがあります。全体的な分布を俯瞰するには良いですが、情報の損失は避けられません。そこで出てくるのが点付きのリッジプロットです。HDI_2018の個々の値を点で出力するにはjittered_points = TRUEを指定するだけです。これだけで密度曲線の内側に点が若干のズレ付き（jitter）で出力されます。ただし、密度曲線がオーバーラップされるリッジプロットの特徴を考えると、グループごとに点の色分けをする必要があります（同じ色になると、どのグループの点かが分からなくなるので）。この場合、point_colorに対し、グループ変数（Continent）をマッピングします。また、密度曲線の色と合わせるために密度曲線の色塗りもfillで指定します。 Country_df %&gt;% ggplot() + geom_density_ridges(aes(x = HDI_2018, y = Continent, fill = Continent, point_color = Continent), alpha = 0.5, jittered_points = TRUE) + guides(fill = &quot;none&quot;, point_color = &quot;none&quot;) + # 凡例を削除 labs(x = &quot;2018年人間開発指数&quot;, y = &quot;大陸&quot;) + theme_minimal(base_size = 12) ## Picking joint bandwidth of 0.054 ## Warning: Removed 6 rows containing non-finite values (stat_density_ridges). 他にも密度曲線の下側にラグプロットを付けることも可能です。こうすれば点ごとに色訳をする必要もなくなります。ラグプロットを付けるためには点の形（point_shape）を「|」にする必要があります。ただ、これだけだと「|」が密度曲線内部に散らばる（jittered）だけです。散らばりをなくす、つまり密度曲線の下段に固定する必要があり、これはaes()その外側にposition = position_points_jitter(width = 0, height = 0)を指定することで出来ます。 Country_df %&gt;% ggplot() + geom_density_ridges(aes(x = HDI_2018, y = Continent, fill = Continent), alpha = 0.5, jittered_points = TRUE, position = position_points_jitter(width = 0, height = 0), point_shape = &quot;|&quot;, point_size = 3) + guides(fill = &quot;none&quot;) + labs(x = &quot;2018年人間開発指数&quot;, y = &quot;大陸&quot;) + theme_minimal(base_size = 12) ## Picking joint bandwidth of 0.054 ## Warning: Removed 6 rows containing non-finite values (stat_density_ridges). 最後に密度曲線でなく、ヒストグラムで示す方法を紹介します。これはgeom_density_ridges()の内部にstat = \"binline\"を指定するだけです。 Country_df %&gt;% ggplot() + geom_density_ridges(aes(x = HDI_2018, y = Continent), alpha = 0.5, stat = &quot;binline&quot;) + labs(x = &quot;2018年人間開発指数&quot;, y = &quot;大陸&quot;) + theme_minimal(base_size = 12) ## `stat_binline()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 6 rows containing non-finite values (stat_binline). 20.5 エラーバー付き散布図 エラーバー付きの散布図は推定結果の点推定値とその不確実性（信頼区間など）を示す際によく使われる図です。以下の表はCountry_dfを用い、大陸（オセアニアを除く）ごとにフリーダムハウス・スコア（FH_Total）を一人当たりPPP GDP（PPP_per_capita）に回帰させた分析から得られたフリーダムハウス・スコア（FH_Total）の係数（以下の式の\\(\\beta_1\\)）の点推定値と95%信頼区間です。 \\[ \\text{PPP per capita} = \\beta_0 + \\beta_1 \\cdot \\text{FH}\\_\\text{Total} + \\varepsilon \\] Pointrange_df &lt;- tibble( Continent = c(&quot;Asia&quot;, &quot;Europe&quot;, &quot;Africa&quot;, &quot;America&quot;), Coef = c(65.3, 588.0, 53.4, 316.0), Conf_lwr = c(-250.0, 376.0, -14.5, 128.0), Conf_upr = c(380.0, 801.0, 121.0, 504.0) ) Pointrange_df ## # A tibble: 4 × 4 ## # Groups: Continent [4] ## Continent Coef Conf_lwr Conf_upr ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia 65.3 -250. 380. ## 2 Europe 588. 376. 801. ## 3 Africa 53.4 -14.5 121. ## 4 America 316. 128. 504. 実は以上のデータは以下のようなコードで作成されています。{purrr}パッケージの使い方に慣れる必要があるので、第27章を参照してください。 Pointrange_df &lt;- Country_df %&gt;% filter(Continent != &quot;Oceania&quot;) %&gt;% group_by(Continent) %&gt;% nest() %&gt;% mutate(Fit = map(data, ~lm(PPP_per_capita ~ FH_Total, data = .)), Est = map(Fit, broom::tidy, conf.int = TRUE)) %&gt;% unnest(Est) %&gt;% filter(term == &quot;FH_Total&quot;) %&gt;% select(Continent, Coef = estimate, Conf_lwr = conf.low, Conf_upr = conf.high) このPointrange_dfを用いて横軸は大陸（Continent）、縦軸には点推定値（Coef）と95%信頼区間（Conf_lwrとConf_upr）を出力します。ここで使う幾何オブジェクトはgeom_pointrange()です。横軸xと点推定値y、95%信頼区間の下限のymin、上限のymaxにマッピングします。エラーバー付き散布図を立てに並べたい場合はyとx、xmin、xmaxにマッピングします。 Pointrange_df %&gt;% ggplot() + geom_hline(yintercept = 0, linetype = 2) + geom_pointrange(aes(x = Continent, y = Coef, ymin = Conf_lwr, ymax = Conf_upr), size = 0.75) + labs(y = expression(paste(beta[1], &quot; with 95% CI&quot;))) + theme_bw(base_size = 12) ここでもう一つの次元を追加することもあるでしょう。たとえば、複数のモデルを比較した場合がそうかもしれません。以下のPointrange_df2について考えてみましょう。 Pointrange_df2 &lt;- tibble( Continent = rep(c(&quot;Asia&quot;, &quot;Europe&quot;, &quot;Africa&quot;, &quot;America&quot;), each = 2), Term = rep(c(&quot;Civic Liverty&quot;, &quot;Political Right&quot;), 4), Coef = c(207.747, 29.188, 1050.164, 1284.101, 110.025, 93.537, 581.4593, 646.9211), Conf_lwr = c(-385.221, -609.771, 692.204, 768.209, -12.648, -53.982, 262.056, 201.511), Conf_upr = c(800.716, 668.147, 1408.125, 1801.994, 232.697, 241.057, 900.863, 1092.331)) Pointrange_df2 ## # A tibble: 8 × 5 ## # Groups: Continent [4] ## Continent Term Coef Conf_lwr Conf_upr ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Civic Liberty 208. -385. 801. ## 2 Asia Political Right 29.2 -610. 668. ## 3 Europe Civic Liberty 1050. 692. 1408. ## 4 Europe Political Right 1285. 768. 1802. ## 5 Africa Civic Liberty 110. -12.6 233. ## 6 Africa Political Right 93.5 -54.0 241. ## 7 America Civic Liberty 581. 262. 901. ## 8 America Political Right 647. 202. 1092. このデータは以下の2つのモデルを大陸ごとに推定した\\(\\beta_1\\)と\\(\\gamma_1\\)の点推定値と95%信頼区間です。 \\[ \\begin{aligned} \\text{PPP per capita} &amp; = \\beta_0 + \\beta_1 \\cdot \\text{FH}\\_\\text{CL} + \\varepsilon \\\\ \\text{PPP per capita} &amp; = \\gamma_0 + \\gamma_1 \\cdot \\text{FH}\\_\\text{PR} + \\upsilon \\end{aligned} \\] どの説明変数を用いたかでエラーバーと点の色分けを行う場合、colorに対してTermをマッピングします。 Pointrange_df2 %&gt;% ggplot() + geom_hline(yintercept = 0, linetype = 2) + geom_pointrange(aes(x = Continent, y = Coef, ymin = Conf_lwr, ymax = Conf_upr, color = Term), size = 0.75) + labs(y = expression(paste(beta[1], &quot; and &quot;, gamma[1], &quot; with 95% CI&quot;)), color = &quot;&quot;) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) 何か違いますね。この2つのエラーバーと点の位置をずらす必要があるようです。これは3次元以上の棒グラフで使ったposition引数で調整可能です。今回は実引数としてposition_dodge(0.5)を指定してみましょう。 Pointrange_df2 %&gt;% ggplot() + geom_hline(yintercept = 0, linetype = 2) + geom_pointrange(aes(x = Continent, y = Coef, ymin = Conf_lwr, ymax = Conf_upr, color = Term), size = 0.75, position = position_dodge(0.5)) + labs(y = expression(paste(beta[1], &quot; and &quot;, gamma[1], &quot; with 95% CI&quot;)), color = &quot;&quot;) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) これで完成です。更に、\\(\\alpha = 0.05\\)水準で統計的に有意か否かを透明度で示し、透明度の凡例を非表示にしてみましょう。\\(\\alpha = 0.05\\)水準で統計的に有意か否かは95%信頼区間の上限と下限の積が0より大きいか否かで判定できます。ggplot()にデータを渡す前に統計的有意か否かを意味するSig変数を作成し、geom_pointrage()の内部ではalphaにSigをマッピングします。 Pointrange_df2 %&gt;% mutate(Sig = if_else(Conf_lwr * Conf_upr &gt; 0, &quot;Significant&quot;, &quot;Insignificant&quot;)) %&gt;% ggplot() + geom_hline(yintercept = 0, linetype = 2) + geom_pointrange(aes(x = Continent, y = Coef, ymin = Conf_lwr, ymax = Conf_upr, color = Term, alpha = Sig), size = 0.75, position = position_dodge(0.5)) + labs(y = expression(paste(beta[1], &quot; and &quot;, gamma[1], &quot; with 95% CI&quot;)), color = &quot;&quot;) + scale_alpha_manual(values = c(&quot;Significant&quot; = 1, &quot;Insignificant&quot; = 0.35)) + guides(alpha = FALSE) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) ## Warning: `guides(&lt;scale&gt; = FALSE)` is deprecated. Please use `guides(&lt;scale&gt; = ## &quot;none&quot;)` instead. 20.6 ロリーポップチャート ロリーポップチャートは棒グラフの特殊な形態であり、棒がロリーポップ（チュッパチャップス）の形をしているものを指します。したがって、2つの図は本質的に同じですが、棒が多い場合はロリーポップチャートを使うケースがあります。棒が非常に多い棒グラフの場合、図を不適切に縮小するとモアレが生じるケースがあるからです。 まず、Country_dfを用い、ヨーロッパ諸国の一人当たりPPP GDP（PPP_per_capita）の棒グラフを作るとします。PPP_per_capitaが欠損していないヨーロッパの国は46行であり、非常に棒が多い棒グラフになります。 Country_df %&gt;% filter(Continent == &quot;Europe&quot;) %&gt;% drop_na(PPP_per_capita) %&gt;% ggplot() + geom_bar(aes(y = Country, x = PPP_per_capita), stat = &quot;identity&quot;) + labs(x = &quot;一人あたり購買力平価GDP&quot;, y = &quot;国&quot;) + theme_bw(base_size = 12) ここで登場するのがロリーポップチャートです。ロリーポップチャートの構成要素は棒とキャンディーの部分です。棒は線になるためgeom_segement()を、キャンディーは散布図geom_point()を使います。散布図については既に第18章で説明しましたので、ここではgeom_segment()について説明します。 geom_segment()は直線を引く幾何オブジェクトであり、線の起点（xとy）と終点（xendとyend）に対してマッピングをする必要があります。横軸上の起点は0、縦軸上の起点はCountryです。そして横軸上の終点はPPP_per_capita、縦軸上のそれはCountryです。縦軸上の起点と終点が同じということは水平線を引くことになります。 geom_segment()で水平線を描いたら、次は散布図をオーバーラップさせます。点の横軸上の位置はPPP_per_capita、縦軸上の位置はCountryです。 Country_df %&gt;% filter(Continent == &quot;Europe&quot;) %&gt;% drop_na(PPP_per_capita) %&gt;% ggplot() + geom_segment(aes(y = Country, yend = Country, x = 0, xend = PPP_per_capita)) + geom_point(aes(y = Country, x = PPP_per_capita), color = &quot;orange&quot;) + labs(x = &quot;一人あたり購買力平価GDP (USD)&quot;, y = &quot;国&quot;) + theme_bw(base_size = 12) + theme(panel.grid.major.y = element_blank(), panel.border = element_blank(), axis.ticks.y = element_blank()) これで完成です。もし一人当たりPPP GDP順で並べ替えたい場合はfct_reorder()を使います。CountryをPPP_per_capitaの低い方を先にくるようにするなら、fct_reorder(Country, PPP_per_capita)です。縦に並ぶの棒グラフなら最初に来る水準が下に位置されます。もし、順番を逆にしたいなら、更にfct_rev()で水準の順番を逆転させます。 Country_df %&gt;% filter(Continent == &quot;Europe&quot;) %&gt;% drop_na(PPP_per_capita) %&gt;% mutate(Country = fct_reorder(Country, PPP_per_capita)) %&gt;% ggplot() + geom_segment(aes(y = Country, yend = Country, x = 0, xend = PPP_per_capita)) + geom_point(aes(y = Country, x = PPP_per_capita), color = &quot;orange&quot;) + labs(x = &quot;一人あたり購買力平価GDP (USD)&quot;, y = &quot;国&quot;) + theme_bw(base_size = 12) + theme(panel.grid.major.y = element_blank(), panel.border = element_blank(), axis.ticks.y = element_blank()) ロリーポップロリーポップチャートで次元を追加するには点（キャンディー）の色分けが考えられます。たとえば、OECD加盟国か否かの次元を追加する場合、geom_point()においてcolorをマッピングするだけです。 Country_df %&gt;% filter(Continent == &quot;Europe&quot;) %&gt;% drop_na(PPP_per_capita) %&gt;% mutate(Country = fct_reorder(Country, PPP_per_capita), OECD = if_else(OECD == 1, &quot;OECD&quot;, &quot;non-OECD&quot;), OECD = factor(OECD, levels = c(&quot;OECD&quot;, &quot;non-OECD&quot;))) %&gt;% ggplot() + geom_segment(aes(y = Country, yend = Country, x = 0, xend = PPP_per_capita)) + geom_point(aes(y = Country, x = PPP_per_capita, color = OECD)) + scale_color_manual(values = c(&quot;OECD&quot; = &quot;orange&quot;, &quot;non-OECD&quot; = &quot;royalblue&quot;)) + labs(x = &quot;一人あたり購買力平価GDP (USD)&quot;, y = &quot;国&quot;, color = &quot;&quot;) + theme_bw(base_size = 12) + theme(panel.grid.major.y = element_blank(), panel.border = element_blank(), axis.ticks.y = element_blank(), legend.position = &quot;bottom&quot;) ファセット分割ももちろんできますが、この場合、OECD加盟国の一人当たりPPP GDPが相対的に高いことを示すなら、一つのファセットにまとめた方が良いでしょう。 以下のようにロリーポップを横に並べることもできますが、棒の数が多いケースがほとんどであるロリーポップチャートではラベルの回転が必要になるため、読みにくくなるかも知れません。 Country_df %&gt;% filter(Continent == &quot;Europe&quot;) %&gt;% drop_na(PPP_per_capita) %&gt;% mutate(Country = fct_reorder(Country, PPP_per_capita), Country = fct_rev(Country)) %&gt;% ggplot() + geom_segment(aes(x = Country, xend = Country, y = 0, yend = PPP_per_capita)) + geom_point(aes(x = Country, y = PPP_per_capita), color = &quot;orange&quot;) + labs(x = &quot;国&quot;, y = &quot;一人あたり購買力平価GDP (USD)&quot;) + theme_bw(base_size = 12) + theme(panel.grid.major.y = element_blank(), panel.border = element_blank(), axis.ticks.y = element_blank(), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) 20.7 平滑化ライン 2次元平面上に散布図をプロットし、二変数間の関係を一本の線で要約するのは平滑化ラインです。{ggplot2}ではgeom_smooth()幾何オブジェクトを重ねることで簡単に平滑化ラインをプロットすることができます。まずは、横軸をフリーダムハウス・スコア（FH_Total）、縦軸を一人当たり購買力平価GDP（PPP_per_capita）にした散布図を出力し、その上に平滑化ラインを追加してみましょう。geom_smooth()にもマッピングが必要で、aes()の内部にxとyをマッピングします。今回はgeom_point()とgeom_smooth()が同じマッピング情報を共有するため、ggplot()内部でマッピングします。 Country_df %&gt;% ggplot(aes(x = FH_Total, y = PPP_per_capita)) + geom_point() + geom_smooth() + labs(x = &quot;Freedom House Score&quot;, y = &quot;PPP per capita (USD)&quot;) + scale_y_continuous(breaks = seq(0, 120000, by = 10000), labels = seq(0, 120000, by = 10000)) + theme_minimal(base_size = 12) ## `geom_smooth()` using method = &#39;loess&#39; and formula &#39;y ~ x&#39; ## Warning: Removed 8 rows containing non-finite values (stat_smooth). ## Warning: Removed 8 rows containing missing values (geom_point). 青い線が平滑化ライン、網掛けの領域が95%信頼区間です。この線はLOESS (LOcal Estimated Scatterplot Smoothing)と呼ばれる非線形平滑化ラインです。どのようなラインを引くかはmethod引数で指定しますが、このmethod既定値が\"loess\"です。これを見るとフリーダムハウス・スコアが75以下の国では国の自由度と所得間の関係があまり見られませんが、75からは正の関係が確認できます。 LOESS平滑化の場合、span引数を使って滑らかさを調整することができます。spanの既定値は0.75ですが、これが小さいほど散布図によりフィットしたラインが引かれ、よりギザギザな線になります。たとえば、spanを0.25にすると以下のようなグラフが得られます。 Country_df %&gt;% ggplot(aes(x = FH_Total, y = PPP_per_capita)) + geom_point() + geom_smooth(method = &quot;loess&quot;, span = 0.25) + labs(x = &quot;Freedom House Score&quot;, y = &quot;PPP per capita (USD)&quot;) + scale_y_continuous(breaks = seq(0, 120000, by = 10000), labels = seq(0, 120000, by = 10000)) + theme_minimal(base_size = 12) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 8 rows containing non-finite values (stat_smooth). ## Warning: Removed 8 rows containing missing values (geom_point). 他にも定番の回帰直線を引くこともできます。methodの実引数を\"lm\"に変えるだけです。 Country_df %&gt;% ggplot(aes(x = FH_Total, y = PPP_per_capita)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + labs(x = &quot;Freedom House Score&quot;, y = &quot;PPP per capita (USD)&quot;) + scale_y_continuous(breaks = seq(0, 120000, by = 10000), labels = seq(0, 120000, by = 10000)) + theme_minimal(base_size = 12) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 8 rows containing non-finite values (stat_smooth). ## Warning: Removed 8 rows containing missing values (geom_point). 信頼区間は既定値だと95%信頼区間が表示されますが、level引数で調整することができます。たとえば、99.9%信頼区間を表示したい場合、level = 0.999を指定します。 Country_df %&gt;% ggplot(aes(x = FH_Total, y = PPP_per_capita)) + geom_point() + geom_smooth(method = &quot;lm&quot;, level = 0.999) + labs(x = &quot;Freedom House Score&quot;, y = &quot;PPP per capita (USD)&quot;) + scale_y_continuous(breaks = seq(0, 120000, by = 10000), labels = seq(0, 120000, by = 10000)) + theme_minimal(base_size = 12) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 8 rows containing non-finite values (stat_smooth). ## Warning: Removed 8 rows containing missing values (geom_point). 信頼区間を消したい場合はse = FALSEを指定します（既定値はTRUE）。 Country_df %&gt;% ggplot(aes(x = FH_Total, y = PPP_per_capita)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + labs(x = &quot;Freedom House Score&quot;, y = &quot;PPP per capita (USD)&quot;) + scale_y_continuous(breaks = seq(0, 120000, by = 10000), labels = seq(0, 120000, by = 10000)) + theme_minimal(base_size = 12) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 8 rows containing non-finite values (stat_smooth). ## Warning: Removed 8 rows containing missing values (geom_point). 最後にデータのサブセットごとに回帰直線を引く方法について説明します。散布図で色分けを行う場合、aes()内でcolor引数を指定しますが、これだけで十分です。今回はこれまでの散布図をOECD加盟有無ごとに色分けし、それぞれ別の回帰直線を重ねてみましょう。回帰直線も色分けしたいのでcolor引数で次元を増やす必要があり、これはgeom_point()と共通であるため、ggplot()内でマッピングします。 Country_df %&gt;% mutate(OECD = if_else(OECD == 1, &quot;加盟国&quot;, &quot;非加盟国&quot;)) %&gt;% ggplot(aes(x = FH_Total, y = PPP_per_capita, color = OECD)) + geom_point() + geom_smooth(method = &quot;lm&quot;) + labs(x = &quot;Freedom House Score&quot;, y = &quot;PPP per capita (USD)&quot;) + scale_y_continuous(breaks = seq(0, 120000, by = 10000), labels = seq(0, 120000, by = 10000)) + coord_cartesian(ylim = c(0, 120000)) + theme_bw(base_size = 12) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 8 rows containing non-finite values (stat_smooth). ## Warning: Removed 8 rows containing missing values (geom_point). これを見ると、国の自由度と所得の間に関係が見られるのはOECD加盟国で、非加盟国では非常に関係が弱いことが分かります。 あまりいい方法ではないと思いますが、散布図は色（color）で分け、回帰直線は線の種類（linetype）で分けるならどうすれば良いでしょうか。この場合はcolorはgeom_point()内部で、linetypeはgeom_smooth()でマッピングします。 Country_df %&gt;% mutate(OECD = if_else(OECD == 1, &quot;加盟国&quot;, &quot;非加盟国&quot;)) %&gt;% ggplot(aes(x = FH_Total, y = PPP_per_capita)) + geom_point(aes(color = OECD)) + geom_smooth(aes(linetype = OECD), method = &quot;lm&quot;, color = &quot;black&quot;) + labs(x = &quot;Freedom House Score&quot;, y = &quot;PPP per capita (USD)&quot;) + scale_y_continuous(breaks = seq(0, 120000, by = 10000), labels = seq(0, 120000, by = 10000)) + coord_cartesian(ylim = c(0, 120000)) + theme_bw(base_size = 12) ## `geom_smooth()` using formula &#39;y ~ x&#39; ## Warning: Removed 8 rows containing non-finite values (stat_smooth). ## Warning: Removed 8 rows containing missing values (geom_point). {ggplot2}が提供する平滑化ラインにはLOESSと回帰直線以外にも\"glm\"や\"gam\"などがります。詳細はRコンソール上で?geom_smoothを入力し、ヘルプを参照してください。 20.8 ヒートマップ 20.8.1 2つの離散変数の分布を表すヒートマップ ヒートマップ（heat map）には2つの使い方があります。まずは、離散変数\\(\\times\\)離散変数の同時分布を示す時です。これは後ほど紹介するモザイク・プロットと目的は同じですが、モザイク・プロットはセルの面積で密度や度数を表すに対し、ヒートマップは主に色で密度や度数を表します。 ここでは一人当たり購買力平価GDP（PPP_per_capita）を「1万ドル未満」、「1万ドル以上・2万ドル未満」、「2万ドル以上、3万ドル未満」、「3万ドル以上」の離散変数に変換し、大陸ごとの国家数をヒートマップとして示してみたいと思います。まずは、変数のリコーディングをし、全てfactor化します。最後に国家名（Country）、大陸（Continent）、所得（Income）、フリーダム・ハウス・スコア（FH_Total）、人間開発指数（HDI_2018）列のみ抽出し、Heatmap_dfという名のオブジェクトとして格納しておきます。 Heatmap_df &lt;- Country_df %&gt;% filter(!is.na(PPP_per_capita)) %&gt;% mutate(Continent = recode(Continent, &quot;Africa&quot; = &quot;アフリカ&quot;, &quot;America&quot; = &quot;アメリカ&quot;, &quot;Asia&quot; = &quot;アジア&quot;, &quot;Europe&quot; = &quot;ヨーロッパ&quot;, .default = &quot;オセアニア&quot;), Continent = factor(Continent, levels = c(&quot;アフリカ&quot;, &quot;アメリカ&quot;, &quot;アジア&quot;, &quot;ヨーロッパ&quot;, &quot;オセアニア&quot;)), Income = case_when(PPP_per_capita &lt; 10000 ~ &quot;1万ドル未満&quot;, PPP_per_capita &lt; 20000 ~ &quot;1万ドル以上\\n2万ドル未満&quot;, PPP_per_capita &lt; 30000 ~ &quot;2万ドル以上\\n3万ドル未満&quot;, TRUE ~ &quot;3万ドル以上&quot;), Income = factor(Income, levels = c(&quot;1万ドル未満&quot;, &quot;1万ドル以上\\n2万ドル未満&quot;, &quot;2万ドル以上\\n3万ドル未満&quot;, &quot;3万ドル以上&quot;))) %&gt;% select(Country, Continent, Income, FH_Total, HDI_2018) Heatmap_df ## # A tibble: 178 × 5 ## Country Continent Income FH_Total HDI_2018 ## &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanistan アジア &quot;1万ドル未満&quot; 27 0.496 ## 2 Albania ヨーロッパ &quot;1万ドル以上\\n2万ドル未満&quot; 67 0.791 ## 3 Algeria アフリカ &quot;1万ドル以上\\n2万ドル未満&quot; 34 0.759 ## 4 Angola アフリカ &quot;1万ドル未満&quot; 32 0.574 ## 5 Antigua and Barbuda アメリカ &quot;2万ドル以上\\n3万ドル未満&quot; 85 0.776 ## 6 Argentina アメリカ &quot;2万ドル以上\\n3万ドル未満&quot; 85 0.83 ## 7 Armenia ヨーロッパ &quot;1万ドル以上\\n2万ドル未満&quot; 53 0.76 ## 8 Australia オセアニア &quot;3万ドル以上&quot; 97 0.938 ## 9 Austria ヨーロッパ &quot;3万ドル以上&quot; 93 0.914 ## 10 Azerbaijan ヨーロッパ &quot;1万ドル以上\\n2万ドル未満&quot; 10 0.754 ## # … with 168 more rows 次はgroup_by()とsummarise()を使って、各カテゴリーに属するケース数を計算し、Nという名の列として追加します。 Heatmap_df1 &lt;- Heatmap_df %&gt;% group_by(Continent, Income) %&gt;% summarise(N = n(), .groups = &quot;drop&quot;) Heatmap_df1 ## # A tibble: 18 × 3 ## Continent Income N ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 アフリカ &quot;1万ドル未満&quot; 41 ## 2 アフリカ &quot;1万ドル以上\\n2万ドル未満&quot; 9 ## 3 アフリカ &quot;2万ドル以上\\n3万ドル未満&quot; 2 ## 4 アメリカ &quot;1万ドル未満&quot; 10 ## 5 アメリカ &quot;1万ドル以上\\n2万ドル未満&quot; 14 ## 6 アメリカ &quot;2万ドル以上\\n3万ドル未満&quot; 6 ## 7 アメリカ &quot;3万ドル以上&quot; 5 ## 8 アジア &quot;1万ドル未満&quot; 17 ## 9 アジア &quot;1万ドル以上\\n2万ドル未満&quot; 10 ## 10 アジア &quot;2万ドル以上\\n3万ドル未満&quot; 3 ## 11 アジア &quot;3万ドル以上&quot; 11 ## 12 ヨーロッパ &quot;1万ドル未満&quot; 1 ## 13 ヨーロッパ &quot;1万ドル以上\\n2万ドル未満&quot; 10 ## 14 ヨーロッパ &quot;2万ドル以上\\n3万ドル未満&quot; 7 ## 15 ヨーロッパ &quot;3万ドル以上&quot; 28 ## 16 オセアニア &quot;1万ドル未満&quot; 1 ## 17 オセアニア &quot;1万ドル以上\\n2万ドル未満&quot; 1 ## 18 オセアニア &quot;3万ドル以上&quot; 2 これでデータの準備は終わりました。ヒートマップを作成する幾何オブジェクトはgeom_tile()です。同時分布を示したい変数を、それぞれxとyにマッピングし、密度、または度数を表す変数をfillにマッピングします。ここでは横軸を大陸（Continent）、縦軸を一人当たり購買力平価GDP（Income）とし、fillにはN変数をマッピングします。 Heatmap_df1 %&gt;% ggplot() + geom_tile(aes(x = Continent, y = Income, fill = N)) + labs(x = &quot;大陸&quot;, y = &quot;一人当たり購買力平価GDP（ドル）&quot;, fill = &quot;国家数&quot;) + theme_bw(base_size = 12) + theme(panel.grid = element_blank()) # グリッドラインを消す 明るいほどカテゴリーに属するケースが多く、暗いほど少ないことを意味します。これを見ると世界で最も多くの割合を占めているのは、一人当たり購買力平価GDPが1万ドル未満のアフリカの国で、次は一人当たり購買力平価GDPが3万ドル以上のヨーロッパの国であることが分かります。欠損している（ケース数が0）セルは白の空白となります。 色をカスタマイズするにはscale_fill_gradient()です。これは第19章で紹介しましたscale_color_gradient()と使い方は同じです。scale_fill_gradient()は中間点なし、scale_fill_gradient2()は中間点ありの場合に使いますが、ここでは度数が小さい場合はcornsilk色を、大きい場合はbrown3色を使います。それぞれlowとhighに色を指定するだけです。 Heatmap_df1 %&gt;% ggplot() + geom_tile(aes(x = Continent, y = Income, fill = N)) + labs(x = &quot;大陸&quot;, y = &quot;一人当たり購買力平価GDP（ドル）&quot;, fill = &quot;国家数&quot;) + scale_fill_gradient(low = &quot;cornsilk&quot;, high = &quot;brown3&quot;) + theme_bw(base_size = 12) + theme(panel.grid = element_blank()) # グリッドラインを消す 気のせいかも知れませんが、先ほどよりは読みやすくなったような気がしますね。 20.8.2 離散変数\\(\\times\\)離散変数における連続変数の値を示すヒートマップ 次は、離散変数\\(\\times\\)離散変数における連続変数の値を示すヒートマップを作ってみましょう。ヒートマップにおけるそれぞれのタイル（tile）は横軸上の位置と縦軸上の位置情報を持ち、これは前回と同様、離散変数でマッピングされます。そして、タイルの色は何らかの連続変数にマッピングされます。前回作成しましたヒートマップは度数、または密度であり、これも実は連続変数だったので、図の作り方は本質的には同じです。 ここでは大陸と所得ごとに人間開発指数の平均値を表すヒートマップを作ってみましょう。大陸（Continent）と所得（Income）でグループ化し、人間開発指数（HDI_2018）の平均値を計算したものをHeatmap_df2という名のオブジェクトとして格納します。 Heatmap_df2 &lt;- Heatmap_df %&gt;% group_by(Continent, Income) %&gt;% summarise(HDI = mean(HDI_2018, na.rm = TRUE), .groups = &quot;drop&quot;) Heatmap_df2 ## # A tibble: 18 × 3 ## Continent Income HDI ## &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 アフリカ &quot;1万ドル未満&quot; 0.510 ## 2 アフリカ &quot;1万ドル以上\\n2万ドル未満&quot; 0.697 ## 3 アフリカ &quot;2万ドル以上\\n3万ドル未満&quot; 0.798 ## 4 アメリカ &quot;1万ドル未満&quot; 0.638 ## 5 アメリカ &quot;1万ドル以上\\n2万ドル未満&quot; 0.752 ## 6 アメリカ &quot;2万ドル以上\\n3万ドル未満&quot; 0.806 ## 7 アメリカ &quot;3万ドル以上&quot; 0.841 ## 8 アジア &quot;1万ドル未満&quot; 0.624 ## 9 アジア &quot;1万ドル以上\\n2万ドル未満&quot; 0.730 ## 10 アジア &quot;2万ドル以上\\n3万ドル未満&quot; 0.818 ## 11 アジア &quot;3万ドル以上&quot; 0.872 ## 12 ヨーロッパ &quot;1万ドル未満&quot; 0.711 ## 13 ヨーロッパ &quot;1万ドル以上\\n2万ドル未満&quot; 0.776 ## 14 ヨーロッパ &quot;2万ドル以上\\n3万ドル未満&quot; 0.827 ## 15 ヨーロッパ &quot;3万ドル以上&quot; 0.902 ## 16 オセアニア &quot;1万ドル未満&quot; 0.543 ## 17 オセアニア &quot;1万ドル以上\\n2万ドル未満&quot; 0.724 ## 18 オセアニア &quot;3万ドル以上&quot; 0.930 作図の方法は前回と同じですが、今回はタイルの色塗り（fill）を人間開発指数の平均値（HDI）でマッピングする必要があります。他の箇所は同じコードでも良いですが、ここでは色塗りの際、中間点を指定してみましょう。たとえば人間開発指数が0.75なら色をcornsilk色とし、これより低いっほどcornflowerblue色に、高いほどbrown3色になるように指定します。中間点を持つグラデーション色塗りはscale_fill_gradient2()で調整することができます。使い方はscale_fill_gradient()とほぼ同じですが、中間点の色（mid）と中間点の値（midpoint）をさらに指定する必要があります。 Heatmap_df2 %&gt;% ggplot() + geom_tile(aes(x = Continent, y = Income, fill = HDI)) + labs(x = &quot;大陸&quot;, y = &quot;一人当たり購買力平価GDP（ドル）&quot;, fill = &quot;人間開発指数の平均値 (2018)&quot;) + scale_fill_gradient2(low = &quot;cornflowerblue&quot;, mid = &quot;cornsilk&quot;, high = &quot;brown3&quot;, midpoint = 0.75) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;, panel.grid = element_blank()) 20.9 等高線図 ヒートマップを使えば、離散変数\\(\\times\\)離散変数の同時分布を可視化することは出来ますが、連続変数\\(\\times\\)連続変数の同時分布を可視化するには限界があります。むろん、一つ一つのタイルを小さくすることも出来ますが、効率的な方法ではないでしょう。ここで活躍するのが等高線図 (contour plot) です。 たとえば、Country_dfのFH_TotalとHDI_2018の分布は散布図を通じて可視化することができます。 Country_df %&gt;% ggplot() + geom_point(aes(x = FH_Total, y = HDI_2018)) + labs(x = &quot;フリーダム・ハウス・スコア&quot;, y = &quot;人間開発指数 (2018)&quot;) + theme_minimal(base_size = 12) 右上に点が集まっていることから、密度の高い箇所だと考えられます。この密度を示す等高線図の幾何オブジェクトはgeom_density_2d()です。マッピング要素はgeom_point()と同じなので、マッピングはggplot()内で行い、geom_density_2d()レイヤーを使いしてみましょう。 Country_df %&gt;% ggplot(aes(x = FH_Total, y = HDI_2018)) + geom_point() + geom_density_2d() + labs(x = &quot;フリーダム・ハウス・スコア&quot;, y = &quot;人間開発指数 (2018)&quot;) + theme_minimal(base_size = 12) 密度に応じて色塗りをする場合はgeom_density_2d()の代わりにgeom_density_2d_filled()を使います。 Country_df %&gt;% ggplot(aes(x = FH_Total, y = HDI_2018)) + geom_density_2d_filled() + labs(x = &quot;フリーダム・ハウス・スコア&quot;, y = &quot;人間開発指数 (2018)&quot;, fill = &quot;密度&quot;) + theme_minimal(base_size = 12) geom_density_2d_filled()オブジェクトの後にgeom_density_2d()オブジェクトを重ねると、区間の区画線を追加することもできます。 Country_df %&gt;% ggplot(aes(x = FH_Total, y = HDI_2018)) + geom_density_2d_filled() + geom_density_2d(color = &quot;black&quot;) + labs(x = &quot;フリーダム・ハウス・スコア&quot;, y = &quot;人間開発指数 (2018)&quot;, fill = &quot;密度&quot;) + theme_minimal(base_size = 12) 色が気に入らない場合、自分で調整することも可能です。scale_fill_manual()で各区間ごとの色を指定することもできませんが、あまり効率的ではありません。ここではscale_fill_brewer()関数を使って、ColorBrewerのパレットを使ってみましょう。引数なしでも使えますが、既定値のパレットは区間が9つまで対応します。今回の等高線図は全部で10区間ですので、あまり適切ではありません。ここでは11区間まで対応可能な\"Spectral\"パレットを使いますが、これはpalette引数で指定できます。 Country_df %&gt;% ggplot(aes(x = FH_Total, y = HDI_2018)) + geom_density_2d_filled() + scale_fill_brewer(palette = &quot;Spectral&quot;) + labs(x = &quot;フリーダム・ハウス・スコア&quot;, y = &quot;人間開発指数 (2018)&quot;, fill = &quot;密度&quot;) + theme_minimal(base_size = 12) paletteで指定可能なカラーパレットの一覧は{RColorBrewer}のdisplay.brewer.all()関数で確認することが出来ます。各パレットが何区間まで対応できるかを見てから自分でパレットを作成することも可能ですが、詳細はネット上の各種記事を参照してください。 RColorBrewer::display.brewer.all() 図 20.1: {RColorBrewer}が提供するパレート一覧 20.10 地図 20.10.1 世界地図 {ggplot2}で地図をプロットする方法は色々あります。理想としては各国政府が提供する地図データをダウンロードし、それを読み込み・加工してプロットすることでしょうが、ここではパッケージを使ったマッピングについて紹介します。 今回使用するパッケージは{rnaturalearth}、{rnaturalearthdata}、{rgeos}です。他にも使うパッケージはありますが、世界地図ならとりあえずこれで十分です。 pacman::p_load(rnaturalearth, rnaturalearthdata, rgeos) 世界地図を読み込む関数は{rnaturalearth}が提供するne_countries()です。とりあえず指定する引数はscaleとretunrclassです。scaleは地図の解像度であり、世界地図なら\"small\"で十分です。もう少し拡大される大陸地図なら\"medium\"が、一国だけの地図なら\"large\"が良いかも知れません。reutrnclassは\"sf\"と指定します。今回は低解像度の世界地図をsfクラスで読み込んでみましょう。 world_map &lt;- ne_countries(scale = &quot;small&quot;, returnclass = &quot;sf&quot;) class(world_map) ## [1] &quot;sf&quot; &quot;data.frame&quot; クラスはdata.frameとsfであり、実際、world_mapを出力してみると、見た目がデータフレームであることが分かります。地図の出力はgeom_sf()幾何オブジェクトを使用します。とりあえず、やってみましょう。 world_map %&gt;% ggplot() + geom_sf() + theme_void() # 何もないテーマを指定する。ここはお好みで もし、各国の人口に応じて色塗りをする場合はどうすれば良いでしょうか。実は、今回使用するデータがデータフレーム形式であることを考えると、これまでの{ggplot2}の使い方とあまり変わりません。{rnaturalearth}から読み込んだデータには既にpop_estという各国の人口データが含まれて負います。この値に応じて色塗りを行うため、geom_sf()内にfill = pop_estでマッピングするだけです。 他にも自分で構築したデータがあるなら、データを結合して使用すれば良いでしょう。これについては後述します。 world_map %&gt;% ggplot() + geom_sf(aes(fill = pop_est)) + # 人口が少ない国はcornflowerblue色に、多い国はbrown3色とする scale_fill_gradient(low = &quot;cornflowerblue&quot;, high = &quot;brown3&quot;) + labs(fill = &quot;人口&quot;) + theme_void() もし、世界でなく一部の地域だけを出力するなら、coord_sf()で座標系を調整します。東アジアと東南アジアの一部を出力したいとします。この場合、経度は90度から150度まで、緯度は10度から50度に絞ることになります。経度はxlimで、緯度はylimで調整します。 world_map %&gt;% ggplot() + geom_sf(aes(fill = pop_est)) + scale_fill_gradient(low = &quot;cornflowerblue&quot;, high = &quot;brown3&quot;) + labs(fill = &quot;人口&quot;) + coord_sf(xlim = c(90, 150), ylim = c(10, 50)) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) 他にもne_countries()内にcontinent引数を指定し、特定の大陸だけを読み込むことで可能です。ここではアジアの国のみを抽出し、asia_mapという名のオブジェクトとして格納します。解像度は中程度とします。 asia_map &lt;- ne_countries(scale = &quot;medium&quot;, continent = &quot;Asia&quot;, returnclass = &quot;sf&quot;) asia_map %&gt;% ggplot() + # 所得グループで色塗り geom_sf(aes(fill = income_grp)) + theme_void() + labs(fill = &quot;Income Group&quot;) アジアの中から更に東アジアに絞りたい場合はfilter()を使用し、subregion列を基準に抽出することも可能です。 asia_map %&gt;% filter(subregion == &quot;Eastern Asia&quot;) %&gt;% ggplot() + geom_sf(aes(fill = income_grp)) + theme_void() + labs(fill = &quot;Income Group&quot;) subregionの値は以下のように確認可能です。 unique(asia_map$subregion) ## [1] &quot;Southern Asia&quot; &quot;Western Asia&quot; ## [3] &quot;South-Eastern Asia&quot; &quot;Eastern Asia&quot; ## [5] &quot;Seven seas (open ocean)&quot; &quot;Central Asia&quot; これまで使用してきたデータがデータフレームと同じ見た目をしているため、{dplyr}を用いたデータハンドリングも可能です。たとえば、人口を連続変数としてでなく、factor型に変換してからマッピングをしてみましょう。 asia_map %&gt;% mutate(Population = case_when(pop_est &lt; 10000000 ~ &quot;1千万未満&quot;, pop_est &lt; 50000000 ~ &quot;5千万未満&quot;, pop_est &lt; 100000000 ~ &quot;1億未満&quot;, pop_est &lt; 500000000 ~ &quot;5億未満&quot;, TRUE ~ &quot;5億以上&quot;), Population = factor(Population, levels = c(&quot;1千万未満&quot;, &quot;5千万未満&quot;, &quot;1億未満&quot;, &quot;5億未満&quot;, &quot;5億以上&quot;))) %&gt;% ggplot() + geom_sf(aes(fill = Population)) + scale_fill_brewer(palette = &quot;Blues&quot;, drop = FALSE) + labs(fill = &quot;人口&quot;) + theme_void() + theme(legend.position = &quot;bottom&quot;) scale_fill_brewer()のpalette引数は等高線図のときに紹介しましたパレート一覧を参照してください。 20.10.2 日本地図（全体） 次は日本地図の出力についてです。日本全土だけを出力するなら、これまで使いましたne_countriesにcountry引数を指定するだけで使えます。たとえば、日本の地図だけなら、country = \"Japan\"を指定します。 ne_countries(scale = &quot;small&quot;, country = &quot;Japan&quot;, returnclass = &quot;sf&quot;) %&gt;% ggplot() + geom_sf() + theme_void() # 空っぽのテーマ これだと、物足りない感があるので、もう少し高解像度の地図にしてみましょう。高解像度の地図データを読み込む際はscale = \"large\"を指定します。 ne_countries(scale = &quot;large&quot;, country = &quot;Japan&quot;, returnclass = &quot;sf&quot;) %&gt;% ggplot() + geom_sf() + theme_void() # 空っぽのテーマ ただ、日本地図を出すという場合、多くは都道府県レベルでマッピングが目的でしょう。世界地図のマッピングならこれで問題ありませんが、一国だけなら、その下の自治体の境界線も必要です。したがって、先ほど使用しましたパッケージのより高解像度の地図が含まれている{rnaturalearthhires}をインストールし、読み込みましょう。2022年Mar月16日現在、{rnaturalearthhires}はCRANに登録されておらず、GitHubのropensciレポジトリーのみで公開されているため、今回は{pacman}のp_load()でなく、p_load_gh()を使用します。 pacman::p_load_gh(&quot;ropensci/rnaturalearthhires&quot;) 地図データの抽出にはne_states()関数を使用します。第一引数として国家名を指定し、地図データのクラスはsfとします。抽出したデータの使い方は世界地図の時と同じです。 Japan_Map &lt;- ne_states(&quot;Japan&quot;, returnclass = &quot;sf&quot;) Japan_Map %&gt;% ggplot() + geom_sf() + theme_void() 今回は各都道府県を人口密度ごとに色塗りをしてみましょう。ne_states()で読み込んだデータに人口密度のデータはないため、別途のデータと結合する必要があります。筆者が予め作成しておいたデータを読み込み、中身を確認してみます。 Japan_Density &lt;- read_csv(&quot;Data/Japan_Density.csv&quot;) Japan_Density ## # A tibble: 47 × 3 ## Code Name Density ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 北海道 66.6 ## 2 2 青森県 128. ## 3 3 岩手県 79.2 ## 4 4 宮城県 316. ## 5 5 秋田県 82.4 ## 6 6 山形県 115. ## 7 7 福島県 133 ## 8 8 茨城県 470. ## 9 9 栃木県 302. ## 10 10 群馬県 305. ## # … with 37 more rows 各都道府県の人口密度がついております、左側のCodeは何でしょうか。これは各都道府県のISOコードであり、このコードをキー変数としてデータを結合することとなります。各都道府県のコードは国土交通省のホームページから確認可能です。 それではデータを結合してみましょう。ne_states()で読み込んだデータの場合、地域のコードはiso_3166_2という列に格納されています。 Japan_Map$iso_3166_2 ## [1] &quot;JP-46&quot; &quot;JP-44&quot; &quot;JP-40&quot; &quot;JP-41&quot; &quot;JP-42&quot; &quot;JP-43&quot; &quot;JP-45&quot; &quot;JP-36&quot; &quot;JP-37&quot; ## [10] &quot;JP-38&quot; &quot;JP-39&quot; &quot;JP-32&quot; &quot;JP-35&quot; &quot;JP-31&quot; &quot;JP-28&quot; &quot;JP-26&quot; &quot;JP-18&quot; &quot;JP-17&quot; ## [19] &quot;JP-16&quot; &quot;JP-15&quot; &quot;JP-06&quot; &quot;JP-05&quot; &quot;JP-02&quot; &quot;JP-03&quot; &quot;JP-04&quot; &quot;JP-07&quot; &quot;JP-08&quot; ## [28] &quot;JP-12&quot; &quot;JP-13&quot; &quot;JP-14&quot; &quot;JP-22&quot; &quot;JP-23&quot; &quot;JP-24&quot; &quot;JP-30&quot; &quot;JP-27&quot; &quot;JP-33&quot; ## [37] &quot;JP-34&quot; &quot;JP-01&quot; &quot;JP-47&quot; &quot;JP-10&quot; &quot;JP-20&quot; &quot;JP-09&quot; &quot;JP-21&quot; &quot;JP-25&quot; &quot;JP-11&quot; ## [46] &quot;JP-19&quot; &quot;JP-29&quot; こちらは文字列となっていますね。これを左から4番目の文字から切り取り、数値型に変換します。変換したコードは結合のためにCodeという名の列として追加しましょう。 Japan_Map &lt;- Japan_Map %&gt;% mutate(Code = str_sub(iso_3166_2, 4), Code = as.numeric(Code)) Japan_Map$Code ## [1] 46 44 40 41 42 43 45 36 37 38 39 32 35 31 28 26 18 17 16 15 6 5 2 3 4 ## [26] 7 8 12 13 14 22 23 24 30 27 33 34 1 47 10 20 9 21 25 11 19 29 続いて、Japan_MapとJapan_DensityをCode列をキー変数として結合します。データの中身を確認すると、Density列が最後(の直前)の列に追加されたことが分かります。 Japan_Map &lt;- left_join(Japan_Map, Japan_Density, by = &quot;Code&quot;) Japan_Map ## Simple feature collection with 47 features and 86 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: 122.9382 ymin: 24.2121 xmax: 153.9856 ymax: 45.52041 ## Geodetic CRS: SOURCECRS ## First 10 features: ## featurecla scalerank adm1_code diss_me iso_3166_2 wikipedia iso_a2 ## 1 Admin-1 scale rank 2 JPN-3501 3501 JP-46 &lt;NA&gt; JP ## 2 Admin-1 scale rank 6 JPN-1835 1835 JP-44 &lt;NA&gt; JP ## 3 Admin-1 scale rank 6 JPN-1829 1829 JP-40 &lt;NA&gt; JP ## 4 Admin-1 scale rank 6 JPN-1827 1827 JP-41 &lt;NA&gt; JP ## 5 Admin-1 scale rank 2 JPN-3500 3500 JP-42 &lt;NA&gt; JP ## 6 Admin-1 scale rank 6 JPN-1830 1830 JP-43 &lt;NA&gt; JP ## 7 Admin-1 scale rank 6 JPN-1831 1831 JP-45 &lt;NA&gt; JP ## 8 Admin-1 scale rank 6 JPN-1836 1836 JP-36 &lt;NA&gt; JP ## 9 Admin-1 scale rank 6 JPN-1833 1833 JP-37 &lt;NA&gt; JP ## 10 Admin-1 scale rank 6 JPN-1832 1832 JP-38 &lt;NA&gt; JP ## adm0_sr name name_alt name_local type type_en code_local code_hasc ## 1 5 Kagoshima &lt;NA&gt; &lt;NA&gt; Ken Prefecture &lt;NA&gt; JP.KS ## 2 1 Oita &lt;NA&gt; &lt;NA&gt; Ken Prefecture &lt;NA&gt; JP.OT ## 3 1 Fukuoka Hukuoka &lt;NA&gt; Ken Prefecture &lt;NA&gt; JP.FO ## 4 1 Saga &lt;NA&gt; &lt;NA&gt; Ken Prefecture &lt;NA&gt; JP.SG ## 5 3 Nagasaki &lt;NA&gt; &lt;NA&gt; Ken Prefecture &lt;NA&gt; JP.NS ## 6 1 Kumamoto &lt;NA&gt; &lt;NA&gt; Ken Prefecture &lt;NA&gt; JP.KM ## 7 1 Miyazaki &lt;NA&gt; &lt;NA&gt; Ken Prefecture &lt;NA&gt; JP.MZ ## 8 1 Tokushima Tokusima &lt;NA&gt; Ken Prefecture &lt;NA&gt; JP.TS ## 9 1 Kagawa &lt;NA&gt; &lt;NA&gt; Ken Prefecture &lt;NA&gt; JP.KG ## 10 4 Ehime &lt;NA&gt; &lt;NA&gt; Ken Prefecture &lt;NA&gt; JP.EH ## note hasc_maybe region region_cod provnum_ne gadm_level check_me datarank ## 1 &lt;NA&gt; JP.NR Kyushu JPN-KYS 3 1 20 9 ## 2 &lt;NA&gt; JP.ON Kyushu JPN-SHK 48 1 20 2 ## 3 &lt;NA&gt; JP.NS Kyushu JPN-KYS 46 1 20 2 ## 4 &lt;NA&gt; JP.OS &lt;NA&gt; &lt;NA&gt; 47 1 20 2 ## 5 &lt;NA&gt; JP.OY &lt;NA&gt; &lt;NA&gt; 5 1 20 9 ## 6 &lt;NA&gt; JP.NI Kyushu JPN-KYS 6 1 20 2 ## 7 &lt;NA&gt; JP.OT Kyushu JPN-KYS 49 1 20 2 ## 8 &lt;NA&gt; JP.SZ Shikoku JPN-SHK 45 1 20 2 ## 9 &lt;NA&gt; JP.SH Shikoku JPN-SHK 4 1 20 2 ## 10 &lt;NA&gt; JP.ST Shikoku JPN-SHK 14 1 20 2 ## abbrev postal area_sqkm sameascity labelrank name_len mapcolor9 mapcolor13 ## 1 &lt;NA&gt; &lt;NA&gt; 0 NA 2 9 5 4 ## 2 &lt;NA&gt; OT 0 7 7 4 5 4 ## 3 &lt;NA&gt; FO 0 7 7 7 5 4 ## 4 &lt;NA&gt; SG 0 NA 6 4 5 4 ## 5 &lt;NA&gt; &lt;NA&gt; 0 NA 2 8 5 4 ## 6 &lt;NA&gt; KM 0 NA 6 8 5 4 ## 7 &lt;NA&gt; MZ 0 NA 6 8 5 4 ## 8 &lt;NA&gt; TS 0 NA 6 9 5 4 ## 9 &lt;NA&gt; KG 0 NA 6 6 5 4 ## 10 &lt;NA&gt; EH 0 NA 6 5 5 4 ## fips fips_alt woe_id woe_label woe_name latitude ## 1 JA18 JA28 2345867 Kagoshima Prefecture, JP, Japan Kagoshima 29.4572 ## 2 JA30 JA47 2345879 Oita Prefecture, JP, Japan Oita 33.2006 ## 3 JA07 JA27 58646425 Fukuoka Prefecture, JP, Japan Fukuoka 33.4906 ## 4 JA33 JA32 2345882 Saga Prefecture, JP, Japan Saga 33.0097 ## 5 JA27 JA31 2345876 Nagasaki Prefecture, JP, Japan Nagasaki 32.6745 ## 6 JA21 JA29 2345870 Kumamoto Prefecture, JP, Japan Kumamoto 32.5880 ## 7 JA25 JA30 2345874 Miyazaki Prefecture, JP, Japan Miyazaki 32.0981 ## 8 JA39 JA37 2345888 Tokushima Prefecture, JP, Japan Tokushima 33.8546 ## 9 JA17 JA35 2345866 Kagawa Prefecture, JP, Japan Kagawa 34.2162 ## 10 JA05 JA34 2345855 Ehime Prefecture, JP, Japan Ehime 33.8141 ## longitude sov_a3 adm0_a3 adm0_label admin geonunit gu_a3 gn_id ## 1 129.601 JPN JPN 4 Japan Japan JPN 1860825 ## 2 131.449 JPN JPN 4 Japan Japan JPN 1854484 ## 3 130.616 JPN JPN 4 Japan Japan JPN 1863958 ## 4 130.147 JPN JPN 4 Japan Japan JPN 1853299 ## 5 128.755 JPN JPN 4 Japan Japan JPN 1856156 ## 6 130.834 JPN JPN 4 Japan Japan JPN 1858419 ## 7 131.286 JPN JPN 4 Japan Japan JPN 1856710 ## 8 134.200 JPN JPN 4 Japan Japan JPN 1850157 ## 9 134.001 JPN JPN 4 Japan Japan JPN 1860834 ## 10 132.916 JPN JPN 4 Japan Japan JPN 1864226 ## gn_name gns_id gns_name gn_level gn_region gn_a1_code region_sub ## 1 Kagoshima-ken -231556 Kagoshima-ken 1 &lt;NA&gt; JP.18 &lt;NA&gt; ## 2 Oita-ken -240089 Oita-ken 1 &lt;NA&gt; JP.30 &lt;NA&gt; ## 3 Fukuoka-ken -227382 Fukuoka-ken 1 &lt;NA&gt; JP.07 &lt;NA&gt; ## 4 Saga-ken -241905 Saga-ken 1 &lt;NA&gt; JP.33 &lt;NA&gt; ## 5 Nagasaki-ken -237758 Nagasaki-ken 1 &lt;NA&gt; JP.27 &lt;NA&gt; ## 6 Kumamoto-ken -234759 Kumamoto-ken 1 &lt;NA&gt; JP.21 &lt;NA&gt; ## 7 Miyazaki-ken -236958 Miyazaki-ken 1 &lt;NA&gt; JP.25 &lt;NA&gt; ## 8 Tokushima-ken -246216 Tokushima-ken 1 &lt;NA&gt; JP.39 &lt;NA&gt; ## 9 Kagawa-ken -231546 Kagawa-ken 1 &lt;NA&gt; JP.17 &lt;NA&gt; ## 10 Ehime-ken -227007 Ehime-ken 1 &lt;NA&gt; JP.05 &lt;NA&gt; ## sub_code gns_level gns_lang gns_adm1 gns_region min_label max_label min_zoom ## 1 &lt;NA&gt; 1 jpn JA18 &lt;NA&gt; 7 11 3 ## 2 &lt;NA&gt; 1 jpn JA30 &lt;NA&gt; 7 11 3 ## 3 &lt;NA&gt; 1 jpn JA07 &lt;NA&gt; 7 11 3 ## 4 &lt;NA&gt; 1 jpn JA33 &lt;NA&gt; 7 11 3 ## 5 &lt;NA&gt; 1 jpn JA27 &lt;NA&gt; 7 11 3 ## 6 &lt;NA&gt; 1 jpn JA21 &lt;NA&gt; 7 11 3 ## 7 &lt;NA&gt; 1 jpn JA25 &lt;NA&gt; 7 11 3 ## 8 &lt;NA&gt; 1 jpn JA39 &lt;NA&gt; 7 11 3 ## 9 &lt;NA&gt; 1 jpn JA17 &lt;NA&gt; 7 11 3 ## 10 &lt;NA&gt; 1 jpn JA05 &lt;NA&gt; 7 11 3 ## wikidataid name_ar name_bn name_de name_en ## 1 Q15701 &lt;NA&gt; &lt;NA&gt; Präfektur Kagoshima Kagoshima Prefecture ## 2 Q133924 &lt;NA&gt; &lt;NA&gt; Präfektur Oita Oita Prefecture ## 3 Q123258 &lt;NA&gt; &lt;NA&gt; Präfektur Fukuoka Fukuoka Prefecture ## 4 Q160420 &lt;NA&gt; &lt;NA&gt; Präfektur Saga Saga Prefecture ## 5 Q169376 &lt;NA&gt; &lt;NA&gt; Präfektur Nagasaki Nagasaki Prefecture ## 6 Q130308 &lt;NA&gt; &lt;NA&gt; Präfektur Kumamoto Kumamoto Prefecture ## 7 Q130300 &lt;NA&gt; &lt;NA&gt; Präfektur Miyazaki Miyazaki Prefecture ## 8 Q160734 &lt;NA&gt; &lt;NA&gt; Präfektur Tokushima Tokushima Prefecture ## 9 Q161454 &lt;NA&gt; &lt;NA&gt; Präfektur Kagawa Kagawa Prefecture ## 10 Q123376 &lt;NA&gt; &lt;NA&gt; Präfektur Ehime Ehime Prefecture ## name_es name_fr name_el name_hi ## 1 Prefectura de Kagoshima Préfecture de Kagoshima &lt;NA&gt; &lt;NA&gt; ## 2 Prefectura de Oita Préfecture d&#39;Oita &lt;NA&gt; &lt;NA&gt; ## 3 Prefectura de Fukuoka Préfecture de Fukuoka &lt;NA&gt; &lt;NA&gt; ## 4 Prefectura de Saga Préfecture de Saga &lt;NA&gt; &lt;NA&gt; ## 5 Prefectura de Nagasaki Préfecture de Nagasaki &lt;NA&gt; &lt;NA&gt; ## 6 Prefectura de Kumamoto Préfecture de Kumamoto &lt;NA&gt; &lt;NA&gt; ## 7 Prefectura de Miyazaki Préfecture de Miyazaki &lt;NA&gt; &lt;NA&gt; ## 8 Prefectura de Tokushima Préfecture de Tokushima &lt;NA&gt; &lt;NA&gt; ## 9 Prefectura de Kagawa Préfecture de Kagawa &lt;NA&gt; &lt;NA&gt; ## 10 Prefectura de Ehime Préfecture d&#39;Ehime &lt;NA&gt; &lt;NA&gt; ## name_hu name_id name_it name_ja ## 1 Kagosima prefektúra Prefektur Kagoshima prefettura di Kagoshima &lt;NA&gt; ## 2 Óita prefektúra Prefektur Oita prefettura di Oita &lt;NA&gt; ## 3 Fukuoka prefektúra Prefektur Fukuoka prefettura di Fukuoka &lt;NA&gt; ## 4 Szaga prefektúra Prefektur Saga Prefettura di Saga &lt;NA&gt; ## 5 Nagaszaki prefektúra Prefektur Nagasaki prefettura di Nagasaki &lt;NA&gt; ## 6 Kumamoto prefektúra Prefektur Kumamoto prefettura di Kumamoto &lt;NA&gt; ## 7 Mijazaki prefektúra Prefektur Miyazaki prefettura di Miyazaki &lt;NA&gt; ## 8 Tokusima prefektúra Prefektur Tokushima prefettura di Tokushima &lt;NA&gt; ## 9 Kagava prefektúra Prefektur Kagawa prefettura di Kagawa &lt;NA&gt; ## 10 Ehime prefektúra Prefektur Ehime prefettura di Ehime &lt;NA&gt; ## name_ko name_nl name_pl name_pt name_ru name_sv ## 1 &lt;NA&gt; Kagoshima Prefektura Kagoshima Kagoshima &lt;NA&gt; Kagoshima prefektur ## 2 &lt;NA&gt; Oita Prefektura Oita Oita &lt;NA&gt; Oita prefektur ## 3 &lt;NA&gt; Fukuoka Prefektura Fukuoka Fukuoka &lt;NA&gt; Fukuoka prefektur ## 4 &lt;NA&gt; Saga Prefektura Saga Saga &lt;NA&gt; Saga prefektur ## 5 &lt;NA&gt; Nagasaki Prefektura Nagasaki Nagasaki &lt;NA&gt; Nagasaki prefektur ## 6 &lt;NA&gt; Kumamoto Prefektura Kumamoto Kumamoto &lt;NA&gt; Kumamoto prefektur ## 7 &lt;NA&gt; Miyazaki Prefektura Miyazaki Miyazaki &lt;NA&gt; Miyazaki prefektur ## 8 &lt;NA&gt; Tokushima Prefektura Tokushima Tokushima &lt;NA&gt; Tokushima prefektur ## 9 &lt;NA&gt; Kagawa Prefektura Kagawa Kagawa &lt;NA&gt; Kagawa prefektur ## 10 &lt;NA&gt; Ehime Prefektura Ehime Ehime &lt;NA&gt; Ehime prefektur ## name_tr name_vi name_zh ne_id Code Name Density ## 1 Kagosima ili Kagoshima &lt;NA&gt; 1159315225 46 鹿児島県 172.9 ## 2 Oita Oita &lt;NA&gt; 1159311905 44 大分県 177.2 ## 3 Fukuoka Fukuoka &lt;NA&gt; 1159311899 40 福岡県 1029.8 ## 4 Saga Saga &lt;NA&gt; 1159311895 41 佐賀県 332.5 ## 5 Nagasaki Nagasaki &lt;NA&gt; 1159315235 42 長崎県 317.7 ## 6 Kumamoto Kumamoto &lt;NA&gt; 1159311901 43 熊本県 234.6 ## 7 Miyazaki Miyazaki &lt;NA&gt; 1159311903 45 宮崎県 138.3 ## 8 Tokushima Tokushima &lt;NA&gt; 1159311909 36 徳島県 173.5 ## 9 Kagawa Kagawa &lt;NA&gt; 1159311907 37 香川県 506.3 ## 10 Ehime Ehime &lt;NA&gt; 1159311139 38 愛媛県 235.2 ## geometry ## 1 MULTIPOLYGON (((129.7832 31... ## 2 MULTIPOLYGON (((131.2009 33... ## 3 MULTIPOLYGON (((130.0363 33... ## 4 MULTIPOLYGON (((129.8145 33... ## 5 MULTIPOLYGON (((130.2041 32... ## 6 MULTIPOLYGON (((130.3446 32... ## 7 MULTIPOLYGON (((131.8723 32... ## 8 MULTIPOLYGON (((134.4424 34... ## 9 MULTIPOLYGON (((133.5919 34... ## 10 MULTIPOLYGON (((132.6399 32... それではマッピングをしてみましょう。人口密度を5つのカテゴリーに順序付きfactor化してから、そのカテゴリーに応じて色塗りをします。 Japan_Map %&gt;% mutate(Density2 = case_when(Density &gt;= 3000 ~ &quot;3000人以上&quot;, Density &gt;= 1000 ~ &quot;1000人以上&quot;, Density &gt;= 500 ~ &quot;500人以上&quot;, Density &gt;= 100 ~ &quot;100人以上&quot;, TRUE ~ &quot;100人未満&quot;), Density2 = factor(Density2, ordered = TRUE, levels = c(&quot;3000人以上&quot;, &quot;1000人以上&quot;, &quot;500人以上&quot;, &quot;100人以上&quot;, &quot;100人未満&quot;))) %&gt;% ggplot() + geom_sf(aes(fill = Density2)) + labs(fill = &quot;人口密度 (km^2)&quot;) + theme_void() 世界地図でも同じやり方でデータの結合が可能です。この場合はISO3コードかISO2コードがキー変数となります。ISO3コードはiso_a3、ISO2コードはiso_a2列に格納されています。他に使用可能なキー変数はiso_n3であり、こちらは各国を識別する3桁の数字となります。 20.10.3 日本地図（特定の都道府県） また日本地図のマッピングですが、今回は市区町村レベルまで見てみましょう。ne_states()では市区町村までマッピングすることはできませんので、今回は徳島大学の瓜生真也先生が公開しました{jpndistrict}を使います。 pacman::p_load_gh(&quot;uribo/jpndistrict&quot;) 今回は大阪府の地図を出力してみましょう。特定の都道府県の地図を読み込むためにはjpn_pref()関数を使用します。都道府県はpref_codeまたはadmin_nameで指定します。大阪のコードは27であるため、pref_code = 27でも良いですし、admin_name = \"大阪府\"でも同じです。 # Osaka_map &lt;- jpn_pref(admin_name = &quot;大阪府&quot;) でも同じ Osaka_map &lt;- jpn_pref(pref_code = 27) class(Osaka_map) ## [1] &quot;sf&quot; &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; プロットの方法は同じです。 Osaka_map %&gt;% ggplot() + geom_sf() + theme_minimal() ここでもデータの結合&amp;マッピングが可能です。大阪府内自治体の人口と学生数が格納されたデータを読み込んでみましょう。こちらは2015年国勢調査の結果から取得したデータです。 Osaka_Student &lt;- read_csv(&quot;data/Osaka_Student.csv&quot;) Osaka_Student ## # A tibble: 75 × 4 ## Code Name Pop Student ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 27000 大阪府 8839469 438901 ## 2 27100 大阪市 2691185 104208 ## 3 27102 大阪市 都島区 104727 3889 ## 4 27103 大阪市 福島区 72484 2448 ## 5 27104 大阪市 此花区 66656 2478 ## 6 27106 大阪市 西区 92430 2633 ## 7 27107 大阪市 港区 82035 3072 ## 8 27108 大阪市 大正区 65141 2627 ## 9 27109 大阪市 天王寺区 75729 3480 ## 10 27111 大阪市 浪速区 69766 1409 ## # … with 65 more rows 各市区町村にもコードが指定されており、Osaka_StudentではCode列、Osaka_mapではciti_code列となります。Osaka_mapのcity_codeは文字列であるため、こちらを数値型に変換しCodeという名の列として追加しておきましょう。続いて、Code列をキー変数とし、2つのデータセットを結合します。 Osaka_map &lt;- Osaka_map %&gt;% mutate(Code = as.numeric(city_code)) Osaka_map &lt;- left_join(Osaka_map, Osaka_Student, by = &quot;Code&quot;) 最後にマッピングです。ここでは人口1万人当たり学生数をStudent_Ratioという列として追加し、こちらの値に合わせて色塗りをしてみましょう。scale_fill_gradient()を使用し、人口1万人当たり学生数が少ないほど白、多いほど黒塗りします。 Osaka_map %&gt;% mutate(Student_Ratio = Student / Pop * 10000) %&gt;% ggplot() + geom_sf(aes(fill = Student_Ratio)) + scale_fill_gradient(low = &quot;white&quot;, high = &quot;black&quot;) + labs(fill = &quot;1万人当たり学生数 (人)&quot;) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) 20.11 非巡回有向グラフ 近年、因果推論の界隈でよく登場する非巡回有向グラフ（DAG）ですが、「グラフ」からも分かるように、DAGの考え方に基づく因果推論の研究には多くの図が登場します。DAGを作図するには{ggplot2}のみでも可能ですが、{dagitty}パッケージでDAGの情報を含むオブジェクトを生成し、{ggdag}で作図した方が簡単です。以下の図はDAGの一例です。 ここでX、Y、Zはノード（node）と呼ばれ、それぞれのノードをつなぐ線のことをエッジ（edge）と呼びます。また、これらのエッジには方向があります（有向）。簡単に言うと原因と結果といった関係ですが、DAGを描く際は、各ノード間の関係を記述する必要があります。 それではまず、以上の図を作ってみましょう。最初のステップとして{dagitty}と{ggdag}をインストールし、読み込みましょう。 pacman::p_load(dagitty, ggdag) つづいて、DAGの情報を含むオブジェクトを作成します。使用する関数はdagify()であり、ここには結果 ~ 原因の形式で各ノード間の関係を記述します。先ほどの図ではXはYの原因（X ~ Y）、ZはXとYの原因（X ~ ZとY ~ Z）です。これらの情報をdagify()内で指定します。 DAG_data1 &lt;- dagify(X ~ Z, Y ~ Z, Y ~ X, exposure = &quot;X&quot;, outcome = &quot;Y&quot;) DAG_data1 ## dag { ## X [exposure] ## Y [outcome] ## Z ## X -&gt; Y ## Z -&gt; X ## Z -&gt; Y ## } Y ~ XとY ~ ZはY ~ X + Zとまとめることも可能です。これは「Yの原因はXとZである」という意味であり、「Yの原因はXであり、Yの原因はZである」と同じ意味です。また、DAGを作図する際、dagify()内にexposureとoutcomeは不要ですが、もしadjustmentSets()関数などを使って統制変数を特定したい場合は処置変数（exposure）と応答変数（outcome）にそれぞれ変数名を指定します。ちなみに、以上のコードは以下のように書くことも可能です。 DAG_data1 &lt;- dagitty( &quot;dag{ X -&gt; Y X &lt;- Z -&gt; Y X [exposure] Y [outcome] }&quot;) DAG_data1 ## dag { ## X [exposure] ## Y [outcome] ## Z ## X -&gt; Y ## Z -&gt; X ## Z -&gt; Y ## } 格納されたDAG_data1オブジェクトのクラスは\"dagitty\"です。\"dagitty\"の可視化には{ggdag}のggdag()を使用します。 DAG_data1 %&gt;% ggdag() DAGにおいて背景、軸の目盛り、ラベルは不要ですので、theme_dag_blank()テーマを指定して全て除去します。 DAG_data1 %&gt;% ggdag() + theme_dag_blank() 20.11.1 ノードの位置を指定する 読者の多くは以上のグラフと異なるものが得られたかも知れません。ノード間の関係は同じはずですが、ノードの位置が異なるでしょう。また、同じコードを実行する度にノードの位置は変わります。以下ではノードの位置を固定する方法について紹介します。位置を指定するにはdagify()内でcoords引数に各ノードの情報が格納されたリスト型オブジェクトを指定する必要があります。リストの長さは2であり、それぞれの名前はxとyです。そしてリストの各要素にはベクトルが入ります。たとえば、ノードXの位置を (1, 1)、Yの位置を (3, 1)、Zの位置を (2, 2)に指定してみましょう。dagify()内で直接リストを書くことも可能ですが、コードの可読性が落ちるため、別途のオブジェクト（DAG_Pos2）として格納しておきます。 DAG_Pos2 &lt;- list(x = c(X = 1, Y = 3, Z = 2), y = c(X = 1, Y = 1, Z = 2)) 続いて、dagify()内でcoords引数を追加し、ノードの位置情報が格納されているDAG_Pos2を指定します。 DAG_data2 &lt;- dagify(X ~ Z, Y ~ X + Z, exposure = &quot;X&quot;, outcome = &quot;Y&quot;, coords = DAG_Pos2) DAG_data2 ## dag { ## X [exposure,pos=&quot;1.000,1.000&quot;] ## Y [outcome,pos=&quot;3.000,1.000&quot;] ## Z [pos=&quot;2.000,2.000&quot;] ## X -&gt; Y ## Z -&gt; X ## Z -&gt; Y ## } 可視化の方法は同じです。 DAG_data2 %&gt;% ggdag() + theme_dag_blank() 以上の使い方だけでも、ほとんどのDAGは描けるでしょう。また、ノードを若干オシャレ（?）にするには、ggdag()内でstylized = TRUEを指定します。 DAG_Pos3 &lt;- list(x = c(X1 = 3, X2 = 3, X3 = 1, T = 2, Y = 4), y = c(X1 = 1, X2 = 2, X3 = 2, T = 3, Y = 3)) DAG_data3 &lt;- dagify(Y ~ T + X1 + X2, T ~ X3, X2 ~ T +X1 + X3, exposure = &quot;T&quot;, outcome = &quot;Y&quot;, coords = DAG_Pos3) DAG_data3 %&gt;% ggdag(stylized = TRUE) + theme_dag_blank() 可視化の話ではありませんが、adjustmentSets()関数を用いると、処置変数Tの総効果（total effect）を推定するためにはどの変数を統制（調整）する必要があるかを調べることも可能です。 adjustmentSets(DAG_data3, effect = &quot;total&quot;) ## { X3 } X3変数のみ統制すれば良いという結果が得られました。また、TからYへの直接効果（direct effect）の場合、effect = \"direct\"を指定します。 adjustmentSets(DAG_data3, effect = &quot;direct&quot;) ## { X1, X2 } X1とX2を統制する必要があることが分かりますね。 20.12 バンプチャート バンプチャート (bump chart)は順位の変化などを示す時に有効なグラフです。たとえば、G7構成国の新型コロナ感染者数の順位の変化を示すにはどうすれば良いでしょうか。そもそもどのような形式のデータが必要でしょうか。まずは必要なデータ形式を紹介したいと思います。 まず、{ggplot2}によるバンプチャートの作成を支援する{ggbump}パッケージをインストールし、読み込みましょう92。 pacman::p_load(ggbump) ここではG7構成国の100万人当り新型コロナ感染者数の順位がどのように変化したのかを2020年4月から7月まで1ヶ月単位で表したデータが必要です。データは以下のようなコードで作成しますが、本書のサポートページからもダウンロード可能です。 Bump_df &lt;- left_join(COVID19_df, Country_df, by = &quot;Country&quot;) %&gt;% select(Country, Date, Population, Confirmed_Total, G7) %&gt;% separate(Date, into = c(&quot;Year&quot;, &quot;Month&quot;, &quot;Day&quot;), sep = &quot;/&quot;) %&gt;% mutate(Month = as.numeric(Month)) %&gt;% filter(Month &gt;= 4, G7 == 1) %&gt;% group_by(Country, Month) %&gt;% summarise(Population = mean(Population), New_Cases = sum(Confirmed_Total, na.rm = TRUE), New_Cases_per_million = New_Cases / Population * 1000000, .groups = &quot;drop&quot;) %&gt;% select(Country, Month, New_Cases_per_million) Bump_df &lt;- Bump_df %&gt;% group_by(Month) %&gt;% mutate(Rank = rank(New_Cases_per_million, ties.method = &quot;random&quot;)) %&gt;% ungroup() %&gt;% select(Country, Month, Rank, New_Cases_per_million) 必要なデータは以下のような形式です。ちなみにバンプチャートを作成するためには最後のNew_Cases_per_million列 (100万人当り新型コロナ感染者数)は不要です。つまり、国名、月、順位のみで十分です。 # 以上のコードを省略し、加工済みのデータを読み込んでもOK # Bump_df &lt;- read_csv(&quot;Data/Bumpchart.csv&quot;) Bump_df それでは{ggbump}が提供するgeom_bump()幾何オブジェクトを使用し、簡単なバンプチャートを作成してみましょう。必要なマッピング要素はxとy、colorです。xには時間を表す変数であるMonthを、yには順位を表すRankをマッピングします。また、7本の線が出るため、月と順位、それぞれの値がどの国の値かを特定する必要があります。groupsに国名であるCountryをマッピングしても線は引けますが、どの線がどの国かが分からなくなるため、colorにCountryをマッピングし、線の色分けをします。 Bump_df %&gt;% ggplot(aes(x = Month, y = Rank, color = Country)) + geom_bump() これで最低限のバンプチャートはできましたが、もう少し見やすく、可愛くしてみましょう。今は線が細いのでややぶ厚めにします。これはgeom_bump()レイヤーのsize引数で指定可能です。また、各月に点を付けることによって、同時期における順位の比較をよりしやすくしてみましょう。これは散布図と同じであるため、geom_point()幾何オブジェクトを使用します。 Bump_df %&gt;% ggplot(aes(x = Month, y = Rank, color = Country)) + geom_point(size = 7) + geom_bump(size = 2) + theme_minimal(base_size = 14) これでだいぶ見やすくなりましたが、凡例における国名の順番がやや気になりますね。7月の時点において順位が最も高い国はアメリカ、最も低い国は日本ですが、凡例の順番はアルファベット順となっています。この凡例の順番を7月時点におけるRankの値に合わせた方がより見やすいでしょう。ここで第14.2.9で紹介しましたfct_reorder2()を使ってCountry変数の水準 (level)を7月時点におけるRankの順位に合わせます。この場合、Country変数 (.f = Country)の水準をMonthが (.x = Month)最も大きい (.fun = last2)時点におけるRankの順番に合わせる (.y = Rank)こととなります。fct_reorder2()内の引数の順番の既定値は.f、.x、.y、.funとなります。 Bump_df %&gt;% mutate(Country = fct_reorder2(Country, Month, Rank, last2)) %&gt;% ggplot(aes(x = Month, y = Rank, color = Country)) + geom_point(size = 7) + geom_bump(size = 2) + theme_minimal(base_size = 14) 最後に縦軸の目盛りラベルを付けます。上に行くほど順位が高くなりますので、1を7に、2を6に、…、7を1に変更します。また、図内のグリッドも不要ですので、theme()を使用し、グリッドを削除します (panel.grid = element_blank())。 Bump_df %&gt;% mutate(Country = fct_reorder2(Country, Month, Rank, last2)) %&gt;% ggplot(aes(x = Month, y = Rank, color = Country)) + geom_point(size = 7) + geom_bump(size = 2) + scale_y_continuous(breaks = 1:7, labels = 7:1) + theme_minimal(base_size = 14) + theme(panel.grid = element_blank()) これでバンプチャートの完成です。このままでの良いかも知れませんが、もう少し手間を掛けることでより読みやすいグラフが作れます。たとえば、今のままだと「日本のトレンド」を確認したい場合、まず凡例から日本の色を確認し、その色に該当する点と線を見つけてトレンドを見る必要がありますね。もし、ここで図の左端と右端の点の横に国名を出力すると、凡例がなくても良いですし、4月の時点から日本のトレンドを確認することも、7月の時点から遡る形で日本のトレンドを確認することも可能かも知れません。 図に文字列を追加するためにはgeom_text()幾何オブジェクトを使用します。マッピング要素は文字列の横軸上の位置 (x)、縦軸上の位置 (y)、そして出力する文字列 (label)です。左端に文字列を出力するのであれば、横軸上の位置は4 (= 4月)よりも若干左側が良いでしょう。ぴったり4になると、点と文字列が重なって読みにくくなりますね。縦軸上の位置は4月の時点での順位 (Rank)で、出力する文字列は国名 (Country)です。現在、使用しているデータは4月から7月までのデータですが、4月に限定したデータを使いたいので、geom_text()内にdata引数を追加し、Bump_dfからMonthの値が4の行のみを抽出したデータを割り当てます (data = filter(Bump_df, Month == 4)、またはdata = Bump_df %&gt;% filter(Month == 4))。右端についても同じです。横軸上の位置は7から右方向へずらし、使用するデータは7月のデータとなります。 最後にもう一点調整が必要ですが、それは座標系です。図の座標系はggplot()関数で使用するデータに基づきます。Bump_dfの場合、横軸 (Month)は4から7です。しかし、文字列を追加した場合、文字列がすべて出力されないかも知れません。したがって、座標系を横方向に広める必要があります。今回は3から8までに調整します。座標系や文字列の位置調整は出力結果を見ながら、少しずつ調整していきましょう。 Bump_df %&gt;% ggplot(aes(x = Month, y = Rank, color = Country)) + geom_point(size = 7) + geom_bump(size = 2) + # 4月の時点での行のみ抽出し、xはMonthより0.15分左方向、 # yはRankの値の位置に国名を出力する。揃える方向は右揃え (hjust = 1) geom_text(data = filter(Bump_df, Month == 4), aes(x = Month - 0.15, y = Rank, label = Country), hjust = 1) + # 7月の時点での行のみ抽出し、xはMonthより0.15分右方向、 # yはRankの値の位置に国名を出力する。揃える方向は左揃え (hjust = 0) geom_text(data = filter(Bump_df, Month == 7), aes(x = Month + 0.15, y = Rank, label = Country), hjust = 0) + # 座標系の調整 coord_cartesian(xlim = c(3, 8)) + scale_x_continuous(breaks = 4:7, labels = 4:7) + scale_y_continuous(breaks = 1:7, labels = 7:1) + labs(y = &quot;Rank&quot;, x = &quot;Month&quot;) + theme_minimal(base_size = 14) + theme(legend.position = &quot;none&quot;, panel.grid = element_blank()) 20.13 沖積図 沖積図 (alluvial plot)は同じ対象を複数回観察したデータ（パネル・データなど）から変化を示すことに適したグラフです。たとえば、同じ回答者を対象に2回世論調査を実施し、1回目調査時の支持政党と2回目調査時の支持政党を変化を見ることも可能です。もし、変化が大きい場合は政党支持態度は弱いこととなりますし、変化が小さい場合は安定していると解釈できるでしょう。 ここでは2020年の選挙と2021年の選挙における有権者の投票先の変化を沖積図で確認してみたいと思います。まずは、沖積図の作成に特化した{ggalluvial}パッケージをインストールし、読み込みます。 pacman::p_load(ggalluvial) 続きまして、実習用データを読み込みます。データは架空のデータです。 Vote_2021 &lt;- read_csv(&quot;Data/Vote_20_21.csv&quot;) head(Vote_2021, 20) ## # A tibble: 20 × 3 ## ID Vote20 Vote21 ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 棄権 棄権 ## 2 2 政党A 政党A ## 3 3 政党A 政党A ## 4 4 政党B 政党A ## 5 5 政党B 政党C ## 6 6 政党A 政党C ## 7 7 その他 その他 ## 8 8 政党B 政党B ## 9 9 政党A 政党A ## 10 10 政党C 政党C ## 11 11 棄権 政党B ## 12 12 政党B 政党A ## 13 13 棄権 棄権 ## 14 14 政党B 政党B ## 15 15 政党C 政党C ## 16 16 DK 政党C ## 17 17 政党B DK ## 18 18 政党A 政党A ## 19 19 政党A 政党A ## 20 20 政党A 政党A 変数名 説明 ID 回答者ID Vote20 2020年選挙における当該回答者の投票先 Vote21 2021年選挙における当該回答者の投票先 たとえば、1番目の回答者は2020年に棄権し、2021年も棄権したことを意味する。また、5番目の回答者は2020年に政党Bに投票し、2021年は政党Cに投票したことを意味する。続いて、このデータを{ggalluvial}に適した形式のデータに加工します。具体的には「2020年棄権、かつ2021年棄権」、「2020年棄権、かつ2021年政党Aへ投票」、…、「2020年政党Bへ投票、かつ2021年政党Aへ投票」のように全ての組み合わせに対し、該当するケース数を計算する必要があります。今回のデータだと、投票先はいずれも政党A、政党B、政党C、政党D、その他、棄権、DK (わからない)の7であるため、49パターンができます。それぞれのパターンに該当するケース数を計算するためにはVote20とVote21でデータをグループ化し、ケース数を計算します。 Vote_2021 &lt;- Vote_2021 %&gt;% group_by(Vote20, Vote21) %&gt;% summarise(Freq = n(), .groups = &quot;drop&quot;) Vote_2021 ## # A tibble: 47 × 3 ## Vote20 Vote21 Freq ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 DK DK 111 ## 2 DK その他 8 ## 3 DK 政党A 116 ## 4 DK 政党B 29 ## 5 DK 政党C 15 ## 6 DK 政党D 7 ## 7 DK 棄権 57 ## 8 その他 DK 18 ## 9 その他 その他 73 ## 10 その他 政党A 121 ## # … with 37 more rows 2020年の調査で「わからない」と回答し、2021年の調査でも「わからない」と回答した回答者数は111名、2020年の調査で「わからない」と回答し、2021年の調査では「その他」と回答した回答者数は8名、…といったことが分かりますね。 続いて、グラフを作成する前に投票先変数 (Vote20とVote21)をfactor化します。可視化の際、投票先が出力される順番に決まりはありませんが、政党A、政党B、政党C、…、DKの順が自然かと思います。むろん、こちらは自分から見て分かりやいように順番を決めましょう。ただし、2変数における水準 (level)の順番は一致させた方が良いでしょう。 Vote_2021 &lt;- Vote_2021 %&gt;% mutate(Vote20 = factor(Vote20, levels = c(&quot;政党A&quot;, &quot;政党B&quot;, &quot;政党C&quot;, &quot;政党D&quot;, &quot;その他&quot;, &quot;棄権&quot;, &quot;DK&quot;)), Vote21 = factor(Vote21, levels = c(&quot;政党A&quot;, &quot;政党B&quot;, &quot;政党C&quot;, &quot;政党D&quot;, &quot;その他&quot;, &quot;棄権&quot;, &quot;DK&quot;))) それでは沖積図を描いてみましょう。使用する幾何オブジェクトはgeom_alluvium()とgeom_stratum()です。必ずこの順番でレイヤーを重ねてください。マッピングはy、axis1、axis2に対し、yには当該パターン内のケース数 (Freq)、axis1は2009年の投票先 (Vote20)、axis2は2010年の投票先 (Vote21)を指定します93。これらのマッピングはgeom_stratum()とgeom_alluvim()共通であるため、ggplot()内でマッピングした方が効率的です。 Vote_2021 %&gt;% ggplot(aes(y = Freq, axis1 = Vote20, axis2 = Vote21)) + geom_alluvium() + geom_stratum() 何かの図は出てきましたが、これだけだと、それぞれの四角形がどの政党を示しているのかが分かりませんね。四角形内に政党名を出力するためには{ggplot2}内蔵のgeom_text()を使用します。マッピング要素はggplot()内でマッピングしたものに加え、labelが必要ですが、ここではafter_stat(stratum)を指定します。そして、aes()のその側にstat = \"stratum\"を指定するだけです。もし、文字化けが生じる場合は、geom_text()内にフォントの指定が必要があり、familyを使います (たとえば、family = \"HiraginoSans-W3\"など)。theme_*()内でbase_familyを指定した場合でも必要です。 Vote_2021 %&gt;% ggplot(aes(y = Freq, axis1 = Vote20, axis2 = Vote21)) + geom_alluvium() + geom_stratum() + geom_text(aes(label = after_stat(stratum)), stat = &quot;stratum&quot;) これで沖積図はとりあえず完成ですが、少し読みやすく加工してみましょう。たとえば、2020年に政党Aに投票した回答者における2021年の投票先の割合を見たいとした場合、geom_alluvium()内にfill = Vote20をマッピングします。これで帯に2020年の投票先ごとの色付けができます。 Vote_2021 %&gt;% ggplot(aes(y = Freq, axis1 = Vote20, axis2 = Vote21)) + geom_alluvium(aes(fill = Vote20)) + geom_stratum() + geom_text(aes(label = after_stat(stratum)), stat = &quot;stratum&quot;) fill = Vote21とマッピングした場合は、感覚が変わります。実際にやってみましょう。 Alluvial_Plot &lt;- Vote_2021 %&gt;% ggplot(aes(y = Freq, axis1 = Vote20, axis2 = Vote21)) + geom_alluvium(aes(fill = Vote21)) + geom_stratum() + geom_text(aes(label = after_stat(stratum)), stat = &quot;stratum&quot;, family = &quot;HiraginoSans-W3&quot;) Alluvial_Plot この場合、2020年に政党Aに投票した人が2021年にどこに流れたかが分かりやすくなります。Vote20に色分けするか、Vote21に色分けするかは作成する人が決める問題であり、自分の主張・メッセージに適したマッピングをしましょう。 最後に、図をもう少し加工してみましょう。まず、横軸に0.8、1.2、1.6、2.0となっている目盛りを修正し、1と2の箇所に「2020年選挙」と「2021年選挙」を出力します。これはscale_x_continuous()で調整可能です。そして、theme_minimal()で余計なものを排除したテーマを適用します。最後にtheme()内で全ての凡例を削除 (legend.position = \"none\")し、パネルのグリッド (panel.grid)と縦軸・横軸のタイトル (axis.title)、縦軸の目盛りラベル (axis.text.y)を削除 (element_blank())します。 Alluvial_Plot + scale_x_continuous(breaks = 1:2, labels = c(&quot;2020年選挙&quot;, &quot;2021年選挙&quot;)) + theme_minimal(base_size = 16) + theme(legend.position = &quot;none&quot;, panel.grid = element_blank(), axis.title = element_blank(), axis.text.y = element_blank()) これでだいぶスッキリした沖積図が出来上がりました。 20.14 ツリーマップ ツリーマップ（tree map）は変数の値の大きさを長方形の面積として表すグラフです。全体におけるシェアを示す時に使う点で、円グラフの代替案の一つになります。円グラフは項目が多すぎると読みにくいデメリットがありますが、ツリーマップは項目が多い場合でも有効です。むろん、多すぎると読みにくいことは同じですので、注意が必要です。 ツリーマップを作成するためには{treemapify}パッケージのgeom_treemap()幾何オブジェクトを使用します。まず、{treemapify}をインストールし、読み込みます。 pacman::p_load(treemapify) ここではCountry_dfからアジア諸国の人口（Population）をツリーマップをして可視化したいと思います。geom_treemap()の場合、各長方形は面積の情報のみを持ちます。この面積の情報をareaにマッピングします。 Country_df %&gt;% filter(Continent == &quot;Asia&quot;) %&gt;% ggplot() + geom_treemap(aes(area = Population)) これだけだと各長方形がどの国を指しているのかが分かりませんね。長方形の上に国名（Country）を追加するためにはgeom_treemap_text()幾何オブジェクトを使用します。マッピングはareaとlabelに対し、それぞれ面積を表すPopulationと国名を表すCountryを指定します。areaはgeom_treemap()とgeom_treemap_text()両方で使われるのでggplot()の内部でマッピングしても問題ありません94。また、aes()の外側にcolor = \"white\"で文字を白に指定し、place = \"center\"で長方形の真ん中にラベルが付くようにします。 Country_df %&gt;% filter(Continent == &quot;Asia&quot;) %&gt;% ggplot(aes(area = Population)) + geom_treemap() + geom_treemap_text(aes(label = Country), color = &quot;white&quot;, place = &quot;center&quot;) これでツリーマップが完成しました。インドと中国の存在感がかなり大きいですね。更にラベルのサイズを長方形に合わせると、その存在感をより高めることができます。ラベルの大きさを長方形に合わせるにはgeom_treepmap_text()の内部にgrow = TRUEを指定します。 Country_df %&gt;% filter(Continent == &quot;Asia&quot;) %&gt;% ggplot(aes(area = Population, label = Country)) + geom_treemap() + geom_treemap_text(color = &quot;white&quot;, place = &quot;center&quot;, grow = TRUE) ここで更に次元を追加するために、色塗りをしてみましょう。たとえば、G20加盟国か否かで色分けをしたい場合、fillにG20をマッピングします。ただし、今のままだとG20は連続変数扱いになりますので、character型、またはfactor型に変換します。 Country_df %&gt;% mutate(G20 = if_else(G20 == 1, &quot;Member&quot;, &quot;Non-member&quot;)) %&gt;% filter(Continent == &quot;Asia&quot;) %&gt;% ggplot(aes(area = Population, fill = G20, label = Country)) + geom_treemap() + geom_treemap_text(color = &quot;white&quot;, place = &quot;centre&quot;, grow = TRUE) + labs(fill = &quot;G20&quot;) + ggtitle(&quot;Population in Asia&quot;) + theme(legend.position = &quot;bottom&quot;) 色塗りは連続変数に対して行うことも可能です。ここでは2018年人間開発指数（HDI_2108）の値に応じて色塗りをしてみます。また、HDI_2018が低い（low）とbrown3、高い（high）とcornflowerblue色にします。真ん中の値（midpoint）は0.7とし、色（mid）はcornsilkを使います。 連続変数でマッピングされた色塗り（fill）の調整にはscale_fill_gradient()、またはscale_fill_gradient2()を使います。前者は中間点なし、後者は中間点ありです。これらの使い方は第19章で紹介しましたscale_color_gradient()と同じです。 Country_df %&gt;% filter(Continent == &quot;Asia&quot;) %&gt;% ggplot(aes(area = Population, fill = HDI_2018, label = Country)) + geom_treemap() + geom_treemap_text(color = &quot;white&quot;, place = &quot;centre&quot;, grow = TRUE) + scale_fill_gradient2(low = &quot;brown3&quot;, mid = &quot;cornsilk&quot;, high = &quot;cornflowerblue&quot;, midpoint = 0.7) + labs(fill = &quot;UN Human Development Index (2018)&quot;) + ggtitle(&quot;Population in Asia&quot;) + theme(legend.position = &quot;bottom&quot;) ちなみに以上の図を円グラフにすると以下のようになります（国名は人口の割合が2.5%を超える国のみ表示）。ツリーマップと比較してかなり読みにくいことが分かります。 Country_df %&gt;% filter(Continent == &quot;Asia&quot;) %&gt;% arrange(Population) %&gt;% mutate(Prop = Population / sum(Population) * 100, LabelY = 100 - (cumsum(Prop) - 0.5 * Prop), CountryName = if_else(Prop &lt; 2.5, &quot;&quot;, Country), Country = fct_inorder(Country)) %&gt;% ggplot() + geom_bar(aes(x = 1, y = Prop, group = Country, fill = HDI_2018), color = &quot;black&quot;, stat = &quot;identity&quot;, width = 1) + geom_text(aes(x = 1, y = LabelY, label = CountryName)) + coord_polar(&quot;y&quot;, start = 0) + scale_fill_gradient2(low = &quot;brown3&quot;, mid = &quot;cornsilk&quot;, high = &quot;cornflowerblue&quot;, midpoint = 0.7) + labs(fill = &quot;UN Human Development Index (2018)&quot;) + ggtitle(&quot;Population in Asia&quot;) + theme_minimal() + theme(legend.position = &quot;bottom&quot;, panel.grid = element_blank(), axis.title = element_blank(), axis.text = element_blank()) ただし、ツリーマップが必ずしも円グラフより優れているとは言えません。たとえば、 Heer and Bostock (2010) の研究では円グラフとツリーマップを含む9種類のグラフを用い、被験者に大小関係を判断してもらう実験を行いましたが、ツリーマップ（四角形の面積）は円グラフ（角度）よりも判断までの所要時間が長いことが述べています。 20.15 モザイクプロット モザイクプロットは2つの離散変数（おもに名目変数）の関係を可視化するために Hartigan and Kleiner (1984) が考案した図です。2つの名目変数間の関係を見る際によく使われるものはクロス表（クロス集計表）でしょう。 pacman::p_load(ggmosaic) Mosaic_df &lt;- Country_df %&gt;% select(Country, Continent, Polity = Polity_Type, PPP = PPP_per_capita) %&gt;% mutate(Continent = factor(Continent, levels = c(&quot;Africa&quot;, &quot;America&quot;, &quot;Asia&quot;, &quot;Europe&quot;, &quot;Oceania&quot;)), Polity = factor(Polity, levels = c(&quot;Autocracy&quot;, &quot;Closed Anocracy&quot;, &quot;Open Anocracy&quot;, &quot;Democracy&quot;, &quot;Full Democracy&quot;)), PPP = if_else(PPP &gt;= 15000, &quot;High PPP&quot;, &quot;Low PPP&quot;), PPP = factor(PPP, levels = c(&quot;Low PPP&quot;, &quot;High PPP&quot;))) %&gt;% drop_na() head(Mosaic_df) ## # A tibble: 6 × 4 ## Country Continent Polity PPP ## &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; ## 1 Afghanistan Asia Closed Anocracy Low PPP ## 2 Albania Europe Democracy Low PPP ## 3 Algeria Africa Open Anocracy Low PPP ## 4 Angola Africa Closed Anocracy Low PPP ## 5 Argentina America Democracy High PPP ## 6 Armenia Europe Democracy Low PPP クロス表を作成する内蔵関数としてはtable()があります。2つの変数が必要となり、第一引数が行、第二引数が列を表します。 Mosaic_Tab &lt;- table(Mosaic_df$Continent, Mosaic_df$Polity) Mosaic_Tab ## ## Autocracy Closed Anocracy Open Anocracy Democracy Full Democracy ## Africa 3 14 11 18 1 ## America 0 1 4 16 5 ## Asia 13 6 0 15 3 ## Europe 2 1 2 16 20 ## Oceania 0 0 2 0 2 このMosaic_Tabのクラスは\"table\"ですが、\"table\"クラスのオブジェクトをplot()に渡すと別途のパッケージを使わずモザイクプロットを作成することができます。 plot(Mosaic_Tab) やや地味ではありますが、モザイクプロットが出来ました。ここからはより読みやすいモザイクプロットを作成するために{ggmosaic}パッケージのgeom_mosaic()関数を使います。 geom_mosaic()の場合、xのみのマッピングで十分です。ただし、特定の変数を指定するのではなく、product(変数1, 変数2)をxにマッピングする必要があります。table()関数同様、変数1は行、変数2は列です。また、欠損値が含まれている行がある場合は、aes()の外側にna.rm = TRUEを指定する必要があります。今回はdrop_na()で欠損値をすべて除外しましたが、念の為に指定しておきます。 Mosaic_df %&gt;% ggplot() + geom_mosaic(aes(x = product(Polity, Continent)), na.rm = TRUE) + labs(x = &quot;Continent&quot;, y = &quot;Polity Type&quot;) + theme_minimal() + theme(panel.grid = element_blank()) ## Warning: `unite_()` was deprecated in tidyr 1.2.0. ## Please use `unite()` instead. ## This warning is displayed once every 8 hours. ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was generated. これで出来上がりですが、\"table\"オブジェクトをplot()に渡した結果とあまり変わらないですね。続いて、この図を少し改良してみましょう。まずはセルの色分けですが、これはfillに色分けする変数をマッピングするだけです。今回は政治体制ごとにセルを色分けしましょう。また、文字を大きめにし、横軸の目盛りラベルを回転します。 Mosaic_df %&gt;% ggplot() + geom_mosaic(aes(x = product(Polity, Continent), fill = Polity), na.rm = TRUE) + labs(x = &quot;Continent&quot;, y = &quot;Polity Type&quot;) + theme_minimal(base_size = 16) + theme(legend.position = &quot;none&quot;, panel.grid = element_blank(), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) 次元を追加するためにはファセット分割を使います。たとえば、一人当たりPPP GDPの高低（PPP）でファセットを分割する場合、facet_wrap(~PPP)レイヤーを足すだけです。 Mosaic_df %&gt;% ggplot() + geom_mosaic(aes(x = product(Polity, Continent), fill = Polity), na.rm = TRUE) + labs(x = &quot;Continent&quot;, y = &quot;Polity Type&quot;) + facet_wrap(~PPP, ncol = 2) + theme_minimal(base_size = 16) + theme(legend.position = &quot;none&quot;, panel.grid = element_blank(), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) ただし、一つ問題があります。それは目盛りラベルの位置です。例えば、右側の横軸目盛りラベルの場合、セルの位置とラベルの位置がずれています。これは2つのファセットが同じ目盛りを共有し、左側の方に合わせられたため生じるものです。よく見ると横軸も縦軸も目盛りラベルに位置が同じであることが分かります。これを解消するためには、facet_wrap()の内部にscale = \"free\"を指定します95。これは各ファセットが独自のスケールを有することを意味します。 Mosaic_df %&gt;% ggplot() + geom_mosaic(aes(x = product(Polity, Continent), fill = Polity), na.rm = TRUE) + labs(x = &quot;Continent&quot;, y = &quot;Polity Type&quot;) + facet_wrap(~PPP, ncol = 2, scale = &quot;free&quot;) + theme_minimal(base_size = 16) + theme(legend.position = &quot;none&quot;, panel.grid = element_blank(), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) 右側ファセットの横軸ラベルが重なってしまいましたが、これでとりあえず完成です。アフリカにおけるOpen AnocracyとClosed Anocracyの頻度が0であるため、これは仕方ありません。一つの対処方法としては以下のように縦軸目盛りを削除し、凡例で代替することが考えられます。 Mosaic_df %&gt;% ggplot() + geom_mosaic(aes(x = product(Polity, Continent), fill = Polity), na.rm = TRUE) + labs(x = &quot;Continent&quot;, y = &quot;Polity Type&quot;, fill = &quot;Polity Type&quot;) + facet_wrap(~PPP, ncol = 2, scale = &quot;free_x&quot;) + theme_minimal(base_size = 16) + theme(panel.grid = element_blank(), axis.text.y = element_blank(), axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) 20.16 その他のグラフ The R Graph Galleryでは本書で紹介できなかった様々な図のサンプルおよびコードを見ることができます。ここまで読み終わった方なら問題なくコードの意味が理解できるでしょう。{ggplot2}では作成できないグラフ（アニメーションや3次元図、インタラクティブなグラフ）についても、他のパッケージを利用した作成方法について紹介されているので、「こんな図が作りたいけど、作り方が分からん！」の時には、まずThe R Graph Galleryに目を通してみましょう。 参考資料 "],["rmarkdown.html", "21. R Markdown [基礎] 21.1 R Markdownとは 21.2 とりあえずKnit 21.3 Markdown文法の基本 21.4 チャンクのオプション 21.5 ヘッダーのオプション 21.6 日本語が含まれているPDFの出力", " 21. R Markdown [基礎] 21.1 R Markdownとは R Markdownとは名前通り、RとMarkdownが結合されたものです。本書を通じてRを紹介してきましたが、Markdownは初めて出てくるものです。John GruberとAaron Swartzが2004年提案した軽量Markup言語ですが、そもそもMarkup言語とはなんでしょうか。 Markup言語を知るためにはプレーンテキスト（plain text）とリッチテキスト（rich text、またはマルチスタイルテキスト）の違いについて知る必要があります。プレーンテキストとは書式情報などが含まれていない純粋なテキストのみで構成されている文書です。書式情報とは文書の余白、文字の大きさ、文字の色などがあります。これまでRStudio上で書いてきたRコードもプレーンテキストです。コードに色が自動的に付けられますが、これはRStudioが色付けをしてくれただけで、ファイル自体はテキストのみで構成されています。macOSのTextEdit、Windowsのメモ帳、Linux GUI環境のgeditやKATE、CLI環境下のvim、Emacs、nanoなどで作成したファイルは全てプレーンテキストです。これらのテキストエディターには書式設定や図表の挿入などの機能は付いておりません。一方、リッチテキストとは書式情報だけでなく、図表なども含まれる文書です。Microsoft Wordとかで作成したファイルがその代表的な例です。他にもPagesやLibreOffice Writerから作成したファイルなどがあります。これらのワードプロセッサーソフトウェアは書式の設定や図表・リンクの挿入などができます。そして、Markup言語とはプレーンテキストのみでリッチテキストを作成するための言語です。 Markup言語の代表的な存在がHTMLです。そもそもHTMLのMLはMarkup Languageの略です。読者の皆さんがウェブブラウザから見る画面のほとんどはHTMLで書かれています。この『私たちのR』もHTMLです。この文書には図表があり、太字、見出し、水平線など、テキスト以外の情報が含んでいます。しかし、HTMLは純粋なテキストのみで書かれており、ウェブブラウザ（Firefox、Chrome、Edgeなど）がテキストファイルを読み込み、解釈して書式が付いている画面を出力してくれます。例えば、リンク（hyperlink）について考えてみましょう。「SONGのHP」をクリックすると宋のホームページに移動します。ある単語をクリックすることで、他のウェブサイトへ飛ばす機能を付けるためにはHTMLファイルの中に、以下のように入力します。 &lt;a href=&quot;https://www.jaysong.net&quot;&gt;SONGのHP&lt;/a&gt; これをウェブブラウザが自動的に「SONGのHP」と変換し、画面に出力してくれます。これは、書式情報などが必要な箇所にコードを埋め込むことによって実現されます。そして、このMarkup言語をより単純な文法で再構成したものがMarkdownです。例えば、以上のHTMLはMarkdownでは以下のように書きます。 [SONGのHP](https://www.jaysong.net) 同じ意味のコードですが、Markdownの方がより簡潔に書けます。このMarkdownは最終的にHTMLやMicrosoft Word、PDF形式で変換されます。一般的にはHTML出力を使いますが、自分のPCにLaTeX環境が用意されている場合はPDF形式で出力することも可能であり、個人的には推奨しておりませんが、Microsoft Work文書ファイルへ変換することも可能です。また、HTML（+ JavaScript）へ出力可能であることを利用し、スライドショー、e-Book、ホームページの作成にもMarkdownが使えます。 R MarkdownはMarkdownにRコードとその結果を同時に載せることができるMarkdownです。それでもピンと来ない方も多いでしょう。それでは、とりあえず、R Markdownをサンプルコードから体験してみましょう。 21.2 とりあえずKnit R Markdownの文法について説明する前に、とりあえずR Markdownというのがどういうものかを味見してみます。既に述べたようにR MarkdownにはRコードも含まれるため、事前にプロジェクトを生成してから進めることをおすすめします。 R Markdownファイルを生成するにはFile -&gt; New File -&gt; R Markdown…を選択します。Title:とAuthor:には文書のタイトルと作成者を入力します。Default Output FormatはデフォルトはHTMLとなっていますが、このままにしておきましょう。ここでの設定はいつでも変更可能ですので、何も触らずにOKを押しても大丈夫です。 OKを押したら自動的にR Markdownのサンプルファイルが生成されます。そしたらSourceペインの上段にあるボタン96をクリックしてみましょう。最初はファイルの保存ダイアログが表示されますが、適切な場所（プロジェクトのフォルダなど）に保存すれば、自動的にMarkdown文書を解釈し始めます。処理が終わればViewerペインに何かの文章が生成されます。これからの内容を進める前にSourceペインとViewerペインの中身をそれぞれ対応しながら、どのような関係があるのかを考えてみましょう。 R Markdownファイルは大きく3つの領域に分けることができます（図@ref(fig: rmarkdown-sample-1)）。まず、最初に---と---で囲まれた領域はヘッダー（Header）と呼ばれる領域です。ここでは題目、作成者情報の入力以外にも、文書全体に通じる設定を行います。これは第21.5節で解説します。次はR Markdownの核心部であるチャンク（Chunk）です。チャンクは```{r}と```で囲まれた領域であり、Rコードが入る箇所です。チャンクに関しましては第21.3節の後半と第21.4節で解説します。その他の領域がマークダウン（Markdown）であり、文書に該当します。 図 21.1: R Markdownのサンプルページ まずは、文章の書き方から説明します。非常に簡単な文法で綺麗、かつ構造化された文書が作成可能であり、これに慣れるとMarkdown基盤のノートアプリなどを使って素早くノート作成、メモが出来ます。 21.3 Markdown文法の基本 まずは、Markdownの文法について解説します。ここではMarkdown文書内に以下のようなことを作成する方法を実際の書き方と、出力画面を対比しながら解説していきます。 改行 強調: 太字、イタリック、アンダーライン、取り消し線 箇条書き 見出し 区切り線 表 画像 リンク 脚注 数式 引用 コメント Rコード 21.3.1 改行 Markdownにおける改行はやや特殊です。特殊といっても難しいことはありません。普段よりもう一行改行するだけです。Markdownの場合、1回の改行は改行として判定されず、同じ行の連続と認識します。たとえば、Inputのように入力するとOutputのように文章1と文章2が繋がります。 Input: 文章1 文章2 Output: 文章1 文章2 文章1と文章2を改行するためにはもう一行、改行する必要があります。以下の例を見てください。 Input: 文章1 文章2 Output: 文章1 文章2 こうすることで段落間の間隔を強制的に入れることとなり、作成者側にも読みやすい文書構造になります97。 21.3.2 強調 文章の一部を強調する方法として太字、イタリック98、アンダーラインがあり、強調ではありませんが、ついでに取り消し線についても紹介します。いずれも強調したい箇所を記号で囲むだけです。 Input: 文章の一部を**太字**にしてみましょう。 *イタリック*もいいですね。 ~~取り消し線~~はあまり使わないかも。 &lt;u&gt;アンダーライン&lt;/u&gt;はHTMLタグを使います。 Output: 文章の一部を太字にしてみましょう。 イタリックもいいですね。 取り消し線はあまり使わないかも。 アンダーラインはHTMLタグを使います。 21.3.3 箇条書き 箇条書きには順序なしと順序付きがあります。順序なしの場合*または-の後に半角スペースを1つ入れるだけです。また、2文字以上の字下げで下位項目を追加することもできます。 Input: - 項目1 - 項目1-1 - 項目1-2 - 項目1-2-1 - 項目1-2-1-1 - 項目1-2-2 - 項目2 - 項目3 Output: 項目1 項目1-1 項目1-2 項目1-2-1 項目1-2-1-1 項目1-2-2 項目2 項目3 続きまして順序付き箇条書きですが、これは-（または*）を数字.に換えるだけです。順序なしの場合と違って数字の後にピリオド（.）が付くことに注意してください。また、下位項目を作成する際、順序なしはスペース2つ以上が必要でしたが、順序付きの場合、少なくとも3つが必要です。 Input: 1. 項目1 1. 項目1-1 2. 項目1-2 2. 項目2 * 項目2-1 * 項目2-2 3. 項目3 Output: 項目1 項目1-1 項目1-2 項目2 項目2-1 項目2-2 項目3 21.3.4 見出し 章、節、段落のタイトルを付ける際は#を使います。#の数が多いほど文字が小さくなります。章の見出しを##にするなら節は###、小節または段落は####が適切でしょう。見出しは####まで使えます。 Input: # 見出し1 ## 見出し2 ### 見出し3 #### 見出し4 Output: 見出し1 見出し2 見出し3 見出し4 21.3.5 区切り線 区切り線は---または***を使います。 Input: --- Output: 21.3.6 表 Markdownの表は非常にシンプルな書き方をしています。行は改行で、列は|で区切られます。ただ、表の第1行はヘッダー（変数名や列名が表示される行）扱いとなり、ヘッダーと内容の区分は|---|で行います。以下はMarkdownを利用した簡単な表の書き方です。ここでは可読性のためにスペースを適宜入れましたが、スペースの有無は結果に影響を与えません。 Input: |ID |Name |Math |English |Favorite food| |:---:|---------|-------:|-------:|-------------| |1 |SONG |15 |10 |Ramen | |2 |Yanai |100 |100 |Cat food | |3 |Shigemura|80 |50 |Raw chicken | |4 |Wickham |80 |90 |Lamb | Output: ID Name Math English Favorite food 1 SONG 15 10 Ramen 2 Yanai 100 100 Cat food 3 Shigemura 80 50 Raw chicken 4 Wickham 80 90 Lamb 1行目はヘッダーであり、太字かつ中央揃えになります。2行目以降はデフォルトでは左揃えになりますが。ただし。|---|をいじることによって当該列の揃えを調整できます。|:---|は左 (デフォルト)、|---:|は右、|:---:|は中央となります。また-の個数は1個以上なら問題ありません。つまり、|-|も|---|も同じです。 21.3.7 画像 R Markdownに画像を入れるには![代替テキスト](ファイル名)と入力します。当たり前ですが、画像ファイルがワーキングディレクトリにない場合はパスを指定する必要があります。[代替テキスト]は画像を読み込めなかった場合のテキストを意味します。これは画像が読み込めなかった場合の代替テキストでもありますが、視覚障害者用のウェブブラウザーのためにも使われます。これらのウェブブラウザーはテキストのみ出力されるものが多く、画像の代わりには代替テキストが読み込まれます。 例えば、HTMLフォルダー内のfavicon.pngというファイルを読み込むとしたら以下のように書きます。 Input: ![『私たちのR』ロゴ](HTML/favicon.png) Output: 21.3.8 リンク ハイパーリンクは[テキスト](URL)のような形式で書きます。[]内は実際に表示されるテキストであり、()は飛ばすURLになります。 Input: 毎日1回は[SONGのホームページ](https://www.jaysong.net)へアクセスしましょう。 Output: 毎日1回はSONGのホームページへアクセスしましょう。 21.3.9 脚注 脚注は[^固有識別子]と[^固有識別子]: 脚注内容の2つの要素が必要です。まず、文末脚注を入れる箇所に[^xxxx]を挿入します。xxxxは任意の文字列れ構いません。しかし、同じR Markdown内においてこの識別子は被らないように注意してください。実際の脚注の内容は[^xxxx]: 内容のように入力します。これはどこに位置しても構いません。文書の途中でも、最後に入れても、脚注の内容は文末に位置します。ただし、脚注を入れる段落のすぐ後の方が作成する側としては読みやすいでしょう。 Input: これは普通の文章です[^foot1]。 [^foot1]: これは普通の脚注です。 Output: これは普通の文章です99。 21.3.10 数式 インライン数式は$数式$で埋め込むことができます。数式はLaTeXの書き方とほぼ同じです。ちなみに、R Markdownの数式はMathJaxによってレンダリングされます。このMathJaxライブラリはHTMLに埋め込まれているのではないため、インターネットに接続せずにHTMLファイルを開くと数式が正しく出力されません。 Input: アインシュタインと言えば、$e = mc^2$でしょう。 Output: アインシュタインと言えば、\\(e = mc^2\\)でしょう。 数式を独立した行として出力する場合は、$の代わりに$$を使用します。 Input: 独立した数式の書き方 $$ y_i \\sim \\text{Normal}(\\mathbf{X} \\boldsymbol{\\beta}, \\sigma). $$ Output: 独立した数式の書き方 \\[ y_i \\sim \\text{Normal}(\\mathbf{X} \\boldsymbol{\\beta}, \\sigma). \\] もし数式が複数の行で構成されている場合は$$内にaligned環境（\\begin{aligned}〜\\end{aligned}）を使用します。むろん、LaTeXと使い方は同じです。 Input: 複数の行にわたる数式の書き方 $$ \\begin{aligned} Y_i &amp; \\sim \\text{Bernoulli}(\\theta_i), \\\\ \\theta_i &amp; = \\text{logit}^{-1}(y_i^*), \\\\ y_i^* &amp; = \\beta_0 + \\beta_1 x_1 + \\beta_2 z_1. \\end{aligned} $$ Output: 複数の行にわたる数式の書き方 \\[ \\begin{aligned} Y_i &amp; \\sim \\text{Bernoulli}(\\theta_i), \\\\ \\theta_i &amp; = \\text{logit}^{-1}(y_i^*), \\\\ y_i^* &amp; = \\beta_0 + \\beta_1 x_1 + \\beta_2 z_1. \\end{aligned} \\] ここまで見ればお分かりかと思いますが、$$の中にはLaTeXコマンドが使用可能です。たとえば、行列を作成する際は以下のように\\begin{bmatrix}環境を使います。 Input: 行列の書き方 $$ X = \\begin{bmatrix} x_{11} &amp; x_{12} \\\\ x_{21} &amp; x_{22} \\\\ x_{31} &amp; x_{32} \\end{bmatrix}. $$ Output: 行列の書き方 \\[ X = \\begin{bmatrix} x_{11} &amp; x_{12} \\\\ x_{21} &amp; x_{22} \\\\ x_{31} &amp; x_{32} \\end{bmatrix}. \\] 21.3.11 引用 引用の際は文章の最初に&gt;を入れるだけです。&gt;の後に半角のスペースが1つ入ります。 Input: 「政治とは何か」についてイーストンは以下のように定義しました。 &gt; [A] political system can be designated as those interactions through which values are authoritatively allocated for a society. Output: 「政治とは何か」についてイーストンは以下のように定義しました。 [A] political system can be designated as those interactions through which values are authoritatively allocated for a society. 21.3.12 コメント R Markdownにもコメントを付けることができます。とりあえず書いたが要らなくなった段落や文章があって、消すことがもったいない場合はコメントアウトするのも1つの方法です。ただし、コメントアウトの方法はRは#でしたが、これはR Markdownでは見出しの記号です。R Markdownのコメントは&lt;!--と--&gt;で囲みます。 Input: 文章1 &lt;!-- ここはコメントです。 --&gt; 文章2 Output: 文章1 文章2 21.3.13 コード 以上の内容まで抑えると、R Markdownを使って、簡単な文法のみで構造化された文書が作成できます。しかし、R Markdownの意義は文章とコード、結果が統合されることです。それでは文書にRコードを入れる方法について紹介します。 コードは```{r}と```の間に入力します。これだけです。これでコードと結果が同時に出力されます。たとえば、print(\"Hello World!\")を走らすコードを入れてみます。 Input: &quot;Hello World!&quot;を出力するコード ```{r} print(&quot;Hello World!&quot;) ``` Output: “Hello World!”を出力するコード print(&quot;Hello World!&quot;) ## [1] &quot;Hello World!&quot; ```{r}と```で囲まれた範囲をR Markdownではチャンク（Chunk）と呼びます。このチャンク内ではRと全く同じことが出来ます。パッケージやデータの読み込み、オブジェクトの生成、データハンドリング、可視化など、全てです。 Input: ```{r} # パッケージの読み込み pacman::p_load(tidyverse) # R内蔵データセットのirisを使った可視化 iris %&gt;% mutate(Species2 = recode(Species, &quot;setosa&quot; = &quot;セトナ&quot;, &quot;versicolor&quot; = &quot;バーシクル&quot;, &quot;virginica&quot; = &quot;バージニカ&quot;)) %&gt;% ggplot() + geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) + labs(x = &quot;萼片の長さ (cm)&quot;, y = &quot;萼片の幅 (cm)&quot;, color = &quot;品種&quot;) + theme_minimal(base_size = 12) ``` Output: # パッケージの読み込み pacman::p_load(tidyverse) # R内蔵データセットのirisを使った可視化 iris %&gt;% mutate(Species2 = recode(Species, &quot;setosa&quot; = &quot;セトナ&quot;, &quot;versicolor&quot; = &quot;バーシクル&quot;, &quot;virginica&quot; = &quot;バージニカ&quot;)) %&gt;% ggplot() + geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) + labs(x = &quot;萼片の長さ (cm)&quot;, y = &quot;萼片の幅 (cm)&quot;, color = &quot;品種&quot;) + theme_minimal(base_size = 12) 他にも文中にRコードを埋め込むことも可能です。例えば、ベクトルX &lt;- c(2, 3, 5, 7, 12)があり、この平均値を文中で示したいとします。むろん、文中に「5.8」と書いても問題はありません。しかし、実はXの入力ミスが見つかり、実はc(2, 3, 5, 7, 11)になったらどうなるでしょうか。この「5.8」と書いた箇所を見つけて5.6と修正したいといけません。これは非常に面倒な作業であり、ミスも起こりやすいです。文中でRコードを入れるためには`rコード`のように入力します。 ```{r} X &lt;- c(2, 3, 5, 7, 11) ``` 変数`X`の平均値は`r mean(X)`です。 Output: X &lt;- c(2, 3, 5, 7, 11) 変数Xの平均値は5.6です。 ここで`X`ですが、単に`で囲まれただけではコードと認識されません。これは主に文中に短いコードを入れる際に使う機能です。 21.4 チャンクのオプション 既に説明しましたとおり、R MakrdownはR + Markdownです。Rはチャンク、Markdownはチャンク外の部分に相当し、それぞれのカスタマイズが可能です。分析のコードと結果はチャンクにオプションを付けることで修正可能であり、文章の部分は次節で紹介するヘッダーで調整できます。ここではチャンクのオプションについて説明します。 チャンクは```{r}で始まりますが、実は{r}の箇所にオプションを追加することができます。具体的には{r チャンク名, オプション1, オプション2, ...}といった形です。まずはチャンク名について解説します。 21.4.1 チャンク名とチャンク間依存関係 チャンク名は{r チャンク名}で指定し、rとチャンク名の間には,が入りません。これはチャンクに名前をしていするオプションですが、多くの場合分析に影響を与えることはありません。このチャンク名が重要となるのはcacheオプションを付ける場合です。 cacheオプションは処理結果を保存しておくことを意味します。チャンク内のコードはKnitする度に計算されます。もし、演算にかなりの時間を費やすコードが含まれている場合、Knitの時間も長くなります。この場合、cache = TRUEオプションを付けておくと、最初のKnit時に結果をファイルとして保存し、次回からはその結果を読み込むだけとなります。時間が非常に節約できるため、よく使われるオプションの1つです。ただし、チャンク内のコードが修正された場合、Knit時にもう一回処理を行います。コードの実質的な内容が変わらなくても、つまり、スペースを1つ入れただけでも再計算となります。 ここで1つ問題が生じます。たとえば、以下のようなコードを考えてみてください。 ```{r} X &lt;- c(2, 3, 5, 7, 10) ``` ```{r, cache = TRUE} mean(X) ``` この構造に問題はありません。しかし、ここでXの5番目の要素を11に修正したとします。そしてもう一回Knitを行ったらどうなるでしょうか。正解は「何も変わらない」です。新しいmean(X)の結果は5.6のはずですが、5.4のままです。なぜなら、2番目のチャンクの結果は既に保存されており、コードも修正していないからです。もう一回強調しておきますが、cahce = TRUEの状態で当該チャンクが修正されない場合、結果は変わりません。 このようにあるチャンクの内容が他のチャンク内容に依存しているケースがあります。この場合、dependsonオプションを使います。使い方はdependson = \"依存するチャンク名\"です。もし、1番目のチャンク名をdefine_Xとしたら、dependson = \"define_X\"とオプションを加えます。 ```{r define_X} X &lt;- c(2, 3, 5, 7, 10) ``` ```{r, cache = TRUE, dependson = &quot;define_X&quot;} mean(X) ``` このようにチャンク名とcache、dependsonオプションを組み合わせると、依存するチャンクの中身が変わったら、cache = TRUEでも再計算を行います。 21.4.2 コードまたは結果の表示/非常時 次は「コードだけ見せたい」、「結果だけ見せたい」場合使うオプションを紹介します。これはあまり使わないかも知れませんが、本書のような技術書にはよく使う機能です。コードのみ出力し、計算を行わない場合はeval = FALSEオプションを、コードを見せず、結果のみ出力する場合はecho = FALSEを指定するだけです。 他にもコードと結果を両方隠すことも可能です。つまり、チャンク内のコードは実行されるが、そのコードと結果を隠すことです。この場合に使うオプションがincludeであり、既定値はTRUEです。チャンクオプションにinclude = FALSEを追加すると、当該チャンクのコードは実行されますが、コードと結果は表示されません。 21.4.3 プロット 既に見てきた通り、R Markdownは作図の結果も出力してくれます。そこで、図のサイズや解像度を変えることもできます。ここではプロットに関するいくつかのオプションを紹介します。 fig.height: 図の高さ。単位はインチ。デフォルト値は7 fig.width: 図の幅。単位はインチ。デフォルト値は7 fig.align: 図の位置。デフォルトは\"left\"。\"center\"の場合、中央揃え、\"right\"の場合は右揃えになる。 fig.cap: 図のキャプション dpi: 図の解像度。デフォルトは72。出版用の図は一般的に300以上を使う 実際に高さ5インチ、幅7インチ、中央揃え、解像度72dpiの図を作成し、キャプションとして「irisデータセットの可視化」を付けてみましょう。 Input: ```{r, fig.height = 5, fig.width = 7, fig.align = &quot;center&quot;, fig.cap = &quot;`iris`データセットの可視化&quot;, dpi = 72} iris %&gt;% mutate(Species2 = recode(Species, &quot;setosa&quot; = &quot;セトナ&quot;, &quot;versicolor&quot; = &quot;バーシクル&quot;, &quot;virginica&quot; = &quot;バージニカ&quot;)) %&gt;% ggplot() + geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) + labs(x = &quot;萼片の長さ (cm)&quot;, y = &quot;萼片の幅 (cm)&quot;, color = &quot;品種&quot;) + theme_minimal(base_size = 12) ``` Output: iris %&gt;% mutate(Species2 = recode(Species, &quot;setosa&quot; = &quot;セトナ&quot;, &quot;versicolor&quot; = &quot;バーシクル&quot;, &quot;virginica&quot; = &quot;バージニカ&quot;)) %&gt;% ggplot() + geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) + labs(x = &quot;萼片の長さ (cm)&quot;, y = &quot;萼片の幅 (cm)&quot;, color = &quot;品種&quot;) + theme_minimal(base_size = 12) 図 21.2: irisデータセットの可視化 21.4.4 コードの見栄 第10章ではスクリプトの書き方を紹介しましたが、常にその書き方に則った書き方をしているとは限りません。自分だけが見るコードなら別に推奨されない書き方でも問題ないかも知れませんが、R Markdownの結果は他人と共有するケースが多いため、読みやすいコードを書くのも大事です。ここで便利なオプションがtidyオプションです。tidy = TRUEを加えると、自動的にコードを読みやすい形に調整してくれます。たとえば、以下のコードは字下げもなく、スペースもほとんど入れていないコードですが、tidy = TRUEを付けた場合と付けなかった場合の出力結果の違いを見てみましょう。 Input: ```{r, eval = FALSE} for(i in 1:10){ print(i*2) } ``` Output: for(i in 1:10){ print(i*2) } Input: ```{r, eval = FALSE, tidy = TRUE} for(i in 1:10){ print(i*2) } ``` Output: for (i in 1:10) { print(i * 2) } tidy = TRUEを付けただけで、読みやすいコードになりました。ちなみにtidyオプションを使うためには事前に{formatR}パッケージをインストールしておく必要があります。ただし、{formatR}パッケージはR Markdwon内において読み込んでおく必要はありません。また、{formatR}パッケージは万能ではないため、普段から読みやすいコードを書くようにしましょう。 21.4.5 チャンクオプションのもう一つの書き方 これまでチャンクオプションは{r}の内部に指定すると述べましたが、チャンクオプションが多くなる場合、チャンクの第1行目が長くなり、コードの可読性が低下する可能性があります。ここで便利な機能が#|によるチャンクオプションの指定です。これはチャンク内部に#|を書いておけば、#|以降の内容がチャンクオプションとして認識される機能です。 図21.2の作図チャンクは以下のように書くことも可能です。 ```{r} #| fig.height: 5 #| fig.width: 7 #| fig.align: &quot;center&quot; #| fig.cap: &quot;`iris`データセットの可視化&quot; #| dpi: 72 iris %&gt;% mutate(Species2 = recode(Species, &quot;setosa&quot; = &quot;セトナ&quot;, &quot;versicolor&quot; = &quot;バーシクル&quot;, &quot;virginica&quot; = &quot;バージニカ&quot;)) %&gt;% ggplot() + geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) + labs(x = &quot;萼片の長さ (cm)&quot;, y = &quot;萼片の幅 (cm)&quot;, color = &quot;品種&quot;) + theme_minimal(base_size = 12) ``` もう一つの方法は、全て (あるいは、ほとんど)のチャンクに渡って共通するチャンクオプションの場合、最初に宣言しておくことです。もし、全ての図を中央に揃え (fig.align = \"center\")、解像度を300dpi (dpi = 300)にするなら、後述するYAMLヘッダーに続く最初のチャンクを以下のように書きます。 ```{r, include = FALSE} knitr::opts_chunk$set(fig.align = &quot;center&quot;, dpi = 300) ``` こう書いておくと、そのRMarkdownファイルの全てのチャンクにfig.align = \"center\"とdpi = 300オプションが付くようになります。一部のチャンクにfig.alignやdpiのオプションを付ける場合、当該チャンクのオプションが優先されます。 このようにチャンクオプションが見やすくなるメリットがありますが、現在 (2022年03月16日)のRStudioは、チャンク内部のオプション指定の入力補助に対応していないことに注意してください。 ただし、通常の書き方だとif()文のような条件分岐がチャンクのオプションとして使えますが、#|の書き方だと正しく作動しません。 21.5 ヘッダーのオプション R Markdownファイルを生成すると、ファイルの最上段には以下のようなヘッダー（header）というものが生成されます。 --- title: &quot;Untitled&quot; author: &quot;Jaehyun Song&quot; date: &quot;8/6/2020&quot; output: html_document --- 基本的には4つの項目が指定されており、それぞれ文書のタイトル（title:）、作成者名（author:）、作成日（date:）、出力形式（output:）があります。タイトルと作成者名はファイル生成時に指定した内容が、作成日は今日の日付が、出力形式はHTMLで設定した場合html_documentになっています。R MarkdownヘッダーはYAML（やむる）形式で書かれています。こちらはいつでも修正可能であり、インラインRコードを埋め込むことも可能です。たとえば、作成日をファイル生成日でなく、Knitした日付にしたい場合は日付を出力するSys.Date()関数を使って、date: \"最終修正: `r Sys.Date()`\"のように書くことも可能です。他にもデフォルトでは指定されていませんが、subtitle:を使ってサブタイトルを指定したり、abstract:で要約を入れることも可能です。 また、R Markdownのコメントは&lt;!--と--&gt;を使いますが、ヘッダー内のコメントはRと同様、#を使います。 ヘッダーで設定できる項目は数十個以上ですが、ここでは頻繁に使われる項目について紹介します。 21.5.1 目次の追加 R Markdownの文章が長くなったり、コードが多く含まれる場合、目次を入れたら文章の構造が一目で把握できるでしょう。目次は見出しに沿って自動的に生成されます。#は章、##は節といった形式です。 --- title: &quot;タイトル&quot; subtitle: &quot;サブタイトル&quot; author: &quot;作成者名&quot; date: &quot;最終修正: `r Sys.Date()`&quot; output: html_document: toc: FALSE toc_depth: 3 toc_float: FALSE number_sections: FALSE --- 字下げには常に注意してください。html_documentはoutput:の下位項目ですから、字下げを行います。また、tocはhtml_documentの下位項目ですので、更に字下げをします。ここでは目次と関連する項目として以下の4つを紹介します。 toc: 目次の出力有無 デフォルトはFALSE、目次を出力する際はTRUEにします。 toc_depth: 目次の深さを指定 デフォルトは3であり、これはどのレベルの見出しまで目次に含むかをしてします。toc_depth: 2なら##見出しまで目次に出力されます toc_float: 目次のフローティング デフォルトはFALSEです。これをTRUEにすると、目次は文書の左側に位置するようになり、文書をスクロールしても目次が付いてきます。 number_sections: 見出しに通し番号を付けるか デフォルトはFALSEです。これをTRUEにすると、見出しに通し番号が付きます。むろん、付いた通し番号は目次でも出力されます。 21.5.2 コードのハイライト R Markdownの場合、コードチャンク内のコードの一部に対して自動的に色付けを行います。たとえば、本書の場合、関数名は緑、引数は赤、文字列は青といった形です。これはコードの可読性を向上させる効果もあります。この色付けの詳細はhtml_document:のhighligh:から調整できます。 --- title: &quot;タイトル&quot; subtitle: &quot;サブタイトル&quot; author: &quot;作成者名&quot; date: &quot;最終修正: `r Sys.Date()`&quot; output: html_document: highlight: &quot;tango&quot; --- R Markdown 2.3の場合、使用可能なテーマは以下の10種類です。自分の好みでハイライトテーマを替えてみましょう。 highlight 出力結果 \"default\" \"tango\" \"pygments\" \"kate\" \"monochrome\" \"espresso\" \"zenburn\" \"haddock\" \"breezedark\" \"textmate\" 21.6 日本語が含まれているPDFの出力 日本語が含まれているPDF出力には片桐智志さんの{rmdja}パッケージが提供するテンプレが便利です。{rmdja}パッケージの詳細は公式レポジトリに譲りますが、ここでは簡単な例をお見せします。以下の内容は自分のPCにLaTeX環境が導入されている場合を想定しています100。 まずは{rmdja}のインストールからです。CRANに登録されていたいため、GitHub経由でインストールします。 # remotes::の代わりにdevtools::も可 # pacman::p_install_gh()も可 remotes::install_github(&#39;Gedevan-Aleksizde/rmdja&#39;) 次はR Markdown文書を作成しますが、RStudioのFile &gt; New File &gt; R Markdown …を選択します。左側のFrom Templateを選択し、pdf article in Japaneseを選択します。OKをクリックするとサンプル文書が表示されるので、YAMLヘッダー以下の内容を修正するだけです。図表番号などの相互参照（corss reference）が初回Knitでは反映されない場合がありますが、2回目からは表示されます。 "],["rmarkdown2.html", "22. R Markdown [応用] 22.1 スライド作成 22.2 書籍 22.3 ホームページ 22.4 履歴書 22.5 パッケージ開発 22.6 Webアプリケーション 22.7 チュートリアル", " 22. R Markdown [応用] R Markdownでできることを紹介。使い方は説明しない 22.1 スライド作成 {xaringan} 22.2 書籍 {bookdown} 22.3 ホームページ {distill}、{blogdown} 22.4 履歴書 {vitae} 22.5 パッケージ開発 {fusen} 簡単なものなら{fusen}で十分だが、ちゃんとした (?) ものを作るなら {devtools} + {usethis} + {roxygen2} + {testthat} + {pkgdown}を使おう 22.6 Webアプリケーション {shiny} 22.7 チュートリアル {learnr} "],["table.html", "23. 表の作成 23.1 {kableExtra}の使い方 23.2 {gt}の使い方 23.3 データの出力", " 23. 表の作成 pacman::p_load(tidyverse, kableExtra, gt, DT) country_df &lt;- read_csv(&quot;Data/Countries.csv&quot;) HTML出力のみならどっちでも問題ないが、{gt}が使いやすい。 ただし、{gt}は開発途上であり、PDF出力との相性が現在 (2022-03-16)、優れているとはいい難いので、PDF出力まで考えているのであれば{knitr}のkable() + {kableExtra}を推奨 LaTeX出力とHTML出力の見た目が異なるため、調整が必要 23.1 {kableExtra}の使い方 country_dfのPopulation (100万で割った値)、Area (1万で割った値)、GPP_per_capita (1万で割った値)、PPP_per_capita (1万で割った値)、HDI_2018、Polity_Score、FH_Totalの記述統計 コード入力が面倒であれば、コピペでOK country_desc &lt;- country_df %&gt;% mutate(Population = Population / 1000000, Area = Area / 10000, GDP_per_capita = GDP_per_capita / 10000, PPP_per_capita = PPP_per_capita / 10000) %&gt;% select(Population, Area, GDP_per_capita, PPP_per_capita, HDI_2018, Polity_Score, FH_Total) %&gt;% summarise(across(everything(), .fns = list(&quot;Mean&quot; = ~mean(.x, na.rm = TRUE), &quot;SD&quot; = ~sd(.x, na.rm = TRUE), &quot;Min&quot; = ~min(.x, na.rm = TRUE), &quot;Max&quot; = ~max(.x, na.rm = TRUE), &quot;Obs&quot; = ~sum(!is.na(.x))), .names = &quot;{.col}-{.fn}&quot;)) %&gt;% pivot_longer(cols = everything(), names_to = &quot;Label&quot;, values_to = &quot;Value&quot;) %&gt;% separate(col = &quot;Label&quot;, into = c(&quot;Variable&quot;, &quot;Stat&quot;), sep = &quot;-&quot;) %&gt;% pivot_wider(names_from = Stat, values_from = Value) country_desc ## # A tibble: 7 × 6 ## Variable Mean SD Min Max Obs ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Population 41.7 151. 0.000801 1447. 186 ## 2 Area 69.6 187. 0 1638. 186 ## 3 GDP_per_capita 1.62 2.57 0.00577 18.3 185 ## 4 PPP_per_capita 2.08 2.10 0.0733 11.3 178 ## 5 HDI_2018 0.713 0.153 0.377 0.954 180 ## 6 Polity_Score 4.26 6.10 -10 10 158 ## 7 FH_Total 57.7 29.9 0 100 185 {summarytools}のdescr()を使う場合 pacman::p_load(summarytools) country_desc &lt;- country_df %&gt;% mutate(Population = Population / 1000000, Area = Area / 10000, GDP_per_capita = GDP_per_capita / 10000, PPP_per_capita = PPP_per_capita / 10000) %&gt;% select(Population, Area, GDP = GDP_per_capita, PPP = PPP_per_capita, HDI = HDI_2018, Polity = Polity_Score, FreedomHouse = FH_Total) %&gt;% descr(stats = c(&quot;mean&quot;, &quot;sd&quot;, &quot;min&quot;, &quot;max&quot;, &quot;n.valid&quot;), order = &quot;preserve&quot;, transpose = TRUE) %&gt;% as.data.frame() %&gt;% rownames_to_column(&quot;Variable&quot;) %&gt;% rename(SD = Std.Dev, Obs = N.Valid) %&gt;% as_tibble() country_desc ## # A tibble: 7 × 6 ## Variable Mean SD Min Max Obs ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Population 41.7 151. 0.000801 1447. 186 ## 2 Area 69.6 187. 0 1638. 186 ## 3 GDP 1.62 2.57 0.00577 18.3 185 ## 4 PPP 2.08 2.10 0.0733 11.3 178 ## 5 HDI 0.713 0.153 0.377 0.954 180 ## 6 Polity 4.26 6.10 -10 10 158 ## 7 FreedomHouse 57.7 29.9 0 100 185 23.1.1 表の出力 kbl(country_desc) Variable Mean SD Min Max Obs Population 41.7377735 151.2702976 0.0008010 1447.47009 186 Area 69.6069247 187.2412489 0.0000000 1637.68700 186 GDP 1.6158103 2.5710359 0.0057700 18.31772 185 PPP 2.0833383 2.0992134 0.0733142 11.34231 178 HDI 0.7134833 0.1528503 0.3770000 0.95400 180 Polity 4.2594937 6.1022919 -10.0000000 10.00000 158 FreedomHouse 57.7135135 29.8656244 0.0000000 100.00000 185 小数点桁数の調整 country_desc %&gt;% kbl(digits = 3) Variable Mean SD Min Max Obs Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 表の幅 (HTML限定) country_desc %&gt;% kbl(digits = 3) %&gt;% kable_styling(full_width = FALSE) Variable Mean SD Min Max Obs Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 23.1.2 列の操作 列名の修正 全ての列を指定する必要がある country_desc %&gt;% kbl(col.names = c(&quot;変数&quot;, &quot;平均値&quot;, &quot;標準偏差&quot;, &quot;最小値&quot;, &quot;最大値&quot;, &quot;観察数&quot;), digits = 3) 変数 平均値 標準偏差 最小値 最大値 観察数 Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 列の揃え 全ての列を指定する必要がある # 不要だが、あえてVariable列を中央揃えにする country_desc %&gt;% kbl(align = c(&quot;crrrrr&quot;), digits = 3) Variable Mean SD Min Max Obs Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 23.1.3 タイトル、フットノート country_desc %&gt;% kbl(caption = &quot;記述統計表&quot;, digits = 3) 表 23.1: 記述統計表 Variable Mean SD Min Max Obs Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 country_desc %&gt;% kbl(caption = &quot;記述統計表&quot;, digits = 3) %&gt;% footnote(general = &quot;『私たちのR』のサンプルデータ&quot;, general_title = &quot;出典:&quot;) 表 23.2: 記述統計表 Variable Mean SD Min Max Obs Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 出典: 『私たちのR』のサンプルデータ country_desc2 &lt;- country_desc names(country_desc2)[4:5] &lt;- paste0(names(country_desc2)[4:5], footnote_marker_number(1)) names(country_desc2)[6] &lt;- paste0(names(country_desc2)[6], footnote_marker_number(2)) country_desc2 %&gt;% kbl(caption = &quot;記述統計表&quot;, escape = FALSE, digits = 3) %&gt;% footnote(general = &quot;出典: 『私たちのR』のサンプルデータ&quot;, number = c(&quot;欠損値を除く&quot;, &quot;欠損していないケース数&quot;)) 表 23.3: 記述統計表 Variable Mean SD Min1 Max1 Obs2 Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 Note: 出典: 『私たちのR』のサンプルデータ 1 欠損値を除く 2 欠損していないケース数 23.1.4 グループ化 列のグループ化 グループ化しない列のラベルは\"\"でなく、\" \"にする。 country_desc %&gt;% kbl(digits = 3) %&gt;% add_header_above(c(&quot; &quot; = 3, &quot;Range&quot; = 2, &quot; &quot; = 1)) Range Variable Mean SD Min Max Obs Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 行のグループ化 country_desc %&gt;% kbl(digits = 3) %&gt;% pack_rows(&quot;Demographic factors&quot;, 1, 2) %&gt;% pack_rows(&quot;Economic factors&quot;, 3, 5) %&gt;% pack_rows(&quot;Political factors&quot;, 6, 7) Variable Mean SD Min Max Obs Demographic factors Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 Economic factors GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Political factors Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 country_desc3 &lt;- country_desc %&gt;% mutate(Factor = c(rep(&quot;Demographic&quot;, 2), rep(&quot;Economic&quot;, 3), rep(&quot;Political&quot;, 2)), .before = Variable) country_desc3 %&gt;% kbl(digits = 3) Factor Variable Mean SD Min Max Obs Demographic Population 41.738 151.270 0.001 1447.470 186 Demographic Area 69.607 187.241 0.000 1637.687 186 Economic GDP 1.616 2.571 0.006 18.318 185 Economic PPP 2.083 2.099 0.073 11.342 178 Economic HDI 0.713 0.153 0.377 0.954 180 Political Polity 4.259 6.102 -10.000 10.000 158 Political FreedomHouse 57.714 29.866 0.000 100.000 185 country_desc3 %&gt;% kbl(digits = 3) %&gt;% collapse_rows(columns = 1, valign = &quot;top&quot;) Factor Variable Mean SD Min Max Obs Demographic Population 41.738 151.270 0.001 1447.470 186 Demographic Area 69.607 187.241 0.000 1637.687 186 Economic GDP 1.616 2.571 0.006 18.318 185 Economic PPP 2.083 2.099 0.073 11.342 178 Economic HDI 0.713 0.153 0.377 0.954 180 Political Polity 4.259 6.102 -10.000 10.000 158 Political FreedomHouse 57.714 29.866 0.000 100.000 185 23.1.5 セルの色分け（HTML限定） {formattable}パッケージ使用 country_desc4 &lt;- country_df %&gt;% mutate(Population = Population / 1000000, Area = Area / 10000, GDP_per_capita = GDP_per_capita / 10000, PPP_per_capita = PPP_per_capita / 10000) %&gt;% select(HDI_2018, Population, Area, GDP = GDP_per_capita, PPP = PPP_per_capita, Polity = Polity_Score, FreedomHouse = FH_Total) %&gt;% drop_na() %&gt;% cor() %&gt;% as.data.frame() %&gt;% rownames_to_column(&quot;Variable&quot;) %&gt;% select(Variable, Cor = HDI_2018) %&gt;% filter(Variable != &quot;HDI_2018&quot;) country_desc4 %&gt;% kbl(digits = 3) Variable Cor Population 0.001 Area 0.125 GDP 0.714 PPP 0.801 Polity 0.287 FreedomHouse 0.574 pacman::p_load(formattable) country_desc4$Cor2 &lt;- color_text(&quot;blue&quot;, &quot;red&quot;)(sprintf(&quot;%.3f&quot;, country_desc4$Cor)) country_desc4$Cor3 &lt;- color_tile(&quot;white&quot;, &quot;mistyrose&quot;)(sprintf(&quot;%.3f&quot;, country_desc4$Cor)) country_desc4 %&gt;% kbl(col.names = c(&quot;変数&quot;, &quot;数字のみ&quot;, &quot;文字色&quot;, &quot;色塗り&quot;), digits = 3, escape = FALSE) %&gt;% add_header_above(c(&quot; &quot; = 1, &quot;人間開発指数との相関係数&quot; = 3)) 人間開発指数との相関係数 変数 数字のみ 文字色 色塗り Population 0.001 0.001 0.001 Area 0.125 0.125 0.125 GDP 0.714 0.714 0.714 PPP 0.801 0.801 0.801 Polity 0.287 0.287 0.287 FreedomHouse 0.574 0.574 0.574 23.1.6 テーマ country_desc %&gt;% kbl(digits = 3) %&gt;% kable_paper() Variable Mean SD Min Max Obs Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 country_desc %&gt;% kbl(digits = 3) %&gt;% kable_classic() Variable Mean SD Min Max Obs Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 country_desc %&gt;% kbl(digits = 3) %&gt;% kable_classic_2() Variable Mean SD Min Max Obs Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 country_desc %&gt;% kbl(digits = 3) %&gt;% kable_minimal() Variable Mean SD Min Max Obs Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 country_desc %&gt;% kbl(digits = 3) %&gt;% kable_material() Variable Mean SD Min Max Obs Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 country_desc %&gt;% kbl(digits = 3) %&gt;% kable_paper(bootstrap_options = &quot;striped&quot;, full_width = FALSE) Variable Mean SD Min Max Obs Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 country_desc %&gt;% kbl(digits = 3) %&gt;% kable_paper(bootstrap_options = c(&quot;striped&quot;, &quot;condensed&quot;), full_width = FALSE) Variable Mean SD Min Max Obs Population 41.738 151.270 0.001 1447.470 186 Area 69.607 187.241 0.000 1637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 -10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 他にも\"hover\"や\"responsive\"、\"bordered\"あり テーマを変更せずにスタイルを変更したい場合はkable_styling()を使用 23.2 {gt}の使い方 そのままcountry_descを使用 表の出力 gt(country_desc) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #mnxwcmxlbj .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #mnxwcmxlbj .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mnxwcmxlbj .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #mnxwcmxlbj .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #mnxwcmxlbj .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mnxwcmxlbj .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #mnxwcmxlbj .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #mnxwcmxlbj .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #mnxwcmxlbj .gt_column_spanner_outer:first-child { padding-left: 0; } #mnxwcmxlbj .gt_column_spanner_outer:last-child { padding-right: 0; } #mnxwcmxlbj .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #mnxwcmxlbj .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #mnxwcmxlbj .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #mnxwcmxlbj .gt_from_md > :first-child { margin-top: 0; } #mnxwcmxlbj .gt_from_md > :last-child { margin-bottom: 0; } #mnxwcmxlbj .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #mnxwcmxlbj .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #mnxwcmxlbj .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #mnxwcmxlbj .gt_row_group_first td { border-top-width: 2px; } #mnxwcmxlbj .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mnxwcmxlbj .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #mnxwcmxlbj .gt_first_summary_row.thick { border-top-width: 2px; } #mnxwcmxlbj .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mnxwcmxlbj .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #mnxwcmxlbj .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #mnxwcmxlbj .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #mnxwcmxlbj .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #mnxwcmxlbj .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mnxwcmxlbj .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #mnxwcmxlbj .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #mnxwcmxlbj .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #mnxwcmxlbj .gt_left { text-align: left; } #mnxwcmxlbj .gt_center { text-align: center; } #mnxwcmxlbj .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #mnxwcmxlbj .gt_font_normal { font-weight: normal; } #mnxwcmxlbj .gt_font_bold { font-weight: bold; } #mnxwcmxlbj .gt_font_italic { font-style: italic; } #mnxwcmxlbj .gt_super { font-size: 65%; } #mnxwcmxlbj .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #mnxwcmxlbj .gt_asterisk { font-size: 100%; vertical-align: 0; } #mnxwcmxlbj .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #mnxwcmxlbj .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #mnxwcmxlbj .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } Variable Mean SD Min Max Obs Population 41.7377735 151.2702976 0.000801000 1447.47009 186 Area 69.6069247 187.2412489 0.000000000 1637.68700 186 GDP 1.6158103 2.5710359 0.005770007 18.31772 185 PPP 2.0833383 2.0992134 0.073314173 11.34231 178 HDI 0.7134833 0.1528503 0.377000000 0.95400 180 Polity 4.2594937 6.1022919 -10.000000000 10.00000 158 FreedomHouse 57.7135135 29.8656244 0.000000000 100.00000 185 小数点桁数の調整 country_desc %&gt;% gt() %&gt;% fmt_number(columns = 2:5, decimals = 3) html { font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif; } #otslrwrcls .gt_table { display: table; border-collapse: collapse; margin-left: auto; margin-right: auto; color: #333333; font-size: 16px; font-weight: normal; font-style: normal; background-color: #FFFFFF; width: auto; border-top-style: solid; border-top-width: 2px; border-top-color: #A8A8A8; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #A8A8A8; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; } #otslrwrcls .gt_heading { background-color: #FFFFFF; text-align: center; border-bottom-color: #FFFFFF; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #otslrwrcls .gt_title { color: #333333; font-size: 125%; font-weight: initial; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; border-bottom-color: #FFFFFF; border-bottom-width: 0; } #otslrwrcls .gt_subtitle { color: #333333; font-size: 85%; font-weight: initial; padding-top: 0; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; border-top-color: #FFFFFF; border-top-width: 0; } #otslrwrcls .gt_bottom_border { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #otslrwrcls .gt_col_headings { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; } #otslrwrcls .gt_col_heading { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 6px; padding-left: 5px; padding-right: 5px; overflow-x: hidden; } #otslrwrcls .gt_column_spanner_outer { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: normal; text-transform: inherit; padding-top: 0; padding-bottom: 0; padding-left: 4px; padding-right: 4px; } #otslrwrcls .gt_column_spanner_outer:first-child { padding-left: 0; } #otslrwrcls .gt_column_spanner_outer:last-child { padding-right: 0; } #otslrwrcls .gt_column_spanner { border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: bottom; padding-top: 5px; padding-bottom: 5px; overflow-x: hidden; display: inline-block; width: 100%; } #otslrwrcls .gt_group_heading { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; } #otslrwrcls .gt_empty_group_heading { padding: 0.5px; color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; vertical-align: middle; } #otslrwrcls .gt_from_md > :first-child { margin-top: 0; } #otslrwrcls .gt_from_md > :last-child { margin-bottom: 0; } #otslrwrcls .gt_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; margin: 10px; border-top-style: solid; border-top-width: 1px; border-top-color: #D3D3D3; border-left-style: none; border-left-width: 1px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 1px; border-right-color: #D3D3D3; vertical-align: middle; overflow-x: hidden; } #otslrwrcls .gt_stub { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; } #otslrwrcls .gt_stub_row_group { color: #333333; background-color: #FFFFFF; font-size: 100%; font-weight: initial; text-transform: inherit; border-right-style: solid; border-right-width: 2px; border-right-color: #D3D3D3; padding-left: 5px; padding-right: 5px; vertical-align: top; } #otslrwrcls .gt_row_group_first td { border-top-width: 2px; } #otslrwrcls .gt_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #otslrwrcls .gt_first_summary_row { border-top-style: solid; border-top-color: #D3D3D3; } #otslrwrcls .gt_first_summary_row.thick { border-top-width: 2px; } #otslrwrcls .gt_last_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #otslrwrcls .gt_grand_summary_row { color: #333333; background-color: #FFFFFF; text-transform: inherit; padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; } #otslrwrcls .gt_first_grand_summary_row { padding-top: 8px; padding-bottom: 8px; padding-left: 5px; padding-right: 5px; border-top-style: double; border-top-width: 6px; border-top-color: #D3D3D3; } #otslrwrcls .gt_striped { background-color: rgba(128, 128, 128, 0.05); } #otslrwrcls .gt_table_body { border-top-style: solid; border-top-width: 2px; border-top-color: #D3D3D3; border-bottom-style: solid; border-bottom-width: 2px; border-bottom-color: #D3D3D3; } #otslrwrcls .gt_footnotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #otslrwrcls .gt_footnote { margin: 0px; font-size: 90%; padding-left: 4px; padding-right: 4px; padding-left: 5px; padding-right: 5px; } #otslrwrcls .gt_sourcenotes { color: #333333; background-color: #FFFFFF; border-bottom-style: none; border-bottom-width: 2px; border-bottom-color: #D3D3D3; border-left-style: none; border-left-width: 2px; border-left-color: #D3D3D3; border-right-style: none; border-right-width: 2px; border-right-color: #D3D3D3; } #otslrwrcls .gt_sourcenote { font-size: 90%; padding-top: 4px; padding-bottom: 4px; padding-left: 5px; padding-right: 5px; } #otslrwrcls .gt_left { text-align: left; } #otslrwrcls .gt_center { text-align: center; } #otslrwrcls .gt_right { text-align: right; font-variant-numeric: tabular-nums; } #otslrwrcls .gt_font_normal { font-weight: normal; } #otslrwrcls .gt_font_bold { font-weight: bold; } #otslrwrcls .gt_font_italic { font-style: italic; } #otslrwrcls .gt_super { font-size: 65%; } #otslrwrcls .gt_footnote_marks { font-style: italic; font-weight: normal; font-size: 75%; vertical-align: 0.4em; } #otslrwrcls .gt_asterisk { font-size: 100%; vertical-align: 0; } #otslrwrcls .gt_slash_mark { font-size: 0.7em; line-height: 0.7em; vertical-align: 0.15em; } #otslrwrcls .gt_fraction_numerator { font-size: 0.6em; line-height: 0.6em; vertical-align: 0.45em; } #otslrwrcls .gt_fraction_denominator { font-size: 0.6em; line-height: 0.6em; vertical-align: -0.05em; } Variable Mean SD Min Max Obs Population 41.738 151.270 0.001 1,447.470 186 Area 69.607 187.241 0.000 1,637.687 186 GDP 1.616 2.571 0.006 18.318 185 PPP 2.083 2.099 0.073 11.342 178 HDI 0.713 0.153 0.377 0.954 180 Polity 4.259 6.102 &minus;10.000 10.000 158 FreedomHouse 57.714 29.866 0.000 100.000 185 23.3 データの出力 通常の出力の場合 country_df ## # A tibble: 186 × 18 ## Country Population Area GDP PPP GDP_per_capita PPP_per_capita G7 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghani… 38928346 6.53e5 1.91e4 8.27e4 491. 2125. 0 ## 2 Albania 2877797 2.74e4 1.53e4 3.97e4 5309. 13781. 0 ## 3 Algeria 43851044 2.38e6 1.70e5 4.97e5 3876. 11324. 0 ## 4 Andorra 77265 4.7 e2 3.15e3 NA 40821. NA 0 ## 5 Angola 32866272 1.25e6 9.46e4 2.19e5 2879. 6649. 0 ## 6 Antigua… 97929 4.4 e2 1.73e3 2.08e3 17643. 21267. 0 ## 7 Argenti… 45195774 2.74e6 4.50e5 1.04e6 9949. 22938. 0 ## 8 Armenia 2963243 2.85e4 1.37e4 3.84e4 4614. 12974. 0 ## 9 Austral… 25499884 7.68e6 1.39e6 1.28e6 54615. 50001. 0 ## 10 Austria 9006398 8.24e4 4.46e5 5.03e5 49555. 55824. 0 ## # … with 176 more rows, and 10 more variables: G20 &lt;dbl&gt;, OECD &lt;dbl&gt;, ## # HDI_2018 &lt;dbl&gt;, Polity_Score &lt;dbl&gt;, Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;, ## # FH_CL &lt;dbl&gt;, FH_Total &lt;dbl&gt;, FH_Status &lt;chr&gt;, Continent &lt;chr&gt; {DT}パッケージのdatatable()関数を使用した場合 datatable(country_df) "],["visualization5.html", "24. モデルの可視化", " 24. モデルの可視化 "],["renv.html", "25. 分析環境の管理", " 25. 分析環境の管理 {renv}による分析環境の管理/共有 分析環境と再現可能な研究 例1: 古いパッケージではできなかったものが、今はできるようになっている {ggplot2}のgeom_pointrange()の場合、昔は点と垂直線のみが引けた（マッピングはx、y、ymin、ymaxのみ可能）。 点と水平線の描きたい場合は、coord_flip()で座標系を回転する必要があった。 今の{ggplot2}だと、xminとxmaxにもマッピングができるため、coord_flip()不要 多分いないと思うが、現在の仕様でコードを古い{ggplot2}で走らせるとエラーが出る。 例2: 昔はできたものの、今はできない 華麗に復活した{dplyr}のrowwise()は、無くなりかけていた関数 {tidyr}のgather()とspread()は近い将来、無くなる 例3: 仕様が変わり、関数名、仮引数名、実引数の使用可能なクラスが異なる場合 開発途上のパッケージだとあり得る。 {revn}のインストール pacman::p_load(renv) 分析環境の保存 プロジェクトの使用を強く推奨 (第6.2章を参照) 分析を始める前: コンソールに renv::init() 分析が終わった後: コンソールに renv::snapshot() 分析環境を再現 renv::restore() 詳細は{renv}開発者のページを参照 {pacman}との相性は大丈夫だろうか。また、GitHubから導入したパッケージの場合は? "],["datahandling3.html", "26. データハンドリング[応用編]", " 26. データハンドリング[応用編] ここでは整形されていない状態のデータを "],["iteration.html", "27. 反復処理 27.1 概要 27.2 *apply()関数群とmap_*()関数群 27.3 引数が2つ以上の場合 27.4 データフレームと{purrr} 27.5 モデルの反復推定", " 27. 反復処理 27.1 概要 *apply()関数群とmap_*()関数群 引数が2つ以上の場合 データフレームと{purrr} モデルの反復推定 サンプルの分割とモデル推定（split()利用） サンプルの分割とモデル推定（nest()利用） データの範囲を指定したモデル推定 説明・応答変数を指定したモデル推定 27.2 *apply()関数群とmap_*()関数群 まず、我らの盟友、{tidyverse}を読み込んでおきましょう。 pacman::p_load(tidyverse) それでは、*apply()関数群とmap_*()関数群の動きとその仕組について調べてみましょう。まず、実習用データとして長さ5のnumericベクトルnum_vecを用意します。 num_vec &lt;- c(3, 2, 5, 4, 7) このnum_vecの個々の要素に2を足す場合はどうすれば良いでしょうか。Rはベクトル単位での演算が行われるため、num_vec + 2だけで十分です。+の右側にある2は長さ1のベクトルですが、num_vecの長さに合わせてリサイクルされます（第9.2章を参照）。 num_vec + 2 ## [1] 5 4 7 6 9 賢明なRユーザーなら上のコードが正解でしょう。しかし、これからの練習のために+を使わずに、for()文を使用してみましょう（第10.3章を参照）。 for (i in num_vec) { print(i + 2) } ## [1] 5 ## [1] 4 ## [1] 7 ## [1] 6 ## [1] 9 実はこれと同じ役割をする関数がRには内蔵されており、それがlapply()関数です。 lapply(オブジェクト名, 関数名, 関数の引数) 以下のコードからも確認出来ますが、足し算を意味する+も関数です。ただし、演算子を関数として使う場合は演算子を`で囲む必要があり、+だと`+`と表記します。 `+`(num_vec, 2) ## [1] 5 4 7 6 9 したがって、lapply()関数を使用してnum_vecの全要素に2を足す場合、以下のようなコードとなります。 lapply(num_vec, `+`, 2) ## [[1]] ## [1] 5 ## ## [[2]] ## [1] 4 ## ## [[3]] ## [1] 7 ## ## [[4]] ## [1] 6 ## ## [[5]] ## [1] 9 これと同じ動きをする関数が{purrr}パッケージのmap()です。{purrr}は{tidyverse}を読み込むと自動的に読み込まれます。 map(num_vec, `+`, 2) ## [[1]] ## [1] 5 ## ## [[2]] ## [1] 4 ## ## [[3]] ## [1] 7 ## ## [[4]] ## [1] 6 ## ## [[5]] ## [1] 9 ただし、lapply()とmap()の場合、戻り値はリスト型となります。もし、ベクトル型の戻り値が必要な場合は更にunlist()関数を使うか、sapply()を使います。 # unlist()を利用し、リストを解除する lapply(num_vec, `+`, 2) %&gt;% unlist() ## [1] 5 4 7 6 9 # sapply()を利用すると戻り値はベクトルとなる sapply(num_vec, `+`, 2) ## [1] 5 4 7 6 9 map()関数ならunlist()でも良いですが、sapply()と同じ動きをするmap_dbl()があります。これは戻り値がdoubleのnumericベクトルになるmap()関数です。 # map_dbl()を利用するとnumeric (double)のベクトルが返される map_dbl(num_vec, `+`, 2) ## [1] 5 4 7 6 9 もし、2を足すだけでなく、更に3で割るためにはどうすれば良いでしょうか。まず考えられるのは更にsapply()やmap_dblを使うことです。 map_dbl(num_vec, `+`, 2) %&gt;% map_dbl(`/`, 3) ## [1] 1.666667 1.333333 2.333333 2.000000 3.000000 もう一つの方法はsapply()やmap_dbl()の第二引数に直接関数を指定する方法です。 sapply(num_vec, function(x){(x + 2) / 3}) ## [1] 1.666667 1.333333 2.333333 2.000000 3.000000 map_dbl(num_vec, function(x){(x + 2) / 3}) ## [1] 1.666667 1.333333 2.333333 2.000000 3.000000 上のコードだと、num_vecの要素が第二引数で指定した関数の引数（x）として用いられます。関数が長くなる場合は、sapply()やmap()の外側に関数を予め指定して置くことも可能です。 add_two_divide_three &lt;- function(x){ (x + 2) / 3 } sapply(num_vec, add_two_divide_three) ## [1] 1.666667 1.333333 2.333333 2.000000 3.000000 map_dbl(num_vec, add_two_divide_three) ## [1] 1.666667 1.333333 2.333333 2.000000 3.000000 ここまでの例だとsapply()とmap_dbl()はほぼ同じ関数です。なぜわざわざ{purrr}パッケージを読み込んでまでmap_dbl()関数を使う必要があるでしょうか。それはmap_dbl()の内部にはラムダ（lambda）式、あるいは無名関数（anonymous function）と呼ばれるものが使用可能だからです。ラムダ式は第13.1章でも説明しましたが、もう一回解説します。ラムダ式は使い捨ての関数で、map_dbl()内部での処理が終わるとメモリ上から削除される関数です。使い捨てですので、関数の名前（オブジェクト名）も与えられておりません。 このラムダ式の作り方ですが、~で始まり、引数の部分には.xが入ります101。したがって、~(.x + 2) / 3はfunction(x){(x + 2) / 3}の簡略したものとなります。ただし、後者だと無名関数の引数に該当するxをyやjなどに書き換えても問題ありませんが、ラムダ式では必ず.xと表記する必要があります。 map_dbl(num_vec, ~(.x + 2) / 3) ## [1] 1.666667 1.333333 2.333333 2.000000 3.000000 かなり短めなコードで「num_vecの全要素に2を足して3で割る」処理ができました。一方、sapply()やlapply()のような*apply()関数群だとラムダ式を使うことはできません。現在のメモリ上にある関数のみしか使うことができません。 sapply(num_vec, ~(.x + 2) / 3) ## Error in match.fun(FUN): &#39;~(.x + 2)/3&#39; is not a function, character or symbol これまでの例は正しいコードではありますが、良いコードとは言えないでしょう。なぜならnum_vec + 2という最適解が存在するからです。*apply()とmap_*()はより複雑な処理に特化しています。たとえば、リスト型データの処理です。以下の例を考えてみましょう。 num_list &lt;- list(List1 = c(1, 3, 5, 7, 9), List2 = c(2, 4, 6, 8, 10, 13, 3), List3 = c(3, 2, NA, 5, 8, 9, 1)) num_listは3つのnumeric型ベクトルで構成されたリスト型オブジェクトです。それぞれのベクトルの平均値を求めてみましょう。これを普通にmean()関数のみで済まそうとすると、リストからベクトルを一つずつ抽出し、3回のmean()関数を使用する必要があります、 mean(num_list[[&quot;List1&quot;]], na.rm = TRUE) ## [1] 5 mean(num_list[[&quot;List2&quot;]], na.rm = TRUE) ## [1] 6.571429 mean(num_list[[&quot;List3&quot;]], na.rm = TRUE) ## [1] 4.666667 もしリストの長さが大きくなると、以下のようにfor()文の方が効率的でしょう。 for (i in names(num_list)) { print(mean(num_list[[i]], na.rm = TRUE)) } ## [1] 5 ## [1] 6.571429 ## [1] 4.666667 計算結果をベクトルとして出力/保存する場合は予めベクトルを用意しておく必要があります。 # num_listの長さと同じ長さの空ベクトルを生成 Return_vec &lt;- rep(NA, length(num_list)) for (i in 1:length(num_list)) { Return_vec[i] &lt;- mean(num_list[[i]], na.rm = TRUE) } Return_vec ## [1] 5.000000 6.571429 4.666667 以上の例はsapply()、またはmap_dbl()関数を使うとより短くすることができます。 sapply(num_list, mean, na.rm = TRUE) ## List1 List2 List3 ## 5.000000 6.571429 4.666667 map_dbl(num_list, mean, na.rm = TRUE) ## List1 List2 List3 ## 5.000000 6.571429 4.666667 *apply()もmap_*()も、それぞれの要素に対して同じ処理を行うことを得意とする関数です。他の応用としては、各ベクトルからn番目の要素を抽出することもできます。ベクトルからn番目の要素を抽出するにはベクトル名[n]と入力しますが、実はこの[も関数です。関数として使う場合は+と同様、`[`と表記します。num_list内の3つのベクトルから3番目の要素を抽出してみましょう102。 map_dbl(num_list, `[`, 3) ## List1 List2 List3 ## 5 6 NA ここまで来たらmap_*()関数群の仕組みについてイメージが出来たかと思います。map_*()関数群の動きは図27.1のように表すことができます。第一引数はデータであり、そのデータの各要素に対して第二引数で指定された関数を適用します。この関数に必要な（データを除く）引数は第三引数以降に指定します。この関数部（第二引数）はRやパッケージなどで予め提供されている関数でも、内部に直接無名関数を作成することもできます。この無名関数はfunction(x){}のような従来の書き方も可能ですが、map_*()関数群の場合~で始まるラムダ式を使うことも可能です。 図 27.1: map_*()関数群のイメージ map()の場合、返り値はリストとなり、map_dbl()の返り値はnumeric (double)型のベクトルとなります。他にもmap_*()関数群にはmap_int()、map_lgl()、map_chr()、map_df()などがあり、それぞれ返り値のデータ型/データ構造を表しています。例えば、返り値がcharacter型のベクトルであれば、map_chr()を使います。c(1, 2, 3, 4, 5)のベクトルの各要素の前に\"ID: \"を付ける例だと以下のように書きます。 # 以下のコードでもOK # map_chr(c(1, 2, 3, 4, 5), ~paste0(&quot;ID: &quot;, .x)) c(1, 2, 3, 4, 5) %&gt;% map_chr(~paste0(&quot;ID: &quot;, .x)) ## [1] &quot;ID: 1&quot; &quot;ID: 2&quot; &quot;ID: 3&quot; &quot;ID: 4&quot; &quot;ID: 5&quot; 27.3 引数が2つ以上の場合 {purrr}を使った本格的な例を紹介する前に、引数が2つ以上の場合を考えたいと思います。まずは引数が2つの場合です。この場合、map2_*()関数群を使用します。例えば、num_vecに長さ5のnumeric型ベクトルnum_vec2をかける例を考えてみましょう。 この場合、データとしてnum_vecとnum_vec2が必要となり、ラムダ式にも2つの引数が必要です。まず、num_vec2を用意します。 num_vec2 &lt;- c(1, 0, 1, 0, 1) 続いてmap2_dbl()関数を使用しnum_vecとnum_vec2の掛け算を行います。map2_*()の使い方はmap_*()とほぼ同様です。 map2_dbl(データ1, データ2, 関数 or ラムダ式, 追加の引数) map_*()との違いとしては、(1) データが2つである、(2) 関数、またはラムダ式に2つの引数が必要である点です。この2点目の引数ですが、データ2は.yと表記します。したがって、データ1とデータ2の掛け算を意味するラムダ式は~.x * .yです。 map2_dbl(num_vec, num_vec2, ~.x * .y) ## [1] 3 0 5 0 7 num_vecとnum_vec2が必ずしも同じデータ構造、データ型、同じ長さである必要がありません。数字の前に\"ID:\"を付ける先ほどの例をmap2_chr()で書いてみましょう。 map2_chr(num_vec, &quot;ID:&quot;, ~paste0(.y, .x)) ## [1] &quot;ID:3&quot; &quot;ID:2&quot; &quot;ID:5&quot; &quot;ID:4&quot; &quot;ID:7&quot; それでは3つ以上の引数について考えてみましょう。たとえば、num_vecの前に\"ID\"を付けるとします。そして\"ID\"とnum_vecの間に\":\"を入れたい場合はどうすればい良いでしょう。むろん、賢い解決方法は単純にpaste()関数を使うだけです。 paste(&quot;ID&quot;, num_vec, sep = &quot;:&quot;) ## [1] &quot;ID:3&quot; &quot;ID:2&quot; &quot;ID:5&quot; &quot;ID:4&quot; &quot;ID:7&quot; この場合、引数は3つです103。この場合の書き方はどうなるでしょうか。map2_*()はデータを2つまでしか指定できません。3つ目以降は関数/ラムダ式の後ろに書くこととなります。ただし、関数/ラムダ式の後ろに指定される引数は長さ1のベクトルでなければなりません。また、ラムダ式内の引数は.xと.yでなく、..1、..2、..3、…となります。 今回の例だとmap2_chr()内にnum_vecがデータ1、\"ID\"がデータ2です。そして、期待される結果は、「“ID” + sepの実引数 + num_vecの値」となります。したがって、ラムダ式はpaste(..2, ..1, sep = ..3)となります。 map2_chr(num_vec, &quot;ID&quot;, ~paste(..2, ..1, sep = ..3), &quot;-&quot;) ## [1] &quot;ID-3&quot; &quot;ID-2&quot; &quot;ID-5&quot; &quot;ID-4&quot; &quot;ID-7&quot; データ2である\"ID\"は長さ1のcharacter型ベクトルであるため、以下のようにmap_chr()を使うことも可能です。 # データ2も長さ1なのでmap_chr()もOK map_chr(num_vec, ~paste(..2, ..1, sep = ..3), &quot;ID&quot;, &quot;-&quot;) ## [1] &quot;ID-3&quot; &quot;ID-2&quot; &quot;ID-5&quot; &quot;ID-4&quot; &quot;ID-7&quot; それではデータを3つ以上使うにはどうすれば良いでしょうか。そこで登場するのがpmap_*()関数です。以下の3つのベクトルを利用し、「名前:数学成績」を出力してみましょう。ただし、不正行為がある場合（cheat_vecの値が1）は成績が0点になるようにしましょう。 name_vec &lt;- c(&quot;Hadley&quot;, &quot;Song&quot;, &quot;Yanai&quot;) math_vec &lt;- c(70, 55, 80) cheat_vec &lt;- c(0, 1, 0) 賢い解決法は普通にpaste0()関数を使う方法です。 paste0(name_vec, &quot;:&quot;, math_vec * (1 - cheat_vec)) ## [1] &quot;Hadley:70&quot; &quot;Song:0&quot; &quot;Yanai:80&quot; 今回はあえてpmap_*()関数を使ってみましょう。pmap_*()の場合、第一引数であるデータはリスト型で渡す必要があります。したがって、3つのベクトルをlist()関数を用いてリスト化します。第二引数には既存の関数やラムダ式を入力し、各引数は..1、..2、…といった形で表記します。 pmap_chr(list(name_vec, math_vec, cheat_vec), ~paste0(..1, &quot;:&quot;, ..2 * (1 - ..3))) ## [1] &quot;Hadley:70&quot; &quot;Song:0&quot; &quot;Yanai:80&quot; 第一引数はデータであるため、まずリストを作成し、パイプ演算子（%&gt;%）でpmap_*()に渡すことも可能です。 list(name_vec, math_vec, cheat_vec) %&gt;% pmap_chr(~paste0(..1, &quot;:&quot;, ..2 * (1 - ..3))) ## [1] &quot;Hadley:70&quot; &quot;Song:0&quot; &quot;Yanai:80&quot; 27.4 データフレームと{purrr} map_*()関数のデータとしてデータフレームを渡すことも可能です。ここでは5行3列のデータフレームを作成してみましょう。 Dummy_df &lt;- data.frame(X = seq(1, 5, by = 1), Y = seq(10, 50, by = 10), Z = seq(2, 10, by = 2)) 各行のX、Y、Zの合計を計算するには{dplyr}のrowwise()とmutate()を組み合わせることで計算出来ることを第13.4章で紹介しました。 Dummy_df %&gt;% rowwise() %&gt;% mutate(Sum = sum(X, Y, Z)) %&gt;% # rowwise()は1行を1グループとする関数であるため、最後にグループ化を解除 ungroup() ## # A tibble: 5 × 4 ## X Y Z Sum ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 10 2 13 ## 2 2 20 4 26 ## 3 3 30 6 39 ## 4 4 40 8 52 ## 5 5 50 10 65 それでは各列の平均値を計算するにはどうすれば良いでしょうか。ここではR内蔵関数であるcolMeans()を使わないことにしましょう。 colMeans(Dummy_df) ## X Y Z ## 3 30 6 まず、mean(Dummy_df$X)を3回実行する方法や、{dplyr}のsummarise()関数を使う方法があります。 Dummy_df %&gt;% summarise(X = mean(X), Y = mean(Y), Z = mean(Z)) ## X Y Z ## 1 3 30 6 実はこの操作、map_dbl()関数を使えば、より簡単です。 map_dbl(Dummy_df, mean) ## X Y Z ## 3 30 6 map_dbl()はnumeric (double) 型ベクトルを返しますが、データフレーム（具体的にはtibble）に返すならmap_df()を使います。 map_df(Dummy_df, mean) ## # A tibble: 1 × 3 ## X Y Z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3 30 6 なぜこれが出来るでしょうか。これを理解するためにはデータフレームとtibbleが本質的にはリスト型と同じであることを理解する必要があります。たとえば、以下のようなリストについて考えてみましょう。 Dummy_list &lt;- list(X = seq(1, 5, by = 1), Y = seq(10, 50, by = 10), Z = seq(2, 10, by = 2)) Dummy_list ## $X ## [1] 1 2 3 4 5 ## ## $Y ## [1] 10 20 30 40 50 ## ## $Z ## [1] 2 4 6 8 10 このDummy_listをas.data.frame()関数を使用して強制的にデータフレームに変換してみましょう。 as.data.frame(Dummy_list) ## X Y Z ## 1 1 10 2 ## 2 2 20 4 ## 3 3 30 6 ## 4 4 40 8 ## 5 5 50 10 Dummy_dfと同じものが出てきました。逆にDummy_dfを、as.list()を使用してリストに変換するとDummy_listと同じものが返されます。 as.list(Dummy_df) ## $X ## [1] 1 2 3 4 5 ## ## $Y ## [1] 10 20 30 40 50 ## ## $Z ## [1] 2 4 6 8 10 ここまで理解できれば、map_*()関数のデータがデータフレームの場合、内部ではリストとして扱われることが分かるでしょう。実際、Dummy_listをデータとして入れてもDummy_dfを入れた結果と同じものが得られます。 map_df(Dummy_list, mean) ## # A tibble: 1 × 3 ## X Y Z ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 3 30 6 27.4.1 tibbleの話 ここまで「データフレーム」と「tibble」を区別せずに説明してきましたが、これからの話しではこの2つを区別する必要があります。tibbleは{tidyverse}のコアパッケージの一つである{tibble}が提供するデータ構造であり、データフレームの上位互換です。tibbleもデータフレーム同様、本質的にはリストですが、リストの構造をより的確に表すことが出来ます。 データフレームをリストとして考える場合、リストの各要素は必ずベクトルである必要があります。たとえば、Dummy_listには3つの要素があり、それぞれ長さ5のベクトルです。一方、リストの中にはリストを入れることも出来ます。たとえば、以下のようなDummy_list2について考えてみましょう。 Dummy_list2 &lt;- list(ID = 1:3, Data = list(Dummy_df, Dummy_df, Dummy_df)) Dummy_list2 ## $ID ## [1] 1 2 3 ## ## $Data ## $Data[[1]] ## X Y Z ## 1 1 10 2 ## 2 2 20 4 ## 3 3 30 6 ## 4 4 40 8 ## 5 5 50 10 ## ## $Data[[2]] ## X Y Z ## 1 1 10 2 ## 2 2 20 4 ## 3 3 30 6 ## 4 4 40 8 ## 5 5 50 10 ## ## $Data[[3]] ## X Y Z ## 1 1 10 2 ## 2 2 20 4 ## 3 3 30 6 ## 4 4 40 8 ## 5 5 50 10 Dummy_list2には2つの要素があり、最初の要素は長さ3のベクトル、2つ目の要素は長さ3のリストです。2つ目の要素がベクトルでないため、Dummy_list2をデータフレームに変換することはできません。 Dummy_df2 &lt;- as.data.frame(Dummy_list2) ## Error in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE, : arguments imply differing number of rows: 3, 5 一方、as_tibble()を使用してtibble型に変換することは可能です。 Dummy_tibble &lt;- as_tibble(Dummy_list2) Dummy_tibble ## # A tibble: 3 × 2 ## ID Data ## &lt;int&gt; &lt;list&gt; ## 1 1 &lt;df [5 × 3]&gt; ## 2 2 &lt;df [5 × 3]&gt; ## 3 3 &lt;df [5 × 3]&gt; 2列目の各セルには5行3列のデータフレーム（df）が格納されていることが分かります。たとえば、Dummy_tibbleのData列を抽出してみましょう。 Dummy_tibble$Data ## [[1]] ## X Y Z ## 1 1 10 2 ## 2 2 20 4 ## 3 3 30 6 ## 4 4 40 8 ## 5 5 50 10 ## ## [[2]] ## X Y Z ## 1 1 10 2 ## 2 2 20 4 ## 3 3 30 6 ## 4 4 40 8 ## 5 5 50 10 ## ## [[3]] ## X Y Z ## 1 1 10 2 ## 2 2 20 4 ## 3 3 30 6 ## 4 4 40 8 ## 5 5 50 10 長さ3のリスト出力されます。続いて、Dummy_tibble$Dataの2番目のセルを抽出してみましょう。 Dummy_tibble$Data[2] ## [[1]] ## X Y Z ## 1 1 10 2 ## 2 2 20 4 ## 3 3 30 6 ## 4 4 40 8 ## 5 5 50 10 データフレームが出力されました。簡単にまとめるとtibbleはデータフレームの中にデータフレームを入れることが出来るデータ構造です。むろん、これまでの通り、データフレームのように使うことも可能です104。これがtibbleの強みでもあり、{purrr}との相性も非常に高いです。たとえば、Data列をmap()関数のデータとして渡せば、複数のデータセットに対して同じモデルの推定が出来るようになります。以下ではその例を紹介します。 27.5 モデルの反復推定 ここからはmap_*()関数群を使って複数のモデルを素早く推定する方法について解説します。サンプルデータは第18章で使いました各国の政治経済データ（Countries.csv）を使用します。csv形式データ読み込みの際、これまではR内蔵関数であるread.csv()と{readr}105のread_csv()を区別せずに使用してきました。しかし、ここからはread_csv()を使用します。2つの使い方はほぼ同じですが、read_csv()は各列のデータ型を自動的に指定してくれるだけではなく、tibble構造として読み込みます。read.csv()を使用する場合、as.tibble(データフレーム名)でデータフレームをtibbleに変換してください。 Country_df &lt;- read_csv(&quot;Data/Countries.csv&quot;) ## Rows: 186 Columns: 18 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (4): Country, Polity_Type, FH_Status, Continent ## dbl (14): Population, Area, GDP, PPP, GDP_per_capita, PPP_per_capita, G7, G2... ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. 27.5.1 サンプルの分割とモデル推定（split()利用） まずは、サンプルを分割し、それぞれの下位サンプルを使った分析を繰り返す方法について解説します。サンプルを分割する方法は2つありますが、最初はR内蔵関数であるsplit()関数を使った方法について紹介します。 # split()の使い方 新しいオブジェクト名 &lt;- split(データ名, 分割の基準となるベクトル) たとえば、Country_dfを大陸ごとにサンプルを分けるとします。大陸を表すベクトルはCountry_df$Continentです。したがって、以下のように入力します。 Split_Data &lt;- split(Country_df, Country_df$Continent) サンプルが分割されたSplit_Dataのデータ構造はリスト型です。 class(Split_Data) ## [1] &quot;list&quot; 中身を見るとリストの各要素としてtibble（データフレーム）が格納されています。リストの中にはあらゆるデータ型、データ構造を入れることができることが分かります。 Split_Data ## $Africa ## # A tibble: 54 × 18 ## Country Population Area GDP PPP GDP_per_capita PPP_per_capita G7 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Algeria 43851044 2.38e6 1.70e5 4.97e5 3876. 11324. 0 ## 2 Angola 32866272 1.25e6 9.46e4 2.19e5 2879. 6649. 0 ## 3 Benin 12123200 1.13e5 1.44e4 3.72e4 1187. 3067. 0 ## 4 Botswana 2351627 5.67e5 1.83e4 4.07e4 7799. 17311. 0 ## 5 Burkina … 20903273 2.74e5 1.57e4 3.76e4 753. 1800. 0 ## 6 Burundi 11890784 2.57e4 3.01e3 8.72e3 253. 733. 0 ## 7 Cabo Ver… 555987 4.03e3 1.98e3 3.84e3 3565. 6913. 0 ## 8 Cameroon 26545863 4.73e5 3.88e4 9.31e4 1460. 3506. 0 ## 9 Central … 4829767 6.23e5 2.22e3 4.46e3 460. 924. 0 ## 10 Chad 16425864 1.26e6 1.13e4 2.51e4 689. 1525. 0 ## # … with 44 more rows, and 10 more variables: G20 &lt;dbl&gt;, OECD &lt;dbl&gt;, ## # HDI_2018 &lt;dbl&gt;, Polity_Score &lt;dbl&gt;, Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;, ## # FH_CL &lt;dbl&gt;, FH_Total &lt;dbl&gt;, FH_Status &lt;chr&gt;, Continent &lt;chr&gt; ## ## $America ## # A tibble: 36 × 18 ## Country Population Area GDP PPP GDP_per_capita PPP_per_capita G7 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Antigua … 97929 4.4 e2 1.73e3 2.08e3 17643. 21267. 0 ## 2 Argentina 45195774 2.74e6 4.50e5 1.04e6 9949. 22938. 0 ## 3 Bahamas 393244 1.00e4 1.28e4 1.40e4 32618. 35662. 0 ## 4 Barbados 287375 4.3 e2 5.21e3 4.62e3 18126. 16066. 0 ## 5 Belize 397628 2.28e4 1.88e3 2.82e3 4727. 7091. 0 ## 6 Bolivia 11673021 1.08e6 4.09e4 1.01e5 3503. 8623. 0 ## 7 Brazil 212559417 8.36e6 1.84e6 3.13e6 8655. 14734. 0 ## 8 Canada 37742154 9.09e6 1.74e6 1.85e6 46008. 49088. 1 ## 9 Chile 19116201 7.44e5 2.82e5 4.64e5 14769. 24262. 0 ## 10 Colombia 50882891 1.11e6 3.24e5 7.37e5 6364. 14475. 0 ## # … with 26 more rows, and 10 more variables: G20 &lt;dbl&gt;, OECD &lt;dbl&gt;, ## # HDI_2018 &lt;dbl&gt;, Polity_Score &lt;dbl&gt;, Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;, ## # FH_CL &lt;dbl&gt;, FH_Total &lt;dbl&gt;, FH_Status &lt;chr&gt;, Continent &lt;chr&gt; ## ## $Asia ## # A tibble: 42 × 18 ## Country Population Area GDP PPP GDP_per_capita PPP_per_capita G7 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Afghanis… 38928346 6.53e5 1.91e4 8.27e4 491. 2125. 0 ## 2 Bahrain 1701575 7.6 e2 3.86e4 7.42e4 22670. 43624. 0 ## 3 Banglade… 164689383 1.30e5 3.03e5 7.34e5 1837. 4458. 0 ## 4 Bhutan 771608 3.81e4 2.45e3 8.77e3 3171. 11363. 0 ## 5 Brunei 437479 5.27e3 1.35e4 2.65e4 30789. 60656. 0 ## 6 Burma 54409800 6.53e5 7.61e4 2.68e5 1398. 4932. 0 ## 7 Cambodia 16718965 1.77e5 2.71e4 6.93e4 1620. 4142. 0 ## 8 China 1447470092 9.39e6 1.48e7 2.20e7 10199. 15177. 0 ## 9 India 1380004385 2.97e6 2.88e6 9.06e6 2083. 6564. 0 ## 10 Indonesia 273523615 1.81e6 1.12e6 3.12e6 4092. 11397. 0 ## # … with 32 more rows, and 10 more variables: G20 &lt;dbl&gt;, OECD &lt;dbl&gt;, ## # HDI_2018 &lt;dbl&gt;, Polity_Score &lt;dbl&gt;, Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;, ## # FH_CL &lt;dbl&gt;, FH_Total &lt;dbl&gt;, FH_Status &lt;chr&gt;, Continent &lt;chr&gt; ## ## $Europe ## # A tibble: 50 × 18 ## Country Population Area GDP PPP GDP_per_capita PPP_per_capita G7 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Albania 2877797 27400 1.53e4 39658. 5309. 13781. 0 ## 2 Andorra 77265 470 3.15e3 NA 40821. NA 0 ## 3 Armenia 2963243 28470 1.37e4 38446. 4614. 12974. 0 ## 4 Austria 9006398 82409 4.46e5 502771. 49555. 55824. 0 ## 5 Azerbai… 10139177 82658 4.80e4 144556. 4739. 14257. 0 ## 6 Belarus 9449323 202910 6.31e4 183461. 6676. 19415. 0 ## 7 Belgium 11589623 30280 5.30e5 597433. 45697. 51549. 0 ## 8 Bosnia … 3280819 51000 2.00e4 49733. 6111. 15159. 0 ## 9 Bulgaria 6948445 108560 6.79e4 156693. 9776. 22551. 0 ## 10 Croatia 4105267 55960 6.04e4 114932. 14717. 27996. 0 ## # … with 40 more rows, and 10 more variables: G20 &lt;dbl&gt;, OECD &lt;dbl&gt;, ## # HDI_2018 &lt;dbl&gt;, Polity_Score &lt;dbl&gt;, Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;, ## # FH_CL &lt;dbl&gt;, FH_Total &lt;dbl&gt;, FH_Status &lt;chr&gt;, Continent &lt;chr&gt; ## ## $Oceania ## # A tibble: 4 × 18 ## Country Population Area GDP PPP GDP_per_capita PPP_per_capita G7 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Australia 25499884 7.68e6 1.39e6 1.28e6 54615. 50001. 0 ## 2 Fiji 896445 1.83e4 5.54e3 1.25e4 6175. 13940. 0 ## 3 New Zeala… 4842780 2.64e5 2.07e5 2.04e5 42729. 42178. 0 ## 4 Papua New… 8947024 4.53e5 2.50e4 3.73e4 2791. 4171. 0 ## # … with 10 more variables: G20 &lt;dbl&gt;, OECD &lt;dbl&gt;, HDI_2018 &lt;dbl&gt;, ## # Polity_Score &lt;dbl&gt;, Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;, FH_CL &lt;dbl&gt;, ## # FH_Total &lt;dbl&gt;, FH_Status &lt;chr&gt;, Continent &lt;chr&gt; それでは分割された各サンプルに対してPolity_ScoreとFH_Totalの相関係数を計算してみましょう。その前に相関分析の方法について調べてみましょう。Rには相関分析の関数が2つ用意されています。単純に相関係数のみを計算するならcor()、係数の不確実性（標準誤差、信頼区間など）まで計算し、検定を行うならcor.test()を使用します。ここではより汎用性の高いcor.test()の使い方について紹介します。 # 相関分析: 方法1 cor.test(~ 変数名1 + 変数名2, data = データ名) # 相関分析: 方法2 cor.test(データ名$変数名1, データ名$変数名2) それでは全サンプルに対して相関分析をしてみましょう。 Cor_fit1 &lt;- cor.test(~ Polity_Score + FH_Total, data = Country_df) Cor_fit1 ## ## Pearson&#39;s product-moment correlation ## ## data: Polity_Score and FH_Total ## t = 19.494, df = 156, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.7896829 0.8821647 ## sample estimates: ## cor ## 0.8420031 ここから相関係数（0.8420031）のみを抽出するにはどうすれば良いでしょうか。それを確認するためにはCor_fit1というオブジェクトの構造を調べる必要があります。ここではR内蔵関数であるstr()を使って確認してみましょう。 str(Cor_fit1) ## List of 9 ## $ statistic : Named num 19.5 ## ..- attr(*, &quot;names&quot;)= chr &quot;t&quot; ## $ parameter : Named int 156 ## ..- attr(*, &quot;names&quot;)= chr &quot;df&quot; ## $ p.value : num 1.16e-43 ## $ estimate : Named num 0.842 ## ..- attr(*, &quot;names&quot;)= chr &quot;cor&quot; ## $ null.value : Named num 0 ## ..- attr(*, &quot;names&quot;)= chr &quot;correlation&quot; ## $ alternative: chr &quot;two.sided&quot; ## $ method : chr &quot;Pearson&#39;s product-moment correlation&quot; ## $ data.name : chr &quot;Polity_Score and FH_Total&quot; ## $ conf.int : num [1:2] 0.79 0.882 ## ..- attr(*, &quot;conf.level&quot;)= num 0.95 ## - attr(*, &quot;class&quot;)= chr &quot;htest&quot; 相関係数は$estimateで抽出できそうですね。実際にCor_fit1から相関係数のみ抽出してみましょう。 Cor_fit1$estimate ## cor ## 0.8420031 それではmap()関数を利用して分割された各サンプルを対象にPolity_ScoreとFH_Totalの相関係数を計算してみましょう。map()のデータはSplit_Dataとし、関数はラムダ式を書いてみましょう。cor.test()内data引数の実引数は.x、または..1となります。最後にmap_dbl(\"estimate\")を利用し、相関係数を抽出、numeric (double) 型ベクトルとして出力します。 Cor_fit2 &lt;- Split_Data %&gt;% map(~cor.test(~ Polity_Score + FH_Total, data = .x)) # Cor_fit2から相関係数のみ出力 map_dbl(Cor_fit2, &quot;estimate&quot;) ## Africa America Asia Europe Oceania ## 0.7612138 0.8356899 0.8338172 0.8419547 0.9960776 もし、小数点3位までのp値が欲しい場合は以下のように入力します。 # Cor_fit2から相関係数のp値を抽出し、小数点3位に丸める map_dbl(Cor_fit2, &quot;p.value&quot;) %&gt;% round(3) ## Africa America Asia Europe Oceania ## 0.000 0.000 0.000 0.000 0.004 27.5.2 サンプルの分割とモデル推定（nest()利用） それではデータフレーム内にデータフレームが格納可能なtibble構造の長所を活かした方法について解説します。ある変数に応じてデータをグループ化する方法については第13.2章で解説しました。{tidyr}パッケージにはグループごとにデータを分割し、分割されたデータを各セルに埋め込むnest()関数を提供しています。具体的な動きを見るために、とりあえず、Country_dfを大陸（Continent）ごとに分割し、それぞれがデータが一つのセルに埋め込まれた新しいデータセット、Nested_Dataを作ってみましょう。 Nested_Data &lt;- Country_df %&gt;% group_by(Continent) %&gt;% nest() Nested_Data ## # A tibble: 5 × 2 ## # Groups: Continent [5] ## Continent data ## &lt;chr&gt; &lt;list&gt; ## 1 Asia &lt;tibble [42 × 17]&gt; ## 2 Europe &lt;tibble [50 × 17]&gt; ## 3 Africa &lt;tibble [54 × 17]&gt; ## 4 America &lt;tibble [36 × 17]&gt; ## 5 Oceania &lt;tibble [4 × 17]&gt; ちなみにgroup_by()とnest()はgroup_nest()を使って以下のようにまとめることも可能です。 Nested_Data &lt;- Country_df %&gt;% group_nest(Continent) 2列目のdata変数の各セルにtibbleが埋め込まれたことがわかります。Nested_Dataのdata列から5つ目の要素（オセアニアのデータ）を確認してみましょう。 # Nested_Data$data[5]の場合、長さ1のリストが出力される # tibble構造で出力する場合は[5]でなく、[[5]]で抽出 Nested_Data$data[[5]] ## # A tibble: 4 × 17 ## Country Population Area GDP PPP GDP_per_capita PPP_per_capita G7 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Australia 25499884 7.68e6 1.39e6 1.28e6 54615. 50001. 0 ## 2 Fiji 896445 1.83e4 5.54e3 1.25e4 6175. 13940. 0 ## 3 New Zeala… 4842780 2.64e5 2.07e5 2.04e5 42729. 42178. 0 ## 4 Papua New… 8947024 4.53e5 2.50e4 3.73e4 2791. 4171. 0 ## # … with 9 more variables: G20 &lt;dbl&gt;, OECD &lt;dbl&gt;, HDI_2018 &lt;dbl&gt;, ## # Polity_Score &lt;dbl&gt;, Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;, FH_CL &lt;dbl&gt;, ## # FH_Total &lt;dbl&gt;, FH_Status &lt;chr&gt; ContinentがOceaniaの行のdata列にオセアニアのみのデータが格納されていることが分かります。このようなデータ構造を入れ子型データ（nested data）と呼びます。この入れ子型データはunnest()関数を使って解除することも可能です。unnest()関数を使う際はどの列を解除するかを指定する必要があり、今回はdata列となります。 # 入れ子型データの解除 Nested_Data %&gt;% unnest(data) ## # A tibble: 186 × 18 ## # Groups: Continent [5] ## Continent Country Population Area GDP PPP GDP_per_capita ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia Afghanistan 38928346 652860 19101. 82737. 491. ## 2 Asia Bahrain 1701575 760 38574. 74230. 22670. ## 3 Asia Bangladesh 164689383 130170 302571. 734108. 1837. ## 4 Asia Bhutan 771608 38117 2447. 8767. 3171. ## 5 Asia Brunei 437479 5270 13469. 26536. 30789. ## 6 Asia Burma 54409800 653290 76086. 268327. 1398. ## 7 Asia Cambodia 16718965 176520 27089. 69253. 1620. ## 8 Asia China 1447470092 9389291 14762792. 21967628. 10199. ## 9 Asia India 1380004385 2973190 2875142. 9058692. 2083. ## 10 Asia Indonesia 273523615 1811570 1119191. 3117334. 4092. ## # … with 176 more rows, and 11 more variables: PPP_per_capita &lt;dbl&gt;, G7 &lt;dbl&gt;, ## # G20 &lt;dbl&gt;, OECD &lt;dbl&gt;, HDI_2018 &lt;dbl&gt;, Polity_Score &lt;dbl&gt;, ## # Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;, FH_CL &lt;dbl&gt;, FH_Total &lt;dbl&gt;, ## # FH_Status &lt;chr&gt; {dplyr}のgroup_by()関数と{tidyr}のnest()、unnest()関数を組み合わせることでデータを入れ子型データへ変換したり、解除することができます。以上の流れを図式化したものが以下の図27.2です。 図 27.2: 入れ子型データの生成過程 それではこの入れ子型データを使用して大陸ごとのPolity_ScoreとFH_Totalの相関係数を計算してみましょう。data列をデータとした相関係数のラムダ式はどう書けば良いでしょうか。これまでの内容が理解できましたら、答えは難しくないでしょう。cor.test()関数のdata引数の実引数として.xを指定するだけです。この結果をCor_testという列として追加し、Nested_Data2という名のオブジェクトとして保存します。 Nested_Data2 &lt;- Nested_Data %&gt;% mutate(Cor_test = map(data, ~cor.test(~ Polity_Score + FH_Total, data = .x))) Nested_Data2 ## # A tibble: 5 × 3 ## # Groups: Continent [5] ## Continent data Cor_test ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 Asia &lt;tibble [42 × 17]&gt; &lt;htest&gt; ## 2 Europe &lt;tibble [50 × 17]&gt; &lt;htest&gt; ## 3 Africa &lt;tibble [54 × 17]&gt; &lt;htest&gt; ## 4 America &lt;tibble [36 × 17]&gt; &lt;htest&gt; ## 5 Oceania &lt;tibble [4 × 17]&gt; &lt;htest&gt; Cor_testという列が追加され、htestというクラス（S3クラス）オブジェクトが格納されていることが分かります。ちゃんと相関分析のオブジェクトが格納されているか、確認してみましょう。 Nested_Data2$Cor_test ## [[1]] ## ## Pearson&#39;s product-moment correlation ## ## data: Polity_Score and FH_Total ## t = 9.0626, df = 36, p-value = 8.05e-11 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.7009872 0.9107368 ## sample estimates: ## cor ## 0.8338172 ## ## ## [[2]] ## ## Pearson&#39;s product-moment correlation ## ## data: Polity_Score and FH_Total ## t = 9.7452, df = 39, p-value = 5.288e-12 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.7210854 0.9130896 ## sample estimates: ## cor ## 0.8419547 ## ## ## [[3]] ## ## Pearson&#39;s product-moment correlation ## ## data: Polity_Score and FH_Total ## t = 7.9611, df = 46, p-value = 3.375e-10 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.6087424 0.8594586 ## sample estimates: ## cor ## 0.7612138 ## ## ## [[4]] ## ## Pearson&#39;s product-moment correlation ## ## data: Polity_Score and FH_Total ## t = 7.6082, df = 25, p-value = 5.797e-08 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.6677292 0.9226837 ## sample estimates: ## cor ## 0.8356899 ## ## ## [[5]] ## ## Pearson&#39;s product-moment correlation ## ## data: Polity_Score and FH_Total ## t = 15.92, df = 2, p-value = 0.003922 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.8197821 0.9999220 ## sample estimates: ## cor ## 0.9960776 5つの相関分析結果が格納されています。続いて、ここから相関係数のみを抽出してみましょう。相関分析オブジェクトから相関係数を抽出するにはオブジェクト名$estimateだけで十分です。mpa_*()関数を使うなら第2引数として関数やラムダ式を指定せず、\"estimate\"のみ入力するだけです。 Nested_Data2 &lt;- Nested_Data2 %&gt;% mutate(Cor_coef = map(Cor_test, &quot;estimate&quot;)) Nested_Data2 ## # A tibble: 5 × 4 ## # Groups: Continent [5] ## Continent data Cor_test Cor_coef ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; ## 1 Asia &lt;tibble [42 × 17]&gt; &lt;htest&gt; &lt;dbl [1]&gt; ## 2 Europe &lt;tibble [50 × 17]&gt; &lt;htest&gt; &lt;dbl [1]&gt; ## 3 Africa &lt;tibble [54 × 17]&gt; &lt;htest&gt; &lt;dbl [1]&gt; ## 4 America &lt;tibble [36 × 17]&gt; &lt;htest&gt; &lt;dbl [1]&gt; ## 5 Oceania &lt;tibble [4 × 17]&gt; &lt;htest&gt; &lt;dbl [1]&gt; Cor_coef列が追加され、それぞれのセルにnumeric型の値が格納されていることが分かります。map()関数はリスト型でデータを返すため、このように出力されます。このCor_coef列の入れ子構造を解除してみましょう。 Nested_Data2 %&gt;% unnest(cols = Cor_coef) ## # A tibble: 5 × 4 ## # Groups: Continent [5] ## Continent data Cor_test Cor_coef ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; ## 1 Asia &lt;tibble [42 × 17]&gt; &lt;htest&gt; 0.834 ## 2 Europe &lt;tibble [50 × 17]&gt; &lt;htest&gt; 0.842 ## 3 Africa &lt;tibble [54 × 17]&gt; &lt;htest&gt; 0.761 ## 4 America &lt;tibble [36 × 17]&gt; &lt;htest&gt; 0.836 ## 5 Oceania &lt;tibble [4 × 17]&gt; &lt;htest&gt; 0.996 Nested_Data2 ## # A tibble: 5 × 4 ## # Groups: Continent [5] ## Continent data Cor_test Cor_coef ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; ## 1 Asia &lt;tibble [42 × 17]&gt; &lt;htest&gt; &lt;dbl [1]&gt; ## 2 Europe &lt;tibble [50 × 17]&gt; &lt;htest&gt; &lt;dbl [1]&gt; ## 3 Africa &lt;tibble [54 × 17]&gt; &lt;htest&gt; &lt;dbl [1]&gt; ## 4 America &lt;tibble [36 × 17]&gt; &lt;htest&gt; &lt;dbl [1]&gt; ## 5 Oceania &lt;tibble [4 × 17]&gt; &lt;htest&gt; &lt;dbl [1]&gt; Cor_coefの各列に格納された値が出力されました。以上の作業を一つのコードとしてまとめることも出来ます。また、相関係数の抽出の際にmap()でなく、map_dbl()を使えば、numeric型ベクトルが返されるのでunnest()も不要となります。 Country_df %&gt;% group_by(Continent) %&gt;% nest() %&gt;% mutate(Cor_test = map(data, ~cor.test(~ Polity_Score + FH_Total, data = .x)), Cor_coef = map_dbl(Cor_test, &quot;estimate&quot;)) ## # A tibble: 5 × 4 ## # Groups: Continent [5] ## Continent data Cor_test Cor_coef ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; ## 1 Asia &lt;tibble [42 × 17]&gt; &lt;htest&gt; 0.834 ## 2 Europe &lt;tibble [50 × 17]&gt; &lt;htest&gt; 0.842 ## 3 Africa &lt;tibble [54 × 17]&gt; &lt;htest&gt; 0.761 ## 4 America &lt;tibble [36 × 17]&gt; &lt;htest&gt; 0.836 ## 5 Oceania &lt;tibble [4 × 17]&gt; &lt;htest&gt; 0.996 たった5行のコードで大陸ごとの相関分析が出来ました。これをmap_*()を使わずに処理するなら以下のようなコードとなります106。 Cor_Test1 &lt;- cor.test(~ Polity_Score + FH_Total, data = subset(Country_df, Country_df$Continent == &quot;Asia&quot;)) Cor_Test2 &lt;- cor.test(~ Polity_Score + FH_Total, data = subset(Country_df, Country_df$Continent == &quot;Europe&quot;)) Cor_Test3 &lt;- cor.test(~ Polity_Score + FH_Total, data = subset(Country_df, Country_df$Continent == &quot;Africa&quot;)) Cor_Test4 &lt;- cor.test(~ Polity_Score + FH_Total, data = subset(Country_df, Country_df$Continent == &quot;America&quot;)) Cor_Test5 &lt;- cor.test(~ Polity_Score + FH_Total, data = subset(Country_df, Country_df$Continent == &quot;Oceania&quot;)) Cor_Result &lt;- c(&quot;Asia&quot; = Cor_Test1$estimate, &quot;Europe&quot; = Cor_Test2$estimate, &quot;Africa&quot; = Cor_Test3$estimate, &quot;America&quot; = Cor_Test4$estimate, &quot;Oceania&quot; = Cor_Test5$estimate) print(Cor_Result) ## Asia.cor Europe.cor Africa.cor America.cor Oceania.cor ## 0.8338172 0.8419547 0.7612138 0.8356899 0.9960776 それでは応用例として回帰分析をしてみましょう。今回もNested_Dataを使用し、PPP_per_capitaを応答変数に、FH_TotalとPopulationを説明変数とした重回帰分析を行い、政治的自由度（FH_Total）の係数や標準誤差などを抽出してみましょう。まずは、ステップごとにコードを分けて説明し、最後には一つのコードとしてまとめたものをお見せします。 Nested_Data %&gt;% mutate(Model = map(data, ~lm(PPP_per_capita ~ FH_Total + Population, data = .x))) ## # A tibble: 5 × 3 ## # Groups: Continent [5] ## Continent data Model ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 Asia &lt;tibble [42 × 17]&gt; &lt;lm&gt; ## 2 Europe &lt;tibble [50 × 17]&gt; &lt;lm&gt; ## 3 Africa &lt;tibble [54 × 17]&gt; &lt;lm&gt; ## 4 America &lt;tibble [36 × 17]&gt; &lt;lm&gt; ## 5 Oceania &lt;tibble [4 × 17]&gt; &lt;lm&gt; Model列からから推定結果の要約を抽出するにはどうすれば良いでしょうか。1つ目の方法はsummary(lmオブジェクト名)$coefficientsで抽出する方法です。 lm_fit1 &lt;- lm(PPP_per_capita ~ FH_Total + Population, data = Country_df) summary(lm_fit1)$coefficients ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.929308e+03 3.229792e+03 0.5973473 5.510476e-01 ## FH_Total 3.256660e+02 4.871626e+01 6.6849553 2.979474e-10 ## Population -2.217793e-06 9.193256e-06 -0.2412413 8.096505e-01 もっと簡単な方法は{broom}のtidy()関数を使う方法です。tidy()関数は推定値に関する様々な情報をデータフレームとして返す便利な関数です。デフォルトだと95%信頼区間は出力されませんが、conf.int = TRUEを指定すると信頼区間も出力されます。tidy()関数を提供する{broom}パッケージは{tidyverse}の一部ですが、{tidyverse}読み込みの際に一緒に読み込まれるものではないため、予め{broom}パッケージを読み込んでおくか、broom::tidy()で使うことができます。 broom::tidy(lm_fit1, conf.int = TRUE) ## # A tibble: 3 × 7 ## term estimate std.error statistic p.value conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Intercept) 1929. 3230. 0.597 5.51e- 1 -4.45e+3 8.30e+3 ## 2 FH_Total 326. 48.7 6.68 2.98e-10 2.30e+2 4.22e+2 ## 3 Population -0.00000222 0.00000919 -0.241 8.10e- 1 -2.04e-5 1.59e-5 それではModel列にあるlmオブジェクトから推定値の情報を抽出し、Model2という列に格納してみましょう。今回はラムダ式を使う必要がありません。なぜなら、tidy()の第一引数がデータだからです（?tidy.lm参照）。他にも必要な引数（conf.int = TRUEなど）があれば、map()の第3引数以降で指定します。 Nested_Data %&gt;% mutate(Model = map(data, ~lm(PPP_per_capita ~ FH_Total + Population, data = .x)), Model2 = map(Model, broom::tidy, conf.int = TRUE)) ## # A tibble: 5 × 4 ## # Groups: Continent [5] ## Continent data Model Model2 ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; ## 1 Asia &lt;tibble [42 × 17]&gt; &lt;lm&gt; &lt;tibble [3 × 7]&gt; ## 2 Europe &lt;tibble [50 × 17]&gt; &lt;lm&gt; &lt;tibble [3 × 7]&gt; ## 3 Africa &lt;tibble [54 × 17]&gt; &lt;lm&gt; &lt;tibble [3 × 7]&gt; ## 4 America &lt;tibble [36 × 17]&gt; &lt;lm&gt; &lt;tibble [3 × 7]&gt; ## 5 Oceania &lt;tibble [4 × 17]&gt; &lt;lm&gt; &lt;tibble [3 × 7]&gt; Model2列の各セルに7列のtibbleが格納されているようです。ここからはdataとModel列は不要ですのでselect()関数を使って除去し、Model2の入れ子構造を解除してみます。 Nested_Data %&gt;% mutate(Model = map(data, ~lm(PPP_per_capita ~ FH_Total + Population, data = .x)), Model2 = map(Model, broom::tidy, conf.int = TRUE)) %&gt;% select(-c(data, Model)) %&gt;% unnest(cols = Model2) ## # A tibble: 15 × 8 ## # Groups: Continent [5] ## Continent term estimate std.error statistic p.value conf.low conf.high ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia (Intercept) 2.13e+4 7.38e+3 2.89 6.32e-3 6.39e+3 3.63e+4 ## 2 Asia FH_Total 6.99e+1 1.56e+2 0.449 6.56e-1 -2.45e+2 3.85e+2 ## 3 Asia Population -1.26e-5 1.26e-5 -1.00 3.23e-1 -3.81e-5 1.29e-5 ## 4 Europe (Intercept) -1.40e+4 9.41e+3 -1.48 1.45e-1 -3.29e+4 5.00e+3 ## 5 Europe FH_Total 6.29e+2 1.08e+2 5.80 7.07e-7 4.10e+2 8.48e+2 ## 6 Europe Population 1.17e-4 8.45e-5 1.39 1.73e-1 -5.33e-5 2.88e-4 ## 7 Africa (Intercept) 3.83e+3 1.84e+3 2.09 4.20e-2 1.44e+2 7.52e+3 ## 8 Africa FH_Total 5.11e+1 3.42e+1 1.49 1.42e-1 -1.77e+1 1.20e+2 ## 9 Africa Population -1.43e-5 2.31e-5 -0.619 5.39e-1 -6.07e-5 3.21e-5 ## 10 America (Intercept) -7.50e+3 5.93e+3 -1.27 2.15e-1 -1.96e+4 4.57e+3 ## 11 America FH_Total 3.12e+2 7.73e+1 4.03 3.20e-4 1.54e+2 4.69e+2 ## 12 America Population 9.13e-5 2.35e-5 3.89 4.77e-4 4.35e-5 1.39e-4 ## 13 Oceania (Intercept) -5.10e+4 2.34e+4 -2.18 2.73e-1 -3.48e+5 2.46e+5 ## 14 Oceania FH_Total 9.76e+2 3.26e+2 2.99 2.05e-1 -3.17e+3 5.12e+3 ## 15 Oceania Population 1.52e-4 6.27e-4 0.242 8.49e-1 -7.81e-3 8.12e-3 各大陸ごとの回帰分析の推定結果が一つのデータフレームとして展開されました。ここではFH_Totalの推定値のみがほしいので、filter()関数を使用し、termの値が\"FH_Total\"の行のみを残します。また、term列も必要なくなるので除外しましょう。 Nested_Data %&gt;% mutate(Model = map(data, ~lm(PPP_per_capita ~ FH_Total + Population, data = .x)), Model2 = map(Model, broom::tidy, conf.int = TRUE)) %&gt;% select(-c(data, Model)) %&gt;% unnest(cols = Model2) %&gt;% filter(term == &quot;FH_Total&quot;) %&gt;% select(-term) ## # A tibble: 5 × 7 ## # Groups: Continent [5] ## Continent estimate std.error statistic p.value conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Asia 69.9 156. 0.449 0.656 -245. 385. ## 2 Europe 629. 108. 5.80 0.000000707 410. 848. ## 3 Africa 51.1 34.2 1.49 0.142 -17.7 120. ## 4 America 312. 77.3 4.03 0.000320 154. 469. ## 5 Oceania 976. 326. 2.99 0.205 -3166. 5117. これで終わりです。政治的自由度と所得水準の関係はアジアとアフリカでは連関の程度が小さく、統計的有意ではありません。オセアニアの場合、連関の程度は大きいと考えられますが、サンプルサイズが小さいため統計的有意な結果は得られませんでした。一方、ヨーロッパとアメリカでは連関の程度も大きく、統計的有意な連関が確認されました。 以上のコードをよりコンパクトにまとめると以下のようなコードとなります。 # {purrr}使用 Nested_Data %&gt;% mutate(Model = map(data, ~lm(PPP_per_capita ~ FH_Total + Population, data = .x)), Model = map(Model, broom::tidy, conf.int = TRUE)) %&gt;% unnest(cols = Model) %&gt;% filter(term == &quot;FH_Total&quot;) %&gt;% select(-c(data, term)) {purrr}パッケージを使用しない例も紹介します。むろん、以下のコードは可能な限り面倒な書き方をしています。for()文やsplit()と*apply()関数を組み合わせると以下の例よりも簡潔なコードは作成できます。R上級者になるためには{tidyverse}的な書き方だけでなく、ネイティブRの書き方にも慣れる必要があります。ぜひ挑戦してみましょう。 # {purrr}を使用しない場合 # FH_Totalの係数と標準誤差のみを抽出する例 lm_fit1 &lt;- lm(PPP_per_capita ~ FH_Total + Population, data = subset(Country_df, Country_df$Continent == &quot;Asia&quot;)) lm_fit2 &lt;- lm(PPP_per_capita ~ FH_Total + Population, data = subset(Country_df, Country_df$Continent == &quot;Europe&quot;)) lm_fit3 &lt;- lm(PPP_per_capita ~ FH_Total + Population, data = subset(Country_df, Country_df$Continent == &quot;Africa&quot;)) lm_fit4 &lt;- lm(PPP_per_capita ~ FH_Total + Population, data = subset(Country_df, Country_df$Continent == &quot;America&quot;)) lm_fit5 &lt;- lm(PPP_per_capita ~ FH_Total + Population, data = subset(Country_df, Country_df$Continent == &quot;Oceania&quot;)) lm_df &lt;- data.frame(Continent = c(&quot;Asia&quot;, &quot;Europe&quot;, &quot;Africa&quot;, &quot;America&quot;, &quot;Oceania&quot;), estimate = c(summary(lm_fit1)$coefficients[2, 1], summary(lm_fit2)$coefficients[2, 1], summary(lm_fit3)$coefficients[2, 1], summary(lm_fit4)$coefficients[2, 1], summary(lm_fit5)$coefficients[2, 1]), se = c(summary(lm_fit1)$coefficients[2, 2], summary(lm_fit2)$coefficients[2, 2], summary(lm_fit3)$coefficients[2, 2], summary(lm_fit4)$coefficients[2, 2], summary(lm_fit5)$coefficients[2, 2])) 27.5.3 データの範囲を指定したモデル推定 これまでの例は名目変数でグループ化を行いましたが、連続変数を使うことも可能です。たとえば、人口1千万未満の国、1千万以上5千万未満、5千万以上1億未満、1億以上でサンプルを分割することです。まず、Country_dfからPPP_per_capita、FH_Total、Population列のみを抽出し、Country_df2に格納します。 Country_df2 &lt;- Country_df %&gt;% select(PPP_per_capita, FH_Total, Population) 続いて、case_when()関数を使用し、Populationの値を基準にケースがどの範囲内に属するかを表す変数Groupを作成します。 Country_df2 &lt;- Country_df2 %&gt;% mutate(Group = case_when(Population &lt; 10000000 ~ &quot;1千万未満&quot;, Population &lt; 50000000 ~ &quot;1千万以上5千万未満&quot;, Population &lt; 100000000 ~ &quot;5千万以上1億未満&quot;, Population &gt;= 100000000 ~ &quot;1億以上&quot;)) 中身を確認してみましょう。 Country_df2 ## # A tibble: 186 × 4 ## PPP_per_capita FH_Total Population Group ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 2125. 27 38928346 1千万以上5千万未満 ## 2 13781. 67 2877797 1千万未満 ## 3 11324. 34 43851044 1千万以上5千万未満 ## 4 NA 94 77265 1千万未満 ## 5 6649. 32 32866272 1千万以上5千万未満 ## 6 21267. 85 97929 1千万未満 ## 7 22938. 85 45195774 1千万以上5千万未満 ## 8 12974. 53 2963243 1千万未満 ## 9 50001. 97 25499884 1千万以上5千万未満 ## 10 55824. 93 9006398 1千万未満 ## # … with 176 more rows あとはこれまでの例と同じ手順となります。まず、データをGroup変数でグループ化し、入れ子構造に変換します。 Country_df2 &lt;- Country_df2 %&gt;% group_nest(Group) Country_df2 ## # A tibble: 4 × 2 ## Group data ## &lt;chr&gt; &lt;list&lt;tibble[,3]&gt;&gt; ## 1 1億以上 [14 × 3] ## 2 1千万以上5千万未満 [61 × 3] ## 3 1千万未満 [96 × 3] ## 4 5千万以上1億未満 [15 × 3] 続いて、data列をデータとし、map()関数でモデルの推定をしてみましょう。目的変数は所得水準、説明変数は政治的自由度とします。推定後、{broom}のtidy()変数で推定値の情報のみを抽出し、入れ子構造を解除します。最後にtermがFH_Totalの行のみを残します。 Country_df2 &lt;- Country_df2 %&gt;% mutate(model = map(data, ~lm(PPP_per_capita ~ FH_Total, data = .x)), est = map(model, broom::tidy, conf.int = TRUE)) %&gt;% unnest(est) %&gt;% filter(term == &quot;FH_Total&quot;) %&gt;% select(!c(term, data, model)) Country_df2 ## # A tibble: 4 × 7 ## Group estimate std.error statistic p.value conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1億以上 325. 158. 2.06 6.23e-2 -19.5 669. ## 2 1千万以上5千万未満 366. 59.6 6.14 9.07e-8 246. 485. ## 3 1千万未満 246. 83.0 2.96 3.94e-3 80.8 411. ## 4 5千万以上1億未満 487. 101. 4.80 3.46e-4 268. 706. せっかくなので推定結果を可視化してみましょう。横軸は人口規模（Group）とし、縦軸は推定値とします。係数の点推定値と95%信頼区間を同時に出力するために、geom_pointrange()幾何オブジェクトを使用します。 Country_df2 %&gt;% mutate( # 横軸の表示順番を指定するために、Group変数をfactor化する Group = factor(Group, levels = c(&quot;1千万未満&quot;, &quot;1千万以上5千万未満&quot;, &quot;5千万以上1億未満&quot;, &quot;1億以上&quot;)), # 統計的有意か否かを表すSig変数の作成 Sig = if_else(conf.low * conf.high &gt; 0, &quot;統計的有意&quot;, &quot;統計的非有意&quot;) ) %&gt;% ggplot() + geom_hline(yintercept = 0, color = &quot;red&quot;) + geom_pointrange(aes(x = Group, y = estimate, ymin = conf.low, ymax = conf.high, color = Sig), size = 0.75) + labs(x = &quot;人口&quot;, y = &quot;政治的自由度が所得に与える影響&quot;, color = &quot;&quot;) + scale_color_manual(values = c(&quot;統計的有意&quot; = &quot;black&quot;, &quot;統計的非有意&quot; = &quot;gray70&quot;)) + theme_minimal(base_size = 12) theme(legend.position = &quot;bottom&quot;) ## List of 1 ## $ legend.position: chr &quot;bottom&quot; ## - attr(*, &quot;class&quot;)= chr [1:2] &quot;theme&quot; &quot;gg&quot; ## - attr(*, &quot;complete&quot;)= logi FALSE ## - attr(*, &quot;validate&quot;)= logi TRUE 政治的自由度が高くなるほど所得水準も高くなる傾向が確認されますが、人口が1億人以上の国においてはそのような傾向が見られないことが分かります。 上記の例は、ある行は一つのグループに属するケースです。しかし、ある行が複数のグループに属するケースもあるでしょう。たとえば、ある変数の値が一定値以上である行のみでグループ化する場合です。FH_Scoreが一定値以上のSub-sampleに対して回帰分析を行う場合、FH_Scoreが最大値（100）である国はすべてのSub-sampleに属することになります。この場合はgroup_by()でグループ化することが難しいかも知れません。しかし、{dplyr}のfilter()を使えば簡単に処理することができます。 ここでは人口を説明変数に、所得水準を応答変数とした単回帰分析を行います。データは政治的自由度が一定値以上の国家のみに限定します。FH_Scoreが0以上の国（すべてのケース）、10以上の国、20以上の国、…などにサンプルを分割してみましょう。まずはFH_Scoreの最小値のみを格納したRnage_dfを作成します。 Range_df &lt;- tibble(Min_FH = seq(0, 80, by = 10)) Range_df ## # A tibble: 9 × 1 ## Min_FH ## &lt;dbl&gt; ## 1 0 ## 2 10 ## 3 20 ## 4 30 ## 5 40 ## 6 50 ## 7 60 ## 8 70 ## 9 80 9行1列のtibbleが出来ました。続いて、Subsetという列を生成し、ここにデータを入れてみましょう。ある変数の値を基準にサンプルを絞るには{dplyr}のfilter()関数を使用します。たとえば、Counter_dfのFH_Totalが50以上のケースに絞るにはfilter(Country_df, FH_Total &gt;= 50)となります。パイプ演算子を使った場合はCountry_df %&gt;% filter(FH_Total &gt;= 50)になりますが、ラムダ式とパイプ演算子の相性はあまり良くありませんので、ここではパイプ演算子なしとします。重要なのはMin_FHの値をデータとしたmap()関数を実行し、実行内容を「Country_dfからFH_TotalがMin_FH以上のケースのみを抽出せよ」にすることです。 Range_df &lt;- Range_df %&gt;% mutate(Subset = map(Min_FH, ~filter(Country_df, FH_Total &gt;= .x))) Range_df ## # A tibble: 9 × 2 ## Min_FH Subset ## &lt;dbl&gt; &lt;list&gt; ## 1 0 &lt;spec_tbl_df [185 × 18]&gt; ## 2 10 &lt;spec_tbl_df [176 × 18]&gt; ## 3 20 &lt;spec_tbl_df [158 × 18]&gt; ## 4 30 &lt;spec_tbl_df [142 × 18]&gt; ## 5 40 &lt;spec_tbl_df [126 × 18]&gt; ## 6 50 &lt;spec_tbl_df [112 × 18]&gt; ## 7 60 &lt;spec_tbl_df [99 × 18]&gt; ## 8 70 &lt;spec_tbl_df [76 × 18]&gt; ## 9 80 &lt;spec_tbl_df [61 × 18]&gt; 入れ子構造になっているのは確認できましたが、ちゃんとフィルタリングされているかどうかも確認してみましょう。たとえば、Range_df$Subset[[9]]だとFH_Totalが80以上の国に絞られていると考えられます。18列の表ですからCountryとFH_Total列のみを確認してみましょう。 Range_df$Subset[[9]] %&gt;% select(Country, FH_Total) ## # A tibble: 61 × 2 ## Country FH_Total ## &lt;chr&gt; &lt;dbl&gt; ## 1 Andorra 94 ## 2 Antigua and Barbuda 85 ## 3 Argentina 85 ## 4 Australia 97 ## 5 Austria 93 ## 6 Bahamas 91 ## 7 Barbados 95 ## 8 Belgium 96 ## 9 Belize 86 ## 10 Bulgaria 80 ## # … with 51 more rows 問題なくフィルタリングされているようですね。ここまで出来ればあとはこれまでの内容の復習でしょう。 Range_df &lt;- Range_df %&gt;% mutate(Model = map(Subset, ~lm(PPP_per_capita ~ Population, data = .x)), Model = map(Model, broom::tidy, conf.int = TRUE)) %&gt;% unnest(cols = Model) %&gt;% filter(term == &quot;Population&quot;) %&gt;% select(-c(Subset, term)) 今回も可視化してみましょう。 Range_df %&gt;% ggplot() + geom_hline(yintercept = 0, color = &quot;red&quot;) + geom_pointrange(aes(x = Min_FH, y = estimate, ymin = conf.low, ymax = conf.high)) + labs(x = &quot;データ内FH_Scoreの最小値&quot;, y = &quot;Populationの係数&quot;) + scale_x_continuous(breaks = seq(0, 80, by = 10), labels = seq(0, 80, by = 10)) + theme_minimal(base_size = 12) 以上の例は実際の分析では多く使われる方法ではないかも知れません。しかし、ノンパラメトリック回帰不連続デザイン（Regression Discontinuity Design; RDD）の場合、感度分析を行う際、バンド幅を色々と調整しながら局所処置効果を推定します。RDDの詳細については矢内の授業資料、およびSONGの授業資料などに譲りますが、ハンド幅の調整はデータの範囲を少しずつ拡張（縮小）させながら同じ分析を繰り返すことです。以下ではアメリカ上院選挙のデータを例に、方法を紹介します。 使用するデータは{rdrobust}パッケージが提供するrdrobust_RDsenateというデータセットです。{pacman}パッケージのp_load()関数を使ってパッケージのインストールと読み込みを行い、data()関数を使って、データを読み込みます。 pacman::p_load(rdrobust) # {rdrobust}のインストール &amp; 読み込み data(&quot;rdrobust_RDsenate&quot;) # rdrobust_RDsenateデータの読み込み # データをSenate_dfという名で格納 Senate_df &lt;- rdrobust_RDsenate Senate_dfの中身を確認してみます。 head(Senate_df) ## margin vote ## 1 -7.6885610 36.09757 ## 2 -3.9237082 45.46875 ## 3 -6.8686604 45.59821 ## 4 -27.6680565 48.47606 ## 5 -8.2569685 51.74687 ## 6 0.7324815 39.80264 本データの詳細は Cattaneo, Frandsen, and Titiunik (2015) に譲りますが、ここでは簡単に説明します。marginはある選挙区の民主党候補者の得票率から共和党候補者の投票率を引いたものです。100なら民主党候補者の圧勝、-100なら共和党候補者の圧勝です。これが0に近いと辛勝または惜敗となり、この辺の民主党候補者と共和党候補者は候補者としての資質や資源が近いと考えられます。voteは次回の選挙における民主党候補者の得票率です。ある候補者が現職であることによるアドバンテージを調べる際、「民主党が勝った選挙区における次回選挙での民主党候補者の得票率」から「民主党が負けた選挙区における次回選挙での民主党候補者の得票率」を引くだけでは不十分でしょう。圧勝できた選挙区は次回でも得票率が高いと考えられますが、これは現職というポジションによるアドバンテージ以外にも、候補者がもともと備えている高い能力・資源にも起因するからです。だから辛勝・惜敗の選挙区のみに限定することで、現職と新人の能力・資源などを出来る限り均質にし、「現職」というポジションだけが異なる状況を見つけることになります。 問題は辛勝と惜敗の基準をどう決めるかですが、広く使われている方法としては Imbens and Kalyanaraman (2012) の最適バンド幅（optimal bandwidth）が広く使われます。しかし、最適バンド幅を使うとしても感度分析（sensitivity analysis）を行うケースも多く、この場合、バンド幅を少しずつ変えながら現職の効果を推定することになります。推定式は以下のようになります。\\(I(\\text{margin} &gt; 0)\\)はmarginが0より大きい場合、1となる指示関数（indicator function）であす。 \\[ \\hat{\\text{vote}} = \\beta_0 + \\beta_1 \\cdot \\text{margin} + \\tau \\cdot I(\\text{margin} &gt; 0) \\quad \\text{where} \\quad -h \\leq \\text{margin} \\leq -h \\] それではまずは\\(h\\)が100、つまり全データを使った分析を試しにやってみましょう。 RDD_Fit &lt;- lm(vote ~ margin + I(margin &gt; 0), data = Senate_df) summary(RDD_Fit) ## ## Call: ## lm(formula = vote ~ margin + I(margin &gt; 0), data = Senate_df) ## ## Residuals: ## Min 1Q Median 3Q Max ## -46.930 -6.402 0.132 7.191 46.443 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 47.33084 0.54192 87.340 &lt; 2e-16 *** ## margin 0.34806 0.01335 26.078 &lt; 2e-16 *** ## I(margin &gt; 0)TRUE 4.78461 0.92290 5.184 2.51e-07 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 11.78 on 1294 degrees of freedom ## (93 observations deleted due to missingness) ## Multiple R-squared: 0.5781, Adjusted R-squared: 0.5774 ## F-statistic: 886.4 on 2 and 1294 DF, p-value: &lt; 2.2e-16 I(margin &gt; 0)TRUEの係数4.785が現職効果です。この作業を\\(h = 100\\)から\\(h = 10\\)まで、5ずつ変えながら分析を繰り返してみます。まずは、RDD_dfというtibbleを作成し、BW列にはc(100, 95, 90, ... 10)を入れます。続いて、filter()関数を利用してSenate_dfからmarginが-BW以上、BW以下のデータを抽出し、Subsetという名の列として格納します。 RDD_df &lt;- tibble(BW = seq(100, 10, by = -5)) RDD_df &lt;- RDD_df %&gt;% mutate(Subset = map(BW, ~filter(Senate_df, margin &gt;= -.x &amp; margin &lt;= .x))) RDD_df ## # A tibble: 19 × 2 ## BW Subset ## &lt;dbl&gt; &lt;list&gt; ## 1 100 &lt;df [1,390 × 2]&gt; ## 2 95 &lt;df [1,327 × 2]&gt; ## 3 90 &lt;df [1,319 × 2]&gt; ## 4 85 &lt;df [1,308 × 2]&gt; ## 5 80 &lt;df [1,303 × 2]&gt; ## 6 75 &lt;df [1,294 × 2]&gt; ## 7 70 &lt;df [1,287 × 2]&gt; ## 8 65 &lt;df [1,270 × 2]&gt; ## 9 60 &lt;df [1,256 × 2]&gt; ## 10 55 &lt;df [1,237 × 2]&gt; ## 11 50 &lt;df [1,211 × 2]&gt; ## 12 45 &lt;df [1,178 × 2]&gt; ## 13 40 &lt;df [1,128 × 2]&gt; ## 14 35 &lt;df [1,077 × 2]&gt; ## 15 30 &lt;df [995 × 2]&gt; ## 16 25 &lt;df [901 × 2]&gt; ## 17 20 &lt;df [778 × 2]&gt; ## 18 15 &lt;df [639 × 2]&gt; ## 19 10 &lt;df [471 × 2]&gt; RDD_df &lt;- RDD_df %&gt;% mutate( # 各Subsetに対し、回帰分析を実施し、Model列に格納 Model = map(Subset, ~lm(vote ~ margin * I(margin &gt; 0), data = .x)), # Model列の各セルから{broom}のtidy()で推定値のみ抽出 Est = map(Model, broom::tidy, conf.int = TRUE) ) %&gt;% # Est列の入れ子構造を解除 unnest(Est) %&gt;% # 現職効果に該当する行のみを抽出 filter(term == &quot;I(margin &gt; 0)TRUE&quot;) %&gt;% # 不要な列を削除 select(!c(Subset, Model, term, statistic, p.value)) RDD_df ## # A tibble: 19 × 5 ## BW estimate std.error conf.low conf.high ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 100 6.04 0.942 4.20 7.89 ## 2 95 5.76 0.975 3.85 7.67 ## 3 90 5.90 0.981 3.98 7.83 ## 4 85 5.80 0.993 3.85 7.75 ## 5 80 5.10 0.999 3.14 7.06 ## 6 75 5.18 1.01 3.21 7.15 ## 7 70 5.57 1.01 3.58 7.55 ## 8 65 5.21 1.03 3.20 7.23 ## 9 60 4.89 1.04 2.86 6.93 ## 10 55 5.23 1.05 3.17 7.29 ## 11 50 5.73 1.07 3.64 7.82 ## 12 45 5.94 1.09 3.80 8.09 ## 13 40 6.12 1.12 3.92 8.33 ## 14 35 6.34 1.15 4.09 8.59 ## 15 30 7.18 1.18 4.86 9.50 ## 16 25 7.38 1.21 5.00 9.76 ## 17 20 7.03 1.32 4.43 9.62 ## 18 15 6.96 1.50 4.01 9.92 ## 19 10 6.90 1.75 3.46 10.3 19回の回帰分析が数行のコードで簡単に実施でき、必要な情報も素早く抽出することができました。 以上の例は、交互作用なしの線形回帰分析による局所処置効果の推定例です。しかし、ノンパラメトリックRDDでは、割当変数（running variable）処置変数の交差項や割当変数の二乗項を入れる場合が多いです。今回の割当変数はmarginです。また、閾値（cutpoint）に近いケースには高い重みを付けることが一般的な作法であり、多く使われるのが三角（triangular）カーネルです。上記の例はすべてのケースに同じ重みを付ける矩形（rectagular）カーネルを使った例です。 以上の理由により、やはりRDDは専用のパッケージを使った方が良いかも知れません。既に読み込んである{rdrobust}も推定可能ですが、ここでは{rdd}パッケージを使ってみましょう。{rdd}パッケージによるRDDはRDestimate()関数を使います。実際の例を確認してみましょう。map()を使う前に、オブジェクトの構造を把握しておくことは重要です。 # cutpoint引数の既定値は0であるため、今回の例では省略可能 RDestimate(応答変数 ~ 割当変数, data = データオブジェクト, cutpoint = 閾値, bw = バンド幅) pacman::p_load(rdd) # パッケージの読み込み # バンド幅を指定したRDD推定 RDD_Fit &lt;- RDestimate(vote ~ margin, data = Senate_df, bw = 100) # RDDの推定結果を見る summary(RDD_Fit) ## ## Call: ## RDestimate(formula = vote ~ margin, data = Senate_df, bw = 100) ## ## Type: ## sharp ## ## Estimates: ## Bandwidth Observations Estimate Std. Error z value Pr(&gt;|z|) ## LATE 100 1258 5.637 0.8845 6.374 1.842e-10 ## Half-BW 50 1127 6.480 1.0040 6.455 1.084e-10 ## Double-BW 200 1297 5.842 0.8568 6.818 9.210e-12 ## ## LATE *** ## Half-BW *** ## Double-BW *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## F-statistics: ## F Num. DoF Denom. DoF p ## LATE 316.0 3 1254 0 ## Half-BW 179.7 3 1123 0 ## Double-BW 506.0 3 1293 0 現職効果は5.637、その標準誤差は0.884です。これらの情報はどこから抽出できるか確認してみます。 # 推定値の情報がどこに格納されているかを確認 str(RDD_Fit) ## List of 12 ## $ type : chr &quot;sharp&quot; ## $ call : language RDestimate(formula = vote ~ margin, data = Senate_df, bw = 100) ## $ est : Named num [1:3] 5.64 6.48 5.84 ## ..- attr(*, &quot;names&quot;)= chr [1:3] &quot;LATE&quot; &quot;Half-BW&quot; &quot;Double-BW&quot; ## $ bw : num [1:3] 100 50 200 ## $ se : num [1:3] 0.884 1.004 0.857 ## $ z : num [1:3] 6.37 6.45 6.82 ## $ p : num [1:3] 1.84e-10 1.08e-10 9.21e-12 ## $ obs : num [1:3] 1258 1127 1297 ## $ ci : num [1:3, 1:2] 3.9 4.51 4.16 7.37 8.45 ... ## $ model : list() ## $ frame : list() ## $ na.action: int [1:93] 28 29 57 58 86 113 114 142 143 168 ... ## - attr(*, &quot;class&quot;)= chr &quot;RD&quot; $estと$seに私たちが探している数値が入っていますね。それぞれ抽出してみると長さ3のnumericベクトルが出力され、その中で1番目の要素がLATEということが分かります。 # est要素の1番目の要素がLATE RDD_Fit$est ## LATE Half-BW Double-BW ## 5.637474 6.480344 5.842049 # se要素の1番目の要素がLATEの標準誤差 RDD_Fit$se ## [1] 0.8844541 1.0039734 0.8568150 それでは分析に入ります。今回も\\(h\\)を予めBWという名の列で格納したRDD_dfを作成します。 RDD_df &lt;- tibble(BW = seq(100, 10, by = -5)) 今回はラムダ式を使わず、事前に関数を定義しておきましょう。関数の自作については第11章を参照してください。 # 引数をxとするRDD_Func()の定義 RDD_Func &lt;- function(x) { # バンド幅をxにしたRDD推定 Temp_Est &lt;- RDestimate(vote ~ margin, data = Senate_df, bw = x) # LATEとその標準誤差をtibbleとして返す tibble(LATE = Temp_Est$est[1], SE = Temp_Est$se[1]) } 問題なく動くかを確認してみましょう。 RDD_Func(100) ## # A tibble: 1 × 2 ## LATE SE ## &lt;dbl&gt; &lt;dbl&gt; ## 1 5.64 0.884 それでは分析をやってみましょう。今回の場合、map()の第二引数はラムダ式ではないため~で始める必要ありません。関数名だけで十分です。 RDD_df &lt;- RDD_df %&gt;% mutate(RDD = map(BW, RDD_Func)) %&gt;% unnest(RDD) RDD_df ## # A tibble: 19 × 3 ## BW LATE SE ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 100 5.64 0.884 ## 2 95 5.64 0.890 ## 3 90 5.63 0.897 ## 4 85 5.61 0.905 ## 5 80 5.65 0.913 ## 6 75 5.75 0.922 ## 7 70 5.81 0.934 ## 8 65 5.91 0.949 ## 9 60 6.07 0.963 ## 10 55 6.29 0.982 ## 11 50 6.48 1.00 ## 12 45 6.67 1.03 ## 13 40 6.91 1.07 ## 14 35 7.19 1.11 ## 15 30 7.28 1.17 ## 16 25 7.10 1.26 ## 17 20 7.27 1.38 ## 18 15 7.49 1.57 ## 19 10 7.98 1.84 せっかくなので可視化してみましょう。今回はgeom_pointrange()を使わず、geom_line()とgeom_ribbon()を組み合わせます。geom_line()はLATEを、geom_ribbion()は95%信頼区間を表します。作図の前に95%信頼区間を計算しておきます。 RDD_df %&gt;% mutate(CI_lwr = LATE + qnorm(0.025) * SE, CI_upr = LATE + qnorm(0.975) * SE) %&gt;% ggplot() + geom_hline(yintercept = 0, color = &quot;red&quot;) + geom_ribbon(aes(x = BW, ymin = CI_lwr, ymax = CI_upr), alpha = 0.5) + geom_line(aes(x = BW, y = LATE), size = 1) + labs(x = &quot;Bandwidth&quot;, y = &quot;Local Average Treatment Effect (%p)&quot;) + theme_minimal(base_size = 12) 27.5.4 説明・応答変数を指定したモデル推定 続いて、同じデータに対して推定式のみを変えた反復推定をやってみましょう。たとえば、応答変数は固定し、グループ変数のみを変えながらt検定を繰り返すケースを考えてみましょう。たとえば、OECDに加盟しているかどうか（OECD）で購買力平価GDP（PPP）の差があるかを検定してみましょう。使用する関数はt.test()です。第一引数には応答変数 ~ 説明変数とし、data引数にはデータフレームやtibbleオブジェクトを指定します。 Diff_test &lt;- t.test(PPP ~ G20, data = Country_df) Diff_test ## ## Welch Two Sample t-test ## ## data: PPP by G20 ## t = -3.4137, df = 18.012, p-value = 0.003094 ## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0 ## 95 percent confidence interval: ## -7667830 -1825482 ## sample estimates: ## mean in group 0 mean in group 1 ## 211287 4957943 ここからいくつかの情報が読み取れます。まず、OECD加盟国のPPPは4957943、非加盟国は211287です。その差分は-4746656です。また、t値は-3.4136、p値は0.003です。これらの情報を効率よく抽出するにはbroom::tidy()が便利です。 broom::tidy(Diff_test) ## # A tibble: 1 × 10 ## estimate estimate1 estimate2 statistic p.value parameter conf.low conf.high ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -4746656. 211287. 4957943. -3.41 0.00309 18.0 -7667830. -1825482. ## # … with 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt; 差分、t値、p値、95%信頼区間などが抽出できます。これをOECDだけでなく、G7やG20に対しても同じ検定を繰り返してみましょう。 t.test()の第一引数だけを変えながら推定をすれば良いでしょう。この第一引数、たとえばPPP ~ G20の方はformula型と呼ばれるRにおけるデータ型の一つです。これはcharacter型でないことに注意してください。 Formula1 &lt;- &quot;PPP ~ G20&quot; t.test(Formula1, data = Country_df) ## Warning in mean.default(x): argument is not numeric or logical: returning NA ## Warning in var(x): NAs introduced by coercion ## Error in t.test.default(Formula1, data = Country_df): not enough &#39;x&#39; observations このようにエラーが出ます。このFormulaをas.formula()関数を使ってformula型に変換し、推定をやってみると問題なく推定できることが分かります。 Formula2 &lt;- as.formula(Formula1) t.test(Formula2, data = Country_df) ## ## Welch Two Sample t-test ## ## data: PPP by G20 ## t = -3.4137, df = 18.012, p-value = 0.003094 ## alternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0 ## 95 percent confidence interval: ## -7667830 -1825482 ## sample estimates: ## mean in group 0 mean in group 1 ## 211287 4957943 これから私たちがやるのは\"PPP ~ \"の次に\"G7\"、\"G20\"、\"OECD\"をpaste()やpaste0()関数を結合し、formula型に変換することです。formula型の列さえ生成できれば、あとはmap()関数にformulaを渡し、データはCountry_dfに固定するだけです。 まずはどの変数を説明変数にするかをGroup列として格納したDiff_dfを作成します。 Diff_df &lt;- tibble(Group = c(&quot;G7&quot;, &quot;G20&quot;, &quot;OECD&quot;)) Diff_df ## # A tibble: 3 × 1 ## Group ## &lt;chr&gt; ## 1 G7 ## 2 G20 ## 3 OECD 続いて、Formula列を作成し、\"PPP ~ \"の次にGroup列の文字列を結合します。 Diff_df &lt;- Diff_df %&gt;% mutate(Formula = paste0(&quot;PPP ~ &quot;, Group)) Diff_df ## # A tibble: 3 × 2 ## Group Formula ## &lt;chr&gt; &lt;chr&gt; ## 1 G7 PPP ~ G7 ## 2 G20 PPP ~ G20 ## 3 OECD PPP ~ OECD 今のFormula列のデータ型を確認してみましょう。 class(Diff_df$Formula[[1]]) ## [1] &quot;character&quot; character型ですね。続いて、map()関数を使用してFormula列をformula型に変換します。 Diff_df &lt;- Diff_df %&gt;% mutate(Formula = map(Formula, as.formula)) Diff_df ## # A tibble: 3 × 2 ## Group Formula ## &lt;chr&gt; &lt;list&gt; ## 1 G7 &lt;formula&gt; ## 2 G20 &lt;formula&gt; ## 3 OECD &lt;formula&gt; データ型も確認してみましょう。 class(Diff_df$Formula[[1]]) ## [1] &quot;formula&quot; formula型になっていることが分かります。 もう一つの方法としては最初からfromula型の変数を入れても良いでしょう。推定するモデルが多くない場合は、こちらの方が簡単かも知れません。たとえば、これまでの作業を直接formula型を格納する形式で行うなら以下のようになります107。 # 方法1 Diff_df &lt;- tibble(Group = c(&quot;G7&quot;, &quot;G20&quot;, &quot;OECD&quot;), Formula = c(PPP ~ G7, PPP ~ G20, PPP ~ OECD)) # 方法2 Diff_df &lt;- list(&quot;G7&quot; = PPP ~ G7, &quot;G20&quot; = PPP ~ G20, &quot;OECD&quot; = PPP ~ OECD) %&gt;% enframe(name = &quot;Group&quot;, value = &quot;Formula&quot;) それではt検定を行います。ここでもラムダ式を使います。式が入る場所には.xを指定し、データはCountry_dfに固定します。 Diff_df &lt;- Diff_df %&gt;% mutate(Model = map(Formula, ~t.test(.x, data = Country_df))) Diff_df ## # A tibble: 3 × 3 ## Group Formula Model ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 G7 &lt;formula&gt; &lt;htest&gt; ## 2 G20 &lt;formula&gt; &lt;htest&gt; ## 3 OECD &lt;formula&gt; &lt;htest&gt; broom::tidy()で推定値の要約を抽出し、入れ子構造を解除します。 Diff_df &lt;- Diff_df %&gt;% mutate(Tidy = map(Model, broom::tidy)) %&gt;% unnest(Tidy) Diff_df ## # A tibble: 3 × 13 ## Group Formula Model estimate estimate1 estimate2 statistic p.value ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 G7 &lt;formula&gt; &lt;htest&gt; -5363390. 507033. 5870423. -2.14 0.0759 ## 2 G20 &lt;formula&gt; &lt;htest&gt; -4746656. 211287. 4957943. -3.41 0.00309 ## 3 OECD &lt;formula&gt; &lt;htest&gt; -1166591. 475459. 1642050. -1.96 0.0564 ## # … with 5 more variables: parameter &lt;dbl&gt;, conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;, ## # method &lt;chr&gt;, alternative &lt;chr&gt; いくつか使用しない情報もあるので、適宜列を削除します。 Diff_df &lt;- Diff_df %&gt;% select(-c(Formula, Model, estimate1, estimate2, p.value, method, alternative)) Diff_df ## # A tibble: 3 × 6 ## Group estimate statistic parameter conf.low conf.high ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 G7 -5363390. -2.14 6.04 -11486296. 759515. ## 2 G20 -4746656. -3.41 18.0 -7667830. -1825482. ## 3 OECD -1166591. -1.96 42.8 -2366187. 33005. 以上のコードをパイプ演算子を使用し、簡潔にまとめると以下のようになります。 Diff_df &lt;- tibble(Group = c(&quot;G7&quot;, &quot;G20&quot;, &quot;OECD&quot;)) Diff_df &lt;- Diff_df %&gt;% mutate(Formula = paste0(&quot;PPP ~ &quot;, Group), Formula = map(Formula, as.formula), Model = map(Formula, ~t.test(.x, data = Country_df)), Tidy = map(Model, broom::tidy)) %&gt;% unnest(Tidy) %&gt;% select(-c(Formula, Model, estimate1, estimate2, p.value, method, alternative)) 推定結果を可視化してみましょう。 Diff_df %&gt;% mutate(Group = fct_inorder(Group), Sig = if_else(conf.low * conf.high &gt; 0, &quot;統計的有意&quot;, &quot;統計的非有意&quot;)) %&gt;% ggplot() + geom_vline(xintercept = 0, linetype = 2) + geom_pointrange(aes(x = estimate, xmin = conf.low, xmax = conf.high, y = Group, color = Sig), size = 0.75) + scale_color_manual(values = c(&quot;統計的有意&quot; = &quot;black&quot;, &quot;統計的非有意&quot; = &quot;gray70&quot;)) + labs(x = &quot;非加盟国のPPP - 加盟国のPPP&quot;, y = &quot;グループ&quot;, color = &quot;&quot;) + theme_minimal(base_size = 12) + theme(legend.position = &quot;bottom&quot;) 以上の方法を応用すると応答変数を変えながら分析を繰り返すこともできます。他にも説明変数が2つ以上のケースにも応用可能です。 参考資料 "],["oop.html", "28. オブジェクト指向型プログラミング 28.1 まずは例から 28.2 OOPとは 28.3 RにおけるOOP 28.4 例題", " 28. オブジェクト指向型プログラミング 28.1 まずは例から Vector1 &lt;- c(1, 5, 3, 7, 9, 12, 5, 4, 10, 1) Vector2 &lt;- c(&quot;A&quot;, &quot;B&quot;, &quot;D&quot;, &quot;B&quot;, &quot;E&quot;, &quot;A&quot;, &quot;A&quot;, &quot;D&quot;, &quot;C&quot;, &quot;C&quot;) summary(Vector1) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.00 3.25 5.00 5.70 8.50 12.00 summary(Vector2) ## Length Class Mode ## 10 character character 同じsummary()関数ですが、中のデータのタイプによって動きが異なります。これがオブジェクト指向プログラミングにおいて「多態性 (polymorphism)」と呼ばれる概念です。同じ関数でもデータ型、またはデータ構造に応じて異なる動きをすることです。ここでのデータ型やデータ構造を、OOPでは「クラス (class)」と呼びます。クラスはclass()関数で確認することができます。 class(Vector1) ## [1] &quot;numeric&quot; class(Vector2) ## [1] &quot;character&quot; Vector1はnumeric、Vector2はcharacterです。もし、無理矢理にVector1のクラスをcharacterに変えればどうなるでしょうか。クラスの変更はclass(オブジェクト名) &lt;- \"クラス名\"でできます。一つのオブジェクトは複数のクラスが持てますが、これはOOPの「継承 (inheritance)」概念に関係するので後で解説します。ここではまず、Vector1のクラスをcharacterにし、もう一回summary()を使ってみましょう。 class(Vector1) &lt;- &quot;character&quot; summary(Vector1) ## Length Class Mode ## 10 character character データの中身は変わっていませんが、summary()関数の動き方が変わりました。このように、Rで頻繁に使うsummary()、print()、plot()などの関数は様々なクラスの対応しております。lm()関数を使った回帰分析の結果オブジェクトのクラス名はlmであり、その結果を見るためにもsummary()関数を使います。他にもplot(lmオブジェクト名)をすると回帰診断の図が表示されます。これができないと、各クラスに応じた関数を作成する必要がありますね。numeric型専用のnumeric_print()、character型専用のcharacter_print()、lm型専用のlm_plot()など…、覚えなきゃいけない関数が増えてきます。ユーザー側でも大変ですが、コードを作成する側も大変です。実際、図28.1108を見ると、プログラマーにとって最も大変な仕事は「名付け」であることが分かります。 図 28.1: Programmers’ Hardest Tasks OOPの多態性にはこのような煩わしい仕事を軽減する機能があります。OOPにはここで紹介した多態性以外にも、「継承 (inheritance)」、「カプセル化 (encapsulation)」のような特徴があります。他にも人によっては「メッセージパッシング (message passing)」、「動的バインディング (dynamic binding)」などの特徴を述べたりしますが、詳しい話は専門書に譲りたいと思います。また、ここではRのS3クラスについて解説しますが、S3はカプセル化に対応しておりません。したがって、ここでは以下の概念について例と一緒に解説していきたいと思います。 オブジェクト (object) クラス (class) メソッド (method) 多態性 (polymorphism) 継承 (inheritance) 28.2 OOPとは 28.2.1 オブジェクト ここは第10章の内容の繰り返しですが、オブジェクト (object) とはメモリに割り当てられた「何か」です。「何か」に該当するのは、ベクトル (vector)、行列 (matrix)、データフレーム (data frame)、リスト (list)、関数 (function) などがあります。一般的に、オブジェクトにはそれぞれ固有の（つまり、他のオブジェクトと重複しない）名前が付いています。 たとえば、1から5までの自然数の数列を my_vec1 &lt;- c(1, 2, 3, 4, 5) # my_vec1 &lt;- 1:5 でも同じ のようにmy_vec1という名前のオブジェクトに格納します。オブジェクトに名前をつけてメモリに割り当てると、その後 my_vec1 と入力するだけでそのオブジェクトの中身を読み込むことができるようになります。 ここで、次のように my_vec1の要素を2倍にする操作を考えてみましょう。 my_vec1 * 2 ## [1] 2 4 6 8 10 my_vec1は、先ほど定義したオブジェクトです。では2はどうでしょうか。2はメモリに割り当てられていないので、オブジェクトではないでしょうか。実は、この数字 2 もオブジェクトです。計算する瞬間のみ2がメモリに割り当てられ、計算が終わったらメモリから消されると考えれば良いでしょう。むろん、* のような演算子でさえもオブジェクトです。 28.2.2 クラス クラス (class) とはオブジェクトを特徴づける属性のことです。既に何度か class() 関数を使ってデータ型やデータ構造を確認しましたが、class()関数でオブジェクトのクラスを確認することができます。先ほど、my_vec1も*も2もオブジェクトであると説明しました。これらがすべてオブジェクトであるということは、何らかのクラス属性を持っているというこです。また、class()関数そのものもオブジェクトなので、何らかのクラスを持ちます。確認してみましょう。 class(my_vec1) ## [1] &quot;numeric&quot; class(`*`) ## [1] &quot;function&quot; class(2) ## [1] &quot;numeric&quot; class(class) ## [1] &quot;function&quot; 統計分析をする際に、Rのクラスを意識することはあまりありません。しかし、Rでオブジェクト指向プログラミングを行う際は、オブジェクトのクラスを厳密に定義する必要があります。 Rにおける全てはオブジェクトであり、全てのオブジェクトは一つ以上クラスが付与されています。このクラスの考え方はプログラミング言語によって異なります。たとえば、Pythonの場合、一つのクラスの内部にはオブジェクトのデータ構造が定義され、そのクラスで使用可能な関数も含んでいます。また、データを含む場合もあります。このようにクラス内部にデータ、データ構造、専用関数などを格納することをカプセル化（encapsulation）と呼びます。 一方、Rの（S3）クラスにはクラス専用関数がクラス内で定義されておらず、データのみが格納されています。 28.2.3 メソッドと多態性 各クラス専用の関数をメソッド（method）と呼びます。たとえば、summary()関数を考えてみましょう。lm()関数を用いた回帰分析から得られたオブジェクトのクラスはlmであり、c()で作られた数値型ベクトルのクラスはnumericです。しかし、同じsummary()関数ですが、引数のクラスがlmかnumericかによって異なる動きを見せます。その例を見ましょう。 X &lt;- c(1, 3, 5, 7, 9, 11) Y &lt;- c(1, 2, 3, 7, 11, 13) lm_class &lt;- lm(Y ~ X) class(X) ## [1] &quot;numeric&quot; class(lm_class) ## [1] &quot;lm&quot; summary(X) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 1.0 3.5 6.0 6.0 8.5 11.0 summary(lm_class) ## ## Call: ## lm(formula = Y ~ X) ## ## Residuals: ## 1 2 3 4 5 6 ## 1.3333 -0.2667 -1.8667 -0.4667 0.9333 0.3333 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -1.6333 1.0546 -1.549 0.19637 ## X 1.3000 0.1528 8.510 0.00105 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.278 on 4 degrees of freedom ## Multiple R-squared: 0.9477, Adjusted R-squared: 0.9346 ## F-statistic: 72.43 on 1 and 4 DF, p-value: 0.001046 このように同じ関数でもクラスによって異なる動作をすることを多態性 (polymorphism)と呼びます。しかし、実はRにおいてこれらの関数は別途作られた関数です。つまり、summary()という関数がクラスごとに定義されていることを意味します。summary()関数がどのクラスで使用可能かを確認するためにはmethods()関数を使います。 methods(&quot;summary&quot;) ## [1] summary,ANY-method summary,DBIObject-method ## [3] summary.aov summary.aovlist* ## [5] summary.aspell* summary.check_packages_in_dir* ## [7] summary.connection summary.data.frame ## [9] summary.Date summary.default ## [11] summary.Duration* summary.ecdf* ## [13] summary.factor summary.ggplot* ## [15] summary.glm summary.haven_labelled* ## [17] summary.hcl_palettes* summary.infl* ## [19] summary.Interval* summary.lm ## [21] summary.loess* summary.manova ## [23] summary.matrix summary.mlm* ## [25] summary.nls* summary.packageStatus* ## [27] summary.Period* summary.POSIXct ## [29] summary.POSIXlt summary.ppr* ## [31] summary.prcomp* summary.princomp* ## [33] summary.proc_time summary.rlang_error* ## [35] summary.rlang_message* summary.rlang_trace* ## [37] summary.rlang_warning* summary.rlang:::list_of_conditions* ## [39] summary.srcfile summary.srcref ## [41] summary.stepfun summary.stl* ## [43] summary.table summary.tukeysmooth* ## [45] summary.vctrs_sclr* summary.vctrs_vctr* ## [47] summary.warnings ## see &#39;?methods&#39; for accessing help and source code このように47種類のクラスに対してsummary()関数が定義されています109。この関数の内部を確認するにはどうすれば良いでしょうか。関数のコードを見るときにはコンソール上に関数名を入力するだけです（()は不要）。 summary ## function (object, ...) ## UseMethod(&quot;summary&quot;) ## &lt;bytecode: 0x7f90cd4405e0&gt; ## &lt;environment: namespace:base&gt; しかし、多態性を持つ関数の内部を見ることはできません。そもそもsummary()関数はクラスごとに異なるコードを持っているため、summaryだけでは「どのクラスのsummary()か」が分かりません。それでもRにはsummary()関数が存在し、それをジェネリック関数（generic function）と呼びます。内部にはUseMethod(\"summary\")のみが書かれており、これは「このsummary()関数は様々なクラスのメソッドとして機能するぞ」と宣言しているだけです。各クラスに対応したメソッドの内部を見るにはgetS3method(\"メソッド名\", \"クラス名\")を使います。summary()メソッドはnumeric型が別途指定されていないため、\"defualt\"となります。 getS3method(&quot;summary&quot;, &quot;default&quot;) ## function (object, ..., digits, quantile.type = 7) ## { ## if (is.factor(object)) ## return(summary.factor(object, ...)) ## else if (is.matrix(object)) { ## if (missing(digits)) ## return(summary.matrix(object, quantile.type = quantile.type, ## ...)) ## else return(summary.matrix(object, digits = digits, quantile.type = quantile.type, ## ...)) ## } ## value &lt;- if (is.logical(object)) ## c(Mode = &quot;logical&quot;, { ## tb &lt;- table(object, exclude = NULL, useNA = &quot;ifany&quot;) ## if (!is.null(n &lt;- dimnames(tb)[[1L]]) &amp;&amp; any(iN &lt;- is.na(n))) dimnames(tb)[[1L]][iN] &lt;- &quot;NA&#39;s&quot; ## tb ## }) ## else if (is.numeric(object)) { ## nas &lt;- is.na(object) ## object &lt;- object[!nas] ## qq &lt;- stats::quantile(object, names = FALSE, type = quantile.type) ## qq &lt;- c(qq[1L:3L], mean(object), qq[4L:5L]) ## if (!missing(digits)) ## qq &lt;- signif(qq, digits) ## names(qq) &lt;- c(&quot;Min.&quot;, &quot;1st Qu.&quot;, &quot;Median&quot;, &quot;Mean&quot;, &quot;3rd Qu.&quot;, ## &quot;Max.&quot;) ## if (any(nas)) ## c(qq, `NA&#39;s` = sum(nas)) ## else qq ## } ## else if (is.recursive(object) &amp;&amp; !is.language(object) &amp;&amp; ## (n &lt;- length(object))) { ## sumry &lt;- array(&quot;&quot;, c(n, 3L), list(names(object), c(&quot;Length&quot;, ## &quot;Class&quot;, &quot;Mode&quot;))) ## ll &lt;- numeric(n) ## for (i in 1L:n) { ## ii &lt;- object[[i]] ## ll[i] &lt;- length(ii) ## cls &lt;- oldClass(ii) ## sumry[i, 2L] &lt;- if (length(cls)) ## cls[1L] ## else &quot;-none-&quot; ## sumry[i, 3L] &lt;- mode(ii) ## } ## sumry[, 1L] &lt;- format(as.integer(ll)) ## sumry ## } ## else c(Length = length(object), Class = class(object), Mode = mode(object)) ## class(value) &lt;- c(&quot;summaryDefault&quot;, &quot;table&quot;) ## value ## } ## &lt;bytecode: 0x7f904d1350b0&gt; ## &lt;environment: namespace:base&gt; Rにはメソッドがクラス内部で定義されず、別途のメソッド名.クラス名()といった関数として作成されています。そしてジェネリック関数によって一つの関数の「ように」まとまっています。このように、ジェネリック関数経由でメソッドを呼び出すことをメソッド・ディスパッチ（method dispatch）と呼びます。 28.2.4 継承 クラスの継承 (inheritance)は一つのオブジェクトが2つ以上のクラスを持つ場合、子クラスが親クラスの特徴を継承することを意味します。たとえば、データフレームの拡張版とも言えるtibbleの場合、複数のクラスを持っています。 my_tibble &lt;- tibble(X = 1:5, Y = 1:5) class(my_tibble) ## [1] &quot;tbl_df&quot; &quot;tbl&quot; &quot;data.frame&quot; このmy_tibbleはtlb_dfとtbl、data.frameといった3つのクラスを持っており、先に出てきたものが子クラス、後に出てくるものが親クラスです。tblクラスとdata.frameクラス両方に同じメソッドが定義されている場合、まず子クラスであるメソッド.tbl()が実行されます。もし、子クラスにメソッドが定義されていない場合はtblの親クラスであるdata.frameのメソッドが実行されます。tibbleはデータフレームとは異なるクラスのオブジェクトですが、データフレームと（ほぼ）同じ操作ができるのは、クラスが継承されるからです。クラスの継承ができないと、tibbleで使える全ての関数（列や行の抽出に使う[や$なども！）を全て一から定義する必要がありますが110、継承を使うことによってこのような手間を省くことが出来ます。 28.3 RにおけるOOP 28.3.1 オブジェクトに任意のクラスを付ける クラスを変えるのは簡単です。class(オブジェクト) &lt;- \"新しいクラス名\"だけです。つまり、関数から何かの結果を返す直前にクラスを変更すれば良いです。 # 方法1 関数名 &lt;- function(...) { ... class(返すオブジェクト名) &lt;- &quot;任意のクラス名&quot; 返すオブジェクト名 # return(オブジェクト名) でもOK } たとえば、入力された2つのベクトル（xとy）をリスト構造とし、クラス名をScoreにするにはどうすれば良いでしょうか。 Make_Score1 &lt;- function(x, y) { # resultリストにxとyを格納 result &lt;- list(Score1 = x, Score2 = y) # 以下は attr(result, &quot;class&quot;) &lt;- &quot;Score&quot; も可 class(result) &lt;- &quot;Score&quot; # resultのクラスを&quot;Score&quot;とする result # resultを返す } My_Score1 &lt;- Make_Score1(x = rnorm(10, 50, 10), y = rnorm(10, 50, 10)) My_Score1 # My_Score1の内部を見る ## $Score1 ## [1] 52.76651 45.25139 58.01932 61.98407 57.22137 66.56256 42.98588 39.79041 ## [9] 60.18205 35.15861 ## ## $Score2 ## [1] 57.66806 46.45710 57.34396 50.67438 34.42431 26.32951 43.88926 44.32712 ## [9] 47.90928 52.80190 ## ## attr(,&quot;class&quot;) ## [1] &quot;Score&quot; class(My_Score1) # My_Score1のクラスを表示 ## [1] &quot;Score&quot; もう一つの方法はstructure()関数を使う方法です。sturcture()の第1引数に返すオブジェクト名を指定し、class = \"クラス名\"引数でクラスを指定します。 Make_Score2 &lt;- function(x, y) { # resultリストにxとyを格納 result &lt;- list(Score1 = x, Score2 = y) structure(result, class = &quot;Score&quot;) # resultを返す } My_Score2 &lt;- Make_Score2(x = rnorm(10, 50, 10), y = rnorm(10, 50, 10)) My_Score2 # My_Score2の内部を見る ## $Score1 ## [1] 31.53875 59.66060 39.72494 53.83409 68.71643 35.14003 36.59862 26.86108 ## [9] 48.83682 60.21164 ## ## $Score2 ## [1] 62.13421 54.56639 77.02598 56.34560 42.20431 44.73238 48.58184 41.54160 ## [9] 39.18036 49.18349 ## ## attr(,&quot;class&quot;) ## [1] &quot;Score&quot; class(My_Score2) # My_Score2のクラスを表示 ## [1] &quot;Score&quot; どれも同じ結果が得られます。 28.3.2 メソッドの作り方 28.3.2.1 既に存在する関数名を使う 先ほど作成しましたScoreクラスのオブジェクトは長さ2のリスト構造をしています。これらの要素それぞれの平均値を求める場合は、mean(My_Score1[[1]])とmean(My_Score1[[2]])を実行する必要があります。なぜなら、mean()はベクトルしか計算できないからです。ここではScoreクラスのオブジェクト要素それぞれの平均値を求める関数mean()を作成します。 しかし、問題があります。それはRにmean()関数が既に存在することです。ここで勝手に上書きするのは良くないでしょう。ここで出てくるのがメソッドです。Scoreクラスのメソッドは「Scoreクラス専用の関数」であり、通常のベクトルならR内蔵のmean()関数を、ScoreクラスのオブジェクトならScoreのメソッドであるmean()を実行します。 メソッドの作り方は自作関数と同じです。相違点としては関数名を関数名.クラス名にすることです。Scoreクラスのメソッドしてのmean()関数を定義する場合、関数名をmean.Scoreとします。 mean.Score &lt;- function(x) { print(mean(x$Score1)) print(mean(x$Score2)) } mean(c(1, 3, 5, 7, 9, 11)) # R内蔵関数のmean()を使う ## [1] 6 mean(My_Score1) # Scoreクラスのメソッドであるmean()を使う ## [1] 51.99222 ## [1] 46.18249 mean(c(1, 3, 5, 7, 9, 11))は引数がnumeric型ベクトルであるため、既存のmean()関数が使用されます。一方、mean(My_Score1)は引数がScoreクラスであるため、mean.Score()が使用されます。このようにmean_Score()のような別途の関数を作る必要なく、既存の関数名が利用できます。実際、methods(mean)を実行すると、Scoreクラスのメソッドとしてmean()関数が用意されたことを確認できます。 methods(mean) ## [1] mean.Date mean.default mean.difftime mean.POSIXct ## [5] mean.POSIXlt mean.quosure* mean.Score mean.vctrs_vctr* ## see &#39;?methods&#39; for accessing help and source code 28.3.2.2 新しい関数を作る もし、新しい関数名を使用し、その関数が様々なクラスに対応するとしましょう。今回はCatというクラスを作ってみましょう。Catクラスの内部は長さ1のリストで、要素の名前はNameとし、ここには長さ1のcharacter型ベクトルが入ります。このCatクラスを作成する関数をMake_Cat()とします。 Make_Cat &lt;- function(name) { # resultリストにxを格納 result &lt;- list(Name = name) structure(result, class = &quot;Cat&quot;) # resultを返す } My_Cat &lt;- Make_Cat(name = &quot;矢内&quot;) My_Cat ## $Name ## [1] &quot;矢内&quot; ## ## attr(,&quot;class&quot;) ## [1] &quot;Cat&quot; class(My_Cat) ## [1] &quot;Cat&quot; 続いて、Catクラスに使うmy_func()を作成します。my_func()はそもそも存在しない関数ですので、普通にmy_func &lt;- function()で作成可能です。この関数はCatのNameの後ろに\": にゃーにゃー\"を付けて出力する関数です。実際にやってみましょう。 my_func &lt;- function(name) { print(paste0(name$Name, &quot;: にゃーにゃー&quot;)) } my_func(My_Cat) ## [1] &quot;矢内: にゃーにゃー&quot; しかし、my_func()をCatクラス以外にも使いたい場合はどうすればいいでしょうか。普通にmy_func.クラス名()で良いでしょうか。確かにそうですが、その前に一つの手順が必要です。それは、my_func()をジェネリック関数として定義することです。この関数そのものは関数として機能はしませんが、「これからmy_func()がいろんなクラスのメソッドとして使われるぞ」と予め決めてくれます。ジェネリック関数を作成しないと関数名.クラス名は定義できません。そこで使うのがUseMethod()です。第一引数はメソッド名、第二引数は任意の引数ですが、通常、xが使われます。また、第二の引数は省略可能で、UseMethod(\"メソッド名\")でも動きます。 my_func &lt;- function(x) { UseMethod(&quot;my_func&quot;, x) } これからはmy_func.クラス名()の関数を作るだけです。まず、Score型オブジェクトに対してはそれぞれの要素の平均値を出力するとします。 my_func.Score &lt;- function(x) { print(mean(x$Score1)) print(mean(x$Score2)) } my_func.Cat &lt;- function(cat) { print(paste0(cat$Name, &quot;: にゃーにゃー&quot;)) } methods(my_func) ## [1] my_func.Cat my_func.Score ## see &#39;?methods&#39; for accessing help and source code my_func()関数はScoreとCatといった2種類のクラスで使われることが確認できます。それでは問題なく作動するかを確認してみましょう。My_Score1とMy_Catを、それぞれmy_func()に渡します。 my_func(My_Score1) ## [1] 51.99222 ## [1] 46.18249 my_func(My_Cat) ## [1] &quot;矢内: にゃーにゃー&quot; 同じ関数名でも、オブジェクトのクラスによって異なる処理が行われることが分かります。 28.3.3 検証用関数を作る この作業は必須ではありませんが、今後、自分でパッケージ等を作ることになったら重要になるかも知れません。 最初の例でもお見せしましたが、Rでは事後的にクラスを変更することができます。強制的にクラスを変更した場合、そのクラスに属するメソッドを使うことができますが、エラーが生じてしまうでしょう。例えば、任意のcharacter型ベクトルMy_Cat2を作成し、Catクラスを付与してみましょう。 My_Cat2 &lt;- &quot;宋&quot; class(My_Cat2) &lt;- &quot;Cat&quot; class(My_Cat2) ## [1] &quot;Cat&quot; My_Cat2のクラスはCatであるため、my_func.Cat()メソッドが使えます。しかし、my_func.Cat()仕組みを見る限り、うまく作動しないでしょう。 my_func(My_Cat2) ## Error: $ operator is invalid for atomic vectors 間違った動作をするよりは、エラーが出て中断される方が良いですし、これで問題ないかも知れません。しかし、可能であれば、引数として使われたオブジェクトが、Catクラスか否かを厳密にチェックする機能があれば良いでしょう。カプセル化されている場合、クラスの定義時にデータの構造が厳密に定義されているため、このような手続きの必要性はあまりありませんが、カプセル化ができないRのS3クラスでは検証用関数（Validator）が必要です。 それではCatクラスの特徴をいくつか考えてみましょう。 オブジェクトの中にはNameという要素のみがある。 Nameは長さ1のCharacter型ベクトルである。 以上の条件を全て満たしていればメソッドを実行し、一つでも満たさない場合はメソッドの実行を中止します。それでは検証用関数Validation_Cat()を作ってみましょう。 Validation_Cat &lt;- function(x) { Message &lt;- &quot;正しいCatクラスではありません。&quot; if (length(x) != 1) { stop(Message) } else if (is.null(names(x))) { stop(Message) } else if (names(x) != &quot;Name&quot;){ stop(Message) } else if (length(x$Name) != 1 | class(x$Name) != &quot;character&quot;) { stop(Message) } } この検証用関数をmy_func.Cat()の最初に入れておきましょう。 my_func.Cat &lt;- function(cat) { Validation_Cat(cat) print(paste0(cat$Name, &quot;: にゃーにゃー&quot;)) } それではMy_CatとMy_Cat2に対してmy_func()メソッドを実行してみます。 my_func(My_Cat) ## [1] &quot;矢内: にゃーにゃー&quot; my_func(My_Cat2) ## Error in Validation_Cat(cat): 正しいCatクラスではありません。 関数を実行する前に与えられたオブジェクトが正しいCatクラスか否かが判断され、パスされた場合のみ、メソッドが実行されることが分かります。もし、あるクラスで使用可能なメソッドが一つだけでしたら、検証用関数はメソッド内に直接書き込んでも良いですが、2つ以上のメソッドを持つ場合は別途の検証用関数を作成しておきましょう。 28.4 例題 ここでは2つのnumeric型ベクトルとそのベクトル名入力し、相関係数を求めるMy_Cor()関数を作ってみます。単に相関係数を求めるだけならcor()やcor.test()があるので、いくつかの機能も追加してみましょう。 たとえば、「1日当たりゲーム時間」と「身長」といった2つのnumeric型ベクトルをそれぞれxとyで入力し、x_nameとy_nameで各ベクトルの名前も指定します。また、入力されたデータを用いて相関係数とその信頼区間を求めます。これらのデータはリスト型として格納されますが、クラスを\"My_Cor_Object\"とします。以下はその例です。 pacman::p_load(tidyverse) set.seed(19861008) Cor_Obj &lt;- My_Cor(x = rnorm(20, 2, 0.5), y = rnorm(20, 165, 6), x_name = &quot;1日当たりゲーム時間&quot;, y_name = &quot;身長&quot;) class(Cor_Obj) ## [1] &quot;My_Cor_Object&quot; このCor_Objの構造をstr()で確認してみます。 str(Cor_Obj) ## List of 4 ## $ data :&#39;data.frame&#39;: 20 obs. of 2 variables: ## ..$ x: num [1:20] 1.96 2.2 1.34 2.29 2.08 ... ## ..$ y: num [1:20] 165 159 155 158 164 ... ## $ var_name: chr [1:2] &quot;1日当たりゲーム時間&quot; &quot;身長&quot; ## $ cor : Named num 0.277 ## ..- attr(*, &quot;names&quot;)= chr &quot;cor&quot; ## $ cor_ci : num [1:2] -0.188 0.641 ## ..- attr(*, &quot;conf.level&quot;)= num 0.95 ## - attr(*, &quot;class&quot;)= chr &quot;My_Cor_Object&quot; Cor_Objには元のデータがデータフレームとして格納され（$data）、それぞれの変数名（$var_name）、相関係数（$cor）、相関係数の95%信頼区間（$cor_ci）がCor_Objの中に入っています。本質的にはリスト型のデータ構造ですが、クラス名がMy_Cor_Objectになっているだけです。 このMy_Cor_Objectクラスには3つのメソッド（専用関数）が用意されており、print()、summary()、plot()です。print()とsummary()は同じ関数で、xとyの平均値、そして相関係数と信頼区間を出力します。plot()は散布図と相関係数を出力します。実際の例を見てみましょう。 print(Cor_Obj) ## 1日当たりゲーム時間の平均値: 2.085 ## 身長の平均値: 164.001 ## 相関係数: 0.277 [-0.188, 0.641] summary(Cor_Obj) # summary()はprint()と同じ ## 1日当たりゲーム時間の平均値: 2.085 ## 身長の平均値: 164.001 ## 相関係数: 0.277 [-0.188, 0.641] plot(Cor_Obj) 既存のcor.test()で作成される\"htest\"クラスに比べ、\"My_Cor_Object\"クラスは各変数の平均値が名前と一緒に表示され、plot()で簡単に散布図が作成できる大変便利なクラスです。このMy_Cor_Objectクラスとそのメソッドの構造を図示したものが図28.2です。 図 28.2: クラスの構造 それでは一つずつ作っていきましょう。まずは、\"My_Cor_Object\"クラスのオブジェクトを作成するMy_Cor()関数からです。 My_Cor &lt;- function(x, y, x_name, y_name) { if (!is.numeric(x) | !is.numeric(y)) { stop(&quot;xまたはyがnumeric型ではありません。&quot;) } if (length(x) != length(y)) { stop(&quot;xとyは同じ長さでなかればなりません。&quot;) } if (!is.character(x_name) | !is.character(y_name)) { stop(&quot;x_nameまたはy_nameがcharacter型ではありません。&quot;) } data &lt;- data.frame(x = x, y = y) var_name &lt;- c(x_name, y_name) cor &lt;- cor.test(x, y)$estimate cor_ci &lt;- cor.test(x, y)$conf.int result &lt;- structure(list(data = data, var_name = var_name, cor = cor, cor_ci = cor_ci), class = &quot;My_Cor_Object&quot;) result } 最初の部分は入力されたデータがMy_Cor_Objectクラスに適した構造か否かを判断します。これは最初から想定外のMy_Cor_Objectクラスのオブジェクトが作成されることを防ぐことが目的です。むろん、R（S3）の性質上、事後的にクラスを変更することが可能ですから、検証用関数も作っておきます。ここでは以下の条件を検証します。 dataという要素が存在し、2列である。 var_nameという要素が存在し、長さ2のcharacter型ベクトルである。 corという要素が存在し、長さ1のnumeric型ベクトルである。 cor_ciという要素が存在し、長さ2のnumeric型ベクトルである。 Validation &lt;- function (x) { UseMethod(&quot;Validation&quot;, x) } Validation.My_Cor_Object &lt;- function(x) { Message &lt;- &quot;正しいMy_Cor_Objectクラスではございません。&quot; if (is.null(x$data) | ncol(x$data) != 2) { stop(Message) } if (is.null(x$var_name) | length(x$var_name) != 2 | class(x$var_name) != &quot;character&quot;) { stop(Message) } if (is.null(x$cor) | length(x$cor) != 1 | class(x$cor) != &quot;numeric&quot;) { stop(Message) } if (is.null(x$cor_ci) | length(x$cor_ci) != 2 | class(x$cor_ci) != &quot;numeric&quot;) { stop(Message) } } ここではValidation()をジェネリック関数として使用しました。自分が開発するパッケージで複数のクラスを提供する予定でしたら、このようなやり方が良いでしょう。 検証用関数は細かく書いた方が良いです。以上のValidation()もより細かくことが出来ます。たとえば、dataが2列か否かを判定するだけでなく、numeric型であるかなども判定した方が良いでしょう。 つづいて、My_Cor_Objectクラス用のprint()関数（メソッド）を作成します。 print.My_Cor_Object &lt;- function(data) { Valdation(data) cat(sprintf(&quot;%sの平均値: %.3f\\n&quot;, data$var_name[1], mean(data$data$x))) cat(sprintf(&quot;%sの平均値: %.3f\\n&quot;, data$var_name[2], mean(data$data$y))) cat(sprintf(&quot;相関係数: %.3f [%.3f, %.3f]\\n&quot;, data$cor, data$cor_ci[1], data$cor_ci[2])) } 次は、summary()メソッドですが、これはprint()と同じ機能をする関数です。この場合、UseMethod(\"メソッド名\")を使うと、指定したメソッドを使うことになります。 summary.My_Cor_Object &lt;- function(data) { UseMethod(&quot;print&quot;) } 最後はplot()メソッドです。 plot.My_Cor_Object &lt;- function(data) { Valdation(data) data$data %&gt;% ggplot(aes(x = x, y = y)) + geom_point() + labs(x = data$var_name[1], y = data$var_name[2]) + ggtitle(sprintf(&quot;相関係数 = %.3f&quot;, data[[&quot;cor&quot;]])) + theme_minimal(base_size = 12) } これで相関係数の計算および可視化が便利になる関数群が完成しました。Rパッケージの開発はこれよりも数倍も複雑ですが、本記事の内容はプログラミングをより効率的に行うための入り口となります。 "],["monte.html", "29. モンテカルロシミュレーション 29.1 モンテカルロシミュレーションとは 29.2 乱数生成 29.3 例1: 誕生日問題 29.4 例2: モンティ・ホール問題 29.5 例3: 円周率の計算 29.6 例4: ブートストラップ法", " 29. モンテカルロシミュレーション 29.1 モンテカルロシミュレーションとは pacman::p_load(tidyverse, ggforce) モンテカルロ法 (Monte Carlo method)とは無作為に抽出された乱数を用い、数値計算やシミュレーションを行う手法を意味します。モンテカルロはヨーロッパのモナコ公国内の一つの地区であり、カジノで有名なところです。カジノではサイコロやルーレット、無作為に配られたカードなど、乱数が頻繁に使われることからこのように名付けられました。 モンテカルロ法を用いたシミュレーションがモンテカルロ・シミュレーションです。計算があまりにも複雑だったり、実質的に代数で解が得られない解析学上の問題などに強みを持つ手法です。一部、明快な例（共役事前分布が存在するなど）を除き、事後分布の計算が非常に複雑（実質、不可能）だと知られていたベイズ統計学もモンテカルロ法（マルコフ連鎖モンテカルロ法; MCMC）によって、ようやく使えるものになったなど、今になってモンテカルロ法は非常に広く用いられています。 モンテカルロ法から得られた結果には常に誤差が存在します。とりわけ、生成された乱数が少ない（= 試行回数が少ない）場合、この誤差は大きくなります。しかし、近年はパソコンの性能が飛躍的に発達しているため、かなり小さな誤差で、つまりより正確な結果が得られるようになりました。 以下ではまず、モンテカルロ法を理解するために必須知識である乱数生成について解説します。具体的には乱数生成のアルゴリズムでなく、Rで乱数を生成する方法について紹介します。続いて、モンテカルロ法を用いたシミュレーションの例として誕生日問題、モンティ・ホール問題、円周率の計算、ブートストラップ法を紹介します。 29.2 乱数生成 29.2.1 sample()によるサンプリング 無作為に値を抽出する方法には2つが考えられます。一つは値の集合から無作為に値を抽出する方法、もう一つは正規分布などの確率分布から値を抽出する方法です。ここではまずsample()関数を用い、値の集合から無作為に値を抽出する方法について説明します。 sample(x = 値の集合ベクトル, size = 抽出の回数, replace = 復元抽出の有無, prob = 各要素が抽出される確率) replaceは復元抽出の有無を指定する引数であり、既定値はFALSE、つまり非復元抽出がデフォルトとなっています。これは一度抽出された要素は、二度と抽出されないことを意味します。値の集合が{0, 1}で、5個の値を抽出する（=sizeがxの長さより大きい）ならば、replaceは必ずTRUEに設定する必要があります。抽選などは非復元抽出であるため、replace引数は省略可能です。しかし、対数の法則やブートストラップなどは復元抽出を仮定している場合が多く、意識的にreplace関数は指定することを推奨します。probは各要素が抽出される確率を意味し、xの実引数と同じ長さのnumeric型ベクトルを指定します。probの実引数の総和は1であることが望ましいですが、総和が1でない場合、自動的に総和が1になるよう正則化を行います。つまり、c(1, 3)はc(0.25, 0.75)と同じことを意味します。 サイコロを3回振るコードを書くなら、値の集合（x）はc(1, 2, 3, 4, 5, 6)、または1:6で、抽出の回数（size）は3となります。また、一回出た目も抽出される可能性があるため、復元抽出を行う必要があります（replace = TRUE）。そして各目が出る確率は1/6ですが、各値が抽出される確率が等しい場合、省略可能です。 # この場合、prob引数は省略可能 sample(1:6, 3, replace = TRUE, prob = rep(1/6, 6)) ## [1] 4 3 6 今回はサイコロを1万回振り、それぞれの目が出た回数を棒グラフとして示してみます。無作為に抽出された値であれば、各目が出る回数は等しいはずです。ベクトルに対してtable()関数を使うと、各要素が出現した回数が出力され、このオブジェクトをbarplot()関数に渡すと棒グラフを作成することができます。 Dice_vec &lt;- sample(1:6, 10^4, replace = TRUE) table(Dice_vec) %&gt;% barplot() 1から6までの目が出た回数がほぼ同じであることが確認できます。この6つの棒の高さがすべて同じになることはありえませんが（そもそも1万を6で割ったら余りが出ますね）、ほぼ同じ割合であることから、疑似乱数とは言え、シミュレーション用としては十分でしょう。 29.2.2 確率分布からの乱数制制 関数名 確率分布 パラメーター rbeta() ベータ分布 n, shape1, shape2 rbinom() 二項分布 n, size, prob rcauchy() コーシー分布 n, location, scale rchisq() \\(\\chi^2\\)分布 n, df rexp() 指数分布 n, rate rf() \\(F\\)分布 n, df1, df2 rgamma() ガンマ分布 n, shape, scale rgeom() 幾何分布 n, prob rhyper() 超幾何分布 nn, m, n, k rlnorm() 対数正規分布 n, meanlog, sdlog rmultinom() 多項分布 n, size, prob rnbinom() 負の二項分布 n, size, prob rnorm() 正規分布 n, mean, sd rpois() ポアソン分布 n, lambda rt() t分布 n, df runif() 一様分布 n, min, max rweibull() ワイブル分布 n, shape, scale mvtnorm::rmvnorm() 多変量正規分布 n, mean, sigma 以上の表に掲載されているパラメーター以外にも指定可能なパラメーターがあるため、詳細は各関数のヘルプを参照してください。たとえば、ガンマ分布の場合、rateで、負の二項分布の場合、muで分布の形状を指定することができます。また、多変量正規分布の乱数を抽出するには{mvtnorm}パッケージのrmvnorm()を使いますが、ここでのmeanは数値型ベクトル、sigmaは行列構造の分散共分散行列を使います111。 29.2.3 シードについて 特定の分布から乱数を抽出する場合、当たり前ですが、抽出の度に値が変わります。たとえば、平均0、標準偏差1の正規分布（標準正規分布）から5つの値を抽出し、小数点3桁に丸める作業を3回繰り返しみましょう。 rnorm(5) %&gt;% round(3) ## [1] 2.174 -0.054 -0.710 0.497 -0.155 rnorm(5) %&gt;% round(3) ## [1] 0.783 0.067 -1.943 0.298 -1.226 rnorm(5) %&gt;% round(3) ## [1] 0.653 0.658 0.665 1.406 0.954 このように、抽出の度に結果が変わります。1回きりのシミュレーションではこれで問題ないでしょうが、同じシミュレーションから同じ結果を得るためには、乱数を固定する必要があります。そこで使うのがシード（seed）です。シードが同じなら抽出される乱数は同じ値を取ります。シードの指定はset.seed(numeric型スカラー)です。たとえば、シードを19861008にし、同じ作業をやってみましょう。 set.seed(19861008) rnorm(5) %&gt;% round(3) ## [1] -0.086 0.396 -1.330 0.574 0.152 rnorm(5) %&gt;% round(3) ## [1] 0.555 0.620 -1.133 0.572 0.900 シードを指定しても2つのベクトルは異なる値を取りますが、もう一度シードを指定してから乱数抽出をしてみましょう。 set.seed(19861008) rnorm(5) %&gt;% round(3) ## [1] -0.086 0.396 -1.330 0.574 0.152 先ほどのコードでシードを指定した直後に抽出した乱数と同じ乱数が得られました。モンテカルロ・シミュレーションにおいて乱数は非常に重要ですが、これはシミュレーションの度に異なる結果が得られることを意味します。つまり、自分が書いたコードから100%同じ結果が得られないだけでなく、自分も同じ結果を再現できないことを意味します。この場合、シードを指定すると乱数が固定され、シミュレーション結果の再現ができるようになります。 一つ注意すべき点は乱数を固定した後、複数回抽出を繰り返す場合、その順番も固定されるという点です。たとえば、シードを固定せずにもう一回5つの値を抽出してみましょう。 rnorm(5) %&gt;% round(3) ## [1] 0.555 0.620 -1.133 0.572 0.900 この結果は先ほどシード指定後、2回目の抽出結果と同じ結果となります。結果を再現するという点では大きな問題はないはずですが、仕様を理解しておくことは重要でしょう。 29.3 例1: 誕生日問題 まず簡単な例として誕生日問題 (birthday problem)をシミュレーションで確認してみましょう。誕生日問題とは「何人いれば、その中に誕生日が同じ2人以上がいる確率が50%を超えるか。」といった問題です。1年を365日で考えると（2月29日生まれの皆さん、すみません…）、366人がいれば確実に (= 100%)同じ誕生日の人が2人以上いることになりますね。100%でなく、50%まで基準を下げるならその半分である183人は必要じゃないかと思うかも知れません。しかし、実はたった23人が集まれば、その中で同じ誕生日の人が2人以上いる確率が50%になります。誕生日のパラドックスとも呼ばれるものですが、これをシミュレーションで確認してたいと思います。 学生の数をn_studentとし、1から365までの公差1の等差数列から、n_student個の値を復元抽出します。 n_student &lt;- 30 # 学生数 # 「1から365までの公差1の等差数列」からn_student個の値を復元抽出 Birth_vec &lt;- sample(1:365, n_student, replace = TRUE) Birth_vec ## [1] 340 122 230 148 12 136 87 46 16 310 104 351 137 53 361 65 106 361 108 ## [20] 281 299 67 342 4 338 88 156 254 192 37 このベクトルの中で重複する要素があるかどうかを確認するにはduplicated()関数を使います。ある要素が他の要素と重複するならTRUEが、なければFALSEが表示されます。 duplicated(Birth_vec) ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [13] FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE ## [25] FALSE FALSE FALSE FALSE FALSE FALSE ただし、一つでもTRUEが含まれていれば、同じ誕生日の人が二人以上はいるということとなるので、更にany()関数を使います。any()内の条件文において、一つでもTRUEがあれば返り値はTRUEとなり、全てFALSEならFALSEを返す関数です。 any(duplicated(Birth_vec)) ## [1] TRUE 以上の作業を100回繰り返す場合、試行回数が100回となります。この場合、TRUEの結果が出る試行は何回でしょうか。 n_student &lt;- 10 # 学生数 n_trials &lt;- 100 # 試行回数 # 結果を格納する空ベクトルを用意する Result_vec &lt;- rep(NA, n_trials) # 反復処理 for (i in 1:n_trials) { Birth_vec &lt;- sample(1:365, n_student, replace = TRUE) Result_vec[i] &lt;- any(duplicated(Birth_vec)) } Result_vec ## [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE ## [13] FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE TRUE FALSE FALSE FALSE ## [25] FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [37] FALSE FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE TRUE FALSE FALSE ## [49] FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [61] FALSE FALSE FALSE FALSE FALSE FALSE TRUE TRUE FALSE FALSE FALSE FALSE ## [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [85] FALSE FALSE FALSE TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE ## [97] FALSE FALSE FALSE FALSE 100回の試行の中でTRUEが出たのは10回ですね。割合で考えると10%です。この試行回数を無限にすると確率として解釈できますが、無限回繰り返しは世の中が終わるまでやっても終わりませんね。ただし、十分に多い試行回数、たとえば1万回程度繰り返すと確率に近似できるでしょう。 n_student &lt;- 10 # 学生数 n_trials &lt;- 10000 # 試行回数 # 結果を格納する空ベクトルを用意する Result_vec &lt;- rep(NA, n_trials) # 反復処理 for (i in 1:n_trials) { Birth_vec &lt;- sample(1:365, n_student, replace = TRUE) Result_vec[i] &lt;- any(duplicated(Birth_vec)) } sum(Result_vec) ## [1] 1147 1万回の試行からTRUEが出た回数は1147回であり、11.5%ですね。つまり、人が10人集まれば誕生日が同じ人が2人以上いる確率は約11.5%ということになります。実はこの確率は厳密に計算可能であり、理論的な確率は約11.7%です。シミュレーションから得られた結果が理論値にかなり近似していることが分かります。 今回は試行回数は100に固定し、学生数を2から100まで調整しながら同じ誕生日の人が2人以上いる割合を計算してみましょう。以下では割合を計算する関数Birthday_Func()を作成し、{purrr}のmap_dbl()関数を使用して反復処理を行います。関数の作成は第11章を、{purrr}の使い方については第27章を参照してください。 # 割合を計算する関数を作成する Birthday_Func &lt;- function (n, n_trials) { # 各試行の結果を格納する空ベクトルを用意する。 Result_vec &lt;- rep(NA, n_trials) # n_trials回だけ{}内コードを繰り返す。 for (i in 1:n_trials) { # 1:365からn個の値を復元抽出 Birth_vec &lt;- sample(1:365, n, replace = TRUE) # 重複する要素があるかをチェックし、結果ベクトルのi番目に格納 Result_vec[i] &lt;- any(duplicated(Birth_vec)) } # 各試行結果が格納されたベクトルからTRUEの割合を返す mean(Result_vec) } # 学生数をStudents列に格納したデータフレーム (tibble)を作成 Prob_df &lt;- tibble(Students = 2:100) # Students列の値に応じてBirthday_Func()を実行 Prob_df &lt;- Prob_df %&gt;% mutate(Probs = map_dbl(Students, ~Birthday_Func(.x, 100))) {purrr}関数を使わずに、for()文を使用した例は以下のようになります。 # {purrr}を使わない方法 Prob_df &lt;- tibble(Students = 2:100, Probs = NA) for (i in 1:nrow(Prob_df)) { Result_vec &lt;- rep(NA, n_trials) for (j in 1:n_trials) { Birth_vec &lt;- sample(1:365, Prob_df$Students[i], replace = TRUE) Result_vec[j] &lt;- any(duplicated(Birth_vec)) } Prob_df$Probs[i] &lt;- mean(Result_vec) } 結果を確認してみましょう。 Prob_df ## # A tibble: 99 × 2 ## Students Probs ## &lt;int&gt; &lt;dbl&gt; ## 1 2 0.01 ## 2 3 0.02 ## 3 4 0.06 ## 4 5 0.01 ## 5 6 0.02 ## 6 7 0.08 ## 7 8 0.06 ## 8 9 0.09 ## 9 10 0.12 ## 10 11 0.18 ## # … with 89 more rows 学生数が何人いれば、同じ誕生日の人が2人以上いる割合が50%になるのでしょうか。割合が0.4以上、0.6以下の行を抽出してみましょう。 Prob_df %&gt;% filter(Probs &gt;= 0.4 &amp; Probs &lt;= 0.6) ## # A tibble: 7 × 2 ## Students Probs ## &lt;int&gt; &lt;dbl&gt; ## 1 18 0.41 ## 2 21 0.46 ## 3 22 0.41 ## 4 23 0.45 ## 5 24 0.52 ## 6 25 0.58 ## 7 27 0.56 大体23人前後ですかね。試行回数を増やせばもう少し厳密に検証出来るかも知れませんが、とりあえず以上の結果を可視化してみましょう。 Prob_df %&gt;% ggplot() + geom_line(aes(x = Students, y = Probs * 100), size = 1) + geom_hline(yintercept = 50, color = &quot;red&quot;, linetype = 2) + labs(x = &quot;学生数&quot;, y = &quot;同じ誕生日の人が2人以上いる割合 (%)\\n(試行回数 = 100)&quot;) + theme_bw(base_size = 12) 非常に直感に反する結果かも知れませんが、50人程度いれば、ほぼ確実に同じ誕生日の人が2人以上いることが分かります。この誕生日問題は以下のように解くことができます。人が\\(n\\)人いる場合、同じ誕生日の人が2人以上いる確率\\(p(n)\\)は、 \\[ p(n) = 1 - \\frac{365!}{365^n (365-n)!} \\] !は階乗を意味し、5!は\\(5 \\times 4 \\times 3 \\times 2 \\times 1\\)を意味します。Rではfactorial()関数を使います。それでは\\(p(50)\\)はいくらでしょうか。 1 - factorial(365) / (365^50 * factorial(365 - 50)) ## [1] NaN あらら、NaNがでましたね。つまり、計算不可です。実際、factorial(365)だけでも計算結果はInfが出ます。むろん、実際に無限ではありませんが、非常に大きい数値ということです。以上の式を計算可能な式に変形すると以下のようになります。 \\[ p(n) = 1 - \\frac{n! \\times _{365}C_n}{365^n} \\] \\(C\\)は二項係数を意味し\\(_nC_k\\)は\\(\\frac{n!}{k!(n-k)!}\\)です。Rではchoose(n, k)で計算可能です。 1 - ((factorial(50) * choose(365, 50)) / 365^50) ## [1] 0.9703736 結果は0.9703736です。つまり、人が50人いれば同じ誕生日の人が2人以上いる確率は約97%ということです。それでは、以上の式を関数化し、p(22)とp(23)を計算してみましょう。 Birth_Expect &lt;- function (n) { 1 - ((factorial(n) * choose(365, n)) / 365^n) } Birth_Expect(22) ## [1] 0.4756953 Birth_Expect(23) ## [1] 0.5072972 確率が50%を超える人数は23人であることが分かります。先ほどのデータフレーム (Prob_df)にこの理論値をExpectという名の列として追加してみましょう。 Prob_df &lt;- Prob_df %&gt;% mutate(Expect = map_dbl(Students, ~Birth_Expect(.x))) Prob_df ## # A tibble: 99 × 3 ## Students Probs Expect ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 0.01 0.00274 ## 2 3 0.02 0.00820 ## 3 4 0.06 0.0164 ## 4 5 0.01 0.0271 ## 5 6 0.02 0.0405 ## 6 7 0.08 0.0562 ## 7 8 0.06 0.0743 ## 8 9 0.09 0.0946 ## 9 10 0.12 0.117 ## 10 11 0.18 0.141 ## # … with 89 more rows これは人間にとっては読みやすい表ですが、可視化まで考えると、tidyなデータといは言えません。したがって、pivot_longer()関数を使用してtidyなデータに整形します。{tidyr}パッケージの使い方は第15章を参照してください。 Prob_df2 &lt;- Prob_df %&gt;% pivot_longer(cols = Probs:Expect, names_to = &quot;Type&quot;, values_to = &quot;Prob&quot;) Prob_df2 ## # A tibble: 198 × 3 ## Students Type Prob ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2 Probs 0.01 ## 2 2 Expect 0.00274 ## 3 3 Probs 0.02 ## 4 3 Expect 0.00820 ## 5 4 Probs 0.06 ## 6 4 Expect 0.0164 ## 7 5 Probs 0.01 ## 8 5 Expect 0.0271 ## 9 6 Probs 0.02 ## 10 6 Expect 0.0405 ## # … with 188 more rows こちらのデータを使用し、シミュレーションから得られた結果と理論値を折れ線グラフで出力してみましょう。 Prob_df2 %&gt;% mutate(Type = ifelse(Type == &quot;Probs&quot;, &quot;シミュレーション&quot;, &quot;理論値&quot;)) %&gt;% ggplot() + geom_line(aes(x = Students, y = Prob * 100, color = Type), size = 1) + labs(x = &quot;学生数&quot;, y = &quot;同じ誕生日の人が2人以上いる割合 (%)\\n(試行回数 = 100)&quot;, color = &quot;&quot;) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) 最後に以上の作業を試行回数10000としてもう一回やってみましょう。 # 学生数をStudents列に格納したデータフレーム (tibble)を作成 Prob_df &lt;- tibble(Students = 2:100) # Students列の値に応じてBirthday_Func()を実行 Prob_df &lt;- Prob_df %&gt;% mutate(Simul = map_dbl(Students, ~Birthday_Func(.x, 10000)), Expect = map_dbl(Students, ~Birth_Expect(.x))) Prob_df %&gt;% pivot_longer(cols = Simul:Expect, names_to = &quot;Type&quot;, values_to = &quot;Prob&quot;) %&gt;% mutate(Type = ifelse(Type == &quot;Simul&quot;, &quot;シミュレーション&quot;, &quot;理論値&quot;)) %&gt;% ggplot() + geom_line(aes(x = Students, y = Prob * 100, color = Type), size = 1) + labs(x = &quot;学生数&quot;, y = &quot;同じ誕生日の人が2人以上いる割合 (%)\\n(試行回数 = 100)&quot;, color = &quot;&quot;) + theme_bw(base_size = 12) + theme(legend.position = &quot;bottom&quot;) モンテカルロ・シミュレーションから得られた割合と理論上の確率が非常に近似していることが分かります。 29.4 例2: モンティ・ホール問題 抽出される乱数が必ずしも数値である必要はありません。たとえば、コイン投げの表と裏、ポーカーで配られたカードなど、数値以外の乱数もあり得ます。ここでは「AとB、C」から一つを選ぶ例として、モンティ・ホール問題をモンテカルロ法で解いてみましょう。 モンティ・ホール問題はアメリカのテレビ番組「Let’s make a deal」の中のゲームであり、この番組の司会者の名前がモンティ・ホール (Monty Hall)さんです。このゲームのルールは非常にシンプルです。 3つのドアがあり、1つのドアの裏に商品 (車)がある。残りの2つは外れ（ヤギ）である。 参加者はドアを選択する。 司会者が残りのドア2つの中で商品がないドアを開けて中身を見せる。 ここで参加者はドアの選択を変える機会が与えられる。 直観的に考えて、司会者が外れのドアを1つ教えてくれたなら、自分が選んだドアを含め、残りの2つのドアの1つに絶対に商品があります。直感的に考えてみると、当たる確率は半々であって、変えても、変えなくても当たる確率は同じだと考えられます。詳細はWikipediaなどを参照してください。この問題を巡る論争とかも紹介されていてなかなか面白いです。 結論から申しますと選択を変えた方が、変えなかった場合より当たる確率が2倍になります。これは条件付き確率とベイズの定理を用いることで数学的に説明できますが、ここではあえてモンテカルロ法で調べてみたいと思います。シミュレーションの具体的な手順は以下の通りです。 結果を格納する長さ1万の空ベクトルを2つ用意する。 (Switch_YesとSwitch_No)。 iの初期値を1とする。 当たり (車)の位置をA, B, Cの中から無作為に1つ決め、Car_Positionに格納する。 最初の選択肢をA, B, Cの中から無作為に1つ決め、Choiceに格納する。 選択肢を変更した場合の結果をSwitch_Yesのi番目の要素としてに格納する。 当たりの位置と最初の選択肢が同じなら (Switch_Yes == Choice)、結果は外れ (ヤギ) 当たりの位置と最初の選択肢が同じでないなら (Switch_Yes != Choice)、結果は当たり (車) 選択肢を変更しなかった場合の結果をSwitch_Noのi番目の要素として格納する。 当たりの位置と最初の選択肢が同じなら (Switch_Yes == Choice)、結果は当たり (車) 当たりの位置と最初の選択肢が同じでないなら (Switch_Yes != Choice)、結果は外れ (ヤギ) iの値を1増やし、3に戻る。 3〜7の手順を1万回繰り返す。 以上の手順をコードで書くと以下のようになります。 Switch_Yes &lt;- rep(NA, 10000) Switch_No &lt;- rep(NA, 10000) set.seed(19861009) for (i in 1:10000) { Car_Position &lt;- sample(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), 1) Choice &lt;- sample(c(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;), 1) Switch_Yes[i] &lt;- ifelse(Car_Position == Choice, &quot;Goat&quot;, &quot;Car&quot;) Switch_No[i] &lt;- ifelse(Car_Position == Choice, &quot;Car&quot;, &quot;Goat&quot;) } table(Switch_Yes) ## Switch_Yes ## Car Goat ## 6737 3263 table(Switch_No) ## Switch_No ## Car Goat ## 3263 6737 選択肢を変更し、車を獲得した回数は10000回中、6737であり、約67%です。つまり、選択肢を変えた方が、変えなかった場合に比べ、車が当たる確率が約2倍高いことを意味します。むろん、車よりもヤギが重宝される地域に住んでいるなら、あえて選択肢を変えず、ヤギを狙った方が良いかも知れません。 29.5 例3: 円周率の計算 今回はもう一つの例として、円周率 (\\(\\pi\\))の計算を紹介したいと思います。\\(\\pi\\)は無理数であるため、厳密な計算は出来ませんが、モンテカルロ・シミュレーションである程度近似できます。たとえば、半径1 (\\(r = 1\\))の円を考えてみましょう。 円の面積は\\(r^2\\pi\\)であるため、この円の面積は\\(\\pi\\)です。また、四角形は辺の長さが2の正四角形ですから面積は4です。続いて、四角形の範囲内の点を付けます。無作為に20個を付けてみます。 20個点のうち、円の外側にあるのは5個、円の内側は15個です。つまり、75%の点が円内にあることを意味します。点の位置は無作為ですので、もし円の大きさが\\(\\pi\\)であれば、点が円内に入る確率は\\(\\frac{\\pi}{4}\\)です。今回の例だと\\(\\frac{\\pi}{4} = 0.75\\)であるため、\\(\\pi = 0.75 \\times 4 = 3\\)となります。実際の円周率は3.141593…なので、そこそこ近似できていますね。 それではこれを実際にやってみましょう。今回は20個の点ではなく、100個にしてみましょう。まず、100個の点を無作為に抽出します。 set.seed(19861009) pi_df &lt;- tibble(x = runif(100, -1, 1), y = runif(100, -1, 1)) pi_df ## # A tibble: 100 × 2 ## x y ## &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.950 -0.344 ## 2 0.0724 0.150 ## 3 0.874 0.971 ## 4 0.938 0.267 ## 5 0.205 0.469 ## 6 -0.343 -0.590 ## 7 -0.0245 -0.635 ## 8 -0.273 -0.886 ## 9 -0.405 0.701 ## 10 0.528 -0.547 ## # … with 90 more rows まず、各辺の長さが2の正四角形とpi_dfで生成した100個の点をプロットします。四角形を描くときにはgeom_rect()幾何オブジェクトを使用します。マッピングは四角形の左下の座標 (xminとymin)、右上の座標 (xmaxとymax)に行います。今回は原点が (0, 0)の半径1の円に接する四角形ですから、左下の座標は (-1, -1)、右上の座標は (1, 1)となります。 pi_df %&gt;% ggplot() + geom_rect(aes(xmin = -1, ymin = -1, xmax = 1, ymax = 1), fill = &quot;white&quot;, color = &quot;black&quot;) + geom_point(aes(x = x, y = y)) + coord_fixed(ratio = 1) + theme_minimal() ここに円を追加してみましょう。円を描くときには{ggforce}パッケージのgeom_circle()幾何オブジェクトを使用します。マッピングは円の原点 (x0とy0)、円の半径 (r)です。原点は (0, 0)で半径は1の円を重ねます。 pi_df %&gt;% ggplot() + geom_rect(aes(xmin = -1, ymin = -1, xmax = 1, ymax = 1), fill = &quot;white&quot;, color = &quot;black&quot;) + geom_circle(aes(x0 = 0, y0 = 0, r = 1)) + geom_point(aes(x = x, y = y)) + coord_fixed(ratio = 1) + theme_minimal() これだけだと読みづらいので、円の中か外かで点の色分けをしてみましょう。そのためには各点が円内に入っているかどうかを判定した変数in_circleを追加します。点(\\(x\\), \\(y\\))が、原点が(\\(x^\\prime\\), \\(y^\\prime\\))、かつ半径\\(r\\)の円内に入っている場合、\\((x - x^\\prime)^2 + (y - y^\\prime)^2 &lt; r^2\\)が成立します。今回は原点が (0, 0)で、半径が1であるため、\\(x^2 + y^2 &lt; 1\\)か否かを判定します。この条件を満たしているかどうかを示すin_circleという変数を追加します。 pi_df &lt;- pi_df %&gt;% mutate(in_circle = if_else(x^2 + y^2 &lt; 1^2, &quot;円内&quot;, &quot;円外&quot;)) 散布図レイヤー (geom_point())内にcolorをin_circle変数でマッピングします。 pi_df %&gt;% ggplot() + geom_rect(aes(xmin = -1, ymin = -1, xmax = 1, ymax = 1), fill = &quot;white&quot;, color = &quot;black&quot;) + # 円の内側か外側かで色分け geom_point(aes(x = x, y = y, color = in_circle), size = 2) + geom_circle(aes(x0 = 0, y0 = 0, r = 1)) + labs(x = &quot;X&quot;, y = &quot;Y&quot;, color = &quot;&quot;) + coord_fixed(ratio = 1) + theme_void(base_size = 12) 実際に円内の点と円外の点の個数を数えてみましょう。 pi_df %&gt;% group_by(in_circle) %&gt;% summarise(N = n()) ## # A tibble: 2 × 2 ## in_circle N ## &lt;chr&gt; &lt;int&gt; ## 1 円内 82 ## 2 円外 18 円内の点は82個、円外の点は18ですね。つまり、\\(\\frac{\\pi}{4} = 0.82\\)であり、\\(\\pi = 0.82 \\times 4 = 3.28\\)です。 82 / 100 * 4 ## [1] 3.28 今回は100個の点で円周率の近似値を計算しましたが、点の数を増やすとより正確な近似値が得られます。以下の例は10000個の点から得られた円周率の例です。 set.seed(19861009) pi_df2 &lt;- tibble(x = runif(5000, -1, 1), y = runif(5000, -1, 1)) pi_df2 &lt;- pi_df2 %&gt;% mutate(in_circle = if_else(x^2 + y^2 &lt; 1, &quot;円内&quot;, &quot;円外&quot;)) pi_df2 %&gt;% ggplot() + geom_rect(aes(xmin = -1, ymin = -1, xmax = 1, ymax = 1), fill = &quot;white&quot;, color = &quot;black&quot;) + geom_point(aes(x = x, y = y, color = in_circle), size = 2) + geom_circle(aes(x0 = 0, y0 = 0, r = 1)) + labs(x = &quot;X&quot;, y = &quot;Y&quot;, color = &quot;&quot;) + coord_fixed(ratio = 1) + theme_void(base_size = 12) pi_df2 %&gt;% group_by(in_circle) %&gt;% summarise(N = n()) ## # A tibble: 2 × 2 ## in_circle N ## &lt;chr&gt; &lt;int&gt; ## 1 円外 1081 ## 2 円内 3919 円内の点は3919個、円外の点は1081ですね。この結果から円周率を計算してみましょう。 3919 / 5000 * 4 ## [1] 3.1352 より実際の円周率に近い値が得られました。 29.6 例4: ブートストラップ法 最後に、様々な分析から得られた統計量の不確実性を計算する方法の一つであるブートストラップ法 (bootstrapping)について説明します。たとえば、平均値の差分の検定 (t検定)差、回帰分析における標準誤差などはRのt.test()、lm()関数を使用すれば瞬時に計算できます。こちらの標準誤差はデータを与えられれば、常に同じ値が得られるもので、何らかの計算式があります。しかし、世の中にはモデルが複雑すぎて、統計量の標準誤差がうまく計算できないケースもあります。そこで登場するのがブートストラップ法を用いると、不確実性の近似値が得られます。ブートストラップ法は Efron (1979) が提案した以来、データ分析において広く使われています。ブートストラップ法については優れた教科書が多くあるので詳細な説明は割愛し、以下ではブートストラップ法の簡単な例を紹介します。 ブートストラップにおいて重要なのは元のデータセットのサンプルサイズを\\(n\\)とした場合、復元抽出を用いてサンプルサイズ\\(n\\)のデータセットをもう一度構築することです。そしてその平均値を計算します。これらの手順を5000回繰り返せば、5000個の平均値が得られます。この5000個の平均値の平均値は元のデータセットの平均値に近似し、5000個の平均値の標準偏差は元のデータセットの平均値の標準誤差 (標準誤差)に近似できます。これは本当でしょうか。実際にやってみましょう。 まずは、長さ100のベクトルを2つ作成します。この2つのベクトルは平均値が0.7、0.9、標準偏差1の正規分布に従うとします。 \\[ \\begin{aligned} \\mbox{Data1} &amp; \\sim \\mbox{Normal}(\\mu = 0.7, \\sigma = 1) \\\\ \\mbox{Data2} &amp; \\sim \\mbox{Normal}(\\mu = 0.9, \\sigma = 1) \\end{aligned} \\] 2つの標本の平均値の差分は約0.2です。この差分の不確実性はいくらでしょうか。ここでは主に使われる平均値の差の検定 (\\(t\\)検定)をやってみましょう。回は標準誤差が同じ2つの分布から得られた標本であるため、等分散を仮定する\\(t\\)検定を行います (var.equal = TRUEを追加)。 set.seed(19861009) Data1 &lt;- rnorm(100, 0.7, 1) Data2 &lt;- rnorm(100, 0.9, 1) ttest_result &lt;- t.test(Data1, Data2, var.equal = TRUE) ttest_result ## ## Two Sample t-test ## ## data: Data1 and Data2 ## t = -2.1707, df = 198, p-value = 0.03114 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -0.58521800 -0.02807095 ## sample estimates: ## mean of x mean of y ## 0.6912143 0.9978588 平均値の差分の不確実性 (=標準誤差)はttest_result$stderrで抽出可能であり、今回は約0.141です。標準誤差の値さえ分かれば、検定統計量も、信頼区間も、\\(p\\)値も計算できるため、重要なのはやはり標準誤差でしょう。以下では試行回数は1万のブートストラップ法で標準誤差の近似値を計算してみます。 結果を格納する長さ1万の空ベクトルResult_vecを作成する。 iの初期値を1と設定する。 Data1から100個 (= Data1の大きさ)の値を無作為抽出 (復元抽出)し、Sample1に格納する。 Data2から100個 (= Data2の大きさ)の値を無作為抽出 (復元抽出)し、Sample2に格納する。 Result_vecのi番目の位置にSample1の平均値とSample2の平均値の差分を格納する。 iを1増加させる。 3~6の手順を1万回繰り返す。 n_trials &lt;- 10000 Result_vec &lt;- rep(NA, n_trials) for (i in 1:n_trials) { Sample1 &lt;- sample(Data1, 100, replace = TRUE) Sample2 &lt;- sample(Data2, 100, replace = TRUE) Result_vec[i] &lt;- mean(Sample1) - mean(Sample2) } Result_vecには平均値の差分が10000個格納されており、これらの値の平均値をブートストラップ推定量 (bootstrap estimate)と呼ぶとします。 # 元のデータの平均値の差分 delta &lt;- mean(Data1) - mean(Data2) delta ## [1] -0.3066445 # ブートストラップ推定量 (平均値の差分の平均値) boot_delta &lt;- mean(Result_vec) boot_delta ## [1] -0.3045563 # ブートストラップ推定量のバイアス boot_b &lt;- delta - boot_delta 実際の平均値の差分 (\\(\\delta_0\\)) は-0.3066445、ブートストラップ推定量 (\\(\\delta^*\\)) は -0.3045563であるため、その差は-0.0020881です。これをブートストラップ推定量のバイアス (\\(b\\)) と呼びます。 ただし、我々に興味があるのは平均値の差分ではありません。平均値の差分はブートストラップ法を用いなくても普通に計算できるからです。ここで重要なのは平均値の差分の不確実性、つまり標準誤差でしょう。ブートストラップ推定量の標準誤差はResult_vecの標準偏差を計算するだけで十分です。 boot_se &lt;- sd(Result_vec) # ブートストラップ推定量の標準偏差 ブートストラップ推定量の標準偏差 (\\(\\mbox{se}^*\\))は約0.14であり、t検定の結果から得られた標準誤差0.141と非常に近い値が得られました。 95%信頼区間を計算してみます。百分位数信頼区間 (Percentile CI)はResult_Vecの左側の領域が2.5%、右側の領域が2.5%となる区間ですので、quantile()関数で計算することができます。 # 95%信頼区間 quantile(Result_vec, c(0.025, 0.975)) ## 2.5% 97.5% ## -0.58084484 -0.02999534 バイアスを補正しないWald信頼区間は\\(\\delta_0 \\pm 1.96 \\times \\mbox{se}^*\\)のように計算します (1.96は標準正規分布の累積密度分布において下側領域が0.975となる点です。)。 delta + qnorm(c(0.025, 0.975)) * boot_se ## [1] -0.58201710 -0.03127185 バイアス修正Wald信頼区間は\\((\\delta_0 - b) \\pm 1.96 \\times \\mbox{se}^*\\)です。 (delta - boot_b) + qnorm(c(0.025, 0.975)) * boot_se ## [1] -0.57992897 -0.02918372 これまでの結果を比較してみましょう。 t検定 ブートストラップ (1): 平均値の差分 -0.307 -0.305 (2): 標準誤差 0.141 0.14 (3): 95%信頼区間 [-0.585, -0.028] (4): 95%信頼区間 (百分位数) [-0.581, -0.03] (5): 95%信頼区間 (Wald) [-0.582, -0.031] (6): 95%信頼区間 (バイアス修正Wald) [-0.58, -0.029] 今回の例はt.test()関数を使えば一発で終わる問題ですが、モデルが複雑になれば推定量の不確実性の計算が難しくなるケースがあります。その時に力を発揮するのがブートストラップ方であり、{boot}、{bootstrap}、{simpleboot}など様々なパッケージが利用可能です。 参考資料 "],["scraping.html", "30. スクレイピング", " 30. スクレイピング {rvest}の使い方? "],["api.html", "31. API", " 31. API "],["solution.html", "演習問題の回答 31.1 基本的な操作 31.2 データの構造 31.3 Rプログラミングの基礎 31.4 関数の自作", " 演習問題の回答 結果は載せておりません。自分で結果を確認しましょう。 31.1 基本的な操作 (myVec1 &lt;- c(3, 9, 10, 8, 3, 5, 8)) # 問1 myVec1[c(2, 4, 6)] # 問2 sum(myVec1) # 問3 sum(myVec1[(myVec1 %% 2 == 1)]) # 問4 (myVec2 &lt;- c(1, 2, 3, 4, 3, 2, 1)) # 問5 (myVec3 &lt;- myVec1 + myVec2) # 問6 myVec3[myVec3 &lt; 10] # 問7 myVec4 &lt;- 1:100 # 問8 sum(myVec4^2) # 問9 sum((myVec4[myVec4 %% 2 == 1])^2) # 問10 31.2 データの構造 31.2.1 ベクトル # 問1 1から10までの公差1の等差数列を作成し、myVec1と名付けよ。 myVec1 &lt;- 1:10 # 問2 myVec1の長さを求めよ。 length(myVec1) # 問3 myVec1から偶数のみを抽出せよ myVec1[myVec1 %% 2 == 0] # 問4 myVec1をmyVec2という名でコピーし、myVec2の偶数を全て0に置換せよ。 myVec2 &lt;- myVec1 myVec2[myVec2 %% 2 == 0] &lt;- 0 # 問5 myVec1の全要素から1を引し、myVec3と名付けよ。 myVec3 &lt;- myVec1 - 1 # 問6 myVec1の奇数番目の要素には1を、偶数番目の要素には2を足し、myVec4と名付けよ。 myVec4 &lt;- myVec1 + c(1, 2) # 問7 myVec4からmyVec1を引け。 myVec4 - myVec1 31.2.2 行列 問1 以下のような2つの行列を作成せよ。 \\[ \\text{myMat1} = \\left[ \\begin{matrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6 \\end{matrix} \\right], \\text{myMat2} = \\left[ \\begin{matrix} 1 &amp; 4 &amp; 7 \\\\ 2 &amp; 5 &amp; 8 \\\\ 3 &amp; 6 &amp; 9 \\end{matrix} \\right] \\] # myMat1: byrow = を指定する場合 myMat1 &lt;- matrix(1:6, nrow = 2, byrow = TRUE) # myMat1: byrow = を指定しない場合 myMat1 &lt;- matrix(c(1, 4, 2, 5, 3, 6), nrow = 2) # myMat2: byrow = を指定する場合 myMat2 &lt;- matrix(c(1, 4, 7, 2, 5, 8, 3, 6, 9), nrow = 3, byrow = TRUE) # myMat2: byrow = を指定しない場合 myMat2 &lt;- matrix(1:9, nrow = 3) 問2 myMat1とmyMat2の掛け算を行い、myMat3と名付けよ。 myMat3 &lt;- myMat1 %*% myMat2 問3 連立方程式の解を求めよ。 # 問3-1 myMat4 &lt;- matrix(c(3, -1, 2, 1, 2, 3, 2, -1, -1), nrow = 3, byrow = TRUE) myMat5 &lt;- matrix(c(12, 11, 2), nrow = 3) # 問3-2 solve(myMat4) # 問3-3 myMat6 &lt;- solve(myMat4) %*% myMat5 # 問3-4 myMat4 %*% myMat6 31.2.3 データフレーム # 問1. 以下のようなデータフレームを作成し、myDF1と名付けよ。 myDF1 &lt;- data.frame( ID = 1:10, Name = c(&quot;Australia&quot;, &quot;China&quot;, &quot;Iran&quot;, &quot;Iraq&quot;, &quot;Japan&quot;, &quot;Qatar&quot;, &quot;Saudi Arabia&quot;, &quot;South Korea&quot;, &quot;Syria&quot;, &quot;UAE&quot;), Rank = c(42, 76, 33, 70, 28, 55, 67, 40, 79, 71), Socre = c(1457, 1323, 1489, 1344, 1500, 1396, 1351, 1464, 1314, 1334) ) # 問2. myDF1からName列を抽出せよ。 myDF1$Name # 問3. myDF1のName列から3番目の要素を抽出せよ。 myDF1$Name[3] # 問4. myDF1の3行目を抽出せよ。 myDF1[3, ] # 問5. FIFA_Women.csvをtibble型として読み込み、myTbl1と名付けよ。 myTbl1 &lt;- read_csv(&quot;Data/FIFA_Women.csv&quot;) # 問6. myTbl1のRank列を抽出し、それぞれの要素が20より小さいかを判定せよ。 myTbl1$Rank &lt; 20 # 問7. Rankが20より小さい国名を抽出せよ。 myTbl1$Team[myTbl1$Rank &lt; 20] # 問8. myTbl1からランキングが20位以内の行を抽出せよ。 myTbl1[myTbl1$Rank &lt; 20, ] 31.3 Rプログラミングの基礎 問1 while()を使う場合 Trial &lt;- 1 Total &lt;- 0 while (Total != 15) { Dice &lt;- sample(1:6, 3, replace = TRUE) Total &lt;- sum(Dice) print(paste0(Trial, &quot;目のサイコロ投げの結果: &quot;, Dice[1], &quot;, &quot;, Dice[2], &quot;, &quot;, Dice[3], &quot; (合計: &quot;, Total, &quot;)&quot;)) Trial &lt;- Trial + 1 } for()を使う場合 for (Trial in 1:10000) { Dice &lt;- sample(1:6, 3, replace = TRUE) Total &lt;- sum(Dice) print(paste0(Trial, &quot;目のサイコロ投げの結果: &quot;, Dice[1], &quot;, &quot;, Dice[2], &quot;, &quot;, Dice[3], &quot; (合計: &quot;, Total, &quot;)&quot;)) if (Total == 15) { break } } 問2 # 問2-1 Cause &lt;- c(&quot;喫煙&quot;, &quot;飲酒&quot;, &quot;食べすぎ&quot;, &quot;寝不足&quot;, &quot;ストレス&quot;) for (i in Cause) { Text &lt;- sprintf(&quot;肥満の原因は%sでしょう。&quot;, i) print(Text) } # 問2-2 Effect &lt;- c(&quot;肥満&quot;, &quot;ハゲ&quot;, &quot;不人気&quot;, &quot;金欠&quot;) for (i in Effect) { for (j in Cause) { Text &lt;- sprintf(&quot;%sの原因は%sでしょう。&quot;, i, j) print(Text) } } # 問2-3 Solution &lt;- c(&quot;この薬を飲めば&quot;, &quot;一日一麺すれば&quot;, &quot;Songに100万円振り込めば&quot;) for (i in Effect) { for (j in Cause) { for (k in Solution) { Text &lt;- sprintf(&quot;%sの原因は%sですが、%s改善されるでしょう。&quot;, i, j, k) print(Text) } } } 31.4 関数の自作 問1 Data &lt;- c(5, 3) if (Data[1] &gt; Data[2]) { Temp &lt;- Data[1] Data[1] &lt;- Data[2] Data[2] &lt;- Temp } Data 問2 my_sqrt &lt;- function(x, g, e = 0.001) { if (!is.numeric(x) | x &lt;= 0) { stop(&quot;xは正の実数でなければなりません。&quot;) } gap = Inf while (gap &gt; e) { gap &lt;- abs(x - g^2) if (gap &gt; e) { g &lt;- (g + x / g) / 2 } else { return(g) } } } 問3 Data &lt;- c(5, 2, 4, 1) for (i in (length(Data)-1):1) { for (j in 1:i) { if (Data[j] &gt; Data[j+1]) { Temp &lt;- Data[j] Data[j] &lt;- Data[j + 1] Data[j+1] &lt;- Temp } } } Data 問4 mySort &lt;- function(x) { for (i in (length(x)-1):1) { for (j in 1:i) { if (x[j] &gt; x[j+1]) { Temp &lt;- x[j] x[j] &lt;- x[j + 1] x[j+1] &lt;- Temp } } } x } # Bubble Sortの例 Data &lt;- c(28, 92, 29, 84, 29, 27, 19, 23, 32, 30) mySort(Data) 問5 DQ_Attack2 &lt;- function(attack, defence, hp, enemy) { DefaultDamage &lt;- (attack / 2) - (defence / 4) DefaultDamage &lt;- ifelse(DefaultDamage &lt; 0, 0, DefaultDamage) DamageWidth &lt;- floor(DefaultDamage / 16) + 1 DamageMin &lt;- DefaultDamage - DamageWidth DamageMin &lt;- ifelse(DamageMin &lt; 0, 0, DamageMin) DamageMax &lt;- DefaultDamage + DamageWidth CurrentHP &lt;- hp while (CurrentHP &gt; 0) { Kaisin &lt;- runif(n = 1, min = 0, max = 1) if (Kaisin &lt;= (1/32)) { Damage &lt;- runif(n = 1, min = attack * 0.95, max = attack * 1.05) } else { Damage &lt;- runif(n = 1, min = DamageMin, max = DamageMax) } Damage &lt;- round(Damage, 0) CurrentHP &lt;- CurrentHP - Damage if (Kaisin &lt;= (1/32)) { print(paste0(&quot;かいしんのいちげき!&quot;, enemy, &quot;に&quot;, Damage, &quot;のダメージ!!&quot;)) } else{ print(paste0(enemy, &quot;に&quot;, Damage, &quot;のダメージ!!&quot;)) } } paste0(enemy, &quot;をやっつけた！&quot;) } 問6 mySample &lt;- function(x, n, seed) { # 以下の条件が満たされない場合、エラーメッセージを出力し、関数を停止 stopifnot( # length(n) == 1が満たされない場合 &quot;a length of n must be 1.&quot; = (length(n) == 1), # length(seed) == 1が満たされない場合 &quot;a length of seed must be 1.&quot; = (length(seed) == 1), # is.numeric(seed) == TRUEが満たされない場合 &quot;seed must be integer of double.&quot; = is.numeric(seed), # ceiling(n) == nが満たされない場合 &quot;n must be interger.&quot; = (ceiling(n) == n) ) # LCG()を用いてn個の乱数を生成し、xの長さだけ倍にする index &lt;- LCG(n = n, seed = seed) * length(x) # 得られた疑似乱数を切り上げる index &lt;- ceiling(index) # ベクトルxのindex番目要素を抽出し、Resultに格納 Result &lt;- x[index] Result } "],["session.html", "本書の執筆環境", " 本書の執筆環境 セッション情報 ## R version 4.1.2 (2021-11-01) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Big Sur 10.16 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.1/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] bookdown_0.24 digest_0.6.29 R6_2.5.1 jsonlite_1.8.0 ## [5] magrittr_2.0.2 evaluate_0.15 stringi_1.7.6 rlang_1.0.2 ## [9] cli_3.2.0 rstudioapi_0.13 jquerylib_0.1.4 bslib_0.3.1 ## [13] rmarkdown_2.13 tools_4.1.2 stringr_1.4.0 xfun_0.30 ## [17] yaml_2.3.5 fastmap_1.1.0 compiler_4.1.2 htmltools_0.5.2 ## [21] knitr_1.37 sass_0.4.0 RStudio情報 RStudio 2022.02.0+442 (Prairie Trillium) パッケージ情報 ## Package Version Built ## 1 abind 1.4-5 4.1.0 ## 2 ade4 1.7-18 4.1.0 ## 3 AER 1.2-9 4.1.0 ## 4 arm 1.12-2 4.1.0 ## 5 AsioHeaders 1.16.1-1 4.1.0 ## 6 askpass 1.1 4.1.0 ## 7 assertive 0.3-6 4.1.0 ## 8 assertive.base 0.0-9 4.1.0 ## 9 assertive.code 0.0-3 4.1.0 ## 10 assertive.data 0.0-3 4.1.0 ## 11 assertive.data.uk 0.0-2 4.1.0 ## 12 assertive.data.us 0.0-2 4.1.0 ## 13 assertive.datetimes 0.0-3 4.1.0 ## 14 assertive.files 0.0-2 4.1.0 ## 15 assertive.matrices 0.0-2 4.1.0 ## 16 assertive.models 0.0-2 4.1.0 ## 17 assertive.numbers 0.0-2 4.1.0 ## 18 assertive.properties 0.0-4 4.1.0 ## 19 assertive.reflection 0.0-5 4.1.0 ## 20 assertive.sets 0.0-3 4.1.0 ## 21 assertive.strings 0.0-3 4.1.0 ## 22 assertive.types 0.0-3 4.1.0 ## 23 assertthat 0.2.1 4.1.0 ## 24 attachment 0.2.4 4.1.0 ## 25 attempt 0.3.1 4.1.0 ## 26 backports 1.4.1 4.1.0 ## 27 BalanceR 0.7.6 4.1.2 ## 28 base 4.1.2 4.1.2 ## 29 base64enc 0.1-3 4.1.0 ## 30 bayestestR 0.11.5 4.1.0 ## 31 beautier 2.6.2 4.1.0 ## 32 beautifyR 0.3.1 4.1.2 ## 33 BH 1.78.0-0 4.1.0 ## 34 BiocManager 1.30.16 4.1.0 ## 35 BiocVersion 3.14.0 4.1.0 ## 36 bit 4.0.4 4.1.0 ## 37 bit64 4.0.5 4.1.0 ## 38 bitops 1.0-7 4.1.0 ## 39 blob 1.2.2 4.1.0 ## 40 blogdown 1.8 4.1.2 ## 41 bookdown 0.24 4.1.0 ## 42 boot 1.3-28 4.1.2 ## 43 brew 1.0-7 4.1.2 ## 44 brio 1.1.3 4.1.0 ## 45 broom 0.7.12 4.1.2 ## 46 bslib 0.3.1 4.1.0 ## 47 cachem 1.0.6 4.1.0 ## 48 callr 3.7.0 4.1.0 ## 49 car 3.0-12 4.1.0 ## 50 carData 3.0-5 4.1.2 ## 51 caret 6.0-91 4.1.2 ## 52 cellranger 1.1.0 4.1.0 ## 53 checkmate 2.0.0 4.1.0 ## 54 chromote 0.0.0.9003 4.1.2 ## 55 cjoint 2.1.0 4.1.0 ## 56 class 7.3-20 4.1.2 ## 57 classInt 0.4-3 4.1.0 ## 58 cli 3.2.0 4.1.2 ## 59 clipr 0.8.0 4.1.2 ## 60 cluster 2.1.2 4.1.2 ## 61 coda 0.19-4 4.1.0 ## 62 codetools 0.2-18 4.1.2 ## 63 colorspace 2.0-3 4.1.2 ## 64 colourpicker 1.1.1 4.1.0 ## 65 commonmark 1.8.0 4.1.2 ## 66 compiler 4.1.2 4.1.2 ## 67 config 0.3.1 4.1.0 ## 68 conquer 1.2.2 4.1.2 ## 69 corpcor 1.6.10 4.1.0 ## 70 corrplot 0.92 4.1.0 ## 71 countdown 0.3.5 4.1.2 ## 72 countrycode 1.3.1 4.1.2 ## 73 cowplot 1.1.1 4.1.0 ## 74 cpp11 0.4.2 4.1.0 ## 75 crayon 1.5.0 4.1.2 ## 76 credentials 1.3.2 4.1.0 ## 77 cregg 0.4.0 4.1.0 ## 78 crosstalk 1.2.0 4.1.0 ## 79 curl 4.3.2 4.1.0 ## 80 dagitty 0.3-1 4.1.0 ## 81 data.table 1.14.2 4.1.0 ## 82 datasets 4.1.2 4.1.2 ## 83 datawizard 0.3.0 4.1.2 ## 84 DBI 1.1.2 4.1.0 ## 85 dbplyr 2.1.1 4.1.0 ## 86 dcurver 0.9.2 4.1.0 ## 87 democracyData 0.3.0 4.1.2 ## 88 dendextend 1.15.2 4.1.0 ## 89 Deriv 4.1.3 4.1.0 ## 90 desc 1.4.1 4.1.2 ## 91 devtools 2.4.3 4.1.0 ## 92 diffobj 0.3.5 4.1.0 ## 93 digest 0.6.29 4.1.0 ## 94 dockerfiler 0.1.4 4.1.0 ## 95 downlit 0.4.0 4.1.0 ## 96 dplyr 1.0.8 4.1.2 ## 97 DT 0.21 4.1.2 ## 98 dtplyr 1.2.1 4.1.2 ## 99 e1071 1.7-9 4.1.0 ## 100 ellipsis 0.3.2 4.1.0 ## 101 estimatr 0.30.6 4.1.2 ## 102 evaluate 0.15 4.1.2 ## 103 extrafont 0.17 4.1.0 ## 104 extrafontdb 1.0 4.1.0 ## 105 fansi 1.0.2 4.1.2 ## 106 farver 2.1.0 4.1.0 ## 107 fastDummies 1.6.3 4.1.0 ## 108 fastmap 1.1.0 4.1.0 ## 109 fontawesome 0.2.2 4.1.0 ## 110 forcats 0.5.1 4.1.0 ## 111 foreach 1.5.2 4.1.2 ## 112 foreign 0.8-82 4.1.2 ## 113 formatR 1.11 4.1.0 ## 114 formattable 0.2.1 4.1.0 ## 115 Formula 1.2-4 4.1.0 ## 116 fs 1.5.2 4.1.0 ## 117 fusen 0.3.0 4.1.0 ## 118 future 1.24.0 4.1.2 ## 119 future.apply 1.8.1 4.1.0 ## 120 fuzzyjoin 0.1.6 4.1.0 ## 121 gamlss.dist 6.0-3 4.1.2 ## 122 gapminder 0.3.0 4.1.0 ## 123 gargle 1.2.0 4.1.0 ## 124 gdtools 0.2.4 4.1.2 ## 125 generics 0.1.2 4.1.2 ## 126 geosphere 1.5-14 4.1.0 ## 127 gert 1.5.0 4.1.2 ## 128 ggalluvial 0.12.3 4.1.0 ## 129 GGally 2.1.2 4.1.0 ## 130 ggbump 0.1.0 4.1.0 ## 131 ggdag 0.2.4 4.1.0 ## 132 ggdendro 0.1.23 4.1.2 ## 133 ggExtra 0.9 4.1.0 ## 134 ggfittext 0.9.1 4.1.0 ## 135 ggforce 0.3.3 4.1.0 ## 136 gghighlight 0.3.2 4.1.0 ## 137 gglm 0.1.0 4.1.0 ## 138 ggmosaic 0.3.4 4.1.2 ## 139 ggplot2 3.3.5 4.1.0 ## 140 ggpubr 0.4.0 4.1.0 ## 141 ggraph 2.0.5 4.1.0 ## 142 ggrepel 0.9.1 4.1.0 ## 143 ggridges 0.5.3 4.1.0 ## 144 ggsci 2.9 4.1.0 ## 145 ggsignif 0.6.3 4.1.0 ## 146 ggstance 0.3.5 4.1.0 ## 147 gh 1.3.0 4.1.0 ## 148 ghibli 0.3.2 4.1.0 ## 149 gitcreds 0.1.1 4.1.0 ## 150 globals 0.14.0 4.1.0 ## 151 glue 1.6.2 4.1.2 ## 152 golem 0.3.2 4.1.2 ## 153 googledrive 2.0.0 4.1.0 ## 154 googlePolylines 0.8.2 4.1.0 ## 155 googlesheets4 1.0.0 4.1.0 ## 156 gower 1.0.0 4.1.2 ## 157 GPArotation 2014.11-1 4.1.0 ## 158 graphics 4.1.2 4.1.2 ## 159 graphlayouts 0.8.0 4.1.2 ## 160 grDevices 4.1.2 4.1.2 ## 161 grid 4.1.2 4.1.2 ## 162 gridExtra 2.3 4.1.0 ## 163 gt 0.4.0 4.1.2 ## 164 gtable 0.3.0 4.1.0 ## 165 hardhat 0.2.0 4.1.2 ## 166 haven 2.4.3 4.1.0 ## 167 here 1.0.1 4.1.0 ## 168 highr 0.9 4.1.0 ## 169 hms 1.1.1 4.1.0 ## 170 hrbrthemes 0.8.0 4.1.0 ## 171 htmltools 0.5.2 4.1.0 ## 172 htmlwidgets 1.5.4 4.1.0 ## 173 httpuv 1.6.5 4.1.2 ## 174 httr 1.4.2 4.1.0 ## 175 icons 0.2.0 4.1.2 ## 176 ids 1.0.1 4.1.0 ## 177 igraph 1.2.11 4.1.2 ## 178 ini 0.3.1 4.1.0 ## 179 inline 0.3.19 4.1.0 ## 180 insight 0.16.0 4.1.2 ## 181 ipred 0.9-12 4.1.0 ## 182 isoband 0.2.5 4.1.0 ## 183 iterators 1.0.14 4.1.2 ## 184 jpmesh 2.1.0 4.1.2 ## 185 jpndistrict 0.3.9.9000 4.1.2 ## 186 jquerylib 0.1.4 4.1.0 ## 187 jsonlite 1.8.0 4.1.2 ## 188 kableExtra 1.3.4 4.1.0 ## 189 KernSmooth 2.23-20 4.1.2 ## 190 knitr 1.37 4.1.0 ## 191 labeling 0.4.2 4.1.0 ## 192 later 1.3.0 4.1.0 ## 193 lattice 0.20-45 4.1.2 ## 194 lava 1.6.10 4.1.0 ## 195 lazyeval 0.2.2 4.1.0 ## 196 leaflet 2.1.0 4.1.2 ## 197 leaflet.providers 1.9.0 4.1.0 ## 198 learnr 0.10.1 4.1.0 ## 199 lifecycle 1.0.1 4.1.0 ## 200 list 9.2 4.1.0 ## 201 listenv 0.8.0 4.1.0 ## 202 lme4 1.1-28 4.1.2 ## 203 lmtest 0.9-39 4.1.0 ## 204 lobstr 1.1.1 4.1.0 ## 205 loo 2.4.1 4.1.0 ## 206 lpdensity 2.3 4.1.2 ## 207 lubridate 1.8.0 4.1.0 ## 208 magic 1.6-0 4.1.2 ## 209 magick 2.7.3 4.1.0 ## 210 magrittr 2.0.2 4.1.2 ## 211 mapproj 1.2.8 4.1.2 ## 212 maps 3.4.0 4.1.0 ## 213 maptools 1.1-3 4.1.2 ## 214 margins 0.3.26 4.1.0 ## 215 markdown 1.1 4.1.0 ## 216 MASS 7.3-55 4.1.2 ## 217 Matrix 1.4-0 4.1.0 ## 218 MatrixModels 0.5-0 4.1.0 ## 219 matrixStats 0.61.0 4.1.0 ## 220 memoise 2.0.1 4.1.0 ## 221 metathis 1.1.1 4.1.0 ## 222 methods 4.1.2 4.1.2 ## 223 mgcv 1.8-39 4.1.2 ## 224 mime 0.12 4.1.0 ## 225 miniUI 0.1.1.1 4.1.0 ## 226 minqa 1.2.4 4.1.0 ## 227 mirt 1.35.1 4.1.0 ## 228 mitools 2.4 4.1.0 ## 229 ModelMetrics 1.2.2.2 4.1.0 ## 230 modelr 0.1.8 4.1.0 ## 231 modelsummary 0.9.6 4.1.2 ## 232 munsell 0.5.0 4.1.0 ## 233 mvtnorm 1.1-3 4.1.0 ## 234 nlme 3.1-155 4.1.2 ## 235 nloptr 2.0.0 4.1.2 ## 236 nnet 7.3-17 4.1.2 ## 237 numDeriv 2016.8-1.1 4.1.0 ## 238 openssl 2.0.0 4.1.2 ## 239 pacman 0.5.1 4.1.0 ## 240 pagedown 0.17 4.1.2 ## 241 palmerpenguins 0.1.0 4.1.0 ## 242 pander 0.6.4 4.1.0 ## 243 parallel 4.1.2 4.1.2 ## 244 parallelly 1.30.0 4.1.0 ## 245 parameters 0.17.0 4.1.2 ## 246 parsermd 0.1.2 4.1.0 ## 247 patchwork 1.1.1 4.1.0 ## 248 pbkrtest 0.5.1 4.1.0 ## 249 performance 0.8.0 4.1.0 ## 250 permute 0.9-7 4.1.2 ## 251 pillar 1.7.0 4.1.2 ## 252 pixmap 0.4-12 4.1.0 ## 253 pkgbuild 1.3.1 4.1.0 ## 254 pkgconfig 2.0.3 4.1.0 ## 255 pkgdown 2.0.2 4.1.2 ## 256 pkgload 1.2.4 4.1.0 ## 257 plotly 4.10.0 4.1.0 ## 258 plyr 1.8.6 4.1.0 ## 259 png 0.1-7 4.1.0 ## 260 polyclip 1.10-0 4.1.0 ## 261 polynom 1.4-0 4.1.0 ## 262 praise 1.0.0 4.1.0 ## 263 PRcalc 0.7.0 4.1.2 ## 264 prediction 0.3.14 4.1.0 ## 265 prettyunits 1.1.1 4.1.0 ## 266 prismatic 1.1.0 4.1.0 ## 267 pROC 1.18.0 4.1.0 ## 268 processx 3.5.2 4.1.0 ## 269 prodlim 2019.11.13 4.1.0 ## 270 productplots 0.1.1 4.1.0 ## 271 progress 1.2.2 4.1.0 ## 272 progressr 0.10.0 4.1.0 ## 273 ProjectTemplate 0.10.2 4.1.0 ## 274 promises 1.2.0.1 4.1.0 ## 275 proxy 0.4-26 4.1.0 ## 276 pryr 0.1.5 4.1.0 ## 277 ps 1.6.0 4.1.0 ## 278 purrr 0.3.4 4.1.0 ## 279 qrcode 0.1.4 4.1.0 ## 280 quadprog 1.5-8 4.1.0 ## 281 qualtRics 3.1.5 4.1.0 ## 282 quantreg 5.88 4.1.2 ## 283 R.cache 0.15.0 4.1.0 ## 284 R.methodsS3 1.8.1 4.1.0 ## 285 R.oo 1.24.0 4.1.0 ## 286 R.utils 2.11.0 4.1.0 ## 287 R6 2.5.1 4.1.0 ## 288 ragg 1.2.2 4.1.2 ## 289 rappdirs 0.3.3 4.1.0 ## 290 rapportools 1.0 4.1.0 ## 291 raster 3.5-15 4.1.2 ## 292 rcmdcheck 1.4.0 4.1.0 ## 293 RColorBrewer 1.1-2 4.1.0 ## 294 Rcpp 1.0.8.2 4.1.2 ## 295 RcppArmadillo 0.10.8.1.0 4.1.2 ## 296 RcppEigen 0.3.3.9.1 4.1.0 ## 297 RcppParallel 5.1.5 4.1.2 ## 298 rdd 0.57 4.1.0 ## 299 rddensity 2.2 4.1.0 ## 300 rdrobust 1.0.8 4.1.0 ## 301 readr 2.1.2 4.1.2 ## 302 readxl 1.3.1 4.1.0 ## 303 recipes 0.2.0 4.1.2 ## 304 RefManageR 1.3.0 4.1.0 ## 305 rematch 1.0.1 4.1.0 ## 306 rematch2 2.1.2 4.1.0 ## 307 remotes 2.4.2 4.1.0 ## 308 renv 0.15.4 4.1.2 ## 309 reprex 2.0.1 4.1.0 ## 310 reshape 0.8.8 4.1.0 ## 311 reshape2 1.4.4 4.1.0 ## 312 rgeos 0.5-9 4.1.0 ## 313 rJava 1.0-6 4.1.0 ## 314 rlang 1.0.2 4.1.2 ## 315 rmarkdown 2.13 4.1.2 ## 316 rmdja 0.4.6.9 4.1.2 ## 317 rnaturalearth 0.1.0 4.1.0 ## 318 rnaturalearthdata 0.1.0 4.1.0 ## 319 rnaturalearthhires 0.2.0 4.1.2 ## 320 roxygen2 7.1.2 4.1.0 ## 321 rpart 4.1.16 4.1.2 ## 322 rprojroot 2.0.2 4.1.0 ## 323 rqog 0.4.2021 4.1.2 ## 324 rstan 2.21.3 4.1.0 ## 325 rstatix 0.7.0 4.1.0 ## 326 rstudioapi 0.13 4.1.0 ## 327 Rttf2pt1 1.3.10 4.1.2 ## 328 rversions 2.1.1 4.1.0 ## 329 rvest 1.0.2 4.1.0 ## 330 s2 1.0.7 4.1.0 ## 331 sandwich 3.0-1 4.1.0 ## 332 sass 0.4.0 4.1.0 ## 333 scales 1.1.1 4.1.0 ## 334 segmented 1.4-0 4.1.2 ## 335 selectr 0.4-2 4.1.0 ## 336 seqinr 4.2-8 4.1.0 ## 337 servr 0.24 4.1.0 ## 338 sessioninfo 1.2.2 4.1.0 ## 339 sf 1.0-7 4.1.2 ## 340 shades 1.4.0 4.1.0 ## 341 shiny 1.7.1 4.1.0 ## 342 shiny.i18n 0.2.0 4.1.0 ## 343 shinyBS 0.61 4.1.0 ## 344 shinyjs 2.1.0 4.1.0 ## 345 sjlabelled 1.1.8 4.1.0 ## 346 sourcetools 0.1.7 4.1.0 ## 347 sp 1.4-6 4.1.0 ## 348 SparseM 1.81 4.1.0 ## 349 spatial 7.3-15 4.1.2 ## 350 splines 4.1.2 4.1.2 ## 351 SQUAREM 2021.1 4.1.0 ## 352 StanHeaders 2.21.0-7 4.1.0 ## 353 stargazer 5.2.3 4.1.2 ## 354 stats 4.1.2 4.1.2 ## 355 stats4 4.1.2 4.1.2 ## 356 stringdist 0.9.8 4.1.0 ## 357 stringi 1.7.6 4.1.0 ## 358 stringr 1.4.0 4.1.0 ## 359 styler 1.7.0 4.1.2 ## 360 summarytools 1.0.0 4.1.0 ## 361 survey 4.1-1 4.1.0 ## 362 survival 3.3-1 4.1.2 ## 363 svglite 2.1.0 4.1.2 ## 364 sys 3.4 4.1.0 ## 365 systemfonts 1.0.4 4.1.2 ## 366 tables 0.9.6 4.1.0 ## 367 tcltk 4.1.2 4.1.2 ## 368 terra 1.5-21 4.1.2 ## 369 testit 0.13 4.1.0 ## 370 TestTemp 0.0.0.9000 4.1.2 ## 371 testthat 3.1.2 4.1.2 ## 372 texreg 1.38.5 4.1.2 ## 373 textshaping 0.3.6 4.1.0 ## 374 tibble 3.1.6 4.1.0 ## 375 tidygraph 1.2.0 4.1.0 ## 376 tidyr 1.2.0 4.1.2 ## 377 tidyselect 1.1.2 4.1.2 ## 378 tidyverse 1.3.1 4.1.0 ## 379 timeDate 3043.102 4.1.0 ## 380 tinytex 0.37 4.1.2 ## 381 titanic 0.1.0 4.1.0 ## 382 tools 4.1.2 4.1.2 ## 383 treemapify 2.5.5 4.1.0 ## 384 tweenr 1.0.2 4.1.0 ## 385 tzdb 0.2.0 4.1.0 ## 386 units 0.8-0 4.1.2 ## 387 usethis 2.1.5 4.1.0 ## 388 usmap 0.6.0 4.1.2 ## 389 usmapdata 0.1.0 4.1.2 ## 390 utf8 1.2.2 4.1.0 ## 391 utils 4.1.2 4.1.2 ## 392 uuid 1.0-3 4.1.0 ## 393 V8 4.1.0 4.1.2 ## 394 vctrs 0.3.8 4.1.0 ## 395 vdemdata 2.0 4.1.2 ## 396 vegan 2.5-7 4.1.0 ## 397 VGAM 1.1-6 4.1.2 ## 398 viridis 0.6.2 4.1.0 ## 399 viridisLite 0.4.0 4.1.0 ## 400 vroom 1.5.7 4.1.0 ## 401 waldo 0.3.1 4.1.0 ## 402 webshot 0.5.2 4.1.0 ## 403 websocket 1.4.1 4.1.0 ## 404 whisker 0.4 4.1.0 ## 405 withr 2.5.0 4.1.2 ## 406 wk 0.6.0 4.1.2 ## 407 xaringan 0.23 4.1.2 ## 408 xaringanBuilder 0.0.9 4.1.2 ## 409 xaringanExtra 0.5.5 4.1.2 ## 410 xfun 0.30 4.1.2 ## 411 xlsx 0.6.5 4.1.0 ## 412 xlsxjars 0.6.1 4.1.0 ## 413 xml2 1.3.3 4.1.0 ## 414 xopen 1.0.0 4.1.0 ## 415 xtable 1.8-4 4.1.0 ## 416 yaml 2.3.5 4.1.2 ## 417 zip 2.2.0 4.1.0 ## 418 zoo 1.8-9 4.1.0 "],["reference.html", "参考資料", " 参考資料 "],["404.html", "", " にゃんと、無効なURLだにゃ！ "]]
