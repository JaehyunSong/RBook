[
  {
    "objectID": "installation.html#RN4E自分のpcにインストール",
    "href": "installation.html#RN4E自分のpcにインストール",
    "title": "2  Rのインストール",
    "section": "\n2.1 自分のPCにインストール",
    "text": "2.1 自分のPCにインストール\n本章の内容は今後、以下の資料に基づき、再作成する予定である。\n\n矢内による資料 (macOS編、Linux (Ubuntu)編、Windows編)\nWindowsの場合、R 4.2からはUTF-8対応、32bit版の削除などかなりの変化があるはず"
  },
  {
    "objectID": "installation.html#RN4Eクラウド版rrstudio",
    "href": "installation.html#RN4Eクラウド版rrstudio",
    "title": "2  Rのインストール",
    "section": "\n2.2 クラウド版R+RStudio",
    "text": "2.2 クラウド版R+RStudio\n\n2.2.1 RStudio Cloud\nhttps://posit.cloud/\n\n2.2.2 JDCat分析ツール\nac.jp、またはgo.jpで終わるメールアドレスを持っている場合のみ使用可能\nhttps://meatwiki.nii.ac.jp/confluence/display/jdcatanalysis\n\n私たちのR 私たちのR 3  IDEの導入 1  R? 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 2  Rのインストール 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-intro",
    "href": "visualization4.html#RN4Esec-visual4-intro",
    "title": "20  可視化 [発展]",
    "section": "\n20.1 概要",
    "text": "20.1 概要\n　第17章では{ggplot2}の仕組みについて、第18章ではよく使われる5種類のプロット（棒グラフ、散布図、折れ線グラフ、箱ひげ図、ヒストグラム）の作り方を、第19章ではスケール、座標系などの操作を通じたグラフの見た目調整について解説しました。本章では第18章の延長線上に位置づけることができ、紹介しきれなかった様々なグラフの作り方について簡単に解説します。本章で紹介するグラフは以下の通りです。\n\nバイオリンプロット\nラグプロット\nリッジプロット\nエラーバー付き散布図\nロリーポップチャート\n平滑化ライン\n文字列の出力\nヒートマップ\n等高線図\n地図\n非巡回有向グラフ\nバンプチャート\n沖積図\nツリーマップ\nモザイクプロット\n\n\n\npacman::p_load(tidyverse)\n\nCountry_df <- read_csv(\"Data/Countries.csv\")\nCOVID19_df <- read_csv(\"Data/COVID19_Worldwide.csv\", guess_max = 10000)"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-violin",
    "href": "visualization4.html#RN4Esec-visual4-violin",
    "title": "20  可視化 [発展]",
    "section": "\n20.2 バイオリンプロット",
    "text": "20.2 バイオリンプロット\n　バイオリンプロットは連続変数の分布を可視化する際に使用するプロットの一つです。第17章で紹介しましたヒストグラムや箱ひげ図と目的は同じです。それではバイオリンプロットとは何かについて例を見ながら解説します。\n　以下の図は対数化した一人当たり購買力平価GDP（PPP_per_capita）のヒストグラムです。\n\n\n\n\n\n\n\n\n　このヒストグラムをなめらかにすると以下のような図になります。\n\n\n\n\n\n\n\n\n　この密度曲線を上下対称にすると以下のような図となり、これがバイオリンプロットです。ヒストグラムのようにデータの分布が分かりやすくなります。\n\n\n\n\n\n\n\n\n　しかし、この図の場合、ヒストグラムと同様、中央値や四分位数などの情報が含まれておりません。これらの箱ひげ図を使用した方が良いでしょう。バイオリンプロットの良い点はバイオリンの中に箱ひげ図を入れ、ヒストグラムと箱ひげ図両方の長所を取ることができる点です。たとえば、バイオリンプロットを90度回転させ、中にバイオリン図を入れると以下のようになります。\n\n\n\n\n\n\n\n\n　それでは実際にバイオリンプロットを作ってみましょう。使い方は箱ひげ図（geom_boxplot()）と同じです。たとえば、横軸は大陸（Continent）に、縦軸は対数化した一人当たり購買力平価GDP（PPP_per_capita）にしたバイオリンプロットを作るには作るにはgeom_violin()幾何オブジェクトの中にマッピングするだけです。大陸ごとに色分けしたい場合はfill引数にContinentをマッピングします。\n\nCountry_df %>%\n    ggplot() +\n    geom_violin(aes(x = Continent, y = PPP_per_capita, fill = Continent)) +\n    labs(x = \"大陸\", y = \"一人当たり購買力平価GDP (対数)\") +\n    scale_y_continuous(breaks = c(0, 1000, 10000, 100000),\n                       labels = c(0, 1000, 10000, 100000),\n                       trans  = \"log10\") + # y軸を対数化\n    guides(fill = \"none\") + # fillのマッピング情報の凡例を隠す\n    theme_minimal(base_size = 16)\n\n\n\n\n\n\n\n　ここに箱ひげ図も載せたい場合は、geom_violin()オブジェクトの後にgeom_boxplot()オブジェクトを入れるだけで十分です。\n\nCountry_df %>%\n    ggplot() +\n    geom_violin(aes(x = Continent, y = PPP_per_capita, fill = Continent)) +\n    geom_boxplot(aes(x = Continent, y = PPP_per_capita),\n                 width = 0.2) +\n    labs(x = \"大陸\", y = \"一人当たり購買力平価GDP (対数)\") +\n    scale_y_continuous(breaks = c(0, 1000, 10000, 100000),\n                       labels = c(0, 1000, 10000, 100000),\n                       trans = \"log10\") +\n    guides(fill = \"none\") +\n    theme_minimal(base_size = 16)\n\n\n\n\n\n\n\n　箱ひげ図は四分位範囲、四分位数、最小値、最大値などの情報を素早く読み取れますが、どの値当たりが分厚いかなどの情報が欠けています。これをバイオリンプロットで補うことで、よりデータの分布を的確に把握することができます。"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-rug",
    "href": "visualization4.html#RN4Esec-visual4-rug",
    "title": "20  可視化 [発展]",
    "section": "\n20.3 ラグプロット",
    "text": "20.3 ラグプロット\n　ラグプロット（rug plot）は変数の分布を示す点ではヒストグラム、箱ひげ図、バイオリンプロットと同じ目的を持ちますが、大きな違いとしてはラグプロット単体で使われるケースがない（または、非常に稀）という点です。ラグプロットは上述しましたヒストグラムや箱ひげ図、または散布図などと組み合わせて使うのが一般的です。\n　以下はCountry_dfのPPP_per_capita（常用対数変換）のヒストグラムです。\n\n\n\n\n\n\n\n\n　一変数の分布を確認する場合、ヒストグラムは情報量の損失が少ない方です。それでも値一つ一つの情報は失われますね。例えば、上記のヒストグラムで左端の度数は1です。左端の棒の区間はおおよそ500から780であり、一人当たりPPPがこの区間に属する国は1カ国ということです。ちなみに、その国はブルンジ共和国ですが、ブルンジ共和国の具体的な一人当たりPPPはヒストグラムから分かりません。情報量をより豊富に持たせるためには区間を細かく刻むことも出来ますが、逆に分布の全体像が読みにくくなります。\n　ここで登場するのがラグプロットです。これは座標平面の端を使ってデータを一時現状に並べたものです。多くの場合、点ではなく、垂直線（｜）を使います。ラグプロットの幾何オブジェクトは{ggplot2}でデフォルトで提供されており、geom_rug()を使います。マッピングはxまたはyに対して行いますが、座標平面の下段にラグプロットを出力する場合はxに変数（ここではPPP_per_capita）をマッピングします。\n\n\n\n\n\n\n\n\nラグプロットを使うと本来のヒストグラムの外見にほぼ影響を与えず、更に情報を付け加えることが可能です。点（｜）の密度でデータの分布を確認することもできますが、その密度の相対的な比較に関してはヒストグラムの方が良いでしょう。\nラグプロットは散布図に使うことも可能です。散布図は一つ一つの点が具体的な値がマッピングされるため、情報量の損失はほぼないでしょう。それでも散布図にラグプロットを加える意味はあります。まず、Country_dfのフリーダムハウス指数（FH_Total）と一人当たりPPP（PPP_per_capita）の散布図を作ってみましょう。\n\n\n\n\n\n\n\n\n散布図の目的は二変量間の関係を確認することであって、それぞれの変数の分布を確認することではありません。もし、FH_TotalとPPP_per_capitaの分布が確認したいなら、それぞれのヒストグラムや箱ひげ図を作成した方が良いでしょう。しかし、ラグプロットを使えば、点（｜）の密度で大まかな分布は確認出来ますし、図の見た目にもほぼ影響を与えません。\n横軸と縦軸両方のラグプロットは、geom_rug()にxとy両方マッピングするだけです。\n\n\n\n\n\n\n\n\n　これでFH_Totalはほぼ均等に分布していて、PPP_per_capitaは2万ドル以下に多く密集していることが確認できます。\n　{ggExtra}のggMarginal()を使えば、ラグプロットでなく、箱ひげ図やヒストグラムを付けることも可能です。{ggplot2}で作図した図をオブジェクトとして格納し、ggMarginal()の第一引数として指定します。第一引数のみだと密度のだけ出力されるため、箱ひげ図を付けるためにはtype = \"boxplot\"を指定します（既定値は\"density\"）。ヒストグラムを出力する場合は\"histogram\"と指定します。"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-ridge",
    "href": "visualization4.html#RN4Esec-visual4-ridge",
    "title": "20  可視化 [発展]",
    "section": "\n20.4 リッジプロット",
    "text": "20.4 リッジプロット\n　リッジプロット（ridge plot）はある変数の分布をグループごとに出力する図です。大陸ごとの人間開発指数の分布を示したり、時系列データなら分布の変化を示す時にも使えます。ここでは大陸ごとの人間開発指数の分布をリッジプロットで示してみましょう。\n　リッジプロットを作成する前に、geom_density()幾何オブジェクトを用い、変数の密度曲線（density curve）を作ってみます。マッピングはxに対し、分布を出力する変数名を指定します。また、密度曲線内部に色塗り（fill）をし、曲線を計算する際のバンド幅（bw）は0.054にします。bwが大きいほど、なめらかな曲線になります。\n\nCountry_df %>%\n  ggplot() +\n  geom_density(aes(x = HDI_2018), fill = \"gray70\", bw = 0.054) +\n  labs(x = \"2018年人間開発指数\", y = \"大陸\") +\n  theme_minimal(base_size = 12)\n\nWarning: Removed 6 rows containing non-finite values (stat_density).\n\n\n\n\n\n\n\n\n　これを大陸ごとに出力する場合、ファセット分割を行います。今回は大陸ごとに1列（ncol = 1）でファセットを分割します。\n\nCountry_df %>%\n  ggplot() +\n  geom_density(aes(x = HDI_2018), fill = \"gray70\", bw = 0.054) +\n  labs(x = \"2018年人間開発指数\", y = \"大陸\") +\n  facet_wrap(~Continent, ncol = 1) +\n  theme_minimal(base_size = 12)\n\nWarning: Removed 6 rows containing non-finite values (stat_density).\n\n\n\n\n\n\n\n\n　それでは上のグラフをリッジプロットとして作図してみましょう。今回は{ggridges}パッケージを使います。\n\npacman::p_load(ggridges)\n\n　使用する幾何オブジェクトはgeom_density_ridges()です。似たような幾何オブジェクトとしてgeom_ridgeline()がありますが、こちらは予め密度曲線の高さを計算しておく必要があります。一方、geom_density_ridges()は変数だけ指定すれば密度を自動的に計算してくれます。マッピングはxとyに対し、それぞれ分布を出力する変数名とグループ変数名を指定します。また、密度曲線が重なるケースもあるため、透明度（alpha）も0.5にしておきましょう。ここでは別途指定しませんが、ハンド幅も指定可能であり、aes()の外側にbandwidthを指定するだけです。\n\nCountry_df %>%\n  ggplot() +\n  geom_density_ridges(aes(x = HDI_2018, y = Continent), \n                      alpha = 0.5) +\n  labs(x = \"2018年人間開発指数\", y = \"大陸\") +\n  theme_minimal(base_size = 12)\n\nPicking joint bandwidth of 0.054\n\n\nWarning: Removed 6 rows containing non-finite values (stat_density_ridges).\n\n\n\n\n\n\n\n\n先ほど作図した図と非常に似た図が出来上がりました。ファセット分割に比べ、空間を最大限に活用していることが分かります。ファセットラベルがなく、グループ名が縦軸上に位置するからです。また、リッジプロットの特徴は密度曲線がオーバラップする点ですが、以下のようにscale = 1を指定すると、オーバラップなしで作成することも可能です。もし、scale = 3にすると最大2つの密度曲線が重なることになります。たとえば最下段のアフリカはアメリカの行と若干オーバラップしていますが、scale = 3の場合、アジアの行までオーバーラップされうることになります。\n\nCountry_df %>%\n  ggplot() +\n  geom_density_ridges(aes(x = HDI_2018, y = Continent), \n                      scale = 1, alpha = 0.5) +\n  labs(x = \"2018年人間開発指数\", y = \"大陸\") +\n  theme_minimal(base_size = 12)\n\nPicking joint bandwidth of 0.054\n\n\nWarning: Removed 6 rows containing non-finite values (stat_density_ridges).\n\n\n\n\n\n\n\n\n　また、横軸の値に応じて背景の色をグラデーションで表現することも可能です。この場合、geom_density_ridges()幾何オブジェクトでなく、geom_density_ridges_gradient()を使い、fillにもマッピングをする必要があります。横軸（x）の値に応じて色塗りをする場合、fill = stat(x)とします。デフォルトでは横軸の値が高いほど空色、低いほど黒になります。ここでは高いほど黄色、低いほど紫ににするため、色弱にも優しいscale_fill_viridis_c()を使い1、カラーオプションはplasmaにします（option = \"c\"）。\n\nCountry_df %>%\n  ggplot() +\n  geom_density_ridges_gradient(aes(x = HDI_2018, y = Continent, fill = stat(x)), \n                               alpha = 0.5) +\n  scale_fill_viridis_c(option = \"C\") +\n  labs(x = \"2018年人間開発指数\", y = \"大陸\", fill = \"2018年人間開発指数\") +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\nPicking joint bandwidth of 0.054\n\n\n\n\n\n\n\n\n　密度曲線は基本的にはなめらかな曲線であるため、データが存在しない箇所にも密度が高く見積もられるケースがあります。全体的な分布を俯瞰するには良いですが、情報の損失は避けられません。そこで出てくるのが点付きのリッジプロットです。HDI_2018の個々の値を点で出力するにはjittered_points = TRUEを指定するだけです。これだけで密度曲線の内側に点が若干のズレ付き（jitter）で出力されます。ただし、密度曲線がオーバーラップされるリッジプロットの特徴を考えると、グループごとに点の色分けをする必要があります（同じ色になると、どのグループの点かが分からなくなるので）。この場合、point_colorに対し、グループ変数（Continent）をマッピングします。また、密度曲線の色と合わせるために密度曲線の色塗りもfillで指定します。\n\nCountry_df %>%\n  ggplot() +\n  geom_density_ridges(aes(x = HDI_2018, y = Continent, fill = Continent,\n                          point_color = Continent), \n                      alpha = 0.5, jittered_points = TRUE) +\n  guides(fill = \"none\", point_color = \"none\") + # 凡例を削除\n  labs(x = \"2018年人間開発指数\", y = \"大陸\") +\n  theme_minimal(base_size = 12)\n\nPicking joint bandwidth of 0.054\n\n\nWarning: Removed 6 rows containing non-finite values (stat_density_ridges).\n\n\n\n\n\n\n\n\n　他にも密度曲線の下側にラグプロットを付けることも可能です。こうすれば点ごとに色訳をする必要もなくなります。ラグプロットを付けるためには点の形（point_shape）を「|」にする必要があります。ただ、これだけだと「|」が密度曲線内部に散らばる（jittered）だけです。散らばりをなくす、つまり密度曲線の下段に固定する必要があり、これはaes()その外側にposition = position_points_jitter(width = 0, height = 0)を指定することで出来ます。\n\nCountry_df %>%\n  ggplot() +\n  geom_density_ridges(aes(x = HDI_2018, y = Continent, fill = Continent), \n                      alpha = 0.5, jittered_points = TRUE,\n                      position = position_points_jitter(width = 0, height = 0),\n                      point_shape = \"|\", point_size = 3) +\n  guides(fill = \"none\") +\n  labs(x = \"2018年人間開発指数\", y = \"大陸\") +\n  theme_minimal(base_size = 12)\n\nPicking joint bandwidth of 0.054\n\n\nWarning: Removed 6 rows containing non-finite values (stat_density_ridges).\n\n\n\n\n\n\n\n\n　最後に密度曲線でなく、ヒストグラムで示す方法を紹介します。これはgeom_density_ridges()の内部にstat = \"binline\"を指定するだけです。\n\nCountry_df %>%\n  ggplot() +\n  geom_density_ridges(aes(x = HDI_2018, y = Continent), alpha = 0.5,\n                      stat = \"binline\") +\n  labs(x = \"2018年人間開発指数\", y = \"大陸\") +\n  theme_minimal(base_size = 12)\n\n`stat_binline()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 6 rows containing non-finite values (stat_binline)."
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-pointrange",
    "href": "visualization4.html#RN4Esec-visual4-pointrange",
    "title": "20  可視化 [発展]",
    "section": "\n20.5 エラーバー付き散布図",
    "text": "20.5 エラーバー付き散布図\n　エラーバー付きの散布図は推定結果の点推定値とその不確実性（信頼区間など）を示す際によく使われる図です。以下の表はCountry_dfを用い、大陸（オセアニアを除く）ごとにフリーダムハウス・スコア（FH_Total）を一人当たりPPP GDP（PPP_per_capita）に回帰させた分析から得られたフリーダムハウス・スコア（FH_Total）の係数（以下の式の\\(\\beta_1\\)）の点推定値と95%信頼区間です。\n\\[\n\\text{PPP per capita} = \\beta_0 + \\beta_1 \\cdot \\text{FH}\\_\\text{Total} + \\varepsilon\n\\]\n\n\n\n\nPointrange_df <- tibble(\n    Continent = c(\"Asia\", \"Europe\", \"Africa\", \"America\"),\n    Coef      = c(65.3, 588.0, 53.4, 316.0),\n    Conf_lwr  = c(-250.0, 376.0, -14.5, 128.0),\n    Conf_upr  = c(380.0, 801.0, 121.0, 504.0)\n)\n\n\nPointrange_df\n\n# A tibble: 4 × 4\n# Groups:   Continent [4]\n  Continent  Coef Conf_lwr Conf_upr\n  <chr>     <dbl>    <dbl>    <dbl>\n1 Asia       65.3   -250.      380.\n2 Europe    588.     376.      801.\n3 Africa     53.4    -14.5     121.\n4 America   316.     128.      504.\n\n\n　実は以上のデータは以下のようなコードで作成されています。{purrr}パッケージの使い方に慣れる必要があるので、第27章を参照してください。\n\nPointrange_df <- Country_df %>%\n    filter(Continent != \"Oceania\") %>%\n    group_by(Continent) %>%\n    nest() %>%\n    mutate(Fit = map(data, ~lm(PPP_per_capita ~ FH_Total, data = .)),\n           Est = map(Fit, broom::tidy, conf.int = TRUE)) %>%\n    unnest(Est) %>%\n    filter(term == \"FH_Total\") %>%\n    select(Continent, Coef = estimate, \n           Conf_lwr = conf.low, Conf_upr = conf.high) \n\n　このPointrange_dfを用いて横軸は大陸（Continent）、縦軸には点推定値（Coef）と95%信頼区間（Conf_lwrとConf_upr）を出力します。ここで使う幾何オブジェクトはgeom_pointrange()です。横軸xと点推定値y、95%信頼区間の下限のymin、上限のymaxにマッピングします。エラーバー付き散布図を縦に並べたい場合はyとx、xmin、xmaxにマッピングします。\n\nPointrange_df %>%\n    ggplot() +\n    geom_hline(yintercept = 0, linetype = 2) +\n    geom_pointrange(aes(x = Continent, y = Coef, \n                        ymin = Conf_lwr, ymax = Conf_upr),\n                    size = 0.75, linewidth = 0.75) +\n    labs(y = expression(paste(beta[1], \" with 95% CI\"))) +\n    theme_bw(base_size = 12)\n\n\n\n\n\n\n\n　点の大きさと線の太さはそれぞれsizeとlinewidthで調整できます。どれも既定値は0.5です。\n　ここでもう一つの次元を追加することもあるでしょう。たとえば、複数のモデルを比較した場合がそうかもしれません。以下のPointrange_df2について考えてみましょう。\n\n\n\n\nPointrange_df2 <- tibble(\n    Continent = rep(c(\"Asia\", \"Europe\", \"Africa\", \"America\"), each = 2),\n    Term      = rep(c(\"Civic Liverty\", \"Political Right\"), 4),\n    Coef      = c(207.747, 29.188, 1050.164, 1284.101,\n                  110.025, 93.537, 581.4593, 646.9211),\n    Conf_lwr  = c(-385.221, -609.771, 692.204, 768.209,\n                  -12.648, -53.982, 262.056, 201.511),\n    Conf_upr  = c(800.716, 668.147, 1408.125, 1801.994,\n                  232.697, 241.057, 900.863, 1092.331))\n\n\nPointrange_df2\n\n# A tibble: 8 × 5\n# Groups:   Continent [4]\n  Continent Term              Coef Conf_lwr Conf_upr\n  <chr>     <chr>            <dbl>    <dbl>    <dbl>\n1 Asia      Civic Liberty    208.    -385.      801.\n2 Asia      Political Right   29.2   -610.      668.\n3 Europe    Civic Liberty   1050.     692.     1408.\n4 Europe    Political Right 1285.     768.     1802.\n5 Africa    Civic Liberty    110.     -12.6     233.\n6 Africa    Political Right   93.5    -54.0     241.\n7 America   Civic Liberty    581.     262.      901.\n8 America   Political Right  647.     202.     1092.\n\n\n　このデータは以下の2つのモデルを大陸ごとに推定した\\(\\beta_1\\)と\\(\\gamma_1\\)の点推定値と95%信頼区間です。\n\\[\n\\begin{aligned}\n\\text{PPP per capita} & = \\beta_0 + \\beta_1 \\cdot \\text{FH}\\_\\text{CL} + \\varepsilon \\\\\n\\text{PPP per capita} & = \\gamma_0 + \\gamma_1 \\cdot \\text{FH}\\_\\text{PR} + \\upsilon\n\\end{aligned}\n\\]\n　どの説明変数を用いたかでエラーバーと点の色分けを行う場合、colorに対してTermをマッピングします。\n\nPointrange_df2 %>%\n    ggplot() +\n    geom_hline(yintercept = 0, linetype = 2) +\n    geom_pointrange(aes(x = Continent, y = Coef, \n                        ymin = Conf_lwr, ymax = Conf_upr,\n                        color = Term), \n                    size = 0.75, linewidth = 0.75) +\n    labs(y = expression(paste(beta[1], \" and \", gamma[1], \" with 95% CI\")),\n         color = \"\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n　何か違いますね。この2つのエラーバーと点の位置をずらす必要があるようです。これは3次元以上の棒グラフで使ったposition引数で調整可能です。今回は実引数としてposition_dodge(0.5)を指定してみましょう。\n\nPointrange_df2 %>%\n    ggplot() +\n    geom_hline(yintercept = 0, linetype = 2) +\n    geom_pointrange(aes(x = Continent, y = Coef, \n                        ymin = Conf_lwr, ymax = Conf_upr,\n                        color = Term),\n                    size = 0.75, linewidth = 0.75,\n                    position = position_dodge(0.5)) +\n    labs(y = expression(paste(beta[1], \" and \", gamma[1], \" with 95% CI\")),\n         color = \"\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n　これで完成です。更に、\\(\\alpha = 0.05\\)水準で統計的に有意か否かを透明度で示し、透明度の凡例を非表示にしてみましょう。\\(\\alpha = 0.05\\)水準で統計的に有意か否かは95%信頼区間の上限と下限の積が0より大きいか否かで判定できます。ggplot()にデータを渡す前に統計的有意か否かを意味するSig変数を作成し、geom_pointrage()の内部ではalphaにSigをマッピングします。\n\nPointrange_df2 %>%\n    mutate(Sig = if_else(Conf_lwr * Conf_upr > 0, \n                         \"Significant\", \"Insignificant\")) %>%\n    ggplot() +\n    geom_hline(yintercept = 0, linetype = 2) +\n    geom_pointrange(aes(x = Continent, y = Coef, \n                        ymin = Conf_lwr, ymax = Conf_upr,\n                        color = Term, alpha = Sig),\n                    size = 0.75, linewidth = 0.75,\n                    position = position_dodge(0.5)) +\n    labs(y = expression(paste(beta[1], \" and \", gamma[1], \" with 95% CI\")),\n         color = \"\") +\n    scale_alpha_manual(values = c(\"Significant\" = 1, \"Insignificant\" = 0.35)) +\n    guides(alpha = \"none\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n　区間を単なる線ではなく、上限と下限に「-」を付ける場合は、geom_point()とgeom_errorbar()を組み合わせます。geom_errorbar()はgeom_pointrange()から点がなくなったものになるため、yへのマッピングは不要です。また、上限と下限に着く水平線の幅はwidthで調整します。既定値のままだとかなり広めになるため、適宜調整しましょう。\n\nPointrange_df2 %>%\n    mutate(Sig = if_else(Conf_lwr * Conf_upr > 0, \n                         \"Significant\", \"Insignificant\")) %>%\n    ggplot(aes(x = Continent, color = Term, alpha = Sig)) +\n    geom_hline(yintercept = 0, linetype = 2) +\n    geom_point(aes(y = Coef), \n               size = 3, position = position_dodge(0.5)) +\n    geom_errorbar(aes(ymin = Conf_lwr, ymax = Conf_upr),\n                  linewidth = 0.75, width = 0.15,\n                  position = position_dodge(0.5)) +\n    labs(y = expression(paste(beta[1], \" and \", gamma[1], \" with 95% CI\")),\n         color = \"\") +\n    scale_alpha_manual(values = c(\"Significant\" = 1, \"Insignificant\" = 0.35)) +\n    guides(alpha = \"none\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-lollipop",
    "href": "visualization4.html#RN4Esec-visual4-lollipop",
    "title": "20  可視化 [発展]",
    "section": "\n20.6 ロリーポップチャート",
    "text": "20.6 ロリーポップチャート\n　ロリーポップチャートは棒グラフの特殊な形態であり、棒がロリーポップ（チュッパチャップス）の形をしているものを指します。したがって、2つの図は本質的に同じですが、棒が多い場合はロリーポップチャートを使うケースがあります。棒が非常に多い棒グラフの場合、図を不適切に縮小するとモアレが生じるケースがあるからです。\n　まず、Country_dfを用い、ヨーロッパ諸国の一人当たりPPP GDP（PPP_per_capita）の棒グラフを作るとします。PPP_per_capitaが欠損していないヨーロッパの国は46行であり、非常に棒が多い棒グラフになります。\n\nCountry_df %>%\n  filter(Continent == \"Europe\") %>%\n  drop_na(PPP_per_capita) %>%\n  ggplot() +\n  geom_bar(aes(y = Country, x = PPP_per_capita), stat = \"identity\") +\n  labs(x = \"一人あたり購買力平価GDP\", y = \"国\") +\n  theme_bw(base_size = 12)\n\n\n\n\n\n\n\nここで登場するのがロリーポップチャートです。ロリーポップチャートの構成要素は棒とキャンディーの部分です。棒は線になるためgeom_segement()を、キャンディーは散布図geom_point()を使います。散布図については既に第18章で説明しましたので、ここではgeom_segment()について説明します。\n　geom_segment()は直線を引く幾何オブジェクトであり、線の起点（xとy）と終点（xendとyend）に対してマッピングをする必要があります。横軸上の起点は0、縦軸上の起点はCountryです。そして横軸上の終点はPPP_per_capita、縦軸上のそれはCountryです。縦軸上の起点と終点が同じということは水平線を引くことになります。\n　geom_segment()で水平線を描いたら、次は散布図をオーバーラップさせます。点の横軸上の位置はPPP_per_capita、縦軸上の位置はCountryです。\n\nCountry_df %>%\n  filter(Continent == \"Europe\") %>%\n  drop_na(PPP_per_capita) %>%\n  ggplot() +\n  geom_segment(aes(y = Country, yend = Country,\n                   x = 0, xend = PPP_per_capita)) +\n  geom_point(aes(y = Country, x = PPP_per_capita), color = \"orange\") +\n  labs(x = \"一人あたり購買力平価GDP (USD)\", y = \"国\") +\n  theme_bw(base_size = 12) +\n  theme(panel.grid.major.y = element_blank(),\n        panel.border = element_blank(),\n        axis.ticks.y = element_blank())\n\n\n\n\n\n\n\n　これで完成です。もし一人当たりPPP GDP順で並べ替えたい場合はfct_reorder()を使います。CountryをPPP_per_capitaの低い方を先にくるようにするなら、fct_reorder(Country, PPP_per_capita)です。縦に並ぶの棒グラフなら最初に来る水準が下に位置されます。もし、順番を逆にしたいなら、更にfct_rev()で水準の順番を逆転させます。\n\nCountry_df %>%\n  filter(Continent == \"Europe\") %>%\n  drop_na(PPP_per_capita) %>%\n  mutate(Country = fct_reorder(Country, PPP_per_capita)) %>% \n  ggplot() +\n  geom_segment(aes(y = Country, yend = Country,\n                   x = 0, xend = PPP_per_capita)) +\n  geom_point(aes(y = Country, x = PPP_per_capita), color = \"orange\") +\n  labs(x = \"一人あたり購買力平価GDP (USD)\", y = \"国\") +\n  theme_bw(base_size = 12) +\n  theme(panel.grid.major.y = element_blank(),\n        panel.border = element_blank(),\n        axis.ticks.y = element_blank())\n\n\n\n\n\n\n\n　ロリーポップロリーポップチャートで次元を追加するには点（キャンディー）の色分けが考えられます。たとえば、OECD加盟国か否かの次元を追加する場合、geom_point()においてcolorをマッピングするだけです。\n\nCountry_df %>%\n  filter(Continent == \"Europe\") %>%\n  drop_na(PPP_per_capita) %>%\n  mutate(Country = fct_reorder(Country, PPP_per_capita),\n         OECD    = if_else(OECD == 1, \"OECD\", \"non-OECD\"),\n         OECD    = factor(OECD, levels = c(\"OECD\", \"non-OECD\"))) %>% \n  ggplot() +\n  geom_segment(aes(y = Country, yend = Country,\n                   x = 0, xend = PPP_per_capita)) +\n  geom_point(aes(y = Country, x = PPP_per_capita, color = OECD)) +\n  scale_color_manual(values = c(\"OECD\" = \"orange\", \"non-OECD\" = \"royalblue\")) +\n  labs(x = \"一人あたり購買力平価GDP (USD)\", y = \"国\", color = \"\") +\n  theme_bw(base_size = 12) +\n  theme(panel.grid.major.y = element_blank(),\n        panel.border       = element_blank(),\n        axis.ticks.y       = element_blank(),\n        legend.position    = \"bottom\")\n\n\n\n\n\n\n\n　ファセット分割ももちろんできますが、この場合、OECD加盟国の一人当たりPPP GDPが相対的に高いことを示すなら、一つのファセットにまとめた方が良いでしょう。\n　以下のようにロリーポップを横に並べることもできますが、棒の数が多いケースがほとんどであるロリーポップチャートではラベルの回転が必要になるため、読みにくくなるかも知れません。\n\nCountry_df %>%\n  filter(Continent == \"Europe\") %>%\n  drop_na(PPP_per_capita) %>%\n  mutate(Country = fct_reorder(Country, PPP_per_capita),\n         Country = fct_rev(Country)) %>% \n  ggplot() +\n  geom_segment(aes(x = Country, xend = Country,\n                   y = 0, yend = PPP_per_capita)) +\n  geom_point(aes(x = Country, y = PPP_per_capita), color = \"orange\") +\n  labs(x = \"国\", y = \"一人あたり購買力平価GDP (USD)\") +\n  theme_bw(base_size = 12) +\n  theme(panel.grid.major.y = element_blank(),\n        panel.border = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-smooth",
    "href": "visualization4.html#RN4Esec-visual4-smooth",
    "title": "20  可視化 [発展]",
    "section": "\n20.7 平滑化ライン",
    "text": "20.7 平滑化ライン\n2次元平面上に散布図をプロットし、二変数間の関係を一本の線で要約するのは平滑化ラインです。{ggplot2}ではgeom_smooth()幾何オブジェクトを重ねることで簡単に平滑化ラインをプロットすることができます。まずは、横軸をフリーダムハウス・スコア（FH_Total）、縦軸を一人当たり購買力平価GDP（PPP_per_capita）にした散布図を出力し、その上に平滑化ラインを追加してみましょう。geom_smooth()にもマッピングが必要で、aes()の内部にxとyをマッピングします。今回はgeom_point()とgeom_smooth()が同じマッピング情報を共有するため、ggplot()内部でマッピングします。\n\nCountry_df %>%\n    ggplot(aes(x = FH_Total, y = PPP_per_capita)) +\n    geom_point() +\n    geom_smooth()  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n　青い線が平滑化ライン、網掛けの領域が95%信頼区間です。この線はLOESS (LOcal Estimated Scatterplot Smoothing)と呼ばれる非線形平滑化ラインです。どのようなラインを引くかはmethod引数で指定しますが、このmethod既定値が\"loess\"です。これを見るとフリーダムハウス・スコアが75以下の国では国の自由度と所得間の関係があまり見られませんが、75からは正の関係が確認できます。\n　LOESS平滑化の場合、span引数を使って滑らかさを調整することができます。spanの既定値は0.75ですが、これが小さいほど散布図によりフィットしたラインが引かれ、よりギザギザな線になります。たとえば、spanを0.25にすると以下のようなグラフが得られます。\n\nCountry_df %>%\n    ggplot(aes(x = FH_Total, y = PPP_per_capita)) +\n    geom_point() +\n    geom_smooth(method = \"loess\", span = 0.25)  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n　他にも定番の回帰直線を引くこともできます。methodの実引数を\"lm\"に変えるだけです。\n\nCountry_df %>%\n    ggplot(aes(x = FH_Total, y = PPP_per_capita)) +\n    geom_point() +\n    geom_smooth(method = \"lm\")  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n　信頼区間は既定値だと95%信頼区間が表示されますが、level引数で調整することができます。たとえば、99.9%信頼区間を表示したい場合、level = 0.999を指定します。\n\nCountry_df %>%\n    ggplot(aes(x = FH_Total, y = PPP_per_capita)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", level = 0.999)  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n　信頼区間を消したい場合はse = FALSEを指定します（既定値はTRUE）。\n\nCountry_df %>%\n    ggplot(aes(x = FH_Total, y = PPP_per_capita)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE)  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n　最後にデータのサブセットごとに回帰直線を引く方法について説明します。散布図で色分けを行う場合、aes()内でcolor引数を指定しますが、これだけで十分です。今回はこれまでの散布図をOECD加盟有無ごとに色分けし、それぞれ別の回帰直線を重ねてみましょう。回帰直線も色分けしたいのでcolor引数で次元を増やす必要があり、これはgeom_point()と共通であるため、ggplot()内でマッピングします。\n\nCountry_df %>%\n    mutate(OECD = if_else(OECD == 1, \"加盟国\", \"非加盟国\")) %>%\n    ggplot(aes(x = FH_Total, y = PPP_per_capita, color = OECD)) +\n    geom_point() +\n    geom_smooth(method = \"lm\")  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    coord_cartesian(ylim = c(0, 120000)) +\n    theme_bw(base_size = 12)\n\n\n\n\n\n\n\n　これを見ると、国の自由度と所得の間に関係が見られるのはOECD加盟国で、非加盟国では非常に関係が弱いことが分かります。\n　あまりいい方法ではないと思いますが、散布図は色（color）で分け、回帰直線は線の種類（linetype）で分けるならどうすれば良いでしょうか。この場合はcolorはgeom_point()内部で、linetypeはgeom_smooth()でマッピングします。\n\nCountry_df %>%\n    mutate(OECD = if_else(OECD == 1, \"加盟国\", \"非加盟国\")) %>%\n    ggplot(aes(x = FH_Total, y = PPP_per_capita)) +\n    geom_point(aes(color = OECD)) +\n    geom_smooth(aes(linetype = OECD), method = \"lm\", color = \"black\")  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    coord_cartesian(ylim = c(0, 120000)) +\n    theme_bw(base_size = 12)\n\n\n\n\n\n\n\n　{ggplot2}が提供する平滑化ラインにはLOESSと回帰直線以外にも\"glm\"や\"gam\"などがります。詳細はRコンソール上で?geom_smoothを入力し、ヘルプを参照してください。"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-text",
    "href": "visualization4.html#RN4Esec-visual4-text",
    "title": "20  可視化 [発展]",
    "section": "\n20.8 文字列の出力",
    "text": "20.8 文字列の出力\n　ここでは図の中に文字列を追加する方法について解説します。\n　まずは、geom_text()からです。これはマッピングされたxとyの箇所に文字列を付ける帰化オブジェクトです。たとえば、Country_dfを用い、大陸（Continent）ごとに人間開発指数（HDI_2018）の平均値を棒グラフで示してみましょう。\n\nbar_plot <- Country_df %>%\n  group_by(Continent) %>%\n  summarise(HDI = mean(HDI_2018, na.rm = TRUE)) %>%\n  ggplot() +\n  geom_bar(aes(x = Continent, y = HDI), stat = \"identity\") +\n  labs(x = \"Continent\", y = \"Mean of\\nHuman Development Index (2018)\") +\n  theme_minimal(base_size = 12)\n\nbar_plot\n\n\n\n\n\n\n\n　この棒の上に具体的な平均値を追加するとしましょう。数字が位置する箇所は棒グラフの横軸上の位置（x）、棒グラフの高さ（y）と一致するため、xとyはそれぞれContinentとHDIでマッピングします。そして、出力する内容をlabelにマッピングします。ここではHDIの値をそのまま出力するので、label = HDIです。\n\nbar_plot +\n  geom_text(aes(x = Continent, y = HDI, label = HDI),\n            size = 4)\n\n\n\n\n\n\n\n　ただし、棒と文字が重なり、やや読みにくいですね。しかも小数点も3桁くらいで十分でしょう。文字の位置をやや高めにするためにy = HDIをy = HDI + 0.03に調整します。また、小数点を丸めるためにlabel = round(HDI, 3)にへんこうします。ただし、round()を使う場合、round(1.1298, 3)は1.13と出力されます。もし、1.130のように出力したい場合はround()の代わりに、第10章でも紹介しましたsprintf()を使用します。今回の例の場合、sprintf(\"%.3f\", 1.1298)のように書きます。\n\nbar_plot +\n  geom_text(aes(x = Continent, y = HDI + 0.03, label = round(HDI, 3)),\n            size = 4)\n\n\n\n\n\n\n\n　geom_text()とほぼ同じ機能を持つ帰化オブジェクトとしてgeom_label()があります。これは使うと文字列が四角に囲まれた形式で出力されます。見出し紙のようなものであり、使い方はgeom_text()と同じです。\n\nbar_plot +\n  geom_label(aes(x = Continent, y = HDI, label = round(HDI, 3)),\n             size = 4)\n\n\n\n\n\n\n\n　続いて、マッピングを行わず、任意の位置に文字列を出力するannotate()です。こちらはマッピングが必要ありません。まず、Contury_dfを用い、フリーダムハウス・スコア（FH_Total）と一人あたり購買力平価GDP（PPP_per_capita）の散布図と回帰直線を出してみましょう。\n\nlm_plot <- Country_df %>%\n    ggplot(aes(x = FH_Total, y = PPP_per_capita)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", level = 0.999)  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    theme_minimal(base_size = 12)\n\n　ここに「注: 青い線は回帰直線を表す。」という文字列を追加します。位置はx = 0、y = 110000とします。まず、annotate()の第一引数として\"text\"を指定します2。そして、xとyに文字列の位置を指定し、labelに出力する文字列を入力します。そして、hjust = 0で文字列を左側に寄せます。これを指定しないと、文字列の真ん中がx = 0に位置することになります。最後にsizeで文字列の大きさを指定します。\n\nlm_plot +\n  annotate(\"text\", x = 0, y = 110000, label = \"注: 青い線は回帰直線を表す。\", \n           hjust = 0, size = 5)\n\n\n\n\n\n\n\n　図の中に数式を入れる時にはRが提供するexpression()関数を使うことも出来ますが、LaTeX文法で数式が入力できる{latex2exp}パッケージはが便利です。使い方は単純で{latex2exp}を読み込み、label引数の実引数を指定する時にTex(\"$LaTeX文法の数式$\")を使うだけです。\"\"の中に数式が入りますが更に$で囲んでください。また、LaTeX文法の数式における\\は\\\\に置換する必要があります。。\n\npacman::p_load(latex2exp)\n\nlm_plot +\n  annotate(\"text\", x = 0, y = 110000, \n           label = TeX(\"$PPP\\\\_per\\\\_capita = \\\\alpha + \\\\beta \\\\cdot Freedom\\\\_House\\\\_Score + \\\\epsilon \\\\ where \\\\ \\\\epsilon \\\\sim Normal(0, \\\\sigma).$\"), \n           hjust = 0, size = 5)"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-heatmap",
    "href": "visualization4.html#RN4Esec-visual4-heatmap",
    "title": "20  可視化 [発展]",
    "section": "\n20.9 ヒートマップ",
    "text": "20.9 ヒートマップ\n\n20.9.1 2つの離散変数の分布を表すヒートマップ\n　ヒートマップ（heat map）には2つの使い方があります。まずは、離散変数\\(\\times\\)離散変数の同時分布を示す時です。これは後ほど紹介するモザイク・プロットと目的は同じですが、モザイク・プロットはセルの面積で密度や度数を表すに対し、ヒートマップは主に色で密度や度数を表します。\n　ここでは一人当たり購買力平価GDP（PPP_per_capita）を「1万ドル未満」、「1万ドル以上・2万ドル未満」、「2万ドル以上、3万ドル未満」、「3万ドル以上」の離散変数に変換し、大陸ごとの国家数をヒートマップとして示してみたいと思います。まずは、変数のリコーディングをし、全てfactor化します。最後に国家名（Country）、大陸（Continent）、所得（Income）、フリーダム・ハウス・スコア（FH_Total）、人間開発指数（HDI_2018）列のみ抽出し、Heatmap_dfという名のオブジェクトとして格納しておきます。\n\nHeatmap_df <- Country_df %>%\n  filter(!is.na(PPP_per_capita)) %>%\n  mutate(Continent = recode(Continent,\n                            \"Africa\"  = \"アフリカ\",\n                            \"America\" = \"アメリカ\",\n                            \"Asia\"    = \"アジア\",\n                            \"Europe\"  = \"ヨーロッパ\",\n                            .default  = \"オセアニア\"),\n         Continent = factor(Continent, levels = c(\"アフリカ\", \"アメリカ\", \"アジア\", \n                                                  \"ヨーロッパ\", \"オセアニア\")),\n         Income    = case_when(PPP_per_capita < 10000 ~ \"1万ドル未満\",\n                               PPP_per_capita < 20000 ~ \"1万ドル以上\\n2万ドル未満\",\n                               PPP_per_capita < 30000 ~ \"2万ドル以上\\n3万ドル未満\",\n                               TRUE                   ~ \"3万ドル以上\"),\n         Income    = factor(Income, levels = c(\"1万ドル未満\", \"1万ドル以上\\n2万ドル未満\",\n                                               \"2万ドル以上\\n3万ドル未満\", \"3万ドル以上\"))) %>%\n  select(Country, Continent, Income, FH_Total, HDI_2018)\n\nHeatmap_df\n\n# A tibble: 178 × 5\n   Country             Continent  Income                     FH_Total HDI_2018\n   <chr>               <fct>      <fct>                         <dbl>    <dbl>\n 1 Afghanistan         アジア     \"1万ドル未満\"                    27    0.496\n 2 Albania             ヨーロッパ \"1万ドル以上\\n2万ドル未満\"       67    0.791\n 3 Algeria             アフリカ   \"1万ドル以上\\n2万ドル未満\"       34    0.759\n 4 Angola              アフリカ   \"1万ドル未満\"                    32    0.574\n 5 Antigua and Barbuda アメリカ   \"2万ドル以上\\n3万ドル未満\"       85    0.776\n 6 Argentina           アメリカ   \"2万ドル以上\\n3万ドル未満\"       85    0.83 \n 7 Armenia             ヨーロッパ \"1万ドル以上\\n2万ドル未満\"       53    0.76 \n 8 Australia           オセアニア \"3万ドル以上\"                    97    0.938\n 9 Austria             ヨーロッパ \"3万ドル以上\"                    93    0.914\n10 Azerbaijan          ヨーロッパ \"1万ドル以上\\n2万ドル未満\"       10    0.754\n# … with 168 more rows\n\n\n　次はgroup_by()とsummarise()を使って、各カテゴリーに属するケース数を計算し、Nという名の列として追加します。\n\nHeatmap_df1 <- Heatmap_df %>%\n  group_by(Continent, Income) %>%\n  summarise(N       = n(),\n            .groups = \"drop\")\n\nHeatmap_df1\n\n# A tibble: 18 × 3\n   Continent  Income                         N\n   <fct>      <fct>                      <int>\n 1 アフリカ   \"1万ドル未満\"                 41\n 2 アフリカ   \"1万ドル以上\\n2万ドル未満\"     9\n 3 アフリカ   \"2万ドル以上\\n3万ドル未満\"     2\n 4 アメリカ   \"1万ドル未満\"                 10\n 5 アメリカ   \"1万ドル以上\\n2万ドル未満\"    14\n 6 アメリカ   \"2万ドル以上\\n3万ドル未満\"     6\n 7 アメリカ   \"3万ドル以上\"                  5\n 8 アジア     \"1万ドル未満\"                 17\n 9 アジア     \"1万ドル以上\\n2万ドル未満\"    10\n10 アジア     \"2万ドル以上\\n3万ドル未満\"     3\n11 アジア     \"3万ドル以上\"                 11\n12 ヨーロッパ \"1万ドル未満\"                  1\n13 ヨーロッパ \"1万ドル以上\\n2万ドル未満\"    10\n14 ヨーロッパ \"2万ドル以上\\n3万ドル未満\"     7\n15 ヨーロッパ \"3万ドル以上\"                 28\n16 オセアニア \"1万ドル未満\"                  1\n17 オセアニア \"1万ドル以上\\n2万ドル未満\"     1\n18 オセアニア \"3万ドル以上\"                  2\n\n\n　これでデータの準備は終わりました。ヒートマップを作成する幾何オブジェクトはgeom_tile()です。同時分布を示したい変数を、それぞれxとyにマッピングし、密度、または度数を表す変数をfillにマッピングします。ここでは横軸を大陸（Continent）、縦軸を一人当たり購買力平価GDP（Income）とし、fillにはN変数をマッピングします。\n\nHeatmap_df1 %>%\n  ggplot() +\n  geom_tile(aes(x = Continent, y = Income, fill = N)) +\n  labs(x = \"大陸\", y = \"一人当たり購買力平価GDP（ドル）\", fill = \"国家数\") +\n  theme_bw(base_size = 12) +\n  theme(panel.grid = element_blank()) # グリッドラインを消す\n\n\n\n\n\n\n\n　明るいほどカテゴリーに属するケースが多く、暗いほど少ないことを意味します。これを見ると世界で最も多くの割合を占めているのは、一人当たり購買力平価GDPが1万ドル未満のアフリカの国で、次は一人当たり購買力平価GDPが3万ドル以上のヨーロッパの国であることが分かります。欠損している（ケース数が0）セルは白の空白となります。\n　色をカスタマイズするにはscale_fill_gradient()です。これは第19章で紹介しましたscale_color_gradient()と使い方は同じです。scale_fill_gradient()は中間点なし、scale_fill_gradient2()は中間点ありの場合に使いますが、ここでは度数が小さい場合はcornsilk色を、大きい場合はbrown3色を使います。それぞれlowとhighに色を指定するだけです。\n\nHeatmap_df1 %>%\n  ggplot() +\n  geom_tile(aes(x = Continent, y = Income, fill = N)) +\n  labs(x = \"大陸\", y = \"一人当たり購買力平価GDP（ドル）\", fill = \"国家数\") +\n  scale_fill_gradient(low  = \"cornsilk\", \n                      high = \"brown3\") +\n  theme_bw(base_size = 12) +\n  theme(panel.grid = element_blank()) # グリッドラインを消す\n\n\n\n\n\n\n\n　気のせいかも知れませんが、先ほどよりは読みやすくなったような気がしますね。\n\n20.9.2 離散変数\\(\\times\\)離散変数における連続変数の値を示すヒートマップ\n　次は、離散変数\\(\\times\\)離散変数における連続変数の値を示すヒートマップを作ってみましょう。ヒートマップにおけるそれぞれのタイル（tile）は横軸上の位置と縦軸上の位置情報を持ち、これは前回と同様、離散変数でマッピングされます。そして、タイルの色は何らかの連続変数にマッピングされます。前回作成しましたヒートマップは度数、または密度であり、これも実は連続変数だったので、図の作り方は本質的には同じです。\n　ここでは大陸と所得ごとに人間開発指数の平均値を表すヒートマップを作ってみましょう。大陸（Continent）と所得（Income）でグループ化し、人間開発指数（HDI_2018）の平均値を計算したものをHeatmap_df2という名のオブジェクトとして格納します。\n\nHeatmap_df2 <- Heatmap_df %>%\n  group_by(Continent, Income) %>%\n  summarise(HDI     = mean(HDI_2018, na.rm = TRUE),\n            .groups = \"drop\")\n\nHeatmap_df2\n\n# A tibble: 18 × 3\n   Continent  Income                       HDI\n   <fct>      <fct>                      <dbl>\n 1 アフリカ   \"1万ドル未満\"              0.510\n 2 アフリカ   \"1万ドル以上\\n2万ドル未満\" 0.697\n 3 アフリカ   \"2万ドル以上\\n3万ドル未満\" 0.798\n 4 アメリカ   \"1万ドル未満\"              0.638\n 5 アメリカ   \"1万ドル以上\\n2万ドル未満\" 0.752\n 6 アメリカ   \"2万ドル以上\\n3万ドル未満\" 0.806\n 7 アメリカ   \"3万ドル以上\"              0.841\n 8 アジア     \"1万ドル未満\"              0.624\n 9 アジア     \"1万ドル以上\\n2万ドル未満\" 0.730\n10 アジア     \"2万ドル以上\\n3万ドル未満\" 0.818\n11 アジア     \"3万ドル以上\"              0.872\n12 ヨーロッパ \"1万ドル未満\"              0.711\n13 ヨーロッパ \"1万ドル以上\\n2万ドル未満\" 0.776\n14 ヨーロッパ \"2万ドル以上\\n3万ドル未満\" 0.827\n15 ヨーロッパ \"3万ドル以上\"              0.902\n16 オセアニア \"1万ドル未満\"              0.543\n17 オセアニア \"1万ドル以上\\n2万ドル未満\" 0.724\n18 オセアニア \"3万ドル以上\"              0.930\n\n\n　作図の方法は前回と同じですが、今回はタイルの色塗り（fill）を人間開発指数の平均値（HDI）でマッピングする必要があります。他の箇所は同じコードでも良いですが、ここでは色塗りの際、中間点を指定してみましょう。たとえば人間開発指数が0.75なら色をcornsilk色とし、これより低いっほどcornflowerblue色に、高いほどbrown3色になるように指定します。中間点を持つグラデーション色塗りはscale_fill_gradient2()で調整することができます。使い方はscale_fill_gradient()とほぼ同じですが、中間点の色（mid）と中間点の値（midpoint）をさらに指定する必要があります。\n\nHeatmap_df2 %>%\n  ggplot() +\n  geom_tile(aes(x = Continent, y = Income, fill = HDI)) +\n  labs(x = \"大陸\", y = \"一人当たり購買力平価GDP（ドル）\", \n       fill = \"人間開発指数の平均値 (2018)\") +\n  scale_fill_gradient2(low  = \"cornflowerblue\", \n                       mid  = \"cornsilk\",\n                       high = \"brown3\",\n                       midpoint = 0.75) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\",\n        panel.grid      = element_blank())"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-contour",
    "href": "visualization4.html#RN4Esec-visual4-contour",
    "title": "20  可視化 [発展]",
    "section": "\n20.10 等高線図",
    "text": "20.10 等高線図\n　ヒートマップを使えば、離散変数\\(\\times\\)離散変数の同時分布を可視化することは出来ますが、連続変数\\(\\times\\)連続変数の同時分布を可視化するには限界があります。むろん、一つ一つのタイルを小さくすることも出来ますが、効率的な方法ではないでしょう。ここで活躍するのが等高線図 (contour plot) です。\n　たとえば、Country_dfのFH_TotalとHDI_2018の分布は散布図を通じて可視化することができます。\n\nCountry_df %>%\n  ggplot() +\n  geom_point(aes(x = FH_Total, y = HDI_2018)) +\n  labs(x = \"フリーダム・ハウス・スコア\", y = \"人間開発指数 (2018)\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n　右上に点が集まっていることから、密度の高い箇所だと考えられます。この密度を示す等高線図の幾何オブジェクトはgeom_density_2d()です。マッピング要素はgeom_point()と同じなので、マッピングはggplot()内で行い、geom_density_2d()レイヤーを使いしてみましょう。\n\nCountry_df %>%\n  ggplot(aes(x = FH_Total, y = HDI_2018)) +\n  geom_point() +\n  geom_density_2d() +\n  labs(x = \"フリーダム・ハウス・スコア\", y = \"人間開発指数 (2018)\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n　密度に応じて色塗りをする場合はgeom_density_2d()の代わりにgeom_density_2d_filled()を使います。\n\nCountry_df %>%\n  ggplot(aes(x = FH_Total, y = HDI_2018)) +\n  geom_density_2d_filled() +\n  labs(x = \"フリーダム・ハウス・スコア\", y = \"人間開発指数 (2018)\",\n       fill = \"密度\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n　geom_density_2d_filled()オブジェクトの後にgeom_density_2d()オブジェクトを重ねると、区間の区画線を追加することもできます。\n\nCountry_df %>%\n  ggplot(aes(x = FH_Total, y = HDI_2018)) +\n  geom_density_2d_filled() +\n  geom_density_2d(color = \"black\") +\n  labs(x = \"フリーダム・ハウス・スコア\", y = \"人間開発指数 (2018)\",\n       fill = \"密度\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n　色が気に入らない場合、自分で調整することも可能です。scale_fill_manual()で各区間ごとの色を指定することもできませんが、あまり効率的ではありません。ここではscale_fill_brewer()関数を使って、ColorBrewerのパレットを使ってみましょう。引数なしでも使えますが、既定値のパレットは区間が9つまで対応します。今回の等高線図は全部で10区間ですので、あまり適切ではありません。ここでは11区間まで対応可能な\"Spectral\"パレットを使いますが、これはpalette引数で指定できます。\n\nCountry_df %>%\n  ggplot(aes(x = FH_Total, y = HDI_2018)) +\n  geom_density_2d_filled() +\n  scale_fill_brewer(palette = \"Spectral\") +\n  labs(x = \"フリーダム・ハウス・スコア\", y = \"人間開発指数 (2018)\",\n       fill = \"密度\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n　paletteで指定可能なカラーパレットの一覧は{RColorBrewer}のdisplay.brewer.all()関数で確認することが出来ます。各パレットが何区間まで対応できるかを見てから自分でパレットを作成することも可能ですが、詳細はネット上の各種記事を参照してください。\n\nRColorBrewer::display.brewer.all()\n\n\n\n{RColorBrewer}が提供するパレート一覧"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-map",
    "href": "visualization4.html#RN4Esec-visual4-map",
    "title": "20  可視化 [発展]",
    "section": "\n20.11 地図",
    "text": "20.11 地図\n\n20.11.1 世界地図\n{ggplot2}で地図をプロットする方法は色々あります。理想としては各国政府が提供する地図データをダウンロードし、それを読み込み・加工してプロットすることでしょうが、ここではパッケージを使ったマッピングについて紹介します。\n　今回使用するパッケージは{rnaturalearth}、{rnaturalearthdata}、{rgeos}です。他にも使うパッケージはありますが、世界地図ならとりあえずこれで十分です。\n\npacman::p_load(rnaturalearth, rnaturalearthdata, rgeos)\n\n　世界地図を読み込む関数は{rnaturalearth}が提供するne_countries()です。とりあえず指定する引数はscaleとretunrclassです。scaleは地図の解像度であり、世界地図なら\"small\"で十分です。もう少し拡大される大陸地図なら\"medium\"が、一国だけの地図なら\"large\"が良いかも知れません。reutrnclassは\"sf\"と指定します。今回は低解像度の世界地図をsfクラスで読み込んでみましょう。\n\nworld_map <- ne_countries(scale = \"small\", returnclass = \"sf\")\n\nclass(world_map)\n\n[1] \"sf\"         \"data.frame\"\n\n\n　クラスはdata.frameとsfであり、実際、world_mapを出力してみると、見た目がデータフレームであることが分かります。地図の出力はgeom_sf()幾何オブジェクトを使用します。とりあえず、やってみましょう。\n\nworld_map %>% \n  ggplot() +\n  geom_sf() +\n  theme_void() # 何もないテーマを指定する。ここはお好みで\n\n\n\n\n\n\n\n　もし、各国の人口に応じて色塗りをする場合はどうすれば良いでしょうか。実は、今回使用するデータがデータフレーム形式であることを考えると、これまでの{ggplot2}の使い方とあまり変わりません。{rnaturalearth}から読み込んだデータには既にpop_estという各国の人口データが含まれています（他にも自分で構築したデータがあるなら、データを結合して使用すれば良いですが、これについては後述します。）。この値に応じて色塗りを行うため、geom_sf()内にfill = pop_estでマッピングするだけです。また、国境線の色はcolorで指定可能です。白（\"white\"）だと少しおしゃれな感じがするのでやってみましょう。国境線は全ての国に適用されるものなので、aes()の外側で指定します。\n\nworld_map %>% \n  ggplot() +\n  geom_sf(aes(fill = pop_est), color = \"white\") +\n  # 人口が少ない国はcornflowerblue色に、多い国はbrown3色とする\n  scale_fill_gradient(low = \"cornflowerblue\", high = \"brown3\") +\n  labs(fill = \"人口\") +\n  theme_void()\n\n\n\n\n\n\n\n　もし、世界でなく一部の地域だけを出力するなら、coord_sf()で座標系を調整します。東アジアと東南アジアの一部を出力したいとします。この場合、経度は90度から150度まで、緯度は10度から50度に絞ることになります。経度はxlimで、緯度はylimで調整します。\n\nworld_map %>% \n  ggplot() +\n  geom_sf(aes(fill = pop_est)) +\n  scale_fill_gradient(low = \"cornflowerblue\", high = \"brown3\") +\n  labs(fill = \"人口\") +\n  coord_sf(xlim = c(90, 150), ylim = c(10, 50)) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n　他にもne_countries()内にcontinent引数を指定し、特定の大陸だけを読み込むことで可能です。ここではアジアの国のみを抽出し、asia_mapという名のオブジェクトとして格納します。解像度は中程度とします。\n\nasia_map <- ne_countries(scale = \"medium\", continent = \"Asia\", \n                         returnclass = \"sf\")\n\nasia_map %>%\n    ggplot() +\n    # 所得グループで色塗り\n    geom_sf(aes(fill = income_grp)) +\n    theme_void() +\n    labs(fill = \"Income Group\")\n\n\n\n\n\n\n\n　アジアの中から更に東アジアに絞りたい場合はfilter()を使用し、subregion列を基準に抽出することも可能です。\n\nasia_map %>%\n    filter(subregion == \"Eastern Asia\") %>%\n    ggplot() +\n    geom_sf(aes(fill = income_grp)) +\n    theme_void() +\n    labs(fill = \"Income Group\")\n\n\n\n\n\n\n\n　subregionの値は以下のように確認可能です。\n\nunique(asia_map$subregion)\n\n[1] \"Southern Asia\"           \"Western Asia\"           \n[3] \"South-Eastern Asia\"      \"Eastern Asia\"           \n[5] \"Seven seas (open ocean)\" \"Central Asia\"           \n\n\n　これまで使用してきたデータがデータフレームと同じ見た目をしているため、{dplyr}を用いたデータハンドリングも可能です。たとえば、人口を連続変数としてでなく、factor型に変換してからマッピングをしてみましょう。\n\nasia_map %>% \n  mutate(Population = case_when(pop_est < 10000000  ~ \"1千万未満\",\n                                pop_est < 50000000  ~ \"5千万未満\",\n                                pop_est < 100000000 ~ \"1億未満\",\n                                pop_est < 500000000 ~ \"5億未満\",\n                                TRUE                ~ \"5億以上\"),\n         Population = factor(Population, \n                             levels = c(\"1千万未満\", \"5千万未満\", \"1億未満\",\n                                        \"5億未満\", \"5億以上\"))) %>%\n  ggplot() +\n  geom_sf(aes(fill = Population)) +\n  scale_fill_brewer(palette = \"Blues\", drop = FALSE) +\n  labs(fill = \"人口\") +\n  theme_void() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n　scale_fill_brewer()のpalette引数は等高線図のときに紹介しましたパレート一覧を参照してください。\n\n20.11.2 日本地図（全体）\n　次は日本地図の出力についてです。日本全土だけを出力するなら、これまで使いましたne_countriesにcountry引数を指定するだけで使えます。たとえば、日本の地図だけなら、country = \"Japan\"を指定します。\n\nne_countries(scale = \"small\", country = \"Japan\", returnclass = \"sf\") %>%\n    ggplot() +\n    geom_sf() +\n    theme_void() # 空っぽのテーマ\n\n\n\n\n\n\n\n　これだと、物足りない感があるので、もう少し高解像度の地図にしてみましょう。高解像度の地図データを読み込む際はscale = \"large\"を指定します。\n\nne_countries(scale = \"large\", country = \"Japan\", returnclass = \"sf\") %>%\n    ggplot() +\n    geom_sf() +\n    theme_void() # 空っぽのテーマ\n\n\n\n\n\n\n\n　ただ、日本地図を出すという場合、多くは都道府県レベルでマッピングが目的でしょう。世界地図のマッピングならこれで問題ありませんが、一国だけなら、その下の自治体の境界線も必要です。したがって、先ほど使用しましたパッケージのより高解像度の地図が含まれている{rnaturalearthhires}をインストールし、読み込みましょう。2022年Dec月20日現在、{rnaturalearthhires}はCRANに登録されておらず、GitHubのropensciレポジトリーのみで公開されているため、今回は{pacman}のp_load()でなく、p_load_gh()を使用します。\n\npacman::p_load_gh(\"ropensci/rnaturalearthhires\")\n\n　地図データの抽出にはne_states()関数を使用します。第一引数として国家名を指定し、地図データのクラスはsfとします。抽出したデータの使い方は世界地図の時と同じです。\n\nJapan_Map <- ne_states(\"Japan\", returnclass = \"sf\")\n\nJapan_Map %>%\n  ggplot() +\n  geom_sf() +\n  theme_void()\n\n\n\n\n\n\n\n　今回は各都道府県を人口密度ごとに色塗りをしてみましょう。ne_states()で読み込んだデータに人口密度のデータはないため、別途のデータと結合する必要があります。筆者が予め作成しておいたデータを読み込み、中身を確認してみます。\n\nJapan_Density <- read_csv(\"Data/Japan_Density.csv\")\n\nJapan_Density\n\n# A tibble: 47 × 3\n    Code Name   Density\n   <dbl> <chr>    <dbl>\n 1     1 北海道    66.6\n 2     2 青森県   128. \n 3     3 岩手県    79.2\n 4     4 宮城県   316. \n 5     5 秋田県    82.4\n 6     6 山形県   115. \n 7     7 福島県   133  \n 8     8 茨城県   470. \n 9     9 栃木県   302. \n10    10 群馬県   305. \n# … with 37 more rows\n\n\n　各都道府県の人口密度がついております、左側のCodeは何でしょうか。これは各都道府県のISOコードであり、このコードをキー変数としてデータを結合することとなります。各都道府県のコードは国土交通省のホームページから確認可能です。\n　それではデータを結合してみましょう。ne_states()で読み込んだデータの場合、地域のコードはiso_3166_2という列に格納されています。\n\nJapan_Map$iso_3166_2\n\n [1] \"JP-46\" \"JP-44\" \"JP-40\" \"JP-41\" \"JP-42\" \"JP-43\" \"JP-45\" \"JP-36\" \"JP-37\"\n[10] \"JP-38\" \"JP-39\" \"JP-32\" \"JP-35\" \"JP-31\" \"JP-28\" \"JP-26\" \"JP-18\" \"JP-17\"\n[19] \"JP-16\" \"JP-15\" \"JP-06\" \"JP-05\" \"JP-02\" \"JP-03\" \"JP-04\" \"JP-07\" \"JP-08\"\n[28] \"JP-12\" \"JP-13\" \"JP-14\" \"JP-22\" \"JP-23\" \"JP-24\" \"JP-30\" \"JP-27\" \"JP-33\"\n[37] \"JP-34\" \"JP-01\" \"JP-47\" \"JP-10\" \"JP-20\" \"JP-09\" \"JP-21\" \"JP-25\" \"JP-11\"\n[46] \"JP-19\" \"JP-29\"\n\n\n　こちらは文字列となっていますね。これを左から4番目の文字から切り取り、数値型に変換します。変換したコードは結合のためにCodeという名の列として追加しましょう。\n\nJapan_Map <- Japan_Map %>%\n    mutate(Code = str_sub(iso_3166_2, 4),\n           Code = as.numeric(Code))\n\nJapan_Map$Code\n\n [1] 46 44 40 41 42 43 45 36 37 38 39 32 35 31 28 26 18 17 16 15  6  5  2  3  4\n[26]  7  8 12 13 14 22 23 24 30 27 33 34  1 47 10 20  9 21 25 11 19 29\n\n\n　続いて、Japan_MapとJapan_DensityをCode列をキー変数として結合します。データの中身を確認すると、Density列が最後(の直前)の列に追加されたことが分かります。\n\nJapan_Map <- left_join(Japan_Map, Japan_Density, by = \"Code\")\n\nJapan_Map\n\nSimple feature collection with 47 features and 86 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 122.9382 ymin: 24.2121 xmax: 153.9856 ymax: 45.52041\nCRS:           +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\nFirst 10 features:\n           featurecla scalerank adm1_code diss_me iso_3166_2 wikipedia iso_a2\n1  Admin-1 scale rank         2  JPN-3501    3501      JP-46      <NA>     JP\n2  Admin-1 scale rank         6  JPN-1835    1835      JP-44      <NA>     JP\n3  Admin-1 scale rank         6  JPN-1829    1829      JP-40      <NA>     JP\n4  Admin-1 scale rank         6  JPN-1827    1827      JP-41      <NA>     JP\n5  Admin-1 scale rank         2  JPN-3500    3500      JP-42      <NA>     JP\n6  Admin-1 scale rank         6  JPN-1830    1830      JP-43      <NA>     JP\n7  Admin-1 scale rank         6  JPN-1831    1831      JP-45      <NA>     JP\n8  Admin-1 scale rank         6  JPN-1836    1836      JP-36      <NA>     JP\n9  Admin-1 scale rank         6  JPN-1833    1833      JP-37      <NA>     JP\n10 Admin-1 scale rank         6  JPN-1832    1832      JP-38      <NA>     JP\n   adm0_sr      name name_alt name_local type    type_en code_local code_hasc\n1        5 Kagoshima     <NA>       <NA>  Ken Prefecture       <NA>     JP.KS\n2        1      Oita     <NA>       <NA>  Ken Prefecture       <NA>     JP.OT\n3        1   Fukuoka  Hukuoka       <NA>  Ken Prefecture       <NA>     JP.FO\n4        1      Saga     <NA>       <NA>  Ken Prefecture       <NA>     JP.SG\n5        3  Nagasaki     <NA>       <NA>  Ken Prefecture       <NA>     JP.NS\n6        1  Kumamoto     <NA>       <NA>  Ken Prefecture       <NA>     JP.KM\n7        1  Miyazaki     <NA>       <NA>  Ken Prefecture       <NA>     JP.MZ\n8        1 Tokushima Tokusima       <NA>  Ken Prefecture       <NA>     JP.TS\n9        1    Kagawa     <NA>       <NA>  Ken Prefecture       <NA>     JP.KG\n10       4     Ehime     <NA>       <NA>  Ken Prefecture       <NA>     JP.EH\n   note hasc_maybe  region region_cod provnum_ne gadm_level check_me datarank\n1  <NA>      JP.NR  Kyushu    JPN-KYS          3          1       20        9\n2  <NA>      JP.ON  Kyushu    JPN-SHK         48          1       20        2\n3  <NA>      JP.NS  Kyushu    JPN-KYS         46          1       20        2\n4  <NA>      JP.OS    <NA>       <NA>         47          1       20        2\n5  <NA>      JP.OY    <NA>       <NA>          5          1       20        9\n6  <NA>      JP.NI  Kyushu    JPN-KYS          6          1       20        2\n7  <NA>      JP.OT  Kyushu    JPN-KYS         49          1       20        2\n8  <NA>      JP.SZ Shikoku    JPN-SHK         45          1       20        2\n9  <NA>      JP.SH Shikoku    JPN-SHK          4          1       20        2\n10 <NA>      JP.ST Shikoku    JPN-SHK         14          1       20        2\n   abbrev postal area_sqkm sameascity labelrank name_len mapcolor9 mapcolor13\n1    <NA>   <NA>         0         NA         2        9         5          4\n2    <NA>     OT         0          7         7        4         5          4\n3    <NA>     FO         0          7         7        7         5          4\n4    <NA>     SG         0         NA         6        4         5          4\n5    <NA>   <NA>         0         NA         2        8         5          4\n6    <NA>     KM         0         NA         6        8         5          4\n7    <NA>     MZ         0         NA         6        8         5          4\n8    <NA>     TS         0         NA         6        9         5          4\n9    <NA>     KG         0         NA         6        6         5          4\n10   <NA>     EH         0         NA         6        5         5          4\n   fips fips_alt   woe_id                       woe_label  woe_name latitude\n1  JA18     JA28  2345867 Kagoshima Prefecture, JP, Japan Kagoshima  29.4572\n2  JA30     JA47  2345879      Oita Prefecture, JP, Japan      Oita  33.2006\n3  JA07     JA27 58646425   Fukuoka Prefecture, JP, Japan   Fukuoka  33.4906\n4  JA33     JA32  2345882      Saga Prefecture, JP, Japan      Saga  33.0097\n5  JA27     JA31  2345876  Nagasaki Prefecture, JP, Japan  Nagasaki  32.6745\n6  JA21     JA29  2345870  Kumamoto Prefecture, JP, Japan  Kumamoto  32.5880\n7  JA25     JA30  2345874  Miyazaki Prefecture, JP, Japan  Miyazaki  32.0981\n8  JA39     JA37  2345888 Tokushima Prefecture, JP, Japan Tokushima  33.8546\n9  JA17     JA35  2345866    Kagawa Prefecture, JP, Japan    Kagawa  34.2162\n10 JA05     JA34  2345855     Ehime Prefecture, JP, Japan     Ehime  33.8141\n   longitude sov_a3 adm0_a3 adm0_label admin geonunit gu_a3   gn_id\n1    129.601    JPN     JPN          4 Japan    Japan   JPN 1860825\n2    131.449    JPN     JPN          4 Japan    Japan   JPN 1854484\n3    130.616    JPN     JPN          4 Japan    Japan   JPN 1863958\n4    130.147    JPN     JPN          4 Japan    Japan   JPN 1853299\n5    128.755    JPN     JPN          4 Japan    Japan   JPN 1856156\n6    130.834    JPN     JPN          4 Japan    Japan   JPN 1858419\n7    131.286    JPN     JPN          4 Japan    Japan   JPN 1856710\n8    134.200    JPN     JPN          4 Japan    Japan   JPN 1850157\n9    134.001    JPN     JPN          4 Japan    Japan   JPN 1860834\n10   132.916    JPN     JPN          4 Japan    Japan   JPN 1864226\n         gn_name  gns_id      gns_name gn_level gn_region gn_a1_code region_sub\n1  Kagoshima-ken -231556 Kagoshima-ken        1      <NA>      JP.18       <NA>\n2       Oita-ken -240089      Oita-ken        1      <NA>      JP.30       <NA>\n3    Fukuoka-ken -227382   Fukuoka-ken        1      <NA>      JP.07       <NA>\n4       Saga-ken -241905      Saga-ken        1      <NA>      JP.33       <NA>\n5   Nagasaki-ken -237758  Nagasaki-ken        1      <NA>      JP.27       <NA>\n6   Kumamoto-ken -234759  Kumamoto-ken        1      <NA>      JP.21       <NA>\n7   Miyazaki-ken -236958  Miyazaki-ken        1      <NA>      JP.25       <NA>\n8  Tokushima-ken -246216 Tokushima-ken        1      <NA>      JP.39       <NA>\n9     Kagawa-ken -231546    Kagawa-ken        1      <NA>      JP.17       <NA>\n10     Ehime-ken -227007     Ehime-ken        1      <NA>      JP.05       <NA>\n   sub_code gns_level gns_lang gns_adm1 gns_region min_label max_label min_zoom\n1      <NA>         1      jpn     JA18       <NA>         7        11        3\n2      <NA>         1      jpn     JA30       <NA>         7        11        3\n3      <NA>         1      jpn     JA07       <NA>         7        11        3\n4      <NA>         1      jpn     JA33       <NA>         7        11        3\n5      <NA>         1      jpn     JA27       <NA>         7        11        3\n6      <NA>         1      jpn     JA21       <NA>         7        11        3\n7      <NA>         1      jpn     JA25       <NA>         7        11        3\n8      <NA>         1      jpn     JA39       <NA>         7        11        3\n9      <NA>         1      jpn     JA17       <NA>         7        11        3\n10     <NA>         1      jpn     JA05       <NA>         7        11        3\n   wikidataid name_ar name_bn             name_de              name_en\n1      Q15701    <NA>    <NA> Präfektur Kagoshima Kagoshima Prefecture\n2     Q133924    <NA>    <NA>      Präfektur Oita      Oita Prefecture\n3     Q123258    <NA>    <NA>   Präfektur Fukuoka   Fukuoka Prefecture\n4     Q160420    <NA>    <NA>      Präfektur Saga      Saga Prefecture\n5     Q169376    <NA>    <NA>  Präfektur Nagasaki  Nagasaki Prefecture\n6     Q130308    <NA>    <NA>  Präfektur Kumamoto  Kumamoto Prefecture\n7     Q130300    <NA>    <NA>  Präfektur Miyazaki  Miyazaki Prefecture\n8     Q160734    <NA>    <NA> Präfektur Tokushima Tokushima Prefecture\n9     Q161454    <NA>    <NA>    Präfektur Kagawa    Kagawa Prefecture\n10    Q123376    <NA>    <NA>     Präfektur Ehime     Ehime Prefecture\n                   name_es                 name_fr name_el name_hi\n1  Prefectura de Kagoshima Préfecture de Kagoshima    <NA>    <NA>\n2       Prefectura de Oita       Préfecture d'Oita    <NA>    <NA>\n3    Prefectura de Fukuoka   Préfecture de Fukuoka    <NA>    <NA>\n4       Prefectura de Saga      Préfecture de Saga    <NA>    <NA>\n5   Prefectura de Nagasaki  Préfecture de Nagasaki    <NA>    <NA>\n6   Prefectura de Kumamoto  Préfecture de Kumamoto    <NA>    <NA>\n7   Prefectura de Miyazaki  Préfecture de Miyazaki    <NA>    <NA>\n8  Prefectura de Tokushima Préfecture de Tokushima    <NA>    <NA>\n9     Prefectura de Kagawa    Préfecture de Kagawa    <NA>    <NA>\n10     Prefectura de Ehime      Préfecture d'Ehime    <NA>    <NA>\n                name_hu             name_id                 name_it name_ja\n1   Kagosima prefektúra Prefektur Kagoshima prefettura di Kagoshima    <NA>\n2       Óita prefektúra      Prefektur Oita      prefettura di Oita    <NA>\n3    Fukuoka prefektúra   Prefektur Fukuoka   prefettura di Fukuoka    <NA>\n4      Szaga prefektúra      Prefektur Saga      Prefettura di Saga    <NA>\n5  Nagaszaki prefektúra  Prefektur Nagasaki  prefettura di Nagasaki    <NA>\n6   Kumamoto prefektúra  Prefektur Kumamoto  prefettura di Kumamoto    <NA>\n7   Mijazaki prefektúra  Prefektur Miyazaki  prefettura di Miyazaki    <NA>\n8   Tokusima prefektúra Prefektur Tokushima prefettura di Tokushima    <NA>\n9     Kagava prefektúra    Prefektur Kagawa    prefettura di Kagawa    <NA>\n10     Ehime prefektúra     Prefektur Ehime     prefettura di Ehime    <NA>\n   name_ko   name_nl              name_pl   name_pt name_ru             name_sv\n1     <NA> Kagoshima Prefektura Kagoshima Kagoshima    <NA> Kagoshima prefektur\n2     <NA>      Oita      Prefektura Oita      Oita    <NA>      Oita prefektur\n3     <NA>   Fukuoka   Prefektura Fukuoka   Fukuoka    <NA>   Fukuoka prefektur\n4     <NA>      Saga      Prefektura Saga      Saga    <NA>      Saga prefektur\n5     <NA>  Nagasaki  Prefektura Nagasaki  Nagasaki    <NA>  Nagasaki prefektur\n6     <NA>  Kumamoto  Prefektura Kumamoto  Kumamoto    <NA>  Kumamoto prefektur\n7     <NA>  Miyazaki  Prefektura Miyazaki  Miyazaki    <NA>  Miyazaki prefektur\n8     <NA> Tokushima Prefektura Tokushima Tokushima    <NA> Tokushima prefektur\n9     <NA>    Kagawa    Prefektura Kagawa    Kagawa    <NA>    Kagawa prefektur\n10    <NA>     Ehime     Prefektura Ehime     Ehime    <NA>     Ehime prefektur\n        name_tr   name_vi name_zh      ne_id Code     Name Density\n1  Kagosima ili Kagoshima    <NA> 1159315225   46 鹿児島県   172.9\n2          Oita      Oita    <NA> 1159311905   44   大分県   177.2\n3       Fukuoka   Fukuoka    <NA> 1159311899   40   福岡県  1029.8\n4          Saga      Saga    <NA> 1159311895   41   佐賀県   332.5\n5      Nagasaki  Nagasaki    <NA> 1159315235   42   長崎県   317.7\n6      Kumamoto  Kumamoto    <NA> 1159311901   43   熊本県   234.6\n7      Miyazaki  Miyazaki    <NA> 1159311903   45   宮崎県   138.3\n8     Tokushima Tokushima    <NA> 1159311909   36   徳島県   173.5\n9        Kagawa    Kagawa    <NA> 1159311907   37   香川県   506.3\n10        Ehime     Ehime    <NA> 1159311139   38   愛媛県   235.2\n                         geometry\n1  MULTIPOLYGON (((129.7832 31...\n2  MULTIPOLYGON (((131.2009 33...\n3  MULTIPOLYGON (((130.0363 33...\n4  MULTIPOLYGON (((129.8145 33...\n5  MULTIPOLYGON (((130.2041 32...\n6  MULTIPOLYGON (((130.3446 32...\n7  MULTIPOLYGON (((131.8723 32...\n8  MULTIPOLYGON (((134.4424 34...\n9  MULTIPOLYGON (((133.5919 34...\n10 MULTIPOLYGON (((132.6399 32...\n\n\n　それではマッピングをしてみましょう。人口密度を5つのカテゴリーに順序付きfactor化してから、そのカテゴリーに応じて色塗りをします。\n\nJapan_Map %>%\n    mutate(Density2 = case_when(Density >= 3000 ~ \"3000人以上\",\n                                Density >= 1000 ~ \"1000人以上\",\n                                Density >=  500 ~ \"500人以上\",\n                                Density >=  100 ~ \"100人以上\",\n                                TRUE            ~ \"100人未満\"),\n           Density2 = factor(Density2, ordered = TRUE,\n                             levels = c(\"3000人以上\", \"1000人以上\", \"500人以上\",\n                                        \"100人以上\", \"100人未満\"))) %>%\n    ggplot() +\n    geom_sf(aes(fill = Density2)) +\n    labs(fill = \"人口密度 (km^2)\") +\n    theme_void()\n\n\n\n\n\n\n\n　世界地図でも同じやり方でデータの結合が可能です。この場合はISO3コードかISO2コードがキー変数となります。ISO3コードはiso_a3、ISO2コードはiso_a2列に格納されています。他に使用可能なキー変数はiso_n3であり、こちらは各国を識別する3桁の数字となります。\n\n20.11.3 日本地図（特定の都道府県）\n　また日本地図のマッピングですが、今回は市区町村レベルまで見てみましょう。ne_states()では市区町村までマッピングすることはできませんので、今回は徳島大学の瓜生真也先生が公開しました{jpndistrict}を使います。\n\npacman::p_load_gh(\"uribo/jpndistrict\")\n\n　今回は大阪府の地図を出力してみましょう。特定の都道府県の地図を読み込むためにはjpn_pref()関数を使用します。都道府県はpref_codeまたはadmin_nameで指定します。大阪のコードは27であるため、pref_code = 27でも良いですし、admin_name = \"大阪府\"でも同じです。\n\n# Osaka_map <- jpn_pref(admin_name = \"大阪府\") でも同じ\nOsaka_map <- jpn_pref(pref_code = 27)\n\nclass(Osaka_map)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n　プロットの方法は同じです。\n\nOsaka_map %>%\n  ggplot() +\n  geom_sf() +\n  theme_minimal()\n\n\n\n\n\n\n\n　ここでもデータの結合&マッピングが可能です。大阪府内自治体の人口と学生数が格納されたデータを読み込んでみましょう。こちらは2015年国勢調査の結果から取得したデータです。\n\nOsaka_Student <- read_csv(\"data/Osaka_Student.csv\")\n\nOsaka_Student\n\n# A tibble: 75 × 4\n    Code Name                Pop Student\n   <dbl> <chr>             <dbl>   <dbl>\n 1 27000 大阪府          8839469  438901\n 2 27100 大阪市          2691185  104208\n 3 27102 大阪市 都島区    104727    3889\n 4 27103 大阪市 福島区     72484    2448\n 5 27104 大阪市 此花区     66656    2478\n 6 27106 大阪市 西区       92430    2633\n 7 27107 大阪市 港区       82035    3072\n 8 27108 大阪市 大正区     65141    2627\n 9 27109 大阪市 天王寺区   75729    3480\n10 27111 大阪市 浪速区     69766    1409\n# … with 65 more rows\n\n\n　各市区町村にもコードが指定されており、Osaka_StudentではCode列、Osaka_mapではciti_code列となります。Osaka_mapのcity_codeは文字列であるため、こちらを数値型に変換しCodeという名の列として追加しておきましょう。続いて、Code列をキー変数とし、2つのデータセットを結合します。\n\nOsaka_map <- Osaka_map %>%\n    mutate(Code = as.numeric(city_code))\n\nOsaka_map <- left_join(Osaka_map, Osaka_Student, by = \"Code\")\n\n　最後にマッピングです。ここでは人口1万人当たり学生数をStudent_Ratioという列として追加し、こちらの値に合わせて色塗りをしてみましょう。scale_fill_gradient()を使用し、人口1万人当たり学生数が少ないほど白、多いほど黒塗りします。\n\nOsaka_map %>%\n  mutate(Student_Ratio = Student / Pop * 10000) %>%\n  ggplot() +\n  geom_sf(aes(fill = Student_Ratio)) +\n  scale_fill_gradient(low = \"white\", high = \"black\") +\n  labs(fill = \"1万人当たり学生数 (人)\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-dag",
    "href": "visualization4.html#RN4Esec-visual4-dag",
    "title": "20  可視化 [発展]",
    "section": "\n20.12 非巡回有向グラフ",
    "text": "20.12 非巡回有向グラフ\n　近年、因果推論の界隈でよく登場する非巡回有向グラフ（DAG）ですが、「グラフ」からも分かるように、DAGの考え方に基づく因果推論の研究には多くの図が登場します。DAGを作図するには{ggplot2}のみでも可能ですが、{dagitty}パッケージでDAGの情報を含むオブジェクトを生成し、{ggdag}で作図した方が簡単です。以下の図はDAGの一例です。\n\n\n\n\n\n\n\n\n　ここでX、Y、Zはノード（node）と呼ばれ、それぞれのノードをつなぐ線のことをエッジ（edge）と呼びます。また、これらのエッジには方向があります（有向）。簡単に言うと原因と結果といった関係ですが、DAGを描く際は、各ノード間の関係を記述する必要があります。\n　それではまず、以上の図を作ってみましょう。最初のステップとして{dagitty}と{ggdag}をインストールし、読み込みましょう。\n\npacman::p_load(dagitty, ggdag)\n\n　つづいて、DAGの情報を含むオブジェクトを作成します。使用する関数はdagify()であり、ここには結果 ~ 原因の形式で各ノード間の関係を記述します。先ほどの図ではXはYの原因（X ~ Y）、ZはXとYの原因（X ~ ZとY ~ Z）です。これらの情報をdagify()内で指定します。\n\nDAG_data1 <- dagify(X ~ Z,\n                    Y ~ Z,\n                    Y ~ X,\n                    exposure = \"X\",\n                    outcome  = \"Y\")\n\nDAG_data1\n\ndag {\nX [exposure]\nY [outcome]\nZ\nX -> Y\nZ -> X\nZ -> Y\n}\n\n\n　Y ~ XとY ~ ZはY ~ X + Zとまとめることも可能です。これは「Yの原因はXとZである」という意味であり、「Yの原因はXであり、Yの原因はZである」と同じ意味です。また、DAGを作図する際、dagify()内にexposureとoutcomeは不要ですが、もしadjustmentSets()関数などを使って統制変数を特定したい場合は処置変数（exposure）と応答変数（outcome）にそれぞれ変数名を指定します。ちなみに、以上のコードは以下のように書くことも可能です。\n\nDAG_data1 <- dagitty(\n  \"dag{\n  X -> Y\n  X <- Z -> Y\n  X [exposure]\n  Y [outcome]\n  }\")\n\nDAG_data1\n\ndag {\nX [exposure]\nY [outcome]\nZ\nX -> Y\nZ -> X\nZ -> Y\n}\n\n\n　格納されたDAG_data1オブジェクトのクラスは\"dagitty\"です。\"dagitty\"の可視化には{ggdag}のggdag()を使用します。\n\nDAG_data1 %>%\n  ggdag()\n\n\n\n\n\n\n\n　DAGにおいて背景、軸の目盛り、ラベルは不要ですので、theme_dag_blank()テーマを指定して全て除去します。\n\nDAG_data1 %>%\n  ggdag() +\n  theme_dag_blank()\n\n\n\n\n\n\n\n\n20.12.1 ノードの位置を指定する\n　読者の多くは以上のグラフと異なるものが得られたかも知れません。ノード間の関係は同じはずですが、ノードの位置が異なるでしょう。また、同じコードを実行する度にノードの位置は変わります。以下ではノードの位置を固定する方法について紹介します。位置を指定するにはdagify()内でcoords引数に各ノードの情報が格納されたリスト型オブジェクトを指定する必要があります。リストの長さは2であり、それぞれの名前はxとyです。そしてリストの各要素にはベクトルが入ります。たとえば、ノードXの位置を (1, 1)、Yの位置を (3, 1)、Zの位置を (2, 2)に指定してみましょう。dagify()内で直接リストを書くことも可能ですが、コードの可読性が落ちるため、別途のオブジェクト（DAG_Pos2）として格納しておきます。\n\nDAG_Pos2  <- list(x = c(X = 1, Y = 3, Z = 2),\n                  y = c(X = 1, Y = 1, Z = 2))\n\n　続いて、dagify()内でcoords引数を追加し、ノードの位置情報が格納されているDAG_Pos2を指定します。\n\nDAG_data2 <- dagify(X ~ Z,\n                    Y ~ X + Z,\n                    exposure = \"X\",\n                    outcome  = \"Y\",\n                    coords   = DAG_Pos2)\n\nDAG_data2\n\ndag {\nX [exposure,pos=\"1.000,1.000\"]\nY [outcome,pos=\"3.000,1.000\"]\nZ [pos=\"2.000,2.000\"]\nX -> Y\nZ -> X\nZ -> Y\n}\n\n\n　可視化の方法は同じです。\n\nDAG_data2 %>%\n  ggdag() +\n  theme_dag_blank()\n\n\n\n\n\n\n\n　以上の使い方だけでも、ほとんどのDAGは描けるでしょう。また、ノードを若干オシャレ（?）にするには、ggdag()内でstylized = TRUEを指定します。\n\nDAG_Pos3  <- list(x = c(X1 = 3, X2 = 3, X3 = 1, T = 2, Y = 4),\n                  y = c(X1 = 1, X2 = 2, X3 = 2, T = 3, Y = 3))\n\nDAG_data3 <- dagify(Y  ~ T + X1 + X2,\n                    T  ~ X3,\n                    X2 ~ T +X1 + X3,\n                    exposure = \"T\",\n                    outcome  = \"Y\",\n                    coords   = DAG_Pos3)\n\nDAG_data3 %>%\n  ggdag(stylized = TRUE) +\n  theme_dag_blank()\n\n\n\n\n\n\n\n　可視化の話ではありませんが、adjustmentSets()関数を用いると、処置変数Tの総効果（total effect）を推定するためにはどの変数を統制（調整）する必要があるかを調べることも可能です。\n\nadjustmentSets(DAG_data3, effect = \"total\")\n\n{ X3 }\n\n\n　X3変数のみ統制すれば良いという結果が得られました。また、TからYへの直接効果（direct effect）の場合、effect = \"direct\"を指定します。\n\nadjustmentSets(DAG_data3, effect = \"direct\")\n\n{ X1, X2 }\n\n\n　X1とX2を統制する必要があることが分かりますね。"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-bump",
    "href": "visualization4.html#RN4Esec-visual4-bump",
    "title": "20  可視化 [発展]",
    "section": "\n20.13 バンプチャート",
    "text": "20.13 バンプチャート\n　バンプチャート (bump chart)は順位の変化などを示す時に有効なグラフです。たとえば、G7構成国の新型コロナ感染者数の順位の変化を示すにはどうすれば良いでしょうか。そもそもどのような形式のデータが必要でしょうか。まずは必要なデータ形式を紹介したいと思います。\n　まず、{ggplot2}によるバンプチャートの作成を支援する{ggbump}パッケージをインストールし、読み込みましょう3。\n\npacman::p_load(ggbump)\n\n　ここではG7構成国の100万人当り新型コロナ感染者数の順位がどのように変化したのかを2020年4月から7月まで1ヶ月単位で表したデータが必要です。データは以下のようなコードで作成しますが、本書のサポートページからもダウンロード可能です。\n\nBump_df <- left_join(COVID19_df, Country_df, by = \"Country\") %>%\n  select(Country, Date, Population, Confirmed_Total, G7) %>%\n  separate(Date, into = c(\"Year\", \"Month\", \"Day\"), sep = \"/\") %>%\n  mutate(Month = as.numeric(Month)) %>%\n  filter(Month >= 4, G7 == 1) %>%\n  group_by(Country, Month) %>%\n  summarise(Population            = mean(Population),\n            New_Cases             = sum(Confirmed_Total, na.rm = TRUE),\n            New_Cases_per_million = New_Cases / Population * 1000000,\n            .groups               = \"drop\") %>%\n  select(Country, Month, New_Cases_per_million)\n\n\nBump_df <- Bump_df %>%\n  group_by(Month) %>%\n  mutate(Rank = rank(New_Cases_per_million, ties.method = \"random\")) %>%\n  ungroup() %>%\n  select(Country, Month, Rank, New_Cases_per_million)\n\n　必要なデータは以下のような形式です。ちなみにバンプチャートを作成するためには最後のNew_Cases_per_million列 (100万人当り新型コロナ感染者数)は不要です。つまり、国名、月、順位のみで十分です。\n\n# 以上のコードを省略し、加工済みのデータを読み込んでもOK\n# Bump_df <- read_csv(\"Data/Bumpchart.csv\")\nBump_df\n\n　それでは{ggbump}が提供するgeom_bump()幾何オブジェクトを使用し、簡単なバンプチャートを作成してみましょう。必要なマッピング要素はxとy、colorです。xには時間を表す変数であるMonthを、yには順位を表すRankをマッピングします。また、7本の線が出るため、月と順位、それぞれの値がどの国の値かを特定する必要があります。groupsに国名であるCountryをマッピングしても線は引けますが、どの線がどの国かが分からなくなるため、colorにCountryをマッピングし、線の色分けをします。\n\nBump_df %>%\n  ggplot(aes(x = Month, y = Rank, color = Country)) +\n  geom_bump()\n\n\n\n\n\n\n\n　これで最低限のバンプチャートはできましたが、もう少し見やすく、可愛くしてみましょう。今は線が細いのでややぶ厚めにします。これはgeom_bump()レイヤーのsize引数で指定可能です。また、各月に点を付けることによって、同時期における順位の比較をよりしやすくしてみましょう。これは散布図と同じであるため、geom_point()幾何オブジェクトを使用します。\n\nBump_df %>%\n  ggplot(aes(x = Month, y = Rank, color = Country)) +\n  geom_point(size = 7) +\n  geom_bump(size = 2) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n　これでだいぶ見やすくなりましたが、凡例における国名の順番がやや気になりますね。7月の時点において順位が最も高い国はアメリカ、最も低い国は日本ですが、凡例の順番はアルファベット順となっています。この凡例の順番を7月時点におけるRankの値に合わせた方がより見やすいでしょう。ここで第14.2.9章で紹介しましたfct_reorder2()を使ってCountry変数の水準 (level)を7月時点におけるRankの順位に合わせます。この場合、Country変数 (.f = Country)の水準をMonthが (.x = Month)最も大きい (.fun = last2)時点におけるRankの順番に合わせる (.y = Rank)こととなります。fct_reorder2()内の引数の順番の既定値は.f、.x、.y、.funとなります。\n\nBump_df %>%\n  mutate(Country = fct_reorder2(Country, Month, Rank, last2)) %>%\n  ggplot(aes(x = Month, y = Rank, color = Country)) +\n  geom_point(size = 7) +\n  geom_bump(size = 2) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n　最後に縦軸の目盛りラベルを付けます。上に行くほど順位が高くなりますので、1を7に、2を6に、…、7を1に変更します。また、図内のグリッドも不要ですので、theme()を使用し、グリッドを削除します (panel.grid = element_blank())。\n\nBump_df %>%\n  mutate(Country = fct_reorder2(Country, Month, Rank, last2)) %>%\n  ggplot(aes(x = Month, y = Rank, color = Country)) +\n  geom_point(size = 7) +\n  geom_bump(size = 2) +\n  scale_y_continuous(breaks = 1:7, labels = 7:1) +\n  theme_minimal(base_size = 14) +\n  theme(panel.grid = element_blank())\n\n\n\n\n\n\n\n　これでバンプチャートの完成です。このままでの良いかも知れませんが、もう少し手間を掛けることでより読みやすいグラフが作れます。たとえば、今のままだと「日本のトレンド」を確認したい場合、まず凡例から日本の色を確認し、その色に該当する点と線を見つけてトレンドを見る必要がありますね。もし、ここで図の左端と右端の点の横に国名を出力すると、凡例がなくても良いですし、4月の時点から日本のトレンドを確認することも、7月の時点から遡る形で日本のトレンドを確認することも可能かも知れません。\n　図に文字列を追加するためにはgeom_text()幾何オブジェクトを使用します。マッピング要素は文字列の横軸上の位置 (x)、縦軸上の位置 (y)、そして出力する文字列 (label)です。左端に文字列を出力するのであれば、横軸上の位置は4 (= 4月)よりも若干左側が良いでしょう。ぴったり4になると、点と文字列が重なって読みにくくなりますね。縦軸上の位置は4月の時点での順位 (Rank)で、出力する文字列は国名 (Country)です。現在、使用しているデータは4月から7月までのデータですが、4月に限定したデータを使いたいので、geom_text()内にdata引数を追加し、Bump_dfからMonthの値が4の行のみを抽出したデータを割り当てます (data = filter(Bump_df, Month == 4)、またはdata = Bump_df %>% filter(Month == 4))。右端についても同じです。横軸上の位置は7から右方向へずらし、使用するデータは7月のデータとなります。\n　最後にもう一点調整が必要ですが、それは座標系です。図の座標系はggplot()関数で使用するデータに基づきます。Bump_dfの場合、横軸 (Month)は4から7です。しかし、文字列を追加した場合、文字列がすべて出力されないかも知れません。したがって、座標系を横方向に広める必要があります。今回は3から8までに調整します。座標系や文字列の位置調整は出力結果を見ながら、少しずつ調整していきましょう。\n\nBump_df %>%\n  ggplot(aes(x = Month, y = Rank, color = Country)) +\n  geom_point(size = 7) +\n  geom_bump(size = 2) +\n  # 4月の時点での行のみ抽出し、xはMonthより0.15分左方向、\n  # yはRankの値の位置に国名を出力する。揃える方向は右揃え (hjust = 1)\n  geom_text(data = filter(Bump_df, Month == 4),\n            aes(x = Month - 0.15, y = Rank, label = Country), hjust = 1) +\n  # 7月の時点での行のみ抽出し、xはMonthより0.15分右方向、\n  # yはRankの値の位置に国名を出力する。揃える方向は左揃え (hjust = 0)\n  geom_text(data = filter(Bump_df, Month == 7),\n            aes(x = Month + 0.15, y = Rank, label = Country), hjust = 0) +\n  # 座標系の調整\n  coord_cartesian(xlim = c(3, 8)) +\n  scale_x_continuous(breaks = 4:7, labels = 4:7) +\n  scale_y_continuous(breaks = 1:7, labels = 7:1) +\n  labs(y = \"Rank\", x = \"Month\") +\n  theme_minimal(base_size = 14) +\n  theme(legend.position = \"none\",\n        panel.grid      = element_blank())"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-alluvial",
    "href": "visualization4.html#RN4Esec-visual4-alluvial",
    "title": "20  可視化 [発展]",
    "section": "\n20.14 沖積図",
    "text": "20.14 沖積図\n　沖積図 (alluvial plot)は同じ対象を複数回観察したデータ（パネル・データなど）から変化を示すことに適したグラフです。たとえば、同じ回答者を対象に2回世論調査を実施し、1回目調査時の支持政党と2回目調査時の支持政党を変化を見ることも可能です。もし、変化が大きい場合は政党支持態度は弱いこととなりますし、変化が小さい場合は安定していると解釈できるでしょう。\n　ここでは2020年の選挙と2021年の選挙における有権者の投票先の変化を沖積図で確認してみたいと思います。まずは、沖積図の作成に特化した{ggalluvial}パッケージをインストールし、読み込みます。\n\npacman::p_load(ggalluvial)\n\n　続きまして、実習用データを読み込みます。データは架空のデータです。\n\nVote_2021 <- read_csv(\"Data/Vote_20_21.csv\")\n\nhead(Vote_2021, 20)\n\n# A tibble: 20 × 3\n      ID Vote20 Vote21\n   <dbl> <chr>  <chr> \n 1     1 棄権   棄権  \n 2     2 政党A  政党A \n 3     3 政党A  政党A \n 4     4 政党B  政党A \n 5     5 政党B  政党C \n 6     6 政党A  政党C \n 7     7 その他 その他\n 8     8 政党B  政党B \n 9     9 政党A  政党A \n10    10 政党C  政党C \n11    11 棄権   政党B \n12    12 政党B  政党A \n13    13 棄権   棄権  \n14    14 政党B  政党B \n15    15 政党C  政党C \n16    16 DK     政党C \n17    17 政党B  DK    \n18    18 政党A  政党A \n19    19 政党A  政党A \n20    20 政党A  政党A \n\n\n\n\n変数名\n説明\n\n\n\nID\n回答者ID\n\n\nVote20\n2020年選挙における当該回答者の投票先\n\n\nVote21\n2021年選挙における当該回答者の投票先\n\n\n\n　たとえば、1番目の回答者は2020年に棄権し、2021年も棄権したことを意味する。また、5番目の回答者は2020年に政党Bに投票し、2021年は政党Cに投票したことを意味する。続いて、このデータを{ggalluvial}に適した形式のデータに加工します。具体的には「2020年棄権、かつ2021年棄権」、「2020年棄権、かつ2021年政党Aへ投票」、…、「2020年政党Bへ投票、かつ2021年政党Aへ投票」のように全ての組み合わせに対し、該当するケース数を計算する必要があります。今回のデータだと、投票先はいずれも政党A、政党B、政党C、政党D、その他、棄権、DK (わからない)の7であるため、49パターンができます。それぞれのパターンに該当するケース数を計算するためにはVote20とVote21でデータをグループ化し、ケース数を計算します。\n\nVote_2021 <- Vote_2021 %>%\n  group_by(Vote20, Vote21) %>%\n  summarise(Freq    = n(),\n            .groups = \"drop\")\n\nVote_2021\n\n# A tibble: 47 × 3\n   Vote20 Vote21  Freq\n   <chr>  <chr>  <int>\n 1 DK     DK       111\n 2 DK     その他     8\n 3 DK     政党A    116\n 4 DK     政党B     29\n 5 DK     政党C     15\n 6 DK     政党D      7\n 7 DK     棄権      57\n 8 その他 DK        18\n 9 その他 その他    73\n10 その他 政党A    121\n# … with 37 more rows\n\n\n　2020年の調査で「わからない」と回答し、2021年の調査でも「わからない」と回答した回答者数は111名、2020年の調査で「わからない」と回答し、2021年の調査では「その他」と回答した回答者数は8名、…といったことが分かりますね。\n　続いて、グラフを作成する前に投票先変数 (Vote20とVote21)をfactor化します。可視化の際、投票先が出力される順番に決まりはありませんが、政党A、政党B、政党C、…、DKの順が自然かと思います。むろん、こちらは自分から見て分かりやいように順番を決めましょう。ただし、2変数における水準 (level)の順番は一致させた方が良いでしょう。\n\nVote_2021 <- Vote_2021 %>%\n  mutate(Vote20 = factor(Vote20, levels = c(\"政党A\", \"政党B\", \"政党C\", \"政党D\", \n                                            \"その他\", \"棄権\", \"DK\")),\n         Vote21 = factor(Vote21, levels = c(\"政党A\", \"政党B\", \"政党C\", \"政党D\", \n                                            \"その他\", \"棄権\", \"DK\")))\n\n　それでは沖積図を描いてみましょう。使用する幾何オブジェクトはgeom_alluvium()とgeom_stratum()です。必ずこの順番でレイヤーを重ねてください。マッピングはy、axis1、axis2に対し、yには当該パターン内のケース数 (Freq)、axis1は2009年の投票先 (Vote20)、axis2は2010年の投票先 (Vote21)を指定します4。これらのマッピングはgeom_stratum()とgeom_alluvim()共通であるため、ggplot()内でマッピングした方が効率的です。\n\nVote_2021 %>%\n    ggplot(aes(y = Freq, axis1 = Vote20, axis2 = Vote21)) +\n    geom_alluvium() +\n    geom_stratum()\n\n\n\n\n\n\n\n　何かの図は出てきましたが、これだけだと、それぞれの四角形がどの政党を示しているのかが分かりませんね。四角形内に政党名を出力するためには{ggplot2}内蔵のgeom_text()を使用します。マッピング要素はggplot()内でマッピングしたものに加え、labelが必要ですが、ここではafter_stat(stratum)を指定します。そして、aes()のその側にstat = \"stratum\"を指定するだけです。もし、文字化けが生じる場合は、geom_text()内にフォントの指定が必要があり、familyを使います (たとえば、family = \"HiraginoSans-W3\"など)。theme_*()内でbase_familyを指定した場合でも必要です。\n\nVote_2021 %>%\n    ggplot(aes(y = Freq, axis1 = Vote20, axis2 = Vote21)) +\n    geom_alluvium() +\n    geom_stratum() +\n    geom_text(aes(label = after_stat(stratum)), \n              stat = \"stratum\")\n\n\n\n\n\n\n\n　これで沖積図はとりあえず完成ですが、少し読みやすく加工してみましょう。たとえば、2020年に政党Aに投票した回答者における2021年の投票先の割合を見たいとした場合、geom_alluvium()内にfill = Vote20をマッピングします。これで帯に2020年の投票先ごとの色付けができます。\n\nVote_2021 %>%\n    ggplot(aes(y = Freq, axis1 = Vote20, axis2 = Vote21)) +\n    geom_alluvium(aes(fill = Vote20)) +\n    geom_stratum() +\n    geom_text(aes(label = after_stat(stratum)), \n              stat = \"stratum\")\n\n\n\n\n\n\n\n　fill = Vote21とマッピングした場合は、感覚が変わります。実際にやってみましょう。\n\nAlluvial_Plot <- Vote_2021 %>%\n    ggplot(aes(y = Freq, axis1 = Vote20, axis2 = Vote21)) +\n    geom_alluvium(aes(fill = Vote21)) +\n    geom_stratum() +\n    geom_text(aes(label = after_stat(stratum)), \n              stat = \"stratum\", family = \"HiraginoSans-W3\")\n\nAlluvial_Plot\n\n\n\n\n\n\n\n　この場合、2020年に政党Aに投票した人が2021年にどこに流れたかが分かりやすくなります。Vote20に色分けするか、Vote21に色分けするかは作成する人が決める問題であり、自分の主張・メッセージに適したマッピングをしましょう。\n　最後に、図をもう少し加工してみましょう。まず、横軸に0.8、1.2、1.6、2.0となっている目盛りを修正し、1と2の箇所に「2020年選挙」と「2021年選挙」を出力します。これはscale_x_continuous()で調整可能です。そして、theme_minimal()で余計なものを排除したテーマを適用します。最後にtheme()内で全ての凡例を削除 (legend.position = \"none\")し、パネルのグリッド (panel.grid)と縦軸・横軸のタイトル (axis.title)、縦軸の目盛りラベル (axis.text.y)を削除 (element_blank())します。\n\nAlluvial_Plot +\n    scale_x_continuous(breaks = 1:2, \n                       labels = c(\"2020年選挙\", \"2021年選挙\")) +\n    theme_minimal(base_size = 16) +\n    theme(legend.position = \"none\",\n          panel.grid = element_blank(),\n          axis.title = element_blank(),\n          axis.text.y = element_blank())\n\n\n\n\n\n\n\n　これでだいぶスッキリした沖積図が出来上がりました。"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-tree",
    "href": "visualization4.html#RN4Esec-visual4-tree",
    "title": "20  可視化 [発展]",
    "section": "\n20.15 ツリーマップ",
    "text": "20.15 ツリーマップ\n　ツリーマップ（tree map）は変数の値の大きさを長方形の面積として表すグラフです。全体におけるシェアを示す時に使う点で、円グラフの代替案の一つになります。円グラフは項目が多すぎると読みにくいデメリットがありますが、ツリーマップは項目が多い場合でも有効です。むろん、多すぎると読みにくいことは同じですので、注意が必要です。\n　ツリーマップを作成するためには{treemapify}パッケージのgeom_treemap()幾何オブジェクトを使用します。まず、{treemapify}をインストールし、読み込みます。\n\npacman::p_load(treemapify)\n\n　ここではCountry_dfからアジア諸国の人口（Population）をツリーマップをして可視化したいと思います。geom_treemap()の場合、各長方形は面積の情報のみを持ちます。この面積の情報をareaにマッピングします。\n\nCountry_df %>%\n  filter(Continent == \"Asia\") %>%\n  ggplot() +\n  geom_treemap(aes(area = Population))\n\n\n\n\n\n\n\n　これだけだと各長方形がどの国を指しているのかが分かりませんね。長方形の上に国名（Country）を追加するためにはgeom_treemap_text()幾何オブジェクトを使用します。マッピングはareaとlabelに対し、それぞれ面積を表すPopulationと国名を表すCountryを指定します。areaはgeom_treemap()とgeom_treemap_text()両方で使われるのでggplot()の内部でマッピングしても問題ありません5。また、aes()の外側にcolor = \"white\"で文字を白に指定し、place = \"center\"で長方形の真ん中にラベルが付くようにします。\n\nCountry_df %>%\n  filter(Continent == \"Asia\") %>%\n  ggplot(aes(area = Population)) +\n  geom_treemap() +\n  geom_treemap_text(aes(label = Country), color = \"white\", place = \"center\")\n\n\n\n\n\n\n\n　これでツリーマップが完成しました。インドと中国の存在感がかなり大きいですね。更にラベルのサイズを長方形に合わせると、その存在感をより高めることができます。ラベルの大きさを長方形に合わせるにはgeom_treepmap_text()の内部にgrow = TRUEを指定します。\n\nCountry_df %>%\n  filter(Continent == \"Asia\") %>%\n  ggplot(aes(area = Population, label = Country)) +\n  geom_treemap() +\n  geom_treemap_text(color = \"white\", place = \"center\",\n                    grow = TRUE)\n\n\n\n\n\n\n\n　ここで更に次元を追加するために、色塗りをしてみましょう。たとえば、G20加盟国か否かで色分けをしたい場合、fillにG20をマッピングします。ただし、今のままだとG20は連続変数扱いになりますので、character型、またはfactor型に変換します。\n\nCountry_df %>%\n  mutate(G20 = if_else(G20 == 1, \"Member\", \"Non-member\")) %>%\n  filter(Continent == \"Asia\") %>%\n  ggplot(aes(area = Population, fill = G20,\n             label = Country)) +\n  geom_treemap() +\n  geom_treemap_text(color = \"white\", place = \"centre\",\n                    grow = TRUE) +\n  labs(fill = \"G20\") +\n  ggtitle(\"Population in Asia\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n　色塗りは連続変数に対して行うことも可能です。ここでは2018年人間開発指数（HDI_2108）の値に応じて色塗りをしてみます。また、HDI_2018が低い（low）とbrown3、高い（high）とcornflowerblue色にします。真ん中の値（midpoint）は0.7とし、色（mid）はcornsilkを使います。\n　連続変数でマッピングされた色塗り（fill）の調整にはscale_fill_gradient()、またはscale_fill_gradient2()を使います。前者は中間点なし、後者は中間点ありです。これらの使い方は第19章で紹介しましたscale_color_gradient()と同じです。\n\nCountry_df %>%\n  filter(Continent == \"Asia\") %>%\n  ggplot(aes(area = Population, fill = HDI_2018,\n             label = Country)) +\n  geom_treemap() +\n  geom_treemap_text(color = \"white\", place = \"centre\",\n                    grow = TRUE) +\n  scale_fill_gradient2(low = \"brown3\",\n                       mid = \"cornsilk\",\n                       high = \"cornflowerblue\",\n                       midpoint = 0.7) +\n  labs(fill = \"UN Human Development Index (2018)\") +\n  ggtitle(\"Population in Asia\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n　ちなみに以上の図を円グラフにすると以下のようになります（国名は人口の割合が2.5%を超える国のみ表示）。ツリーマップと比較してかなり読みにくいことが分かります。\n\nCountry_df %>%\n  filter(Continent == \"Asia\") %>%\n  arrange(Population) %>%\n  mutate(Prop        = Population / sum(Population) * 100,\n         LabelY      = 100 - (cumsum(Prop) - 0.5 * Prop),\n         CountryName = if_else(Prop < 2.5, \"\", Country),\n         Country     = fct_inorder(Country)) %>%\n  ggplot() +\n  geom_bar(aes(x = 1, y = Prop, group = Country, fill = HDI_2018), \n           color = \"black\", stat = \"identity\", width = 1) +\n  geom_text(aes(x = 1, y = LabelY, label = CountryName)) +\n  coord_polar(\"y\", start = 0) +\n  scale_fill_gradient2(low = \"brown3\",\n                       mid = \"cornsilk\",\n                       high = \"cornflowerblue\",\n                       midpoint = 0.7) +\n  labs(fill = \"UN Human Development Index (2018)\") +\n  ggtitle(\"Population in Asia\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        panel.grid = element_blank(),\n        axis.title = element_blank(),\n        axis.text  = element_blank())\n\n\n\n\n\n\n\n　ただし、ツリーマップが必ずしも円グラフより優れているとは言えません。たとえば、 Heer and Bostock (2010) の研究では円グラフとツリーマップを含む9種類のグラフを用い、被験者に大小関係を判断してもらう実験を行いましたが、ツリーマップ（四角形の面積）は円グラフ（角度）よりも判断までの所要時間が長いことが述べています。"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-mosaic",
    "href": "visualization4.html#RN4Esec-visual4-mosaic",
    "title": "20  可視化 [発展]",
    "section": "\n20.16 モザイクプロット",
    "text": "20.16 モザイクプロット\nモザイクプロットは2つの離散変数（おもに名目変数）の関係を可視化するために Hartigan and Kleiner (1984) が考案した図です。2つの名目変数間の関係を見る際によく使われるものはクロス表（クロス集計表）でしょう。\n\npacman::p_load(ggmosaic)\n\n\nMosaic_df <- Country_df %>%\n    select(Country, Continent, Polity = Polity_Type, PPP = PPP_per_capita) %>%\n    mutate(Continent = factor(Continent, \n                              levels = c(\"Africa\", \"America\", \"Asia\",\n                                         \"Europe\", \"Oceania\")),\n           Polity    = factor(Polity,\n                              levels = c(\"Autocracy\", \"Closed Anocracy\",\n                                         \"Open Anocracy\", \"Democracy\",\n                                         \"Full Democracy\")),\n           PPP       = if_else(PPP >= 15000, \"High PPP\", \"Low PPP\"),\n           PPP       = factor(PPP, levels = c(\"Low PPP\", \"High PPP\"))) %>%\n    drop_na()\n\n\nhead(Mosaic_df)\n\n# A tibble: 6 × 4\n  Country     Continent Polity          PPP     \n  <chr>       <fct>     <fct>           <fct>   \n1 Afghanistan Asia      Closed Anocracy Low PPP \n2 Albania     Europe    Democracy       Low PPP \n3 Algeria     Africa    Open Anocracy   Low PPP \n4 Angola      Africa    Closed Anocracy Low PPP \n5 Argentina   America   Democracy       High PPP\n6 Armenia     Europe    Democracy       Low PPP \n\n\n　クロス表を作成する内蔵関数としてはtable()があります。2つの変数が必要となり、第一引数が行、第二引数が列を表します。\n\nMosaic_Tab <- table(Mosaic_df$Continent, Mosaic_df$Polity)\nMosaic_Tab\n\n         \n          Autocracy Closed Anocracy Open Anocracy Democracy Full Democracy\n  Africa          3              14            11        18              1\n  America         0               1             4        16              5\n  Asia           13               6             0        15              3\n  Europe          2               1             2        16             20\n  Oceania         0               0             2         0              2\n\n\n　このMosaic_Tabのクラスは\"table\"ですが、\"table\"クラスのオブジェクトをplot()に渡すと別途のパッケージを使わずモザイクプロットを作成することができます。\n\n\n\n\nplot(Mosaic_Tab)\n\n\n\n\n\n\n\n　やや地味ではありますが、モザイクプロットが出来ました。ここからはより読みやすいモザイクプロットを作成するために{ggmosaic}パッケージのgeom_mosaic()関数を使います。\n　geom_mosaic()の場合、xのみのマッピングで十分です。ただし、特定の変数を指定するのではなく、product(変数1, 変数2)をxにマッピングする必要があります。table()関数同様、変数1は行、変数2は列です。また、欠損値が含まれている行がある場合は、aes()の外側にna.rm = TRUEを指定する必要があります。今回はdrop_na()で欠損値をすべて除外しましたが、念の為に指定しておきます。\n\nMosaic_df %>%\n    ggplot() +\n    geom_mosaic(aes(x = product(Polity, Continent)), na.rm = TRUE) +\n    labs(x = \"Continent\", y = \"Polity Type\") +\n    theme_minimal() +\n    theme(panel.grid = element_blank())\n\nWarning: `unite_()` was deprecated in tidyr 1.2.0.\nℹ Please use `unite()` instead.\nℹ The deprecated feature was likely used in the ggmosaic package.\n  Please report the issue at <]8;;https://github.com/haleyjeppson/ggmosaichttps://github.com/haleyjeppson/ggmosaic]8;;>.\n\n\n\n\n\n\n\n\n　これで出来上がりですが、\"table\"オブジェクトをplot()に渡した結果とあまり変わらないですね。続いて、この図を少し改良してみましょう。まずはセルの色分けですが、これはfillに色分けする変数をマッピングするだけです。今回は政治体制ごとにセルを色分けしましょう。また、文字を大きめにし、横軸の目盛りラベルを回転します。\n\nMosaic_df %>%\n    ggplot() +\n    geom_mosaic(aes(x = product(Polity, Continent), fill = Polity), \n                na.rm = TRUE) +\n    labs(x = \"Continent\", y = \"Polity Type\") +\n    theme_minimal(base_size = 16) +\n    theme(legend.position = \"none\",\n          panel.grid      = element_blank(),\n          axis.text.x     = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n\n　次元を追加するためにはファセット分割を使います。たとえば、一人当たりPPP GDPの高低（PPP）でファセットを分割する場合、facet_wrap(~PPP)レイヤーを足すだけです。\n\nMosaic_df %>%\n    ggplot() +\n    geom_mosaic(aes(x = product(Polity, Continent), fill = Polity), \n                na.rm = TRUE) +\n    labs(x = \"Continent\", y = \"Polity Type\") +\n    facet_wrap(~PPP, ncol = 2) +\n    theme_minimal(base_size = 16) +\n    theme(legend.position = \"none\",\n          panel.grid      = element_blank(),\n          axis.text.x     = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n\n　ただし、一つ問題があります。それは目盛りラベルの位置です。例えば、右側の横軸目盛りラベルの場合、セルの位置とラベルの位置がずれています。これは2つのファセットが同じ目盛りを共有し、左側の方に合わせられたため生じるものです。よく見ると横軸も縦軸も目盛りラベルに位置が同じであることが分かります。これを解消するためには、facet_wrap()の内部にscale = \"free\"を指定します6。これは各ファセットが独自のスケールを有することを意味します。\n\nMosaic_df %>%\n    ggplot() +\n    geom_mosaic(aes(x = product(Polity, Continent), fill = Polity), \n                na.rm = TRUE) +\n    labs(x = \"Continent\", y = \"Polity Type\") +\n    facet_wrap(~PPP, ncol = 2, scale = \"free\") +\n    theme_minimal(base_size = 16) +\n    theme(legend.position = \"none\",\n          panel.grid      = element_blank(),\n          axis.text.x     = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n\n　右側ファセットの横軸ラベルが重なってしまいましたが、これでとりあえず完成です。アフリカにおけるOpen AnocracyとClosed Anocracyの頻度が0であるため、これは仕方ありません。一つの対処方法としては以下のように縦軸目盛りを削除し、凡例で代替することが考えられます。\n\nMosaic_df %>%\n    ggplot() +\n    geom_mosaic(aes(x = product(Polity, Continent), fill = Polity), \n                na.rm = TRUE) +\n    labs(x = \"Continent\", y = \"Polity Type\", fill = \"Polity Type\") +\n    facet_wrap(~PPP, ncol = 2, scale = \"free_x\") +\n    theme_minimal(base_size = 16) +\n    theme(panel.grid  = element_blank(),\n          axis.text.y = element_blank(),\n          axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "visualization4.html#RN4Esec-visual4-further",
    "href": "visualization4.html#RN4Esec-visual4-further",
    "title": "20  可視化 [発展]",
    "section": "\n20.17 その他のグラフ",
    "text": "20.17 その他のグラフ\nThe R Graph Galleryでは本書で紹介できなかった様々な図のサンプルおよびコードを見ることができます。ここまで読み終わった方なら問題なくコードの意味が理解できるでしょう。{ggplot2}では作成できないグラフ（アニメーションや3次元図、インタラクティブなグラフ）についても、他のパッケージを利用した作成方法について紹介されているので、「こんな図が作りたいけど、作り方が分からん！」の時には、まずThe R Graph Galleryに目を通してみましょう。\n\n私たちのR 私たちのR 21  モデルの可視化 19  可視化 [応用] 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 20  可視化 [発展] 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR\n\n\n\nHartigan, J. A., and Beat Kleiner. 1984. “A Mosaic of Television Ratings.” The American Statistician 38: 32–35.\n\n\nHeer, Jeffrey, and Michael Bostock. 2010. “Crowdsourcing Graphical Perception: Using Mechanical Turk to Assess Visualization Design.” Proceedings of the SIGCHI Conference on Human Factors in Computing Systems."
  },
  {
    "objectID": "visualization5.html",
    "href": "visualization5.html",
    "title": "21  モデルの可視化",
    "section": "",
    "text": "私たちのR 私たちのR 22  R Markdown [基礎] 20  可視化 [発展] 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 21  モデルの可視化 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "rmarkdown.html#RN4Ermarkdown-intro",
    "href": "rmarkdown.html#RN4Ermarkdown-intro",
    "title": "22  R Markdown [基礎]",
    "section": "\n22.1 R Markdownとは",
    "text": "22.1 R Markdownとは\n　R Markdownとは名前通り、RとMarkdownが結合されたものです。本書を通じてRを紹介してきましたが、Markdownは初めて出てくるものです。John GruberとAaron Swartzが2004年提案した軽量Markup言語ですが、そもそもMarkup言語とはなんでしょうか。\n　Markup言語を知るためにはプレーンテキスト（plain text）とリッチテキスト（rich text、またはマルチスタイルテキスト）の違いについて知る必要があります。プレーンテキストとは書式情報などが含まれていない純粋なテキストのみで構成されている文書です。書式情報とは文書の余白、文字の大きさ、文字の色などがあります。これまでRStudio上で書いてきたRコードもプレーンテキストです。コードに色が自動的に付けられますが、これはRStudioが色付けをしてくれただけで、ファイル自体はテキストのみで構成されています。macOSのTextEdit、Windowsのメモ帳、Linux GUI環境のgeditやKATE、CLI環境下のvim、Emacs、nanoなどで作成したファイルは全てプレーンテキストです。これらのテキストエディターには書式設定や図表の挿入などの機能は付いておりません。一方、リッチテキストとは書式情報だけでなく、図表なども含まれる文書です。Microsoft Wordとかで作成したファイルがその代表的な例です。他にもPagesやLibreOffice Writerから作成したファイルなどがあります。これらのワードプロセッサーソフトウェアは書式の設定や図表・リンクの挿入などができます。そして、Markup言語とはプレーンテキストのみでリッチテキストを作成するための言語です。\n　Markup言語の代表的な存在がHTMLです。そもそもHTMLのMLはMarkup Languageの略です。読者の皆さんがウェブブラウザから見る画面のほとんどはHTMLで書かれています。この『私たちのR』もHTMLです。この文書には図表があり、太字、見出し、水平線など、テキスト以外の情報が含んでいます。しかし、HTMLは純粋なテキストのみで書かれており、ウェブブラウザ（Firefox、Chrome、Edgeなど）がテキストファイルを読み込み、解釈して書式が付いている画面を出力してくれます。例えば、リンク（hyperlink）について考えてみましょう。「SONGのHP」をクリックすると宋のホームページに移動します。ある単語をクリックすることで、他のウェブサイトへ飛ばす機能を付けるためにはHTMLファイルの中に、以下のように入力します。\n<a href=\"https://www.jaysong.net\">SONGのHP</a>\n　これをウェブブラウザが自動的に「SONGのHP」と変換し、画面に出力してくれます。これは、書式情報などが必要な箇所にコードを埋め込むことによって実現されます。そして、このMarkup言語をより単純な文法で再構成したものがMarkdownです。例えば、以上のHTMLはMarkdownでは以下のように書きます。\n[SONGのHP](https://www.jaysong.net)\n　同じ意味のコードですが、Markdownの方がより簡潔に書けます。このMarkdownは最終的にHTMLやMicrosoft Word、PDF形式で変換されます。一般的にはHTML出力を使いますが、自分のPCにLaTeX環境が用意されている場合はPDF形式で出力することも可能であり、個人的には推奨しておりませんが、Microsoft Work文書ファイルへ変換することも可能です。また、HTML（+ JavaScript）へ出力可能であることを利用し、スライドショー、e-Book、ホームページの作成にもMarkdownが使えます。\n　R MarkdownはMarkdownにRコードとその結果を同時に載せることができるMarkdownです。それでもピンと来ない方も多いでしょう。それでは、とりあえず、R Markdownをサンプルコードから体験してみましょう。"
  },
  {
    "objectID": "rmarkdown.html#RN4Eとりあえずknit",
    "href": "rmarkdown.html#RN4Eとりあえずknit",
    "title": "22  R Markdown [基礎]",
    "section": "\n22.2 とりあえずKnit",
    "text": "22.2 とりあえずKnit\n　R Markdownの文法について説明する前に、とりあえずR Markdownというのがどういうものかを味見してみます。既に述べたようにR MarkdownにはRコードも含まれるため、事前にプロジェクトを生成してから進めることをおすすめします。\n　R Markdownファイルを生成するにはFile -> New File -> R Markdown…を選択します。Title:とAuthor:には文書のタイトルと作成者を入力します。Default Output FormatはデフォルトはHTMLとなっていますが、このままにしておきましょう。ここでの設定はいつでも変更可能ですので、何も触らずにOKを押しても大丈夫です。\n　OKを押したら自動的にR Markdownのサンプルファイルが生成されます。そしたらSourceペインの上段にあるボタン1をクリックしてみましょう。最初はファイルの保存ダイアログが表示されますが、適切な場所（プロジェクトのフォルダなど）に保存すれば、自動的にMarkdown文書を解釈し始めます。処理が終わればViewerペインに何かの文章が生成されます。これからの内容を進める前にSourceペインとViewerペインの中身をそれぞれ対応しながら、どのような関係があるのかを考えてみましょう。\n　R Markdownファイルは大きく3つの領域に分けることができます（ 図 22.1 ）。まず、最初に---と---で囲まれた領域はヘッダー（Header）と呼ばれる領域です。ここでは題目、作成者情報の入力以外にも、文書全体に通じる設定を行います。これは第22.5節で解説します。次はR Markdownの核心部であるチャンク（Chunk）です。チャンクは```{r}と```で囲まれた領域であり、Rコードが入る箇所です。チャンクに関しましては第22.3節の後半と第22.4節で解説します。その他の領域がマークダウン（Markdown）であり、文書に該当します。\n\n\n図 22.1: R Markdownのサンプルページ\n\n\n　まずは、文章の書き方から説明します。非常に簡単な文法で綺麗、かつ構造化された文書が作成可能であり、これに慣れるとMarkdown基盤のノートアプリなどを使って素早くノート作成、メモが出来ます。"
  },
  {
    "objectID": "rmarkdown.html#RN4Esec-rmarkdown_grammar",
    "href": "rmarkdown.html#RN4Esec-rmarkdown_grammar",
    "title": "22  R Markdown [基礎]",
    "section": "\n22.3 Markdown文法の基本",
    "text": "22.3 Markdown文法の基本\n　まずは、Markdownの文法について解説します。ここではMarkdown文書内に以下のようなことを作成する方法を実際の書き方と、出力画面を対比しながら解説していきます。\n\n改行\n強調: 太字、イタリック、アンダーライン、取り消し線\n箇条書き\n見出し\n区切り線\n表\n画像\nリンク\n脚注\n数式\n引用\nコメント\nRコード\n\n\n22.3.1 改行\n　Markdownにおける改行はやや特殊です。特殊といっても難しいことはありません。普段よりもう一行改行するだけです。Markdownの場合、1回の改行は改行として判定されず、同じ行の連続と認識します。たとえば、Inputのように入力するとOutputのように文章1と文章2が繋がります。\nInput:\n文章1\n文章2\nOutput:\n文章1 文章2\n　文章1と文章2を改行するためにはもう一行、改行する必要があります。以下の例を見てください。\nInput:\n文章1\n\n文章2\nOutput:\n文章1\n文章2\n　こうすることで段落間の間隔を強制的に入れることとなり、作成者側にも読みやすい文書構造になります2。\n\n22.3.2 強調\n文章の一部を強調する方法として太字、イタリック3、アンダーラインがあり、強調ではありませんが、ついでに取り消し線についても紹介します。いずれも強調したい箇所を記号で囲むだけです。\nInput:\n文章の一部を**太字**にしてみましょう。\n\n*イタリック*もいいですね。\n\n~~取り消し線~~はあまり使わないかも。\n\n<u>アンダーライン</u>はHTMLタグを使います。\nOutput:\n文章の一部を太字にしてみましょう。\nイタリックもいいですね。\n取り消し線はあまり使わないかも。\nアンダーラインはHTMLタグを使います。\n\n22.3.3 箇条書き\n箇条書きには順序なしと順序付きがあります。順序なしの場合*または-の後に半角スペースを1つ入れるだけです。また、2文字以上の字下げで下位項目を追加することもできます。\nInput:\n- 項目1\n  - 項目1-1\n  - 項目1-2\n    - 項目1-2-1\n      - 項目1-2-1-1\n    - 項目1-2-2\n- 項目2\n- 項目3\nOutput:\n\n項目1\n\n項目1-1\n項目1-2\n\n項目1-2-1\n\n項目1-2-1-1\n\n\n項目1-2-2\n\n\n\n\n項目2\n項目3\n\n　続きまして順序付き箇条書きですが、これは-（または*）を数字.に換えるだけです。順序なしの場合と違って数字の後にピリオド（.）が付くことに注意してください。また、下位項目を作成する際、順序なしはスペース2つ以上が必要でしたが、順序付きの場合、少なくとも3つが必要です。\nInput:\n1. 項目1\n   1. 項目1-1\n   2. 項目1-2\n2. 項目2\n   * 項目2-1\n   * 項目2-2\n3. 項目3\nOutput:\n\n項目1\n\n項目1-1\n項目1-2\n\n\n項目2\n\n項目2-1\n項目2-2\n\n\n項目3\n\n22.3.4 見出し\n　章、節、段落のタイトルを付ける際は#を使います。#の数が多いほど文字が小さくなります。章の見出しを##にするなら節は###、小節または段落は####が適切でしょう。見出しは####まで使えます。\nInput:\n# 見出し1\n## 見出し2\n### 見出し3\n#### 見出し4\nOutput:\n\n見出し1\n\n\n見出し2\n\n\n見出し3\n\n\n見出し4\n\n\n22.3.5 区切り線\n区切り線は---または***を使います。\nInput:\n---\nOutput:\n\n22.3.6 表\n　Markdownの表は非常にシンプルな書き方をしています。行は改行で、列は|で区切られます。ただ、表の第1行はヘッダー（変数名や列名が表示される行）扱いとなり、ヘッダーと内容の区分は|---|で行います。以下はMarkdownを利用した簡単な表の書き方です。ここでは可読性のためにスペースを適宜入れましたが、スペースの有無は結果に影響を与えません。\nInput:\n|ID   |Name     |Math    |English |Favorite food|\n|:---:|---------|-------:|-------:|-------------|\n|1    |SONG     |15      |10      |Ramen        |\n|2    |Yanai    |100     |100     |Cat food     |\n|3    |Shigemura|80      |50      |Raw chicken  |\n|4    |Wickham  |80      |90      |Lamb         |\nOutput:\n\n\nID\nName\nMath\nEnglish\nFavorite food\n\n\n\n1\nSONG\n15\n10\nRamen\n\n\n2\nYanai\n100\n100\nCat food\n\n\n3\nShigemura\n80\n50\nRaw chicken\n\n\n4\nWickham\n80\n90\nLamb\n\n\n\n　1行目はヘッダーであり、太字かつ中央揃えになります。2行目以降はデフォルトでは左揃えになりますが。ただし。|---|をいじることによって当該列の揃えを調整できます。|:---|は左 (デフォルト)、|---:|は右、|:---:|は中央となります。また-の個数は1個以上なら問題ありません。つまり、|-|も|---|も同じです。\n\n22.3.7 画像\n　R Markdownに画像を入れるには![代替テキスト](ファイル名)と入力します。当たり前ですが、画像ファイルがワーキングディレクトリにない場合はパスを指定する必要があります。[代替テキスト]は画像を読み込めなかった場合のテキストを意味します。これは画像が読み込めなかった場合の代替テキストでもありますが、視覚障害者用のウェブブラウザーのためにも使われます。これらのウェブブラウザーはテキストのみ出力されるものが多く、画像の代わりには代替テキストが読み込まれます。\n　例えば、Figsフォルダー内のfavicon.pngというファイルを読み込むとしたら以下のように書きます。\nInput:\n![『私たちのR』ロゴ](Figs/favicon.png)\nOutput:\n\n\n『私たちのR』ロゴ\n\n\n\n22.3.8 リンク\n　ハイパーリンクは[テキスト](URL)のような形式で書きます。[]内は実際に表示されるテキストであり、()は飛ばすURLになります。\nInput:\n毎日1回は[SONGのホームページ](https://www.jaysong.net)へアクセスしましょう。\nOutput:\n毎日1回はSONGのホームページへアクセスしましょう。\n\n22.3.9 脚注\n　脚注は[^固有識別子]と[^固有識別子]: 脚注内容の2つの要素が必要です。まず、文末脚注を入れる箇所に[^xxxx]を挿入します。xxxxは任意の文字列れ構いません。しかし、同じR Markdown内においてこの識別子は被らないように注意してください。実際の脚注の内容は[^xxxx]: 内容のように入力します。これはどこに位置しても構いません。文書の途中でも、最後に入れても、脚注の内容は文末に位置します。ただし、脚注を入れる段落のすぐ後の方が作成する側としては読みやすいでしょう。\nInput:\nこれは普通の文章です[^foot1]。\n\n[^foot1]: これは普通の脚注です。\nOutput:\nこれは普通の文章です4。\n\n22.3.10 数式\n　インライン数式は$数式$で埋め込むことができます。数式はLaTeXの書き方とほぼ同じです。ちなみに、R Markdownの数式はMathJaxによってレンダリングされます。このMathJaxライブラリはHTMLに埋め込まれているのではないため、インターネットに接続せずにHTMLファイルを開くと数式が正しく出力されません。\nInput:\nアインシュタインと言えば、$e = mc^2$でしょう。\nOutput:\nアインシュタインと言えば、\\(e = mc^2\\)でしょう。\n　数式を独立した行として出力する場合は、$の代わりに$$を使用します。\nInput:\n独立した数式の書き方\n\n$$\ny_i \\sim \\text{Normal}(\\mathbf{X} \\boldsymbol{\\beta}, \\sigma).\n$$\nOutput:\n独立した数式の書き方\n\\[\ny_i \\sim \\text{Normal}(\\mathbf{X} \\boldsymbol{\\beta}, \\sigma).\n\\]\n　もし数式が複数の行で構成されている場合は$$内にaligned環境（\\begin{aligned}〜\\end{aligned}）を使用します。むろん、LaTeXと使い方は同じです。\nInput:\n複数の行にわたる数式の書き方\n\n$$\n\\begin{aligned}\n  Y_i      & \\sim \\text{Bernoulli}(\\theta_i), \\\\\n  \\theta_i & = \\text{logit}^{-1}(y_i^*), \\\\\n  y_i^*    & = \\beta_0 + \\beta_1 x_1 + \\beta_2 z_1.\n\\end{aligned}\n$$\nOutput:\n複数の行にわたる数式の書き方\n\\[\n\\begin{aligned}\n  Y_i      & \\sim \\text{Bernoulli}(\\theta_i), \\\\\n  \\theta_i & = \\text{logit}^{-1}(y_i^*), \\\\\n  y_i^*    & = \\beta_0 + \\beta_1 x_1 + \\beta_2 z_1.\n\\end{aligned}\n\\]\n　ここまで見ればお分かりかと思いますが、$$の中にはLaTeXコマンドが使用可能です。たとえば、行列を作成する際は以下のように\\begin{bmatrix}環境を使います。\nInput:\n行列の書き方\n\n$$\nX = \\begin{bmatrix}\n  x_{11} & x_{12} \\\\\n  x_{21} & x_{22} \\\\\n  x_{31} & x_{32}\n\\end{bmatrix}.\n$$\nOutput:\n行列の書き方\n\\[\nX = \\begin{bmatrix}\n  x_{11} & x_{12} \\\\\n  x_{21} & x_{22} \\\\\n  x_{31} & x_{32}\n\\end{bmatrix}.\n\\]\n\n22.3.11 引用\n　引用の際は文章の最初に>を入れるだけです。>の後に半角のスペースが1つ入ります。\nInput:\n「政治とは何か」についてイーストンは以下のように定義しました。\n\n> [A] political system can be designated as those interactions through which values are authoritatively allocated for a society.\nOutput:\n「政治とは何か」についてイーストンは以下のように定義しました。\n\n[A] political system can be designated as those interactions through which values are authoritatively allocated for a society.\n\n\n22.3.12 コメント\n　R Markdownにもコメントを付けることができます。とりあえず書いたが要らなくなった段落や文章があって、消すことがもったいない場合はコメントアウトするのも1つの方法です。ただし、コメントアウトの方法はRは#でしたが、これはR Markdownでは見出しの記号です。R Markdownのコメントは<!--と-->で囲みます。\nInput:\n文章1\n\n<!--\nここはコメントです。\n-->\n\n文章2\nOutput:\n文章1\n\n文章2\n\n22.3.13 コード\n　以上の内容まで抑えると、R Markdownを使って、簡単な文法のみで構造化された文書が作成できます。しかし、R Markdownの意義は文章とコード、結果が統合されることです。それでは文書にRコードを入れる方法について紹介します。\n　コードは```{r}と```の間に入力します。これだけです。これでコードと結果が同時に出力されます。たとえば、print(\"Hello World!\")を走らすコードを入れてみます。\nInput:\n\"Hello World!\"を出力するコード\n\n```{r}\nprint(\"Hello World!\")\n```\nOutput:\n“Hello World!”を出力するコード\n\nprint(\"Hello World!\")\n\n[1] \"Hello World!\"\n\n\n　```{r}と```で囲まれた範囲をR Markdownではチャンク（Chunk）と呼びます。このチャンク内ではRと全く同じことが出来ます。パッケージやデータの読み込み、オブジェクトの生成、データハンドリング、可視化など、全てです。\nInput: 　\n```{r}\n# パッケージの読み込み\nlibrary(tidyverse)\n# R内蔵データセットのirisを使った可視化\niris %>%\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) %>%\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\") +\n  theme_minimal(base_family = \"HiraKakuProN-W3\")\n```\nOutput:\n\n# パッケージの読み込み\nlibrary(tidyverse)\n# R内蔵データセットのirisを使った可視化\niris %>%\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) %>%\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\") +\n  theme_minimal(base_family = \"HiraKakuProN-W3\")\n\n\n\n\n　他にも文中にRコードを埋め込むことも可能です。例えば、ベクトルX <- c(2, 3, 5, 7, 12)があり、この平均値を文中で示したいとします。むろん、文中に「5.8」と書いても問題はありません。しかし、実はXの入力ミスが見つかり、実はc(2, 3, 5, 7, 11)になったらどうなるでしょうか。この「5.8」と書いた箇所を見つけて5.6と修正したいといけません。これは非常に面倒な作業であり、ミスも起こりやすいです。文中でRコードを入れるためには`rコード`のように入力します。\nInput:\n```{r}\nX <- c(2, 3, 5, 7, 11)knit\n```\n\n変数`X`の平均値は`r mean(X)`です。\nOutput:\n\nX <- c(2, 3, 5, 7, 11)\n\n変数Xの平均値は5.6です。\nここで`X`ですが、単に`で囲まれただけではコードと認識されません。これは主に文中に短いコードを入れる際に使う機能です。"
  },
  {
    "objectID": "rmarkdown.html#RN4Esec-rmarkdown_chunk",
    "href": "rmarkdown.html#RN4Esec-rmarkdown_chunk",
    "title": "22  R Markdown [基礎]",
    "section": "\n22.4 チャンクのオプション",
    "text": "22.4 チャンクのオプション\n　既に説明しましたとおり、R MakrdownはR + Markdownです。Rはチャンク、Markdownはチャンク外の部分に相当し、それぞれのカスタマイズが可能です。分析のコードと結果はチャンクにオプションを付けることで修正可能であり、文章の部分は次節で紹介するヘッダーで調整できます。ここではチャンクのオプションについて説明します。\n　チャンクは```{r}で始まりますが、実は{r}の箇所にオプションを追加することができます。具体的には{r チャンク名, オプション1, オプション2, ...}といった形です。まずはチャンク名について解説します。\n\n22.4.1 チャンク名とチャンク間依存関係\n　チャンク名は{r チャンク名}で指定し、rとチャンク名の間には,が入りません。これはチャンクに名前をしていするオプションですが、多くの場合分析に影響を与えることはありません。このチャンク名が重要となるのはcacheオプションを付ける場合です。\n　cacheオプションは処理結果を保存しておくことを意味します。チャンク内のコードはKnitする度に計算されます。もし、演算にかなりの時間を費やすコードが含まれている場合、Knitの時間も長くなります。この場合、cache = TRUEオプションを付けておくと、最初のKnit時に結果をファイルとして保存し、次回からはその結果を読み込むだけとなります。時間が非常に節約できるため、よく使われるオプションの1つです。ただし、チャンク内のコードが修正された場合、Knit時にもう一回処理を行います。コードの実質的な内容が変わらなくても、つまり、スペースを1つ入れただけでも再計算となります。\n　ここで1つ問題が生じます。たとえば、以下のようなコードを考えてみてください。\n```{r}\nX <- c(2, 3, 5, 7, 10)\n```\n\n```{r, cache = TRUE}\nmean(X)\n```\n　この構造に問題はありません。しかし、ここでXの5番目の要素を11に修正したとします。そしてもう一回Knitを行ったらどうなるでしょうか。正解は「何も変わらない」です。新しいmean(X)の結果は5.6のはずですが、5.4のままです。なぜなら、2番目のチャンクの結果は既に保存されており、コードも修正していないからです。もう一回強調しておきますが、cahce = TRUEの状態で当該チャンクが修正されない場合、結果は変わりません。\n　このようにあるチャンクの内容が他のチャンク内容に依存しているケースがあります。この場合、dependsonオプションを使います。使い方はdependson = \"依存するチャンク名\"です。もし、1番目のチャンク名をdefine_Xとしたら、dependson = \"define_X\"とオプションを加えます。\n```{r define_X}\nX <- c(2, 3, 5, 7, 10)\n```\n\n```{r, cache = TRUE, dependson = \"define_X\"}\nmean(X)\n```\n　このようにチャンク名とcache、dependsonオプションを組み合わせると、依存するチャンクの中身が変わったら、cache = TRUEでも再計算を行います。\n\n22.4.2 コードまたは結果の表示/非常時\n　次は「コードだけ見せたい」、「結果だけ見せたい」場合使うオプションを紹介します。これはあまり使わないかも知れませんが、本書のような技術書にはよく使う機能です。コードのみ出力し、計算を行わない場合はeval = FALSEオプションを、コードを見せず、結果のみ出力する場合はecho = FALSEを指定するだけです。\n他にもコードと結果を両方隠すことも可能です。つまり、チャンク内のコードは実行されるが、そのコードと結果を隠すことです。この場合に使うオプションがincludeであり、既定値はTRUEです。チャンクオプションにinclude = FALSEを追加すると、当該チャンクのコードは実行されますが、コードと結果は表示されません。\n\n22.4.3 プロット\n　既に見てきた通り、R Markdownは作図の結果も出力してくれます。そこで、図のサイズや解像度を変えることもできます。ここではプロットに関するいくつかのオプションを紹介します。\n\n\nfig.height: 図の高さ。単位はインチ。デフォルト値は7\n\nfig.width: 図の幅。単位はインチ。デフォルト値は7\n\nfig.align: 図の位置。デフォルトは\"left\"。\"center\"の場合、中央揃え、\"right\"の場合は右揃えになる。\n\nfig.cap: 図のキャプション\n\ndpi: 図の解像度。デフォルトは72。出版用の図は一般的に300以上を使う\n\n　実際に高さ5インチ、幅7インチ、中央揃え、解像度72dpiの図を作成し、キャプションとして「irisデータセットの可視化」を付けてみましょう。\nInput: 　\n```{r, fig.height = 5, fig.width = 7, fig.align = \"center\", fig.cap = \"図の例\", dpi = 72}\niris %>%\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) %>%\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\") +\n  theme_minimal(base_family = \"HiraKakuProN-W3\")\n```\nOutput:\n\niris %>%\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) %>%\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\") +\n  theme_minimal(base_family = \"HiraKakuProN-W3\")\n\n\n\n図の例\n\n\n\n\n\n22.4.4 コードの見栄\n　第10章ではスクリプトの書き方を紹介しましたが、常にその書き方に則った書き方をしているとは限りません。自分だけが見るコードなら別に推奨されない書き方でも問題ないかも知れませんが、R Markdownの結果は他人と共有するケースが多いため、読みやすいコードを書くのも大事です。ここで便利なオプションがtidyオプションです。tidy = TRUEを加えると、自動的にコードを読みやすい形に調整してくれます。たとえば、以下のコードは字下げもなく、スペースもほとんど入れていないコードですが、tidy = TRUEを付けた場合と付けなかった場合の出力結果の違いを見てみましょう。\nInput:\n```{r, eval = FALSE}\nfor(i in 1:10){\nprint(i*2)\n}\n```\nOutput:　\n\nfor(i in 1:10){\nprint(i*2)\n}\n\nInput:\n```{r, eval = FALSE, tidy = TRUE}\nfor(i in 1:10){\nprint(i*2)\n}\n```\nOutput:\n\nfor (i in 1:10) {\n    print(i * 2)\n}\n\n　tidy = TRUEを付けただけで、読みやすいコードになりました。ちなみにtidyオプションを使うためには事前にformatRパッケージをインストールしておく必要があります。ただし、formatRパッケージはR Markdwon内において読み込んでおく必要はありません。また、formatRパッケージは万能ではないため、普段から読みやすいコードを書くようにしましょう。"
  },
  {
    "objectID": "rmarkdown.html#RN4Esec-rmarkdown_header",
    "href": "rmarkdown.html#RN4Esec-rmarkdown_header",
    "title": "22  R Markdown [基礎]",
    "section": "\n22.5 ヘッダーのオプション",
    "text": "22.5 ヘッダーのオプション\n　R Markdownファイルを生成すると、ファイルの最上段には以下のようなヘッダー（header）というものが生成されます。\n---\ntitle: \"Untitled\"\nauthor: \"Jaehyun Song\"\ndate: \"8/6/2020\"\noutput: html_document\n---\n　基本的には4つの項目が指定されており、それぞれ文書のタイトル（title:）、作成者名（author:）、作成日（date:）、出力形式（output:）があります。タイトルと作成者名はファイル生成時に指定した内容が、作成日は今日の日付が、出力形式はHTMLで設定した場合html_documentになっています。R MarkdownヘッダーはYAML（やむる）形式で書かれています。こちらはいつでも修正可能であり、インラインRコードを埋め込むことも可能です。たとえば、作成日をファイル生成日でなく、Knitした日付にしたい場合は日付を出力するSys.Date()関数を使って、date: \"最終修正: `r Sys.Date()`\"のように書くことも可能です。他にもデフォルトでは指定されていませんが、subtitle:を使ってサブタイトルを指定したり、abstract:で要約を入れることも可能です。\n　また、R Markdownのコメントは<!--と-->を使いますが、ヘッダー内のコメントはRと同様、#を使います。\n　ヘッダーで設定できる項目は数十個以上ですが、ここでは頻繁に使われる項目について紹介します。\n\n22.5.1 目次の追加\n　R Markdownの文章が長くなったり、コードが多く含まれる場合、目次を入れたら文章の構造が一目で把握できるでしょう。目次は見出しに沿って自動的に生成されます。#は章、##は節といった形式です。\n---\ntitle: \"タイトル\"\nsubtitle: \"サブタイトル\"\nauthor: \"作成者名\"\ndate: \"最終修正: `r Sys.Date()`\"\noutput:\n  html_document:\n    toc: FALSE\n    toc_depth: 3\n    toc_float: FALSE\n    number_sections: FALSE\n---\n　字下げには常に注意してください。html_documentはoutput:の下位項目ですから、字下げを行います。また、tocはhtml_documentの下位項目ですので、更に字下げをします。ここでは目次と関連する項目として以下の4つを紹介します。\n\n\ntoc: 目次の出力有無\n\nデフォルトはFALSE、目次を出力する際はTRUEにします。\n\n\n\ntoc_depth: 目次の深さを指定\n\nデフォルトは3であり、これはどのレベルの見出しまで目次に含むかをしてします。toc_depth: 2なら##見出しまで目次に出力されます\n\n\n\ntoc_float: 目次のフローティング\n\nデフォルトはFALSEです。これをTRUEにすると、目次は文書の左側に位置するようになり、文書をスクロールしても目次が付いてきます。\n\n\n\nnumber_sections: 見出しに通し番号を付けるか\n\nデフォルトはFALSEです。これをTRUEにすると、見出しに通し番号が付きます。むろん、付いた通し番号は目次でも出力されます。\n\n\n\n22.5.2 コードのハイライト\n　R Markdownの場合、コードチャンク内のコードの一部に対して自動的に色付けを行います。たとえば、本書の場合、関数名は緑、引数は赤、文字列は青といった形です。これはコードの可読性を向上させる効果もあります。この色付けの詳細はhtml_document:のhighlight:から調整できます。\n---\ntitle: \"タイトル\"\nsubtitle: \"サブタイトル\"\nauthor: \"作成者名\"\ndate: \"最終修正: `r Sys.Date()`\"\noutput:\n  html_document:\n    highlight: \"tango\"\n---\nR Markdown 2.3の場合、使用可能なテーマは以下の10種類です。自分の好みでハイライトテーマを替えてみましょう。\n\n\n\nhighlightの値\n出力結果\n\n\n\n\"default\"\n\n\n\n\"tango\"\n\n\n\n\"pygments\"\n\n\n\n\"kate\"\n\n\n\n\"monochrome\"\n\n\n\n\"espresso\"\n\n\n\n\"zenburn\"\n\n\n\n\"haddock\"\n\n\n\n\"breezedark\"\n\n\n\n\"textmate\""
  },
  {
    "objectID": "rmarkdown.html#RN4Esec-rmarkdown_japanese",
    "href": "rmarkdown.html#RN4Esec-rmarkdown_japanese",
    "title": "22  R Markdown [基礎]",
    "section": "\n22.6 日本語が含まれているPDFの出力",
    "text": "22.6 日本語が含まれているPDFの出力\n　日本語が含まれているPDF出力には片桐智志さんの{rmdja}パッケージが提供するテンプレが便利です。{rmdja}パッケージの詳細は公式レポジトリに譲りますが、ここでは簡単な例をお見せします。以下の内容は自分のPCにLaTeX環境が導入されている場合を想定しています5。\n　まずは{rmdja}のインストールからです。CRANに登録されていたいため、GitHub経由でインストールします。\n# remotes::の代わりにdevtools::も可\n# pacman::p_install_gh()も可\nremotes::install_github('Gedevan-Aleksizde/rmdja')\n次はR Markdown文書を作成しますが、RStudioのFile > New File > R Markdown …を選択します。左側のFrom Templateを選択し、pdf article in Japaneseを選択します。OKをクリックするとサンプル文書が表示されるので、YAMLヘッダー以下の内容を修正するだけです。図表番号などの相互参照（corss reference）が初回Knitでは反映されない場合がありますが、2回目からは表示されます。\n\n私たちのR 私たちのR 23  R Markdown [応用] 21  モデルの可視化 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 22  R Markdown [基礎] 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "rmarkdown2.html#RN4Ermakrdown2-slide",
    "href": "rmarkdown2.html#RN4Ermakrdown2-slide",
    "title": "23  R Markdown [応用]",
    "section": "\n23.1 スライド作成",
    "text": "23.1 スライド作成\n{xaringan}"
  },
  {
    "objectID": "rmarkdown2.html#RN4Ermakrdown2-book",
    "href": "rmarkdown2.html#RN4Ermakrdown2-book",
    "title": "23  R Markdown [応用]",
    "section": "\n23.2 書籍",
    "text": "23.2 書籍\n{bookdown}"
  },
  {
    "objectID": "rmarkdown2.html#RN4Ermakrdown2-homepage",
    "href": "rmarkdown2.html#RN4Ermakrdown2-homepage",
    "title": "23  R Markdown [応用]",
    "section": "\n23.3 ホームページ",
    "text": "23.3 ホームページ\n{distill}、{blogdown}"
  },
  {
    "objectID": "rmarkdown2.html#RN4Ermakrdown2-cv",
    "href": "rmarkdown2.html#RN4Ermakrdown2-cv",
    "title": "23  R Markdown [応用]",
    "section": "\n23.4 履歴書",
    "text": "23.4 履歴書\n{vitae}"
  },
  {
    "objectID": "rmarkdown2.html#RN4Ermakrdown2-package",
    "href": "rmarkdown2.html#RN4Ermakrdown2-package",
    "title": "23  R Markdown [応用]",
    "section": "\n23.5 パッケージ開発",
    "text": "23.5 パッケージ開発\n{fusen}\n簡単なものなら{fusen}で十分だが、ちゃんとした (?) ものを作るなら {devtools} + {usethis} + {roxygen2} + {testthat} + {pkgdown}を使おう"
  },
  {
    "objectID": "rmarkdown2.html#RN4Ermakrdown2-shiny",
    "href": "rmarkdown2.html#RN4Ermakrdown2-shiny",
    "title": "23  R Markdown [応用]",
    "section": "\n23.6 Webアプリケーション",
    "text": "23.6 Webアプリケーション\n{shiny}"
  },
  {
    "objectID": "rmarkdown2.html#RN4Ermakrdown2-tutorial",
    "href": "rmarkdown2.html#RN4Ermakrdown2-tutorial",
    "title": "23  R Markdown [応用]",
    "section": "\n23.7 チュートリアル",
    "text": "23.7 チュートリアル\n{learnr}\n\n私たちのR 私たちのR 24  Quarto入門 22  R Markdown [基礎] 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 23  R Markdown [応用] 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "quarto.html#RN4Esec-quarto-intro",
    "href": "quarto.html#RN4Esec-quarto-intro",
    "title": "24  Quarto入門",
    "section": "\n24.1 Quartoとは",
    "text": "24.1 Quartoとは\n以下のように、QuartoとR Markdownは同じやり方でHTML/PDF/Wordファイルを生成する。\n\nR Markdown\n\n\n.Rmd \\(\\rightarrow\\) knitr \\(\\rightarrow\\) .md \\(\\rightarrow\\) pandoc \\(\\rightarrow\\) HTML/PDF/Word…\n\n\nQuarto\n\n\n.qmd \\(\\rightarrow\\) (knitr / Jupyter / Observable) \\(\\rightarrow\\) .md \\(\\rightarrow\\) pandoc \\(\\rightarrow\\) HTML/PDF/Word…\n\n\nR Markdownの場合、コードがRに限定されている（むろん、今はpythonなども使用可能）。\n\n一方、Quartoはマルチリンガル（R、Pyhton、Juliaなど）\n\n\nR Markdownのエンジンはknitr\n\n一方、Quartoはknitr、Jupyter、Observableが使用可能であり、今後も追加予定\n\n\n文書作成のための{rmarkdown}、ホームページ作成のための{blogdown}、スライド作成のための{xaringan}など\n\nQuartoはこれらを全て一つに統合\nQuarto Extensionという拡張機能を追加する形式\n\n\nQuartoはRStudio以外にもVS Code、Jupyterなどでも使用可能\nQuartoはR Markdownの上位互換でもなく、R Markdownを代替するものでもない（参考）。\n\nつまり、既存のR Markdownを問題なく使っているのであれば、Quartoへの移行は不要\n現在のところ、QuartoはR Markdown生態系を一つに統合したものに近く、文法などもほぼ同じであるため、移行のために新しい事をゼロベースから勉強する必要はほぼない"
  },
  {
    "objectID": "quarto.html#RN4Esec-quarto-setup",
    "href": "quarto.html#RN4Esec-quarto-setup",
    "title": "24  Quarto入門",
    "section": "\n24.2 セットアップ",
    "text": "24.2 セットアップ\nQuartoのインストール\n\n\nhttps://quarto.org/docs/get-started/\n\n自分のOSに合わせてダウンロード&インストール\n\n\n\n{quarto}のインストール（インストールしておくだけで良い）\n\npacman::p_install(\"quarto\") # または、install.packages(\"quarto\")"
  },
  {
    "objectID": "quarto.html#RN4Esec-quarto-howtouse",
    "href": "quarto.html#RN4Esec-quarto-howtouse",
    "title": "24  Quarto入門",
    "section": "\n24.3 簡単な使い方",
    "text": "24.3 簡単な使い方\n\n24.3.1 とりあえずRender\n\nR Markdownと同じ感覚で使用可能\n\nFile > New File > Quarto Document …\nRStudioが最新版でない場合、アップデートする\nR Markdownの「Knit」はQuartoだと「Render」\n\nQuartoの場合、Knit以外にもJupyterなどのエンジンも使用可能であるため、名称がRender\nKnitボタンと同じ位置であり、ショートカットキーは同じく「Cmd + Shift + K (macOS)」、または「Ctrl + Shift + K (Windows)」\n\n\n\n\n\n24.3.2 チャンクオプションの付け方\n　現時点においてR Markdownと同じ書き方でも問題ない。\n```{r fig-scatter1, fig.height = 5, fig.width = 7, fig.cap = \"図の例\", cache = TRUE}\niris %>%\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) %>%\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\")\n```\n　Quarto特有の書き方としては、チャンクオプションを{r}内に書かず、チャンク内に#|で書く方法がある。#|とオプションの間には半角スペースを入れること。\n```{r}\n#| label: fig-scatter1\n#| fig-cap: \"図の例\"\n#| fig-height: 5\n#| fig-width: 7\n#| fig-align: \"center\"\n#| cache: true\niris %>%\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) %>%\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\")\n```\n注意すべき点としては\n\n一部のオプションの仮引数名が異なる。\n\n例) fig.width（RMarkdown）とfig-width（Quarto）など\n\n\n\nTRUEとFALSEの代わりにtrueとfalseを使用（YAMLと同じ書き方）\n\n仮引数 = 実引数でなく、仮引数: 実引数で書く\n\n24.3.3 相互参照について\n以下の @fig-scatter1 は萼片の長さと幅を品種ごとに分けて示した散布図である。\n\n```{r}\n#| label: fig-scatter1\n#| fig-cap: \"萼片の長さと幅の関係（品種別）\"\niris %>%\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) %>%\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\")\n```\n\n章、図、表の場合、ラベルはsec-、fig-、tbl-で始まる必要がある\n相互参照の箇所は@ラベル名と書く。念の為に、前後に半角スペースを入れておく。\n\nR Markdownの場合: 図\\@ref(fig-scatter1)\n\nQuartoの場合: @fig-scatter1\n\nデフォルトのままだと「Figure X」と出力される。「図 X」の形式にしたい場合は言語を指定する必要がある（YAMLヘッダーにlang: jaを追加するか、language:で別途定義する）。\n\n\n\n\n\n24.3.4 コールアウト\nInput:\n:::{.callout-note}\n## Rはみんなの友達!\n\n末永くよろしくね!\n:::\n\n:::{.callout-warning}\n## Rはみんなの友達!\n\n末永くよろしくね!\n:::\n\n:::{.callout-important}\n## Rはみんなの友達!\n\n末永くよろしくね!\n:::\n\n:::{.callout-tip}\n## Rはみんなの友達!\n\n末永くよろしくね!\n:::\n\n:::{.callout-caution}\n## Rはみんなの友達!\n\n末永くよろしくね!\n:::\nOutput:\n\n\n\n\n\n\nRはみんなの友達!\n\n\n\n末永くよろしくね!\n\n\n\n\n\n\n\n\nRはみんなの友達!\n\n\n\n末永くよろしくね!\n\n\n\n\n\n\n\n\nRはみんなの友達!\n\n\n\n末永くよろしくね!\n\n\n\n\n\n\n\n\nRはみんなの友達!\n\n\n\n末永くよろしくね!\n\n\n\n\n\n\n\n\nRはみんなの友達!\n\n\n\n末永くよろしくね!\n\n\nInput:\n:::{.callout-note collapse=\"true\"}\n## Rはみんなの友達!（クリック）\n\n末永くよろしくね!\n:::\nOutput:\n\n\n\n\n\n\nRはみんなの友達!\n\n\n\n\n\n末永くよろしくね!\n\n\n\n\n24.3.5 段組み\n段組みについて\n\n24.3.6 図表について\n\n大きさの調整\nキャプション"
  },
  {
    "objectID": "quarto.html#RN4Equartoを知り尽くす",
    "href": "quarto.html#RN4Equartoを知り尽くす",
    "title": "24  Quarto入門",
    "section": "\n24.4 Quartoを知り尽くす",
    "text": "24.4 Quartoを知り尽くす\n\nQuarto公式HP：https://quarto.org/docs/guide/\nrstudio::conf 2022 Workshopの資料：https://rstudio-conf-2022.github.io/get-started-quarto/\n\n\n私たちのR 私たちのR 25  表の作成 23  R Markdown [応用] 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 24  Quarto入門 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "table.html#RN4Esec-table-kbl",
    "href": "table.html#RN4Esec-table-kbl",
    "title": "25  表の作成",
    "section": "\n25.1 {kableExtra}の使い方",
    "text": "25.1 {kableExtra}の使い方\ncountry_dfのPopulation (100万で割った値)、Area (1万で割った値)、GPP_per_capita (1万で割った値)、PPP_per_capita (1万で割った値)、HDI_2018、Polity_Score、FH_Totalの記述統計\nコード入力が面倒であれば、コピペでOK\n\ncountry_desc <- country_df %>%\n    mutate(Population     = Population / 1000000,\n           Area           = Area / 10000,\n           GDP_per_capita = GDP_per_capita / 10000,\n           PPP_per_capita = PPP_per_capita / 10000) %>%\n    select(Population, Area, GDP_per_capita, PPP_per_capita, \n           HDI_2018, Polity_Score, FH_Total) %>%\n    summarise(across(everything(),\n                     .fns = list(\"Mean\" = ~mean(.x, na.rm = TRUE),\n                                 \"SD\"   = ~sd(.x, na.rm = TRUE),\n                                 \"Min\"  = ~min(.x, na.rm = TRUE),\n                                 \"Max\"  = ~max(.x, na.rm = TRUE),\n                                 \"Obs\"  = ~sum(!is.na(.x))),\n                     .names = \"{.col}-{.fn}\")) %>%\n    pivot_longer(cols = everything(),\n                 names_to = \"Label\",\n                 values_to = \"Value\") %>%\n    separate(col  = \"Label\",\n             into = c(\"Variable\", \"Stat\"),\n             sep  = \"-\") %>%\n    pivot_wider(names_from  = Stat,\n                values_from = Value)\n\n\ncountry_desc\n\n# A tibble: 7 × 6\n  Variable         Mean      SD        Min      Max   Obs\n  <chr>           <dbl>   <dbl>      <dbl>    <dbl> <dbl>\n1 Population     41.7   151.      0.000801 1447.      186\n2 Area           69.6   187.      0        1638.      186\n3 GDP_per_capita  1.62    2.57    0.00577    18.3     185\n4 PPP_per_capita  2.08    2.10    0.0733     11.3     178\n5 HDI_2018        0.713   0.153   0.377       0.954   180\n6 Polity_Score    4.26    6.10  -10          10       158\n7 FH_Total       57.7    29.9     0         100       185\n\n\n{summarytools}のdescr()を使う場合\n\npacman::p_load(summarytools)\n\ncountry_desc <- country_df %>%\n    mutate(Population     = Population / 1000000,\n           Area           = Area / 10000,\n           GDP_per_capita = GDP_per_capita / 10000,\n           PPP_per_capita = PPP_per_capita / 10000) %>%\n    select(Population, Area, GDP = GDP_per_capita, PPP = PPP_per_capita, \n           HDI = HDI_2018, Polity = Polity_Score, FreedomHouse = FH_Total) %>%\n    descr(stats = c(\"mean\", \"sd\", \"min\", \"max\", \"n.valid\"),\n          order = \"preserve\", transpose = TRUE) %>%\n    as.data.frame() %>%\n    rownames_to_column(\"Variable\") %>%\n    rename(SD = Std.Dev, Obs = N.Valid) %>%\n    as_tibble()\n\n\ncountry_desc\n\n# A tibble: 7 × 6\n  Variable       Mean      SD        Min      Max   Obs\n  <chr>         <dbl>   <dbl>      <dbl>    <dbl> <dbl>\n1 Population   41.7   151.      0.000801 1447.      186\n2 Area         69.6   187.      0        1638.      186\n3 GDP           1.62    2.57    0.00577    18.3     185\n4 PPP           2.08    2.10    0.0733     11.3     178\n5 HDI           0.713   0.153   0.377       0.954   180\n6 Polity        4.26    6.10  -10          10       158\n7 FreedomHouse 57.7    29.9     0         100       185\n\n\n\n25.1.1 表の出力\n\nkbl(country_desc)\n\n\n\n\n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Population \n    41.7377735 \n    151.2702976 \n    0.0008010 \n    1447.47009 \n    186 \n  \n\n Area \n    69.6069247 \n    187.2412489 \n    0.0000000 \n    1637.68700 \n    186 \n  \n\n GDP \n    1.6158103 \n    2.5710359 \n    0.0057700 \n    18.31772 \n    185 \n  \n\n PPP \n    2.0833383 \n    2.0992134 \n    0.0733142 \n    11.34231 \n    178 \n  \n\n HDI \n    0.7134833 \n    0.1528503 \n    0.3770000 \n    0.95400 \n    180 \n  \n\n Polity \n    4.2594937 \n    6.1022919 \n    -10.0000000 \n    10.00000 \n    158 \n  \n\n FreedomHouse \n    57.7135135 \n    29.8656244 \n    0.0000000 \n    100.00000 \n    185 \n  \n\n\n\n\n小数点桁数の調整\n\ncountry_desc %>%\n    kbl(digits = 3)\n\n\n\n\n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n表の幅 (HTML限定)\n\ncountry_desc %>%\n    kbl(digits = 3) %>%\n    kable_styling(full_width = FALSE)\n\n\n\n\n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n\n25.1.2 列の操作\n列名の修正\n全ての列を指定する必要がある\n\ncountry_desc %>%\n    kbl(col.names = c(\"変数\", \"平均値\", \"標準偏差\", \n                      \"最小値\", \"最大値\", \"観察数\"),\n        digits = 3)\n\n\n\n\n 変数 \n    平均値 \n    標準偏差 \n    最小値 \n    最大値 \n    観察数 \n  \n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n列の揃え\n全ての列を指定する必要がある\n\n# 不要だが、あえてVariable列を中央揃えにする\ncountry_desc %>%\n    kbl(align = c(\"crrrrr\"),\n        digits = 3)\n\n\n\n\n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n\n25.1.3 タイトル、フットノート\n\ncountry_desc %>%\n    kbl(caption = \"記述統計表\", digits = 3)\n\n\n\n記述統計表\n \n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n\ncountry_desc %>%\n    kbl(caption = \"記述統計表\", digits = 3) %>%\n    footnote(general       = \"『私たちのR』のサンプルデータ\",\n             general_title = \"出典:\")\n\n\n\n記述統計表\n \n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n出典:\n\n 『私たちのR』のサンプルデータ\n\n\n\n\n\ncountry_desc2 <- country_desc\n\nnames(country_desc2)[4:5] <- paste0(names(country_desc2)[4:5],\n                                    footnote_marker_number(1))\nnames(country_desc2)[6] <- paste0(names(country_desc2)[6],\n                                  footnote_marker_number(2))\n\ncountry_desc2 %>%\n    kbl(caption = \"記述統計表\", escape = FALSE, digits = 3) %>%\n    footnote(general = \"出典: 『私たちのR』のサンプルデータ\",\n             number  = c(\"欠損値を除く\", \"欠損していないケース数\"))\n\n\n\n記述統計表\n \n Variable \n    Mean \n    SD \n    Min1\n\n    Max1\n\n    Obs2\n\n  \n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\nNote: \n\n 出典: 『私たちのR』のサンプルデータ\n\n1 欠損値を除く\n\n2 欠損していないケース数\n\n\n\n\n\n25.1.4 グループ化\n列のグループ化\nグループ化しない列のラベルは\"\"でなく、\" \"にする。\n\ncountry_desc %>%\n    kbl(digits = 3) %>%\n    add_header_above(c(\" \" = 3, \"Range\" = 2, \" \" = 1))\n\n\n\n\n\n\nRange\n\n\n\n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n行のグループ化\n\ncountry_desc %>%\n    kbl(digits = 3) %>%\n    pack_rows(\"Demographic factors\", 1, 2) %>%\n    pack_rows(\"Economic factors\", 3, 5) %>%\n    pack_rows(\"Political factors\", 6, 7)\n\n\n\n\n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\nDemographic factors\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \nEconomic factors\n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \nPolitical factors\n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n\ncountry_desc3 <- country_desc %>%\n    mutate(Factor  = c(rep(\"Demographic\", 2),\n                       rep(\"Economic\", 3),\n                       rep(\"Political\", 2)),\n           .before = Variable)\n\ncountry_desc3 %>%\n    kbl(digits = 3)\n\n\n\n\n Factor \n    Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Demographic \n    Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Demographic \n    Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n Economic \n    GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n Economic \n    PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n Economic \n    HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Political \n    Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n Political \n    FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n\ncountry_desc3 %>%\n    kbl(digits = 3) %>%\n    collapse_rows(columns = 1, valign = \"top\")\n\n\n\n\n Factor \n    Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Demographic \n    Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Demographic \n    Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n Economic \n    GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n Economic \n    PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n Economic \n    HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Political \n    Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n Political \n    FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n\n25.1.5 セルの色分け（HTML限定）\n{formattable}パッケージ使用\n\ncountry_desc4 <- country_df %>%\n    mutate(Population     = Population / 1000000,\n           Area           = Area / 10000,\n           GDP_per_capita = GDP_per_capita / 10000,\n           PPP_per_capita = PPP_per_capita / 10000) %>%\n    select(HDI_2018, \n           Population, Area, GDP = GDP_per_capita, PPP = PPP_per_capita, \n           Polity = Polity_Score, FreedomHouse = FH_Total) %>%\n    drop_na() %>%\n    cor() %>%\n    as.data.frame() %>%\n    rownames_to_column(\"Variable\") %>%\n    select(Variable, Cor = HDI_2018) %>%\n    filter(Variable != \"HDI_2018\")\n\n\ncountry_desc4 %>%\n    kbl(digits = 3)\n\n\n\n\n Variable \n    Cor \n  \n\n\n Population \n    0.001 \n  \n\n Area \n    0.125 \n  \n\n GDP \n    0.714 \n  \n\n PPP \n    0.801 \n  \n\n Polity \n    0.287 \n  \n\n FreedomHouse \n    0.574 \n  \n\n\n\n\n\npacman::p_load(formattable)\n\ncountry_desc4$Cor2 <- color_text(\"blue\", \"red\")(sprintf(\"%.3f\", country_desc4$Cor))\ncountry_desc4$Cor3 <- color_tile(\"white\", \"mistyrose\")(sprintf(\"%.3f\", country_desc4$Cor))\n\ncountry_desc4 %>%\n    kbl(col.names = c(\"変数\", \"数字のみ\", \"文字色\", \"色塗り\"),\n        digits = 3, escape = FALSE) %>%\n    add_header_above(c(\" \" = 1, \"人間開発指数との相関係数\" = 3))\n\n\n\n\n\n\n人間開発指数との相関係数\n\n\n 変数 \n    数字のみ \n    文字色 \n    色塗り \n  \n\n\n\n Population \n    0.001 \n    0.001 \n    0.001 \n  \n\n Area \n    0.125 \n    0.125 \n    0.125 \n  \n\n GDP \n    0.714 \n    0.714 \n    0.714 \n  \n\n PPP \n    0.801 \n    0.801 \n    0.801 \n  \n\n Polity \n    0.287 \n    0.287 \n    0.287 \n  \n\n FreedomHouse \n    0.574 \n    0.574 \n    0.574 \n  \n\n\n\n\n\n25.1.6 テーマ\n\ncountry_desc %>%\n    kbl(digits = 3) %>%\n    kable_paper()\n\n\n\n\n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n\ncountry_desc %>%\n    kbl(digits = 3) %>%\n    kable_classic()\n\n\n\n\n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n\ncountry_desc %>%\n    kbl(digits = 3) %>%\n    kable_classic_2()\n\n\n\n\n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n\ncountry_desc %>%\n    kbl(digits = 3) %>%\n    kable_minimal()\n\n\n\n\n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n\ncountry_desc %>%\n    kbl(digits = 3) %>%\n    kable_material()\n\n\n\n\n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n\ncountry_desc %>%\n    kbl(digits = 3) %>%\n    kable_paper(bootstrap_options = \"striped\",\n                full_width        = FALSE)\n\n\n\n\n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n\ncountry_desc %>%\n    kbl(digits = 3) %>%\n    kable_paper(bootstrap_options = c(\"striped\", \"condensed\"),\n                full_width        = FALSE)\n\n\n\n\n Variable \n    Mean \n    SD \n    Min \n    Max \n    Obs \n  \n\n\n Population \n    41.738 \n    151.270 \n    0.001 \n    1447.470 \n    186 \n  \n\n Area \n    69.607 \n    187.241 \n    0.000 \n    1637.687 \n    186 \n  \n\n GDP \n    1.616 \n    2.571 \n    0.006 \n    18.318 \n    185 \n  \n\n PPP \n    2.083 \n    2.099 \n    0.073 \n    11.342 \n    178 \n  \n\n HDI \n    0.713 \n    0.153 \n    0.377 \n    0.954 \n    180 \n  \n\n Polity \n    4.259 \n    6.102 \n    -10.000 \n    10.000 \n    158 \n  \n\n FreedomHouse \n    57.714 \n    29.866 \n    0.000 \n    100.000 \n    185 \n  \n\n\n\n\n他にも\"hover\"や\"responsive\"、\"bordered\"あり\nテーマを変更せずにスタイルを変更したい場合はkable_styling()を使用\n\n25.1.7 LaTeX形式への出力\nRMarkdownの出力形式がHTMLでなく、PDFの場合\n\n\nkable_style()やテーマ関数 (kable_*())内にfull_width = FALSEの指定は不要\n縦線を無くしたい場合はkbl()内にbooktabs = TRUEを指定\n\n\ncountry_desc %>%\n    kbl(digits = 3, booktabs = TRUE)\n\n表を中央に位置づけたい場合はkable_style()内にposition = \"center\"を指定\n\ncountry_desc %>%\n    kbl(digits = 3, booktabs = TRUE) %>%\n    kable_styling(position = \"center\")\n\nLaTeX用表のコードが必要な場合、format = \"latex\"を指定\n\ncountry_desc %>%\n    kbl(format = \"latex\", digits = 3, booktabs = TRUE)"
  },
  {
    "objectID": "table.html#RN4Esec-table-gt",
    "href": "table.html#RN4Esec-table-gt",
    "title": "25  表の作成",
    "section": "\n25.2 {gt}の使い方",
    "text": "25.2 {gt}の使い方\nそのままcountry_descを使用\n表の出力\n\ngt(country_desc)\n\n\n\n\n\n\nVariable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n\n\nPopulation\n41.7377735\n151.2702976\n0.000801000\n1447.47009\n186\n\n\nArea\n69.6069247\n187.2412489\n0.000000000\n1637.68700\n186\n\n\nGDP\n1.6158103\n2.5710359\n0.005770007\n18.31772\n185\n\n\nPPP\n2.0833383\n2.0992134\n0.073314173\n11.34231\n178\n\n\nHDI\n0.7134833\n0.1528503\n0.377000000\n0.95400\n180\n\n\nPolity\n4.2594937\n6.1022919\n-10.000000000\n10.00000\n158\n\n\nFreedomHouse\n57.7135135\n29.8656244\n0.000000000\n100.00000\n185\n\n\n\n\n\n\n小数点桁数の調整\n\ncountry_desc %>%\n    gt() %>%\n    fmt_number(columns = 2:5, decimals = 3)\n\n\n\n\n\n\nVariable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n\n\nPopulation\n41.738\n151.270\n0.001\n1,447.470\n186\n\n\nArea\n69.607\n187.241\n0.000\n1,637.687\n186\n\n\nGDP\n1.616\n2.571\n0.006\n18.318\n185\n\n\nPPP\n2.083\n2.099\n0.073\n11.342\n178\n\n\nHDI\n0.713\n0.153\n0.377\n0.954\n180\n\n\nPolity\n4.259\n6.102\n−10.000\n10.000\n158\n\n\nFreedomHouse\n57.714\n29.866\n0.000\n100.000\n185"
  },
  {
    "objectID": "table.html#RN4Esec-table-dataout",
    "href": "table.html#RN4Esec-table-dataout",
    "title": "25  表の作成",
    "section": "\n25.3 データの出力",
    "text": "25.3 データの出力\n通常の出力の場合\n\ncountry_df\n\n# A tibble: 186 × 18\n   Country       Popul…¹   Area    GDP     PPP GDP_p…² PPP_p…³    G7   G20  OECD\n   <chr>           <dbl>  <dbl>  <dbl>   <dbl>   <dbl>   <dbl> <dbl> <dbl> <dbl>\n 1 Afghanistan    3.89e7 6.53e5 1.91e4  8.27e4    491.   2125.     0     0     0\n 2 Albania        2.88e6 2.74e4 1.53e4  3.97e4   5309.  13781.     0     0     0\n 3 Algeria        4.39e7 2.38e6 1.70e5  4.97e5   3876.  11324.     0     0     0\n 4 Andorra        7.73e4 4.7 e2 3.15e3 NA       40821.     NA      0     0     0\n 5 Angola         3.29e7 1.25e6 9.46e4  2.19e5   2879.   6649.     0     0     0\n 6 Antigua and …  9.79e4 4.4 e2 1.73e3  2.08e3  17643.  21267.     0     0     0\n 7 Argentina      4.52e7 2.74e6 4.50e5  1.04e6   9949.  22938.     0     1     0\n 8 Armenia        2.96e6 2.85e4 1.37e4  3.84e4   4614.  12974.     0     0     0\n 9 Australia      2.55e7 7.68e6 1.39e6  1.28e6  54615.  50001.     0     1     1\n10 Austria        9.01e6 8.24e4 4.46e5  5.03e5  49555.  55824.     0     0     1\n# … with 176 more rows, 8 more variables: HDI_2018 <dbl>, Polity_Score <dbl>,\n#   Polity_Type <chr>, FH_PR <dbl>, FH_CL <dbl>, FH_Total <dbl>,\n#   FH_Status <chr>, Continent <chr>, and abbreviated variable names\n#   ¹​Population, ²​GDP_per_capita, ³​PPP_per_capita\n\n\n{DT}パッケージのdatatable()関数を使用した場合\n\ndatatable(country_df)\n\n\n\n\n\n\n\n\n\n\n\n私たちのR 私たちのR 26  分析環境の管理 24  Quarto入門 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 25  表の作成 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "renv.html",
    "href": "renv.html",
    "title": "26  分析環境の管理",
    "section": "",
    "text": "{renv}による分析環境の管理/共有\n\n分析環境と再現可能な研究\n\n例1: 古いパッケージではできなかったものが、今はできるようになっている\n\n{ggplot2}のgeom_pointrange()の場合、昔は点と垂直線のみが引けた（マッピングはx、y、ymin、ymaxのみ可能）。\n点と水平線の描きたい場合は、coord_flip()で座標系を回転する必要があった。\n今の{ggplot2}だと、xminとxmaxにもマッピングができるため、coord_flip()不要\n多分いないと思うが、現在の仕様でコードを古い{ggplot2}で走らせるとエラーが出る。\n\n\n例2: 昔はできたものの、今はできない\n\n華麗に復活した{dplyr}のrowwise()は、無くなりかけていた関数\n{tidyr}のgather()とspread()は近い将来、無くなる\n\n\n例3: 仕様が変わり、関数名、仮引数名、実引数の使用可能なクラスが異なる場合\n\n開発途上のパッケージだとあり得る。\n\n\n\n{revn}のインストール\npacman::p_load(renv)\n\n分析環境の保存\nプロジェクトの使用を強く推奨 (第6.2章を参照)\n分析を始める前: コンソールに\nrenv::init()\n分析が終わった後: コンソールに\nrenv::snapshot()\n\n分析環境を再現\nrenv::restore()\n\n詳細は{renv}開発者のページを参照\n{pacman}との相性は大丈夫だろうか。また、GitHubから導入したパッケージの場合は?\n\n私たちのR 私たちのR 27  反復処理 25  表の作成 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 26  分析環境の管理 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "iteration.html#RN4Esec-iteration-intro",
    "href": "iteration.html#RN4Esec-iteration-intro",
    "title": "27  反復処理",
    "section": "\n27.1 *apply()関数群とmap_*()関数群",
    "text": "27.1 *apply()関数群とmap_*()関数群\nまず、我らの盟友、{tidyverse}を読み込んでおきましょう。\n\npacman::p_load(tidyverse)\n\nそれでは、*apply()関数群とmap_*()関数群の動きとその仕組について調べてみましょう。まず、実習用データとして長さ5のnumericベクトルnum_vecを用意します。\n\nnum_vec <- c(3, 2, 5, 4, 7)\n\nこのnum_vecの個々の要素に2を足す場合はどうすれば良いでしょうか。Rはベクトル単位での演算が行われるため、num_vec + 2だけで十分です。+の右側にある2は長さ1のベクトルですが、num_vecの長さに合わせてリサイクルされます（第9.2章を参照）。\n\nnum_vec + 2\n\n[1] 5 4 7 6 9\n\n\n賢明なRユーザーなら上のコードが正解でしょう。しかし、これからの練習のために+を使わずに、for()文を使用してみましょう（第10.3章を参照）。\n\nfor (i in num_vec) {\n    print(i + 2)\n}\n\n[1] 5\n[1] 4\n[1] 7\n[1] 6\n[1] 9\n\n\n実はこれと同じ役割をする関数がRには内蔵されており、それがlapply()関数です。\n\nlapply(オブジェクト名, 関数名, 関数の引数)\n\n以下のコードからも確認出来ますが、足し算を意味する+も関数です。ただし、演算子を関数として使う場合は演算子を`で囲む必要があり、+だと`+`と表記します。\n\n`+`(num_vec, 2)\n\n[1] 5 4 7 6 9\n\n\nしたがって、lapply()関数を使用してnum_vecの全要素に2を足す場合、以下のようなコードとなります。\n\nlapply(num_vec, `+`, 2)\n\n[[1]]\n[1] 5\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 7\n\n[[4]]\n[1] 6\n\n[[5]]\n[1] 9\n\n\nこれと同じ動きをする関数が{purrr}パッケージのmap()です。{purrr}は{tidyverse}を読み込むと自動的に読み込まれます。\n\nmap(num_vec, `+`, 2)\n\n[[1]]\n[1] 5\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 7\n\n[[4]]\n[1] 6\n\n[[5]]\n[1] 9\n\n\nただし、lapply()とmap()の場合、戻り値はリスト型となります。もし、ベクトル型の戻り値が必要な場合は更にunlist()関数を使うか、sapply()を使います。\n\n# unlist()を利用し、リストを解除する\nlapply(num_vec, `+`, 2) %>% unlist()\n\n[1] 5 4 7 6 9\n\n# sapply()を利用すると戻り値はベクトルとなる\nsapply(num_vec, `+`, 2)\n\n[1] 5 4 7 6 9\n\n\nmap()関数ならunlist()でも良いですが、sapply()と同じ動きをするmap_dbl()があります。これは戻り値がdoubleのnumericベクトルになるmap()関数です。\n\n# map_dbl()を利用するとnumeric (double)のベクトルが返される\nmap_dbl(num_vec, `+`, 2)\n\n[1] 5 4 7 6 9\n\n\nもし、2を足すだけでなく、更に3で割るためにはどうすれば良いでしょうか。まず考えられるのは更にsapply()やmap_dblを使うことです。\n\nmap_dbl(num_vec, `+`, 2) %>% \n    map_dbl(`/`, 3)\n\n[1] 1.666667 1.333333 2.333333 2.000000 3.000000\n\n\nもう一つの方法はsapply()やmap_dbl()の第二引数に直接関数を指定する方法です。\n\nsapply(num_vec, function(x){(x + 2) / 3})\n\n[1] 1.666667 1.333333 2.333333 2.000000 3.000000\n\nmap_dbl(num_vec, function(x){(x + 2) / 3})\n\n[1] 1.666667 1.333333 2.333333 2.000000 3.000000\n\n\n上のコードだと、num_vecの要素が第二引数で指定した関数の引数（x）として用いられます。関数が長くなる場合は、sapply()やmap()の外側に関数を予め指定して置くことも可能です。\n\nadd_two_divide_three <- function(x){\n    (x + 2) / 3 \n}\nsapply(num_vec, add_two_divide_three)\n\n[1] 1.666667 1.333333 2.333333 2.000000 3.000000\n\nmap_dbl(num_vec, add_two_divide_three)\n\n[1] 1.666667 1.333333 2.333333 2.000000 3.000000\n\n\nここまでの例だとsapply()とmap_dbl()はほぼ同じ関数です。なぜわざわざ{purrr}パッケージを読み込んでまでmap_dbl()関数を使う必要があるでしょうか。それはmap_dbl()の内部にはラムダ（lambda）式、あるいは無名関数（anonymous function）と呼ばれるものが使用可能だからです。ラムダ式は第13.1章でも説明しましたが、もう一回解説します。ラムダ式は使い捨ての関数で、map_dbl()内部での処理が終わるとメモリ上から削除される関数です。使い捨てですので、関数の名前（オブジェクト名）も与えられておりません。\nこのラムダ式の作り方ですが、~で始まり、引数の部分には.xが入ります1。したがって、~(.x + 2) / 3はfunction(x){(x + 2) / 3}の簡略したものとなります。ただし、後者だと無名関数の引数に該当するxをyやjなどに書き換えても問題ありませんが、ラムダ式では必ず.xと表記する必要があります。\n\nmap_dbl(num_vec, ~(.x + 2) / 3)\n\n[1] 1.666667 1.333333 2.333333 2.000000 3.000000\n\n\nかなり短めなコードで「num_vecの全要素に2を足して3で割る」処理ができました。一方、sapply()やlapply()のような*apply()関数群だとラムダ式を使うことはできません。現在のメモリ上にある関数のみしか使うことができません。\n\nsapply(num_vec, ~(.x + 2) / 3)\n\nError in match.fun(FUN): '~(.x + 2)/3' is not a function, character or symbol\n\n\nこれまでの例は正しいコードではありますが、良いコードとは言えないでしょう。なぜならnum_vec + 2という最適解が存在するからです。*apply()とmap_*()はより複雑な処理に特化しています。たとえば、リスト型データの処理です。以下の例を考えてみましょう。\n\nnum_list <- list(List1 = c(1, 3, 5, 7, 9),\n                 List2 = c(2, 4, 6, 8, 10, 13, 3),\n                 List3 = c(3, 2, NA, 5, 8, 9, 1))\n\nnum_listは3つのnumeric型ベクトルで構成されたリスト型オブジェクトです。それぞれのベクトルの平均値を求めてみましょう。これを普通にmean()関数のみで済まそうとすると、リストからベクトルを一つずつ抽出し、3回のmean()関数を使用する必要があります、\n\nmean(num_list[[\"List1\"]], na.rm = TRUE)\n\n[1] 5\n\nmean(num_list[[\"List2\"]], na.rm = TRUE)\n\n[1] 6.571429\n\nmean(num_list[[\"List3\"]], na.rm = TRUE)\n\n[1] 4.666667\n\n\nもしリストの長さが大きくなると、以下のようにfor()文の方が効率的でしょう。\n\nfor (i in names(num_list)) {\n    print(mean(num_list[[i]], na.rm = TRUE))\n}\n\n[1] 5\n[1] 6.571429\n[1] 4.666667\n\n\n計算結果をベクトルとして出力/保存する場合は予めベクトルを用意しておく必要があります。\n\n# num_listの長さと同じ長さの空ベクトルを生成\nReturn_vec <- rep(NA, length(num_list))\n\nfor (i in 1:length(num_list)) {\n    Return_vec[i] <- mean(num_list[[i]], na.rm = TRUE)\n}\n\nReturn_vec\n\n[1] 5.000000 6.571429 4.666667\n\n\n以上の例はsapply()、またはmap_dbl関数を使うとより短くすることができます。\n\nsapply(num_list, mean, na.rm = TRUE)\n\n   List1    List2    List3 \n5.000000 6.571429 4.666667 \n\nmap_dbl(num_list, mean, na.rm = TRUE)\n\n   List1    List2    List3 \n5.000000 6.571429 4.666667 \n\n\n*apply()もmap_*()も、それぞれの要素に対して同じ処理を行うことを得意とする関数です。他の応用としては、各ベクトルからn番目の要素を抽出することもできます。ベクトルからn番目の要素を抽出するにはベクトル名[n]と入力しますが、実はこの[も関数です。関数として使う場合は+と同様、`[`と表記します。num_list内の3つのベクトルから3番目の要素を抽出してみましょう2。\n\nmap_dbl(num_list, `[`, 3)\n\nList1 List2 List3 \n    5     6    NA \n\n\nここまで来たらmap_*()関数群の仕組みについてイメージが出来たかと思います。map_*()関数群の動きは 図 27.1 のように表すことができます。第一引数はデータであり、そのデータの各要素に対して第二引数で指定された関数を適用します。この関数に必要な（データを除く）引数は第三引数以降に指定します。この関数部（第二引数）はRやパッケージなどで予め提供されている関数でも、内部に直接無名関数を作成することもできます。この無名関数はfunction(x){}のような従来の書き方も可能ですが、map_*()関数群の場合~で始まるラムダ式を使うことも可能です。\n\n\n図 27.1: map関数群のイメージ\n\n\nmap()の場合、返り値はリストとなり、map_dbl()の返り値はnumeric (double)型のベクトルとなります。他にもmap_*()関数群にはmap_int()、map_lgl()、map_chr()、map_df()などがあり、それぞれ返り値のデータ型/データ構造を表しています。例えば、返り値がcharacter型のベクトルであれば、map_chr()を使います。c(1, 2, 3, 4, 5)のベクトルの各要素の前に\"ID: \"を付ける例だと以下のように書きます。\n\n# 以下のコードでもOK\n# map_chr(c(1, 2, 3, 4, 5), ~paste0(\"ID: \", .x))\nc(1, 2, 3, 4, 5) %>%\n  map_chr(~paste0(\"ID: \", .x))\n\n[1] \"ID: 1\" \"ID: 2\" \"ID: 3\" \"ID: 4\" \"ID: 5\""
  },
  {
    "objectID": "iteration.html#RN4Esec-iteration-map2",
    "href": "iteration.html#RN4Esec-iteration-map2",
    "title": "27  反復処理",
    "section": "\n27.2 引数が2つ以上の場合",
    "text": "27.2 引数が2つ以上の場合\n{purrr}を使った本格的な例を紹介する前に、引数が2つ以上の場合を考えたいと思います。まずは引数が2つの場合です。この場合、map2_*()関数群を使用します。例えば、num_vecに長さ5のnumeric型ベクトルnum_vec2をかける例を考えてみましょう。\nこの場合、データとしてnum_vecとnum_vec2が必要となり、ラムダ式にも2つの引数が必要です。まず、num_vec2を用意します。\n\nnum_vec2 <- c(1, 0, 1, 0, 1)\n\n続いてmap2_dbl()関数を使用しnum_vecとnum_vec2の掛け算を行います。map2_*()の使い方はmap_*()とほぼ同様です。\n\nmap2_dbl(データ1, データ2, 関数 or ラムダ式, 追加の引数)\n\nmap_*()との違いとしては、(1) データが2つである、(2) 関数、またはラムダ式に2つの引数が必要である点です。この2点目の引数ですが、データ2は.yと表記します。したがって、データ1とデータ2の掛け算を意味するラムダ式は~.x * .yです。\n\nmap2_dbl(num_vec, num_vec2, ~.x * .y)\n\n[1] 3 0 5 0 7\n\n\nnum_vecとnum_vec2が必ずしも同じデータ構造、データ型、同じ長さである必要がありません。数字の前に\"ID:\"を付ける先ほどの例をmap2_chr()で書いてみましょう。\n\nmap2_chr(num_vec, \"ID:\", ~paste0(.y, .x))\n\n[1] \"ID:3\" \"ID:2\" \"ID:5\" \"ID:4\" \"ID:7\"\n\n\nそれでは3つ以上の引数について考えてみましょう。たとえば、num_vecの前に\"ID\"を付けるとします。そして\"ID\"とnum_vecの間に\":\"を入れたい場合はどうすればい良いでしょう。むろん、賢い解決方法は単純にpaste()関数を使うだけです。\n\npaste(\"ID\", num_vec, sep = \":\")\n\n[1] \"ID:3\" \"ID:2\" \"ID:5\" \"ID:4\" \"ID:7\"\n\n\nこの場合、引数は3つです3。この場合の書き方はどうなるでしょうか。map2_*()はデータを2つまでしか指定できません。3つ目以降は関数/ラムダ式の後ろに書くこととなります。ただし、関数/ラムダ式の後ろに指定される引数は長さ1のベクトルでなければなりません。また、ラムダ式内の引数は.xと.yでなく、..1、..2、..3、…となります。\n今回の例だとmap2_chr()内にnum_vecがデータ1、\"ID\"がデータ2です。そして、期待される結果は、「“ID” + sepの実引数 + num_vecの値」となります。したがって、ラムダ式はpaste(..2, ..1, sep = ..3)となります。\n\nmap2_chr(num_vec, \"ID\", ~paste(..2, ..1, sep = ..3), \"-\")\n\n[1] \"ID-3\" \"ID-2\" \"ID-5\" \"ID-4\" \"ID-7\"\n\n\nデータ2である\"ID\"は長さ1のcharacter型ベクトルであるため、以下のようにmap_chr()を使うことも可能です。\n\n# データ2も長さ1なのでmap_chr()もOK\nmap_chr(num_vec, ~paste(..2, ..1, sep = ..3), \"ID\", \"-\")\n\n[1] \"ID-3\" \"ID-2\" \"ID-5\" \"ID-4\" \"ID-7\"\n\n\nそれではデータを3つ以上使うにはどうすれば良いでしょうか。そこで登場するのがpmap_*()関数です。以下の3つのベクトルを利用し、「名前:数学成績」を出力してみましょう。ただし、不正行為がある場合（cheat_vecの値が1）は成績が0点になるようにしましょう。\n\nname_vec  <- c(\"Hadley\", \"Song\", \"Yanai\")\nmath_vec  <- c(70, 55, 80)\ncheat_vec <- c(0, 1, 0)\n\n賢い解決法は普通にpaste0()関数を使う方法です。\n\npaste0(name_vec, \":\", math_vec * (1 - cheat_vec))\n\n[1] \"Hadley:70\" \"Song:0\"    \"Yanai:80\" \n\n\n今回はあえてpmap_*()関数を使ってみましょう。pmap_*()の場合、第一引数であるデータはリスト型で渡す必要があります。したがって、3つのベクトルをlist()関数を用いてリスト化します。第二引数には既存の関数やラムダ式を入力し、各引数は..1、..2、…といった形で表記します。\n\npmap_chr(list(name_vec, math_vec, cheat_vec), \n         ~paste0(..1, \":\", ..2 * (1 - ..3)))\n\n[1] \"Hadley:70\" \"Song:0\"    \"Yanai:80\" \n\n\n第一引数はデータであるため、まずリストを作成し、パイプ演算子（%>%）でpmap_*()に渡すことも可能です。\n\nlist(name_vec, math_vec, cheat_vec) %>%\n  pmap_chr(~paste0(..1, \":\", ..2 * (1 - ..3)))\n\n[1] \"Hadley:70\" \"Song:0\"    \"Yanai:80\""
  },
  {
    "objectID": "iteration.html#RN4Esec-iteration-df",
    "href": "iteration.html#RN4Esec-iteration-df",
    "title": "27  反復処理",
    "section": "\n27.3 データフレームと{purrr}",
    "text": "27.3 データフレームと{purrr}\nmap_*()関数のデータとしてデータフレームを渡すことも可能です。ここでは5行3列のデータフレームを作成してみましょう。\n\nDummy_df <- data.frame(X = seq(1,  5,  by = 1),\n                       Y = seq(10, 50, by = 10),\n                       Z = seq(2,  10, by = 2))\n\n各行のX、Y、Zの合計を計算するには{dplyr}のrowwise()とmutate()を組み合わせることで計算出来ることを第13.4章で紹介しました。\n\nDummy_df %>%\n  rowwise() %>%\n  mutate(Sum = sum(X, Y, Z)) %>%\n  # rowwise()は1行を1グループとする関数であるため、最後にグループ化を解除\n  ungroup()\n\n# A tibble: 5 × 4\n      X     Y     Z   Sum\n  <dbl> <dbl> <dbl> <dbl>\n1     1    10     2    13\n2     2    20     4    26\n3     3    30     6    39\n4     4    40     8    52\n5     5    50    10    65\n\n\nそれでは各列の平均値を計算するにはどうすれば良いでしょうか。ここではR内蔵関数であるcolMeans()を使わないことにしましょう。\n\ncolMeans(Dummy_df)\n\n X  Y  Z \n 3 30  6 \n\n\nまず、mean(Dummy_df$X)を3回実行する方法や、{dplyr}のsummarise()関数を使う方法があります。\n\nDummy_df %>%\n  summarise(X = mean(X), \n            Y = mean(Y),\n            Z = mean(Z))\n\n  X  Y Z\n1 3 30 6\n\n\n実はこの操作、map_dbl()関数を使えば、より簡単です。\n\nmap_dbl(Dummy_df, mean)\n\n X  Y  Z \n 3 30  6 \n\n\nmap_dbl()はnumeric (double) 型ベクトルを返しますが、データフレーム（具体的にはtibble）に返すならmap_df()を使います。\n\nmap_df(Dummy_df, mean)\n\n# A tibble: 1 × 3\n      X     Y     Z\n  <dbl> <dbl> <dbl>\n1     3    30     6\n\n\nなぜこれが出来るでしょうか。これを理解するためにはデータフレームとtibbleが本質的にはリスト型と同じであることを理解する必要があります。たとえば、以下のようなリストについて考えてみましょう。\n\nDummy_list <- list(X = seq(1,  5,  by = 1),\n                   Y = seq(10, 50, by = 10),\n                   Z = seq(2,  10, by = 2))\n\nDummy_list\n\n$X\n[1] 1 2 3 4 5\n\n$Y\n[1] 10 20 30 40 50\n\n$Z\n[1]  2  4  6  8 10\n\n\nこのDummy_listをas.data.frame()関数を使用して強制的にデータフレームに変換してみましょう。\n\nas.data.frame(Dummy_list)\n\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n\nDummy_dfと同じものが出てきました。逆にDummy_dfを、as.list()を使用してリストに変換するとDummy_listと同じものが返されます。\n\nas.list(Dummy_df)\n\n$X\n[1] 1 2 3 4 5\n\n$Y\n[1] 10 20 30 40 50\n\n$Z\n[1]  2  4  6  8 10\n\n\nここまで理解できれば、map_*()関数のデータがデータフレームの場合、内部ではリストとして扱われることが分かるでしょう。実際、Dummy_listをデータとして入れてもDummy_dfを入れた結果と同じものが得られます。\n\nmap_df(Dummy_list, mean)\n\n# A tibble: 1 × 3\n      X     Y     Z\n  <dbl> <dbl> <dbl>\n1     3    30     6\n\n\n\n27.3.1 tibbleの話\nここまで「データフレーム」と「tibble」を区別せずに説明してきましたが、これからの話しではこの2つを区別する必要があります。tibbleは{tidyverse}のコアパッケージの一つである{tibble}が提供するデータ構造であり、データフレームの上位互換です。tibbleもデータフレーム同様、本質的にはリストですが、リストの構造をより的確に表すことが出来ます。\nデータフレームをリストとして考える場合、リストの各要素は必ずベクトルである必要があります。たとえば、Dummy_listには3つの要素があり、それぞれ長さ5のベクトルです。一方、リストの中にはリストを入れることも出来ます。たとえば、以下のようなDummy_list2について考えてみましょう。\n\nDummy_list2 <- list(ID   = 1:3, \n                    Data = list(Dummy_df, Dummy_df, Dummy_df))\n\nDummy_list2\n\n$ID\n[1] 1 2 3\n\n$Data\n$Data[[1]]\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n$Data[[2]]\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n$Data[[3]]\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n\nDummy_list2には2つの要素があり、最初の要素は長さ3のベクトル、2つ目の要素は長さ3のリストです。2つ目の要素がベクトルでないため、Dummy_list2をデータフレームに変換することはできません。\n\nDummy_df2 <- as.data.frame(Dummy_list2)\n\nError in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE, : arguments imply differing number of rows: 3, 5\n\n\n一方、as_tibble()を使用してtibble型に変換することは可能です。\n\nDummy_tibble <- as_tibble(Dummy_list2)\n\nDummy_tibble\n\n# A tibble: 3 × 2\n     ID Data        \n  <int> <list>      \n1     1 <df [5 × 3]>\n2     2 <df [5 × 3]>\n3     3 <df [5 × 3]>\n\n\n2列目の各セルには5行3列のデータフレーム（df）が格納されていることが分かります。たとえば、Dummy_tibbleのData列を抽出してみましょう。\n\nDummy_tibble$Data\n\n[[1]]\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n[[2]]\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n[[3]]\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n\n長さ3のリスト出力されます。続いて、Dummy_tibble$Dataの2番目のセルを抽出してみましょう。\n\nDummy_tibble$Data[2]\n\n[[1]]\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n\nデータフレームが出力されました。簡単にまとめるとtibbleはデータフレームの中にデータフレームを入れることが出来るデータ構造です。むろん、これまでの通り、データフレームのように使うことも可能です4。これがtibbleの強みでもあり、{purrr}との相性も非常に高いです。たとえば、Data列をmap()関数のデータとして渡せば、複数のデータセットに対して同じモデルの推定が出来るようになります。以下ではその例を紹介します。"
  },
  {
    "objectID": "iteration.html#RN4Esec-iteration-model1",
    "href": "iteration.html#RN4Esec-iteration-model1",
    "title": "27  反復処理",
    "section": "\n27.4 モデルの反復推定",
    "text": "27.4 モデルの反復推定\nここからはmap_*()関数群を使って複数のモデルを素早く推定する方法について解説します。サンプルデータは第18章で使いました各国の政治経済データ（Countries.csv）を使用します。csv形式データ読み込みの際、これまではR内蔵関数であるread.csv()と{readr}5のread_csv()を区別せずに使用してきました。しかし、ここからはread_csv()を使用します。2つの使い方はほぼ同じですが、read_csv()は各列のデータ型を自動的に指定してくれるだけではなく、tibble構造として読み込みます。read.csv()を使用する場合、as_tibble(データフレーム名)でデータフレームをtibbleに変換してください。\n\nCountry_df <- read_csv(\"Data/Countries.csv\")\n\n\n27.4.1 サンプルの分割とモデル推定（split()利用）\nまずは、サンプルを分割し、それぞれの下位サンプルを使った分析を繰り返す方法について解説します。サンプルを分割する方法は2つありますが、最初はR内蔵関数であるsplit()関数を使った方法について紹介します。\n\n# split()の使い方\n新しいオブジェクト名 <- split(データ名, 分割の基準となるベクトル)\n\nたとえば、Country_dfを大陸ごとにサンプルを分けるとします。大陸を表すベクトルはCountry_df$Continentです。したがって、以下のように入力します。\n\nSplit_Data <- split(Country_df, Country_df$Continent)\n\nサンプルが分割されたSplit_Dataのデータ構造はリスト型です。\n\nclass(Split_Data)\n\n[1] \"list\"\n\n\n中身を見るとリストの各要素としてtibble（データフレーム）が格納されています。リストの中にはあらゆるデータ型、データ構造を入れることができることが分かります。\n\nSplit_Data\n\n$Africa\n# A tibble: 54 × 18\n   Country        Popul…¹   Area    GDP    PPP GDP_p…² PPP_p…³    G7   G20  OECD\n   <chr>            <dbl>  <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl> <dbl> <dbl>\n 1 Algeria         4.39e7 2.38e6 1.70e5 4.97e5   3876.  11324.     0     0     0\n 2 Angola          3.29e7 1.25e6 9.46e4 2.19e5   2879.   6649.     0     0     0\n 3 Benin           1.21e7 1.13e5 1.44e4 3.72e4   1187.   3067.     0     0     0\n 4 Botswana        2.35e6 5.67e5 1.83e4 4.07e4   7799.  17311.     0     0     0\n 5 Burkina Faso    2.09e7 2.74e5 1.57e4 3.76e4    753.   1800.     0     0     0\n 6 Burundi         1.19e7 2.57e4 3.01e3 8.72e3    253.    733.     0     0     0\n 7 Cabo Verde      5.56e5 4.03e3 1.98e3 3.84e3   3565.   6913.     0     0     0\n 8 Cameroon        2.65e7 4.73e5 3.88e4 9.31e4   1460.   3506.     0     0     0\n 9 Central Afric…  4.83e6 6.23e5 2.22e3 4.46e3    460.    924.     0     0     0\n10 Chad            1.64e7 1.26e6 1.13e4 2.51e4    689.   1525.     0     0     0\n# … with 44 more rows, 8 more variables: HDI_2018 <dbl>, Polity_Score <dbl>,\n#   Polity_Type <chr>, FH_PR <dbl>, FH_CL <dbl>, FH_Total <dbl>,\n#   FH_Status <chr>, Continent <chr>, and abbreviated variable names\n#   ¹​Population, ²​GDP_per_capita, ³​PPP_per_capita\n\n$America\n# A tibble: 36 × 18\n   Country        Popul…¹   Area    GDP    PPP GDP_p…² PPP_p…³    G7   G20  OECD\n   <chr>            <dbl>  <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl> <dbl> <dbl>\n 1 Antigua and B…  9.79e4 4.4 e2 1.73e3 2.08e3  17643.  21267.     0     0     0\n 2 Argentina       4.52e7 2.74e6 4.50e5 1.04e6   9949.  22938.     0     1     0\n 3 Bahamas         3.93e5 1.00e4 1.28e4 1.40e4  32618.  35662.     0     0     0\n 4 Barbados        2.87e5 4.3 e2 5.21e3 4.62e3  18126.  16066.     0     0     0\n 5 Belize          3.98e5 2.28e4 1.88e3 2.82e3   4727.   7091.     0     0     0\n 6 Bolivia         1.17e7 1.08e6 4.09e4 1.01e5   3503.   8623.     0     0     0\n 7 Brazil          2.13e8 8.36e6 1.84e6 3.13e6   8655.  14734.     0     1     0\n 8 Canada          3.77e7 9.09e6 1.74e6 1.85e6  46008.  49088.     1     1     1\n 9 Chile           1.91e7 7.44e5 2.82e5 4.64e5  14769.  24262.     0     0     1\n10 Colombia        5.09e7 1.11e6 3.24e5 7.37e5   6364.  14475.     0     0     1\n# … with 26 more rows, 8 more variables: HDI_2018 <dbl>, Polity_Score <dbl>,\n#   Polity_Type <chr>, FH_PR <dbl>, FH_CL <dbl>, FH_Total <dbl>,\n#   FH_Status <chr>, Continent <chr>, and abbreviated variable names\n#   ¹​Population, ²​GDP_per_capita, ³​PPP_per_capita\n\n$Asia\n# A tibble: 42 × 18\n   Country     Population   Area    GDP    PPP GDP_p…¹ PPP_p…²    G7   G20  OECD\n   <chr>            <dbl>  <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl> <dbl> <dbl>\n 1 Afghanistan   38928346 6.53e5 1.91e4 8.27e4    491.   2125.     0     0     0\n 2 Bahrain        1701575 7.6 e2 3.86e4 7.42e4  22670.  43624.     0     0     0\n 3 Bangladesh   164689383 1.30e5 3.03e5 7.34e5   1837.   4458.     0     0     0\n 4 Bhutan          771608 3.81e4 2.45e3 8.77e3   3171.  11363.     0     0     0\n 5 Brunei          437479 5.27e3 1.35e4 2.65e4  30789.  60656.     0     0     0\n 6 Burma         54409800 6.53e5 7.61e4 2.68e5   1398.   4932.     0     0     0\n 7 Cambodia      16718965 1.77e5 2.71e4 6.93e4   1620.   4142.     0     0     0\n 8 China       1447470092 9.39e6 1.48e7 2.20e7  10199.  15177.     0     1     0\n 9 India       1380004385 2.97e6 2.88e6 9.06e6   2083.   6564.     0     1     0\n10 Indonesia    273523615 1.81e6 1.12e6 3.12e6   4092.  11397.     0     1     0\n# … with 32 more rows, 8 more variables: HDI_2018 <dbl>, Polity_Score <dbl>,\n#   Polity_Type <chr>, FH_PR <dbl>, FH_CL <dbl>, FH_Total <dbl>,\n#   FH_Status <chr>, Continent <chr>, and abbreviated variable names\n#   ¹​GDP_per_capita, ²​PPP_per_capita\n\n$Europe\n# A tibble: 50 × 18\n   Country       Popul…¹   Area    GDP     PPP GDP_p…² PPP_p…³    G7   G20  OECD\n   <chr>           <dbl>  <dbl>  <dbl>   <dbl>   <dbl>   <dbl> <dbl> <dbl> <dbl>\n 1 Albania        2.88e6  27400 1.53e4  39658.   5309.  13781.     0     0     0\n 2 Andorra        7.73e4    470 3.15e3     NA   40821.     NA      0     0     0\n 3 Armenia        2.96e6  28470 1.37e4  38446.   4614.  12974.     0     0     0\n 4 Austria        9.01e6  82409 4.46e5 502771.  49555.  55824.     0     0     1\n 5 Azerbaijan     1.01e7  82658 4.80e4 144556.   4739.  14257.     0     0     0\n 6 Belarus        9.45e6 202910 6.31e4 183461.   6676.  19415.     0     0     0\n 7 Belgium        1.16e7  30280 5.30e5 597433.  45697.  51549.     0     0     1\n 8 Bosnia and H…  3.28e6  51000 2.00e4  49733.   6111.  15159.     0     0     0\n 9 Bulgaria       6.95e6 108560 6.79e4 156693.   9776.  22551.     0     0     0\n10 Croatia        4.11e6  55960 6.04e4 114932.  14717.  27996.     0     0     0\n# … with 40 more rows, 8 more variables: HDI_2018 <dbl>, Polity_Score <dbl>,\n#   Polity_Type <chr>, FH_PR <dbl>, FH_CL <dbl>, FH_Total <dbl>,\n#   FH_Status <chr>, Continent <chr>, and abbreviated variable names\n#   ¹​Population, ²​GDP_per_capita, ³​PPP_per_capita\n\n$Oceania\n# A tibble: 4 × 18\n  Country Popul…¹   Area    GDP    PPP GDP_p…² PPP_p…³    G7   G20  OECD HDI_2…⁴\n  <chr>     <dbl>  <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl> <dbl> <dbl>   <dbl>\n1 Austra…  2.55e7 7.68e6 1.39e6 1.28e6  54615.  50001.     0     1     1   0.938\n2 Fiji     8.96e5 1.83e4 5.54e3 1.25e4   6175.  13940.     0     0     0   0.724\n3 New Ze…  4.84e6 2.64e5 2.07e5 2.04e5  42729.  42178.     0     0     1   0.921\n4 Papua …  8.95e6 4.53e5 2.50e4 3.73e4   2791.   4171.     0     0     0   0.543\n# … with 7 more variables: Polity_Score <dbl>, Polity_Type <chr>, FH_PR <dbl>,\n#   FH_CL <dbl>, FH_Total <dbl>, FH_Status <chr>, Continent <chr>, and\n#   abbreviated variable names ¹​Population, ²​GDP_per_capita, ³​PPP_per_capita,\n#   ⁴​HDI_2018\n\n\nそれでは分割された各サンプルに対してPolity_ScoreとFH_Totalの相関係数を計算してみましょう。その前に相関分析の方法について調べてみましょう。Rには相関分析の関数が2つ用意されています。単純に相関係数のみを計算するならcor()、係数の不確実性（標準誤差、信頼区間など）まで計算し、検定を行うならcor.test()を使用します。ここではより汎用性の高いcor.test()の使い方について紹介します。\n\n# 相関分析: 方法1\ncor.test(~ 変数名1 + 変数名2, data = データ名)\n\n# 相関分析: 方法2\ncor.test(データ名$変数名1, データ名$変数名2)\n\nそれでは全サンプルに対して相関分析をしてみましょう。\n\nCor_fit1 <- cor.test(~ Polity_Score + FH_Total, data = Country_df)\nCor_fit1\n\n\n    Pearson's product-moment correlation\n\ndata:  Polity_Score and FH_Total\nt = 19.494, df = 156, p-value < 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7896829 0.8821647\nsample estimates:\n      cor \n0.8420031 \n\n\nここから相関係数（0.8420031）のみを抽出するにはどうすれば良いでしょうか。それを確認するためにはCor_fit1というオブジェクトの構造を調べる必要があります。ここではR内蔵関数であるstr()を使って確認してみましょう。\n\nstr(Cor_fit1)\n\nList of 9\n $ statistic  : Named num 19.5\n  ..- attr(*, \"names\")= chr \"t\"\n $ parameter  : Named int 156\n  ..- attr(*, \"names\")= chr \"df\"\n $ p.value    : num 1.16e-43\n $ estimate   : Named num 0.842\n  ..- attr(*, \"names\")= chr \"cor\"\n $ null.value : Named num 0\n  ..- attr(*, \"names\")= chr \"correlation\"\n $ alternative: chr \"two.sided\"\n $ method     : chr \"Pearson's product-moment correlation\"\n $ data.name  : chr \"Polity_Score and FH_Total\"\n $ conf.int   : num [1:2] 0.79 0.882\n  ..- attr(*, \"conf.level\")= num 0.95\n - attr(*, \"class\")= chr \"htest\"\n\n\n相関係数は$estimateで抽出できそうですね。実際にCor_fit1から相関係数のみ抽出してみましょう。\n\nCor_fit1$estimate\n\n      cor \n0.8420031 \n\n\nそれではmap()関数を利用して分割された各サンプルを対象にPolity_ScoreとFH_Totalの相関係数を計算してみましょう。map()のデータはSplit_Dataとし、関数はラムダ式を書いてみましょう。cor.test()内data引数の実引数は.x、または..1となります。最後にmap_dbl(\"estimate\")を利用し、相関係数を抽出、numeric (double) 型ベクトルとして出力します。\n\nCor_fit2 <- Split_Data %>%\n  map(~cor.test(~ Polity_Score + FH_Total, data = .x))\n\n\n# Cor_fit2から相関係数のみ出力\nmap_dbl(Cor_fit2, \"estimate\")\n\n   Africa   America      Asia    Europe   Oceania \n0.7612138 0.8356899 0.8338172 0.8419547 0.9960776 \n\n\nもし、小数点3位までのp値が欲しい場合は以下のように入力します。\n\n# Cor_fit2から相関係数のp値を抽出し、小数点3位に丸める\nmap_dbl(Cor_fit2, \"p.value\") %>% round(3)\n\n Africa America    Asia  Europe Oceania \n  0.000   0.000   0.000   0.000   0.004 \n\n\n\n27.4.2 サンプルの分割とモデル推定（nest()利用）\nそれではデータフレーム内にデータフレームが格納可能なtibble構造の長所を活かした方法について解説します。ある変数に応じてデータをグループ化する方法については第13.2章で解説しました。{tidyr}パッケージにはグループごとにデータを分割し、分割されたデータを各セルに埋め込むnest()関数を提供しています。具体的な動きを見るために、とりあえず、Country_dfを大陸（Continent）ごとに分割し、それぞれがデータが一つのセルに埋め込まれた新しいデータセット、Nested_Dataを作ってみましょう。\n\nNested_Data <- Country_df %>% \n  group_by(Continent) %>%\n  nest()\n\nちなみにgroup_by()とnest()はgroup_nest()を使って以下のようにまとめることも可能です。\n\nNested_Data <- Country_df %>% \n  group_nest(Continent)\n\n\nNested_Data\n\n# A tibble: 5 × 2\n# Groups:   Continent [5]\n  Continent data              \n  <chr>     <list>            \n1 Asia      <tibble [42 × 17]>\n2 Europe    <tibble [50 × 17]>\n3 Africa    <tibble [54 × 17]>\n4 America   <tibble [36 × 17]>\n5 Oceania   <tibble [4 × 17]> \n\n\n2列目のdata変数の各セルにtibbleが埋め込まれたことがわかります。Nested_Dataのdata列から5つ目の要素（オセアニアのデータ）を確認してみましょう。\n\n# Nested_Data$data[5]の場合、長さ1のリストが出力される\n# tibble構造で出力する場合は[5]でなく、[[5]]で抽出\nNested_Data$data[[5]]\n\n# A tibble: 4 × 17\n  Country Popul…¹   Area    GDP    PPP GDP_p…² PPP_p…³    G7   G20  OECD HDI_2…⁴\n  <chr>     <dbl>  <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl> <dbl> <dbl>   <dbl>\n1 Austra…  2.55e7 7.68e6 1.39e6 1.28e6  54615.  50001.     0     1     1   0.938\n2 Fiji     8.96e5 1.83e4 5.54e3 1.25e4   6175.  13940.     0     0     0   0.724\n3 New Ze…  4.84e6 2.64e5 2.07e5 2.04e5  42729.  42178.     0     0     1   0.921\n4 Papua …  8.95e6 4.53e5 2.50e4 3.73e4   2791.   4171.     0     0     0   0.543\n# … with 6 more variables: Polity_Score <dbl>, Polity_Type <chr>, FH_PR <dbl>,\n#   FH_CL <dbl>, FH_Total <dbl>, FH_Status <chr>, and abbreviated variable\n#   names ¹​Population, ²​GDP_per_capita, ³​PPP_per_capita, ⁴​HDI_2018\n\n\nContinentがOceaniaの行のdata列にオセアニアのみのデータが格納されていることが分かります。このようなデータ構造を入れ子型データ（nested data）と呼びます。この入れ子型データはunnest()関数を使って解除することも可能です。unnest()関数を使う際はどの列を解除するかを指定する必要があり、今回はdata列となります。\n\n# 入れ子型データの解除\nNested_Data %>%\n  unnest(data)\n\n# A tibble: 186 × 18\n# Groups:   Continent [5]\n   Continent Country    Popul…¹   Area    GDP    PPP GDP_p…² PPP_p…³    G7   G20\n   <chr>     <chr>        <dbl>  <dbl>  <dbl>  <dbl>   <dbl>   <dbl> <dbl> <dbl>\n 1 Asia      Afghanist…  3.89e7 6.53e5 1.91e4 8.27e4    491.   2125.     0     0\n 2 Asia      Bahrain     1.70e6 7.6 e2 3.86e4 7.42e4  22670.  43624.     0     0\n 3 Asia      Bangladesh  1.65e8 1.30e5 3.03e5 7.34e5   1837.   4458.     0     0\n 4 Asia      Bhutan      7.72e5 3.81e4 2.45e3 8.77e3   3171.  11363.     0     0\n 5 Asia      Brunei      4.37e5 5.27e3 1.35e4 2.65e4  30789.  60656.     0     0\n 6 Asia      Burma       5.44e7 6.53e5 7.61e4 2.68e5   1398.   4932.     0     0\n 7 Asia      Cambodia    1.67e7 1.77e5 2.71e4 6.93e4   1620.   4142.     0     0\n 8 Asia      China       1.45e9 9.39e6 1.48e7 2.20e7  10199.  15177.     0     1\n 9 Asia      India       1.38e9 2.97e6 2.88e6 9.06e6   2083.   6564.     0     1\n10 Asia      Indonesia   2.74e8 1.81e6 1.12e6 3.12e6   4092.  11397.     0     1\n# … with 176 more rows, 8 more variables: OECD <dbl>, HDI_2018 <dbl>,\n#   Polity_Score <dbl>, Polity_Type <chr>, FH_PR <dbl>, FH_CL <dbl>,\n#   FH_Total <dbl>, FH_Status <chr>, and abbreviated variable names\n#   ¹​Population, ²​GDP_per_capita, ³​PPP_per_capita\n\n\n{dplyr}のgroup_by()関数と{tidyr}のnest()、unnest()関数を組み合わせることでデータを入れ子型データへ変換したり、解除することができます。以上の流れを図式化したものが以下の 図 27.2 です。\n\n\n図 27.2: 入れ子型データの生成過程\n\n\nそれではこの入れ子型データを使用して大陸ごとのPolity_ScoreとFH_Totalの相関係数を計算してみましょう。data列をデータとした相関係数のラムダ式はどう書けば良いでしょうか。これまでの内容が理解できましたら、答えは難しくないでしょう。cor.test()関数のdata引数の実引数として.xを指定するだけです。この結果をCor_testという列として追加し、Nested_Data2という名のオブジェクトとして保存します。\n\nNested_Data2 <- Nested_Data %>%\n  mutate(Cor_test = map(data, ~cor.test(~ Polity_Score + FH_Total, data = .x)))\n\nNested_Data2\n\n# A tibble: 5 × 3\n# Groups:   Continent [5]\n  Continent data               Cor_test\n  <chr>     <list>             <list>  \n1 Asia      <tibble [42 × 17]> <htest> \n2 Europe    <tibble [50 × 17]> <htest> \n3 Africa    <tibble [54 × 17]> <htest> \n4 America   <tibble [36 × 17]> <htest> \n5 Oceania   <tibble [4 × 17]>  <htest> \n\n\nCor_testという列が追加され、htestというクラス（S3クラス）オブジェクトが格納されていることが分かります。ちゃんと相関分析のオブジェクトが格納されているか、確認してみましょう。\n\nNested_Data2$Cor_test\n\n[[1]]\n\n    Pearson's product-moment correlation\n\ndata:  Polity_Score and FH_Total\nt = 9.0626, df = 36, p-value = 8.05e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7009872 0.9107368\nsample estimates:\n      cor \n0.8338172 \n\n\n[[2]]\n\n    Pearson's product-moment correlation\n\ndata:  Polity_Score and FH_Total\nt = 9.7452, df = 39, p-value = 5.288e-12\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7210854 0.9130896\nsample estimates:\n      cor \n0.8419547 \n\n\n[[3]]\n\n    Pearson's product-moment correlation\n\ndata:  Polity_Score and FH_Total\nt = 7.9611, df = 46, p-value = 3.375e-10\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6087424 0.8594586\nsample estimates:\n      cor \n0.7612138 \n\n\n[[4]]\n\n    Pearson's product-moment correlation\n\ndata:  Polity_Score and FH_Total\nt = 7.6082, df = 25, p-value = 5.797e-08\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6677292 0.9226837\nsample estimates:\n      cor \n0.8356899 \n\n\n[[5]]\n\n    Pearson's product-moment correlation\n\ndata:  Polity_Score and FH_Total\nt = 15.92, df = 2, p-value = 0.003922\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8197821 0.9999220\nsample estimates:\n      cor \n0.9960776 \n\n\n5つの相関分析結果が格納されています。続いて、ここから相関係数のみを抽出してみましょう。相関分析オブジェクトから相関係数を抽出するにはオブジェクト名$estimateだけで十分です。mpa_*()関数を使うなら第2引数として関数やラムダ式を指定せず、\"estimate\"のみ入力するだけです。\n\nNested_Data2 <- Nested_Data2 %>%\n  mutate(Cor_coef = map(Cor_test, \"estimate\"))\n\nNested_Data2\n\n# A tibble: 5 × 4\n# Groups:   Continent [5]\n  Continent data               Cor_test Cor_coef \n  <chr>     <list>             <list>   <list>   \n1 Asia      <tibble [42 × 17]> <htest>  <dbl [1]>\n2 Europe    <tibble [50 × 17]> <htest>  <dbl [1]>\n3 Africa    <tibble [54 × 17]> <htest>  <dbl [1]>\n4 America   <tibble [36 × 17]> <htest>  <dbl [1]>\n5 Oceania   <tibble [4 × 17]>  <htest>  <dbl [1]>\n\n\nCor_coef列が追加され、それぞれのセルにnumeric型の値が格納されていることが分かります。map()関数はリスト型でデータを返すため、このように出力されます。このCor_coef列の入れ子構造を解除してみましょう。\n\nNested_Data2 <- Nested_Data2 %>%\n  unnest(cols = Cor_coef)\n\nNested_Data2\n\n# A tibble: 5 × 4\n# Groups:   Continent [5]\n  Continent data               Cor_test Cor_coef\n  <chr>     <list>             <list>      <dbl>\n1 Asia      <tibble [42 × 17]> <htest>     0.834\n2 Europe    <tibble [50 × 17]> <htest>     0.842\n3 Africa    <tibble [54 × 17]> <htest>     0.761\n4 America   <tibble [36 × 17]> <htest>     0.836\n5 Oceania   <tibble [4 × 17]>  <htest>     0.996\n\n\nCor_coefの各列に格納された値が出力されました。以上の作業を一つのコードとしてまとめることも出来ます。また、相関係数の抽出の際にmap()でなく、map_dbl()を使えば、numeric型ベクトルが返されるのでunnest()も不要となります。\n\nCountry_df %>%\n  group_by(Continent) %>%\n  nest() %>%\n  mutate(Cor_test = map(data, ~cor.test(~ Polity_Score + FH_Total, data = .x)),\n         Cor_coef = map_dbl(Cor_test, \"estimate\"))\n\n# A tibble: 5 × 4\n# Groups:   Continent [5]\n  Continent data               Cor_test Cor_coef\n  <chr>     <list>             <list>      <dbl>\n1 Asia      <tibble [42 × 17]> <htest>     0.834\n2 Europe    <tibble [50 × 17]> <htest>     0.842\n3 Africa    <tibble [54 × 17]> <htest>     0.761\n4 America   <tibble [36 × 17]> <htest>     0.836\n5 Oceania   <tibble [4 × 17]>  <htest>     0.996\n\n\nたった5行のコードで大陸ごとの相関分析が出来ました。これをmap_*()を使わずに処理するなら以下のようなコードとなります6。\n\nCor_Test1 <- cor.test(~ Polity_Score + FH_Total, \n                      data = subset(Country_df, Country_df$Continent == \"Asia\"))\nCor_Test2 <- cor.test(~ Polity_Score + FH_Total, \n                      data = subset(Country_df, Country_df$Continent == \"Europe\"))\nCor_Test3 <- cor.test(~ Polity_Score + FH_Total, \n                      data = subset(Country_df, Country_df$Continent == \"Africa\"))\nCor_Test4 <- cor.test(~ Polity_Score + FH_Total, \n                      data = subset(Country_df, Country_df$Continent == \"America\"))\nCor_Test5 <- cor.test(~ Polity_Score + FH_Total, \n                      data = subset(Country_df, Country_df$Continent == \"Oceania\"))\n\nCor_Result <- c(\"Asia\" = Cor_Test1$estimate, \"Europe\" = Cor_Test2$estimate,\n                \"Africa\" = Cor_Test3$estimate, \"America\" = Cor_Test4$estimate,\n                \"Oceania\" = Cor_Test5$estimate)\n\nprint(Cor_Result)\n\n   Asia.cor  Europe.cor  Africa.cor America.cor Oceania.cor \n  0.8338172   0.8419547   0.7612138   0.8356899   0.9960776 \n\n\nそれでは応用例として回帰分析をしてみましょう。今回もNested_Dataを使用し、PPP_per_capitaを応答変数に、FH_TotalとPopulationを説明変数とした重回帰分析を行い、政治的自由度（FH_Total）の係数や標準誤差などを抽出してみましょう。まずは、ステップごとにコードを分けて説明し、最後には一つのコードとしてまとめたものをお見せします。\n\nNested_Data %>%\n  mutate(Model = map(data, \n                     ~lm(PPP_per_capita ~ FH_Total + Population, \n                         data = .x)))\n\n# A tibble: 5 × 3\n# Groups:   Continent [5]\n  Continent data               Model \n  <chr>     <list>             <list>\n1 Asia      <tibble [42 × 17]> <lm>  \n2 Europe    <tibble [50 × 17]> <lm>  \n3 Africa    <tibble [54 × 17]> <lm>  \n4 America   <tibble [36 × 17]> <lm>  \n5 Oceania   <tibble [4 × 17]>  <lm>  \n\n\nModel列からから推定結果の要約を抽出するにはどうすれば良いでしょうか。1つ目の方法はsummary(lmオブジェクト名)$coefficientsで抽出する方法です。\n\nlm_fit1 <- lm(PPP_per_capita ~ FH_Total + Population, data = Country_df)\n\nsummary(lm_fit1)$coefficients\n\n                 Estimate   Std. Error    t value     Pr(>|t|)\n(Intercept)  1.929308e+03 3.229792e+03  0.5973473 5.510476e-01\nFH_Total     3.256660e+02 4.871626e+01  6.6849553 2.979474e-10\nPopulation  -2.217793e-06 9.193256e-06 -0.2412413 8.096505e-01\n\n\nもっと簡単な方法は{broom}のtidy()関数を使う方法です。tidy()関数は推定値に関する様々な情報をデータフレームとして返す便利な関数です。デフォルトだと95%信頼区間は出力されませんが、conf.int = TRUEを指定すると信頼区間も出力されます。tidy()関数を提供する{broom}パッケージは{tidyverse}の一部ですが、{tidyverse}読み込みの際に一緒に読み込まれるものではないため、予め{broom}パッケージを読み込んでおくか、broom::tidy()で使うことができます。\n\nbroom::tidy(lm_fit1, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term             estimate     std.error statistic  p.value    conf.low conf.…¹\n  <chr>               <dbl>         <dbl>     <dbl>    <dbl>       <dbl>   <dbl>\n1 (Intercept) 1929.         3230.             0.597 5.51e- 1    -4.45e+3 8.30e+3\n2 FH_Total     326.           48.7            6.68  2.98e-10     2.30e+2 4.22e+2\n3 Population    -0.00000222    0.00000919    -0.241 8.10e- 1    -2.04e-5 1.59e-5\n# … with abbreviated variable name ¹​conf.high\n\n\nそれではModel列にあるlmオブジェクトから推定値の情報を抽出し、Model2という列に格納してみましょう。今回はラムダ式を使う必要がありません。なぜなら、tidy()の第一引数がデータだからです（?tidy.lm参照）。他にも必要な引数（conf.int = TRUEなど）があれば、map()の第3引数以降で指定します。\n\nNested_Data %>%\n  mutate(Model  = map(data, \n                      ~lm(PPP_per_capita ~ FH_Total + Population, \n                          data = .x)),\n         Model2 = map(Model, broom::tidy, conf.int = TRUE))\n\n# A tibble: 5 × 4\n# Groups:   Continent [5]\n  Continent data               Model  Model2          \n  <chr>     <list>             <list> <list>          \n1 Asia      <tibble [42 × 17]> <lm>   <tibble [3 × 7]>\n2 Europe    <tibble [50 × 17]> <lm>   <tibble [3 × 7]>\n3 Africa    <tibble [54 × 17]> <lm>   <tibble [3 × 7]>\n4 America   <tibble [36 × 17]> <lm>   <tibble [3 × 7]>\n5 Oceania   <tibble [4 × 17]>  <lm>   <tibble [3 × 7]>\n\n\nModel2列の各セルに7列のtibbleが格納されているようです。ここからはdataとModel列は不要ですのでselect()関数を使って除去し、Model2の入れ子構造を解除してみます。\n\nNested_Data %>%\n  mutate(Model  = map(data, \n                      ~lm(PPP_per_capita ~ FH_Total + Population, \n                          data = .x)),\n         Model2 = map(Model, broom::tidy, conf.int = TRUE)) %>%\n  select(-c(data, Model)) %>%\n  unnest(cols = Model2)\n\n# A tibble: 15 × 8\n# Groups:   Continent [5]\n   Continent term        estimate     std.error stati…¹ p.value conf.low conf.…²\n   <chr>     <chr>          <dbl>         <dbl>   <dbl>   <dbl>    <dbl>   <dbl>\n 1 Asia      (Intercept)  2.13e+4  7376.          2.89  6.32e-3  6.39e+3 3.63e+4\n 2 Asia      FH_Total     6.99e+1   156.          0.449 6.56e-1 -2.45e+2 3.85e+2\n 3 Asia      Population  -1.26e-5     0.0000126  -1.00  3.23e-1 -3.81e-5 1.29e-5\n 4 Europe    (Intercept) -1.40e+4  9407.         -1.48  1.45e-1 -3.29e+4 5.00e+3\n 5 Europe    FH_Total     6.29e+2   108.          5.80  7.07e-7  4.10e+2 8.48e+2\n 6 Europe    Population   1.17e-4     0.0000845   1.39  1.73e-1 -5.33e-5 2.88e-4\n 7 Africa    (Intercept)  3.83e+3  1836.          2.09  4.20e-2  1.44e+2 7.52e+3\n 8 Africa    FH_Total     5.11e+1    34.2         1.49  1.42e-1 -1.77e+1 1.20e+2\n 9 Africa    Population  -1.43e-5     0.0000231  -0.619 5.39e-1 -6.07e-5 3.21e-5\n10 America   (Intercept) -7.50e+3  5926.         -1.27  2.15e-1 -1.96e+4 4.57e+3\n11 America   FH_Total     3.12e+2    77.3         4.03  3.20e-4  1.54e+2 4.69e+2\n12 America   Population   9.13e-5     0.0000235   3.89  4.77e-4  4.35e-5 1.39e-4\n13 Oceania   (Intercept) -5.10e+4 23351.         -2.18  2.73e-1 -3.48e+5 2.46e+5\n14 Oceania   FH_Total     9.76e+2   326.          2.99  2.05e-1 -3.17e+3 5.12e+3\n15 Oceania   Population   1.52e-4     0.000627    0.242 8.49e-1 -7.81e-3 8.12e-3\n# … with abbreviated variable names ¹​statistic, ²​conf.high\n\n\n各大陸ごとの回帰分析の推定結果が一つのデータフレームとして展開されました。ここではFH_Totalの推定値のみがほしいので、filter()関数を使用し、termの値が\"FH_Total\"の行のみを残します。また、term列も必要なくなるので除外しましょう。\n\nNested_Data %>%\n  mutate(Model  = map(data, \n                      ~lm(PPP_per_capita ~ FH_Total + Population, \n                          data = .x)),\n         Model2 = map(Model, broom::tidy, conf.int = TRUE)) %>%\n  select(-c(data, Model)) %>%\n  unnest(cols = Model2) %>%\n  filter(term == \"FH_Total\") %>%\n  select(-term)\n\n# A tibble: 5 × 7\n# Groups:   Continent [5]\n  Continent estimate std.error statistic     p.value conf.low conf.high\n  <chr>        <dbl>     <dbl>     <dbl>       <dbl>    <dbl>     <dbl>\n1 Asia          69.9     156.      0.449 0.656         -245.       385.\n2 Europe       629.      108.      5.80  0.000000707    410.       848.\n3 Africa        51.1      34.2     1.49  0.142          -17.7      120.\n4 America      312.       77.3     4.03  0.000320       154.       469.\n5 Oceania      976.      326.      2.99  0.205        -3166.      5117.\n\n\nこれで終わりです。政治的自由度と所得水準の関係はアジアとアフリカでは連関の程度が小さく、統計的有意ではありません。オセアニアの場合、連関の程度は大きいと考えられますが、サンプルサイズが小さいため統計的有意な結果は得られませんでした。一方、ヨーロッパとアメリカでは連関の程度も大きく、統計的有意な連関が確認されました。\n以上のコードをよりコンパクトにまとめると以下のようなコードとなります。\n\n# {purrr}使用\nNested_Data %>%\n  mutate(Model = map(data, ~lm(PPP_per_capita ~ FH_Total + Population, data = .x)),\n         Model = map(Model, broom::tidy, conf.int = TRUE)) %>%\n  unnest(cols = Model) %>%\n  filter(term == \"FH_Total\") %>%\n  select(-c(Data, term))\n\n{purrr}パッケージを使用しない例も紹介します。むろん、以下のコードは可能な限り面倒な書き方をしています。for()文やsplit()と*apply()関数を組み合わせると以下の例よりも簡潔なコードは作成できます。R上級者になるためには{tidyverse}的な書き方だけでなく、ネイティブRの書き方にも慣れる必要があります。ぜひ挑戦してみましょう。\n\n# {purrr}を使用しない場合\n# FH_Totalの係数と標準誤差のみを抽出する例\nlm_fit1 <- lm(PPP_per_capita ~ FH_Total + Population, \n              data = subset(Country_df, Country_df$Continent == \"Asia\"))\nlm_fit2 <- lm(PPP_per_capita ~ FH_Total + Population, \n              data = subset(Country_df, Country_df$Continent == \"Europe\"))\nlm_fit3 <- lm(PPP_per_capita ~ FH_Total + Population, \n              data = subset(Country_df, Country_df$Continent == \"Africa\"))\nlm_fit4 <- lm(PPP_per_capita ~ FH_Total + Population, \n              data = subset(Country_df, Country_df$Continent == \"America\"))\nlm_fit5 <- lm(PPP_per_capita ~ FH_Total + Population, \n              data = subset(Country_df, Country_df$Continent == \"Oceania\"))\n\nlm_df <- data.frame(Continent = c(\"Asia\", \"Europe\", \"Africa\", \"America\", \"Oceania\"),\n                    estimate  = c(summary(lm_fit1)$coefficients[2, 1],\n                                  summary(lm_fit2)$coefficients[2, 1],\n                                  summary(lm_fit3)$coefficients[2, 1],\n                                  summary(lm_fit4)$coefficients[2, 1],\n                                  summary(lm_fit5)$coefficients[2, 1]),\n                    se        = c(summary(lm_fit1)$coefficients[2, 2],\n                                  summary(lm_fit2)$coefficients[2, 2],\n                                  summary(lm_fit3)$coefficients[2, 2],\n                                  summary(lm_fit4)$coefficients[2, 2],\n                                  summary(lm_fit5)$coefficients[2, 2]))\n\n\n27.4.3 データの範囲を指定したモデル推定\nこれまでの例は名目変数でグループ化を行いましたが、連続変数を使うことも可能です。たとえば、人口1千万未満の国、1千万以上5千万未満、5千万以上1億未満、1億以上でサンプルを分割することです。まず、Country_dfからPPP_per_capita、FH_Total、Population列のみを抽出し、Country_df2に格納します。\n\nCountry_df2 <- Country_df %>%\n  select(PPP_per_capita, FH_Total, Population)\n\n続いて、case_when()関数を使用し、Populationの値を基準にケースがどの範囲内に属するかを表す変数Groupを作成します。\n\nCountry_df2 <- Country_df2 %>%\n  mutate(Group = case_when(Population <  10000000  ~ \"1千万未満\",\n                           Population <  50000000  ~ \"1千万以上5千万未満\",\n                           Population <  100000000 ~ \"5千万以上1億未満\",\n                           Population >= 100000000 ~ \"1億以上\"))\n\n中身を確認してみましょう。\n\nCountry_df2\n\n# A tibble: 186 × 4\n   PPP_per_capita FH_Total Population Group             \n            <dbl>    <dbl>      <dbl> <chr>             \n 1          2125.       27   38928346 1千万以上5千万未満\n 2         13781.       67    2877797 1千万未満         \n 3         11324.       34   43851044 1千万以上5千万未満\n 4            NA        94      77265 1千万未満         \n 5          6649.       32   32866272 1千万以上5千万未満\n 6         21267.       85      97929 1千万未満         \n 7         22938.       85   45195774 1千万以上5千万未満\n 8         12974.       53    2963243 1千万未満         \n 9         50001.       97   25499884 1千万以上5千万未満\n10         55824.       93    9006398 1千万未満         \n# … with 176 more rows\n\n\nあとはこれまでの例と同じ手順となります。まず、データをGroup変数でグループ化し、入れ子構造に変換します。\n\nCountry_df2 <- Country_df2 %>%\n  group_by(Group) %>%\n  nest()\n\n変換後のデータを確認してみます。\n\nCountry_df2\n\n# A tibble: 4 × 2\n# Groups:   Group [4]\n  Group              data             \n  <chr>              <list>           \n1 1千万以上5千万未満 <tibble [61 × 3]>\n2 1千万未満          <tibble [96 × 3]>\n3 1億以上            <tibble [14 × 3]>\n4 5千万以上1億未満   <tibble [15 × 3]>\n\n\n続いて、data列をデータとし、map()関数でモデルの推定をしてみましょう。目的変数は所得水準、説明変数は政治的自由度とします。推定後、{broom}のtidy()変数で推定値の情報のみを抽出し、入れ子構造を解除します。最後にtermがFH_Totalの行のみを残します。\n\nCountry_df2 <- Country_df2 %>%\n  mutate(Model = map(data, ~lm(PPP_per_capita ~ FH_Total, data = .x)),\n         Est   = map(Model, broom::tidy, conf.int = TRUE)) %>%\n  unnest(Est) %>%\n  filter(term == \"FH_Total\") %>%\n  select(!term)\n\nCountry_df2\n\n# A tibble: 4 × 9\n# Groups:   Group [4]\n  Group           data     Model estim…¹ std.e…² stati…³ p.value conf.…⁴ conf.…⁵\n  <chr>           <list>   <lis>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>\n1 1千万以上5千万… <tibble> <lm>     366.    59.6    6.14 9.07e-8   246.     485.\n2 1千万未満       <tibble> <lm>     246.    83.0    2.96 3.94e-3    80.8    411.\n3 1億以上         <tibble> <lm>     325.   158.     2.06 6.23e-2   -19.5    669.\n4 5千万以上1億未… <tibble> <lm>     487.   101.     4.80 3.46e-4   268.     706.\n# … with abbreviated variable names ¹​estimate, ²​std.error, ³​statistic,\n#   ⁴​conf.low, ⁵​conf.high\n\n\nせっかくなので推定結果を可視化してみましょう。横軸は人口規模（Group）とし、縦軸は推定値とします。係数の点推定値と95%信頼区間を同時に出力するために、geom_pointrange()幾何オブジェクトを使用します。\n\nCountry_df2 %>%\n  mutate(\n    # 横軸の表示順番を指定するために、Group変数をfactor化する\n    Group = factor(Group, levels = c(\"1千万未満\", \"1千万以上5千万未満\",\n                                     \"5千万以上1億未満\", \"1億以上\")),\n    # 統計的有意か否かを表すSig変数の作成\n    Sig   = if_else(conf.low * conf.high > 0, \"統計的有意\", \"統計的非有意\")\n    ) %>%\n  ggplot() + \n  geom_hline(yintercept = 0, color = \"red\") +\n  geom_pointrange(aes(x = Group, y = estimate, \n                      ymin = conf.low, ymax = conf.high, color = Sig), \n                  size = 0.75) +\n  labs(x = \"人口\", y = \"政治的自由度が所得に与える影響\", color = \"\") +\n  scale_color_manual(values = c(\"統計的有意\" = \"black\",\n                                \"統計的非有意\" = \"gray70\")) +\n  theme_minimal(base_size   = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n図 27.3: 政治的自由度が所得に与える影響 (人口規模別)\n\n\n\n\n政治的自由度が高くなるほど所得水準も高くなる傾向が確認されますが、人口が1億人以上の国においてはそのような傾向が見られないことが分かります。\n上記の例は、ある行は一つのグループに属するケースです。しかし、ある行が複数のグループに属するケースもあるでしょう。たとえば、ある変数の値が一定値以上である行のみでグループ化する場合です。FH_Scoreが一定値以上のSub-sampleに対して回帰分析を行う場合、FH_Scoreが最大値（100）である国はすべてのSub-sampleに属することになります。この場合はgroup_by()でグループ化することが難しいかも知れません。しかし、{dplyr}のfilter()を使えば簡単に処理することができます。\nここでは人口を説明変数に、所得水準を応答変数とした単回帰分析を行います。データは政治的自由度が一定値以上の国家のみに限定します。FH_Scoreが0以上の国（すべてのケース）、10以上の国、20以上の国、…などにサンプルを分割してみましょう。まずはFH_Scoreの最小値のみを格納したRnage_dfを作成します。\n\nRange_df <- tibble(Min_FH = seq(0, 80, by = 10))\n\nRange_df\n\n# A tibble: 9 × 1\n  Min_FH\n   <dbl>\n1      0\n2     10\n3     20\n4     30\n5     40\n6     50\n7     60\n8     70\n9     80\n\n\n9行1列のtibbleが出来ました。続いて、Subsetという列を生成し、ここにデータを入れてみましょう。ある変数の値を基準にサンプルを絞るには{dplyr}のfilter()関数を使用します。たとえば、Counter_dfのFH_Totalが50以上のケースに絞るにはfilter(Country_df, FH_Total >= 50)となります。パイプ演算子を使った場合はCountry_df %>% filter(FH_Total >= 50)になりますが、ラムダ式とパイプ演算子の相性はあまり良くありませんので、ここではパイプ演算子なしとします。重要なのはMin_FHの値をデータとしたmap()関数を実行し、実行内容を「Country_dfからFH_TotalがMin_FH以上のケースのみを抽出せよ」にすることです。\n\nRange_df <- Range_df %>%\n  mutate(Subset = map(Min_FH, ~filter(Country_df, FH_Total >= .x)))\n\nRange_df\n\n# A tibble: 9 × 2\n  Min_FH Subset               \n   <dbl> <list>               \n1      0 <spc_tbl_ [185 × 18]>\n2     10 <spc_tbl_ [176 × 18]>\n3     20 <spc_tbl_ [158 × 18]>\n4     30 <spc_tbl_ [142 × 18]>\n5     40 <spc_tbl_ [126 × 18]>\n6     50 <spc_tbl_ [112 × 18]>\n7     60 <spc_tbl_ [99 × 18]> \n8     70 <spc_tbl_ [76 × 18]> \n9     80 <spc_tbl_ [61 × 18]> \n\n\n入れ子構造になっているのは確認できましたが、ちゃんとフィルタリングされているかどうかも確認してみましょう。たとえば、Range_df$Subset[[9]]だとFH_Totalが80以上の国に絞られていると考えられます。18列の表ですからCountryとFH_Total列のみを確認してみましょう。\n\nRange_df$Subset[[9]] %>%\n  select(Country, FH_Total)\n\n# A tibble: 61 × 2\n   Country             FH_Total\n   <chr>                  <dbl>\n 1 Andorra                   94\n 2 Antigua and Barbuda       85\n 3 Argentina                 85\n 4 Australia                 97\n 5 Austria                   93\n 6 Bahamas                   91\n 7 Barbados                  95\n 8 Belgium                   96\n 9 Belize                    86\n10 Bulgaria                  80\n# … with 51 more rows\n\n\n問題なくフィルタリングされているようですね。ここまで出来ればあとはこれまでの内容の復習でしょう。\n\nRange_df <- Range_df %>%\n  mutate(Model  = map(Subset, ~lm(PPP_per_capita ~ Population, data = .x)),\n         Model  = map(Model,  broom::tidy, conf.int = TRUE)) %>%\n  unnest(cols = Model) %>%\n  filter(term == \"Population\") %>%\n  select(-c(Subset, term))\n\n今回も可視化してみましょう。\n\nRange_df %>%\n  ggplot() +\n  geom_hline(yintercept = 0, color = \"red\") +\n  geom_pointrange(aes(x = Min_FH, y = estimate, \n                      ymin = conf.low, ymax = conf.high)) +\n  labs(x = \"データ内FH_Scoreの最小値\", y = \"Populationの係数\") +\n  scale_x_continuous(breaks = seq(0, 80, by = 10),\n                     labels = seq(0, 80, by = 10)) +\n  theme_minimal(base_size = 12)\n\n\n\n図 27.4: Populationの係数の推定値\n\n\n\n\n以上の例は実際の分析では多く使われる方法ではないかも知れません。しかし、ノンパラメトリック回帰不連続デザイン（Regression Discontinuity Design; RDD）の場合、感度分析を行う際、バンド幅を色々と調整しながら局所処置効果を推定します。RDDの詳細については矢内の授業資料、およびSONGの授業資料などに譲りますが、ハンド幅の調整はデータの範囲を少しずつ拡張（縮小）させながら同じ分析を繰り返すことです。以下ではアメリカ上院選挙のデータを例に、方法を紹介します。\n使用するデータは{rdrobust}パッケージが提供するrdrobust_RDsenateというデータセットです。{pacman}パッケージのp_load()関数を使ってパッケージのインストールと読み込みを行い、data()関数を使って、データを読み込みます。\n\npacman::p_load(rdrobust)  # {rdrobust}のインストール & 読み込み\ndata(\"rdrobust_RDsenate\") # rdrobust_RDsenateデータの読み込み\n\n# データをSenate_dfという名で格納\nSenate_df <- as_tibble(rdrobust_RDsenate)\n\nSenate_dfの中身を確認してみます。\n\nSenate_df\n\n# A tibble: 1,390 × 2\n    margin  vote\n     <dbl> <dbl>\n 1  -7.69   36.1\n 2  -3.92   45.5\n 3  -6.87   45.6\n 4 -27.7    48.5\n 5  -8.26   51.7\n 6   0.732  39.8\n 7   3.49   53.2\n 8  -3.09   52.0\n 9   4.70   51.7\n10  -8.12   57.5\n# … with 1,380 more rows\n\n\n本データの詳細は Cattaneo, Frandsen, and Titiunik (2015) に譲りますが、ここでは簡単に説明します。marginはある選挙区の民主党候補者の得票率から共和党候補者の投票率を引いたものです。100なら民主党候補者の圧勝、-100なら共和党候補者の圧勝です。これが0に近いと辛勝または惜敗となり、この辺の民主党候補者と共和党候補者は候補者としての資質や資源が近いと考えられます。voteは次回の選挙における民主党候補者の得票率です。ある候補者が現職であることによるアドバンテージを調べる際、「民主党が勝った選挙区における次回選挙での民主党候補者の得票率」から「民主党が負けた選挙区における次回選挙での民主党候補者の得票率」を引くだけでは不十分でしょう。圧勝できた選挙区は次回でも得票率が高いと考えられますが、これは現職というポジションによるアドバンテージ以外にも、候補者がもともと備えている高い能力・資源にも起因するからです。だから辛勝・惜敗の選挙区のみに限定することで、現職と新人の能力・資源などを出来る限り均質にし、「現職」というポジションだけが異なる状況を見つけることになります。\n問題は辛勝と惜敗の基準をどう決めるかですが、広く使われている方法としては Imbens and Kalyanaraman (2012) の最適バンド幅（optimal bandwidth）が広く使われます。しかし、最適バンド幅を使うとしても感度分析（sensitivity analysis）を行うケースも多く、この場合、バンド幅を少しずつ変えながら現職の効果を推定することになります。推定式は以下のようになります。\\(I(\\text{margin} > 0)\\)はmarginが0より大きい場合、1となる指示関数（indicator function）であす。\n\\[\n\\hat{\\text{vote}} = \\beta_0 + \\beta_1 \\cdot \\text{margin} + \\tau \\cdot I(\\text{margin} > 0) \\quad \\text{where} \\quad -h \\leq \\text{margin} \\leq -h\n\\]\nそれではまずは\\(h\\)が100、つまり全データを使った分析を試しにやってみましょう。\n\nRDD_Fit <- lm(vote ~ margin + I(margin > 0), data = Senate_df)\n\nsummary(RDD_Fit)\n\n\nCall:\nlm(formula = vote ~ margin + I(margin > 0), data = Senate_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-46.930  -6.402   0.132   7.191  46.443 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       47.33084    0.54192  87.340  < 2e-16 ***\nmargin             0.34806    0.01335  26.078  < 2e-16 ***\nI(margin > 0)TRUE  4.78461    0.92290   5.184 2.51e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.78 on 1294 degrees of freedom\n  (93 observations deleted due to missingness)\nMultiple R-squared:  0.5781,    Adjusted R-squared:  0.5774 \nF-statistic: 886.4 on 2 and 1294 DF,  p-value: < 2.2e-16\n\n\nI(margin > 0)TRUEの係数4.785が現職効果です。この作業を\\(h = 100\\)から\\(h = 10\\)まで、5ずつ変えながら分析を繰り返してみます。まずは、RDD_dfというtibbleを作成し、BW列にはc(100, 95, 90, ... 10)を入れます。続いて、filter()関数を利用してSenate_dfからmarginが-BW以上、BW以下のデータを抽出し、Subsetという名の列として格納します。\n\nRDD_df <- tibble(BW = seq(100, 10, by = -5))\n\nRDD_df <- RDD_df %>%\n  mutate(Subset = map(BW, ~filter(Senate_df, \n                                  margin >= -.x & margin <= .x)))\n\nRDD_df\n\n# A tibble: 19 × 2\n      BW Subset              \n   <dbl> <list>              \n 1   100 <tibble [1,390 × 2]>\n 2    95 <tibble [1,327 × 2]>\n 3    90 <tibble [1,319 × 2]>\n 4    85 <tibble [1,308 × 2]>\n 5    80 <tibble [1,303 × 2]>\n 6    75 <tibble [1,294 × 2]>\n 7    70 <tibble [1,287 × 2]>\n 8    65 <tibble [1,270 × 2]>\n 9    60 <tibble [1,256 × 2]>\n10    55 <tibble [1,237 × 2]>\n11    50 <tibble [1,211 × 2]>\n12    45 <tibble [1,178 × 2]>\n13    40 <tibble [1,128 × 2]>\n14    35 <tibble [1,077 × 2]>\n15    30 <tibble [995 × 2]>  \n16    25 <tibble [901 × 2]>  \n17    20 <tibble [778 × 2]>  \n18    15 <tibble [639 × 2]>  \n19    10 <tibble [471 × 2]>  \n\n\n\nRDD_df <- RDD_df %>%\n  mutate(\n    # 各Subsetに対し、回帰分析を実施し、Model列に格納\n    Model  = map(Subset, ~lm(vote ~ margin * I(margin > 0), data = .x)),\n    # Model列の各セルから{broom}のtidy()で推定値のみ抽出\n    Est    = map(Model, broom::tidy, conf.int = TRUE)\n    ) %>%\n  # Est列の入れ子構造を解除\n  unnest(Est) %>% \n  # 現職効果に該当する行のみを抽出\n  filter(term == \"I(margin > 0)TRUE\") %>%\n  # 不要な列を削除\n  select(!c(Subset, Model, term, statistic, p.value))\n\nRDD_df\n\n# A tibble: 19 × 5\n      BW estimate std.error conf.low conf.high\n   <dbl>    <dbl>     <dbl>    <dbl>     <dbl>\n 1   100     6.04     0.942     4.20      7.89\n 2    95     5.76     0.975     3.85      7.67\n 3    90     5.90     0.981     3.98      7.83\n 4    85     5.80     0.993     3.85      7.75\n 5    80     5.10     0.999     3.14      7.06\n 6    75     5.18     1.01      3.21      7.15\n 7    70     5.57     1.01      3.58      7.55\n 8    65     5.21     1.03      3.20      7.23\n 9    60     4.89     1.04      2.86      6.93\n10    55     5.23     1.05      3.17      7.29\n11    50     5.73     1.07      3.64      7.82\n12    45     5.94     1.09      3.80      8.09\n13    40     6.12     1.12      3.92      8.33\n14    35     6.34     1.15      4.09      8.59\n15    30     7.18     1.18      4.86      9.50\n16    25     7.38     1.21      5.00      9.76\n17    20     7.03     1.32      4.43      9.62\n18    15     6.96     1.50      4.01      9.92\n19    10     6.90     1.75      3.46     10.3 \n\n\n19回の回帰分析が数行のコードで簡単に実施でき、必要な情報も素早く抽出することができました。\n以上の例は、交互作用なしの線形回帰分析による局所処置効果の推定例です。しかし、ノンパラメトリックRDDでは、割当変数（running variable）処置変数の交差項や割当変数の二乗項を入れる場合が多いです。今回の割当変数はmarginです。また、閾値（cutpoint）に近いケースには高い重みを付けることが一般的な作法であり、多く使われるのが三角（triangular）カーネルです。上記の例はすべてのケースに同じ重みを付ける矩形（rectagular）カーネルを使った例です。\n以上の理由により、やはりRDDは専用のパッケージを使った方が良いかも知れません。既に読み込んである{rdrobust}も推定可能ですが、ここでは{rdd}パッケージを使ってみましょう。{rdd}パッケージによるRDDはRDestimate()関数を使います。実際の例を確認してみましょう。map()を使う前に、オブジェクトの構造を把握しておくことは重要です。\n\n# cutpoint引数の既定値は0であるため、今回の例では省略可能\nRDestimate(応答変数 ~ 割当変数, data = データオブジェクト, cutpoint = 閾値, bw = バンド幅)\n\n\npacman::p_load(rdd) # パッケージの読み込み\n\n# バンド幅を指定したRDD推定\nRDD_Fit <- RDestimate(vote ~ margin, data = Senate_df, bw = 100)\n\n# RDDの推定結果を見る\nsummary(RDD_Fit)\n\n\nCall:\nRDestimate(formula = vote ~ margin, data = Senate_df, bw = 100)\n\nType:\nsharp \n\nEstimates:\n           Bandwidth  Observations  Estimate  Std. Error  z value  Pr(>|z|) \nLATE       100        1258          5.637     0.8845      6.374    1.842e-10\nHalf-BW     50        1127          6.480     1.0040      6.455    1.084e-10\nDouble-BW  200        1297          5.842     0.8568      6.818    9.210e-12\n              \nLATE       ***\nHalf-BW    ***\nDouble-BW  ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nF-statistics:\n           F      Num. DoF  Denom. DoF  p\nLATE       316.0  3         1254        0\nHalf-BW    179.7  3         1123        0\nDouble-BW  506.0  3         1293        0\n\n\n現職効果は5.637、その標準誤差は0.884です。これらの情報はどこから抽出できるか確認してみます。\n\n# 推定値の情報がどこに格納されているかを確認\nstr(RDD_Fit)\n\nList of 12\n $ type     : chr \"sharp\"\n $ call     : language RDestimate(formula = vote ~ margin, data = Senate_df, bw = 100)\n $ est      : Named num [1:3] 5.64 6.48 5.84\n  ..- attr(*, \"names\")= chr [1:3] \"LATE\" \"Half-BW\" \"Double-BW\"\n $ bw       : num [1:3] 100 50 200\n $ se       : num [1:3] 0.884 1.004 0.857\n $ z        : num [1:3] 6.37 6.45 6.82\n $ p        : num [1:3] 1.84e-10 1.08e-10 9.21e-12\n $ obs      : num [1:3] 1258 1127 1297\n $ ci       : num [1:3, 1:2] 3.9 4.51 4.16 7.37 8.45 ...\n $ model    : list()\n $ frame    : list()\n $ na.action: int [1:93] 28 29 57 58 86 113 114 142 143 168 ...\n - attr(*, \"class\")= chr \"RD\"\n\n\n$estと$seに私たちが探している数値が入っていますね。それぞれ抽出してみると長さ3のnumericベクトルが出力され、その中で1番目の要素がLATEということが分かります。\n\n# est要素の1番目の要素がLATE\nRDD_Fit$est\n\n     LATE   Half-BW Double-BW \n 5.637474  6.480344  5.842049 \n\n# se要素の1番目の要素がLATEの標準誤差\nRDD_Fit$se\n\n[1] 0.8844541 1.0039734 0.8568150\n\n\nそれでは分析に入ります。今回も\\(h\\)を予めBWという名の列で格納したRDD_dfを作成します。\n\nRDD_df <- tibble(BW = seq(100, 10, by = -5))\n\n今回はラムダ式を使わず、事前に関数を定義しておきましょう。関数の自作については第11章を参照してください。\n\n# 引数をxとするRDD_Func()の定義\nRDD_Func <- function(x) {\n  # バンド幅をxにしたRDD推定\n  Temp_Est <- RDestimate(vote ~ margin, data = Senate_df, bw = x)\n  # LATEとその標準誤差をtibbleとして返す\n  tibble(LATE = Temp_Est$est[1],\n         SE   = Temp_Est$se[1])\n}\n\n問題なく動くかを確認してみましょう。\n\nRDD_Func(100)\n\n# A tibble: 1 × 2\n   LATE    SE\n  <dbl> <dbl>\n1  5.64 0.884\n\n\nそれでは分析をやってみましょう。今回の場合、map()の第二引数はラムダ式ではないため~で始める必要ありません。関数名だけで十分です。\n\nRDD_df <- RDD_df %>%\n  mutate(RDD  = map(BW, RDD_Func)) %>%\n  unnest(RDD)\n\nRDD_df\n\n# A tibble: 19 × 3\n      BW  LATE    SE\n   <dbl> <dbl> <dbl>\n 1   100  5.64 0.884\n 2    95  5.64 0.890\n 3    90  5.63 0.897\n 4    85  5.61 0.905\n 5    80  5.65 0.913\n 6    75  5.75 0.922\n 7    70  5.81 0.934\n 8    65  5.91 0.949\n 9    60  6.07 0.963\n10    55  6.29 0.982\n11    50  6.48 1.00 \n12    45  6.67 1.03 \n13    40  6.91 1.07 \n14    35  7.19 1.11 \n15    30  7.28 1.17 \n16    25  7.10 1.26 \n17    20  7.27 1.38 \n18    15  7.49 1.57 \n19    10  7.98 1.84 \n\n\nせっかくなので可視化してみましょう。今回はgeom_pointrange()を使わず、geom_line()とgeom_ribbon()を組み合わせます。geom_line()はLATEを、geom_ribbion()は95%信頼区間を表します。作図の前に95%信頼区間を計算しておきます。\n\nRDD_df %>%\n  mutate(CI_lwr = LATE + qnorm(0.025) * SE,\n         CI_upr = LATE + qnorm(0.975) * SE) %>%\n  ggplot() +\n  geom_hline(yintercept = 0, color = \"red\") +\n  geom_ribbon(aes(x = BW, ymin = CI_lwr, ymax = CI_upr), alpha = 0.5) +\n  geom_line(aes(x = BW, y = LATE), size = 1) +\n  labs(x = \"Bandwidth\", y = \"Local Average Treatment Effect (%p)\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n図 27.5: LATEの推定値 (バンド幅別)\n\n\n\n\n\n27.4.4 説明・応答変数を指定したモデル推定\n続いて、同じデータに対して推定式のみを変えた反復推定をやってみましょう。たとえば、応答変数は固定し、グループ変数のみを変えながらt検定を繰り返すケースを考えてみましょう。たとえば、OECDに加盟しているかどうか（OECD）で購買力平価GDP（PPP）の差があるかを検定してみましょう。使用する関数はt.test()です。第一引数には応答変数 ~ 説明変数とし、data引数にはデータフレームやtibbleオブジェクトを指定します。\n\nDiff_test <- t.test(PPP ~ G20, data = Country_df)\n\nDiff_test\n\n\n    Welch Two Sample t-test\n\ndata:  PPP by G20\nt = -3.4137, df = 18.012, p-value = 0.003094\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -7667830 -1825482\nsample estimates:\nmean in group 0 mean in group 1 \n         211287         4957943 \n\n\nここからいくつかの情報が読み取れます。まず、OECD加盟国のPPPは4957943、非加盟国は211287です。その差分は-4746656です。また、t値は-3.4136、p値は0.003です。これらの情報を効率よく抽出するにはbroom::tidy()が便利です。\n\nbroom::tidy(Diff_test)\n\n# A tibble: 1 × 10\n  estim…¹ estim…² estim…³ stati…⁴ p.value param…⁵ conf.…⁶ conf.…⁷ method alter…⁸\n    <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl>   <dbl> <chr>  <chr>  \n1 -4.75e6 211287.  4.96e6   -3.41 0.00309    18.0 -7.67e6 -1.83e6 Welch… two.si…\n# … with abbreviated variable names ¹​estimate, ²​estimate1, ³​estimate2,\n#   ⁴​statistic, ⁵​parameter, ⁶​conf.low, ⁷​conf.high, ⁸​alternative\n\n\n差分、t値、p値、95%信頼区間などが抽出できます。これをOECDだけでなく、G7やG20に対しても同じ検定を繰り返してみましょう。\nt.test()の第一引数だけを変えながら推定をすれば良いでしょう。この第一引数、たとえばPPP ~ G20の方はformula型と呼ばれるRにおけるデータ型の一つです。これはcharacter型でないことに注意してください。\n\nFormula1 <- \"PPP ~ G20\"\nt.test(Formula1, data = Country_df)\n\nWarning in mean.default(x): argument is not numeric or logical: returning NA\n\n\nWarning in var(x): NAs introduced by coercion\n\n\nError in t.test.default(Formula1, data = Country_df): not enough 'x' observations\n\n\nこのようにエラーが出ます。このFormulaをas.formula()関数を使ってformula型に変換し、推定をやってみると問題なく推定できることが分かります。\n\nFormula2 <- as.formula(Formula1)\nt.test(Formula2, data = Country_df)\n\n\n    Welch Two Sample t-test\n\ndata:  PPP by G20\nt = -3.4137, df = 18.012, p-value = 0.003094\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -7667830 -1825482\nsample estimates:\nmean in group 0 mean in group 1 \n         211287         4957943 \n\n\nこれから私たちがやるのは\"PPP ~ \"の次に\"G7\"、\"G20\"、\"OECD\"をpaste()やpaste0()関数を結合し、formula型に変換することです。formula型の列さえ生成できれば、あとはmap()関数にformulaを渡し、データはCountry_dfに固定するだけです。\nまずはどの変数を説明変数にするかをGroup列として格納したDiff_dfを作成します。\n\nDiff_df <- tibble(Group = c(\"G7\", \"G20\", \"OECD\"))\n\nDiff_df\n\n# A tibble: 3 × 1\n  Group\n  <chr>\n1 G7   \n2 G20  \n3 OECD \n\n\n続いて、Formula列を作成し、\"PPP ~ \"の次にGroup列の文字列を結合します。\n\nDiff_df <- Diff_df %>%\n  mutate(Formula = paste0(\"PPP ~ \", Group))\n\nDiff_df\n\n# A tibble: 3 × 2\n  Group Formula   \n  <chr> <chr>     \n1 G7    PPP ~ G7  \n2 G20   PPP ~ G20 \n3 OECD  PPP ~ OECD\n\n\n今のFormula列のデータ型を確認してみましょう。\n\nclass(Diff_df$Formula[[1]])\n\n[1] \"character\"\n\n\ncharacter型ですね。続いて、map()関数を使用してFormula列をformula型に変換します。\n\nDiff_df <- Diff_df %>%\n  mutate(Formula = map(Formula, as.formula))\n\nDiff_df\n\n# A tibble: 3 × 2\n  Group Formula  \n  <chr> <list>   \n1 G7    <formula>\n2 G20   <formula>\n3 OECD  <formula>\n\n\nデータ型も確認してみましょう。\n\nclass(Diff_df$Formula[[1]])\n\n[1] \"formula\"\n\n\nformula型になっていることが分かります。それではt検定を行います。ここでもラムダ式を使います。式が入る場所には.xを指定し、データはCountry_dfに固定します。\n\nDiff_df <- Diff_df %>%\n  mutate(Model = map(Formula, ~t.test(.x, data = Country_df)))\n\nDiff_df\n\n# A tibble: 3 × 3\n  Group Formula   Model  \n  <chr> <list>    <list> \n1 G7    <formula> <htest>\n2 G20   <formula> <htest>\n3 OECD  <formula> <htest>\n\n\nbroom::tidy()で推定値の要約を抽出し、入れ子構造を解除します。\n\nDiff_df <- Diff_df %>%\n  mutate(Tidy = map(Model, broom::tidy)) %>%\n  unnest(Tidy)\n\nDiff_df\n\n# A tibble: 3 × 13\n  Group Formula   Model    estimate estimate1 estimate2 statis…¹ p.value param…²\n  <chr> <list>    <list>      <dbl>     <dbl>     <dbl>    <dbl>   <dbl>   <dbl>\n1 G7    <formula> <htest> -5363390.   507033.  5870423.    -2.14 0.0759     6.04\n2 G20   <formula> <htest> -4746656.   211287.  4957943.    -3.41 0.00309   18.0 \n3 OECD  <formula> <htest> -1166591.   475459.  1642050.    -1.96 0.0564    42.8 \n# … with 4 more variables: conf.low <dbl>, conf.high <dbl>, method <chr>,\n#   alternative <chr>, and abbreviated variable names ¹​statistic, ²​parameter\n\n\nいくつか使用しない情報もあるので、適宜列を削除します。\n\nDiff_df <- Diff_df %>%\n  select(-c(Formula, Model, estimate1, estimate2, \n            p.value, method, alternative))\n\nDiff_df\n\n# A tibble: 3 × 6\n  Group  estimate statistic parameter   conf.low conf.high\n  <chr>     <dbl>     <dbl>     <dbl>      <dbl>     <dbl>\n1 G7    -5363390.     -2.14      6.04 -11486296.   759515.\n2 G20   -4746656.     -3.41     18.0   -7667830. -1825482.\n3 OECD  -1166591.     -1.96     42.8   -2366187.    33005.\n\n\n以上のコードをパイプ演算子を使用し、簡潔にまとめると以下のようになります。\n\nDiff_df <- tibble(Group = c(\"G7\", \"G20\", \"OECD\"))\n\nDiff_df <- Diff_df %>%\n  mutate(Formula = paste0(\"PPP ~ \", Group),\n         Formula = map(Formula, as.formula),\n         Model   = map(Formula, ~t.test(.x, data = Country_df)),\n         Tidy    = map(Model, broom::tidy)) %>%\n  unnest(Tidy) %>%\n  select(-c(Formula, Model, estimate1, estimate2, \n            p.value, method, alternative))\n\n推定結果を可視化してみましょう。\n\nDiff_df %>%\n  mutate(Group = fct_inorder(Group),\n         Sig   = if_else(conf.low * conf.high > 0, \"統計的有意\",\n                         \"統計的非有意\")) %>%\n  ggplot() +\n  geom_vline(xintercept = 0, linetype = 2) +\n  geom_pointrange(aes(x = estimate, xmin = conf.low, xmax = conf.high,\n                      y = Group, color = Sig), size = 0.75) +\n  scale_color_manual(values = c(\"統計的有意\"   = \"black\",\n                                \"統計的非有意\" = \"gray70\")) +\n  labs(x = \"非加盟国のPPP - 加盟国のPPP\", y = \"グループ\", color = \"\") +\n  theme_bw(base_size   = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n図 27.6: 非加盟国と加盟国の一人当たりPPP-GDPの差分 (OECD/G20/G7)\n\n\n\n\n以上の方法を応用すると応答変数を変えながら分析を繰り返すこともできます。他にも説明変数が2つ以上のケースにも応用可能です。\n\n私たちのR 私たちのR 28  オブジェクト指向プログラミング 26  分析環境の管理 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 27  反復処理 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR\n\n\n\nCattaneo, Matias D., Brigham R. Frandsen, and Rocío Titiunik. 2015. “Randomization Inference in the Regression Discontinuity Design: An Application to the Study of Party Advantages in the u.s. Senate.” Journal of Causal Inference 3: 1–24.\n\n\nImbens, Guido, and Karthik Kalyanaraman. 2012. “Optimal Bandwidth Choice for the Regression Discontinuity Estimator.” The Review of Economic Studies 79: 933–59."
  },
  {
    "objectID": "oop.html#RN4Esec-oop_intro",
    "href": "oop.html#RN4Esec-oop_intro",
    "title": "28  オブジェクト指向プログラミング",
    "section": "\n28.1 まずは例から",
    "text": "28.1 まずは例から\n　まずは、{tidyverse}パッケージを読み込みます。\n\npacman::p_load(tidyverse)\n\n\nVector1 <- c(1, 5, 3, 7, 9, 12, 5, 4, 10, 1)\nVector2 <- c(\"A\", \"B\", \"D\", \"B\", \"E\", \"A\", \"A\", \"D\", \"C\", \"C\")\n\n\nsummary(Vector1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    3.25    5.00    5.70    8.50   12.00 \n\nsummary(Vector2)\n\n   Length     Class      Mode \n       10 character character \n\n\n　同じsummary()関数ですが、中のデータのタイプによって動きが異なります。これがオブジェクト指向プログラミングにおいて「多態性 (polymorphism)」と呼ばれる概念です。同じ関数でもデータ型、またはデータ構造に応じて異なる動きをすることです。ここでのデータ型やデータ構造を、OOPでは「クラス (class)」と呼びます。クラスはclass()関数で確認することができます。\n\nclass(Vector1)\n\n[1] \"numeric\"\n\nclass(Vector2)\n\n[1] \"character\"\n\n\n　Vector1はnumeric、Vector2はcharacterです。もし、無理矢理にVector1のクラスをcharacterに変えればどうなるでしょうか。クラスの変更はclass(オブジェクト名) <- \"クラス名\"でできます。一つのオブジェクトは複数のクラスが持てますが、これはOOPの「継承 (inheritance)」概念に関係するので後で解説します。ここではまず、Vector1のクラスをcharacterにし、もう一回summary()を使ってみましょう。\n\nclass(Vector1) <- \"character\"\nsummary(Vector1)\n\n   Length     Class      Mode \n       10 character character \n\n\n　データの中身は変わっていませんが、summary()関数の動き方が変わりました。このように、Rで頻繁に使うsummary()、print()、plot()などの関数は様々なクラスの対応しております。lm()関数を使った回帰分析の結果オブジェクトのクラス名はlmであり、その結果を見るためにもsummary()関数を使います。他にもplot(lmオブジェクト名)をすると回帰診断の図が表示されます。これができないと、各クラスに応じた関数を作成する必要がありますね。numeric型専用のnumeric_print()、character型専用のcharacter_print()、lm型専用のlm_plot()など…、覚えなきゃいけない関数が増えてきます。ユーザー側でも大変ですが、コードを作成する側も大変です。実際、下の 図 28.1 を見ると、プログラマーにとって最も大変な仕事は「名付け」であることが分かります1。\n\n\n図 28.1: Programmer’s Hardest Tasks\n\n\n　OOPの多態性にはこのような煩わしい仕事を軽減する機能があります。OOPにはここで紹介した多態性以外にも、「継承 (inheritance)」、「カプセル化 (encapsulation)」のような特徴があります。他にも人によっては「メッセージパッシング (message passing)」、「動的バインディング (dynamic binding)」などの特徴を述べたりしますが、詳しい話は専門書に譲りたいと思います。また、ここではRのS3クラスについて解説しますが、S3はカプセル化に対応しておりません。したがって、ここでは以下の概念について例と一緒に解説していきたいと思います。\n\nオブジェクト (object)\nクラス (class)\nメソッド (method)\n多態性 (polymorphism)　\n継承 (inheritance)"
  },
  {
    "objectID": "oop.html#RN4Esec-oop_about_oop",
    "href": "oop.html#RN4Esec-oop_about_oop",
    "title": "28  オブジェクト指向プログラミング",
    "section": "\n28.2 OOPとは",
    "text": "28.2 OOPとは\n\n28.2.1 オブジェクト\n　ここは第10章の内容の繰り返しですが、オブジェクト (object) とはメモリに割り当てられた「何か」です。「何か」に該当するのは、ベクトル (vector)、行列 (matrix)、データフレーム (data frame)、リスト (list)、関数 (function) などがあります。一般的に、オブジェクトにはそれぞれ固有の（つまり、他のオブジェクトと重複しない）名前が付いています。\n　たとえば、1から5までの自然数の数列を\n\nmy_vec1 <- c(1, 2, 3, 4, 5)  # my_vec1 <- 1:5 でも同じ\n\nのようにmy_vec1という名前のオブジェクトに格納します。オブジェクトに名前をつけてメモリに割り当てると、その後 my_vec1 と入力するだけでそのオブジェクトの中身を読み込むことができるようになります。\n　ここで、次のように my_vec1の要素を2倍にする操作を考えてみましょう。\n\nmy_vec1 * 2\n\n[1]  2  4  6  8 10\n\n\n　my_vec1は、先ほど定義したオブジェクトです。では2はどうでしょうか。2はメモリに割り当てられていないので、オブジェクトではないでしょうか。実は、この数字 2 もオブジェクトです。計算する瞬間のみ2がメモリに割り当てられ、計算が終わったらメモリから消されると考えれば良いでしょう。むろん、* のような演算子でさえもオブジェクトです。\n\n28.2.2 クラス\n　クラス (class) とはオブジェクトを特徴づける属性のことです。既に何度か class() 関数を使ってデータ型やデータ構造を確認しましたが、class()関数でオブジェクトのクラスを確認することができます。先ほど、my_vec1も*も2もオブジェクトであると説明しました。これらがすべてオブジェクトであるということは、何らかのクラス属性を持っているというこです。また、class()関数そのものもオブジェクトなので、何らかのクラスを持ちます。確認してみましょう。\n\nclass(my_vec1)\n\n[1] \"numeric\"\n\nclass(`*`)\n\n[1] \"function\"\n\nclass(2)\n\n[1] \"numeric\"\n\nclass(class)\n\n[1] \"function\"\n\n\n　統計分析をする際に、Rのクラスを意識することはあまりありません。しかし、Rでオブジェクト指向プログラミングを行う際は、オブジェクトのクラスを厳密に定義する必要があります。\n　Rにおける全てはオブジェクトであり、全てのオブジェクトは一つ以上クラスが付与されています。このクラスの考え方はプログラミング言語によって異なります。たとえば、Pythonの場合、一つのクラスの内部にはオブジェクトのデータ構造が定義され、そのクラスで使用可能な関数も含んでいます。また、データを含む場合もあります。このようにクラス内部にデータ、データ構造、専用関数などを格納することをカプセル化（encapsulation）と呼びます。\n　一方、Rの（S3）クラスにはクラス専用関数がクラス内で定義されておらず、データのみが格納されています。\n\n28.2.3 メソッドと多態性\n　各クラス専用の関数をメソッド（method）と呼びます。たとえば、summary()関数を考えてみましょう。lm()関数を用いた回帰分析から得られたオブジェクトのクラスはlmであり、c()で作られた数値型ベクトルのクラスはnumericです。しかし、同じsummary()関数ですが、引数のクラスがlmかnumericかによって異なる動きを見せます。その例を見ましょう。\n\nX <- c(1, 3, 5, 7, 9, 11)\nY <- c(1, 2, 3, 7, 11, 13)\nlm_class <- lm(Y ~ X)\nclass(X)\n\n[1] \"numeric\"\n\nclass(lm_class)\n\n[1] \"lm\"\n\nsummary(X)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    1.0     3.5     6.0     6.0     8.5    11.0 \n\nsummary(lm_class)\n\n\nCall:\nlm(formula = Y ~ X)\n\nResiduals:\n      1       2       3       4       5       6 \n 1.3333 -0.2667 -1.8667 -0.4667  0.9333  0.3333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)   \n(Intercept)  -1.6333     1.0546  -1.549  0.19637   \nX             1.3000     0.1528   8.510  0.00105 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.278 on 4 degrees of freedom\nMultiple R-squared:  0.9477,    Adjusted R-squared:  0.9346 \nF-statistic: 72.43 on 1 and 4 DF,  p-value: 0.001046\n\n\n　このように同じ関数でもクラスによって異なる動作をすることを多態性 (polymorphism)と呼びます。しかし、実はRにおいてこれらの関数は別途作られた関数です。つまり、summary()という関数がクラスごとに定義されていることを意味します。summary()関数がどのクラスで使用可能かを確認するためにはmethods()関数を使います。\n\nmethods(\"summary\")\n\n [1] summary,ANY-method                  summary,DBIObject-method           \n [3] summary.aov                         summary.aovlist*                   \n [5] summary.aspell*                     summary.check_packages_in_dir*     \n [7] summary.connection                  summary.data.frame                 \n [9] summary.Date                        summary.default                    \n[11] summary.Duration*                   summary.ecdf*                      \n[13] summary.factor                      summary.ggplot*                    \n[15] summary.glm                         summary.haven_labelled*            \n[17] summary.hcl_palettes*               summary.infl*                      \n[19] summary.Interval*                   summary.lm                         \n[21] summary.loess*                      summary.manova                     \n[23] summary.matrix                      summary.mlm*                       \n[25] summary.nls*                        summary.packageStatus*             \n[27] summary.Period*                     summary.POSIXct                    \n[29] summary.POSIXlt                     summary.ppr*                       \n[31] summary.prcomp*                     summary.princomp*                  \n[33] summary.proc_time                   summary.rlang_error*               \n[35] summary.rlang_message*              summary.rlang_trace*               \n[37] summary.rlang_warning*              summary.rlang:::list_of_conditions*\n[39] summary.srcfile                     summary.srcref                     \n[41] summary.stepfun                     summary.stl*                       \n[43] summary.table                       summary.tukeysmooth*               \n[45] summary.vctrs_sclr*                 summary.vctrs_vctr*                \n[47] summary.warnings                   \nsee '?methods' for accessing help and source code\n\n\n　このように47種類のクラスに対してsummary()関数が定義されています2。この関数の内部を確認するにはどうすれば良いでしょうか。関数のコードを見るときにはコンソール上に関数名を入力するだけです（()は不要）。\n\nsummary\n\nfunction (object, ...) \nUseMethod(\"summary\")\n<bytecode: 0x7fa269d29b70>\n<environment: namespace:base>\n\n\n　しかし、多態性を持つ関数の内部を見ることはできません。そもそもsummary()関数はクラスごとに異なるコードを持っているため、summaryだけでは「どのクラスのsummary()か」が分かりません。それでもRにはsummary()関数が存在し、それをジェネリック関数（generic function）と呼びます。内部にはUseMethod(\"summary\")のみが書かれており、これは「このsummary()関数は様々なクラスのメソッドとして機能するぞ」と宣言しているだけです。各クラスに対応したメソッドの内部を見るにはgetS3method(\"メソッド名\", \"クラス名\")を使います。summary()メソッドはnumeric型が別途指定されていないため、\"defualt\"となります。\n\ngetS3method(\"summary\", \"default\")\n\nfunction (object, ..., digits, quantile.type = 7) \n{\n    if (is.factor(object)) \n        return(summary.factor(object, ...))\n    else if (is.matrix(object)) {\n        if (missing(digits)) \n            return(summary.matrix(object, quantile.type = quantile.type, \n                ...))\n        else return(summary.matrix(object, digits = digits, quantile.type = quantile.type, \n            ...))\n    }\n    value <- if (is.logical(object)) \n        c(Mode = \"logical\", {\n            tb <- table(object, exclude = NULL, useNA = \"ifany\")\n            if (!is.null(n <- dimnames(tb)[[1L]]) && any(iN <- is.na(n))) dimnames(tb)[[1L]][iN] <- \"NA's\"\n            tb\n        })\n    else if (is.numeric(object)) {\n        nas <- is.na(object)\n        object <- object[!nas]\n        qq <- stats::quantile(object, names = FALSE, type = quantile.type)\n        qq <- c(qq[1L:3L], mean(object), qq[4L:5L])\n        if (!missing(digits)) \n            qq <- signif(qq, digits)\n        names(qq) <- c(\"Min.\", \"1st Qu.\", \"Median\", \"Mean\", \"3rd Qu.\", \n            \"Max.\")\n        if (any(nas)) \n            c(qq, `NA's` = sum(nas))\n        else qq\n    }\n    else if (is.recursive(object) && !is.language(object) && \n        (n <- length(object))) {\n        sumry <- array(\"\", c(n, 3L), list(names(object), c(\"Length\", \n            \"Class\", \"Mode\")))\n        ll <- numeric(n)\n        for (i in 1L:n) {\n            ii <- object[[i]]\n            ll[i] <- length(ii)\n            cls <- oldClass(ii)\n            sumry[i, 2L] <- if (length(cls)) \n                cls[1L]\n            else \"-none-\"\n            sumry[i, 3L] <- mode(ii)\n        }\n        sumry[, 1L] <- format(as.integer(ll))\n        sumry\n    }\n    else c(Length = length(object), Class = class(object), Mode = mode(object))\n    class(value) <- c(\"summaryDefault\", \"table\")\n    value\n}\n<bytecode: 0x7fa22d0c0860>\n<environment: namespace:base>\n\n\n　Rにはメソッドがクラス内部で定義されず、別途のメソッド名.クラス名()といった関数として作成されています。そしてジェネリック関数によって一つの関数の「ように」まとまっています。このように、ジェネリック関数経由でメソッドを呼び出すことをメソッド・ディスパッチ（method dispatch）と呼びます。\n\n28.2.4 継承\n　クラスの継承 (inheritance)は一つのオブジェクトが2つ以上のクラスを持つ場合、子クラスが親クラスの特徴を継承することを意味します。たとえば、データフレームの拡張版とも言えるtibbleの場合、複数のクラスを持っています。\n\nmy_tibble <- tibble(X = 1:5, Y = 1:5)\nclass(my_tibble)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n　このmy_tibbleはtlb_dfとtbl、data.frameといった3つのクラスを持っており、先に出てきたものが子クラス、後に出てくるものが親クラスです。tblクラスとdata.frameクラス両方に同じメソッドが定義されている場合、まず子クラスであるメソッド.tbl()が実行されます。もし、子クラスにメソッドが定義されていない場合はtblの親クラスであるdata.frameのメソッドが実行されます。tibbleはデータフレームとは異なるクラスのオブジェクトですが、データフレームと（ほぼ）同じ操作ができるのは、クラスが継承されるからです。クラスの継承ができないと、tibbleで使える全ての関数（列や行の抽出に使う[や$なども！）を全て一から定義する必要がありますが3、継承を使うことによってこのような手間を省くことが出来ます。"
  },
  {
    "objectID": "oop.html#RN4Esec-oop_in_r",
    "href": "oop.html#RN4Esec-oop_in_r",
    "title": "28  オブジェクト指向プログラミング",
    "section": "\n28.3 RにおけるOOP",
    "text": "28.3 RにおけるOOP\n\n28.3.1 オブジェクトに任意のクラスを付ける\n　クラスを変えるのは簡単です。class(オブジェクト) <- \"新しいクラス名\"だけです。つまり、関数から何かの結果を返す直前にクラスを変更すれば良いです。\n\n# 方法1\n関数名 <- function(...) {\n  \n  ...\n  \n  class(返すオブジェクト名) <- \"任意のクラス名\"\n  \n  返すオブジェクト名 # return(オブジェクト名) でもOK\n}\n\n　たとえば、入力された2つのベクトル（xとy）をリスト構造とし、クラス名をScoreにするにはどうすれば良いでしょうか。\n\nMake_Score1 <- function(x, y) {\n  \n  # resultリストにxとyを格納\n  result <- list(Score1 = x, Score2 = y)\n  \n  # 以下は attr(result, \"class\") <- \"Score\" も可\n  class(result) <- \"Score\" # resultのクラスを\"Score\"とする\n  \n  result                   # resultを返す\n}\n\nMy_Score1 <- Make_Score1(x = rnorm(10, 50, 10),\n                         y = rnorm(10, 50, 10))\n\nMy_Score1 # My_Score1の内部を見る\n\n$Score1\n [1] 53.13496 24.03579 46.79989 49.35460 66.55157 59.09767 56.81219 45.11277\n [9] 43.01650 54.30033\n\n$Score2\n [1] 42.77602 46.60492 34.35071 47.39764 76.93813 42.69540 34.44876 33.10258\n [9] 42.97212 66.89960\n\nattr(,\"class\")\n[1] \"Score\"\n\nclass(My_Score1) # My_Score1のクラスを表示\n\n[1] \"Score\"\n\n\n　もう一つの方法はstructure()関数を使う方法です。sturcture()の第1引数に返すオブジェクト名を指定し、class = \"クラス名\"引数でクラスを指定します。\n\nMake_Score2 <- function(x, y) {\n  \n  # resultリストにxとyを格納\n  result <- list(Score1 = x, Score2 = y)\n  \n  structure(result, class = \"Score\") # resultを返す\n}\n\nMy_Score2 <- Make_Score2(x = rnorm(10, 50, 10),\n                         y = rnorm(10, 50, 10))\n\nMy_Score2 # My_Score2の内部を見る\n\n$Score1\n [1] 49.30043 56.70409 41.67685 50.87590 32.83826 46.01314 38.67260 59.12435\n [9] 57.50880 61.23703\n\n$Score2\n [1] 52.88635 58.72981 63.15181 53.71398 50.73291 56.30333 48.45925 40.28827\n [9] 37.06377 44.20820\n\nattr(,\"class\")\n[1] \"Score\"\n\nclass(My_Score2) # My_Score2のクラスを表示\n\n[1] \"Score\"\n\n\n　どれも同じ結果が得られます。\n\n28.3.2 メソッドの作り方\n\n28.3.2.1 既に存在する関数名を使う\n　先ほど作成しましたScoreクラスのオブジェクトは長さ2のリスト構造をしています。これらの要素それぞれの平均値を求める場合は、mean(My_Score1[[1]])とmean(My_Score1[[2]])を実行する必要があります。なぜなら、mean()はベクトルしか計算できないからです。ここではScoreクラスのオブジェクト要素それぞれの平均値を求める関数mean()を作成します。\n　しかし、問題があります。それはRにmean()関数が既に存在することです。ここで勝手に上書きするのは良くないでしょう。ここで出てくるのがメソッドです。Scoreクラスのメソッドは「Scoreクラス専用の関数」であり、通常のベクトルならR内蔵のmean()関数を、ScoreクラスのオブジェクトならScoreのメソッドであるmean()を実行します。\n　メソッドの作り方は自作関数と同じです。相違点としては関数名を関数名.クラス名にすることです。Scoreクラスのメソッドしてのmean()関数を定義する場合、関数名をmean.Scoreとします。\n\nmean.Score <- function(x) {\n  print(mean(x$Score1))\n  print(mean(x$Score2))\n}\n\nmean(c(1, 3, 5, 7, 9, 11)) # R内蔵関数のmean()を使う\n\n[1] 6\n\nmean(My_Score1) # Scoreクラスのメソッドであるmean()を使う\n\n[1] 49.82163\n[1] 46.81859\n\n\n　mean(c(1, 3, 5, 7, 9, 11))は引数がnumeric型ベクトルであるため、既存のmean()関数が使用されます。一方、mean(My_Score1)は引数がScoreクラスであるため、mean.Score()が使用されます。このようにmean_Score()のような別途の関数を作る必要なく、既存の関数名が利用できます。実際、methods(mean)を実行すると、Scoreクラスのメソッドとしてmean()関数が用意されたことを確認できます。\n\nmethods(mean)\n\n[1] mean.Date        mean.default     mean.difftime    mean.POSIXct    \n[5] mean.POSIXlt     mean.quosure*    mean.Score       mean.vctrs_vctr*\nsee '?methods' for accessing help and source code\n\n\n\n28.3.2.2 新しい関数を作る\n　もし、新しい関数名を使用し、その関数が様々なクラスに対応するとしましょう。今回はCatというクラスを作ってみましょう。Catクラスの内部は長さ1のリストで、要素の名前はNameとし、ここには長さ1のcharacter型ベクトルが入ります。このCatクラスを作成する関数をMake_Cat()とします。\n\nMake_Cat <- function(name) {\n  \n  # resultリストにxを格納\n  result <- list(Name = name)\n  \n  structure(result, class = \"Cat\") # resultを返す\n}\n\nMy_Cat <- Make_Cat(name = \"矢内\")\nMy_Cat\n\n$Name\n[1] \"矢内\"\n\nattr(,\"class\")\n[1] \"Cat\"\n\nclass(My_Cat)\n\n[1] \"Cat\"\n\n\n　続いて、Catクラスに使うmy_func()を作成します。my_func()はそもそも存在しない関数ですので、普通にmy_func <- function()で作成可能です。この関数はCatのNameの後ろに\": にゃーにゃー\"を付けて出力する関数です。実際にやってみましょう。\n\nmy_func <- function(name) {\n  print(paste0(name$Name, \": にゃーにゃー\"))\n}\n\nmy_func(My_Cat)\n\n[1] \"矢内: にゃーにゃー\"\n\n\n　しかし、my_func()をCatクラス以外にも使いたい場合はどうすればいいでしょうか。普通にmy_func.クラス名()で良いでしょうか。確かにそうですが、その前に一つの手順が必要です。それは、my_func()をジェネリック関数として定義することです。この関数そのものは関数として機能はしませんが、「これからmy_func()がいろんなクラスのメソッドとして使われるぞ」と予め決めてくれます。ジェネリック関数を作成しないと関数名.クラス名は定義できません。そこで使うのがUseMethod()です。第一引数はメソッド名、第二引数は任意の引数ですが、通常、xが使われます。また、第二の引数は省略可能で、UseMethod(\"メソッド名\")でも動きます。\n\nmy_func <- function(x) {\n  UseMethod(\"my_func\", x)\n}\n\n　これからはmy_func.クラス名()の関数を作るだけです。まず、Score型オブジェクトに対してはそれぞれの要素の平均値を出力するとします。\n\nmy_func.Score <- function(x) {\n  print(mean(x$Score1))\n  print(mean(x$Score2))\n}\n\nmy_func.Cat <- function(cat) {\n  print(paste0(cat$Name, \": にゃーにゃー\"))\n}\n\n\nmethods(my_func)\n\n[1] my_func.Cat   my_func.Score\nsee '?methods' for accessing help and source code\n\n\n　my_func()関数はScoreとCatといった2種類のクラスで使われることが確認できます。それでは問題なく作動するかを確認してみましょう。My_Score1とMy_Catを、それぞれmy_func()に渡します。\n\nmy_func(My_Score1)\n\n[1] 49.82163\n[1] 46.81859\n\nmy_func(My_Cat)\n\n[1] \"矢内: にゃーにゃー\"\n\n\n　同じ関数名でも、オブジェクトのクラスによって異なる処理が行われることが分かります。\n\n28.3.3 検証用関数を作る\n　この作業は必須ではありませんが、今後、自分でパッケージ等を作ることになったら重要になるかも知れません。\n　最初の例でもお見せしましたが、Rでは事後的にクラスを変更することができます。強制的にクラスを変更した場合、そのクラスに属するメソッドを使うことができますが、エラーが生じてしまうでしょう。例えば、任意のcharacter型ベクトルMy_Cat2を作成し、Catクラスを付与してみましょう。\n\nMy_Cat2 <- \"宋\"\nclass(My_Cat2) <- \"Cat\"\nclass(My_Cat2)\n\n[1] \"Cat\"\n\n\n　My_Cat2のクラスはCatであるため、my_func.Cat()メソッドが使えます。しかし、my_func.Cat()仕組みを見る限り、うまく作動しないでしょう。\n\nmy_func(My_Cat2)\n\nError in cat$Name: $ operator is invalid for atomic vectors\n\n\n　間違った動作をするよりは、エラーが出て中断される方が良いですし、これで問題ないかも知れません。しかし、可能であれば、引数として使われたオブジェクトが、Catクラスか否かを厳密にチェックする機能があれば良いでしょう。カプセル化されている場合、クラスの定義時にデータの構造が厳密に定義されているため、このような手続きの必要性はあまりありませんが、カプセル化ができないRのS3クラスでは検証用関数（Validator）が必要です。\n　それではCatクラスの特徴をいくつか考えてみましょう。\n\nオブジェクトの中にはNameという要素のみがある。\n\nNameは長さ1のCharacter型ベクトルである。\n\n　以上の条件を全て満たしていればメソッドを実行し、一つでも満たさない場合はメソッドの実行を中止します。それでは検証用関数Validation_Cat()を作ってみましょう。\n\nValidation_Cat <- function(x) {\n  Message <- \"正しいCatクラスではありません。\"\n  \n  if (length(x) != 1) {\n    stop(Message)\n  } else if (is.null(names(x))) {\n    stop(Message)\n  } else if (names(x) != \"Name\"){\n    stop(Message)\n  } else if (length(x$Name) != 1 | class(x$Name) != \"character\") {\n    stop(Message)\n  }\n}\n\n　この検証用関数をmy_func.Cat()の最初に入れておきましょう。\n\nmy_func.Cat <- function(cat) {\n  Validation_Cat(cat)\n  \n  print(paste0(cat$Name, \": にゃーにゃー\"))\n}\n\n　それではMy_CatとMy_Cat2に対してmy_func()メソッドを実行してみます。\n\nmy_func(My_Cat)\n\n[1] \"矢内: にゃーにゃー\"\n\nmy_func(My_Cat2)\n\nError in Validation_Cat(cat): 正しいCatクラスではありません。\n\n\n　関数を実行する前に与えられたオブジェクトが正しいCatクラスか否かが判断され、パスされた場合のみ、メソッドが実行されることが分かります。もし、あるクラスで使用可能なメソッドが一つだけでしたら、検証用関数はメソッド内に直接書き込んでも良いですが、2つ以上のメソッドを持つ場合は別途の検証用関数を作成しておきましょう。"
  },
  {
    "objectID": "oop.html#RN4Esec-oop_example",
    "href": "oop.html#RN4Esec-oop_example",
    "title": "28  オブジェクト指向プログラミング",
    "section": "\n28.4 例題",
    "text": "28.4 例題\n　ここでは2つのnumeric型ベクトルとそのベクトル名入力し、相関係数を求めるMy_Cor()関数を作ってみます。単に相関係数を求めるだけならcor()やcor.test()があるので、いくつかの機能も追加してみましょう。\n\n\n\n　たとえば、「1日当たりゲーム時間」と「身長」といった2つのnumeric型ベクトルをそれぞれxとyで入力し、x_nameとy_nameで各ベクトルの名前も指定します。また、入力されたデータを用いて相関係数とその信頼区間を求めます。これらのデータはリスト型として格納されますが、クラスを\"My_Cor_Object\"とします。以下はその例です。\n\nCor_Obj <- My_Cor(x      = rnorm(20, 2, 0.5), \n                  y      = rnorm(20, 165, 6), \n                  x_name = \"1日当たりゲーム時間\", \n                  y_name = \"身長\")\n\nclass(Cor_Obj)\n\n[1] \"My_Cor_Object\"\n\n\n　このCor_Objの構造をstr()で確認してみます。\n\nstr(Cor_Obj)\n\nList of 4\n $ data    :'data.frame':   20 obs. of  2 variables:\n  ..$ x: num [1:20] 1.974 2.012 0.787 2.473 2.054 ...\n  ..$ y: num [1:20] 162 159 164 161 168 ...\n $ var_name: chr [1:2] \"1日当たりゲーム時間\" \"身長\"\n $ cor     : Named num -0.114\n  ..- attr(*, \"names\")= chr \"cor\"\n $ cor_ci  : num [1:2] -0.53 0.346\n  ..- attr(*, \"conf.level\")= num 0.95\n - attr(*, \"class\")= chr \"My_Cor_Object\"\n\n\n　Cor_Objには元のデータがデータフレームとして格納され（$data）、それぞれの変数名（$var_name）、相関係数（$cor）、相関係数の95%信頼区間（$cor_ci）がCor_Objの中に入っています。本質的にはリスト型のデータ構造ですが、クラス名がMy_Cor_Objectになっているだけです。\n　このMy_Cor_Objectクラスには3つのメソッド（専用関数）が用意されており、print()、summary()、plot()です。print()とsummary()は同じ関数で、xとyの平均値、そして相関係数と信頼区間を出力します。plot()は散布図と相関係数を出力します。実際の例を見てみましょう。\n\nprint(Cor_Obj)\n\n1日当たりゲーム時間の平均値: 1.953\n身長の平均値: 165.395\n相関係数: -0.114 [-0.530, 0.346]\n\nsummary(Cor_Obj) # summary()はprint()と同じ\n\n1日当たりゲーム時間の平均値: 1.953\n身長の平均値: 165.395\n相関係数: -0.114 [-0.530, 0.346]\n\nplot(Cor_Obj)\n\n\n\n\n　既存のcor.test()で作成される\"htest\"クラスに比べ、\"My_Cor_Object\"クラスは各変数の平均値が名前と一緒に表示され、plot()で簡単に散布図が作成できる大変便利なクラスです。このMy_Cor_Objectクラスとそのメソッドの構造を図示したものが 図 28.2 です。\n\n\n図 28.2: My_Cor_Objectクラスの構造\n\n\n　それでは一つずつ作っていきましょう。まずは、\"My_Cor_Object\"クラスのオブジェクトを作成するMy_Cor()関数からです。\n\nMy_Cor <- function(x, y, x_name, y_name) {\n    if (!is.numeric(x) | !is.numeric(y)) {\n        stop(\"xまたはyがnumeric型ではありません。\")\n    }\n    if (length(x) != length(y)) {\n        stop(\"xとyは同じ長さでなかればなりません。\")\n    }\n    if (!is.character(x_name) | !is.character(y_name)) {\n        stop(\"x_nameまたはy_nameがcharacter型ではありません。\")\n    }\n    \n    data     <- data.frame(x = x, y = y)\n    var_name <- c(x_name, y_name)\n    cor      <- cor.test(x, y)$estimate\n    cor_ci   <- cor.test(x, y)$conf.int\n    \n    result   <- structure(list(data     = data, \n                               var_name = var_name, \n                               cor      = cor,\n                               cor_ci   = cor_ci),\n                          class = \"My_Cor_Object\")\n    \n    result\n}\n\n　最初の部分は入力されたデータがMy_Cor_Objectクラスに適した構造か否かを判断します。これは最初から想定外のMy_Cor_Objectクラスのオブジェクトが作成されることを防ぐことが目的です。むろん、R（S3）の性質上、事後的にクラスを変更することが可能ですから、検証用関数も作っておきます。ここでは以下の条件を検証します。\n\n\ndataという要素が存在し、2列である。\n\nvar_nameという要素が存在し、長さ2のcharacter型ベクトルである。\n\ncorという要素が存在し、長さ1のnumeric型ベクトルである。\n\ncor_ciという要素が存在し、長さ2のnumeric型ベクトルである。\n\n\nValidation <- function (x) {\n  UseMethod(\"Validation\", x)\n}\n\nValidation.My_Cor_Object <- function(x) {\n  Message <- \"正しいMy_Cor_Objectクラスではございません。\"\n  \n  if (is.null(x$data) | ncol(x$data) != 2) {\n    stop(Message)\n  }\n  if (is.null(x$var_name) | length(x$var_name) != 2 | class(x$var_name) != \"character\") {\n    stop(Message)\n  }\n  if (is.null(x$cor) | length(x$cor) != 1 | class(x$cor) != \"numeric\") {\n    stop(Message)\n  }\n  if (is.null(x$cor_ci) | length(x$cor_ci) != 2 | class(x$cor_ci) != \"numeric\") {\n    stop(Message)\n  }\n}\n\n　ここではValidation()をジェネリック関数として使用しました。自分が開発するパッケージで複数のクラスを提供する予定でしたら、このようなやり方が良いでしょう。\n　検証用関数は細かく書いた方が良いです。以上のValidation()もより細かくことが出来ます。たとえば、dataが2列か否かを判定するだけでなく、numeric型であるかなども判定した方が良いでしょう。\n　つづいて、My_Cor_Objectクラス用のprint()関数（メソッド）を作成します。\n\nprint.My_Cor_Object <- function(data) {\n    Valdation(data)\n    \n    cat(sprintf(\"%sの平均値: %.3f\\n\", \n                data$var_name[1],\n                mean(data$data$x)))\n    cat(sprintf(\"%sの平均値: %.3f\\n\", \n                data$var_name[2],\n                mean(data$data$y)))\n    cat(sprintf(\"相関係数: %.3f [%.3f, %.3f]\\n\", \n                data$cor, \n                data$cor_ci[1],\n                data$cor_ci[2]))\n}\n\n　次は、summary()メソッドですが、これはprint()と同じ機能をする関数です。この場合、UseMethod(\"メソッド名\")を使うと、指定したメソッドを使うことになります。\n\nsummary.My_Cor_Object <- function(data) {\n  UseMethod(\"print\")\n}\n\n　最後はplot()メソッドです。\n\nplot.My_Cor_Object <- function(data) {\n    Valdation(data)\n    \n    data$data %>%\n      ggplot(aes(x = x, y = y)) +\n      geom_point() +\n      labs(x = data$var_name[1], y = data$var_name[2]) +\n      ggtitle(sprintf(\"相関係数 = %.3f\", data[[\"cor\"]])) +\n      theme_minimal(base_family = \"HiraKakuProN-W3\")\n}\n\n　これで相関係数の計算および可視化が便利になる関数群が完成しました。Rパッケージの開発はこれよりも数倍も複雑ですが、本記事の内容はプログラミングをより効率的に行うための入り口となります。\n\n私たちのR 私たちのR 29  モンテカルロ・シミュレーション 27  反復処理 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 28  オブジェクト指向プログラミング 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "monte.html#RN4Esec-monte-intro",
    "href": "monte.html#RN4Esec-monte-intro",
    "title": "29  モンテカルロ・シミュレーション",
    "section": "\n29.1 モンテカルロシミュレーションとは",
    "text": "29.1 モンテカルロシミュレーションとは\n\npacman::p_load(tidyverse, ggforce)\n\n　モンテカルロ法 (Monte Carlo method)とは無作為に抽出された乱数を用い、数値計算やシミュレーションを行う手法を意味します。モンテカルロはヨーロッパのモナコ公国内の一つの地区であり、カジノで有名なところです。カジノではサイコロやルーレット、無作為に配られたカードなど、乱数が頻繁に使われることからこのように名付けられました。\n　モンテカルロ法を用いたシミュレーションがモンテカルロ・シミュレーションです。計算があまりにも複雑だったり、実質的に代数で解が得られない解析学上の問題などに強みを持つ手法です。一部、明快な例（共役事前分布が存在するなど）を除き、事後分布の計算が非常に複雑（実質、不可能）だと知られていたベイズ統計学もモンテカルロ法（マルコフ連鎖モンテカルロ法; MCMC）によって、ようやく使えるものになったなど、今になってモンテカルロ法は非常に広く用いられています。\n　モンテカルロ法から得られた結果には常に誤差が存在します。とりわけ、生成された乱数が少ない（= 試行回数が少ない）場合、この誤差は大きくなります。しかし、近年はパソコンの性能が飛躍的に発達しているため、かなり小さな誤差で、つまりより正確な結果が得られるようになりました。\n　以下ではまず、モンテカルロ法を理解するために必須知識である乱数生成について解説します。具体的には乱数生成のアルゴリズムでなく、Rで乱数を生成する方法について紹介します。続いて、モンテカルロ法を用いたシミュレーションの例として誕生日問題、モンティ・ホール問題、円周率の計算、ブートストラップ法を紹介します。"
  },
  {
    "objectID": "monte.html#RN4Esec-monte-rng",
    "href": "monte.html#RN4Esec-monte-rng",
    "title": "29  モンテカルロ・シミュレーション",
    "section": "\n29.2 乱数生成",
    "text": "29.2 乱数生成\n\n29.2.1 sample()によるサンプリング\n　無作為に値を抽出する方法には2つが考えられます。一つは値の集合から無作為に値を抽出する方法、もう一つは正規分布などの確率分布から値を抽出する方法です。ここではまずsample()関数を用い、値の集合から無作為に値を抽出する方法について説明します。\n\nsample(x = 値の集合ベクトル, size = 抽出の回数, \n       replace = 復元抽出の有無, prob = 各要素が抽出される確率)\n\n　replaceは復元抽出の有無を指定する引数であり、既定値はFALSE、つまり非復元抽出がデフォルトとなっています。これは一度抽出された要素は、二度と抽出されないことを意味します。値の集合が{0, 1}で、5個の値を抽出する（=sizeがxの長さより大きい）ならば、replaceは必ずTRUEに設定する必要があります。抽選などは非復元抽出であるため、replace引数は省略可能です。しかし、対数の法則やブートストラップなどは復元抽出を仮定している場合が多く、意識的にreplace関数は指定することを推奨します。probは各要素が抽出される確率を意味し、xの実引数と同じ長さのnumeric型ベクトルを指定します。probの実引数の総和は1であることが望ましいですが、総和が1でない場合、自動的に総和が1になるよう正則化を行います。つまり、c(1, 3)はc(0.25, 0.75)と同じことを意味します。\n　サイコロを3回振るコードを書くなら、値の集合（x）はc(1, 2, 3, 4, 5, 6)、または1:6で、抽出の回数（size）は3となります。また、一回出た目も抽出される可能性があるため、復元抽出を行う必要があります（replace = TRUE）。そして各目が出る確率は1/6ですが、各値が抽出される確率が等しい場合、省略可能です。\n\n# この場合、prob引数は省略可能\nsample(1:6, 3, replace = TRUE, prob = rep(1/6, 6))\n\n[1] 5 5 2\n\n\n　今回はサイコロを1万回振り、それぞれの目が出た回数を棒グラフとして示してみます。無作為に抽出された値であれば、各目が出る回数は等しいはずです。ベクトルに対してtable()関数を使うと、各要素が出現した回数が出力され、このオブジェクトをbarplot()関数に渡すと棒グラフを作成することができます。\n\nDice_vec <- sample(1:6, 10^4, replace = TRUE)\ntable(Dice_vec) %>% barplot()\n\n\n\n図 29.1: 6面体サイコロを1万回投げた場合\n\n\n\n\n　1から6までの目が出た回数がほぼ同じであることが確認できます。この6つの棒の高さがすべて同じになることはありえませんが（そもそも1万を6で割ったら余りが出ますね）、ほぼ同じ割合であることから、疑似乱数とは言え、シミュレーション用としては十分でしょう。\n\n29.2.2 確率分布からの乱数制制\n\n\n関数名\n確率分布\nパラメーター\n\n\n\nrbeta()\nベータ分布\n\nn, shape1, shape2\n\n\n\nrbinom()\n二項分布\n\nn, size, prob\n\n\n\nrcauchy()\nコーシー分布\n\nn, location, scale\n\n\n\nrchisq()\n\n\\(\\chi^2\\)分布\n\nn, df\n\n\n\nrexp()\n指数分布\n\nn, rate\n\n\n\nrf()\n\n\\(F\\)分布\n\nn, df1, df2\n\n\n\nrgamma()\nガンマ分布\n\nn, shape, scale\n\n\n\nrgeom()\n幾何分布\n\nn, prob\n\n\n\nrhyper()\n超幾何分布\n\nnn, m, n, k\n\n\n\nrlnorm()\n対数正規分布\n\nn, meanlog, sdlog\n\n\n\nrmultinom()\n多項分布\n\nn, size, prob\n\n\n\nrnbinom()\n負の二項分布\n\nn, size, prob\n\n\n\nrnorm()\n正規分布\n\nn, mean, sd\n\n\n\nrpois()\nポアソン分布\n\nn, lambda\n\n\n\nrt()\nt分布\n\nn, df\n\n\n\nrunif()\n一様分布\n\nn, min, max\n\n\n\nrweibull()\nワイブル分布\n\nn, shape, scale\n\n\n\nmvtnorm::rmvnorm()\n多変量正規分布\n\nn, mean, sigma\n\n\n\n\n　以上の表に掲載されているパラメーター以外にも指定可能なパラメーターがあるため、詳細は各関数のヘルプを参照してください。たとえば、ガンマ分布の場合、rateで、負の二項分布の場合、muで分布の形状を指定することができます。また、多変量正規分布の乱数を抽出するには{mvtnorm}パッケージのrmvnorm()を使いますが、ここでのmeanは数値型ベクトル、sigmaは行列構造の分散共分散行列を使います1。\n\n29.2.3 シードについて\n　特定の分布から乱数を抽出する場合、当たり前ですが、抽出の度に値が変わります。たとえば、平均0、標準偏差1の正規分布（標準正規分布）から5つの値を抽出し、小数点3桁に丸める作業を3回繰り返しみましょう。\n\nrnorm(5) %>% round(3)\n\n[1]  0.934 -0.308  1.067  2.028  0.238\n\nrnorm(5) %>% round(3)\n\n[1] -0.396  0.403 -1.126  0.444 -0.902\n\nrnorm(5) %>% round(3)\n\n[1]  0.052 -0.499 -0.604  1.017 -0.331\n\n\n　このように、抽出の度に結果が変わります。1回きりのシミュレーションではこれで問題ないでしょうが、同じシミュレーションから同じ結果を得るためには、乱数を固定する必要があります。そこで使うのがシード（seed）です。シードが同じなら抽出される乱数は同じ値を取ります。シードの指定はset.seed(numeric型スカラー)です。たとえば、シードを19861008にし、同じ作業をやってみましょう。\n\nset.seed(19861008)\nrnorm(5) %>% round(3)\n\n[1] -0.086  0.396 -1.330  0.574  0.152\n\nrnorm(5) %>% round(3)\n\n[1]  0.555  0.620 -1.133  0.572  0.900\n\n\n　シードを指定しても2つのベクトルは異なる値を取りますが、もう一度シードを指定してから乱数抽出をしてみましょう。\n\nset.seed(19861008)\nrnorm(5) %>% round(3)\n\n[1] -0.086  0.396 -1.330  0.574  0.152\n\n\n　先ほどのコードでシードを指定した直後に抽出した乱数と同じ乱数が得られました。モンテカルロ・シミュレーションにおいて乱数は非常に重要ですが、これはシミュレーションの度に異なる結果が得られることを意味します。つまり、自分が書いたコードから100%同じ結果が得られないだけでなく、自分も同じ結果を再現できないことを意味します。この場合、シードを指定すると乱数が固定され、シミュレーション結果の再現ができるようになります。\n　一つ注意すべき点は乱数を固定した後、複数回抽出を繰り返す場合、その順番も固定されるという点です。たとえば、シードを固定せずにもう一回5つの値を抽出してみましょう。\n\nrnorm(5) %>% round(3)\n\n[1]  0.555  0.620 -1.133  0.572  0.900\n\n\n　この結果は先ほどシード指定後、2回目の抽出結果と同じ結果となります。結果を再現するという点では大きな問題はないはずですが、仕様を理解しておくことは重要でしょう。"
  },
  {
    "objectID": "monte.html#RN4Esec-monte-birthday",
    "href": "monte.html#RN4Esec-monte-birthday",
    "title": "29  モンテカルロ・シミュレーション",
    "section": "\n29.3 例1: 誕生日問題",
    "text": "29.3 例1: 誕生日問題\n　まず簡単な例として誕生日問題 (birthday problem)をシミュレーションで確認してみましょう。誕生日問題とは「何人いれば、その中に誕生日が同じ2人以上がいる確率が50%を超えるか。」といった問題です。1年を365日で考えると（2月29日生まれの皆さん、すみません…）、366人がいれば確実に (= 100%)同じ誕生日の人が2人以上いることになりますね。100%でなく、50%まで基準を下げるならその半分である183人は必要じゃないかと思うかも知れません。しかし、実はたった23人が集まれば、その中で同じ誕生日の人が2人以上いる確率が50%になります。誕生日のパラドックスとも呼ばれるものですが、これをシミュレーションで確認してたいと思います。\n　学生の数をn_studentとし、1から365までの公差1の等差数列から、n_student個の値を復元抽出します。\n\nn_student <- 30 # 学生数\n# 「1から365までの公差1の等差数列」からn_student個の値を復元抽出\nBirth_vec <- sample(1:365, n_student, replace = TRUE)\n\nBirth_vec\n\n [1] 340 122 230 148  12 136  87  46  16 310 104 351 137  53 361  65 106 361 108\n[20] 281 299  67 342   4 338  88 156 254 192  37\n\n\n　このベクトルの中で重複する要素があるかどうかを確認するにはduplicated()関数を使います。ある要素が他の要素と重複するならTRUEが、なければFALSEが表示されます。\n\nduplicated(Birth_vec)\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE\n\n\n　ただし、一つでもTRUEが含まれていれば、同じ誕生日の人が二人以上はいるということとなるので、更にany()関数を使います。any()内の条件文において、一つでもTRUEがあれば返り値はTRUEとなり、全てFALSEならFALSEを返す関数です。\n\nany(duplicated(Birth_vec))\n\n[1] TRUE\n\n\n　以上の作業を100回繰り返す場合、試行回数が100回となります。この場合、TRUEの結果が出る試行は何回でしょうか。\n\nn_student <- 10   # 学生数\nn_trials  <- 100  # 試行回数\n\n# 結果を格納する空ベクトルを用意する\nResult_vec <- rep(NA, n_trials)\n\n# 反復処理\nfor (i in 1:n_trials) {\n    Birth_vec     <- sample(1:365, n_student, replace = TRUE)\n    Result_vec[i] <- any(duplicated(Birth_vec))\n}\n\nResult_vec\n\n  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n [13] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n [25] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [37] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE\n [49] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [61] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE\n [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [85] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [97] FALSE FALSE FALSE FALSE\n\n\n　100回の試行の中でTRUEが出たのは10回ですね。割合で考えると10%です。この試行回数を無限にすると確率として解釈できますが、無限回繰り返しは世の中が終わるまでやっても終わりませんね。ただし、十分に多い試行回数、たとえば1万回程度繰り返すと確率に近似できるでしょう。\n\nn_student <- 10    # 学生数\nn_trials  <- 10000 # 試行回数\n\n# 結果を格納する空ベクトルを用意する\nResult_vec <- rep(NA, n_trials)\n\n# 反復処理\nfor (i in 1:n_trials) {\n    Birth_vec     <- sample(1:365, n_student, replace = TRUE)\n    Result_vec[i] <- any(duplicated(Birth_vec))\n}\n\nsum(Result_vec)\n\n[1] 1147\n\n\n　1万回の試行からTRUEが出た回数は1147回であり、11.5%ですね。つまり、人が10人集まれば誕生日が同じ人が2人以上いる確率は約11.5%ということになります。実はこの確率は厳密に計算可能であり、理論的な確率は約11.7%です。シミュレーションから得られた結果が理論値にかなり近似していることが分かります。\n　今回は試行回数は100に固定し、学生数を2から100まで調整しながら同じ誕生日の人が2人以上いる割合を計算してみましょう。以下では割合を計算する関数Birthday_Func()を作成し、{purrr}のmap_dbl()関数を使用して反復処理を行います。関数の作成は第11章を、{purrr}の使い方については第27章を参照してください。\n\n# 割合を計算する関数を作成する\nBirthday_Func <- function (n, n_trials) {\n    \n    # 各試行の結果を格納する空ベクトルを用意する。\n    Result_vec <- rep(NA, n_trials)\n    \n    # n_trials回だけ{}内コードを繰り返す。\n    for (i in 1:n_trials) {\n        # 1:365からn個の値を復元抽出\n        Birth_vec     <- sample(1:365, n, replace = TRUE)\n        # 重複する要素があるかをチェックし、結果ベクトルのi番目に格納\n        Result_vec[i] <- any(duplicated(Birth_vec))\n    }\n    \n    # 各試行結果が格納されたベクトルからTRUEの割合を返す\n    mean(Result_vec)\n}\n\n# 学生数をStudents列に格納したデータフレーム (tibble)を作成\nProb_df <- tibble(Students = 2:100)\n\n# Students列の値に応じてBirthday_Func()を実行\nProb_df <- Prob_df %>%\n    mutate(Probs = map_dbl(Students, ~Birthday_Func(.x, 100)))\n\n　{purrr}関数を使わずに、for()文を使用した例は以下のようになります。\n\n# {purrr}を使わない方法\nProb_df <- tibble(Students = 2:100,\n                  Probs    = NA)\n\nfor (i in 1:nrow(Prob_df)) {\n    \n    Result_vec <- rep(NA, n_trials)\n    \n    for (j in 1:n_trials) {\n        Birth_vec     <- sample(1:365, Prob_df$Students[i], replace = TRUE)\n        Result_vec[j] <- any(duplicated(Birth_vec))\n    }\n    \n    Prob_df$Probs[i] <- mean(Result_vec)\n}\n\n　結果を確認してみましょう。\n\nProb_df\n\n# A tibble: 99 × 2\n   Students Probs\n      <int> <dbl>\n 1        2  0.01\n 2        3  0.02\n 3        4  0.06\n 4        5  0.01\n 5        6  0.02\n 6        7  0.08\n 7        8  0.06\n 8        9  0.09\n 9       10  0.12\n10       11  0.18\n# … with 89 more rows\n\n\n　学生数が何人いれば、同じ誕生日の人が2人以上いる割合が50%になるのでしょうか。割合が0.4以上、0.6以下の行を抽出してみましょう。\n\nProb_df %>%\n    filter(Probs >= 0.4 & Probs <= 0.6)\n\n# A tibble: 7 × 2\n  Students Probs\n     <int> <dbl>\n1       18  0.41\n2       21  0.46\n3       22  0.41\n4       23  0.45\n5       24  0.52\n6       25  0.58\n7       27  0.56\n\n\n　大体23人前後ですかね。試行回数を増やせばもう少し厳密に検証出来るかも知れませんが、とりあえず以上の結果を可視化してみましょう。\n\nProb_df %>%\n    ggplot() +\n    geom_line(aes(x = Students, y = Probs * 100), size = 1) +\n    geom_hline(yintercept = 50, color = \"red\", linetype = 2) +\n    labs(x = \"学生数\",\n         y = \"同じ誕生日の人が2人以上いる割合 (%)\\n(試行回数 = 100)\") +\n    theme_bw(base_size = 12)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n図 29.2: 同じ誕生日の人が2人以上いる割合 (%) (試行回数 = 100)\n\n\n\n\n　非常に直感に反する結果かも知れませんが、50人程度いれば、ほぼ確実に同じ誕生日の人が2人以上いることが分かります。この誕生日問題は以下のように解くことができます。人が\\(n\\)人いる場合、同じ誕生日の人が2人以上いる確率\\(p(n)\\)は、\n\\[\np(n) = 1 - \\frac{365!}{365^n (365-n)!}\n\\]\n　!は階乗を意味し、5!は\\(5 \\times 4 \\times 3 \\times 2 \\times 1\\)を意味します。Rではfactorial()関数を使います。それでは\\(p(50)\\)はいくらでしょうか。\n\n1 - factorial(365) / (365^50 * factorial(365 - 50))\n\n[1] NaN\n\n\n　あらら、NaNがでましたね。つまり、計算不可です。実際、factorial(365)だけでも計算結果はInfが出ます。むろん、実際に無限ではありませんが、非常に大きい数値ということです。以上の式を計算可能な式に変形すると以下のようになります。\n\\[\np(n) = 1 - \\frac{n! \\times _{365}C_n}{365^n}\n\\]\n　\\(C\\)は二項係数を意味し\\(_nC_k\\)は\\(\\frac{n!}{k!(n-k)!}\\)です。Rではchoose(n, k)で計算可能です。\n\n1 - ((factorial(50) * choose(365, 50)) / 365^50)\n\n[1] 0.9703736\n\n\n　結果は0.9703736です。つまり、人が50人いれば同じ誕生日の人が2人以上いる確率は約97%ということです。それでは、以上の式を関数化し、p(22)とp(23)を計算してみましょう。\n\nBirth_Expect <- function (n) {\n    1 - ((factorial(n) * choose(365, n)) / 365^n)\n}\n\nBirth_Expect(22)\n\n[1] 0.4756953\n\nBirth_Expect(23)\n\n[1] 0.5072972\n\n\n　確率が50%を超える人数は23人であることが分かります。先ほどのデータフレーム (Prob_df)にこの理論値をExpectという名の列として追加してみましょう。\n\nProb_df <- Prob_df %>%\n    mutate(Expect = map_dbl(Students, ~Birth_Expect(.x)))\n\nProb_df\n\n# A tibble: 99 × 3\n   Students Probs  Expect\n      <int> <dbl>   <dbl>\n 1        2  0.01 0.00274\n 2        3  0.02 0.00820\n 3        4  0.06 0.0164 \n 4        5  0.01 0.0271 \n 5        6  0.02 0.0405 \n 6        7  0.08 0.0562 \n 7        8  0.06 0.0743 \n 8        9  0.09 0.0946 \n 9       10  0.12 0.117  \n10       11  0.18 0.141  \n# … with 89 more rows\n\n\n　これは人間にとっては読みやすい表ですが、可視化まで考えると、tidyなデータといは言えません。したがって、pivot_longer()関数を使用してtidyなデータに整形します。{tidyr}パッケージの使い方は第15章を参照してください。\n\nProb_df2 <- Prob_df %>%\n    pivot_longer(cols      = Probs:Expect,\n                 names_to  = \"Type\",\n                 values_to = \"Prob\") \n\nProb_df2\n\n# A tibble: 198 × 3\n   Students Type      Prob\n      <int> <chr>    <dbl>\n 1        2 Probs  0.01   \n 2        2 Expect 0.00274\n 3        3 Probs  0.02   \n 4        3 Expect 0.00820\n 5        4 Probs  0.06   \n 6        4 Expect 0.0164 \n 7        5 Probs  0.01   \n 8        5 Expect 0.0271 \n 9        6 Probs  0.02   \n10        6 Expect 0.0405 \n# … with 188 more rows\n\n\n　こちらのデータを使用し、シミュレーションから得られた結果と理論値を折れ線グラフで出力してみましょう。\n\nProb_df2 %>%\n    mutate(Type = ifelse(Type == \"Probs\", \"シミュレーション\", \"理論値\")) %>%\n    ggplot() +\n    geom_line(aes(x = Students, y = Prob * 100, color = Type), size = 1) +\n    labs(x     = \"学生数\",\n         y     = \"同じ誕生日の人が2人以上いる割合 (%)\\n(試行回数 = 100)\",\n         color = \"\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\")\n\n\n\n図 29.3: 同じ誕生日の人が2人以上いる割合 (%) (試行回数 = 100)\n\n\n\n\n　最後に以上の作業を試行回数10000としてもう一回やってみましょう。\n\n# 学生数をStudents列に格納したデータフレーム (tibble)を作成\nProb_df <- tibble(Students = 2:100)\n\n# Students列の値に応じてBirthday_Func()を実行\nProb_df <- Prob_df %>%\n    mutate(Simul  = map_dbl(Students, ~Birthday_Func(.x, 10000)),\n           Expect = map_dbl(Students, ~Birth_Expect(.x)))\n\nProb_df %>%\n    pivot_longer(cols      = Simul:Expect,\n                 names_to  = \"Type\",\n                 values_to = \"Prob\") %>%\n    mutate(Type = ifelse(Type == \"Simul\", \"シミュレーション\", \"理論値\")) %>%\n    ggplot() +\n    geom_line(aes(x = Students, y = Prob * 100, color = Type), size = 1) +\n    labs(x     = \"学生数\",\n         y     = \"同じ誕生日の人が2人以上いる割合 (%)\\n(試行回数 = 100)\",\n         color = \"\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\")\n\n\n\n図 29.4: 同じ誕生日の人が2人以上いる割合 (%) (試行回数 = 100)\n\n\n\n\n　モンテカルロ・シミュレーションから得られた割合と理論上の確率が非常に近似していることが分かります。"
  },
  {
    "objectID": "monte.html#RN4Esec-monte-montyhall",
    "href": "monte.html#RN4Esec-monte-montyhall",
    "title": "29  モンテカルロ・シミュレーション",
    "section": "\n29.4 例2: モンティ・ホール問題",
    "text": "29.4 例2: モンティ・ホール問題\n　抽出される乱数が必ずしも数値である必要はありません。たとえば、コイン投げの表と裏、ポーカーで配られたカードなど、数値以外の乱数もあり得ます。ここでは「AとB、C」から一つを選ぶ例として、モンティ・ホール問題をモンテカルロ法で解いてみましょう。\n　モンティ・ホール問題はアメリカのテレビ番組「Let’s make a deal」の中のゲームであり、この番組の司会者の名前がモンティ・ホール (Monty Hall)さんです。このゲームのルールは非常にシンプルです。\n\n3つのドアがあり、1つのドアの裏に商品 (車)がある。残りの2つは外れ（ヤギ）である。\n参加者はドアを選択する。\n司会者が残りのドア2つの中で商品がないドアを開けて中身を見せる。\nここで参加者はドアの選択を変える機会が与えられる。\n\n　直観的に考えて、司会者が外れのドアを1つ教えてくれたなら、自分が選んだドアを含め、残りの2つのドアの1つに絶対に商品があります。直感的に考えてみると、当たる確率は半々であって、変えても、変えなくても当たる確率は同じだと考えられます。詳細はWikipediaなどを参照してください。この問題を巡る論争とかも紹介されていてなかなか面白いです。\n　結論から申しますと選択を変えた方が、変えなかった場合より当たる確率が2倍になります。これは条件付き確率とベイズの定理を用いることで数学的に説明できますが、ここではあえてモンテカルロ法で調べてみたいと思います。シミュレーションの具体的な手順は以下の通りです。\n\n結果を格納する長さ1万の空ベクトルを2つ用意する。 (Switch_YesとSwitch_No)。\n\niの初期値を1とする。\n当たり (車)の位置をA, B, Cの中から無作為に1つ決め、Car_Positionに格納する。\n最初の選択肢をA, B, Cの中から無作為に1つ決め、Choiceに格納する。\n選択肢を変更した場合の結果をSwitch_Yesのi番目の要素としてに格納する。\n\n当たりの位置と最初の選択肢が同じなら (Switch_Yes == Choice)、結果は外れ (ヤギ)\n当たりの位置と最初の選択肢が同じでないなら (Switch_Yes != Choice)、結果は当たり (車)\n\n\n選択肢を変更しなかった場合の結果をSwitch_Noのi番目の要素として格納する。\n\n当たりの位置と最初の選択肢が同じなら (Switch_Yes == Choice)、結果は当たり (車)\n当たりの位置と最初の選択肢が同じでないなら (Switch_Yes != Choice)、結果は外れ (ヤギ)\n\n\n\niの値を1増やし、3に戻る。\n3〜7の手順を1万回繰り返す。\n\n　以上の手順をコードで書くと以下のようになります。\n\nSwitch_Yes <- rep(NA, 10000)\nSwitch_No  <- rep(NA, 10000)\n\nset.seed(19861009)\nfor (i in 1:10000) {\n    Car_Position <- sample(c(\"A\", \"B\", \"C\"), 1)\n    Choice       <- sample(c(\"A\", \"B\", \"C\"), 1)\n    \n    Switch_Yes[i] <- ifelse(Car_Position == Choice, \"Goat\", \"Car\")\n    Switch_No[i]  <- ifelse(Car_Position == Choice, \"Car\", \"Goat\")\n}\n\ntable(Switch_Yes)\n\nSwitch_Yes\n Car Goat \n6737 3263 \n\ntable(Switch_No)\n\nSwitch_No\n Car Goat \n3263 6737 \n\n\n　選択肢を変更し、車を獲得した回数は10000回中、6737であり、約67%です。つまり、選択肢を変えた方が、変えなかった場合に比べ、車が当たる確率が約2倍高いことを意味します。むろん、車よりもヤギが重宝される地域に住んでいるなら、あえて選択肢を変えず、ヤギを狙った方が良いかも知れません。"
  },
  {
    "objectID": "monte.html#RN4Esec-monte-pi",
    "href": "monte.html#RN4Esec-monte-pi",
    "title": "29  モンテカルロ・シミュレーション",
    "section": "\n29.5 例3: 円周率の計算",
    "text": "29.5 例3: 円周率の計算\n　今回はもう一つの例として、円周率 (\\(\\pi\\))の計算を紹介したいと思います。\\(\\pi\\)は無理数であるため、厳密な計算は出来ませんが、モンテカルロ・シミュレーションである程度近似できます。たとえば、半径1 (\\(r = 1\\))の円を考えてみましょう。\n\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\n\n\n\n　円の面積は\\(r^2\\pi\\)であるため、この円の面積は\\(\\pi\\)です。また、四角形は辺の長さが2の正四角形ですから面積は4です。続いて、四角形の範囲内の点を付けます。無作為に20個を付けてみます。\n\n\n\n\n\n\n\n\n　20個点のうち、円の外側にあるのは5個、円の内側は15個です。つまり、75%の点が円内にあることを意味します。点の位置は無作為ですので、もし円の大きさが\\(\\pi\\)であれば、点が円内に入る確率は\\(\\frac{\\pi}{4}\\)です。今回の例だと\\(\\frac{\\pi}{4} = 0.75\\)であるため、\\(\\pi = 0.75 \\times 4 = 3\\)となります。実際の円周率は3.141593…なので、そこそこ近似できていますね。\n　それではこれを実際にやってみましょう。今回は20個の点ではなく、100個にしてみましょう。まず、100個の点を無作為に抽出します。\n\nset.seed(19861009)\npi_df <- tibble(x = runif(100, -1, 1),\n                y = runif(100, -1, 1))\n\npi_df\n\n# A tibble: 100 × 2\n         x      y\n     <dbl>  <dbl>\n 1 -0.950  -0.344\n 2  0.0724  0.150\n 3  0.874   0.971\n 4  0.938   0.267\n 5  0.205   0.469\n 6 -0.343  -0.590\n 7 -0.0245 -0.635\n 8 -0.273  -0.886\n 9 -0.405   0.701\n10  0.528  -0.547\n# … with 90 more rows\n\n\n　まず、各辺の長さが2の正四角形とpi_dfで生成した100個の点をプロットします。四角形を描くときにはgeom_rect()幾何オブジェクトを使用します。マッピングは四角形の左下の座標 (xminとymin)、右上の座標 (xmaxとymax)に行います。今回は原点が (0, 0)の半径1の円に接する四角形ですから、左下の座標は (-1, -1)、右上の座標は (1, 1)となります。\n\npi_df %>%\n    ggplot() +\n    geom_rect(aes(xmin = -1, ymin = -1, xmax = 1, ymax = 1),\n              fill = \"white\", color = \"black\") +\n    geom_point(aes(x = x, y = y)) +\n    coord_fixed(ratio = 1) +\n    theme_minimal()\n\n\n\n\n\n\n\n　ここに円を追加してみましょう。円を描くときには{ggforce}パッケージのgeom_circle()幾何オブジェクトを使用します。マッピングは円の原点 (x0とy0)、円の半径 (r)です。原点は (0, 0)で半径は1の円を重ねます。\n\npi_df %>%\n    ggplot() +\n    geom_rect(aes(xmin = -1, ymin = -1, xmax = 1, ymax = 1),\n              fill = \"white\", color = \"black\") +\n    geom_circle(aes(x0 = 0, y0 = 0, r = 1)) +\n    geom_point(aes(x = x, y = y)) +\n    coord_fixed(ratio = 1) +\n    theme_minimal()\n\n\n\n\n\n\n\n　これだけだと読みづらいので、円の中か外かで点の色分けをしてみましょう。そのためには各点が円内に入っているかどうかを判定した変数in_circleを追加します。点(\\(x\\), \\(y\\))が、原点が(\\(x^\\prime\\), \\(y^\\prime\\))、かつ半径\\(r\\)の円内に入っている場合、\\((x - x^\\prime)^2 + (y - y^\\prime)^2 < r^2\\)が成立します。今回は原点が (0, 0)で、半径が1であるため、\\(x^2 + y^2 < 1\\)か否かを判定します。この条件を満たしているかどうかを示すin_circleという変数を追加します。\n\npi_df <- pi_df %>%\n    mutate(in_circle = if_else(x^2 + y^2 < 1^2, \"円内\", \"円外\"))\n\n　散布図レイヤー (geom_point())内にcolorをin_circle変数でマッピングします。\n\npi_df %>%\n    ggplot() +\n    geom_rect(aes(xmin = -1, ymin = -1, xmax = 1, ymax = 1),\n              fill = \"white\", color = \"black\") +\n    # 円の内側か外側かで色分け\n    geom_point(aes(x = x, y = y, color = in_circle), size = 2) +\n    geom_circle(aes(x0 = 0, y0 = 0, r = 1)) +\n    labs(x = \"X\", y = \"Y\", color = \"\") +\n    coord_fixed(ratio = 1) +\n    theme_void(base_size = 12)\n\n\n\n\n\n\n\n　実際に円内の点と円外の点の個数を数えてみましょう。\n\npi_df %>%\n    group_by(in_circle) %>%\n    summarise(N = n())\n\n# A tibble: 2 × 2\n  in_circle     N\n  <chr>     <int>\n1 円内         82\n2 円外         18\n\n\n　円内の点は82個、円外の点は18ですね。つまり、\\(\\frac{\\pi}{4} = 0.82\\)であり、\\(\\pi = 0.82 \\times 4 = 3.28\\)です。\n\n82 / 100 * 4\n\n[1] 3.28\n\n\n　今回は100個の点で円周率の近似値を計算しましたが、点の数を増やすとより正確な近似値が得られます。以下の例は10000個の点から得られた円周率の例です。\n\n\n\n\n\n\n\n\n# A tibble: 2 × 2\n  in_circle     N\n  <chr>     <int>\n1 円内       3919\n2 円外       1081\n\n\n　円内の点は3919個、円外の点は1081ですね。この結果から円周率を計算してみましょう。\n\n3919 / 5000 * 4\n\n[1] 3.1352\n\n\n　より実際の円周率に近い値が得られました。"
  },
  {
    "objectID": "monte.html#RN4Esec-monte-bootstrap",
    "href": "monte.html#RN4Esec-monte-bootstrap",
    "title": "29  モンテカルロ・シミュレーション",
    "section": "\n29.6 例4: ブートストラップ法",
    "text": "29.6 例4: ブートストラップ法\n　最後に、様々な分析から得られた統計量の不確実性を計算する方法の一つであるブートストラップ法 (bootstrapping)について説明します。たとえば、平均値の差分の検定 (t検定)差、回帰分析における標準誤差などはRのt.test()、lm()関数を使用すれば瞬時に計算できます。こちらの標準誤差はデータを与えられれば、常に同じ値が得られるもので、何らかの計算式があります。しかし、世の中にはモデルが複雑すぎて、統計量の標準誤差がうまく計算できないケースもあります。そこで登場するのがブートストラップ法を用いると、不確実性の近似値が得られます。ブートストラップ法は Efron (1979) が提案した以来、データ分析において広く使われています。ブートストラップ法については優れた教科書が多くあるので詳細な説明は割愛し、以下ではブートストラップ法の簡単な例を紹介します。\n　ブートストラップにおいて重要なのは元のデータセットのサンプルサイズを\\(n\\)とした場合、復元抽出を用いてサンプルサイズ\\(n\\)のデータセットをもう一度構築することです。そしてその平均値を計算します。これらの手順を5000回繰り返せば、5000個の平均値が得られます。この5000個の平均値の平均値は元のデータセットの平均値に近似し、5000個の平均値の標準偏差は元のデータセットの平均値の標準誤差 (標準誤差)に近似できます。これは本当でしょうか。実際にやってみましょう。\n　まずは、長さ100のベクトルを2つ作成します。この2つのベクトルは平均値が0.7、0.9、標準偏差1の正規分布に従うとします。\n\\[\n\\begin{aligned}\n\\mbox{Data1} & \\sim \\mbox{Normal}(\\mu = 0.7, \\sigma = 1) \\\\\n\\mbox{Data2} & \\sim \\mbox{Normal}(\\mu = 0.9, \\sigma = 1)\n\\end{aligned}\n\\]\n　2つの標本の平均値の差分は約0.2です。この差分の不確実性はいくらでしょうか。ここでは主に使われる平均値の差の検定 (\\(t\\)検定)をやってみましょう。回は標準誤差が同じ2つの分布から得られた標本であるため、等分散を仮定する\\(t\\)検定を行います (var.equal = TRUEを追加)。\n\nset.seed(19861009)\nData1 <- rnorm(100, 0.7, 1)\nData2 <- rnorm(100, 0.9, 1)\n\nttest_result <- t.test(Data1, Data2, var.equal = TRUE)\n\nttest_result\n\n\n    Two Sample t-test\n\ndata:  Data1 and Data2\nt = -2.1707, df = 198, p-value = 0.03114\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.58521800 -0.02807095\nsample estimates:\nmean of x mean of y \n0.6912143 0.9978588 \n\n\n平均値の差分の不確実性 (=標準誤差)はttest_result$stderrで抽出可能であり、今回は約0.141です。標準誤差の値さえ分かれば、検定統計量も、信頼区間も、\\(p\\)値も計算できるため、重要なのはやはり標準誤差でしょう。以下では試行回数は1万のブートストラップ法で標準誤差の近似値を計算してみます。\n\n結果を格納する長さ1万の空ベクトルResult_vecを作成する。\n\niの初期値を1と設定する。\n\nData1から100個 (= Data1の大きさ)の値を無作為抽出 (復元抽出)し、Sample1に格納する。\n\nData2から100個 (= Data2の大きさ)の値を無作為抽出 (復元抽出)し、Sample2に格納する。\n\nResult_vecのi番目の位置にSample1の平均値とSample2の平均値の差分を格納する。\n\niを1増加させる。\n3~6の手順を1万回繰り返す。\n\n\nn_trials   <- 10000\nResult_vec <- rep(NA, n_trials)\n\nfor (i in 1:n_trials) {\n    Sample1 <- sample(Data1, 100, replace = TRUE)\n    Sample2 <- sample(Data2, 100, replace = TRUE)\n    \n    Result_vec[i] <- mean(Sample1) - mean(Sample2)\n}\n\n　Result_vecには平均値の差分が10000個格納されており、これらの値の平均値をブートストラップ推定量 (bootstrap estimate)と呼ぶとします。\n\n# 元のデータの平均値の差分\ndelta <- mean(Data1) - mean(Data2)\ndelta\n\n[1] -0.3066445\n\n# ブートストラップ推定量 (平均値の差分の平均値)\nboot_delta <- mean(Result_vec)\nboot_delta\n\n[1] -0.3045563\n\n# ブートストラップ推定量のバイアス\nboot_b <- delta - boot_delta\n\n　実際の平均値の差分 (\\(\\delta_0\\)) は-0.3066445、ブートストラップ推定量 (\\(\\delta^*\\)) は -0.3045563であるため、その差は-0.0020881です。これをブートストラップ推定量のバイアス (\\(b\\)) と呼びます。\n　ただし、我々に興味があるのは平均値の差分ではありません。平均値の差分はブートストラップ法を用いなくても普通に計算できるからです。ここで重要なのは平均値の差分の不確実性、つまり標準誤差でしょう。ブートストラップ推定量の標準誤差はResult_vecの標準偏差を計算するだけで十分です。\n\nboot_se <- sd(Result_vec) # ブートストラップ推定量の標準偏差\n\n　ブートストラップ推定量の標準偏差 (\\(\\mbox{se}^*\\))は約0.14であり、t検定の結果から得られた標準誤差0.141と非常に近い値が得られました。\n　95%信頼区間を計算してみます。百分位数信頼区間 (Percentile CI)はResult_Vecの左側の領域が2.5%、右側の領域が2.5%となる区間ですので、quantile()関数で計算することができます。\n\n# 95%信頼区間\nquantile(Result_vec, c(0.025, 0.975))\n\n       2.5%       97.5% \n-0.58084484 -0.02999534 \n\n\n　バイアスを補正しないWald信頼区間は\\(\\delta_0 \\pm 1.96 \\times \\mbox{se}^*\\)のように計算します (1.96は標準正規分布の累積密度分布において下側領域が0.975となる点です。)。\n\ndelta + qnorm(c(0.025, 0.975)) * boot_se\n\n[1] -0.58201710 -0.03127185\n\n\n　バイアス修正Wald信頼区間は\\((\\delta_0 - b) \\pm 1.96 \\times \\mbox{se}^*\\)です。\n\n(delta - boot_b) + qnorm(c(0.025, 0.975)) * boot_se\n\n[1] -0.57992897 -0.02918372\n\n\n　これまでの結果を比較してみましょう。\n\n\n\n\n\n  \n    t検定 \n    ブートストラップ \n  \n\n\n (1): 平均値の差分 \n    -0.307 \n    -0.305 \n  \n\n (2): 標準誤差 \n    0.141 \n    0.14 \n  \n\n (3): 95%信頼区間 \n    [-0.585, -0.028] \n     \n  \n\n (4): 95%信頼区間 (百分位数) \n     \n    [-0.581, -0.03] \n  \n\n (5): 95%信頼区間 (Wald) \n     \n    [-0.582, -0.031] \n  \n\n (6): 95%信頼区間 (バイアス修正Wald) \n     \n    [-0.58, -0.029] \n  \n\n\n\n\n　今回の例はt.test()関数を使えば一発で終わる問題ですが、モデルが複雑になれば推定量の不確実性の計算が難しくなるケースがあります。その時に力を発揮するのがブートストラップ方であり、{boot}、{bootstrap}、{simpleboot}など様々なパッケージが利用可能です。\n\n私たちのR 私たちのR 30  スクレイピング 28  オブジェクト指向プログラミング 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 29  モンテカルロ・シミュレーション 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR\n\n\n\nEfron, Bradley. 1979. “Bootstrap Methods: Another Look at the Jackknife.” The Annals of Statistics 7: 1–26."
  },
  {
    "objectID": "scraping.html",
    "href": "scraping.html",
    "title": "30  スクレイピング",
    "section": "",
    "text": "{rvest}の使い方\n\n私たちのR 私たちのR 31  API 29  モンテカルロ・シミュレーション 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 30  スクレイピング 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "api.html",
    "href": "api.html",
    "title": "31  API",
    "section": "",
    "text": "私たちのR 私たちのR R Tips 30  スクレイピング 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 31  API 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "tips.html#RN4Etrue-と-false",
    "href": "tips.html#RN4Etrue-と-false",
    "title": "R Tips",
    "section": "\nTRUE と FALSE\n",
    "text": "TRUE と FALSE\n\nR で真を表す TRUE と 偽を表す FALSE は頻繁に利用する。\nたとえば、行列を作るときに、brrow に TRUE を与えるか、FALSE を与えるかで、結果が変わる。\n\nmatrix(1:9, nrow = 3, byrow = FALSE)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\nmatrix(1:9, nrow = 3, byrow = TRUE)\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n\nTRUE と FALSE は、それぞれ省略して T と F をも書ける。 頻繁に使うので、このような書き方は一見すると便利である。\n\nmatrix(1:9, nrow = 3, byrow = F)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\nmatrix(1:9, nrow = 3, byrow = T)\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n\nしかし、省略形を使うべきではない。省略形を使うと、次のような問題が起こりうる。\n\nT <- FALSE\nmatrix(1:9, nrow = 3, byrow = T)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\nこの例では、T に FALSE を代入した結果、T が偽になっており、byrow = T が bryow = FALSE として処理されている。\n上の書き方では、T が TRUE を意図しているのか、それとも FALSE を意図しているのか、見分けるのが困難である。\nタイプする文字数が少し増えるが、コードの可読性と保守性が高めるために、TRUE と FALSE は常に完全にスペルすべきだ。\n\n私たちのR 私たちのR 本書の執筆環境 31  API 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - R Tips 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "session.html",
    "href": "session.html",
    "title": "本書の執筆環境",
    "section": "",
    "text": "セッション情報\n\nsessionInfo()\n\nR version 4.2.1 (2022-06-23)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.30     jsonlite_1.8.3    magrittr_2.0.3    evaluate_0.18    \n [5] rlang_1.0.6       stringi_1.7.8     cli_3.4.1         rstudioapi_0.14  \n [9] ragg_1.2.4        rmarkdown_2.17    textshaping_0.3.6 tools_4.2.1      \n[13] stringr_1.4.1     htmlwidgets_1.5.4 xfun_0.34         yaml_2.3.6       \n[17] fastmap_1.1.0     compiler_4.2.1    systemfonts_1.0.4 htmltools_0.5.3  \n[21] knitr_1.40       \n\n\nインストール済みパッケージ\n\npacman::p_load(tidyverse)\ninstalled.packages() %>%\n  as_tibble() %>%\n  select(Package, Version, Built) %>%\n  print(n = Inf)\n\n# A tibble: 465 × 3\n    Package            Version    Built\n    <chr>              <chr>      <chr>\n  1 abind              1.4-5      4.2.0\n  2 AER                1.2-10     4.2.0\n  3 aod                1.3.2      4.2.0\n  4 arm                1.13-1     4.2.0\n  5 AsioHeaders        1.22.1-1   4.2.0\n  6 askpass            1.1        4.2.0\n  7 assertthat         0.2.1      4.2.0\n  8 attempt            0.3.1      4.2.0\n  9 backports          1.4.1      4.2.0\n 10 BalanceR           0.7.7      4.2.1\n 11 base               4.2.1      4.2.1\n 12 base64enc          0.1-3      4.2.0\n 13 bayestestR         0.13.0     4.2.0\n 14 beautifyR          0.3.1      4.2.0\n 15 BH                 1.78.0-0   4.2.0\n 16 bibtex             0.5.0      4.2.0\n 17 bit                4.0.4      4.2.0\n 18 bit64              4.0.5      4.2.0\n 19 bitops             1.0-7      4.2.0\n 20 blob               1.2.3      4.2.0\n 21 blogdown           1.15       4.2.1\n 22 bookdown           0.29       4.2.0\n 23 Boom               0.9.11     4.2.0\n 24 BoomSpikeSlab      1.2.5      4.2.0\n 25 boot               1.3-28     4.2.1\n 26 brew               1.0-8      4.2.0\n 27 brio               1.1.3      4.2.0\n 28 broom              1.0.1      4.2.0\n 29 broom.helpers      1.9.0      4.2.0\n 30 bslib              0.4.1      4.2.1\n 31 bsts               0.9.9      4.2.1\n 32 cachem             1.0.6      4.2.0\n 33 callr              3.7.3      4.2.1\n 34 car                3.1-1      4.2.0\n 35 carData            3.0-5      4.2.0\n 36 CausalImpact       1.2.7      4.2.0\n 37 cellranger         1.1.0      4.2.0\n 38 checkmate          2.1.0      4.2.0\n 39 chromote           0.1.1      4.2.0\n 40 cjoint             2.1.0      4.2.0\n 41 class              7.3-20     4.2.1\n 42 classInt           0.4-8      4.2.0\n 43 cli                3.4.1      4.2.0\n 44 clipr              0.8.0      4.2.0\n 45 cluster            2.1.4      4.2.0\n 46 cobalt             4.4.1      4.2.1\n 47 coda               0.19-4     4.2.0\n 48 codetools          0.2-18     4.2.1\n 49 collections        0.3.6      4.2.0\n 50 colorspace         2.0-3      4.2.0\n 51 colourpicker       1.2.0      4.2.0\n 52 commonmark         1.8.1      4.2.0\n 53 compiler           4.2.1      4.2.1\n 54 config             0.3.1      4.2.0\n 55 corpcor            1.6.10     4.2.0\n 56 corrplot           0.92       4.2.0\n 57 countrycode        1.4.0      4.2.0\n 58 cowplot            1.1.1      4.2.0\n 59 cpp11              0.4.3      4.2.0\n 60 cranlogs           2.1.1      4.2.0\n 61 crayon             1.5.2      4.2.0\n 62 credentials        1.3.2      4.2.0\n 63 cregg              0.4.0      4.2.0\n 64 crosstalk          1.2.0      4.2.0\n 65 crul               1.3        4.2.0\n 66 cshapes            2.0        4.2.0\n 67 curl               4.3.3      4.2.0\n 68 cyclocomp          1.1.0      4.2.0\n 69 dagitty            0.3-1      4.2.0\n 70 data.table         1.14.4     4.2.1\n 71 data.tree          1.0.0      4.2.0\n 72 DataCombine        0.2.21     4.2.0\n 73 datasets           4.2.1      4.2.1\n 74 datawizard         0.6.3      4.2.0\n 75 DBI                1.1.3      4.2.0\n 76 dbplyr             2.2.1      4.2.0\n 77 dcurver            0.9.2      4.2.0\n 78 deldir             1.0-6      4.2.0\n 79 democracyData      0.3.0      4.2.0\n 80 dendextend         1.16.0     4.2.0\n 81 Deriv              4.1.3      4.2.0\n 82 desc               1.4.2      4.2.0\n 83 devtools           2.4.5      4.2.0\n 84 diffobj            0.3.5      4.2.0\n 85 digest             0.6.30     4.2.1\n 86 doMC               1.3.8      4.2.0\n 87 doParallel         1.0.17     4.2.0\n 88 doRNG              1.8.2      4.2.0\n 89 downlit            0.4.2      4.2.0\n 90 dplyr              1.0.10     4.2.0\n 91 DT                 0.26       4.2.1\n 92 dtplyr             1.2.2      4.2.0\n 93 e1071              1.7-12     4.2.1\n 94 ellipsis           0.3.2      4.2.0\n 95 estimatr           1.0.0      4.2.0\n 96 evaluate           0.18       4.2.1\n 97 extrafont          0.18       4.2.0\n 98 extrafontdb        1.0        4.2.0\n 99 fansi              1.0.3      4.2.0\n100 farver             2.1.1      4.2.1\n101 fastDummies        1.6.3      4.2.0\n102 fastmap            1.1.0      4.2.0\n103 FNN                1.1.3.1    4.2.0\n104 fontawesome        0.4.0      4.2.0\n105 forcats            0.5.2      4.2.0\n106 foreach            1.5.2      4.2.0\n107 foreign            0.8-83     4.2.0\n108 formatR            1.12       4.2.0\n109 formattable        0.2.1      4.2.0\n110 Formula            1.2-4      4.2.0\n111 fs                 1.5.2      4.2.0\n112 future             1.29.0     4.2.0\n113 fuzzyjoin          0.1.6      4.2.0\n114 gamlss.dist        6.0-5      4.2.0\n115 gapminder          0.3.0      4.2.0\n116 gargle             1.2.1      4.2.0\n117 gdtools            0.2.4      4.2.0\n118 generics           0.1.3      4.2.1\n119 geojson            0.3.4      4.2.0\n120 geojsonio          0.10.0     4.2.0\n121 geojsonlint        0.4.0      4.2.0\n122 geojsonsf          2.0.3      4.2.0\n123 geometries         0.2.0      4.2.0\n124 geosphere          1.5-14     4.2.0\n125 gert               1.9.1      4.2.0\n126 ggalluvial         0.12.3     4.2.0\n127 GGally             2.1.2      4.2.0\n128 gganimate          1.0.8      4.2.0\n129 ggbump             0.1.0      4.2.0\n130 ggdag              0.2.7      4.2.0\n131 ggdendro           0.1.23     4.2.0\n132 ggExtra            0.10.0     4.2.0\n133 ggfittext          0.9.1      4.2.0\n134 ggforce            0.4.1      4.2.0\n135 ggh4x              0.2.2      4.2.0\n136 gghighlight        0.4.0      4.2.0\n137 ggmosaic           0.3.3      4.2.0\n138 ggplot2            3.4.0      4.2.0\n139 ggpubr             0.4.0      4.2.0\n140 ggraph             2.1.0      4.2.1\n141 ggrepel            0.9.2      4.2.0\n142 ggridges           0.5.4      4.2.1\n143 ggsci              2.9        4.2.0\n144 ggsignif           0.6.4      4.2.0\n145 ggstance           0.3.5      4.2.0\n146 gh                 1.3.1      4.2.0\n147 ghibli             0.3.3      4.2.0\n148 gitcreds           0.1.2      4.2.0\n149 globals            0.16.1     4.2.0\n150 glue               1.6.2      4.2.0\n151 golem              0.3.5      4.2.1\n152 googledrive        2.0.0      4.2.0\n153 googlePolylines    0.8.2      4.2.0\n154 googlesheets4      1.0.1      4.2.0\n155 GPArotation        2022.10-2  4.2.0\n156 graphics           4.2.1      4.2.1\n157 graphlayouts       0.8.3      4.2.0\n158 grDevices          4.2.1      4.2.1\n159 grid               4.2.1      4.2.1\n160 gridExtra          2.3        4.2.0\n161 gsynth             1.2.1      4.2.0\n162 gt                 0.7.0      4.2.0\n163 gtable             0.3.1      4.2.0\n164 gtsummary          1.6.2      4.2.0\n165 haven              2.5.1      4.2.0\n166 here               1.0.1      4.2.0\n167 highr              0.9        4.2.0\n168 Hmisc              4.7-1      4.2.0\n169 hms                1.1.2      4.2.0\n170 hrbrthemes         0.8.0      4.2.0\n171 htmlTable          2.4.1      4.2.0\n172 htmltools          0.5.3      4.2.0\n173 htmlwidgets        1.5.4      4.2.0\n174 httpcode           0.3.0      4.2.0\n175 httpuv             1.6.6      4.2.0\n176 httr               1.4.4      4.2.0\n177 icons              0.2.0      4.2.0\n178 ids                1.0.1      4.2.0\n179 igraph             1.3.5      4.2.0\n180 ini                0.3.1      4.2.0\n181 inline             0.3.19     4.2.0\n182 insight            0.18.6     4.2.1\n183 interp             1.1-3      4.2.0\n184 isoband            0.2.6      4.2.0\n185 ISOcodes           2022.09.29 4.2.0\n186 iterators          1.0.14     4.2.0\n187 jpeg               0.1-9      4.2.0\n188 jpmesh             2.1.0      4.2.0\n189 jpndistrict        0.3.9.9000 4.2.0\n190 jqr                1.2.3      4.2.0\n191 jquerylib          0.1.4      4.2.0\n192 jsonify            1.2.1      4.2.0\n193 jsonlite           1.8.3      4.2.0\n194 jsonvalidate       1.3.2      4.2.0\n195 kableExtra         1.3.4      4.2.0\n196 keras              2.9.0      4.2.0\n197 kernlab            0.9-31     4.2.0\n198 KernSmooth         2.23-20    4.2.1\n199 knitr              1.40       4.2.0\n200 labeling           0.4.2      4.2.0\n201 labelled           2.10.0     4.2.0\n202 languageserver     0.3.14     4.2.0\n203 later              1.3.0      4.2.0\n204 latex2exp          0.9.5      4.2.1\n205 lattice            0.20-45    4.2.1\n206 latticeExtra       0.6-30     4.2.0\n207 lazyeval           0.2.2      4.2.0\n208 leaflet            2.1.1      4.2.0\n209 leaflet.providers  1.9.0      4.2.0\n210 learnr             0.11.2     4.2.1\n211 lfe                2.8-8      4.2.0\n212 lifecycle          1.0.3      4.2.0\n213 lintr              3.0.2      4.2.0\n214 list               9.2.4      4.2.0\n215 listenv            0.8.0      4.2.0\n216 lme4               1.1-31     4.2.1\n217 lmtest             0.9-40     4.2.0\n218 lobstr             1.1.2      4.2.0\n219 loo                2.5.1      4.2.0\n220 LowRankQP          1.0.5      4.2.0\n221 lpdensity          2.3.1      4.2.0\n222 lubridate          1.9.0      4.2.0\n223 magic              1.6-0      4.2.0\n224 magick             2.7.3      4.2.0\n225 magrittr           2.0.3      4.2.0\n226 maptools           1.1-5      4.2.0\n227 margins            0.3.26     4.2.0\n228 markdown           1.3        4.2.0\n229 MASS               7.3-58.1   4.2.0\n230 MatchIt            4.4.0      4.2.0\n231 Matrix             1.5-1      4.2.0\n232 MatrixModels       0.5-1      4.2.1\n233 matrixStats        0.62.0     4.2.0\n234 memoise            2.0.1      4.2.0\n235 metathis           1.1.2      4.2.0\n236 methods            4.2.1      4.2.1\n237 mgcv               1.8-41     4.2.0\n238 mime               0.12       4.2.0\n239 miniUI             0.1.1.1    4.2.0\n240 minqa              1.2.5      4.2.0\n241 mirt               1.37.1     4.2.1\n242 mitools            2.4        4.2.0\n243 modelr             0.1.9      4.2.0\n244 modelsummary       1.1.0      4.2.0\n245 munsell            0.5.0      4.2.0\n246 mvtnorm            1.1-3      4.2.0\n247 naniar             0.6.1      4.2.0\n248 nlme               3.1-160    4.2.0\n249 nloptr             2.0.3      4.2.0\n250 nnet               7.3-18     4.2.0\n251 norm               1.0-10.0   4.2.0\n252 numDeriv           2016.8-1.1 4.2.0\n253 openssl            2.0.4      4.2.1\n254 openxlsx           4.2.5.1    4.2.1\n255 optimx             2022-4.30  4.2.0\n256 packageRank        0.7.2      4.2.0\n257 packrat            0.8.1      4.2.0\n258 pacman             0.5.1      4.2.0\n259 pagedown           0.19       4.2.1\n260 pander             0.6.5      4.2.0\n261 panelView          1.1.11     4.2.0\n262 parallel           4.2.1      4.2.1\n263 parallelly         1.32.1     4.2.0\n264 parameters         0.19.0     4.2.0\n265 parsedate          1.3.1      4.2.0\n266 pbapply            1.5-0      4.2.0\n267 pbkrtest           0.5.1      4.2.0\n268 performance        0.10.0     4.2.0\n269 permute            0.9-7      4.2.0\n270 pillar             1.8.1      4.2.0\n271 pkgbuild           1.3.1      4.2.0\n272 pkgconfig          2.0.3      4.2.0\n273 pkgdown            2.0.6      4.2.0\n274 pkgload            1.3.1      4.2.0\n275 pkgsearch          3.1.2      4.2.0\n276 plotly             4.10.1     4.2.1\n277 plyr               1.8.7      4.2.0\n278 png                0.1-7      4.2.0\n279 polyclip           1.10-4     4.2.0\n280 polynom            1.4-1      4.2.0\n281 ppcor              1.1        4.2.0\n282 praise             1.0.0      4.2.0\n283 PRcalc             0.7.0      4.2.0\n284 prediction         0.3.14     4.2.0\n285 prettyunits        1.1.1      4.2.0\n286 prismatic          1.1.1      4.2.0\n287 processx           3.8.0      4.2.0\n288 productplots       0.1.1      4.2.0\n289 profvis            0.3.7      4.2.0\n290 progress           1.2.2      4.2.0\n291 promises           1.2.0.1    4.2.0\n292 protolite          2.1.3      4.2.0\n293 proxy              0.4-27     4.2.0\n294 pryr               0.1.5      4.2.0\n295 ps                 1.7.2      4.2.0\n296 psData             0.2.2      4.2.0\n297 purrr              0.3.5      4.2.0\n298 q2c                0.2.0      4.2.1\n299 qrcode             0.1.4      4.2.0\n300 quadprog           1.5-8      4.2.0\n301 qualtRics          3.1.6      4.2.0\n302 quantreg           5.94       4.2.0\n303 quarto             1.2        4.2.0\n304 R.cache            0.16.0     4.2.0\n305 R.methodsS3        1.8.2      4.2.0\n306 R.oo               1.25.0     4.2.0\n307 R.utils            2.12.1     4.2.0\n308 R6                 2.5.1      4.2.0\n309 R7                 0.0.0.9000 4.2.1\n310 ragg               1.2.4      4.2.1\n311 rapidjsonr         1.2.0      4.2.0\n312 rappdirs           0.3.3      4.2.0\n313 rapportools        1.1        4.2.0\n314 raster             3.6-3      4.2.0\n315 rcmdcheck          1.4.0      4.2.0\n316 RColorBrewer       1.1-3      4.2.0\n317 Rcpp               1.0.9      4.2.0\n318 RcppArmadillo      0.11.4.0.1 4.2.0\n319 RcppEigen          0.3.3.9.3  4.2.0\n320 RcppParallel       5.1.5      4.2.0\n321 RcppProgress       0.4.2      4.2.0\n322 RcppTOML           0.1.7      4.2.0\n323 RCurl              1.98-1.9   4.2.0\n324 rdd                0.57       4.2.0\n325 rddensity          2.2        4.2.0\n326 rdrobust           2.1.0      4.2.0\n327 readr              2.1.3      4.2.0\n328 readxl             1.4.1      4.2.0\n329 RefManageR         1.4.0      4.2.0\n330 rematch            1.0.1      4.2.0\n331 rematch2           2.1.2      4.2.0\n332 remotes            2.4.2      4.2.0\n333 renv               0.16.0     4.2.0\n334 reprex             2.0.2      4.2.0\n335 reshape            0.8.9      4.2.0\n336 reshape2           1.4.4      4.2.0\n337 reticulate         1.26       4.2.0\n338 rex                1.2.1      4.2.0\n339 rgenoud            5.9-0.3    4.2.0\n340 rgeos              0.5-9      4.2.0\n341 rio                0.5.29     4.2.0\n342 rJava              1.0-6      4.2.0\n343 rlang              1.0.6      4.2.0\n344 rmapshaper         0.4.6      4.2.0\n345 rmarkdown          2.17       4.2.0\n346 rmdja              0.4.6.9    4.2.0\n347 rnaturalearth      0.1.0      4.2.0\n348 rnaturalearthdata  0.1.0      4.2.0\n349 rnaturalearthhires 0.2.0      4.2.0\n350 rngtools           1.5.2      4.2.0\n351 roxygen2           7.2.1      4.2.0\n352 rpart              4.1.19     4.2.0\n353 rprojroot          2.0.3      4.2.0\n354 rqog               0.4.2022   4.2.0\n355 rsconnect          0.8.28     4.2.1\n356 rstan              2.21.7     4.2.0\n357 rstatix            0.7.0      4.2.0\n358 rstudioapi         0.14       4.2.0\n359 Rttf2pt1           1.3.11     4.2.1\n360 rversions          2.1.2      4.2.0\n361 rvest              1.0.3      4.2.0\n362 s2                 1.1.0      4.2.0\n363 sandwich           3.0-2      4.2.0\n364 sass               0.4.2      4.2.0\n365 scales             1.2.1      4.2.0\n366 selectr            0.4-2      4.2.0\n367 servr              0.25       4.2.0\n368 sessioninfo        1.2.2      4.2.0\n369 sf                 1.0-9      4.2.1\n370 sfheaders          0.4.0      4.2.0\n371 shades             1.4.0      4.2.0\n372 shiny              1.7.3      4.2.0\n373 shiny.i18n         0.2.0      4.2.0\n374 shinyBS            0.61.1     4.2.0\n375 shinyjs            2.1.0      4.2.0\n376 SimpleConjoint     0.1.1      4.2.0\n377 sjlabelled         1.2.0      4.2.0\n378 sourcetools        0.1.7      4.2.0\n379 sp                 1.5-1      4.2.1\n380 SparseM            1.81       4.2.0\n381 spatial            7.3-15     4.2.1\n382 splines            4.2.1      4.2.1\n383 StanHeaders        2.21.0-7   4.2.0\n384 stargazer          5.2.3      4.2.0\n385 stats              4.2.1      4.2.1\n386 stats4             4.2.1      4.2.1\n387 stringdist         0.9.10     4.2.1\n388 stringi            1.7.8      4.2.0\n389 stringr            1.4.1      4.2.0\n390 styler             1.8.1      4.2.1\n391 sugrrants          0.2.8      4.2.0\n392 summarytools       1.0.1      4.2.0\n393 survey             4.1-1      4.2.0\n394 survival           3.4-0      4.2.1\n395 svglite            2.1.0      4.2.0\n396 Synth              1.1-6      4.2.1\n397 sys                3.4.1      4.2.1\n398 systemfonts        1.0.4      4.2.0\n399 tables             0.9.10     4.2.1\n400 tcltk              4.2.1      4.2.1\n401 tcltk2             1.2-11     4.2.0\n402 tensorflow         2.9.0      4.2.0\n403 terra              1.6-17     4.2.1\n404 testthat           3.1.5      4.2.1\n405 textshaping        0.3.6      4.2.0\n406 tfautograph        0.3.2      4.2.0\n407 tfprobability      0.15.1     4.2.0\n408 tfruns             1.5.1      4.2.0\n409 tibble             3.1.8      4.2.0\n410 tidyfast           0.2.1      4.2.0\n411 tidygraph          1.2.2      4.2.0\n412 tidyr              1.2.1      4.2.0\n413 tidyselect         1.2.0      4.2.0\n414 tidyverse          1.3.2      4.2.0\n415 timechange         0.1.1      4.2.0\n416 tinytex            0.42       4.2.0\n417 titanic            0.1.0      4.2.0\n418 tools              4.2.1      4.2.1\n419 treemapify         2.5.5      4.2.0\n420 triebeard          0.3.0      4.2.0\n421 tweenr             2.0.2      4.2.0\n422 tzdb               0.3.0      4.2.0\n423 units              0.8-0      4.2.0\n424 UpSetR             1.4.0      4.2.0\n425 urlchecker         1.0.1      4.2.0\n426 urlshorteneR       1.5.7      4.2.0\n427 urltools           1.7.3      4.2.0\n428 usethis            2.1.6      4.2.0\n429 usmap              0.6.0      4.2.0\n430 usmapdata          0.1.0      4.2.0\n431 utf8               1.2.2      4.2.0\n432 utils              4.2.1      4.2.1\n433 uuid               1.1-0      4.2.0\n434 V8                 4.2.2      4.2.1\n435 vctrs              0.5.0      4.2.0\n436 vdemdata           3.0        4.2.0\n437 vegan              2.6-4      4.2.0\n438 VGAM               1.1-7      4.2.1\n439 viridis            0.6.2      4.2.0\n440 viridisLite        0.4.1      4.2.0\n441 visdat             0.5.3      4.2.0\n442 vroom              1.6.0      4.2.0\n443 waldo              0.4.0      4.2.0\n444 webshot            0.5.4      4.2.1\n445 websocket          1.4.1      4.2.0\n446 WeightIt           0.13.1     4.2.0\n447 whisker            0.4        4.2.0\n448 withr              2.5.0      4.2.0\n449 wk                 0.7.0      4.2.0\n450 woRdle             0.0.1      4.2.0\n451 xaringan           0.27       4.2.1\n452 xaringanBuilder    0.0.9      4.2.0\n453 xaringanExtra      0.7.0      4.2.0\n454 xfun               0.34       4.2.1\n455 xlsx               0.6.5      4.2.0\n456 xlsxjars           0.6.1      4.2.0\n457 xml2               1.3.3      4.2.0\n458 xmlparsedata       1.0.5      4.2.0\n459 xopen              1.0.0      4.2.0\n460 xtable             1.8-4      4.2.0\n461 xts                0.12.2     4.2.0\n462 yaml               2.3.6      4.2.1\n463 zeallot            0.1.0      4.2.0\n464 zip                2.2.2      4.2.0\n465 zoo                1.8-11     4.2.0\n\n\n\n私たちのR 私たちのR 参考文献 R Tips 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 本書の執筆環境 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "参考文献",
    "section": "",
    "text": "私たちのR 私たちのR 本書の執筆環境 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 参考文献 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR\n\n\n\n\nCattaneo, Matias D., Brigham R. Frandsen, and Rocío Titiunik. 2015.\n“Randomization Inference in the Regression Discontinuity Design:\nAn Application to the Study of Party Advantages in the u.s.\nSenate.” Journal of Causal Inference 3: 1–24.\n\n\nChambers, John M. 2016. Extending r. Boca Raton, FL: CRC Press.\n\n\nEfron, Bradley. 1979. “Bootstrap Methods: Another Look at the\nJackknife.” The Annals of Statistics 7: 1–26.\n\n\nGrolemund, Garrett, and Hadley Wickham. 2016. R for Data\nScience. O’Reilly.\n\n\nHartigan, J. A., and Beat Kleiner. 1984. “A Mosaic of Television\nRatings.” The American Statistician 38: 32–35.\n\n\nHeer, Jeffrey, and Michael Bostock. 2010. “Crowdsourcing Graphical\nPerception: Using Mechanical Turk to Assess Visualization\nDesign.” Proceedings of the SIGCHI Conference on Human\nFactors in Computing Systems.\n\n\nImbens, Guido, and Karthik Kalyanaraman. 2012. “Optimal Bandwidth\nChoice for the Regression Discontinuity Estimator.” The\nReview of Economic Studies 79: 933–59.\n\n\nInbar, Ohad, Noam Tractinsky, and Joachim Meyer. 2007. “Minimalism\nin Information Visualization: Attitudes Towards Maximizing the Data-Ink\nRatio.” In ECCE ’07: Proceedings of the 14th European\nConference on Cognitive Ergonomics: Invent! Explore!, 185–88.\n\n\nKuznicki, James T., and N. Bruce McCutcheon. 1979.\n“Cross-Enhancement of the Sour Taste on Single Human Taste\nPapillae.” Journal of Experimental Psychology: General\n108: 68–89.\n\n\nTufte, Edward R. 2001. The Visual Display of Quantitative\nInformation (2nd Ed.). Graphics Press.\n\n\nWickham, Hadley. 2014. “Tidy Data.” Journal of\nStatistical Software 59.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. Springer."
  },
  {
    "objectID": "ide.html#RN4Esec-ide-intro",
    "href": "ide.html#RN4Esec-ide-intro",
    "title": "3  IDEの導入",
    "section": "\n3.1 IDE",
    "text": "3.1 IDE\n　プログラミングは基本的にコードを書く作業の連続だが、コードを書く他にも様々な作業を行うことになる。たとえば、自分が書いたコードの結果が正しく動作するかの確認作業や、なにか問題がある場合の対処（デバッグ）などがある。また、コードを書く際、誤字やミスなどがないかも確認する必要がある。他にもプログラムで使用されるファイルを管理しなければならない。これらの仕事を手助けしてくれるのが統合開発環境 (integrated development environment; IDE) と呼ばれるものである。\n　プログラマにとって優れたIDEを使うということは、優れた秘書を雇用するようなものだ。ファイルの管理、うろ覚えのコマンドの補完入力、コードの色分けなどを自動的に行ってくれる。さらに、コードの実行結果の画面をコードと同時に表示してくれたり、これまでの作業を記録してくれるなど、多くの作業を手助けしてくれる。Rにはいくつかの優れたIDEが用意されている。本書では代表的なIDEである RStudio を使うことにする。ただし、プログラミングにIDEは必須ではない。IDEをインストールしなくても、本書を読む上で特に問題はない（RStudioに関する説明の部分を除く）が、Rの実行環境に特にこだわりがないなら RStudioの導入を強く推奨する。\n\n\n\n\n図 3.1: RStudio\n\n\n\n\n　RStudio以外にもRのIDEはある。魔界において圧倒的なシェアを誇ると噂されるWindowsという名のOSを使用しているなら、R Tools for Visual Studio がRStudioの代替候補として有力だ。\n\n\n\n\n図 3.2: R Tools for Visual Studio\n\n\n\n\n　自分が使い慣れたテキストエディタをIDEとして使うことも可能である。Sublime Text や Atom はむろん、伝統のある Emacs や Vim を使うこともできる。"
  },
  {
    "objectID": "ide.html#RN4Eide-install",
    "href": "ide.html#RN4Eide-install",
    "title": "3  IDEの導入",
    "section": "\n3.2 RStudioのインストールと起動",
    "text": "3.2 RStudioのインストールと起動\n\n3.2.1 macOSの場合\nポチポチ、ドラッグ・アンド・ドロップ\n\n3.2.2 Linux (Ubuntu)の場合\nダウンロードしたバージョン (例えば、最新バージョン) が分かっていれば、ターミナルでwgetコマンドで直接ダウンロード\nたとえば、~/Downloadsフォルダーに2020.02.0-443バージョンをダウンロードする場合は\n$ cd ~/Downloads/\n$ wget https://download1.rstudio.org/desktop/bionic/amd64/rstudio-2022.02.0-443-amd64.deb\n分からない場合は、RStudioのホームページの「All Installer」のリストから「Ubuntu 18+/Debian 10+」用の.debファイルをダウンロード\n.debファイルのインストールは、ターミナルを使って~/Downloadフォルダー内のrstudio-2022.02.0-443-amd64.debファイルをインストールするなら…\n$ cd ~/Downloads/\n$ sudo gdebi rstudio-2022.02.0-443-amd64.deb\ngdebiがインストール済みならnautilus (Linux MintならNemo?)で.debファイルをダブルクリックしてインストール可能\n\n3.2.3 Windowsの場合\nポチポチ\n\n私たちのR 私たちのR 4  分析環境のカスタマイズ 2  Rのインストール 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 3  IDEの導入 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "r_customize.html#RN4ECustomize-rprofile",
    "href": "r_customize.html#RN4ECustomize-rprofile",
    "title": "4  分析環境のカスタマイズ",
    "section": "\n4.1 .Rprofileの設定",
    "text": "4.1 .Rprofileの設定"
  },
  {
    "objectID": "r_customize.html#RN4ECustomize-rstudio",
    "href": "r_customize.html#RN4ECustomize-rstudio",
    "title": "4  分析環境のカスタマイズ",
    "section": "\n4.2 RStudioのカスタマイズ",
    "text": "4.2 RStudioのカスタマイズ\n以下の設定はRStudio 2022.02.0+442 (Prairie Trillium)の設定\n\nTools > Global Options\nGeneral\n\nBasicタブ\n\nRestore .RData into workspace at startupのチェックを消す。\nSave workspace to .RData on exit:をNeverに変更する。\nAlways save history (even when not saving .RData)のチェックを消す。\n\n\n\n\nCode\n\nEditingタブ\n\nInsert spaces for tabのチェックを付ける。\n\nTab widthは2か4\n\n\nAuto-detect code indentationのチェックを付ける。\nInsert matching parens/quotesのチェックを付ける。\nAuto-indent code after pasteのチェックを付ける。\nVertically align arguments in auto-indentのチェックを付ける。\nAlways save R scripts before sourcingのチェックを付ける。\nCtrl + Return executes:をMulti-line R statementに変更する。\n\n\nDisplayタブ\n\nHighlight selected wordのチェックを付ける。\nHighlight selected lineのチェックを付ける。\nShow line numbersのチェックを付ける。\nShow syntax highlighting in console inputのチェックを付ける。\nHighlight R function callsのチェックを付ける。\nRainbow parenthesesのチェックを付ける。\n\n\nSavingタブ\n\nDefault text encoding:のChangeをクリックし、UTF-8を選択する。\n\n\nCompletionタブ\n\nShow code completion:をAutomaticallyに変更する。\nAllow automatic completions in consoleのチェックを付ける。\nInsert parentheses after function completionsのチェックを付ける。\nShow help tooltip after function completionsのチェックを付ける。\nInsert spaces around equals for argument completionsのチェックを付ける。\nUse tab for autocompletionのチェックを付ける。\n\n\n\n\nAppearance\n\n自分の好みのものを選択する。\n\n\nPane Layout\n\n左上: Source\n右上: Console\n左下: 全てチェックを消す。\n左下: 全てチェックを付ける。\n\n\nR Markdown\n\nBasicタブ\n\nShow output inline for all R Markdown documentsのチェックを消す。\n\n\n\n\n左下のApplyをクリック\n\n\n私たちのR 私たちのR 5  Rパッケージ 3  IDEの導入 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 4  分析環境のカスタマイズ 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "packages.html#RN4Esec-packages_intro",
    "href": "packages.html#RN4Esec-packages_intro",
    "title": "5  Rパッケージ",
    "section": "\n5.1 パッケージとは",
    "text": "5.1 パッケージとは\n　Rには様々な関数 (functions) が提供されている。平均値を求めるmean()、合計を求めるsum()、線形回帰分析を行うlm()、平均値の検定を行うt.test()などがあり、全てを列挙することはできない。しかし、データ分析の技術は日々発展し、Rがデフォルトで提供する関数では不可能ではないが、かなり長いコードが必要な分析を使わざる得ないケースもあろう。Rは開発元だけでなく、誰でも関数を作ることができる。通常なら数百行のコードが必要な分析を一行のコードで実行可能とする関数を多くのRユーザーが作ってきた。これらの関数を集めたのがパッケージである。Rにはグラフ作成に特化したパッケージ、機械学習に特化したパッケージ、テキスト分析に特化したパッケージなど、数千のパッケージが開発されている。このパッケージの豊富さがRの最大のメリットでもある。誰かが新しい分析手法を提案したら、数日内、あるいはその手法が論文として出版される前からRパッケージとして公開されるケースが多い。\n　本章ではパッケージをインストールし、読み込む方法について説明する。また、パッケージの管理をアシストするパッケージ、{pacman}の使い方についても紹介する。"
  },
  {
    "objectID": "packages.html#RN4Esec-packages_install",
    "href": "packages.html#RN4Esec-packages_install",
    "title": "5  Rパッケージ",
    "section": "\n5.2 パッケージのインストール",
    "text": "5.2 パッケージのインストール\n　Rの環境は何かを作るための作業台に似ている。作業台にはモノを作るために材料だけでなく、工具・道具セットなども置いたりもする。この作業台がRにおける「環境 (environment) 」であり、材料がベクトルや行列、データフレームなどのデータ、工具セットがパッケージになる。データについては後で説明するとし、ここではパッケージについて考えたい。\n　モノを作るためには素材・材料だけでは不十分だろう。多くの場合、なんらかの道具セットが必要となる。Rには既にいくつかの必須道具セットを用意されているが、他にも様々な道具セットがある。そして、これら道具セットには、一般的に複数の道具が含まれている。一つ一つの道具のことを、ここでは「関数 (function) 」と呼ぶ。これらの道具セットを購入し、作業台の収納に入れておくことがパッケージをインストールすることである。\n\ninstall.packages(\"パッケージ名\")\n\n　これらのパッケージは基本的にCRANというRの公式道具屋からダウンロード・インストールされる。もう一つの大きな道具屋としてはGitHubがある1。GitHubは個人経営の道具屋が集まっているモールのようなものである。GitHub道具屋を使用するためには、予めCRANから{devtools}、または{remotes}というパッケージをインストールしておく必要がある。\n　ここでは{devtools}というパッケージをインストールしてみよう。{devtools}はCRANに登録されているため、install.pcakges()関数でインストールできる。パッケージ名を\"で囲むことを忘れないこと。\n\ninstall.packages(\"devtools\")\n\n　もし、CRANに登録されていないパッケージをGitHubからインストールするなら、{devtools}パッケージ、または{remotes}のinstall_github()関数を使う。\n\n# あらかじめ{devtools}、または{remotes}をインストールしておく\n# {remotes}をインストールした場合は、remotes::install_github()を使用する\ndevtools::install_github(\"作成者のGitHubのID/パッケージ名\")\n\n　たとえば、筆者 (Song) が作成しました{BalanceR}パッケージがインストールしたいなら、以下のように打つ。\n\n# {remotes}をインストールした場合は、\n# remotes::install_github(\"JaehyunSong/BalanceR\")\ndevtools::install_github(\"JaehyunSong/BalanceR\")\n\n　ここでJaehyunSongはSongのGitHub IDであり、BalanceRはパッケージ名である。"
  },
  {
    "objectID": "packages.html#RN4Esec-packages_library",
    "href": "packages.html#RN4Esec-packages_library",
    "title": "5  Rパッケージ",
    "section": "\n5.3 パッケージの読み込み",
    "text": "5.3 パッケージの読み込み\n　先ほど述べたように、パッケージのインストールは道具セットの購入と収納に似ている。ただし、実際に道具セットを使うためには、それを自分の作業台上に載せた方が効率がいいだろう2 3。この作業がパッケージの読み込み (load) である。インストールしたパッケージを読み込むにはlibrary()またはrequire()関数を使う。require()は関数内に使う目的で設計された関数だが、パッケージを読み込むという点では全く同じである。\n\n\n\n\n図 5.1: Rパッケージと作業環境\n\n\n\n\n\nlibrary(\"パッケージ名\")\n#または\nrequire(\"パッケージ名\")\n\n　読み込まれたパッケージはセッションが開かれている時のみに有効である。一通りの作業が終わり、作業部屋から退出すると、作業台上の道具セットは収納に自動的に戻される。つまり、RまたはRStudioを閉じると読み込まれたパッケージは自動的に取り外されるということである。しかし、作業の途中に読み込んだパッケージをセッションから取り外したい時があるかも知れない。この場合、detach()関数を使う。\n\ndetach(\"パッケージ名\")"
  },
  {
    "objectID": "packages.html#RN4Esec-packages_update",
    "href": "packages.html#RN4Esec-packages_update",
    "title": "5  Rパッケージ",
    "section": "\n5.4 パッケージのアップデート",
    "text": "5.4 パッケージのアップデート\n　Rパッケージはバグが修正されたり、新しい機能 (=関数) が追加されるなど、日々更新される。できる限りパッケージは最新版に維持した方が良いだろう。パッケージのアップデートはパッケージのインストールと同じである。{dplyr}というパッケージを最新版にアップデートしたい場合、install.packages(\"dplyr\")で十分である。\n　しかし、Rを使っていくうちに数十個のパッケージをインストールしていくこととなり、一つ一つアップデートするのは面倒だろう。そもそも既に最新版が入っていて (または開発休止/中止)、アップデートが不要なパッケージがあるかも知れない。実はRStudioを使えば、アップデートが必要なパッケージのリストが表示され、一気にアップデートすることができる。RStudioのPackagesペインにある「Update」をクリックしてみれば、アップデート可能なパッケージの一覧が表示される。ここでアップデートしたいパッケージの左にチェックをするか、下段の「Select All」を選択して「Install Updates」をクリックすれば、チェックされているパッケージがアップデートされる。\n　ただし、場合によってはアップデート時、以下のようなメッセージがコンソールに表示されるかも知れない。\n  There are binary versions available but the source versions\n  are later:\n      binary source needs_compilation\nterra 1.5-17 1.5-21              TRUE\nyaml   2.2.2  2.3.4              TRUE\n\nDo you want to install from sources the packages which need compilation? (Yes/no/cancel)\n　コンソールにYes、no、cancelのいずれかを入力してReturnキー (Enterキー)を押す必要がある。どうしても最新のパッケージが欲しい場合はYesを入力すれば良いが、インストールに時間がかかる場合がある。一方、noを入力した場合は、若干古いバージョンがインストールされるが、インストールに必要な時間が短いため、基本的にはnoでも問題ないだろう。cancelを入力した場合はアップデートが全てキャンセルされる。"
  },
  {
    "objectID": "packages.html#RN4Esec-packages_pacman",
    "href": "packages.html#RN4Esec-packages_pacman",
    "title": "5  Rパッケージ",
    "section": "\n5.5 {pacman}によるパッケージ管理",
    "text": "5.5 {pacman}によるパッケージ管理\n　CRANとGitHubなどには数千のRパッケージが公開されており、Rの使用歴が長くなればインストールされているパッケージが増えたり、一つのスクリプト内で使用するパッケージも増えていくだろう。また、パッケージは他のパッケージの機能に依存することがほとんどなので、自分の想像以上の数のパッケージがインストールされているかも知れない。このように膨大な数のパッケージを管理するためのパッケージが{pacman}である。{pacman}はCRANから入手可能である。\n\ninstall.packages(\"pacman\")\n\n\n5.5.1 インストール\n　パッケージをCRANからインストールにはp_install()関数を使用する。使い方はinstall.packages()と同じであり、複数のパッケージをインストールしたい場合はパッケージ名の箇所にc(パッケージ名1, パッケージ名2, ...)を入れる。パッケージ名は\"で囲んでも、囲まなくても良い。GitHubに公開されているパッケージはp_install_gh()関数を使用する。これは{devtools}、または{remotes}のinstall_github()と同じ使い方となり、必ず\"で囲む必要がある。\n　これらの関数を使う際、わざわざlibrary(pacman)を使う必要はない。パッケージのインストールや、読み込みなどはコード内に何回も使われることがほとんどないため、{pacman}を読み込まずpacman::関数名()で当該関数を使うことができる。\n\n# CRANからインストール\npacman::p_install(パッケージ名)\n# githubからインストール\npacman::p_install_gh(\"作成者のGitHubのID/パッケージ名\") \n\n\n5.5.2 読み込み\n　パッケージの読み込みにはp_load()関数を使い、実はこの関数は{pacman}を使う最も大きな要素である。p_load()関数の使い方は以下の通りである。\n\npacman::p_load(パッケージ名)\n\n　p_load()の便利なところは (1) 複数のパッケージが指定可能であることと、 (2) インストールされていないパッケージはCRANから自動的にインストールして読み込んでくれる点だ。たとえば、{tidyverse}と{broom}、{estimatr}という3つのパッケージを読み込む場合、library()関数を使うと以下のようになる。\n\n# library() を使う場合\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(estimatr)\n\n　一方、{pacman}のp_load()を使えば、以下のように3つのパッケージを読み込むことができる。\n\n# {pacman}のp_load() を使う場合\npacman::p_load(tidyverse, broom, estimatr)\n\n　また、p_load()内のパッケージがインストールされていない場合、CRANのパッケージリストから検索し、そのパッケージをインストールしてくれる。したがって、上で紹介したp_install()は実質的に使うケースはほぼない。ただし、GitHub上のパッケージは自動的にインストールしてくれない。たとえば、GitHub上のみにて公開されている{BlanceR}パッケージがインストールされていない場合、p_load(BalanceR)を実行しても{BalanceR}はインストールされない4。あらかじめp_install_gh()でインストールしておく必要がある。\n\n5.5.3 アップデート\n　{pacman}にはアップデートが可能なパッケージを全てアップデートしてくれるp_update()という関数も用意されている。使い方は簡単で、コンソール上にp_update()のみの入力すれば良い。ただし、一部のパッケージのみをアップデートしたいのであれば、RStudioが提供するアップデート機能を使った方が良いかも知れない5。\n　また、同じ機能の関数としてp_up()があるが、コードの可読性のためにp_update()の方を推奨したい。\n\npacman::p_update()"
  },
  {
    "objectID": "packages.html#RN4Esec-packages_tidyverse",
    "href": "packages.html#RN4Esec-packages_tidyverse",
    "title": "5  Rパッケージ",
    "section": "\n5.6 必須パッケージのインストール",
    "text": "5.6 必須パッケージのインストール\n　ここでは現在のRにおいて必須パッケージである{tidyverse}をインストールする。{tidyverse}は{dplyr}、{ggplot2}、{tidyr}など、Rにおいて不可欠なパッケージを含むパッケージ群である。また、上で紹介した{devtools}も今のうちにインストールしておこう。既に導入済みの読者は走らせなくても良い。\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"devtools\")\n\n\n私たちのR 私たちのR 6  基本的な操作 4  分析環境のカスタマイズ 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 5  Rパッケージ 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "aboutr.html#RN4Esec-aboutr-intro",
    "href": "aboutr.html#RN4Esec-aboutr-intro",
    "title": "1  R?",
    "section": "\n1.1 Rとは",
    "text": "1.1 Rとは\n\n\n図 1.1: R Logo\n\n\n　Rは統計、データ分析、作図のためのインタープリタープログラミング言語である。Rという名前は二人の開発者 Ross Ihaka と Robert Clifford Gentleman のイニシャルに由来する。R言語は完全にゼロベースから開発されたものではなく、1976年に開発されたS言語に起源をもつ。S言語もR言語同様、統計やデータ分析に特化した言語であり、S言語の開発が中止された現在、RはSの正当な後継者であると言ってよいだろう。\n　R以外にも、統計・データ分析のために利用可能なソフトウェアはたくさんある。社会科学におけるデータ分析の授業を履修したことがあるなら、SPSS や Stata という名前をきいたことがあるかもしれない。工学系ならMATLAB が有名かもしれない。企業ではSAS という高価なソフトもよく使われる1。\n　これらのソフト（アプリ）は基本的に有料だが、お金がないとデータ分析のソフトウェアが使えないわけではない。無料でありながら優れたソフトウェアも多く公開されている。以下にその一部を示す。\n\n\nソフト・言語名\n備考\n\n\n\nPSPP\nSPSSにとてもよく似た無料ソフトウェア。\n\n\n\nJASP/jamovi\n\n裏で動いているのはR。詳細は本章の後半で\n\n\ngretl\n時系列分析など、計量経済学で利用される手法に特化したソフト。\n\n\nGNU Octave\n\nMATLAB とほぼ同じ文法をもつ無料言語\n\n\nHAD\n\n清水裕士 先生が開発しているExcelベースのデータ分析マクロ\n\n\n\n　統計分析に特化したプログラミング言語としてRの競合相手になるのは Julia と Python だろう。Julia言語は一見Rによく似ているが、計算速度が Rより速いと言われている2。ただし、比較的新しい言語であるため、パッケージと解説書がRよりも少ないという難点がある。Pythonは現在のデータサイエンス界隈において、Rとともに最も広く使われている言語である3。Pythonは統計・データ分析に特化した言語ではないが、統計・データ分析のライブラリが非常に充実しており、機械学習（とくに、コンピュータービジョン）ではRよりも広く使われている。Python以外の言語、たとえば C や Java、Ruby、Fortranでも統計・データ分析は可能ある。実際、RやPythonのパッケージの一部はCやJavaで作成されている。ただし、RやPythonに比べると、データ分析の方法を解説したマニュアル・参考書があまりないのがつらいところだ。ひとつの言語だけでなく、複数の言語を使えるようになったほうが良いことは言うまでもない。本書はRについて解説するが、他の言語にもぜひ挑戦してほしい。"
  },
  {
    "objectID": "aboutr.html#RN4Esec-aboutr-why-r",
    "href": "aboutr.html#RN4Esec-aboutr-why-r",
    "title": "1  R?",
    "section": "\n1.2 Why R?",
    "text": "1.2 Why R?\n　私たちRユーザにとっての神のような存在であるHadley Wickham（通称：羽鳥先生）は Advanced R (2nd Ed.) で次のように仰せられた。\n\n\nIt’s free, open source, and available on every major platform. As a result, if you do your analysis in R, anyone can easily replicate it, regardless of where they live or how much money they earn.\n\n\n\nRは無料で、オープンソースで、多くのプラットフォーム（訳注: macOS, Linux, Windowsなど）で利用できます。よって、Rを使って分析すれば、どこに住んでいるか、いくらお金を稼いでいるかに関係なく、誰でも簡単にその分析を再現できることができます。\n\n\n\nR has a diverse and welcoming community, both online (e.g. the #rstats twitter community) and in person (like the many R meetups). Two particularly inspiring community groups are rweekly newsletter which makes it easy to keep up to date with R, and R-Ladies which has made a wonderfully welcoming community for women and other minority genders.\n\n\n\nオンライン (twitterの#rstatなど)、オフライン (訳注：日本では Tokyo.R が有名。筆者たちが開催している KUT.R もある)　の両方で、多様なRコミュニティがあります。他にも最新のRをキャッチアップするためのニュースレターであるrweeklyや、女性や性的マイノリティーにやさしい R-Ladies も活発に活動しています。\n\n\n\nA massive set of packages for statistical modelling, machine learning, visualisation, and importing and manipulating data. Whatever model or graphic you’re trying to do, chances are that someone has already tried to do it and you can learn from their efforts.\n\n\n\n統計モデリング、機械学習、可視化、データ読み込みおよびハンドリングのための膨大なパッケージが用意されています。どのようなモデルやグラフでも、既に誰かがその実装を試みた可能性が高く、先人らの努力に学ことができます。\n\n\n\nPowerful tools for communicating your results. R Markdown makes it easy to turn your results into HTML files, PDFs, Word documents, PowerPoint presentations, dashboards and more. Shiny allows you to make beautiful interactive apps without any knowledge of HTML or javascript.\n\n\n\n分析結果を伝達する強力なツールを提供しています。R Makrdownは分析結果をHTML、PDF、Word、PowerPoint、Dashboard 形式に変換してくれます。HTMLや JavaScript の知識がなくても、Shinyを使って美しい対話型のアプリケーションを開発することができます。\n\n\n\nRStudio, the IDE, provides an integrated development environment, tailored to the needs of data science, interactive data analysis, and statistical programming.\n\n\n\n代表的な統合開発環境であるRStudioはデータサイエンス、対話型のデータ分析、そして統計的プログラミングが必要とするものに最適化されています。\n\n\n\nCutting edge tools. Researchers in statistics and machine learning will often publish an R package to accompany their articles. This means immediate access to the very latest statistical techniques and implementations.\n\n\n\nRは最先端のツールです。多くの統計学や機械学習の研究者は自分の研究成果とRパッケージを同時に公開しています。これは最先端の方法を誰よりも早く実施可能にします。\n\n\n\nDeep-seated language support for data analysis. This includes features like missing values, data frames, and vectorisation.\n\n\n\nデータ分析を根強くサポートする言語です。欠損値、データフレーム、ベクトル化などがその例です。\n\n\n\nA strong foundation of functional programming. The ideas of functional programming are well suited to the challenges of data science, and the R language is functional at heart, and provides many primitives needed for effective functional programming.\n\n\n\nRはデータサイエンスに非常に有効である関数型プログラミングのための最適な環境を提供しています。\n\n\n\nRStudio, the company, which makes money by selling professional products to teams of R users, and turns around and invests much of that money back into the open source community (over 50% of software engineers at RStudio work on open source projects). I work for RStudio because I fundamentally believe in its mission.\n\n\n\nRStudio社は営利企業ですが、その収益の多くをオープンソースコミュニティーに投資しています。\n\n\n\nPowerful metaprogramming facilities. R’s metaprogramming capabilities allow you to write magically succinct and concise functions and provide an excellent environment for designing domain-specific languages like ggplot2, dplyr, data.table, and more.\n\n\n\nメタプログラミングが強力です。Rが持つメタプログラミング能力はあなたのコードを劇的に簡潔にするだけでなく、統計/データ分析に特化したggplot2、dplyr、data.tableなどの開発も可能にしました。\n\n\n\nThe ease with which R can connect to high-performance programming languages like C, Fortran, and C++.\n\n\n\nRはC、C++、Fortranのようなハイパフォーマンス言語と容易に結合できるように設計されています。\n\n　しかし、他のプログラミング言語と同様、Rは完璧な言語ではありません。以下はR言語の短所の一部です。その多くはRそのものの問題というよりも、(プログラマーではなく)データ分析の研究者が中心となっているRユーザーから起因する問題です。\n\n\nMuch of the R code you’ll see in the wild is written in haste to solve a pressing problem. As a result, code is not very elegant, fast, or easy to understand. Most users do not revise their code to address these shortcomings.\n\n\n\nあなたが普段見る多くのRコードは「今の」問題を解決するために迅速に書かれたものです。この場合、コードはあまりエレガントでも、速くも、読みやすくありません。ほとんどのユーザーはこの短所を克服するためのコード修正を行っておりません。\n\n\n\nCompared to other programming languages, the R community is more focussed on results than processes. Knowledge of software engineering best practices is patchy. For example, not enough R programmers use source code control or automated testing.\n\n\n\n他のプログラミング言語に比べ、Rコミュニティーは過程よりも結果に注目する傾向があります。多くのユーザーにおいて、ソフトウェアエンジニアリングの知識を蓄えるための方法が不完全です。たとえば、(GitHubなどの) コード管理システムや自動化された検証を使用するRプログラマーは多くありません。\n\n\n\nMetaprogramming is a double-edged sword. Too many R functions use tricks to reduce the amount of typing at the cost of making code that is hard to understand and that can fail in unexpected ways.\n\n\n\nRの長所でもあるメタプログラミングは諸刃の剣です。あまりにも多くのR関数はコーディングのコストを減らすようなトリックを使用しており、その代償としてコードの理解が難しく、予期せぬ失敗の可能性があります。\n\n\n\nInconsistency is rife across contributed packages, and even within base R. You are confronted with over 25 years of evolution every time you use R, and this can make learning R tough because there are so many special cases to remember.\n\n\n\n開発されたパッケージは、R内蔵のパッケージさえも一貫性が乏しいです。あなたはRを使う度にこの25年を超えるRの進化に直面することになります。また、Rには覚えておくべきの特殊なケースが多く、これはR学習の妨げとなっています。\n\n\n\nR is not a particularly fast programming language, and poorly written R code can be terribly slow. R is also a profligate user of memory.\n\n\n\nRは格別に速い言語ではありません。下手に書かれたコードは驚くほど遅いです。また、Rはメモリの浪費が激しい言語と知られています。"
  },
  {
    "objectID": "aboutr.html#RN4Esec-aboutr-gui-cui",
    "href": "aboutr.html#RN4Esec-aboutr-gui-cui",
    "title": "1  R?",
    "section": "\n1.3 GUIとCUI",
    "text": "1.3 GUIとCUI\n　現在、多くのソフトウェアはGUIを採用している。GUI とは Graphical User Interface の略で、ソフトウェア上の入力および出力にグラフィックを利用する。単純にいうと「マウスでポチポチするだけで操作できる環境」のことだ。一方、Rでは基本的にCUI (Character User Interface) を利用する4。これは全ての操作を文字列ベースで行う、つまりキーボードで行うことを意味する5。\n　身近な例として、あるラーメン屋での注文（呪文）システムを考えてみよう。無料トッピングを指定するときに「決まった言い方」で指定するのがCUI方式である。一文字でも間違うとオーダーは通りらない。たとえば、「野菜マッシマッシ!」とか「野菜MashMash!」と言ってしまうと、店長さんに「は？」と言われ、周りの客から白い目で見られる6。他方、食券の自動発売機でトッピングを指定できるのがGUI方式だ7。この場合、そもそも間違いは起きない。誰でも簡単に注文できるのがGUI式のメリットだが、自分で注文するものが決まっていて、注文の仕方を知っているなら CUI式のほうが早い。毎回同じ注文をするなら、注文内容を録音しておいて、次回はそれを再生することも可能である。GUI方式では、注文方法を再現するのは難しい。\n\n\n図 1.2: CUIとGUIの比較\n\n\n　CUIとGUIを比べたとき、一見するとGUIのほうが優れているように見える。マウスでポチポチするだけで操作できるほうが楽に見えるし、間違いの心配もなさそうな気がする。キーボードで長いコマンドを打つCUIよりも、ボタンをクリックしたほうが手早く済みそうにも思える8。そして、CUIのコマンドを覚えるのはしんどい9。\n　しかし、CUIにはCUIなりの長所がある。まず、コードが記録できる。マウスでポチポチした操作は、パソコンの画面全体を録画しない限り記録できない。よって、GUIでは自分の分析プロセスを記録することが難しい。他方、すべてコマンドで操作した場合、入力したコマンドを文字列として記録することは容易である。また、CUIはGUIよりも柔軟である。先ほどのラーメン屋の例で考えると、CUIでは「一応」野菜ちょいマシのような注文（呪文）のカスタマイズもできる10。しかし、GUI（券売機）だと注文の自由なカスタマイズはできない。店が用意したボタンしか押せない（ソフトがメニューに表示しているコマンドしか実行できない）。また、コマンドの入力の時間や暗記も、それほど難しくはない。後で説明するように、Rユーザにとっての超有能な秘書であるRStudio (IDEの1種) がコマンド入力を助けてくれる。スペルが間違っていたり、うろ覚えのコマンドなどがあっても、RStudio （あるいはその他のIDE）が瞬時に正解に導いてくれる。\n　本書はCUIとしてのRについて解説する。Rは統計ソフトでありながら、言語でもある。外国語の勉強に喩えるなら、CUIを使うのは単語や熟語を覚え、文法やよく使う表現を学習して自分で考えて話すことであるのに対し、GUIを使うのは AI に翻訳を頼み、外国語については自分で一切考えないことに似ている。たいして興味のない国になぜか旅行で訪れることになった場合にはGUI方式で済ますのも良いだろう。しかし、それでその言語を「勉強した」とか「理解した」などという人はいないはずだ。Rを「理解」したいなら、CUI以外の選択肢はない11。\n　それでもやはりGUIのほうがとっつきやすいという頑固なあなたのために代表的なRの GUI を紹介するので、以下のリストを確認したらこの本は閉じていただきたい。またいつかどこかでお会いしましょう。CUIを使う覚悟ができたあなたは、以下のリストを読みとばし、引き続き一緒にRの世界を楽しみましょう！\n\n\n図 1.3: R Commander\n\n\n\n\n図 1.4: RKWard\n\n\n\n\n図 1.5: JASP\n\n\n\n\n図 1.6: jamovi\n\n\n\n\n図 1.7: R AnalyticFlow\n\n\n\n私たちのR 私たちのR 2  Rのインストール 紹介 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 1  R? 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "programming.html#RN4Esec-programming_intro",
    "href": "programming.html#RN4Esec-programming_intro",
    "title": "10  Rプログラミングの基礎",
    "section": "\n10.1 R言語の基礎概念",
    "text": "10.1 R言語の基礎概念\n\n10.1.1 オブジェクト\n　これまで「オブジェクト」や「関数」などという概念を定義せずに使ってきたが、ここではR言語の構成する基本的な概念についてもう少し詳細に解説する。これらは、プログラミングをする上である程度は意識的に使う必要があるものである。\n　まず、オブジェクト (object) とはメモリに割り当てられた「何か」である。「何か」に該当するのは、ベクトル (vector)、行列 (matrix)、データフレーム (data frame)、リスト (list)、関数 (function) などである。一般的に、オブジェクトにはそれぞれ固有の（つまり、他のオブジェクトと重複しない）名前が付いている。\n　たとえば、1から5までの自然数の数列を\n\nmy_vec1 <- c(1, 2, 3, 4, 5)  # my_vec1 <- 1:5  でも同じ\n\nのようにmy_vec1という名前のオブジェクトに格納する。オブジェクトに名前をつけてメモリに割り当てると、その後 my_vec1 と入力するだけでそのオブジェクトの中身を読み込むことができるようになる。\n　ここで、次のように my_vec1の要素を2倍にする操作を考えてみよう。\n\nmy_vec1 * 2\n\n[1]  2  4  6  8 10\n\n\nmy_vec1は、先ほど定義したオブジェクトである。では2はどうだろうか。2はメモリに割り当てられていないので、オブジェクトではないのだろうか。実は、この数字 2 もオブジェクトである。計算する瞬間のみ2がメモリに割り当てられ、計算が終わったらメモリから消されると考えれば良い。「Rに存在するあらゆるものはオブジェクトである (Everything that exists in R is an object)」 (Chambers 2016)。* のような演算子でさえもオブジェクトである。\n\n10.1.2 クラス\n　クラス (class) とはオブジェクトを特徴づける属性である。既に何度か class() 関数を使ってデータ型やデータ構造を確認したが、class()関数でオブジェクトのクラスを確認することができる。先ほど、my_vec1も*も2もオブジェクトであると説明した。これらがすべてオブジェクトであるということは、何らかのクラス属性を持っているというこである。また、class()関数そのものもオブジェクトなので、何らかのクラスをもつ。確認してみよう。\n\nclass(my_vec1)\n\n[1] \"numeric\"\n\nclass(`*`)\n\n[1] \"function\"\n\nclass(2)\n\n[1] \"numeric\"\n\nclass(class)\n\n[1] \"function\"\n\n\n　統計分析をする際に、Rのクラスを意識することはあまりない。しかし、Rでパッケージを開発したり、複雑な関数を自作する場合、オブジェクト指向プログラミング (Object-oriented Programming; OOP) の考え方が重要で、オブジェクトのクラスを厳密に定義する必要がある5。\n　自分でパッケージを開発しないとしても、クラスの概念は知っておいたほうが良い。この後説明する関数には引数というものがあるが、引数には特定のクラスのオブジェクトしか指定できない。関数の使い方がわからないときには?関数名 でヘルプを表示するが、ヘルプには各引数に使うべきクラスが書かれている。クラスについて何も知らないと、ヘルプを読んでも意味がわからないかもしれない。\n　たとえば、Rコンソール上で?meanを入力して実行すると、 図 10.1 のような mean() 関数のヘルプが表示される。ヘルプに示されているとおり、mean()関数に必要な引数は x、trim、na.rmである。仮引数xの説明を読むと、x の実引数にはnumeric または logical のベクトルクラスが使えることが分かる。さらに、date、date-time、time interval が使えることも教えてくれる。\n\n\n図 10.1: mean()関数のヘルプ画面\n\n\n　回帰分析を行うlm()関数の場合、data という仮引数があるが、dataの実引数に指定できるのは data.frame クラスまたは tibbleクラスのオブジェクトである6。通常はクラスを意識せずにRを使っても問題ないが、\n\n全てのオブジェクトにはクラスが付与されており、\n関数 (の引数) ごとに実引数として使えるクラスが異なる\n\nという2点は覚えておこう。\n\n10.1.3 関数と引数\n　関数 (function) は、入力されたデータを内部で決められた手順に従って処理し、その結果を返すものである。「Rで起こるあらゆることは関数の呼び出しである (Everything that happens in R is a function call)」(Chambers 2016)。\n　関数は 関数名(関数の入力となるオブジェクト) のように使う。たとえば、class(my_vec1)はmy_vec1というオブジェクトのクラスを返す関数である。また、sum(my_vec1)はmy_vec1の要素の総和を計算して返す関数である。\n　関数は自分で作成することもできる（次章で説明する）。複雑な作業を繰り返す場合、その作業を関数として記述することで、一行でその作業を再現することが可能になる。「2度以上同じことを繰り返すなら関数を作れ」というのが、Rユーザの心得である。\n　関数を使うためには、 引数 (ひきすう) と呼ばれるものが必要である。例えば、sum() 関数はこれだけだと何もできない。何らかのオブジェクトがが入力として与えられないと、結果を返すことができない。sum(my_vec1)のようにすることではじめて結果が返される。ここでmy_vec1がsum()関数の引数である。\n　関数は引数は複数持つことができる。たとえば、欠測値を含む以下のmy_vec2を考えてみよう。\n\nmy_vec2 <- c(1, 2, 3, NA, 5)\n\n　この数列の総和を sum()関数で求めようとすると、結果は欠測値 NA になる。\n\nsum(my_vec2)\n\n[1] NA\n\n\n　これはsum()の基本仕様が「入力に欠測値が含まれている場合は欠測値を返す」ことになっているためである。入力されたデータのなかで欠測値を除いたものの総和を求めるために、sum()はもう1つの引数が用意されている。それが na.rm である。na.rm = TRUEを指定すると、欠測値を除外した総和を返す。\n\nsum(my_vec2, na.rm = TRUE)\n\n[1] 11\n\n\n　第6章で説明したとおり、na.rm などのように引数を区別するために関数によって用意されたものを仮引数 (parameter) と呼び、TRUE のように引数の中身としてユーザが指定するものを実引数 (argument) と呼ぶ。my_vec2 は実引数である。\n　引数を指定するとき、my_vec2のように仮引数を明示しないこともある。多くの場合、それがなければ関数がそもそも動かないという第1引数の仮引数は明示しないことが多い。そもそも、第1引数には仮引数がない（名前がない）場合もある。sum() 関数の第1引数はnumeric または complex 型のベクトルだが、仮引数がそもそもない（... で定義されている）。\n　しかし、第1引数以外については、na.rm = TRUE のように仮引数を明示すべきである。関数によっては数十個の引数をとるものもあり、仮引数を明示しないと、どの実引数がどの仮引数に対応するのかわかりにくい。\n　多くの引数は関数によって定義された既定値 (default value) をもっている。たとえば、sum()関数の na.rm の既定値は FALSE である。既定値が用意されている場合、その引数を指定せずに関数を使うことができる。\n　ある関数がどのような引数を要求しているか、その既定値は何か、引数として何か決められたデータ型/データ構造があるかを調べたいときは ?関数名 （()がないことに注意）または help(関数名）をコンソールに入力する。多くの関数に詳細なヘルプが付いているので、ネットで検索したり、誰かに質問する前にひとまずヘルプを読むべきである。"
  },
  {
    "objectID": "programming.html#RN4Esec-programming_style",
    "href": "programming.html#RN4Esec-programming_style",
    "title": "10  Rプログラミングの基礎",
    "section": "\n10.2 Rのコーディングスタイル",
    "text": "10.2 Rのコーディングスタイル\n　Rコードの書き方に唯一の正解はない。文法が正しければ、つまり、Rが意図どおりの実行結果を出してくれさえすれば、それは「正しい」コードである。しかし、コードというのは、一度書けば二度と読まないというものではない。最初に「書く」とき以外に、「修正する」ときや「再利用」するときなどに繰り返し読むことになる。また、共同研究をする場合には共同研究者がコードを読む。さらに、近年では研究成果を報告する際に分析に利用したコードを後悔公開することも当たり前になりつつあり、その場合には自分で書いたコードを世界中の人が読む可能性がある。\n　ここで大事なのは、Rコードを読むのはRだけではないということである。人間も重要な「読者」である。Rコードを書くときは人間に優しいコードを書くように心がえよう。唯一の正解がなくても、読みやすく、多くの人が採用している標準的な書き方はある。ここでは、人間に優しいコードを書くためのコーディングスタイルについて説明しよう。\n\n10.2.1 オブジェクト名\n　ベクトル、データフレーム、自作の関数などのすべてのオブジェクトには名前をつける必要がある（ラムダ式などの無名関数を除く）。名前はある程度自由に付けることができるが、大事な原則がある。それは、\n\nオブジェクト名は英数字と限られた記号のみにする\n数字で始まる変数名は避ける\n\n1つ目は原則にすぎない。よって、日本語やハングルの変数名をつけることもできる。しかし、それは推奨しない。英数字以外（マルチバイト文字）は文字化けの可能性がある（文字コードの問題が発生する）し、コードを書く際列がずれる原因にもなる\n\nvar1 <- c(2, 3, 5, 7, 11)      # 推奨\n\n\n変数1 <- c(2, 3, 5, 7, 11)     # 非推奨\n\n\nvar1\n\n[1]  2  3  5  7 11\n\n\n\n変数1\n\n[1]  2  3  5  7 11\n\n\n　2つ目のルールは必ず守る必要がある。つまり、数字で始まるオブジェクト名は作成できない。\n\n100A <- \"R\"\n\nError: <text>:1:4: unexpected symbol\n1: 100A\n       ^\n\n\n予約語を避ける\n　Rが提供する組込の関数やオブジェクトと重複する名前を自分で作成するオブジェクトに付けるのは避けよう。例えば、Rには円周率 (\\(\\pi\\)) がpiという名前で用意されている。\n\npi\n\n[1] 3.141593\n\n\npiという名前で新しい変数を作ることはできる。\n\npi  <- 777\n\nしかし、既存のpiが上書きされてしまうので避けたほうが良い。\n\npi   # もはや円周率ではない\n\n[1] 777\n\n\n元の円周率を使うこともできるが、手間が増える。\n\nbase::pi\n\n[1] 3.141593\n\n\n　また、ユーザが自由に使えない名前もある。それらの名前を「予約語」と呼ぶ。予約語の使用は禁止されている。\n\nif  <- \"YY\"\n\nError: <text>:1:5: unexpected assignment\n1: if  <-\n        ^\n\n\n\nfor <- \"JS\"\n\nError: <text>:1:5: unexpected assignment\n1: for <-\n        ^\n\n\n\nTRUE <- \"いつもひとつ！\"\n\nError in TRUE <- \"いつもひとつ！\": invalid (do_set) left-hand side to assignment\n\n\nこのように、予約語はそもそも使えないので、それほど意識する必要はない。\n　ただし、以下のコードのようなことが起こるので注意してほしい。\n\nvals <- 1:5\nvals[c(TRUE, TRUE, FALSE, FALSE, TRUE)]\n\n[1] 1 2 5\n\nvals[c(T, T, F, F, T)]\n\n[1] 1 2 5\n\n\nここから、T は TRUE、F は FALSE と同じ働きをしていることがわかる。ここで、次のコードを実行してみよう。\n\nT <- \"Taylor\"\nF <- \"Fourier\"\nvals[c(T, T, F, F, T)]\n\n[1] NA NA NA NA NA\n\n\nこのように、T とFはあらかじめ使える状態で用意されているものの、予約語ではないので値が代入できてしまう。しかし、T とF を自分で定義したオブジェクトの名前に使うと混乱の元になるので、使用は避けるのが無難である。\n　また、TRUE と FALSE を T やF で済ませる悪習は廃して常に完全にスペルすべきである。\n「短さ」と「分かりやすさ」を重視する\nオブジェクト名を見るだけでその中にどのようなデータが含まれているか推測できる名前をつけるべきである。たとえば、性別を表す変数を作るなら、\n\nvar2 <- c(\"female\", \"male\", \"male\", \"female\")\n\nではなく、\n\ngender <- c(\"female\", \"male\", \"male\", \"female\")\n\nとしたほうが良い。gender という名前がついていれば、「この変数には性別に関する情報が入っているだろう」と容易に想像できる。\n　また、オブジェクト名は、短くて読みやすいほうが良い。数学の成績データをもつ次のオブジェクトについて考えよう。\n\nmathematicsscore <- c(30, 91, 43, 77, 100)\n\nオブジェクト名から、中にどのような情報が含まれるか想像することはできる。しかし、この名前は長く、読みにくい。そこで、次のように名前を変えたほうが良い。\n\nMathScore  <- c(30, 91, 43, 77, 100)\nmathScore  <- c(30, 91, 43, 77, 100)\nmath_score <- c(30, 91, 43, 77, 100)\n\nこれらの例では、mathematics を math に縮め、mathとscoreの間に区切りを入れて読みやすくしている。大文字と小文字の組み合わせで区切る方法はキャメルケース (camel case)と呼ばれ、大文字から始まるキャメルケースを大文字キャメルケース (upper camel case)、小文字から始まるキャメルケースを小文字キャメルケース (lower camel case) と呼ぶ。また、_（アンダーバー, アンスコ） で区切る方法はスネークケース (snake case) と呼ばれる。キャメルケースとスネークケースは、一貫した方法で使えばどちらを使っても良いだろう。\n　かつては “.” を使って単語を繋ぐのが標準的だった時代もあり、組込関数には “.” を使ったものも多い。data.frame() や read.csv() などがその例である。しかし、“.” はクラスのメソッドとして使われることがあり、混乱するので使うのは避けたほうが良い。{tidyverse} では、readr::read_csv() のように、スネークケースが採用されている。他にも -（ハイフン）で区切るチェーンケース (chain case)というのもあるが、Rで-は「マイナス（減算演算子）」であり、チェーンケースは使えない7。\n\n10.2.2 改行\n　コードは1行が長すぎないように適宜改行する。Rやパッケージなどが提供している関数のなかには10個以上の引数を必要とするものもあり。コードを1行で書こうとするとコードの可読性が著しく低くなってしまう。\n　1行に何文字入れるべきかについて決まったルールはないが、1行の最大文字数を半角80字にするという基準が伝統的に使われてきた。これま昔のパソコンで使ったパンチカード ( 図 10.2 )では1行に80個の穴を開けることができたことに由来する。\n\n\n図 10.2: パンチカードの例\n\n\n最近は昔と比べてモニタのサイズが大きく、解像度も高いので、80文字にこだわる必要はない。自分のRStudioのSource Paneに収まるよう、切りがいいところで改行しよう。\n\n10.2.3 スペースとインデント\n　適切なスペースはコードの可読性を向上させる。以下の2つのコードは同じ内容を実行するが、後者にはスペースがないので読にくい。\n\n# 良い例\nsum(my_vec2, na.rm = TRUE)\n\n# 悪い例\nsum(my_vec2,na.rm=TRUE)\n\n　どこにスペースを入れるかについてのルールは特になり。Rは「半角スペース」を無視するので、プログラムの動作に関して言えば、半角スペースはあってもなくても同じである。標準的なルールとして、「,の後にスペース」、「演算子の前後にスペース」などが考えらえる。ただし、^の前後にはスペースを入れないことが多い。また、後ほど紹介するfor(){}、while(){}、if(){}などのように、関数以外の ()の前後にはスペースを入れる。それに対し、sum() や read.csv() などのように、関数のかっこの場合には、関数名と()の間にスペースを入れない。\n　また、スペースを2回以上入れることもある。たとえば、あるデータフレームを作る例を考えよう。\n\n# 良い例\ndata.frame(\n  name     = c(\"Song\",  \"Yanai\", \"Wickham\"),\n  favorite = c(\"Ramen\", \"Cat\",   \"R\"),\n  gender   = c(\"Male\",  \"Male\",  \"Male\")\n)\n\n# 悪い例\ndata.frame(\n  name = c(\"Song\", \"Yanai\", \"Hadley\"),\n  favorite = c(\"Ramen\", \"Cat\", \"R\"),\n  gender = c(\"Male\", \"Male\", \"Male\")\n)\n\n上の2つのコードの内容は同じだが、前者のほうが読みやすい。\n　ここでもう1つ注目してほしいのは、「字下げ (indent)」の使い方である。上のコードは次のように一行にまとめることができるが、読みにくい。\n\n# 邪悪な例\ndata.frame(name=c(\"Song\",\"Yanai\",\"Hadley\"),favorite=c(\"Ramen\",\"Cat\",\"R\"),fender=c(\"Male\",\"Male\",\"Male\"))\n\nこのように1行のコードが長い場合、「改行」が重要である。しかし、Rの最も基本的なルールは「1行に1つのコード」なので、改行するとこのルールを破ることになってしまう。そこで、コードの途中で改行するときは、2行目以降を字下げすることで、1つのコードが前の行から続いていることを明確にしよう。前の行の続きの行は2文字（または4文字）分字下げする。こうすることで、「この行は上の行の続き」ということが「見て」わかるようになる。\n\n# 良い例\ndata.frame(\n  name     = c(\"Song\",  \"Yanai\", \"Hadley\"),\n  favorite = c(\"Ramen\", \"Cat\",   \"R\"),\n  gender   = c(\"Male\",  \"Male\",  \"Male\")\n)\n\n# 悪い例\ndata.frame(\nname     = c(\"Song\",  \"Yanai\", \"Hadley\"),\nfavorite = c(\"Ramen\", \"Cat\",   \"R\"),\ngender   = c(\"Male\",  \"Male\",  \"Male\")\n)\n\n　RStudioは自動的に字下げをしてくれるので、RStudioを使っているならあまり意識する必要はない。自動で字下げしてくれないエディタを使っている場合は、字下げに気をつけよう。\n\n10.2.4 代入\nオブジェクトに値を代入する演算子として、これまで <- を使ってきたが、=を使うこともできる。R以外の多くのプログラミング言語では、代入演算子として=を採用している。しかし、引数の指定と代入を区別するためん、本書では<-の使用を推奨する。また、既に説明したとおり、option + -（macOSの場合）または Alt + -（Windows の場合）というショートカットを使うと、<- だけでなく、その前後のスペースを自動的に挿入してくれる。コードが読みやすくなるので、代入演算子は常にショートカットで入力する習慣をつけよう。\n　この節で説明したコードの書き方は、コーディングスタイルの一部に過ぎない。本書では、できるだけ読みやすいコードを例として示すことを心がけている。最初は本書（あるいは他の本やウェブサイトに掲載されているもののなかで気に入ったもの）のスタイルを真似して書いてみてほしい。コードを書き写しているうちに、自にとって最善の書き方が見えてくるだろう。\n　コーディングスタイルについては、以下の2つの資料がさらに詳しい。とりわけ、羽鳥先生が書いたThe tidyverse style guide は事実上の業界標準であり、Google’s Style Guide も このガイドをベースにしている。かなりの分量だが、パッケージ開発などを考えているなら一度は目を通しておいたほうが良いだろう。\n\nThe tidyverse style guide\nGoogle’s Style Guide"
  },
  {
    "objectID": "programming.html#RN4Esec-programming_iteration",
    "href": "programming.html#RN4Esec-programming_iteration",
    "title": "10  Rプログラミングの基礎",
    "section": "\n10.3 反復",
    "text": "10.3 反復\n　人間があまり得意ではないが、コンピュータが得意とする代表的な作業が「反復作業」である。普通の人間なら数時間から数年かかるような退屈な反復作業でも、コンピュータを使えば数秒で終わることが多い。Rでもさまざまな反復作業を行うことができる。\n　反復作業を行うときは、反復作業を「いつ終わらせるか」を考えなくてはならない。終わりを規程する方法として、以下の2つが考えられる。\n\n処理を繰り返し回数を指定し、その回数に達したら終了する: for 文を使う\n一定の条件を指定し、その条件が満たされるときに処理を終了する: while 文を使う\n\nこの節では、これら2つのケースのそれぞれについて解説する。\n\n10.3.1 for による反復\n　forを利用した反復を、forループ と呼ぶ。まず、forループの雛形をみてみよう。\nfor (任意の変数 in ベクトル) {\n  処理内容\n}\n任意の変数の選び方はいろいろ考えられるが、よく使うのはインデクス (index) i である。このインデクスはforループの内部で使うために用いられる変数である。そして、in の後の「ベクトル」には長さ1以上のベクトルを指定する。ベクトルは必ずしもnumeric型である必要はないが、インデクスを利用したforループではインデクスを指定する正の整数を要素にもつベクトルを使う。\n　また、{}内の内容が1行のみの場合には、{}は省略しても良い。その場合、処理内容を()の直後に書。つまり、以下のような書き方もできる。\nfor (任意の変数 in ベクトル) 処理内容\nこれはforだけでなく、ifやfunction()など、{}で処理内容を囲む関数に共通である。処理内容が2行以上の場合は、必ず{}で囲むようにしよう。\n　例として、インデクス \\(i\\) の内容を画面に表示することをN回繰り返すforループを書いてみよう。繰り返し回数を指定するために、for (i in 1:N)と書く。5回繰り返すならfor (i in 1:5)とする。1:5はc(1, 2, 3, 4, 5)と同じなので、for (i in c(1, 2, 3, 4, 5))でもいいが、1:5 を使って書いたほうが、コードが読みやすい。\n　以下コードを作成し、実行してみよう。このコードは3行がひとつのかたまりになったコードである。forの行（あるいは最後の}の行）にカーソルを置いた状態で Cmd/Ctrl + Return/Enter を押せば、forループ全体が一挙に実行される。\n\n# 以下のコードはこのように書くことも可能\n# for(i in 1:5) print(i)\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\n1から5までの数字が表示された。\n　ここで、このforループがどのような順番で処理を実行したのか確認してみよう。上のコードは、次のようなステップを踏んで1から5までの数字を画面に表示している。\n\n\niにベクトル1:5の最初の要素を代入 (i <- 1)\n\nprint(i)を実行\n\n{}中身の処理が終わったらiにベクトル1:5内の次の要素を代入 (i <- 2)\n\nprint(i)を実行\n\n{}中身の処理が終わったらiにベクトル1:5内の次の要素を代入 (i <- 3)\n\nprint(i)を実行\n\n{}中身の処理が終わったらiにベクトル1:5内の次の要素を代入 (i <- 4)\n\nprint(i)を実行\n\n{}中身の処理が終わったらiにベクトル1:5内の次の要素を代入 (i <- 5)\n\nprint(i)を実行\n\n{}中身の処理が終わったらiにベクトル1:5内の次の要素を代入するが、5が最後の要素なので反復終了\n\nこの手順を要約すると、次のようになる。\n\n任意の変数 (ここではi)にベクトル (ここでは1:5)の最初の要素が格納され、{}内の処理を行う。\n\n{}内の処理が終わったら、ベクトル (ここでは1:5)の次の要素を任意の変数 (ここではi)に格納し、{}内の処理を行う。\n格納できる要素がなくなったら反復を終了する。\n\nしたがって、反復はベクトル (ここでは1:5)の長さだけ実行される (ここでは5回)。\n\n\n\n　反復回数はベクトルの長さで決まる。既に述べたとおり、1:5のような書き方でなく、普通のベクトルを指定しても問題ない。たとえば、長さ6の dmg_vals というベクトルを作り、その要素を出力するコードを書いてみよう。\n\ndmg_vals <- c(24, 64, 31, 46, 81, 102)\n\nfor (damage in dmg_vals) {\n  x <- paste0(\"トンヌラに\", damage, \"のダメージ!!\")\n  print(x)\n}\n\n[1] \"トンヌラに24のダメージ!!\"\n[1] \"トンヌラに64のダメージ!!\"\n[1] \"トンヌラに31のダメージ!!\"\n[1] \"トンヌラに46のダメージ!!\"\n[1] \"トンヌラに81のダメージ!!\"\n[1] \"トンヌラに102のダメージ!!\"\n\n\n　スライムくらいなら一撃で撃破できそうな立派な勇者である。\n　ちなみに、paste0()は引数を空白なし8で繋いだ文字列を返す関数である。詳細は第16で解説するが、簡単な例だけ示しておこう。\n\npaste0(\"Rは\", \"みんなの\", \"ともだち\")\n\n[1] \"Rはみんなのともだち\"\n\npaste0(\"私の\", \"HP/MPは\", 500, \"/\", 400, \"です。\")\n\n[1] \"私のHP/MPは500/400です。\"\n\n\n　文字列のベクトルを使ったforループもできる。10個の都市名が格納されたcitiesの要素を1つずつ出力するコードは次のように書ける。\n\ncities <- c(\"Sapporo\", \"Sendai\", \"Tokyo\", \"Yokohama\", \"Nagoya\",\n            \"Kyoto\", \"Osaka\", \"Kobe\", \"Hiroshima\", \"Fukuoka\")\nfor (i in seq_along(cities)) {\n  x <- paste0(\"現在、cityの値は\", cities[i], \"です。\")\n  print(x)\n}\n\n[1] \"現在、cityの値はSapporoです。\"\n[1] \"現在、cityの値はSendaiです。\"\n[1] \"現在、cityの値はTokyoです。\"\n[1] \"現在、cityの値はYokohamaです。\"\n[1] \"現在、cityの値はNagoyaです。\"\n[1] \"現在、cityの値はKyotoです。\"\n[1] \"現在、cityの値はOsakaです。\"\n[1] \"現在、cityの値はKobeです。\"\n[1] \"現在、cityの値はHiroshimaです。\"\n[1] \"現在、cityの値はFukuokaです。\"\n\n\n　ここでは for (i in 1:10) ではなく、for (i in seq_along(cities))と表記。この例からわかるように、seq_along() を使うと、ベクトルのインデクス自動的に作ってくれる。上の例では、seq_along(ten_cities) が自動的にベクトル長さを計算し、1:length(ten_cities) すなわち 1:10 と同じ処理をしてくれる。ベクトルの長さが自明でないとき（ベクトルが非常に長いとき）には、seq_along() を使うのが便利である。後で cities の中身を書き換えたときに、cities の長さが変わることも考えられるので、ベクトルのインデクス指定には seq_along() を使おう。\n　また、インデクスを使わないforループも書ける。上と同じ結果は、次のコードで実現することができる。\n\nfor (city in cities) {\n  x <- paste0(\"現在、cityの値は\", city, \"です。\")\n  print(x)\n}\n\n[1] \"現在、cityの値はSapporoです。\"\n[1] \"現在、cityの値はSendaiです。\"\n[1] \"現在、cityの値はTokyoです。\"\n[1] \"現在、cityの値はYokohamaです。\"\n[1] \"現在、cityの値はNagoyaです。\"\n[1] \"現在、cityの値はKyotoです。\"\n[1] \"現在、cityの値はOsakaです。\"\n[1] \"現在、cityの値はKobeです。\"\n[1] \"現在、cityの値はHiroshimaです。\"\n[1] \"現在、cityの値はFukuokaです。\"\n\n\nこのように、ベクトルの中身が数字でない場合でも、forループでベクトルの要素を1つずつ順番に利用することができる。\n　次に、\"1番目の都市名はSapporoです\"、\"2番目の都市名はSendaiです\"、…　のように出力する方法を考えよう。これまでは出力する文字列のなかで1箇所（都市名）のみを変えながら表示したが、今回は「i」と「city」の2箇所を同時に変える。これは、インデクス iを使って反復を実行しながら、cities のi番目要素を呼び出すことで実現できる。以下のコードを実行してみよう。\n\nfor (i in seq_along(cities)) {\n  msg <- paste0(i, \"番目の都市名は\", cities[i], \"です。\")\n  print(msg)\n}\n\n[1] \"1番目の都市名はSapporoです。\"\n[1] \"2番目の都市名はSendaiです。\"\n[1] \"3番目の都市名はTokyoです。\"\n[1] \"4番目の都市名はYokohamaです。\"\n[1] \"5番目の都市名はNagoyaです。\"\n[1] \"6番目の都市名はKyotoです。\"\n[1] \"7番目の都市名はOsakaです。\"\n[1] \"8番目の都市名はKobeです。\"\n[1] \"9番目の都市名はHiroshimaです。\"\n[1] \"10番目の都市名はFukuokaです。\"\n\n\nこのように、インデクスとそれに対応するベクトルの要素を抽出すれば、望みどおりの処理ができる。\n多重forループ\n　forループの中でさらにforループを使うともできる。最初はやや難しいかもしれないが、多重反復はプログラミング技術としてよく使われるので9、この機会に勉強しよう。\n　多重forループを理解するためにうってつけの例は掛け算九九である。積算演算子 * の「左の数」と「右の数」 のそれぞれに1から9までの数字を代入するすべての組み合わせを考えるためには、2つのforループが必要だ10。i * jでiとjそれぞれに1から9を代入しながら結果を出力するコードは次のように書ける。\n\nfor (i in 1:9) {\n  for (j in 1:9) {\n    print(paste(i, \"*\", j, \"=\", i * j))\n  }\n}\n\n[1] \"1 * 1 = 1\"\n[1] \"1 * 2 = 2\"\n[1] \"1 * 3 = 3\"\n[1] \"1 * 4 = 4\"\n[1] \"1 * 5 = 5\"\n[1] \"1 * 6 = 6\"\n[1] \"1 * 7 = 7\"\n[1] \"1 * 8 = 8\"\n[1] \"1 * 9 = 9\"\n[1] \"2 * 1 = 2\"\n[1] \"2 * 2 = 4\"\n[1] \"2 * 3 = 6\"\n[1] \"2 * 4 = 8\"\n[1] \"2 * 5 = 10\"\n[1] \"2 * 6 = 12\"\n[1] \"2 * 7 = 14\"\n[1] \"2 * 8 = 16\"\n[1] \"2 * 9 = 18\"\n[1] \"3 * 1 = 3\"\n[1] \"3 * 2 = 6\"\n[1] \"3 * 3 = 9\"\n[1] \"3 * 4 = 12\"\n[1] \"3 * 5 = 15\"\n[1] \"3 * 6 = 18\"\n[1] \"3 * 7 = 21\"\n[1] \"3 * 8 = 24\"\n[1] \"3 * 9 = 27\"\n[1] \"4 * 1 = 4\"\n[1] \"4 * 2 = 8\"\n[1] \"4 * 3 = 12\"\n[1] \"4 * 4 = 16\"\n[1] \"4 * 5 = 20\"\n[1] \"4 * 6 = 24\"\n[1] \"4 * 7 = 28\"\n[1] \"4 * 8 = 32\"\n[1] \"4 * 9 = 36\"\n[1] \"5 * 1 = 5\"\n[1] \"5 * 2 = 10\"\n[1] \"5 * 3 = 15\"\n[1] \"5 * 4 = 20\"\n[1] \"5 * 5 = 25\"\n[1] \"5 * 6 = 30\"\n[1] \"5 * 7 = 35\"\n[1] \"5 * 8 = 40\"\n[1] \"5 * 9 = 45\"\n[1] \"6 * 1 = 6\"\n[1] \"6 * 2 = 12\"\n[1] \"6 * 3 = 18\"\n[1] \"6 * 4 = 24\"\n[1] \"6 * 5 = 30\"\n[1] \"6 * 6 = 36\"\n[1] \"6 * 7 = 42\"\n[1] \"6 * 8 = 48\"\n[1] \"6 * 9 = 54\"\n[1] \"7 * 1 = 7\"\n[1] \"7 * 2 = 14\"\n[1] \"7 * 3 = 21\"\n[1] \"7 * 4 = 28\"\n[1] \"7 * 5 = 35\"\n[1] \"7 * 6 = 42\"\n[1] \"7 * 7 = 49\"\n[1] \"7 * 8 = 56\"\n[1] \"7 * 9 = 63\"\n[1] \"8 * 1 = 8\"\n[1] \"8 * 2 = 16\"\n[1] \"8 * 3 = 24\"\n[1] \"8 * 4 = 32\"\n[1] \"8 * 5 = 40\"\n[1] \"8 * 6 = 48\"\n[1] \"8 * 7 = 56\"\n[1] \"8 * 8 = 64\"\n[1] \"8 * 9 = 72\"\n[1] \"9 * 1 = 9\"\n[1] \"9 * 2 = 18\"\n[1] \"9 * 3 = 27\"\n[1] \"9 * 4 = 36\"\n[1] \"9 * 5 = 45\"\n[1] \"9 * 6 = 54\"\n[1] \"9 * 7 = 63\"\n[1] \"9 * 8 = 72\"\n[1] \"9 * 9 = 81\"\n\n\n　上のコードがどのような処理をしているか考えてみよう。まず、iに1が代入される。次に、jに1から9までの数順番に1つずつ代入され、1 * 1、1 * 2、1 * 3、…、1 * 9が計算される。1 * 9の計算が終わったら、iに2が代入される。そして再び内側のforループが実行され、2 * 1、2 * 2、2 * 3、…、2 * 9が計算される。これを9の段まで繰り返す。段の順番を降順にして9の段を最初に計算し、1の段を最後に計算したい場合は、i in 1:9をi in 9:1に変えればよい。\n\nfor (i in 9:1) {\n  for (j in 1:9) {\n    print(paste(i, \"*\", j, \"=\", i * j))\n  }\n}\n\n[1] \"9 * 1 = 9\"\n[1] \"9 * 2 = 18\"\n[1] \"9 * 3 = 27\"\n[1] \"9 * 4 = 36\"\n[1] \"9 * 5 = 45\"\n[1] \"9 * 6 = 54\"\n[1] \"9 * 7 = 63\"\n[1] \"9 * 8 = 72\"\n[1] \"9 * 9 = 81\"\n[1] \"8 * 1 = 8\"\n[1] \"8 * 2 = 16\"\n[1] \"8 * 3 = 24\"\n[1] \"8 * 4 = 32\"\n[1] \"8 * 5 = 40\"\n[1] \"8 * 6 = 48\"\n[1] \"8 * 7 = 56\"\n[1] \"8 * 8 = 64\"\n[1] \"8 * 9 = 72\"\n[1] \"7 * 1 = 7\"\n[1] \"7 * 2 = 14\"\n[1] \"7 * 3 = 21\"\n[1] \"7 * 4 = 28\"\n[1] \"7 * 5 = 35\"\n[1] \"7 * 6 = 42\"\n[1] \"7 * 7 = 49\"\n[1] \"7 * 8 = 56\"\n[1] \"7 * 9 = 63\"\n[1] \"6 * 1 = 6\"\n[1] \"6 * 2 = 12\"\n[1] \"6 * 3 = 18\"\n[1] \"6 * 4 = 24\"\n[1] \"6 * 5 = 30\"\n[1] \"6 * 6 = 36\"\n[1] \"6 * 7 = 42\"\n[1] \"6 * 8 = 48\"\n[1] \"6 * 9 = 54\"\n[1] \"5 * 1 = 5\"\n[1] \"5 * 2 = 10\"\n[1] \"5 * 3 = 15\"\n[1] \"5 * 4 = 20\"\n[1] \"5 * 5 = 25\"\n[1] \"5 * 6 = 30\"\n[1] \"5 * 7 = 35\"\n[1] \"5 * 8 = 40\"\n[1] \"5 * 9 = 45\"\n[1] \"4 * 1 = 4\"\n[1] \"4 * 2 = 8\"\n[1] \"4 * 3 = 12\"\n[1] \"4 * 4 = 16\"\n[1] \"4 * 5 = 20\"\n[1] \"4 * 6 = 24\"\n[1] \"4 * 7 = 28\"\n[1] \"4 * 8 = 32\"\n[1] \"4 * 9 = 36\"\n[1] \"3 * 1 = 3\"\n[1] \"3 * 2 = 6\"\n[1] \"3 * 3 = 9\"\n[1] \"3 * 4 = 12\"\n[1] \"3 * 5 = 15\"\n[1] \"3 * 6 = 18\"\n[1] \"3 * 7 = 21\"\n[1] \"3 * 8 = 24\"\n[1] \"3 * 9 = 27\"\n[1] \"2 * 1 = 2\"\n[1] \"2 * 2 = 4\"\n[1] \"2 * 3 = 6\"\n[1] \"2 * 4 = 8\"\n[1] \"2 * 5 = 10\"\n[1] \"2 * 6 = 12\"\n[1] \"2 * 7 = 14\"\n[1] \"2 * 8 = 16\"\n[1] \"2 * 9 = 18\"\n[1] \"1 * 1 = 1\"\n[1] \"1 * 2 = 2\"\n[1] \"1 * 3 = 3\"\n[1] \"1 * 4 = 4\"\n[1] \"1 * 5 = 5\"\n[1] \"1 * 6 = 6\"\n[1] \"1 * 7 = 7\"\n[1] \"1 * 8 = 8\"\n[1] \"1 * 9 = 9\"\n\n\n　九九を覚えるときにはこれで良いが、実数どうしの掛け算で i * jとj * i は同じ（交換法則が成り立つ）なので、2つの数字の積を知りたいだけなら片方だけ出力すれば十分だろう。そこで、for (j in 1:9) を for (j in i:9) に変えてみよう。\n\nfor (i in 1:9) {\n  for (j in i:9) {\n    print(paste(i, \"*\", j, \"=\", i * j))\n  }\n}\n\n[1] \"1 * 1 = 1\"\n[1] \"1 * 2 = 2\"\n[1] \"1 * 3 = 3\"\n[1] \"1 * 4 = 4\"\n[1] \"1 * 5 = 5\"\n[1] \"1 * 6 = 6\"\n[1] \"1 * 7 = 7\"\n[1] \"1 * 8 = 8\"\n[1] \"1 * 9 = 9\"\n[1] \"2 * 2 = 4\"\n[1] \"2 * 3 = 6\"\n[1] \"2 * 4 = 8\"\n[1] \"2 * 5 = 10\"\n[1] \"2 * 6 = 12\"\n[1] \"2 * 7 = 14\"\n[1] \"2 * 8 = 16\"\n[1] \"2 * 9 = 18\"\n[1] \"3 * 3 = 9\"\n[1] \"3 * 4 = 12\"\n[1] \"3 * 5 = 15\"\n[1] \"3 * 6 = 18\"\n[1] \"3 * 7 = 21\"\n[1] \"3 * 8 = 24\"\n[1] \"3 * 9 = 27\"\n[1] \"4 * 4 = 16\"\n[1] \"4 * 5 = 20\"\n[1] \"4 * 6 = 24\"\n[1] \"4 * 7 = 28\"\n[1] \"4 * 8 = 32\"\n[1] \"4 * 9 = 36\"\n[1] \"5 * 5 = 25\"\n[1] \"5 * 6 = 30\"\n[1] \"5 * 7 = 35\"\n[1] \"5 * 8 = 40\"\n[1] \"5 * 9 = 45\"\n[1] \"6 * 6 = 36\"\n[1] \"6 * 7 = 42\"\n[1] \"6 * 8 = 48\"\n[1] \"6 * 9 = 54\"\n[1] \"7 * 7 = 49\"\n[1] \"7 * 8 = 56\"\n[1] \"7 * 9 = 63\"\n[1] \"8 * 8 = 64\"\n[1] \"8 * 9 = 72\"\n[1] \"9 * 9 = 81\"\n\n\nこのコードは、1の段は1 * 1から1 * 9 までのすべてを計算するが、2の段は2 * 2から、3の段は3 * 3から計算を始めて出力するコードである。2の段の場合、2 * 1は1の段で 1 * 2 が計算済みなのでスキップする。3の段の場合、3 * 1 は1の段で、3 * 2 は2の段でそれぞれ計算済みなのでとばす。 それぞれの段で同様の処理を続け、最後の9の段では9 * 9 のみが計算される。\n　このように多重forループは複数のベクトルの組み合わせて処理を行う場合に便利である。\n　複数のベクトルでなく、データフレームなどの2次元以上データにも多重forループは使われる。データフレームは複数のベクトルで構成されている（各列が1つのベクトル）ため、実質的には複数のベクトルを扱うことになる。\n　例として、FIFA_Men.csv を利用し、それぞれの国のチーム名、FAFAランキング、ポイントをまとめて表示するコードを書いてみよう。すべてのチームを表示すると結果が長くなるので、対象をOFC (オセアニアサッカー連盟) 所属チームに限定する。\n\n# read_csv()を使用するために{tidyverse}を読み込む\npacman::p_load(tidyverse)\n# FIFA_Men.csvを読み込み、myDFという名で保存\nmy_df <- read_csv(\"Data/FIFA_Men.csv\")\n# my_dfのConfederation列がOFCの行だけを抽出\nmy_df <- my_df[my_df$Confederation == \"OFC\", ]\n\nmy_df\n\n# A tibble: 10 × 6\n      ID Team              Rank Points Prev_Points Confederation\n   <dbl> <chr>            <dbl>  <dbl>       <dbl> <chr>        \n 1     4 American Samoa     192    900         900 OFC          \n 2    69 Fiji               163    996         996 OFC          \n 3   135 New Caledonia      156   1035        1035 OFC          \n 4   136 New Zealand        122   1149        1149 OFC          \n 5   147 Papua New Guinea   165    991         991 OFC          \n 6   159 Samoa              194    894         894 OFC          \n 7   171 Solomon Islands    141   1073        1073 OFC          \n 8   185 Tahiti             161   1014        1014 OFC          \n 9   191 Tonga              203    862         862 OFC          \n10   204 Vanuatu            163    996         996 OFC          \n\n\nOFCに10チーム加盟していることがわかる。\n　以下のような内容が表示されるコードを書きたい。\n=====1番目のチーム情報=====\nTeam: American Samoa\nRank: 192\nPoints: 900\n=====2番目のチーム情報=====\nTeam: Fiji\nRank: 163\nPoints: 996\n=====3番目のチーム情報=====\nTeam: New Caledonia\n...\nこれは1つのforループでも作成できるが、勉強のために2つのforループを使って書いてみよう。\n\nfor (i in 1:nrow(my_df)) {\n  print(paste0(\"=====\", i, \"番目のチーム情報=====\"))\n  \n  for (j in c(\"Team\", \"Rank\", \"Points\")) {\n    print(paste0(j, \": \", my_df[i, j]))\n  }\n}\n\n以上のコードを実行すると以下のような結果が表示される（全部掲載すると長くなるので、ここでは最初の2チームのみ掲載する。\n\n\n[1] \"=====1番目のチーム情報=====\"\n[1] \"Team: American Samoa\"\n[1] \"Rank: 192\"\n[1] \"Points: 900\"\n[1] \"=====2番目のチーム情報=====\"\n[1] \"Team: Fiji\"\n[1] \"Rank: 163\"\n[1] \"Points: 996\"\n\n\nこのコードについて説明しよう。まず、外側のforループでは任意の変数としてインデクスiを、内側のforループではインデクスjを使っている。Rは、コードを上から順番に処理する（同じ行なら、カッコの中から処理する）。したがって、まず処理されるのは外側のforループである。iにはベクトル1:nrow(my_df)の要素が順番に割り当てられる。nrow() は行列またはデータフレームの行数を求める関数で、my_dfは10行のデータなので1:10になる。つまり、外側のforループはiに1, 2, 3, …, 10の順で値を格納しながらループ内の処理を繰り返す。ここで、外側のforループの中身を見てみよう。まず、print() を使って \"=====i番目のチーム情報=====\" というメッセージを出力している。最初はiが1なので、\"=====1番目のチーム情報=====\"が表示される。\n　次に実行されるのが内側のforループである。ここではjにc(\"Team\", \"Rank\", \"Points\")を格納しながら内側のforループの内のコードをが3回繰り返し処理される。内側のコードの内容は、たとえば、i = 1の状態で、j = \"Team\"なら、print(paste0(\"Team\", \": \", my_df[1, \"Team\"]))である。第9.4章で説明した通り、my_df[1, \"Team\"]はmy_dfのTeam 列の1番目の要素を意味する。この処理が終わると、次はjに\"Rank\"が代入され、同じコードを処理する。そして、j = \"Points\"まで処理が終わったら、内側のforループは一度終了する。\n　内側のforループが終わっても、外側のforループはまだ終わっていない。次は、i に 2 が格納され、\"=====2番目のチーム情報=====\" を表示し、再度内側のforループを最初から処理する。 i = 10の状態で内側のforループが終了ると外側のforループも終了する。多重forループはこのように反復処理を実行する。\n　チーム名の次に所属連盟も表示したいときはどう直せば良いだろうか。正解はc(\"Team\", \"Rank\", \"Points\")のベクトルで、\"Team\"と\"Rank\"の間に\"Confederation\"を追加するだけである。実際にやってみよう (スペースの関係上、最初の2チームの結果のみ掲載する)。\n\nfor (i in 1:nrow(my_df)) {\n  print(paste0(\"=====\", i, \"番目のチーム情報=====\"))\n  \n  for (j in c(\"Team\", \"Confederation\", \"Rank\", \"Points\")) {\n    print(paste0(j, \": \", my_df[i, j]))\n  }\n}\n\n\n\n[1] \"=====1番目のチーム情報=====\"\n[1] \"Team: American Samoa\"\n[1] \"Confederation: OFC\"\n[1] \"Rank: 192\"\n[1] \"Points: 900\"\n[1] \"=====2番目のチーム情報=====\"\n[1] \"Team: Fiji\"\n[1] \"Confederation: OFC\"\n[1] \"Rank: 163\"\n[1] \"Points: 996\"\n\n\n　ちなみに、1つのforループで同じ結果を実現するには次のようにする。結果は掲載しないが、自分で試してみてほしい。また、cat()関数の使い方については?catを参照されたい。ちなみに\\nは改行コードである。\n\nfor (i in 1:nrow(my_df)) {\n  cat(paste0(\"=====\", i, \"番目のチーム情報=====\\n\"))\n  cat(paste0(\"Team:\",   my_df$Team[i], \"\\n\",\n             \"Rank:\",   my_df$Rank[i], \"\\n\",\n             \"Points:\", my_df$Points[i], \"\\n\"))\n}\n\n　リスト型を対象とした多重forループの例も確認しておこう。複数のベクトルを含むリストの場合、3番目のベクトルの5番目の要素を抽出するには、リスト名[[3]][5] のように2つの位置を指定する必要がある。たとえば、3人で構成されたグループが3つあり、それぞれのグループにおける id （例：学籍番号）の順番で名前が格納されている my_listを考えてみよう。\n\nmy_list <- list(A = c(\"Song\", \"Wickham\", \"Yanai\"),\n                B = c(\"Watanabe\", \"Toyoshima\", \"Fujii\"),\n                C = c(\"Abe\", \"Moon\", \"Xi\"))\n\nここで、まず各クラスの出席番号1番の人の名字をすべて出力し、次は2番の人、最後に3番の人を表示するにはどうすれば良いだろうか。以下のコードを見てみよう。\n\nfor (i in 1:3) {\n  \n  for (j in names(my_list)) {\n    print(my_list[[j]][i])\n  }\n  \n  print(paste0(\"===ここまでが出席番号\", i, \"番の人です===\"))\n}\n\n[1] \"Song\"\n[1] \"Watanabe\"\n[1] \"Abe\"\n[1] \"===ここまでが出席番号1番の人です===\"\n[1] \"Wickham\"\n[1] \"Toyoshima\"\n[1] \"Moon\"\n[1] \"===ここまでが出席番号2番の人です===\"\n[1] \"Yanai\"\n[1] \"Fujii\"\n[1] \"Xi\"\n[1] \"===ここまでが出席番号3番の人です===\"\n\n\nこのコードは以下のように動く。\n\n1行目: 任意の変数をiとし、1から3までの数字をiに格納しながら、3回反復作業を行う。\n3行目: 任意の変数をjとし、ここにはリストの要素名（A, B, C）を格納しながら、リストの長さだけ処理を繰り返す。names(my_list)はc(\"A\", \"B\", \"C\")である。\n4行目: my_list[[j]][i]の内容を出力する。最初はi = 1、j = \"A\"なので、print(my_list[[\"A\"]][1])、つまり、my_listから\"A\"を取り出し、そこの1番目の要素を出力する\n7行目: 各ベクトルからi番目の要素を出力し、print(paste0(\"===ここまでが出席番号\", i, \"番の人です===\"))を実行する。iに次の要素を入れ、作業を反復する。iに格納する要素がなくなったら、反復を終了する。\n\n　多重forループは3重、4重にすることも可能だが、コードの可読性が低下するため、多くても3重、できれば最大二重までにしておいたほうがよい。3重以上にforループを重ねる場合は、内側のforループを後ほど解説する関数でまとめたほうがいいだろう。\n　上の例では、リストの各要素に名前 (A, B, C) が付けられていることを利用した。リストに名前がない場合はどうすれば良いだろうか（そもそも、名前のないリストなど作らないほうが良いのだが…）。例えば、次のような場合である。\n\nmy_list <- list(c(\"Song\", \"Wickham\", \"Yanai\"),\n                c(\"Watanabe\", \"Toyoshima\", \"Fujii\"),\n                c(\"Abe\", \"Moon\", \"Xi\"))\n\nこの場合には、次のようにすればよい。\n\nfor (i in 1:3) {\n  \n  for (j in seq_along(my_list)) {\n    print(my_list[[j]][i])\n  }\n  \n  print(paste0(\"===ここまでが出席番号\", i, \"番の人です===\"))\n}\n\n[1] \"Song\"\n[1] \"Watanabe\"\n[1] \"Abe\"\n[1] \"===ここまでが出席番号1番の人です===\"\n[1] \"Wickham\"\n[1] \"Toyoshima\"\n[1] \"Moon\"\n[1] \"===ここまでが出席番号2番の人です===\"\n[1] \"Yanai\"\n[1] \"Fujii\"\n[1] \"Xi\"\n[1] \"===ここまでが出席番号3番の人です===\"\n\n\n内側のforループでリストの要素名を使う代わりに、リストの要素を位置で指定している。\n\n10.3.2 whileによる反復\n　forによるループは任意の変数にベクトルの要素を1つずつ代入し、ベクトルの要素を使い尽くすまで反復処理を行う。したがって、ベクトルの長さによってループの回数が決まる。\n　それに対し、「ある条件が満たされる限り、反復し続ける」あるいは「ある条件が満たされるまで、反復し続ける」ことも可能である。そのときに使うのが、whileによる whileループである。whileループの書き方はforループにとてもよく似ている。\n　基本的な使い方は、以下のとおりである。\nwhile (条件) {\n  条件が満たされた場合の処理内容\n}\nforがwhileに変わり、()内の書き方が(任意の変数 in ベクトル)から(条件)に変わった。この()内の条件が満たされる間は{}内の内容を処理が繰り返し実行される。1から5までの整数を表示するコードは、forループを使うと次のように書ける。\n\nfor (i in 1:5) {\n  print(i)\n}\n\n　これをwhileループを使って書き直すと、次のようになる。\n\ni <- 1\nwhile (i < 6) {\n  print(i)\n  i <- i + 1\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nwhileループを繰り返す条件はi < 6である。これにより、「iが6未満」なら処理が繰り返される。注意すべき点として、i が6未満か否かの判断をループの開始時点で行うので、あらかじめ変数 i を用意する必要があることがあげられる。1行めにある i <- 1 がそれである。そして、{}内の最終行に i <- i + 1 があり、iを1ずつ増やしている。i = 5 の時点では print(i) が実行されるが、i = 6になると、ループをもう1ど実行する条件が満たされないので、反復が停止する。\n　i <- i + 1のように内容を少しずつ書き換えるさいは、そのコードを置く位置にも注意が必要だ。先ほどのコードのうち、i <- i + 1 を print(i)の前に移動してみよう。\n\ni <- 1\n\nwhile (i < 6) {\n  i <- i + 1\n  print(i)\n}\n\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n\n\n2から6までの整数が出力された。これはiを出力する前にiに1が足されるためである。i <- i + 1の位置をこのままにして、先ほどと同じように1から5までの整数を表示するには、次のようにコードを書き換える。\n\ni <- 0\n\nwhile (i < 5) {\n  i <- i + 1\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\n変更点したのは、\n1.iの初期値を0にした 2. ()内の条件を(i < 6)から(i < 5)にした\nという2点である。\n　whileループは慣れないとややこしいと感じるだろう。forループで代替できるケースも多い。それでもwhile文が必要になるケースもある。それは先述した通り、「目標は決まっているが、その目標が達成されるまでは処理を何回繰り返せばいいか分からない」場合である。\n　たとえば、6面のサイコロ投げを考えよう。投げる度に出た目を記録し、その和が30以上に達したときサイコロ投げを中止するにはどうすればいいだろうか。何回サイコロを投げればいいかがあらかじめわからないと、forループは使えない。連続で6が出るなら5回で十分かもしれないが、1が出続けるなら30回投げる必要がある。このように、「反復処理は行うが、何回行えばいいか分からない。ただし、停止条件は知っている」場合にwhileループを使う。\n　サイコロ投げの例は、以下のコードで実行できる。\n\ntotal <- 0\ntrial <- 1\n\nwhile (total < 30) {\n  die  <- sample(1:6, size = 1)\n  total <- total + die\n  \n  print(paste0(trial, \"回目のサイコロ投げの結果: \", die,\n               \"（これまでの総和: \", total, \"）\"))\n  \n  # print()文は以下のような書き方も可能\n  # Result <- sprintf(\"%d回目のサイコロ投げの結果: %d （これまでの総和: %d）\", \n  #                   trial, die, total)\n  # print(Result)\n  \n  trial <- trial + 1\n}\n\n[1] \"1回目のサイコロ投げの結果: 3（これまでの総和: 3）\"\n[1] \"2回目のサイコロ投げの結果: 4（これまでの総和: 7）\"\n[1] \"3回目のサイコロ投げの結果: 6（これまでの総和: 13）\"\n[1] \"4回目のサイコロ投げの結果: 6（これまでの総和: 19）\"\n[1] \"5回目のサイコロ投げの結果: 5（これまでの総和: 24）\"\n[1] \"6回目のサイコロ投げの結果: 1（これまでの総和: 25）\"\n[1] \"7回目のサイコロ投げの結果: 3（これまでの総和: 28）\"\n[1] \"8回目のサイコロ投げの結果: 2（これまでの総和: 30）\"\n\n\nこのコードの中身を説明しよう。まず、これまで出た目の和を記録する変数totalを用意し、初期値として0を格納する。また、何回目のサイコロ投げかを記録するためにtrialという変数を用意し、初期値として1を格納する（コードの1、2行目）。\n　次に、while文を書く。反復する条件はtotalが30未満と設定する。つまり、totalが30以上になったら反復を終了する（コードの4行目）。\n　続いて、サイコロを投げ、出た目をdieという変数に格納します。サイコロ投げは1から6の間の整数から無作為に1つを値を抽出することでシミュレートできる。そこで使われるのが sample()関数である（コードの5行目）。sample() 関数は与えられたベクトル内の要素を無作為に抽出する。sample(c(1, 2, 3, 4, 5, 6), size = 1)は「c(1, 2, 3, 4, 5, 6)から1つの要素を無作為に抽出せよ」という意味である（乱数生成を利用したシミュレーションについては後の章で詳しく説明する）。サイコロの目が出たら、その目をtotalの値に足す (コードの6行目)。\n　その後、「1回目のサイコロ投げの結果: 5 (これまでの総和: 5)」のように、1回の処理の結果を表示する。 (コードの8行目)。最後にtrialの値を1増やし (コードの14行目)、1度の処理が終了する。\n　1度の処理が終わったら、whileループの条件判断に戻り、条件が満たされていれば再び処理を繰り返す。これを条件が満たされなくなるまで繰り返す。\n　この反復処理は、forループで再現することもできる。次のようにすればよい。\n\ntotal <- 0\n\nfor (trial in 1:30) {\n  die  <- sample(1:6, 1)\n  total <- total + die\n  \n  # print()の代わりにsprintf()を使うことも可能\n  result <- sprintf(\"%d回目のサイコロ投げの結果: %d （これまでの総和: %d）\",\n                    trial, die, total)\n  print(result)\n  \n  if (total >= 30)  break() # ()は省略可能\n}\n\n[1] \"1回目のサイコロ投げの結果: 5 （これまでの総和: 5）\"\n[1] \"2回目のサイコロ投げの結果: 2 （これまでの総和: 7）\"\n[1] \"3回目のサイコロ投げの結果: 3 （これまでの総和: 10）\"\n[1] \"4回目のサイコロ投げの結果: 6 （これまでの総和: 16）\"\n[1] \"5回目のサイコロ投げの結果: 4 （これまでの総和: 20）\"\n[1] \"6回目のサイコロ投げの結果: 4 （これまでの総和: 24）\"\n[1] \"7回目のサイコロ投げの結果: 5 （これまでの総和: 29）\"\n[1] \"8回目のサイコロ投げの結果: 6 （これまでの総和: 35）\"\n\n\nこのコードの中身を説明しよう。事前にサイコロを投げる回数はわからないが、6面サイコロの場合30回以内には必ず合計が30になるので、trial in 1:30としておく。あとはwhileループの書き方とほぼ同じだが、forループではiが自動的に更新されるのでi <- i + 1は不要である。さらに、一定の条件が満たされるときにループを停止する必要がある。そこで登場するのが条件 if とbreak()である。条件分岐は次節で説明するが、ifから始まる行のコードは、「totalが30以上になったらループから脱出せよ」ということを意味する。このようにループからの脱出を指示する関数が break()だ。break() 関数は()を省略して breakと書いてもよい。\n　これは余談だが、結果の表示に今回はこれまで使ってきたprint()とpaste0()（またはpaste()）の代わりに、sprintf()を使っている。sprintf() 内の%dはその位置に指定された変数の値を整数として代入することを意味する。sprintf()にの引数にはまず出力する文字列を指定し、次に代入する変数を順番に入力する。%sは文字 (string) 型、%fは実数 (floating-point number) を意味する。%fでは小数の桁数も指定可能であり、小数第2位まで表示させるには %.2f のように表記する。以下のコードは3つの変数の値と文字列を結合する処理をprint(paste0())とsprintf()を用いて書いたもので、同じ結果が得られる。\n\nname   <- \"Song\"\nbowls  <- 50\nheight <- 176.2\n\nprint(paste0(name, \"がひと月に食べるラーメンは\", bowls, \"杯で、身長は\", height, \"cmです。\"))\n\n[1] \"Songがひと月に食べるラーメンは50杯で、身長は176.2cmです。\"\n\n# %sにnameを、%dにbowlsを、%.1fにheightを小数第1位まで格納し、出力\nsprintf(\"%sがひと月に食べるラーメンは%d杯で、身長は%.1fcmです。\", name, bowls, height)\n\n[1] \"Songがひと月に食べるラーメンは50杯で、身長は176.2cmです。\"\n\n\nただし、{}内のsprintf()はそのまま出力されないため、一旦、オブジェクトとして保存し、それをprint()を使って出力する必要がある。詳細については、?sprintfを参照されたい。\n　今回例として挙げたサイコロ投げは「多くても30回以内に終わる」ことが分かっていたの forループで書き換えることができた。しかし、終了までに必要な反復回数は未知であることもある。目的に応じて forとwhileを使い分けることが求められる。"
  },
  {
    "objectID": "programming.html#RN4Esec-programming_condition",
    "href": "programming.html#RN4Esec-programming_condition",
    "title": "10  Rプログラミングの基礎",
    "section": "\n10.4 条件分岐",
    "text": "10.4 条件分岐\n\n10.4.1 if、else if、else による条件分岐\nこの節では条件分岐について説明する。条件分岐は、条件に応じて異なる処理を行いときに利用する。if による条件分岐の基本形は次のとおりである。\nif (条件) {\n  条件が満たされた場合のみ実行される処理の内容\n}\nwhileを使ったループによく似ているが、while文は条件が満たされる限り{}の内容を繰り返し実行するのに対し、if 文では条件が満たされれときに{}の内容が1回だけ実行されて処理が終了するという違いがある。たとえば、名前が格納されているオブジェクトnameの中身が\"Song\"なら「ラーメン大好き」と出力されるコードを考えてみよう。\n\nname <- \"Song\"\n\nif (name == \"Song\") {\n  print(\"ラーメン大好き\")\n}\n\n[1] \"ラーメン大好き\"\n\n\nif文の ()内の条件は、「nameの中身が\"Song\"」の場合のみ{}内の処理を実行せよということを意味する。nameの中身が\"Yanai\"ならどうなるだろうか。\n\nname <- \"Yanai\"\n\nif (name == \"Song\") {\n  print(\"ラーメン大好き\")\n}\n\n何も表示されない。このように、if文単体だと、条件が満たされない場合には何も実行されない。\n条件にに応じて異なる処理を実行するために、else を使う。これはifとセットで使われるもので、ifの条件が満たされなかった場合の処理内容を指定することができる。elseを加えると、次のようなコードが書ける。\nif (条件) {\n  条件が満たされた場合の処理内容\n} else {\n  条件が満たされなかった場合の処理内容\n}\nelse文は、以下のように改行して書くこともできる。\nif (条件) {\n  条件が満たされた場合の処理内容\n} \nelse {\n  条件が満たされなかった場合の処理内容\n}\nしかし、この書き方はあまり良くない。else は必ず if とセットで用いられるので、if の処理の終わりである } の直後に半角スペースを1つ挟んで書くのが標準的なコーディングスタイルである。\n　それでは nameが\"Song\"でない場合には、「ラーメン好きじゃない」表示されるコードを書いてみよう。\n\nname <- \"Song\"\n\nif (name == \"Song\") {\n  print(\"ラーメン大好き\")\n} else {\n  print(\"ラーメン好きじゃない\")\n}\n\n[1] \"ラーメン大好き\"\n\n\nnameが\"Song\"の場合、前と変わらず「ラーメン大好き」が出力される。nameを\"Yanai\"に変えてみよう。\n\nname <- \"Yanai\"\n\nif (name == \"Song\") {\n  print(\"ラーメン大好き\")\n} else {\n  print(\"ラーメン好きじゃない\")\n}\n\n[1] \"ラーメン好きじゃない\"\n\n\n「ラーメン好きじゃない」が表示される。\n　しかし、世の中はと「ラーメン大好き」と「ラーメン好きじゃない」のみで構成されているわけではない。「ラーメン大好き」なのはSong と Koike、「ラーメン好きじゃない」のは Yanai のみで、それ以外の人は「ラーメンそこそこ好き」だとしよう。つまり3つのパタンがある。それぞれに別の処理を実行するには、3つ以上の条件に対応できる条件分岐が必要になる。\n　そのような場合には else ifをifとelseの間に挿入する。\nif (条件1) {\n  条件1が満たされた場合の処理内容\n} else if (条件2) {\n  条件1が満たされず、条件2が満たされた場合の処理内容\n} else if (条件3) {\n  条件1, 2が満たされず、条件3が満たされた場合の処理内容\n} else {\n  条件が全て満たされなかった場合の処理内容\n}\nこのように条件分岐を書くと、if文の条件が満たされれば最初の{}内の処理を実行し、満たされなかったら次のelse ifの条件を判定する。その条件が満たされれば{}の処理を実行し、満たされなければ次のelse ifへ移動…を順に実施する。どの条件も満たされないときは、最終的に else の内容が実行される。\n　それでは実際にコードを書いてみよう。\n\nname <- \"Song\"\n\nif (name == \"Song\" | name == \"Koike\") {\n  # 上の条件は、(name %in% c(\"Song\", \"Koike\"))  でもOK\n  print(\"ラーメン大好き\")\n} else if (name == \"Yanai\") {\n  print(\"ラーメン好きじゃない\")\n} else {\n  print(\"ラーメンそこそこ好き\")\n}\n\n[1] \"ラーメン大好き\"\n\n\nこのコードでは、まずnameが\"Song\" または \"Koike\" か否かを判定し、TRUEなら「ラーメン大好き」を表示する。FALSE なら次の else if文へ移動する。ここではNameが\"Yanai\"かどうかを判定する。\n　最初の条件に登場する |は「OR （または）」を意味する論理演算子であり、第6章で解説した。このように、条件の中で|や&などの論理演算子を使うことで、複数の条件を指定することができる。また、name == \"Song\" | name == \"Koike\"はname %in% c(\"Song\", \"Koike\")に書き換えることがでる。x %in% yはxがyに含まれているか否かを判定する演算子である。たとえば、\"A\" %in% c(\"A\", \"B\", \"C\")の結果はTRUEだが、\"Z\" %in% c(\"A\", \"B\", \"C\")の結果はFALSEになる。\n　それではnameを\"Yanai\"、\"Koike\"、\"Shigemura\"、\"Hakiai\"に変えながら結果を確認してみよう。\n\nname <- \"Yanai\"\n\nif (name %in% c(\"Song\", \"Koike\")) {\n  print(\"ラーメン大好き\")\n} else if (name == \"Yanai\") {\n  print(\"ラーメン好きじゃない\")\n} else {\n  print(\"ラーメンそこそこ好き\")\n}\n\n[1] \"ラーメン好きじゃない\"\n\n\n\nname <- \"Koike\"\n\nif (name %in% c(\"Song\", \"Koike\")) {\n  print(\"ラーメン大好き\")\n} else if (name == \"Yanai\") {\n  print(\"ラーメン好きじゃない\")\n} else {\n  print(\"ラーメンそこそこ好き\")\n}\n\n[1] \"ラーメン大好き\"\n\n\n\nname <- \"Shigemura\"\n\nif (name %in% c(\"Song\", \"Koike\")) {\n  print(\"ラーメン大好き\")\n} else if (name == \"Yanai\") {\n  print(\"ラーメン好きじゃない\")\n} else {\n  print(\"ラーメンそこそこ好き\")\n}\n\n[1] \"ラーメンそこそこ好き\"\n\n\n\nname <- \"Hakiai\"\n\nif (name %in% c(\"Song\", \"Koike\")) {\n  print(\"ラーメン大好き\")\n} else if (name == \"Yanai\") {\n  print(\"ラーメン好きじゃない\")\n} else {\n  print(\"ラーメンそこそこ好き\")\n}\n\n[1] \"ラーメンそこそこ好き\"\n\n\n　if文が単独で使われることもそれほど多くない。if文は主に反復処理を行うforループまたはwhile()ループの中、もしくは次節で説明する自作関数内に使われることが多い。上の例では名前からラーメンに対する情熱を判定するために何度も同じコードを書いてきたが、同じコードを繰り返し書くのは効率が悪い。繰り返し行う作業を関数としてまとめれば便利である。関数の作成については第11章で説明する。\n　ここではforループと条件分岐の組み合わせについて考えてみよう。学生10人の成績が入っているベクトルscoresがあるとしよう。そして、成績が60点以上なら「合格」を、未満なら「不合格」を返すようなコードを書く。この作業を効率的に行うために、 forループとif文を組み合わせる方法を考える。forループではインデクス変数iに1から10までの数字を代入することを繰り返す。ここでの10はベクトルscoresの長さなので、seq_along() を使う。そして、scoresのi番目要素に対して60点以上か否かの判定を行い、「合格」または「不合格」という結果を返す。\n　以上の内容を実行するコードは、次のように書ける。\n\nscores <- c(58, 100, 81, 97, 71, 61, 47, 60, 73, 85)\n\nfor (i in seq_along(scores)) {\n  if (scores[i] >= 60) {\n    print(paste0(\"学生\", i, \"の判定結果: 合格\"))\n  } else {\n    print(paste0(\"学生\", i, \"の判定結果: 不合格\"))\n  }\n}\n\n[1] \"学生1の判定結果: 不合格\"\n[1] \"学生2の判定結果: 合格\"\n[1] \"学生3の判定結果: 合格\"\n[1] \"学生4の判定結果: 合格\"\n[1] \"学生5の判定結果: 合格\"\n[1] \"学生6の判定結果: 合格\"\n[1] \"学生7の判定結果: 不合格\"\n[1] \"学生8の判定結果: 合格\"\n[1] \"学生9の判定結果: 合格\"\n[1] \"学生10の判定結果: 合格\"\n\n\nこのコードは、以下の処理を行っている。\n\n1行目: まず、ベクトルscoresを定義する。\n3行目: for文でループを作る。任意の変数としてインデクスiを使う。ベクトルの各要素をのインデクスを入れ替えながら反復を行います。したがって、i in 1:10でも問題ないが、ここではi in seq_along(scores)を利用する。こうすることで、scoresベクトルの長さが変わっても、forの内容を修正する必要がなくなる。\n4, 5行目: scoresのi番目要素が60点以上かどうかを判定し、TRUEなら「学生iの判定結果: 合格」を表示する。\n6-8行目: scores のi番目要素が60点以上でない場合、「学生iの判定結果: 不合格」を表示する。\n\nprint()内でpaste0()を使うとコードの可読性がやや落ちるので、sprintf()を使ってもよいかもしれない（後で説明するパイプ演算子 %>% を使えば、可読性の問題は解決する）。\n\nscores <- c(58, 100, 81, 97, 71, 61, 47, 60, 73, 85)\n\nfor (i in seq_along(scores)) {\n  if (scores[i] >= 60) {\n    result <- sprintf(\"学生%dの判定結果: 合格\", i)\n  } else {\n    result <- sprintf(\"学生%dの判定結果: 不合格\", i)\n  }\n  \n  print(result)\n}\n\n[1] \"学生1の判定結果: 不合格\"\n[1] \"学生2の判定結果: 合格\"\n[1] \"学生3の判定結果: 合格\"\n[1] \"学生4の判定結果: 合格\"\n[1] \"学生5の判定結果: 合格\"\n[1] \"学生6の判定結果: 合格\"\n[1] \"学生7の判定結果: 不合格\"\n[1] \"学生8の判定結果: 合格\"\n[1] \"学生9の判定結果: 合格\"\n[1] \"学生10の判定結果: 合格\"\n\n\n　次に、結果を出力するのではなく、結果を別のベクトルに格納する例を考えてみよう。あらかじめ scores と同じ長さの空ベクトルpfを用意します。ここに各学生について合否判定の結果を「合格」または「不合格」として格納する処理を行う。以下のようなコードが書ける。\n\nscores <- c(58, 100, 81, 97, 71, 61, 47, 60, 73, 85)\npf     <- rep(NA, length(scores))\n\nfor (i in seq_along(scores)) {\n  if (scores[i] >= 60) {\n    pf[i] <- \"合格\"\n  } else {\n    pf[i] <- \"不合格\"\n  }\n}\n\nこのコードでは、scores を定義した後、中身がNAのみで構成される長さがscores と同じベクトルpfを定義する。rep(NA, length(scores))はNAをlength(Scores)個（ここでは10個）並べたベクトルを生成する。 続いて、点数によって条件分岐を行い、メッセージを出力するのではなく、pfのi番目に\"合格\"か\"不合格\"を入れる。結果を確認してみよう。\n\npf\n\n [1] \"不合格\" \"合格\"   \"合格\"   \"合格\"   \"合格\"   \"合格\"   \"不合格\" \"合格\"  \n [9] \"合格\"   \"合格\"  \n\n\n　このように、if文は反復処理を行うforループまたはwhileループと組み合わせることでその本領を発揮する。実は、今回の例については次に説明するifelse()を使えば1行で処理することができる。しかし、複雑な処理を伴う反復と条件分岐を組み合わせるには、今回のようにforループとif文を組み合わせるのが有効である。\n\n10.4.2 ifelse()による条件分岐\nifelse()は与えられたベクトル内の各要素に対して条件分岐を行い、それをベクトルの全要素について繰り返す関数である。簡単な条件分岐と反復処理を同時に行う非常に便利な関数である。ifelse()の基本的な書き方は以下のとおり。\nifelse(条件, 条件がTRUEの場合の処理、条件がFALSEの場合の処理)\n　たとえば、学生10人の成績が入っているベクトルscoresに対し、60点以上の場合に合格 (\"Pass\")、60点未満の場合に不合格 (\"Fail\") の値を割り当て、pfというベクトルに格納しよう。\n\nscores <- c(58, 100, 81, 97, 71, 61, 47, 60, 73, 85)\npf <- ifelse(scores >= 60, \"Pass\", \"Fail\")\npf\n\n [1] \"Fail\" \"Pass\" \"Pass\" \"Pass\" \"Pass\" \"Pass\" \"Fail\" \"Pass\" \"Pass\" \"Pass\"\n\n\n条件はscoresの値が60以上か否かであり、60以上なら\"Pass\"を、それ以外なら\"Fail\"を返す。\n　返す値として新しい値を与える代わりに、一定の条件が満たされたら現状の値を保持し、それ以外なら指定した値に変更して返すこともできる。たとえば、世論調査では以下のように「答えたくない」または「わからない」を9や99などで記録することが多い。この値はこのままでは分析するのが難しいので、欠損値として扱いたいことがある。例として、次の質問を考えよう。\nQ. あなたはラーメンが好きですか。\n\n1.大好き\n2.そこそこ好き\n3.好きではない\n9.答えたくない\n\nこの質問に対する10人の回答が格納されたデータフレーム (Ramen) があるとしよう。このデータフレームには2つの列があり、id 列は回答者のID（識別番号）、ramen 列にはは上の質問に対する答えが入ってる。\n\nRamen <- data.frame(\n  id    = 1:10,\n  ramen = c(1, 1, 2, 1, 3, 1, 9, 2, 1, 9)\n)\n\n\nRamen\n\n   id ramen\n1   1     1\n2   2     1\n3   3     2\n4   4     1\n5   5     3\n6   6     1\n7   7     9\n8   8     2\n9   9     1\n10 10     9\n\n\n　このramen列に対し、ramen == 9ならNAを割り当て、それ以外の場合は元の値をそのまま残したいとしよう。そしてその結果をRamenのramen列に上書する。これは次のコードで実行できる。\n\nRamen$ramen <- ifelse(Ramen$ramen == 9, NA, Ramen$ramen)\nRamen\n\n   id ramen\n1   1     1\n2   2     1\n3   3     2\n4   4     1\n5   5     3\n6   6     1\n7   7    NA\n8   8     2\n9   9     1\n10 10    NA\n\n\n　3つ以上のパタンに分岐させたいときは、ifelse()の中でifelse()を使うこともできる。scoresベクトルの例を考えてよう。ここで90点以上ならS、80点以上ならA、70点以上ならB、60点以上ならCを割り当て、それ以外はFを返すことにしよう。そして、その結果をgrade という変数に格納してみよう。\n\ngrade <- ifelse(scores >= 90, \"S\", \n                ifelse(scores >= 80, \"A\",\n                       ifelse(scores >= 70, \"B\",\n                              ifelse(scores >= 60, \"C\", \"F\"))))\n\nこのコードでは、ifelse()の条件がFALSEの場合、次のifelse()での判定を行う。結果を確認しておこう。\n\ngrade\n\n [1] \"F\" \"S\" \"A\" \"S\" \"B\" \"C\" \"F\" \"C\" \"B\" \"A\"\n\n\n　この例からもわかるとおり、ifelse()を使いすぎるとコードの可読性が低くなるので、このようなコードはあまり推奨できない。複数の条件に応じて返す値を変える処理は、{dplyr}パッケージのcase_when()関数で行うのがよいだろう。この関数については、第13章で詳細に説明するが、ここでは上のコードと同じ処理を実施する例のみ示す。\n\ngrade2 <- dplyr::case_when(scores >= 90 ~ \"S\",\n                           scores >= 80 ~ \"A\",\n                           scores >= 70 ~ \"B\",\n                           scores >= 60 ~ \"C\",\n                           TRUE         ~ \"F\")\n\ngrade2\n\n [1] \"F\" \"S\" \"A\" \"S\" \"B\" \"C\" \"F\" \"C\" \"B\" \"A\"\n\n\n\n10.4.3 switch()による条件分岐\n　switch()は、与えられた長さ1の文字列11を用いた条件分岐を行う。これが単体で使われうことはほとんどなく、通常は関数のなかで使われる。したがって、初めて本書を読む場合はこの節を一旦とばし、第11章を読んだ後に必要に応じて戻ってきてほしい。\n　ここでは2つの数値xとyの加減乗除を行う関数m_calc という名前の関数を作る。この関数はx とy以外にoperationという引数をもち、このoperationの値によって行う処理が変わる。たとえば、operation = \"+\"なら足し算を、operation = \"*\"なら掛け算を行う。\n\nmy_calc <- function(x, y, operation) {\n  switch(operation,\n         \"+\" = x + y,\n         \"-\" = x - y,\n         \"*\" = x * y,\n         \"/\" = x / y,\n         stop(\"operation の値に使えるのは +, -, *, / のみです。\")\n         )\n}\n\nこのコードの中身を確認しよう。重要なのは2行目から8行目の部分である。switch()の最初の引数は条件を判定する長さ1のベクトルである。ここではこれがoperationである。そして、operationに指定される実引数の値によって異なる処理を行う。\"+\" = x + yは「operationの値が\"+\"なら、x + yを実行する」ことを意味する。これを他の演算子に対しても指定する。最後の引数は、どの条件にも合わない場合の処理である。ここでは, operation の値に使えるのは +, -, *, / のみです。\"というエラーメッセージを表示し、関数の実行を停止するために stop() 関数を指定している。\n　上のコードは、if、else if、 elseを使って書き換えることができる。\n\nmy_calc2 <- function(x, y, operation = c(\"+\", \"-\", \"*\", \"/\")) {\n  \n  operation <- match.arg(operation)\n  \n  if (operation == \"+\") {\n    return(x + y)\n  } else if (operation == \"-\") {\n    return(x - y)\n  } else if (operation == \"*\") {\n    return(x * y)\n  } else {\n    return(x / y)\n  } \n}\n\n先ほどと異なる点は、function()の中でoperationのデフォルト値をベクトルとしてした与えたことだ。これは「operation引数の値がこれらの値以外になることは許さない」ということを意味する。match.arg()関数は、operation引数が予め指定された引数の値と一致するか否かを判断する。指定された引数と一致しない場合、エラーを表示し、処理を中断する。ちなみに、match.arg()はswith()文と組み合わせて使うこともできる。\n　今回の例の場合、switch()を使ったほうがコードの内容がわかりやすく、読みやすいが、ifによる条件分岐でも十分に対応可能である。また、条件によって行う処理が複雑な場合にはswitch()よりもifのほうが使いやすい。\n　作った関数を使ってみよう。\n\nmy_calc(5, 3, operation = \"+\")\n\n[1] 8\n\nmy_calc(5, 3, operation = \"-\")\n\n[1] 2\n\nmy_calc(5, 3, operation = \"*\")\n\n[1] 15\n\nmy_calc(5, 3, operation = \"/\")\n\n[1] 1.666667\n\n\nでは\"+\"、\"-\"、\"*\"、\"/\"以外の値をoperationに与えるとうなるだろうか。ためしに\"^\"を入れてみよう。\n\nmy_calc(5, 3, operation = \"^\")\n\nError in my_calc(5, 3, operation = \"^\"): operation の値に使えるのは +, -, *, / のみです。\n\n\nstop()内に書いたエラーメッセージが表示され、処理が中止される。"
  },
  {
    "objectID": "programming.html#RN4Esec-programming_exercise",
    "href": "programming.html#RN4Esec-programming_exercise",
    "title": "10  Rプログラミングの基礎",
    "section": "\n10.5 練習問題",
    "text": "10.5 練習問題\n問1\n\n3つの6面サイコロ投げを考える。3つの目の和が15になるまでサイコロ投げを繰り返す。どのような目が出て、その合計はいくつか。そして、何回目のサイコロ投げかを表示するコードを　\n\n\nforループを用いて書きなさい\n\nwhileループを用いて書きなさい\n上の2つのコードが同じ結果を表示することを確認したうえで、どちらの方法がより効率的か考察しなさい。\n\n\n\n\n\n[1] \"1目のサイコロ投げの結果: 4, 2, 6 (合計: 12)\"\n[1] \"2目のサイコロ投げの結果: 5, 4, 1 (合計: 10)\"\n[1] \"3目のサイコロ投げの結果: 5, 6, 4 (合計: 15)\"\n\n\n問2\n\n以下のような長さ5の文字型ベクトルcauseがある。「肥満の原因はXXでしょう。」というメッセージを表示するコードを書きなさい。ただし、「XX」の箇所にはベクトルの各要素を代入すること。表示されるメッセージは5個でなければならない。\n\n\ncause <- c(\"喫煙\", \"飲酒\", \"食べすぎ\", \"寝不足\", \"ストレス\")\n\n\n\n[1] \"肥満の原因は喫煙でしょう。\"\n[1] \"肥満の原因は飲酒でしょう。\"\n[1] \"肥満の原因は食べすぎでしょう。\"\n[1] \"肥満の原因は寝不足でしょう。\"\n[1] \"肥満の原因はストレスでしょう。\"\n\n\n\n長さ4の文字型ベクトルeffectを以下のように定義する。このとき、「YYの原因はXXでしょう。」というメッセージを表示するコードを書きなさい。ただし、「YY」にはeffectの要素を、「XX」にはcauseの要素を代入すること。出力されるメッセージは20個でなければならない。\n\n\neffect <- c(\"肥満\", \"腹痛\", \"不人気\", \"金欠\")\n\n\n長さ3の文字型ベクトルsolutionを以下のように定義する。このとき、「YYの原因はXXですが、ZZ改善されるでしょう。」というメッセージを出力するコードを書きなさい。ただし、「YY」にはeffectの要素を、「XX」にはcauseの要素を、「ZZ」にはsolutionの要素を代入すること。出力されるメッセージは60個でなければならない。\n\n\nsolution <- c(\"この薬を飲めば\", \"一日一麺すれば\", \"神戸大に登山すれば\")\n\n問3\n\n長さ2のnumericベクトルdataについて考える。条件分岐を用いてdataの1番目の要素 (data[1]) が2番目の要素 (data[2]) より大きい場合、1番目の要素と2番目の順番を逆転させる条件分岐を作成せよ。たとえば、data <- c(5, 3)なら、条件分岐後のdataの値がc(3, 5)になるようにするコードを書きなさい。\n\n\n私たちのR 私たちのR 11  関数の自作 9  データ構造 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 10  Rプログラミングの基礎 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR\n\n\n\nChambers, John M. 2016. Extending r. Boca Raton, FL: CRC Press."
  },
  {
    "objectID": "functions.html#RN4Esec-func_intro",
    "href": "functions.html#RN4Esec-func_intro",
    "title": "11  関数の自作",
    "section": "\n11.1 関数の作成",
    "text": "11.1 関数の作成\n　これまでclass()や、sum()、print()など、様々な関数 (functions) を使ってきた。「Rで起こるあらゆることは関数の呼び出しである (Everything that happens in R is a function call)」(Chambers 2016) と言われるように、「Rを使う」ということは、「Rの関数を使う」ということである。\n　関数は関数名() ように括弧とセットで表記されることが多い。1つの関数でも、括弧の中に異なる引数を指定することで、さまざまな結果を出すことができる。例として、第6章でも説明したseq()関数について考えてみよう。この関数を使うと、一連の数字からなるベクトルを作ることができる。from で数列の初項を、to で数列の最終項を指定し、by で要素間の差（第2要素は第1要素に by を加えた値になる ）を指定するか、length.out で最終的にできるベクトルの要素の数を指定する。\n　Rを含むプログラミングにおける関数は、何かを入力すると何かを出力する箱のようなものである。関数を使うだけなら、関数という箱の中で何が起こっているかを理解する必要はない。例えば、mean() という関数に実数のベクトルを入力すると、平均値を実数として返すということを知っていれば、mean() が具体的にどのような計算を行っているかを知らなくても、実用上は問題ない。つまり、関数をブラックボックスとして扱うことができる。\nこのように1つの関数でも指定する内容は、by になったりlength.out になったりする。by や length.out、from、to などのように、関数で指定する対象になっているもののことを 仮引数 (parameter) と呼ぶ。また、by = 1 の1や、length.out = 10 の10のように、仮引数に実際に渡される値のことを実引数 (argument) と呼ぶ。特に誤解が生じないと思われる場合には、仮引数と実引数を区別せずに引数（ひきすう）と呼ぶ。 Rでは、1つの関数で使う引数の数が複数あることが多いので、仮引数を明示する習慣を身につけたほうがよい。 ただし、第1引数（関数で最初に指定する引数）として必ず入力すべきものは決められている場合がほとんどなので、第1引数の仮引数は省略されることが多い。仮引数が省略される代わりに、第1引数の実引数はほぼ必ず入力する（いくつかの例外もある）。\n関数とは()内の引数のデータを関数内部の手続きに沿って処理し、その結果を返すものです。あるデータを引数として受け付ける関数であれば、その引数を変えるだけで「先ほどとは異なるデータに対し、同じ処理を行う」ことが可能となり、コーディングの労力が省けます。\nここでは、ベクトルc(1, 2, 3, 4, 5)の総和を計算する方法について考えてみましょう。まず、1つ目は単純に足し算をする方法があります。\n\n1 + 2 + 3 + 4 + 5\n\n[1] 15\n\n\n他にも反復処理を使うことも可能です。とりわけ、1:100のようなベクトルを1つ目の方法で記述するのは時間の無駄でしょう。for()文を使った方法は以下のようになります。\n\nResult <- 0\n\nfor (i in 1:5) {\n  Result <- Result + i  \n}\n\n\nResult\n\n[1] 15\n\n\n数個の数字を足すだけなら方法1の方が楽でしょうし、数百個の数字の場合は方法2の方が効率的です。それでもやはりsum()関数の方が数倍は効率的です。また、関数を使うことで、スクリプトの量をへらすこともできます。1から100までの総和なら、方法2のfor (i in 1:5)をfor (i in 1:100)に変えることで対応可能ですが、それでも全体としては数行のコードで書かなくてもなりません。一方、sum(1:100)なら一行で済みます。\nsum()はまだマシな方です。たとえば、回帰分析をしたい場合、毎回回帰分析のコードを一から書くのはあまりにも非効率的です。lm()関数を使うと、データや回帰式などを指定するだけで、一連の作業を全て自動的に行い、その結果を返してくれます。中には回帰式の係数も計算してくれますが、他にも残差や決定係数なども計算してくれます。その意味で、lm()という関数は複数の機能を一つの関数としてまとめたものでもあります。\nこれらの関数は既にR開発チームが書いた関数ですが、ユーザー側から関数を作成することも可能です。長いコードを書く、同じ作業を繰り返す場合、関数の作成はほぼ必須とも言えます。ここではまず、簡単な関数を作成してみましょう。与えられた数字を二乗し、その結果を返すmyPower()関数を作ってみましょう。\n\nmyPower <- function(x) {\n  x^2\n}\n\n\n# 引数が一つしかないので、myPower(24)も可能\nmyPower(x = 24)\n\n[1] 576\n\n\nそれではコードを解説します。関数は以下のように定義されます。\n関数名 <- function (引数名) {\n  処理内容\n}\nまず、関数名をmyPowerとし、それが関数であることを宣言します。そして、この関数の引数の名前はxとします。それが\nmyPower <- function (x)\nの部分です。続いて、{}内に処理内容を書きます。今回はx^2であり、これはxの2乗を意味します。そして、関数の処理結果が返されますが、{}内の最後の行が結果として返されます。x^2の部分はreturn(x^2)と書き換えることも可能です。return()は「この結果を返せよ」という意味の関数ですが、返す結果が最後の行である場合、省略可能であり、Hadely先生もこのような書き方を推奨しています。\nそれでは、もうちょっと複雑な関数を作成してみましょう。ベクトルを引数とし、その和を計算するmySum()という関数です。要するにsum()関数を再現したものです。\n\n# mySum関数を定義し、引数はxのみとする\nmySum <- function(x) {\n  # 結果を格納するベクトルResultを生成し、0を入れておく\n  Result <- 0\n  \n  # xの要素をiに一つずつ入れながら反復処理\n  for (i in x) {\n    # Resultに既存のResultの値にiを足した結果を上書きする\n    Result <- Result + i\n  }\n  \n  # Resultを返す\n  Result\n}\n\n\nmySum(1:5)\n\n[1] 15\n\n\n普通のsum()関数と同じ動きをする関数が出来上がりました。よく見ると、上で説明した総和を計算する方法2のコードを丸ごと関数内に入っているだけです。変わったところがあるとすれば、for()文であり、for (i in 1:5)がfor (i in x)に変わっただけです。ここのxはmySum <- function (x)のxを意味します。このように関数を一回作成しておくと、これからは総和を出す作業を1行に短縮することができます。\nこのmySum()ですが、一つ問題があります。それはxに欠損値が含まれている場合、結果がNAになることです。\n\nmySum(c(1, 2, 3, NA, 5))\n\n[1] NA\n\n\n実際、R内蔵関数であるsum()も同じですが、sum()にはna.rm =というもう一つの引数があり、これをTRUEにすることで欠損値を除いた総和が計算できます。つまり、関数は複数の引数を持つことができます。それでは、mySum()を改良してみましょう。ここにもna.rmという関数を追加し、na.rm引数がTRUEの場合、xから欠損値を除いた上で総和を計算するようにしましょう。\n\nmySum <- function(x, na.rm = FALSE) {\n  if (na.rm == TRUE) {\n    x <- x[!is.na(x)]\n  }\n  \n  Result <- 0\n  \n  for (i in x) {\n      Result <- Result + i\n  }\n  \n  Result\n}\n\n\nmySum(c(1, 2, 3, NA, 5))\n\n[1] NA\n\nmySum(c(1, 2, 3, NA, 5), na.rm = FALSE)\n\n[1] NA\n\nmySum(c(1, 2, 3, NA, 5), na.rm = TRUE)\n\n[1] 11\n\n\n変わったところは、まずfunction (x)がfunction (x, na.rm = FALSE)になりました。これはxとna.rmの引数が必要であるが、na.rmのデフォルト値はFALSEであることを意味します。デフォルト値が指定されている場合、関数を使用する際、その引数は省略できます。実際、sum()関数のna.rm引数もFALSEがデフォルトとなっており、省略可能となっています。\n次は最初に条件分岐が追加されました。ここではna.rmがTRUEの場合、xから欠損値を抜いたベクトルをxに上書きするように指定しました。もし、FALSEならこの処理は行いません。\nこれでR開発チームが作成したsum()関数と同じものが出来上がりました。それでは引数の順番について簡単に解説し、もうちょっと複雑な関数を作ってみましょう。引数の順番は基本的にfunction()の()内で定義した順番であるなら、引数名を省略することも可能です。\n\nmySum(c(1, 2, 3, NA, 5), TRUE)\n\n[1] 11\n\n\nただし、順番を逆にすると、以下のようにわけのわからない結果が返されます。\n\nmySum(TRUE, c(1, 2, 3, NA, 5))\n\nError in if (na.rm == TRUE) {: the condition has length > 1\n\n\n任意の順番で引数を指定する場合、引数名を指定する必要があります。\n\nmySum(na.rm = TRUE, x = c(1, 2, 3, NA, 5))\n\n[1] 11\n\n\n自分で関数を作成し、他の人にも使ってもらう場合、引数名、順番、デフォルト値を適切に設定しておくことも大事です。"
  },
  {
    "objectID": "functions.html#RN4Esec-func_adv",
    "href": "functions.html#RN4Esec-func_adv",
    "title": "11  関数の自作",
    "section": "\n11.2 ちょっと複雑な関数",
    "text": "11.2 ちょっと複雑な関数\nそれではちょっとした遊び心を込めた関数を作ってみましょう。その名もドラクエ戦闘シミュレーターです。\n以下はドラクエ11のダメージ公式です。\n\nダメージの基礎値 = (攻撃力 / 2) - (守備力 / 4)\n\n0未満の場合、基礎値は0とする\n\n\nダメージの幅 = (ダメージの基礎値 / 16) + 1\n\n端数は切り捨てます (floor()関数使用)\n\n\n\nダメージの最小値は「ダメージの基礎値 - ダメージの幅」、最大値は「ダメージの基礎値 - ダメージの幅」となります。この最小値が負になることもありますが、その場合は0扱いになります。実際のダメージはこの範囲内でランダムに決まります (runif()関数使用)。\n\n# DQ_Attack関数を定義\nDQ_Attack <- function(attack, defence, hp, enemy) {\n  ## 引数一覧\n  ## attack: 勇者の力 + 武器の攻撃力 (長さ1の数値型ベクトル)\n  ## defence: 敵の守備力 (長さ1の数値型ベクトル)\n  ## hp: 敵のHP (長さ1の数値型ベクトル)\n  ## enemy: 敵の名前 (長さ1の文字型ベクトル)\n  \n  # ダメージの基礎値\n  DefaultDamage <- (attack / 2) - (defence / 4)\n  # ダメージの基礎値が負の場合、0とする\n  DefaultDamage <- ifelse(DefaultDamage < 0, 0, DefaultDamage)\n  # ダメージの幅\n  DamageWidth   <- floor(DefaultDamage / 16) + 1\n  \n  # ダメージの最小値\n  DamageMin     <- DefaultDamage - DamageWidth\n  # ダメージの最小値が負の場合、0とする\n  DamageMin     <- ifelse(DamageMin < 0, 0, DamageMin)\n  # ダメージの最大値\n  DamageMax     <- DefaultDamage + DamageWidth\n  \n  # 敵の残りHPを格納する\n  CurrentHP     <- hp\n  \n  # 残りHPが0より大きい場合、以下の処理を繰り返す\n  while (CurrentHP > 0) {\n    # ダメージの最小値から最大値の間の数値を1つ無作為に抽出する\n    Damage <- runif(n = 1, min = DamageMin, max = DamageMax)\n    # 小数点1位で丸める\n    Damage <- round(Damage, 0)\n    # 残りのHPを更新する\n    CurrentHP <- CurrentHP - Damage\n    # メッセージを表示\n    print(paste0(enemy, \"に\", Damage, \"のダメージ!!\"))\n  }\n  \n  # 上記の反復処理が終わったら勝利メッセージを出力\n  paste0(enemy, \"をやっつけた！\")\n}\n\n初めて見る関数が3つありますね。まず、floor()関数は引数の端数は切り捨てる関数です。たとえば、floor(2.1)もfloor(2.6)も結果は2です。続いて、runif()関数は指定された範囲の一様分布から乱数を生成する関数です。引数は生成する乱数の個数 (n)、最小値 (min)、最大値 (max)の3つです。runif(5, 3, 10)なら最小値3、最大値10の乱数を5個生成するという意味です。正規分布は平均値周辺の値が生成されやすい一方、一様分布の場合、ある値が抽出される確率は同じです。最後にround()関数は四捨五入の関数です。引数は2つあり、1つ目の引数は数値型のベクトルです。2つ目は丸める小数点です。たとえば、round(3.127, 1)の結果は3.1であり、round(3.127, 2)の結果は3.13となります。\nそれでは「ひのきのぼう」を装備したレベル1の勇者を考えてみましょう。ドラクエ5の場合、Lv1勇者の力は11、「ひのきのぼう」の攻撃力は2ですので、攻撃力は13です。まずは定番のスライムから狩ってみましょう。スライムのHPと守備力は両方7です。\n\nDQ_Attack(13, defence = 7, hp = 7, \"スライム\")\n\n[1] \"スライムに4のダメージ!!\"\n[1] \"スライムに5のダメージ!!\"\n\n\n[1] \"スライムをやっつけた！\"\n\n\nまぁ、こんなもんでしょう。それではスライムナイト (=ピエール)はどうでしょう。スライムナイトのHPのは40、守備力は44です。\n\nDQ_Attack(13, defence = 44, hp = 40, \"スライムナイト\")\n\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n\n\n[1] \"スライムナイトをやっつけた！\"\n\n\nこれだと「なんと　スライムナイトが　おきあがりなかまに　なりたそうに　こちらをみている！」のメッセージを見る前に勇者ご一行が全滅しますね。エスターク (HP: 9000 / 守備力: 250)は計算するまでもないでしょう…\n以上の関数に条件分岐を追加することで「かいしんの　いちげき！」を入れることもできますし1、逆に敵からの攻撃を計算して誰が先に倒れるかをシミュレーションすることも可能でしょうね。色々遊んでみましょう。"
  },
  {
    "objectID": "functions.html#RN4Esec-func_in_func",
    "href": "functions.html#RN4Esec-func_in_func",
    "title": "11  関数の自作",
    "section": "\n11.3 関数 in 関数",
    "text": "11.3 関数 in 関数\n当たり前かも知れまっせんが、自作関数を他の自作関数に含めることもできます。ここでは乱数を生成する関数を作ってみましょう。パソコンだけだと完全な乱数を作成することは不可能ですが2、乱数に近いものは作れます。このようにソフトウェアで生成された乱数は擬似乱数と呼ばれ、様々なアルゴリズムが提案されています。天才、フォン・ノイマン大先生も乱数生成では天才ではなかったらしく、彼が提案した平方採中法 (middle-square method)は使い物になりませんので、ここではもうちょっとマシな方法である線形合同法 (linear congruential generators; 以下、LCG)を採用します。平方採中法よりは式が複雑ですが、それでも非常に簡単な式で乱数が生成可能であり、Rによる実装に関しては平方採中法より簡単です。ちなみに、線形合同法にも様々な問題があり、Rのデフォルトは広島大学の松本眞先生と山形大学の西村拓士先生が開発しましたメルセンヌ・ツイスタ (Mersenne twister)を採用しています。それでは、LCGのアルゴリズムから見ましょう。\n乱数の列があるとし、\\(n\\)番目の乱数を\\(X_n\\)とします。この場合、\\(X_{n+1}\\)は以下のように生成されます。\n\\[\nX_{n+1} = (aX_n + c) \\text{ mod } m\n\\]\n\\(\\text{mod}\\)は余りを意味し、\\(5 \\text{mod} 3\\)は5を3で割った際の余りですので、2となります。\\(a\\)と\\(c\\)、\\(m\\)は以下の条件を満たす任意の数です。\n\\[\\begin{align}\n0 < &  m, \\\\\n0 < &  a < m, \\\\\n0 \\leq &  c < m.\n\\end{align}\\]\nベストな\\(a\\)、\\(c\\)、\\(m\\)も決め方はありませんが、ここではTurbo Cの設定を真似て\\(a = 22695477\\)、\\(c = 1\\)、\\(m = 2^{32}\\)をデフォルト値として設定します3。そして、もう一つ重要なのが最初の数、つまり\\(X_n\\)をどう決めるかですが、これは自由に決めて問題ありません。最初の数 (\\(X_0\\))はシード (seed)と呼ばれ、最終的には使わない数字となります。それではseedという引数からある乱数を生成する関数rng_number()を作ってみましょう。\n\nrng_number <- function(seed, a = 22695477, c = 1, m = 2^32) {\n  (a * seed + c) %% m\n}\n\n簡単な四則演算のみで構成された関数ですね。ちなみに%%は余りを計算する演算子です。とりあえず、seedを12345に設定し、一つの乱数を生成してみましょう。\n\nrng_number(12345)\n\n[1] 1002789326\n\n\nかなり大きい数字が出ました。ちなみに線形合同法で得られる乱数の最大値は\\(m\\)、最小値は0です。次は、今回得られた乱数1.0027893^{9}を新しいseedとし、新しい乱数を作ってみましょう。\n\nrng_number(1002789326)\n\n[1] 3785644968\n\n\nこの作業を繰り返すと、(疑似)乱数の数列が得られます。続いて、この作業をn回繰り返し、長さnの乱数ベクトルを返す関数LCGを作ってみましょう。いかがコードになります。\n\nLCG <- function(n, seed, a = 22695477, c = 1, m = 2^32) {\n  rng_vec    <- rep(NA, n + 1) # seedも入るので長さn+1の空ベクトルを生成\n  rng_vec[1] <- seed           # 1番目の要素にseedを入れる\n  \n  # iに2からn+1までの値を順次的に投入しながら、反復処理\n  for (i in 2:(n+1)) {\n    # rng_vecのi番目にi-1番目の要素をseedにした疑似乱数を格納\n    rng_vec[i] <- rng_number(rng_vec[i - 1], a, c, m)\n  }\n  \n  rng_vec <- rng_vec[-1] # 1番目の要素 (seed)を捨てる\n  rng_vec <- rng_vec / m # 最小値0、最大値1になるように、mで割る\n  \n  rng_vec # 結果を返す\n}\n\nそれでは、詳細に解説します。\n\n1行目: 関数LCGを定義し、必要な引数としてnとseedを設定する。\n2行目: 結果を格納する空ベクトルrng_vecを生成。ただし、1番目にはseedが入るので、長さをn+1とする。\n3行目: rng_vecの1番目にseedを格納する。\n6行目: 疑似乱数をn回生成し、格納するように反復作業を行う。任意の変数はiとし、iに代入される値は2からn+1までである。\n8行目: rng_vecのi-1番目要素をseedにした疑似乱数を生成し、rng_vecのi番目に格納する。1回目の処理だとi=2であるため、rng_vec[1] (= seed)をseedにした疑似乱数が生成され、rng_vec[2]に格納される。\n11行目: rng_vecの1番目の要素はseedであるため、捨てる。\n12行目: 乱数が最小値0、最大値1になるように、調整する。具体的には得られた乱数をm (デフォルトは\\(2^{32}\\))で割るだけである。\n14行目: 結果ベクトルを返す。\n\nそれでは、seedを19861008とした疑似乱数10000個を生成し、LCG_Numbersという名のベクトルに格納してみましょう。結果を全て表示させるのは無理があるので、最初の20個のみを確認してみます。\n\nLCG_Numbers <- LCG(10000, 19861008)\nhead(LCG_Numbers, 20)\n\n [1] 0.58848246 0.09900449 0.21707060 0.89462981 0.23421890 0.72341249\n [7] 0.55965400 0.59552685 0.96594972 0.69050965 0.98383344 0.20136551\n[13] 0.25856502 0.37569497 0.50086451 0.03986446 0.89291806 0.24760102\n[19] 0.27912510 0.24493750\n\n\n正直、これが乱数かどうかは見るだけでは分かりませんね。簡単な確認方法としては、これらの乱数列のヒストグラムを見れば分かります。得られた数列が本当に乱数(に近いもの)なら、その分布は一様分布に従っているからです。ただし、一様分布に従っていることが乱数を意味するものではありません。\n可視化については第17章以降で解説しますが、ここでは簡単にhist()関数を使ってみましょう。必要な引数はnumeric型のベクトルのみです。以下のコードにあるxlab =などはラベルを指定する引数ですが、省略しても構いません。\n\nhist(LCG_Numbers, xlab = \"乱数\", ylab = \"度数\", \n     main = \"生成された乱数10000個のヒストグラム\")\n\n\n\n\nややギザギザしているように見えますが4、これなら一様分布だと考えて良いでしょう。"
  },
  {
    "objectID": "functions.html#RN4Esec-func_exercise",
    "href": "functions.html#RN4Esec-func_exercise",
    "title": "11  関数の自作",
    "section": "\n11.4 練習問題",
    "text": "11.4 練習問題\n問1\n\n長さ2のnumericベクトルDataについて考える。条件分岐を用いてDataの1番目の要素 (Data[1])が2番目の要素 (Data[2])より大きい場合、1番目の要素と2番目の順番を逆転させる条件分岐を作成せよ。たとえば、Data <- c(5, 3)なら、条件分岐後のDataの値がc(3, 5)になること。\n\n問2\n\n与えられた正の実数の平方根を求めるmy_sqrt()を作成する。平方根を計算する方法はHero of Alexandriaの近似法5を使用する。\n\n平方根を求めるx、任意の初期値g、非常に小さい正の実数eを入力する。eの既定値は0.001とする。\n\ngの2乗を計算し、x - g^2の絶対値をgapとする（gapの初期値はInfとする）。\n\ngapがeより小さい場合、gをxの平方根として返す。\n\ngapがeより大きい場合、g + (x / g)を新しいgとする。\n2へ戻る。\n\n\n\nwhile()関数を使えば簡単である。\n\n\n\n\n\n# Rのsqrt()関数\nsqrt(29)\n\n[1] 5.385165\n\n# 計算例1\nmy_sqrt(29, 5) # 29の平方根。初期値は5\n\n[1] 5.385185\n\n# 計算例2\nmy_sqrt(29, 5, e = 0.00001) # 29の平方根。初期値は5。eは0.00001\n\n[1] 5.385165\n\n# 計算例3\nmy_sqrt(-3, 5, e = 0.00001) # あえてエラーを出してみる\n\nError in my_sqrt(-3, 5, e = 1e-05): xは正の実数でなければなりません。\n\n\n問3\n\n問3ではベクトルの1番目要素と2番目の要素を比較し、前者が大きい場合において順番を入れ替える条件分岐を行った。これを長さ3以上のベクトルにも適用したい。長さ4のnumeric型ベクトルDataがある場合の計算手順について考えてみよう。\n\n\nData[1]とData[2]の要素を比較し、Data[1] > Data[2]の場合、入れ替える。\n\nData[2]とData[3]の要素を比較し、Data[2] > Data[3]の場合、入れ替える。\n\nData[3]とData[4]の要素を比較し、Data[3] > Data[4]の場合、入れ替える。この段階でData[4]はDataの最大値が格納される。\n続いて、Data[1]とData[2]の要素を比較し、Data[1] > Data[2]の場合、入れ替える。\n\nData[2]とData[3]の要素を比較し、Data[2] > Data[3]の場合、入れ替える。この段階でData[3]にはDataの2番目に大きい数値が格納される。\n最後にData[1]とData[2]の要素を比較し、Data[1] > Data[2]の場合、入れ替える。ここで並び替えは終了\n\n\n\nヒント: 2つのfor()文が必要となる。これは「バブルソート」と呼ばれる最も簡単なソートアルゴリズムである。イメージとしては、長さNのベクトルの場合、n番目の要素とn+1番目の要素を比較しながら、大きい方を後ろの方に追い込む形である。最初は、Data[4]最後の要素に最大値を格納し、続いて、Data[3]に次に大きい数値を、Data[2]に次に大きい数値を入れる仕組みである。\n\n最初はData[1]とData[2]、Data[2]とData[3]、Data[3]とData[4]の3ペアの比較を行う。\n続いて、Data[1]とData[2]、Data[2]とData[3]の2ペアの比較を行う\n最後に、Data[1]とData[2]の1ペアの比較を行う\nつまり、外側のfor()文は「Dataの長さ-1」回繰り返すことになる。\n内側のfor()文は3, 2, 1ペアの比較を行うことになる。\n\n\n\n問4\n\n「問4」の練習問題で作成したコードを関数化せよ。関数名はmySort()であり、引数は長さ2以上のnumeric型ベクトルのみである。引数名は自由に決めても良いし、dataやxなどを使っても良い。\n\n問5\n\n既に作成したDQ_Attack関数を修正してみよう。今の関数は通常攻撃のみであるが、稀に「会心の一撃」が発生するように修正する。\n\n会心の一撃が発生する確率は1/32とする (Hint: 0から1の間の乱数を生成し、その乱数が1/32以下であるか否かで条件分岐させる)。乱数の生成はrunif()または、自作関数のLCG()でも良い。\n会心の一撃のダメージの最小値は攻撃力の95%、最大値は105%とする。\n会心の一撃が発生したら、\"かいしんのいちげき! スライムに10のダメージ!!\"のようなメッセージを出力させること。\n\n\n\n問6\n\n与えられたベクトルxからn個の要素を無作為に抽出する関数、mySample()を定義せよ。mySample()の引数はxとn、seedとし、xは長さ1以上のベクトルとする。nは長さ1の整数型ベクトルである。\n\n以下の場合、エラーメッセージを出力し、処理を中止させること。\n\n\nnとseedが長さ1ベクトルでない場合、\n\nseedがnumeric型でない場合\n\nnが整数でない場合 (floor(n) == nで判定)\n\n\n\nヒント: LCG()関数を用いて乱数を生成した場合、生成された擬似乱数は0以上1以下である。ベクトルxの長さをlength(x)とした場合、擬似乱数にlength(x)を掛けると、擬似乱数は0以上length(x)以下になる。これらの値を切り上げると (ceiling()関数)、その値は1以上length(x)以下の整数となる。\n\n\n\n\n私たちのR 私たちのR 12  データハンドリング [抽出] 10  Rプログラミングの基礎 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 11  関数の自作 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR\n\n\n\nChambers, John M. 2016. Extending r. Boca Raton, FL: CRC Press."
  },
  {
    "objectID": "datahandling1.html#RN4Esec-handling1-intro",
    "href": "datahandling1.html#RN4Esec-handling1-intro",
    "title": "12  データハンドリング [抽出]",
    "section": "\n12.1 データハンドリングとtidyverse",
    "text": "12.1 データハンドリングとtidyverse\n\nThe tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. (Tidyverseホームページから)\n\n　Tidyverseとはデータサイエンスのために考案された、強い信念と思想に基づいたRパッケージの集合です。Tidyverseに属するパッケージは思想、文法およびデータ構造を共有しています。Tidyverseの中核をなすパッケージは{ggplot2}(第17、18、19、20章)、{dplyr}(第12、13章)、{tidyr}(第15章)、{readr}(第7.1章)、{purrr} (第27章)、{tibble}(第9.4章)、{stringr} (第16章)、{forcats} (第14章)などがあり、このパッケージを支える数十のパッケージが含まれています。これらのパッケージは個別に読み込む必要はなく、{tidyverse}パッケージを読み込むだけで十分です。\n\nlibrary(tidyverse)\n\n　Rにおけるデータハンドリング (データ操作)の標準が{dplyr}と{tidyr}中心となり、文字列の処理は{stringr}、factor型の操作は{forcats}、大量のモデルを自動的に分析し、結果を処理するためには{tibble}と{purrr}、可視化は{ggplot2}が主に使われています。これらのパッケージ間、あるいはパッケージ内におけるオブジェクトのやり取りは全てパイプ演算子を通じて行われています。また、これらのパッケージは整然データ (tidydata)を想定するか、整然データの作成するに特化しています。\n　Tidyverseの思想に基づいた「tidyverse流のコーディング」は現在のRそのものと言っても過言ではありません。ただし、tidyverseじゃないと出来ないデータハンドリング、可視化などはありません。tidyverseはデータサイエンスの思想に近いものであり、「異なる思想を持っているからこのような分析はできない」といったものはありません。tidyverseという概念が提唱される前にもRは存在し、tidyverse無き世界で今と同じことをやってきました。ただし、tidyverse流で書かれたRコードは可読性が優れ、コードを書く手間も短くなります。tidyverseの考え方がRのける「標準語」として定着しつつあるのは否めない事実であり、学習する誘引としては十分すぎるでしょう。"
  },
  {
    "objectID": "datahandling1.html#RN4Esec-handling1-pipe",
    "href": "datahandling1.html#RN4Esec-handling1-pipe",
    "title": "12  データハンドリング [抽出]",
    "section": "\n12.2 パイプ演算子 (%>%)",
    "text": "12.2 パイプ演算子 (%>%)\n\n\n\n\n\n\n新しいパイプ演算子|>\n\n\n\n　以下で紹介するパイプ演算子%>%は{magrittr}パッケージが提供する演算子であり、R内臓のパイプ演算子はありませんでした。しかし、R 4.1から内蔵パイプ演算子|>が使えるようになっています。使い方はほぼ違いはありませんが（位置指定子（placeholder）の使い方の違いはあります）、将来、以下の内容は|>に書き換える予定です。\n\n\n　{dplyr}パッケージを利用する前にパイプ演算子について説明します。パイプ演算子は{dplyr}に含まれている演算子ではなく、{magrittr}という別のパッケージから提供される演算子ですが、{tidyverse}パッケージを読み込むと自動的に読み込まれます。パイプ演算子はx %>% y()のような書き方となりますが、これは「xをy()の第一引数として渡す」ことを意味します。xの部分はベクトルやデータフレームのようなオブジェクトでも、関数でも構いません。なぜなら、関数から得られた結果もまたベクトルやデータフレームといったものになるからです。つまり、x() %>% y()という使い方も可能です。そして、パイプは無限に繋ぐこともできます。「データdfを関数x()で処理をし、その結果をまた関数y()で処理する」ことは、パイプを使うとdf %>% x() %>% y()のような書き方となります。\n　たとえば、「paste(3, \"+\", 5, \"=\", 8)を実行し、その結果をrep()関数を使って3回複製し、それをprint()を使って出力する」コードを考えてみましょう。方法としては2つ考えられます。まずは、それぞれの処理を別途のオブジェクトに格納する方法です。そして二つ目は関数の中に関数を使う方法です。\n\n# 方法1: 一関数一オブジェクト\nResult1 <- paste(3, \"+\", 5, \"=\", 8)\nResult2 <- rep(Result1, 3)\nprint(Result2)\n\n[1] \"3 + 5 = 8\" \"3 + 5 = 8\" \"3 + 5 = 8\"\n\n# 方法2: 関数の中に関数の中に関数\nprint(rep(paste(3, \"+\", 5, \"=\", 8), 3))\n\n[1] \"3 + 5 = 8\" \"3 + 5 = 8\" \"3 + 5 = 8\"\n\n\n　どれも結果は同じです。コードを書く手間を考えれば、後者の方が楽かも知れませんが、可読性があまりよくありません。一方、前者は可読性は良いものの、コードも長くなり、オブジェクトを2つも作ってしまうのでメモリの無駄遣いになります。\n　コードの可読性と書く手間、両方を満足する書き方がパイプ演算子%>%です。まずは、例から見ましょう。\n\n# %>%を使う\npaste(3, \"+\", 5, \"=\", 8) %>% rep(3) %>% print()\n\n[1] \"3 + 5 = 8\" \"3 + 5 = 8\" \"3 + 5 = 8\"\n\n\n　まず、結果は先ほどと同じです。それではコードの説明をしましょう。まずは、paste(3, \"+\", 5, \"=\", 8)を実行します。そしてその結果をそのままrep()関数の第一引数として渡されます。つまり、rep(paste(3, \"+\", 5, \"=\", 8), 3)になるわけです。ここではrep(3)と書きましたが、第一引数が渡されたため、3は第二引数扱いになります (パイプ演算子前のオブジェクトを第二、三引数として渡す方法は適宜説明します。)。そして、これをまたprint()関数に渡します。結果としてはprint(rep(paste(3, \"+\", 5, \"=\", 8), 3))となります。\n　関数を重ねると読む順番は「カッコの内側から外側へ」になりますが、パイプ演算子を使うと「左 (上)から右 (下)へ」といったより自然な読み方が可能になります。また、以下のコードのように、パイプ演算子後に改行を行うことでより読みやすいコードになります。これからはパイプ演算子の後は必ず改行をします。\n\n# 改行 (+字下げ)したらもっと読みやすくなる\npaste(3, \"+\", 5, \"=\", 8) %>% \n    rep(3) %>% \n    print()\n\n　パイプ演算子を使わない方法 図 12.1 のようにイメージできます。一回の処理ごとに結果を保存し、それをまた次の処理時においてデータとして使うイメージです。\n\n\n図 12.1: パイプ演算子を使わない場合\n\n\n　一方、 図 12.2 はパイプ演算子を使う場合のプロセスです。処理後の結果を保存せず、すぐに次のプロセスに渡すことで、メモリ (図だとボウル)や時間、コードの無駄を減らすことができます。むろん、 図 12.1 の結果1を使って色々試してみたい場合は、一旦結果1までは格納し、適宜引き出して使った方が効率的でしょう。パイプ演算子はたしかに便利で、「今どき」のRの書き方を象徴するようなものですが、一つの結果を出すまであまりにも多くのパイプ演算子を使うことはあ望ましくありません。\n\n\n図 12.2: パイプ演算子を使う場合\n\n\n　データハンドリングもこれど同様に、様々な作業を順に沿って行う必要があります。例えば、「(1) 列を選択して、(2) 欠損値を含む列を除去して、 (3) ある変数の値を100倍にして、(4) ある変数の値がが小さい行から大きい順へ並び替える」といった手順です。これらの作業はパイプ演算子を使えば、スムーズに行うことが可能です。"
  },
  {
    "objectID": "datahandling1.html#RN4Esec-handling1-select",
    "href": "datahandling1.html#RN4Esec-handling1-select",
    "title": "12  データハンドリング [抽出]",
    "section": "\n12.3 列の抽出",
    "text": "12.3 列の抽出\n　それでは今回の実習用データを読み込みましょう。Ramen.csvには「ぐるなび」から取得したラーメン屋6292店舗の情報が入っています。具体的には東京、神奈川、千葉、埼玉、大阪、京都、兵庫、奈良、和歌山それぞれ都府県にあるラーメン屋の中から最大1000店舗の情報を抽出したものです。東京都は、ぐるなびに登録したラーメン屋が3000店舗以上ですが、1000店舗の基準はぐるなびの「おすすめ」の順で上位1000店舗となります。また、店側またはぐるなびが登録したカテゴリを基準に抽出したため、実際はラーメン屋ではないにもかかわらずラーメン屋としてデータ内に含まれている可能性があります。\n　まず、このデータを読み込み、dfという名付けます。\n\ndf <- read_csv(\"Data/Ramen.csv\")\n\n　データの中身を確認してみましょう。\n\ndf\n\n# A tibble: 6,292 × 14\n   ID      Name    Pref  Zipcode Latit…¹ Longi…² Line  Station  Walk   Bus   Car\n   <chr>   <chr>   <chr>   <dbl>   <dbl>   <dbl> <chr> <chr>   <dbl> <dbl> <dbl>\n 1 e539604 居酒屋… 東京… 1040031    35.7    140. 地下… 銀座一…     3    NA    NA\n 2 gfeb600 本格上… 東京… 1100005    35.7    140. 地下… 仲御徒…     1    NA    NA\n 3 ggt5900 食べ飲… 東京… 1250041    35.8    140. ＪＲ… 金町駅      2    NA    NA\n 4 g181340 博多餃… 東京… 1920904    35.7    139. ＪＲ  八王子…     1    NA    NA\n 5 ggww100 まさ屋… 東京… 1500042    35.7    140. 地下… 渋谷駅      7    NA    NA\n 6 gdzk500 完全個… 東京… 1000013    35.7    140. 地下… 虎ノ門…     3    NA    NA\n 7 ga2g202 鶏そば… 東京… 1760006    35.7    140. 西武… 江古田…     2    NA    NA\n 8 gg9m100 宴会個… 東京… 1010021    35.7    140. ＪＲ  秋葉原…     4    NA    NA\n 9 gdvk200 中国料… 東京… 1000006    35.7    140. ＪＲ  有楽町…     1    NA    NA\n10 gggb200 中国料… 東京… 1140002    35.8    140. 地下… 王子駅      2    NA    NA\n# … with 6,282 more rows, 3 more variables: Budget <dbl>, ScoreN <dbl>,\n#   Score <dbl>, and abbreviated variable names ¹​Latitude, ²​Longitude\n\n\n　1行目の# A tibble: 2,000 x 12から、ケース数 (店舗数)は2000、変数は12個あることが分かります。各変数の詳細は 表 12.1 の通りです。\n\n\n\n\n\n表 12.1:  Ramen.csvの詳細 \n \n 変数名 \n    説明 \n  \n\n\n `ID` \n    店舗ID \n  \n\n `Name` \n    店舗名 \n  \n\n `Pref` \n    店舗の所在地 (都府県) \n  \n\n `Zipcode` \n    店舗の郵便番号 \n  \n\n `Latitude` \n    緯度 \n  \n\n `Longitude` \n    経度 \n  \n\n `Line` \n    最寄りの駅の路線 \n  \n\n `Station` \n    最寄りの駅 \n  \n\n `Walk` \n    最寄りの駅からの距離 (徒歩; 分) \n  \n\n `Bus` \n    最寄りの駅からの距離 (バス; 分) \n  \n\n `Car` \n    最寄りの駅からの距離 (車; 分) \n  \n\n `Budget` \n    平均予算 (円) \n  \n\n `ScoreN` \n    口コミの数 \n  \n\n `Score` \n    口コミ評価の平均値 \n  \n\n\n\n\n\n　それではここからはdfを用いた{dplyr}の様々な機能を紹介していきます。\n\n12.3.1 特定の列を抽出する\n　まずは、データフレームから特定の列のみを残す、除去する方法について紹介します。たとえば、dfからID、Name、Pref、Scoreのみを残すとします。{dplyr}を使わない方法と{dplyr}のselect()関数を使った方法を紹介します。\n\n# dplyrを使わない方法\ndf[, c(\"ID\", \"Name\", \"Pref\", \"Score\")]\n\n# A tibble: 6,292 × 4\n   ID      Name                                                     Pref   Score\n   <chr>   <chr>                                                    <chr>  <dbl>\n 1 e539604 居酒屋 龍記 京橋店                                       東京都 NA   \n 2 gfeb600 本格上海料理 新錦江 上野御徒町本店                       東京都  4.5 \n 3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ）               東京都 NA   \n 4 g181340 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル）併設 東京都 NA   \n 5 ggww100 まさ屋 渋谷店                                            東京都 NA   \n 6 gdzk500 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店              東京都 NA   \n 7 ga2g202 鶏そば きらり                                            東京都 NA   \n 8 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店                    東京都  3.33\n 9 gdvk200 中国料理 宝龍                                            東京都  2.5 \n10 gggb200 中国料理 天安門                                          東京都 NA   \n# … with 6,282 more rows\n\n# dplyr::select()を使う方法\n# select(df, ID, Name, Pref, Score)でもOK\ndf %>%\n  select(ID, Name, Pref, Score)\n\n# A tibble: 6,292 × 4\n   ID      Name                                                     Pref   Score\n   <chr>   <chr>                                                    <chr>  <dbl>\n 1 e539604 居酒屋 龍記 京橋店                                       東京都 NA   \n 2 gfeb600 本格上海料理 新錦江 上野御徒町本店                       東京都  4.5 \n 3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ）               東京都 NA   \n 4 g181340 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル）併設 東京都 NA   \n 5 ggww100 まさ屋 渋谷店                                            東京都 NA   \n 6 gdzk500 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店              東京都 NA   \n 7 ga2g202 鶏そば きらり                                            東京都 NA   \n 8 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店                    東京都  3.33\n 9 gdvk200 中国料理 宝龍                                            東京都  2.5 \n10 gggb200 中国料理 天安門                                          東京都 NA   \n# … with 6,282 more rows\n\n\n　どれも結果は同じですが、select()関数を使った方がより読みやすいコードになっているでしょう。むろん、select()関数を使わない方がスッキリする方も知るかも知れません。実際、自分でパッケージなどを作成する際はselect()を使わない場合が多いです。ただし、一般的な分析の流れではselect()の方がコードも意味も明確となり、パイプ演算子でつなぐのも容易です。\n　select()関数の使い方は非常に簡単です。第一引数はデータフレームですが、パイプ演算子を使う場合は省略可能です。第二引数以降の引数はデータフレームの変数名です。つまり、ここには残す変数名のみを書くだけで十分です。\n　また、select()関数を使って列の順番を変えることもできます。たとえば、ID、Pref、Name、Scoreの順で列を残すなら、この順番で引数を書くだけです。\n\ndf %>%\n  select(ID, Pref, Name)\n\n# A tibble: 6,292 × 3\n   ID      Pref   Name                                                    \n   <chr>   <chr>  <chr>                                                   \n 1 e539604 東京都 居酒屋 龍記 京橋店                                      \n 2 gfeb600 東京都 本格上海料理 新錦江 上野御徒町本店                      \n 3 ggt5900 東京都 食べ飲み放題×中華ビストロ NOZOMI（のぞみ）              \n 4 g181340 東京都 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル）併設\n 5 ggww100 東京都 まさ屋 渋谷店                                           \n 6 gdzk500 東京都 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店             \n 7 ga2g202 東京都 鶏そば きらり                                           \n 8 gg9m100 東京都 宴会個室×餃子酒場 北京飯店 秋葉原本店                   \n 9 gdvk200 東京都 中国料理 宝龍                                           \n10 gggb200 東京都 中国料理 天安門                                         \n# … with 6,282 more rows\n\n\n\n12.3.2 特定の列を抽出し、列名を変更する\n　また、特定の列を残す際、変数名を変更することも可能です。今回もID、Name、Pref、Scoreのみを残しますが、Pref列はPrefectureに変えてみましょう。\n\ndf %>%\n  select(ID, Name, Prefecture = Pref, Score)\n\n# A tibble: 6,292 × 4\n   ID      Name                                                    Prefe…¹ Score\n   <chr>   <chr>                                                   <chr>   <dbl>\n 1 e539604 居酒屋 龍記 京橋店                                      東京都  NA   \n 2 gfeb600 本格上海料理 新錦江 上野御徒町本店                      東京都   4.5 \n 3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ）              東京都  NA   \n 4 g181340 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル）併… 東京都  NA   \n 5 ggww100 まさ屋 渋谷店                                           東京都  NA   \n 6 gdzk500 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店             東京都  NA   \n 7 ga2g202 鶏そば きらり                                           東京都  NA   \n 8 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店                   東京都   3.33\n 9 gdvk200 中国料理 宝龍                                           東京都   2.5 \n10 gggb200 中国料理 天安門                                         東京都  NA   \n# … with 6,282 more rows, and abbreviated variable name ¹​Prefecture\n\n\n　抽出する際、変数を新しい変数名 = 既存の変数名にするだけで、変数名が簡単に変更できました。もし、特定の列は抽出しないものの、変数名を変えるにはどうすれば良いでしょうか。ここではdfのPrefをPrefectureに、WalkをDistanceに変更してみます。{dplyr}を使わない場合と{dplyr}のrename()関数を使う場合を両方紹介します。\n　まずは、name()関数についてですが、これはデータフレームの変数名をベクトルとして出力する関数です。\n\nnames(df)\n\n [1] \"ID\"        \"Name\"      \"Pref\"      \"Zipcode\"   \"Latitude\"  \"Longitude\"\n [7] \"Line\"      \"Station\"   \"Walk\"      \"Bus\"       \"Car\"       \"Budget\"   \n[13] \"ScoreN\"    \"Score\"    \n\n\n　察しの良い読者は気づいたかも知れませんが、names(データフレーム名)の結果はベクトルであり、上書きも可能です。つまり、names(df)の3番目と9番目の要素を\"Prefecture\"と\"Distance\"に上書きすることができるということです。\n\n# dplyrを使わずに列名を変更する方法\nnames(df)[c(3, 9)] <- c(\"Prefecture\", \"Distance\")\n\n# dfの中身を出力\ndf\n\n# A tibble: 6,292 × 14\n   ID    Name  Prefe…¹ Zipcode Latit…² Longi…³ Line  Station Dista…⁴   Bus   Car\n   <chr> <chr> <chr>     <dbl>   <dbl>   <dbl> <chr> <chr>     <dbl> <dbl> <dbl>\n 1 e539… 居酒… 東京都  1040031    35.7    140. 地下… 銀座一…       3    NA    NA\n 2 gfeb… 本格… 東京都  1100005    35.7    140. 地下… 仲御徒…       1    NA    NA\n 3 ggt5… 食べ… 東京都  1250041    35.8    140. ＪＲ… 金町駅        2    NA    NA\n 4 g181… 博多… 東京都  1920904    35.7    139. ＪＲ  八王子…       1    NA    NA\n 5 ggww… まさ… 東京都  1500042    35.7    140. 地下… 渋谷駅        7    NA    NA\n 6 gdzk… 完全… 東京都  1000013    35.7    140. 地下… 虎ノ門…       3    NA    NA\n 7 ga2g… 鶏そ… 東京都  1760006    35.7    140. 西武… 江古田…       2    NA    NA\n 8 gg9m… 宴会… 東京都  1010021    35.7    140. ＪＲ  秋葉原…       4    NA    NA\n 9 gdvk… 中国… 東京都  1000006    35.7    140. ＪＲ  有楽町…       1    NA    NA\n10 gggb… 中国… 東京都  1140002    35.8    140. 地下… 王子駅        2    NA    NA\n# … with 6,282 more rows, 3 more variables: Budget <dbl>, ScoreN <dbl>,\n#   Score <dbl>, and abbreviated variable names ¹​Prefecture, ²​Latitude,\n#   ³​Longitude, ⁴​Distance\n\n\n　簡単に変数名の変更ができました。続いて、{dplyr}のrename()関数を使った方法です。今回は、PrefectureをPrefに、DistanceをWalkに戻して見ましょう。そして、出力するだけにとどまらず、dfに上書きしましょう。\n\n# dfのPrefectureをPrefに、DistanceをWalkに変更し、上書きする\ndf <- df %>%\n  rename(Pref = Prefecture, Walk = Distance)\n\n　これで終わりです。実はselect()関数と使い方がほぼ同じです。ただし、残す変数名を指定する必要がなく、名前を変更する変数名と新しい変数名を入れるだけです。変数が少ないデータならselect()でもあまり不便は感じないかも知れませんが、変数が多くなるとrename()関数は非常に便利です。\n\n12.3.3 特定の列を除外する\n　逆に、一部の変数をデータフレームから除去したい場合もあるでしょう。たとえば、緯度 (Latitude)と経度 (Longitude)はラーメン屋の情報としては不要かもしれません。この2つの変数を除外するためにはどうすれば良いでしょうか。まず考えられるのは、この2つの変数を除いた変数を指定・抽出する方法です。\n\ndf %>%\n  select(ID, Name, Pref, Zipcode, \n         Line, Station, Walk, Bus, Car, Budget, ScoreN, Score)\n\n# A tibble: 6,292 × 12\n   ID    Name  Pref  Zipcode Line  Station  Walk   Bus   Car Budget ScoreN Score\n   <chr> <chr> <chr>   <dbl> <chr> <chr>   <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>\n 1 e539… 居酒… 東京… 1040031 地下… 銀座一…     3    NA    NA   3000      0 NA   \n 2 gfeb… 本格… 東京… 1100005 地下… 仲御徒…     1    NA    NA   2000      2  4.5 \n 3 ggt5… 食べ… 東京… 1250041 ＪＲ… 金町駅      2    NA    NA   2980      0 NA   \n 4 g181… 博多… 東京… 1920904 ＪＲ  八王子…     1    NA    NA   2000      0 NA   \n 5 ggww… まさ… 東京… 1500042 地下… 渋谷駅      7    NA    NA    380      0 NA   \n 6 gdzk… 完全… 東京… 1000013 地下… 虎ノ門…     3    NA    NA   2980      0 NA   \n 7 ga2g… 鶏そ… 東京… 1760006 西武… 江古田…     2    NA    NA    850      0 NA   \n 8 gg9m… 宴会… 東京… 1010021 ＪＲ  秋葉原…     4    NA    NA   2000      3  3.33\n 9 gdvk… 中国… 東京… 1000006 ＪＲ  有楽町…     1    NA    NA   1000      2  2.5 \n10 gggb… 中国… 東京… 1140002 地下… 王子駅      2    NA    NA   2000      0 NA   \n# … with 6,282 more rows\n\n\n　かなり長いコードになりましたね。しかし、もっと簡単な方法があります。それは-を使う方法です。\n\ndf %>%\n  select(-Latitude, -Longitude) # select(-c(Latitude, Longitude))\n\n# A tibble: 6,292 × 12\n   ID    Name  Pref  Zipcode Line  Station  Walk   Bus   Car Budget ScoreN Score\n   <chr> <chr> <chr>   <dbl> <chr> <chr>   <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>\n 1 e539… 居酒… 東京… 1040031 地下… 銀座一…     3    NA    NA   3000      0 NA   \n 2 gfeb… 本格… 東京… 1100005 地下… 仲御徒…     1    NA    NA   2000      2  4.5 \n 3 ggt5… 食べ… 東京… 1250041 ＪＲ… 金町駅      2    NA    NA   2980      0 NA   \n 4 g181… 博多… 東京… 1920904 ＪＲ  八王子…     1    NA    NA   2000      0 NA   \n 5 ggww… まさ… 東京… 1500042 地下… 渋谷駅      7    NA    NA    380      0 NA   \n 6 gdzk… 完全… 東京… 1000013 地下… 虎ノ門…     3    NA    NA   2980      0 NA   \n 7 ga2g… 鶏そ… 東京… 1760006 西武… 江古田…     2    NA    NA    850      0 NA   \n 8 gg9m… 宴会… 東京… 1010021 ＪＲ  秋葉原…     4    NA    NA   2000      3  3.33\n 9 gdvk… 中国… 東京… 1000006 ＪＲ  有楽町…     1    NA    NA   1000      2  2.5 \n10 gggb… 中国… 東京… 1140002 地下… 王子駅      2    NA    NA   2000      0 NA   \n# … with 6,282 more rows\n\n\n　除外したい変数名の前に-を付けただけです。また、-Latitudeと-Longitudeをそれぞれ指定せず、-c(Latitude, Longitude)のようにc()でまとめるのも可能です。\n\n12.3.4 隣接した列を指定する\n　先ほど、dfから緯度 (Latitude)と経度 (Longitude)を除外する例を考えてみましょう。-を使うと簡単ですが、場合によっては残す変数名を指定する必要もあります。\n\ndf %>%\n  select(ID, Name, Pref, Zipcode, \n         Line, Station, Walk, Bus, Car, Budget, ScoreN, Score)\n\n　よく考えてみれば、IDからZipcodeは隣接した列ですし、LineからScoreまでもそうです。これはnames()関数で確認できます。\n\nnames(df)\n\n [1] \"ID\"        \"Name\"      \"Pref\"      \"Zipcode\"   \"Latitude\"  \"Longitude\"\n [7] \"Line\"      \"Station\"   \"Walk\"      \"Bus\"       \"Car\"       \"Budget\"   \n[13] \"ScoreN\"    \"Score\"    \n\n\n　ここで便利な演算子が:です。これまで、xからyまでの公差1の等差数列を作成する際にx:yを使って来ましたが、これに非常に似ています。データフレームの「x列からy列まで」の表記もselect()関数内では:と書くことができます。したがって、上記のコードは以下のように短縮化可能です。\n\ndf %>%\n  select(ID:Zipcode, Line:Score)\n\n　「dfのIDからZipcodeまで、そしてLineからScoreまでの列を選択する」という意味です。非常に便利な演算子ですので、-と合わせて覚えておきましょう。\n\n12.3.5 一部の列の順番だけを変える\n　ある列の位置を替えたいとします。たとえば、ScoreとScoreNをそれぞれ1列目、2列目にしたい場合、どうすれば良いでしょうか。これまで勉強したことを考えると、以下のようなコードで問題ないでしょう。\n\ndf %>%\n  select(Score, ScoreN, ID:Budget)\n\n# A tibble: 6,292 × 14\n   Score ScoreN ID      Name  Pref   Zipcode Latit…¹ Longi…² Line  Station  Walk\n   <dbl>  <dbl> <chr>   <chr> <chr>    <dbl>   <dbl>   <dbl> <chr> <chr>   <dbl>\n 1 NA         0 e539604 居酒… 東京都 1040031    35.7    140. 地下… 銀座一…     3\n 2  4.5       2 gfeb600 本格… 東京都 1100005    35.7    140. 地下… 仲御徒…     1\n 3 NA         0 ggt5900 食べ… 東京都 1250041    35.8    140. ＪＲ… 金町駅      2\n 4 NA         0 g181340 博多… 東京都 1920904    35.7    139. ＪＲ  八王子…     1\n 5 NA         0 ggww100 まさ… 東京都 1500042    35.7    140. 地下… 渋谷駅      7\n 6 NA         0 gdzk500 完全… 東京都 1000013    35.7    140. 地下… 虎ノ門…     3\n 7 NA         0 ga2g202 鶏そ… 東京都 1760006    35.7    140. 西武… 江古田…     2\n 8  3.33      3 gg9m100 宴会… 東京都 1010021    35.7    140. ＪＲ  秋葉原…     4\n 9  2.5       2 gdvk200 中国… 東京都 1000006    35.7    140. ＪＲ  有楽町…     1\n10 NA         0 gggb200 中国… 東京都 1140002    35.8    140. 地下… 王子駅      2\n# … with 6,282 more rows, 3 more variables: Bus <dbl>, Car <dbl>, Budget <dbl>,\n#   and abbreviated variable names ¹​Latitude, ²​Longitude\n\n\n　しかし、{dplyr}にはrelocate()というより便利な専用関数を提供しています。relocate()には変数名を指定するだけですが、ここで指定した変数がデータフレームの最初列の方に移動します。\n\ndf %>%\n  relocate(Score, ScoreN)\n\n# A tibble: 6,292 × 14\n   Score ScoreN ID      Name  Pref   Zipcode Latit…¹ Longi…² Line  Station  Walk\n   <dbl>  <dbl> <chr>   <chr> <chr>    <dbl>   <dbl>   <dbl> <chr> <chr>   <dbl>\n 1 NA         0 e539604 居酒… 東京都 1040031    35.7    140. 地下… 銀座一…     3\n 2  4.5       2 gfeb600 本格… 東京都 1100005    35.7    140. 地下… 仲御徒…     1\n 3 NA         0 ggt5900 食べ… 東京都 1250041    35.8    140. ＪＲ… 金町駅      2\n 4 NA         0 g181340 博多… 東京都 1920904    35.7    139. ＪＲ  八王子…     1\n 5 NA         0 ggww100 まさ… 東京都 1500042    35.7    140. 地下… 渋谷駅      7\n 6 NA         0 gdzk500 完全… 東京都 1000013    35.7    140. 地下… 虎ノ門…     3\n 7 NA         0 ga2g202 鶏そ… 東京都 1760006    35.7    140. 西武… 江古田…     2\n 8  3.33      3 gg9m100 宴会… 東京都 1010021    35.7    140. ＪＲ  秋葉原…     4\n 9  2.5       2 gdvk200 中国… 東京都 1000006    35.7    140. ＪＲ  有楽町…     1\n10 NA         0 gggb200 中国… 東京都 1140002    35.8    140. 地下… 王子駅      2\n# … with 6,282 more rows, 3 more variables: Bus <dbl>, Car <dbl>, Budget <dbl>,\n#   and abbreviated variable names ¹​Latitude, ²​Longitude\n\n\n　relocate()を使うとID:Budgetが省略可能となり、より短いコードになります。もう一つの例は、最初に持ってくるのではなく、「ある変数の前」または「ある変数の後」に移動させるケースです。これもrelocate()で可能ですが、もう一つの引数が必要です。PrefとZipcdoeの順番を変えるなら、まずは以下のような方法が考えられます。\n\ndf %>%\n  select(ID:Name, Zipcode, Pref, Latitude:Score)\n\n# A tibble: 6,292 × 14\n   ID      Name    Zipcode Pref  Latit…¹ Longi…² Line  Station  Walk   Bus   Car\n   <chr>   <chr>     <dbl> <chr>   <dbl>   <dbl> <chr> <chr>   <dbl> <dbl> <dbl>\n 1 e539604 居酒屋… 1040031 東京…    35.7    140. 地下… 銀座一…     3    NA    NA\n 2 gfeb600 本格上… 1100005 東京…    35.7    140. 地下… 仲御徒…     1    NA    NA\n 3 ggt5900 食べ飲… 1250041 東京…    35.8    140. ＪＲ… 金町駅      2    NA    NA\n 4 g181340 博多餃… 1920904 東京…    35.7    139. ＪＲ  八王子…     1    NA    NA\n 5 ggww100 まさ屋… 1500042 東京…    35.7    140. 地下… 渋谷駅      7    NA    NA\n 6 gdzk500 完全個… 1000013 東京…    35.7    140. 地下… 虎ノ門…     3    NA    NA\n 7 ga2g202 鶏そば… 1760006 東京…    35.7    140. 西武… 江古田…     2    NA    NA\n 8 gg9m100 宴会個… 1010021 東京…    35.7    140. ＪＲ  秋葉原…     4    NA    NA\n 9 gdvk200 中国料… 1000006 東京…    35.7    140. ＪＲ  有楽町…     1    NA    NA\n10 gggb200 中国料… 1140002 東京…    35.8    140. 地下… 王子駅      2    NA    NA\n# … with 6,282 more rows, 3 more variables: Budget <dbl>, ScoreN <dbl>,\n#   Score <dbl>, and abbreviated variable names ¹​Latitude, ²​Longitude\n\n\n　これをrelocate()で書き換えるなら、.afterまたは.before引数が必要になります。relocate(変数名1, .after = 変数名2)は「変数1を変数2の直後に移動させる」 ことを意味します。\n\ndf %>%\n  relocate(Pref, .after = Zipcode)\n\n# A tibble: 6,292 × 14\n   ID      Name    Zipcode Pref  Latit…¹ Longi…² Line  Station  Walk   Bus   Car\n   <chr>   <chr>     <dbl> <chr>   <dbl>   <dbl> <chr> <chr>   <dbl> <dbl> <dbl>\n 1 e539604 居酒屋… 1040031 東京…    35.7    140. 地下… 銀座一…     3    NA    NA\n 2 gfeb600 本格上… 1100005 東京…    35.7    140. 地下… 仲御徒…     1    NA    NA\n 3 ggt5900 食べ飲… 1250041 東京…    35.8    140. ＪＲ… 金町駅      2    NA    NA\n 4 g181340 博多餃… 1920904 東京…    35.7    139. ＪＲ  八王子…     1    NA    NA\n 5 ggww100 まさ屋… 1500042 東京…    35.7    140. 地下… 渋谷駅      7    NA    NA\n 6 gdzk500 完全個… 1000013 東京…    35.7    140. 地下… 虎ノ門…     3    NA    NA\n 7 ga2g202 鶏そば… 1760006 東京…    35.7    140. 西武… 江古田…     2    NA    NA\n 8 gg9m100 宴会個… 1010021 東京…    35.7    140. ＪＲ  秋葉原…     4    NA    NA\n 9 gdvk200 中国料… 1000006 東京…    35.7    140. ＪＲ  有楽町…     1    NA    NA\n10 gggb200 中国料… 1140002 東京…    35.8    140. 地下… 王子駅      2    NA    NA\n# … with 6,282 more rows, 3 more variables: Budget <dbl>, ScoreN <dbl>,\n#   Score <dbl>, and abbreviated variable names ¹​Latitude, ²​Longitude\n\n\n　.beforeを使うことできます。この場合は「ZipcodeをPrefの直前に移動させる」 ことを指定する必要があります。結果は省略しますが、自分でコードを走らせ、上と同じ結果が得られるかを確認してみてください。\n\ndf %>%\n  relocate(Zipcode, .before = Pref)\n\n\n12.3.6 select()の便利な機能\n　select()関数は他にも便利な機能がいくつかあります。ここではいくつの機能を紹介しますが、より詳しい内容は?dplyr::selectを参照してください。\nstarts_with()とends_with()、contains()、num_range(): 特定の文字を含む変数を選択する\n　まずは、特定の文字を含む変数名を指定する方法です。starts_with(\"X\")、ends_with(\"X\")、contains(\"X\")は変数名が\"X\"で始まるか、\"X\"で終わるか、\"X\"を含むかを判断し、条件に合う変数名を返す関数です。実際の例を見ましょう。\n\n# ID、Nameに続いて、Scoreで始まる変数名を抽出\ndf %>%\n  select(ID, Name, starts_with(\"Score\"))\n\n# A tibble: 6,292 × 4\n   ID      Name                                                     ScoreN Score\n   <chr>   <chr>                                                     <dbl> <dbl>\n 1 e539604 居酒屋 龍記 京橋店                                            0 NA   \n 2 gfeb600 本格上海料理 新錦江 上野御徒町本店                            2  4.5 \n 3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ）                    0 NA   \n 4 g181340 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル）併設      0 NA   \n 5 ggww100 まさ屋 渋谷店                                                 0 NA   \n 6 gdzk500 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店                   0 NA   \n 7 ga2g202 鶏そば きらり                                                 0 NA   \n 8 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店                         3  3.33\n 9 gdvk200 中国料理 宝龍                                                 2  2.5 \n10 gggb200 中国料理 天安門                                               0 NA   \n# … with 6,282 more rows\n\n# eで終わる変数名を除去\ndf %>%\n  select(-ends_with(\"e\")) # !ends_with(\"e\")も可能\n\n# A tibble: 6,292 × 8\n   ID      Pref   Station       Walk   Bus   Car Budget ScoreN\n   <chr>   <chr>  <chr>        <dbl> <dbl> <dbl>  <dbl>  <dbl>\n 1 e539604 東京都 銀座一丁目駅     3    NA    NA   3000      0\n 2 gfeb600 東京都 仲御徒町駅       1    NA    NA   2000      2\n 3 ggt5900 東京都 金町駅           2    NA    NA   2980      0\n 4 g181340 東京都 八王子駅         1    NA    NA   2000      0\n 5 ggww100 東京都 渋谷駅           7    NA    NA    380      0\n 6 gdzk500 東京都 虎ノ門駅         3    NA    NA   2980      0\n 7 ga2g202 東京都 江古田駅         2    NA    NA    850      0\n 8 gg9m100 東京都 秋葉原駅         4    NA    NA   2000      3\n 9 gdvk200 東京都 有楽町駅         1    NA    NA   1000      2\n10 gggb200 東京都 王子駅           2    NA    NA   2000      0\n# … with 6,282 more rows\n\n# reを含む変数名を抽出するが、ScoreNは除去する\ndf %>%\n  select(contains(\"re\"), -ScoreN)\n\n# A tibble: 6,292 × 2\n   Pref   Score\n   <chr>  <dbl>\n 1 東京都 NA   \n 2 東京都  4.5 \n 3 東京都 NA   \n 4 東京都 NA   \n 5 東京都 NA   \n 6 東京都 NA   \n 7 東京都 NA   \n 8 東京都  3.33\n 9 東京都  2.5 \n10 東京都 NA   \n# … with 6,282 more rows\n\n\n　他の使い方としてはX1、X2のような「文字+数字」の変数を選択する際、starts_with()が活躍します。たとえば、以下のようなmyDF1があるとします。\n\n# tibble()でなく、data.frame()も使用可能です。\nmyDF1 <- tibble(\n  ID  = 1:5,\n  X1  = c(2, 4, 6, 2, 7),\n  Y1  = c(3, 5, 1, 1, 0),\n  X1D = c(4, 2, 1, 6, 9),\n  X2  = c(5, 5, 6, 0, 2),\n  Y2  = c(3, 3, 2, 3, 1),\n  X2D = c(8, 9, 5, 0, 1),\n  X3  = c(3, 0, 3, 0, 2),\n  Y3  = c(1, 5, 9, 1, 3),\n  X3D = c(9, 1, 3, 3, 8)\n)\n\nmyDF1\n\n# A tibble: 5 × 10\n     ID    X1    Y1   X1D    X2    Y2   X2D    X3    Y3   X3D\n  <int> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>\n1     1     2     3     4     5     3     8     3     1     9\n2     2     4     5     2     5     3     9     0     5     1\n3     3     6     1     1     6     2     5     3     9     3\n4     4     2     1     6     0     3     0     0     1     3\n5     5     7     0     9     2     1     1     2     3     8\n\n\n　このmyDF1からID、Y1、Y2、Y3を抽出するにはどうすれば良いでしょうか。これらの変数は隣接していないため、:も使えませんが、starts_with()を使えば簡単です。\n\nmyDF1 %>%\n  select(ID, starts_with(\"Y\"))\n\n# A tibble: 5 × 4\n     ID    Y1    Y2    Y3\n  <int> <dbl> <dbl> <dbl>\n1     1     3     3     1\n2     2     5     3     5\n3     3     1     2     9\n4     4     1     3     1\n5     5     0     1     3\n\n\n　それでは、ID、X1、X2、X3はどうでしょうか。starts_with(\"X\")だと、X1cなども選択されてしまいますね。ここで-ends_with()の出番です。つまり、「まずはstarts_with(\"X\")でXで始まる変数を選択し、続いて、Dで終わるものを除外すればいいじゃん？」です。それでは、やってみましょうか。\n\nmyDF1 %>%\n  select(ID, starts_with(\"X\"), -ends_with(\"D\"))\n\n# A tibble: 5 × 3\n     X1    X2    X3\n  <dbl> <dbl> <dbl>\n1     2     5     3\n2     4     5     0\n3     6     6     3\n4     2     0     0\n5     7     2     2\n\n\n　あらら、IDも同時になくなりましたね1。実はこのような時のために用意された関数があり、それがnum_range()です。num_range()の第一引数はstarts_with()関数と同じですが、第二引数も必要です。この第二引数にはnumeric型のベクトルが必要です。1:3でも、c(1, 2, 3)でも構いません。たとえば、ID、X1、X2、X3するには以下のように書きます。\n\nmyDF1 %>%\n  select(ID, num_range(\"X\", 1:3))\n\n# A tibble: 5 × 4\n     ID    X1    X2    X3\n  <int> <dbl> <dbl> <dbl>\n1     1     2     5     3\n2     2     4     5     0\n3     3     6     6     3\n4     4     2     0     0\n5     5     7     2     2\n\n\nall_of()とany_of(): 文字型ベクトルを用いた変数の選択\n　all_of()とany_of()はselect()内の変数名として文字型ベクトルを使う際に用いる関数です。これは抽出したい列名が既にcharacter型ベクトルとして用意されている場合、便利な関数です。たとえば、以下のName_Vecを考えてみましょう。\n\nName_Vec <- c(\"X1\", \"X2\", \"X3\")\n\n　このName_Vecの要素と同じ列名を持つ列とID列をmyDF1から抽出する方法は以下の2通りです。\n\nmyDF1[, c(\"ID\", Name_Vec)]\n\n# A tibble: 5 × 4\n     ID    X1    X2    X3\n  <int> <dbl> <dbl> <dbl>\n1     1     2     5     3\n2     2     4     5     0\n3     3     6     6     3\n4     4     2     0     0\n5     5     7     2     2\n\nmyDF1 %>%\n  select(ID, all_of(Name_Vec))\n\n# A tibble: 5 × 4\n     ID    X1    X2    X3\n  <int> <dbl> <dbl> <dbl>\n1     1     2     5     3\n2     2     4     5     0\n3     3     6     6     3\n4     4     2     0     0\n5     5     7     2     2\n\n\n　今の例だと、select()を使わない前者の方が便利かも知れませんが、select()内に外の変数名も指定する場合も多いので、後者の方が汎用性は高いです。私から見れば、今の例でも後者の方が読みやすく、使いやすいと思います。\n　それでは以下のようなName_Vecはどうでしょう。今回は、myDF1に含まれていないX4とX5もあります。\n\nName_Vec <- c(\"X1\", \"X2\", \"X3\", \"X4\", \"X5\")\n\nmyDF1 %>%\n  select(all_of(Name_Vec))\n\n## Error: Can't subset columns that don't exist.\n##   Columns `X4` and `X5` don't exist.\n　このようにエラーが出てしまします。つまり、all_of()の場合、引数の要素全てがデータフレームに存在する必要があります。もし、ないものは無視して、合致する列だけ取り出したいはどうすれば良いでしょうか。そこで登場するのがany_of()です。\n\nmyDF1 %>%\n  select(any_of(Name_Vec))\n\n# A tibble: 5 × 3\n     X1    X2    X3\n  <dbl> <dbl> <dbl>\n1     2     5     3\n2     4     5     0\n3     6     6     3\n4     2     0     0\n5     7     2     2\n\n\n　any_of()の方がより使いやすいと思う方も多いでしょうが、必ずしもそうとは限りません。たとえば、Name_Vecに誤字などが含まれる場合、any_of()だと誤字が含まれている変数は取り出しません。この場合はむしろちゃんとエラーを表示してくれた方が嬉しいですね。\nlast_col(): 最後の列を選択する\n　普段あまり使わない機能ですが、最後の列を選択するlast_col()という関数もあります。\n\n# IDと最後の列のみを抽出\ndf %>%\n  select(ID, last_col(0))\n\n# A tibble: 6,292 × 2\n   ID      Score\n   <chr>   <dbl>\n 1 e539604 NA   \n 2 gfeb600  4.5 \n 3 ggt5900 NA   \n 4 g181340 NA   \n 5 ggww100 NA   \n 6 gdzk500 NA   \n 7 ga2g202 NA   \n 8 gg9m100  3.33\n 9 gdvk200  2.5 \n10 gggb200 NA   \n# … with 6,282 more rows\n\n\n　最後からk番目の列を指定することも可能です。最後の列の番号が0であり、その手前の列は1となります。つまり、last_col()の中には「最後から何番目の列か」を指定すれば良いです。最後の列は最後の列そのままなので0です。\n\n# IDと最後から2列目を抽出\ndf %>%\n  select(ID, last_col(1))\n\n# A tibble: 6,292 × 2\n   ID      ScoreN\n   <chr>    <dbl>\n 1 e539604      0\n 2 gfeb600      2\n 3 ggt5900      0\n 4 g181340      0\n 5 ggww100      0\n 6 gdzk500      0\n 7 ga2g202      0\n 8 gg9m100      3\n 9 gdvk200      2\n10 gggb200      0\n# … with 6,282 more rows\n\n\n　このlast_col()の引数を指定しないと、それは最後の列を意味します。つまり、last_col()とlast_col(0)は同じです。これを利用すれば、「ある変数の最後の列へ移動させる」こともできます。たとえば、IDを最後の列に移動させたい場合、relocate(ID, .after = last_col())のように書きます。\nwhere(): データ型から変数を選択する\n　最後に、「numeric型の列のみ抽出したい」、「character型の列だけほしい」場合に便利なwhere()関数を紹介します。where()の中に入る引数は一つだけであり、データ型を判定する関数名が入ります。たとえば、numeric型か否かを判断する関数はis.numeric()です。dfからnumeric型の変数のみを抽出したい場合は以下のように書きます。ただし、where()の中の関数は()を省略します。\n\n# numeric型の列を抽出する\ndf %>%\n  select(where(is.numeric))\n\n# A tibble: 6,292 × 9\n   Zipcode Latitude Longitude  Walk   Bus   Car Budget ScoreN Score\n     <dbl>    <dbl>     <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>\n 1 1040031     35.7      140.     3    NA    NA   3000      0 NA   \n 2 1100005     35.7      140.     1    NA    NA   2000      2  4.5 \n 3 1250041     35.8      140.     2    NA    NA   2980      0 NA   \n 4 1920904     35.7      139.     1    NA    NA   2000      0 NA   \n 5 1500042     35.7      140.     7    NA    NA    380      0 NA   \n 6 1000013     35.7      140.     3    NA    NA   2980      0 NA   \n 7 1760006     35.7      140.     2    NA    NA    850      0 NA   \n 8 1010021     35.7      140.     4    NA    NA   2000      3  3.33\n 9 1000006     35.7      140.     1    NA    NA   1000      2  2.5 \n10 1140002     35.8      140.     2    NA    NA   2000      0 NA   \n# … with 6,282 more rows\n\n\n　!を使って条件に合致する列を除外することも可能です。もし、character型の列を除外する場合は以下のように!where(is.character)を指定します。\n\n# character型でない列を抽出する\ndf %>%\n  select(!where(is.character))\n\n# A tibble: 6,292 × 9\n   Zipcode Latitude Longitude  Walk   Bus   Car Budget ScoreN Score\n     <dbl>    <dbl>     <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>\n 1 1040031     35.7      140.     3    NA    NA   3000      0 NA   \n 2 1100005     35.7      140.     1    NA    NA   2000      2  4.5 \n 3 1250041     35.8      140.     2    NA    NA   2980      0 NA   \n 4 1920904     35.7      139.     1    NA    NA   2000      0 NA   \n 5 1500042     35.7      140.     7    NA    NA    380      0 NA   \n 6 1000013     35.7      140.     3    NA    NA   2980      0 NA   \n 7 1760006     35.7      140.     2    NA    NA    850      0 NA   \n 8 1010021     35.7      140.     4    NA    NA   2000      3  3.33\n 9 1000006     35.7      140.     1    NA    NA   1000      2  2.5 \n10 1140002     35.8      140.     2    NA    NA   2000      0 NA   \n# … with 6,282 more rows\n\n\n　&を使って複数の条件を使うことも可能です。たとえば、ID変数に加えて「\"L\"で始まる変数の中でnumeric型の列を抽出」するコードは以下のようになります。\n\n# IDと、Lで始まるnumeric型の列を抽出する\ndf %>%\n  select(ID, starts_with(\"L\") & where(is.numeric))\n\n# A tibble: 6,292 × 3\n   ID      Latitude Longitude\n   <chr>      <dbl>     <dbl>\n 1 e539604     35.7      140.\n 2 gfeb600     35.7      140.\n 3 ggt5900     35.8      140.\n 4 g181340     35.7      139.\n 5 ggww100     35.7      140.\n 6 gdzk500     35.7      140.\n 7 ga2g202     35.7      140.\n 8 gg9m100     35.7      140.\n 9 gdvk200     35.7      140.\n10 gggb200     35.8      140.\n# … with 6,282 more rows"
  },
  {
    "objectID": "datahandling1.html#RN4Esec-handling1-filter",
    "href": "datahandling1.html#RN4Esec-handling1-filter",
    "title": "12  データハンドリング [抽出]",
    "section": "\n12.4 行の抽出",
    "text": "12.4 行の抽出\n\n12.4.1 指定した行を抽出する\n　他にも特定の行を抽出する場合があります。たとえば、「dfの最初の5行」や「dfの8行目のケース」といった場合です。この操作には{dplyr}のslice_*()関数群が便利です。それではそれぞれの関数の使い方について紹介していきます。その前に、実習用データとしてdfから一部の列のみを抽出したselelct.dfを作成します。\n\nselect.df <- df %>% \n  select(ID, Name, Pref, Budget, Score)\n\nslice(): 指定した番号の行のみ抽出する\n　select.dfから2, 8, 9行目の行を抽出したいとします。このような簡単な操作はパッケージを使わず、以下のように抽出することができます。\n\n# select.dfから2, 8, 9行目の行を抽出し、出力する\nselect.df[c(2, 8, 9),]\n\n# A tibble: 3 × 5\n  ID      Name                                  Pref   Budget Score\n  <chr>   <chr>                                 <chr>   <dbl> <dbl>\n1 gfeb600 本格上海料理 新錦江 上野御徒町本店    東京都   2000  4.5 \n2 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店 東京都   2000  3.33\n3 gdvk200 中国料理 宝龍                         東京都   1000  2.5 \n\n\n　しかし、以下のslice()関数を使うとパイプ演算子を前後に付けることが可能であり2、コードの可読性も高いです。slice()関数には以下のように抽出したい行の番号を入れるだけです。\n\n# select.dfから2, 8, 9行目の行を抽出し、出力する\nselect.df %>% \n  slice(2, 8, 9) # slice(c(2, 8, 9))もOK\n\n# A tibble: 3 × 5\n  ID      Name                                  Pref   Budget Score\n  <chr>   <chr>                                 <chr>   <dbl> <dbl>\n1 gfeb600 本格上海料理 新錦江 上野御徒町本店    東京都   2000  4.5 \n2 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店 東京都   2000  3.33\n3 gdvk200 中国料理 宝龍                         東京都   1000  2.5 \n\n\n　slice(2, 8, 9)でもslice(c(2, 8, 9))でも構いません。また、隣接した行でしたら:を使うことも可能です。たとえば、10行目から15行目まで抽出する場合はslice(10:15)のような書き方も出来ます。\nslice_head(): 最初のn行を抽出する\n\n# select.dfから最初の3行抽出し、出力する\nselect.df %>% \n  slice_head(n = 3)\n\n# A tibble: 3 × 5\n  ID      Name                                       Pref   Budget Score\n  <chr>   <chr>                                      <chr>   <dbl> <dbl>\n1 e539604 居酒屋 龍記 京橋店                         東京都   3000  NA  \n2 gfeb600 本格上海料理 新錦江 上野御徒町本店         東京都   2000   4.5\n3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ） 東京都   2980  NA  \n\n\n　これはhead(データ名, n = 出力する個数)と同じ動きをする関数です。注意点としては引数n =を必ず付ける点です。たとえば、slice_head(3)にすると、select.dfの3行目のみ抽出されます。\nslice_tail(): 最後のn行を抽出する\n\n# select.dfから最後の7行を抽出し、出力する\nselect.df %>% \n  slice_tail(n = 7)\n\n# A tibble: 7 × 5\n  ID      Name                    Pref     Budget Score\n  <chr>   <chr>                   <chr>     <dbl> <dbl>\n1 5508852 場鶴                    和歌山県     NA    NA\n2 7113351 来来亭 橋本店           和歌山県     NA    NA\n3 6364939 ばり馬 和歌山紀三井寺店 和歌山県     NA    NA\n4 7103349 ramen BIRDMAN           和歌山県     NA    NA\n5 7315303 薩摩ラーメン 斗天王     和歌山県     NA    NA\n6 7703472 まるしげ                和歌山県     NA    NA\n7 6395035 暴豚製麺所              和歌山県     NA    NA\n\n\n　これはtail(データ名, n = 出力する個数)と同じ動きをする関数です。ちなみに、このn引数もn =を明記する必要があります。\nslice_max(): 指定した変数が大きい順でn行抽出する\n　slice_max()は指定した変数が大きい順でn行抽出する関数です。たとえば、Budgetが高い順で4店舗を抽出する場合は以下のように書きます。\n\n# select.dfからScoreの値が高い順で5行を抽出し、出力する\nselect.df %>% \n  slice_max(Budget, n = 4)\n\n# A tibble: 4 × 5\n  ID      Name                                              Pref    Budget Score\n  <chr>   <chr>                                             <chr>    <dbl> <dbl>\n1 g670609 横浜ベイシェラトン ホテル＆タワーズ 中国料理 彩龍 神奈川…   8000    NA\n2 g910420 JASMINE 憶江南                                    東京都    7000    NA\n3 7176666 赤坂焼鳥 鳳                                       東京都    7000    NA\n4 b612800 羽衣 銀座本店                                     東京都    6000    NA\n\n\nslice_min(): 指定した変数が小さい順でn行抽出する\n　一方、slice_min()関数が小さい順で抽出します。\n\n# select.dfからScoreの値が低い順で3行を抽出し、出力する\nselect.df %>% \n  slice_min(Score, n = 3)\n\n# A tibble: 4 × 5\n  ID      Name                        Pref   Budget Score\n  <chr>   <chr>                       <chr>   <dbl> <dbl>\n1 6384909 葛西大勝軒                  東京都     NA     1\n2 6929243 由丸 アトレヴィ大塚店       東京都     NA     1\n3 5816075 ラーメン戯拉戯拉            千葉県     NA     1\n4 5495086 らあめん花月嵐 坂戸わかば店 埼玉県     NA     1\n\n\n　ただし、n = 3と指定したはずなのに、4行が抽出されました。これは同点のケースがあるからです。実際、select.dfにはScoreが1のケースが4つあります。もし、同点の存在によりnに収まらない場合、slice_max()、slice_min()関数はnを超える行を出力します。これを強制的にn行に合わせるためにはwith_ties = FALSE引数を付けます。この場合、データで格納されている順でn個のみ出力されます。\n\nselect.df %>% \n  slice_min(Score, n = 3, with_ties = FALSE)\n\n# A tibble: 3 × 5\n  ID      Name                  Pref   Budget Score\n  <chr>   <chr>                 <chr>   <dbl> <dbl>\n1 6384909 葛西大勝軒            東京都     NA     1\n2 6929243 由丸 アトレヴィ大塚店 東京都     NA     1\n3 5816075 ラーメン戯拉戯拉      千葉県     NA     1\n\n\nslice_sample(): 無作為にn行を抽出する\n　最後に無作為にn行を抽出するslice_sample()関数です。引数はnであり、抽出したい行数を指定します。たとえば、select.dfから無作為に10行抽出したい場合は、\n\n# select.dfから無作為に5行を抽出し、出力する\nselect.df %>% \n  slice_sample(n = 10)\n\n# A tibble: 10 × 5\n   ID      Name                      Pref     Budget Score\n   <chr>   <chr>                     <chr>     <dbl> <dbl>\n 1 7680282 麺屋 七利屋               神奈川県     NA NA   \n 2 6911281 葵 aoi                    大阪府       NA NA   \n 3 5506914 昇龍軒 都島店             大阪府       NA NA   \n 4 a424601 胡椒饅頭 ＰＡＯＰＡＯ     東京都     3200  3.62\n 5 7070848 中華そば専門店 みたか     兵庫県       NA NA   \n 6 7759003 仙楽                      大阪府       NA NA   \n 7 7433492 鶏SOBA 春夏冬～あきない～ 千葉県       NA NA   \n 8 5506565 天下一品 二条駅前店       京都府       NA  3   \n 9 7271144 津久野飯店                大阪府       NA NA   \n10 5494199 やまちやんラーメン        埼玉県       NA NA   \n\n\nのように書きます。ブートストラップ法や機械学習における交差検証 (cross-validation)の際に有用な関数ですが、ブートストラップや機械学習のパッケージの多くはサンプル分割の関数を提供しているため、あまり使う機会はないでしょう。また、slice_sample()関数をブートストラップ法のために用いる場合は、ケースを反復抽出する必要があり、replace = TRUEを付けると反復抽出を行います。デフォルト値はFALSEです。\n\n12.4.2 条件に合致する行を抽出する\n　これまで見てきたslice()を用いる行の抽出は、実際あまり使う機会がありません。多くの場合、「何かの条件と合致するケースのみ抽出する」または、「何かの条件と合致しないケースのみを抽出する」やこれらの組み合わせで行の抽出を行います。そこで登場するのがdplyr()パッケージのfilter()関数です。filter()関数の使い方は以下の通りです。\n\n# dplyr::filter()の使い方\nfilter(データフレーム名, 条件1, 条件2, ...)\n\n　むろん、第一引数がデータですから、%>%を使うことも可能です。\n\n# dplyr::filter()の使い方 (パイプを使う方法)\nデータフレーム名 %>%\n  filter(条件1, 条件2, ...)\n\n　まずは、条件が一つの場合を考えてみましょう。ここでは「Prefが\"京都府\"であるケースのみに絞り、NameとStation、Score列のみを出力する」ケースを考えてみましょう。まず、filter()関数で行を抽出し、続いてselect()関数で抽出する列を指定します。むろん、今回の場合、filter()とselect()の順番は替えても構いません。\n\n# dfからPrefが\"京都府\"であるケースのみ残し、df2という名で保存\ndf2 <- df %>%\n  filter(Pref == \"京都府\")\n\n# df2からName, Station, Score列を抽出\ndf2 %>%\n  select(Name, Station, Score)\n\n# A tibble: 414 × 3\n   Name                                                    Station    Score\n   <chr>                                                   <chr>      <dbl>\n 1 中国料理 鳳麟                                           くいな橋駅 NA   \n 2 黒毛和牛一頭買い焼肉と 炊き立て土鍋ご飯 市場小路 烏丸店 四条駅      3.19\n 3 京の中華 ハマムラ みやこみち店                          京都駅     NA   \n 4 焼肉処 真 桂店                                          桂駅       NA   \n 5 祇園京都ラーメン                                        祇園四条駅 NA   \n 6 創作料理 串カツ トンカツ jiro                           新田辺駅   NA   \n 7 祇園 晩餐のあと                                         祇園四条駅 NA   \n 8 DETAIL                                                  東山駅     NA   \n 9 めんや龍神                                              北大路駅   NA   \n10 無尽蔵 京都八条家                                       京都駅      3.5 \n# … with 404 more rows\n\n\n　これはdfからPref == \"京都府\"のケースのみ残したものをdf2として格納し、それをまたselect()関数を使って列を抽出するコードです。これでも問題ありませんが、これだとパイプ演算子の便利さが分かりません。パイプ演算子は複数使うことが可能です。\n\ndf %>%\n  filter(Pref == \"京都府\") %>%\n  select(Name, Station, Score)\n\n# A tibble: 414 × 3\n   Name                                                    Station    Score\n   <chr>                                                   <chr>      <dbl>\n 1 中国料理 鳳麟                                           くいな橋駅 NA   \n 2 黒毛和牛一頭買い焼肉と 炊き立て土鍋ご飯 市場小路 烏丸店 四条駅      3.19\n 3 京の中華 ハマムラ みやこみち店                          京都駅     NA   \n 4 焼肉処 真 桂店                                          桂駅       NA   \n 5 祇園京都ラーメン                                        祇園四条駅 NA   \n 6 創作料理 串カツ トンカツ jiro                           新田辺駅   NA   \n 7 祇園 晩餐のあと                                         祇園四条駅 NA   \n 8 DETAIL                                                  東山駅     NA   \n 9 めんや龍神                                              北大路駅   NA   \n10 無尽蔵 京都八条家                                       京都駅      3.5 \n# … with 404 more rows\n\n\n　全く同じ結果ですが、無駄にdf2というデータフレームを作らず済むので、メモリの観点からも嬉しいですし、何よりコードが短く、しかも可読性も上がりました。\n　今回は==を使って合致するものに絞りましたが、!=を使って合致しないものに絞ることも可能です。または、比較演算子 (<、>、>=、<=など)を使うことも可能です。それでは、組み込み数 (ScoreN)が0ではないケースを取り出し、Name、Station、ScoreN、Score列を出力させてみましょう。\n\ndf %>%\n  filter(ScoreN != 0) %>%\n  select(Name, Station, starts_with(\"Score\"))\n\n# A tibble: 1,344 × 4\n   Name                                              Station       ScoreN Score\n   <chr>                                             <chr>          <dbl> <dbl>\n 1 本格上海料理 新錦江 上野御徒町本店                仲御徒町駅         2  4.5 \n 2 宴会個室×餃子酒場 北京飯店 秋葉原本店             秋葉原駅           3  3.33\n 3 中国料理 宝龍                                     有楽町駅           2  2.5 \n 4 麺達 うま家                                       高田馬場駅         2  3   \n 5 刀削麺・火鍋・西安料理 XI’AN（シーアン） 後楽園店 後楽園駅           1 NA   \n 6 七志らーめん 渋谷道玄坂店                         渋谷駅             7  4.5 \n 7 永楽                                              京成小岩駅         6  4.42\n 8 よってこや お台場店                               お台場海浜公…      1  4   \n 9 ラーメン武藤製麺所                                竹ノ塚駅           4  3.5 \n10 桂花ラーメン 新宿末広店                           新宿三丁目駅       8  3   \n# … with 1,334 more rows\n\n\n　これで口コミ数が1以上の店舗のみに絞ることができました。ただし、店によっては口コミはあっても、評価 (Score)が付いていないところもあります。たとえば、「刀削麺・火鍋・西安料理 XI’AN（シーアン） 後楽園店」の場合、口コミはありますが、評価はありません。したがって、今回は評価が付いている店舗に絞ってみましょう。\n\ndf %>%\n  filter(Score != NA) %>%\n  select(Name, Station, starts_with(\"Score\"))\n\n# A tibble: 0 × 4\n# … with 4 variables: Name <chr>, Station <chr>, ScoreN <dbl>, Score <dbl>\n\n\n　あらら、何の結果も表示されませんでした。これはfilter()内の条件に合致するケースが存在しないことを意味します。しかし、先ほどの結果を見ても、評価が付いている店はいっぱいありましたね。これはなぜでしょう。\n　察しの良い読者さんは気づいているかと思いますが、第8.8章で説明した通り、NAか否かを判定する際は==や!=は使えません。is.na()を使います。filter(is.na(Score))なら「ScoreがNAであるケースに絞る」ことを意味しますが、今回は「ScoreがNAでないケースに絞る」ことが目的ですので、is.na()の前に!を付けます。\n\ndf %>%\n  filter(!is.na(Score)) %>%\n  select(Name, Station, starts_with(\"Score\"))\n\n# A tibble: 1,134 × 4\n   Name                                  Station          ScoreN Score\n   <chr>                                 <chr>             <dbl> <dbl>\n 1 本格上海料理 新錦江 上野御徒町本店    仲御徒町駅            2  4.5 \n 2 宴会個室×餃子酒場 北京飯店 秋葉原本店 秋葉原駅              3  3.33\n 3 中国料理 宝龍                         有楽町駅              2  2.5 \n 4 麺達 うま家                           高田馬場駅            2  3   \n 5 七志らーめん 渋谷道玄坂店             渋谷駅                7  4.5 \n 6 永楽                                  京成小岩駅            6  4.42\n 7 よってこや お台場店                   お台場海浜公園駅      1  4   \n 8 ラーメン武藤製麺所                    竹ノ塚駅              4  3.5 \n 9 桂花ラーメン 新宿末広店               新宿三丁目駅          8  3   \n10 北斗 新橋店                           新橋駅                4  2.5 \n# … with 1,124 more rows\n\n\n　これで口コミ評価が登録された店舗に絞ることができました。\n　続いて、複数の条件を持つケースを考えてみましょう。例えば、「京都府内の店舗で、口コミ評価が3.5以上の店舗」を出力したい場合、以下のようなコードとなります。\n\ndf %>%\n  filter(Pref == \"京都府\", Score >= 3.5) %>%\n  select(Name, Station, ScoreN, Score)\n\n# A tibble: 53 × 4\n   Name               Station    ScoreN Score\n   <chr>              <chr>       <dbl> <dbl>\n 1 無尽蔵 京都八条家  京都駅          2  3.5 \n 2 一蘭 京都河原町店  河原町駅        2  3.75\n 3 ミスター・ギョーザ 西大路駅        8  4.06\n 4 一蘭 京都八幡店    樟葉駅          3  4   \n 5 中華料理 清華園    京都駅          3  5   \n 6 まがり             <NA>            2  4   \n 7 魁力屋 北山店      北大路駅        2  4.25\n 8 大中BAL横店        <NA>            7  4.1 \n 9 こうちゃん         西舞鶴駅        1  5   \n10 大黒ラーメン       伏見桃山駅      4  4.25\n# … with 43 more rows\n\n\n　条件をfilter()内に追加するだけです。今回は!is.na(Score)は不要です。なぜなら、Score >= 3.5という条件で既に欠損値は対象外になるからです。条件文が複数ある場合、ANDかORかを指定する必要があります。つまり、条件文AとBがある場合、「AとB両方満たすものを出力する」か「AとBどちらかを満たすものを出力するか」を指定する必要があります。今の結果ってANDでしたよね。filter()関数は、別途の指定がない場合、全てAND扱いになります。RのAND演算子は&ですので、以上のコードは以下のコードと同じです。\n\ndf %>%\n  filter(Pref == \"京都府\" & Score >= 3.5) %>%\n  select(Name, Station, ScoreN, Score)\n\n# A tibble: 53 × 4\n   Name               Station    ScoreN Score\n   <chr>              <chr>       <dbl> <dbl>\n 1 無尽蔵 京都八条家  京都駅          2  3.5 \n 2 一蘭 京都河原町店  河原町駅        2  3.75\n 3 ミスター・ギョーザ 西大路駅        8  4.06\n 4 一蘭 京都八幡店    樟葉駅          3  4   \n 5 中華料理 清華園    京都駅          3  5   \n 6 まがり             <NA>            2  4   \n 7 魁力屋 北山店      北大路駅        2  4.25\n 8 大中BAL横店        <NA>            7  4.1 \n 9 こうちゃん         西舞鶴駅        1  5   \n10 大黒ラーメン       伏見桃山駅      4  4.25\n# … with 43 more rows\n\n\n　AND演算子 (&)が使えるということはOR演算子 (|)も使えることを意味します。たとえば、Stationが\"高田馬場駅\"か\"三田駅\"の条件を指定したい場合、\n\ndf %>% \n  filter(Station == \"高田馬場駅\" | Station == \"三田駅\") %>%\n  select(Name, Station, ScoreN, Score)\n\n# A tibble: 14 × 4\n   Name                                 Station    ScoreN Score\n   <chr>                                <chr>       <dbl> <dbl>\n 1 麺達 うま家                          高田馬場駅      2  3   \n 2 らぁ麺 やまぐち                      高田馬場駅      7  4.08\n 3 博多一瑞亭 三田店                    三田駅          0 NA   \n 4 つけ麺屋 ひまわり                    高田馬場駅      4  2.75\n 5 石器ラーメン 高田馬場                高田馬場駅      0 NA   \n 6 旨辛らーめん 表裏                    高田馬場駅      0 NA   \n 7 三歩一                               高田馬場駅      8  4.56\n 8 えぞ菊 戸塚店                        高田馬場駅      4  3.62\n 9 麺屋　宗                             高田馬場駅      5  4.2 \n10 とんこつラーメン 博多風龍 高田馬場店 高田馬場駅      2  3   \n11 横浜家系ラーメン 馬場壱家            高田馬場駅      0 NA   \n12 らーめん よし丸                      高田馬場駅      1  5   \n13 札幌ラーメン どさん子 三田店         三田駅          0 NA   \n14 天下一品 三田店                      三田駅          0 NA   \n\n\nのように書きます（ちなみに高田馬場の「やまぐち」は本当に美味しいです）。むろん、複数の変数を用いたORも可能です。たとえば、「Prefが\"京都府\"かScoreが3以上」のような条件も可能ですが (Pref == \"京都府\" | Score >= 3)、実際、このような例はあまりありません。よく使うのは「変数Xがaかbかcか」のような例です。ただし、この場合は|を使わないもっと簡単な方法があります。それは第10.4章で紹介した%in%演算子です。以下のコードは上のコードと同じものです。\n\ndf %>% \n  filter(Station %in% c(\"高田馬場駅\", \"三田駅\")) %>%\n  select(Name, Station, ScoreN, Score)\n\n# A tibble: 14 × 4\n   Name                                 Station    ScoreN Score\n   <chr>                                <chr>       <dbl> <dbl>\n 1 麺達 うま家                          高田馬場駅      2  3   \n 2 らぁ麺 やまぐち                      高田馬場駅      7  4.08\n 3 博多一瑞亭 三田店                    三田駅          0 NA   \n 4 つけ麺屋 ひまわり                    高田馬場駅      4  2.75\n 5 石器ラーメン 高田馬場                高田馬場駅      0 NA   \n 6 旨辛らーめん 表裏                    高田馬場駅      0 NA   \n 7 三歩一                               高田馬場駅      8  4.56\n 8 えぞ菊 戸塚店                        高田馬場駅      4  3.62\n 9 麺屋　宗                             高田馬場駅      5  4.2 \n10 とんこつラーメン 博多風龍 高田馬場店 高田馬場駅      2  3   \n11 横浜家系ラーメン 馬場壱家            高田馬場駅      0 NA   \n12 らーめん よし丸                      高田馬場駅      1  5   \n13 札幌ラーメン どさん子 三田店         三田駅          0 NA   \n14 天下一品 三田店                      三田駅          0 NA   \n\n\n　結局、|が使われるケースがかなり限定されます。あるとすれば、「変数Xがa以下か、b以上か」のようなケースですね。ただし、&と|を同時に使うケースは考えられます。たとえば、大阪駅と京都駅周辺のうまいラーメン屋を調べるとします。問題は美味しさの基準ですが、3.5点以上としましょう。ただし、京都府民はラーメンに非常に厳しく、3点以上なら美味しいと仮定します。この場合、「(Stationが\"大阪駅\"かつScore >= 3.5)、または(Stationが\"京都駅\"かつScore >= 3)」のような条件が必要になります。()は「()の中から判定せよ」という、普通の算数での使い方と同じです。それでは、実際に検索してみましょう。\n\ndf %>%\n  filter((Station == \"大阪駅\" & Score >= 3.5) | (Station == \"京都駅\" & Score >= 3)) %>%\n  select(Name, Station, Walk, ScoreN, Score)\n\n# A tibble: 6 × 5\n  Name                      Station  Walk ScoreN Score\n  <chr>                     <chr>   <dbl>  <dbl> <dbl>\n1 Lei can ting 大阪ルクア店 大阪駅      3      3  4   \n2 神座 ルクア大阪店         大阪駅      1     10  3.94\n3 みつか坊主 醸             大阪駅     10      4  5   \n4 無尽蔵 京都八条家         京都駅      5      2  3.5 \n5 中華料理 清華園           京都駅     10      3  5   \n6 ますたに 京都拉麺小路店   京都駅      9      3  3.67\n\n\n　Songが大好きな神座がヒットして嬉しいです。"
  },
  {
    "objectID": "datahandling1.html#RN4Esec-handling1-arrange",
    "href": "datahandling1.html#RN4Esec-handling1-arrange",
    "title": "12  データハンドリング [抽出]",
    "section": "\n12.5 行のソート",
    "text": "12.5 行のソート\n　続いて、行のソートについて解説します。「食べログ」などのレビューサービスを利用する場合、口コミ評価が高い順で見るのが一般的でしょう3。また、サッカーのランキングも多くは1位から下の順位で掲載されるのが一般的です。ここではこのようにある変数の値順に行を並び替える方法について説明します。\n　ソートには{dplyr}パッケージのarrange()関数を使います。引数は変数名のみです。たとえば、奈良県のラーメン屋を検索してみましょう。並び替える順は駅から近い店舗を上位に、遠い店舗を下位に並べます。このような順は昇順 (ascending)と呼ばれ、ランキング表などでよく見ます。駅から近い順にソートするので、まず最寄りの駅情報が欠損でないことが必要です。また、ラーメン屋の評価も気になるので口コミが1つ以上付いている店舗に絞りましょう。表示する列は店舗名、最寄りの駅、徒歩距離、口コミ数、点数です。\n\ndf %>%\n  filter(Pref == \"奈良県\", !is.na(Station), ScoreN > 0) %>%\n  select(Name, Station, Walk, ScoreN, Score) %>%\n  arrange(Walk) %>%\n  print(n = Inf)\n\n# A tibble: 24 × 5\n   Name                                  Station             Walk ScoreN Score\n   <chr>                                 <chr>              <dbl>  <dbl> <dbl>\n 1 麺屋 あまのじゃく 本店                富雄駅                 2      2  4.5 \n 2 紀州和歌山らーめんきぶんや 奈良富雄店 富雄駅                 4      1  4   \n 3 ラーメン家 みつ葉                     富雄駅                 4      1  3.5 \n 4 天下一品 新大宮店                     新大宮駅               6      1  3   \n 5 麺屋 一徳                             天理駅                 7      1  3   \n 6 丸源ラーメン 橿原店                   金橋駅                 8      1  3.5 \n 7 らーめん食堂 よってこや 平群店        元山上口駅            10      1  4   \n 8 天理スタミナラーメン本店              櫟本駅                11      2  3.25\n 9 博多長浜らーめん夢街道 奈良土橋店     真菅駅                11      1  3.5 \n10 ぶ～け                                奈良駅                11      1  5   \n11 つけめん らーめん元喜神 押熊店        学研奈良登美ヶ丘駅    12      4  4.12\n12 彩華ラーメン 本店                     前栽駅                12      5  3.6 \n13 力皇                                  天理駅                13      1  3.5 \n14 らーめん きみちゃん                   京終駅                14      2  4.5 \n15 無鉄砲がむしゃら                      帯解駅                15      2  4   \n16 彩華ラーメン 田原本店                 石見駅                15      1  4   \n17 神座 大和高田店                       大和高田駅            17      2  3.75\n18 彩華ラーメン 奈良店                   尼ヶ辻駅              17      3  4.33\n19 彩華ラーメン 桜井店                   大福駅                18      1  3   \n20 天下一品 東生駒店                     東生駒駅              19      1  3.5 \n21 まりお流ラーメン                      新大宮駅              20      1  5   \n22 どうとんぼり神座 奈良柏木店           西ノ京駅              22      1  3   \n23 河童ラーメン本舗 押熊店               学研奈良登美ヶ丘駅    28      1  4   \n24 博多長浜らーめん 夢街道 四条大路店    新大宮駅              29      4  2.88\n\n\n　3行まではこれまで習ってきたもので、4行目がソートの関数、arrange()です。引数はソートの基準となる変数で、今回は最寄りの駅からの徒歩距離を表すWalkです。5行目は省略可能ですが、tibbleクラスの場合、10行までしか出力されないので、print(n = Inf)で「すべての行を表示」させます。nを指定することで出力される行数が調整可能です。奈良県のラーメン屋の中で最寄りの駅から最も近い店は「麺屋 あまのじゃく 本店」で徒歩2分でした。京田辺店も駅から約2分ですし、近いですね。ちなみにSongはここの塩とんこつが好きです。世界一こってりなラーメンとも言われる「チョモランマ」で有名な「まりお流ラーメン」は新大宮駅から徒歩20分でかなり遠いことが分かります。\n　続いて、駅からの距離ではなく、評価が高い順にしてみましょう。評価が高いほど上に来るので、今回は昇順でなく、降順 (descending)でソートする必要があります。arrange()関数は基本的に、指定された変数を基準に昇順でソートします。降順にするためにはdesc()関数を更に用います。たとえば、arrange(desc(変数名))のようにです。それでは実際にやってみましょう。上のコードの4行目をarange(Walk)からarrange(desc(Score))にちょっと修正するだけです。\n\ndf %>%\n  filter(Pref == \"奈良県\", !is.na(Station), ScoreN > 0) %>%\n  select(Name, Station, Walk, ScoreN, Score) %>%\n  arrange(desc(Score)) %>%\n  print(n = Inf)\n\n# A tibble: 24 × 5\n   Name                                  Station             Walk ScoreN Score\n   <chr>                                 <chr>              <dbl>  <dbl> <dbl>\n 1 まりお流ラーメン                      新大宮駅              20      1  5   \n 2 ぶ～け                                奈良駅                11      1  5   \n 3 麺屋 あまのじゃく 本店                富雄駅                 2      2  4.5 \n 4 らーめん きみちゃん                   京終駅                14      2  4.5 \n 5 彩華ラーメン 奈良店                   尼ヶ辻駅              17      3  4.33\n 6 つけめん らーめん元喜神 押熊店        学研奈良登美ヶ丘駅    12      4  4.12\n 7 河童ラーメン本舗 押熊店               学研奈良登美ヶ丘駅    28      1  4   \n 8 無鉄砲がむしゃら                      帯解駅                15      2  4   \n 9 紀州和歌山らーめんきぶんや 奈良富雄店 富雄駅                 4      1  4   \n10 彩華ラーメン 田原本店                 石見駅                15      1  4   \n11 らーめん食堂 よってこや 平群店        元山上口駅            10      1  4   \n12 神座 大和高田店                       大和高田駅            17      2  3.75\n13 彩華ラーメン 本店                     前栽駅                12      5  3.6 \n14 天下一品 東生駒店                     東生駒駅              19      1  3.5 \n15 力皇                                  天理駅                13      1  3.5 \n16 博多長浜らーめん夢街道 奈良土橋店     真菅駅                11      1  3.5 \n17 ラーメン家 みつ葉                     富雄駅                 4      1  3.5 \n18 丸源ラーメン 橿原店                   金橋駅                 8      1  3.5 \n19 天理スタミナラーメン本店              櫟本駅                11      2  3.25\n20 麺屋 一徳                             天理駅                 7      1  3   \n21 どうとんぼり神座 奈良柏木店           西ノ京駅              22      1  3   \n22 彩華ラーメン 桜井店                   大福駅                18      1  3   \n23 天下一品 新大宮店                     新大宮駅               6      1  3   \n24 博多長浜らーめん 夢街道 四条大路店    新大宮駅              29      4  2.88\n\n\n　よく考えてみれば、「評価が同点の場合、どうなるの?」と疑問を抱く方がいるかも知れません。たとえば、7行目の「河童ラーメン本舗 押熊店」と8行目の「無鉄砲がむしゃら」はどれも評価が4点ですが、「河童ラーメン本舗 押熊店」が先に表示されます。そのこれは簡単です。同点の場合、データセット内で上に位置する行が先に表示されます。これを確認するにはwhich()関数を使います。()内に条件文を指定することで、この条件に合致する要素の位置を返します。もし、条件に合致するものが複数あった場合は全ての位置を返します4。\n\nwhich(df$Name == \"河童ラーメン本舗 押熊店\")\n\n[1] 6021\n\nwhich(df$Name == \"無鉄砲がむしゃら\")\n\n[1] 6040\n\n\n　データ内に「河童ラーメン本舗 押熊店」がより上に位置することが分かります。「もし同点なら口コミ評価数が多いところにしたい」場合はどうすれば良いでしょうか。これはarrange()内に変数名を足すだけで十分です。\n\ndf %>%\n  filter(Pref == \"奈良県\", !is.na(Station), ScoreN > 0) %>%\n  select(Name, Station, Walk, ScoreN, Score) %>%\n  arrange(desc(Score), desc(ScoreN)) %>%\n  print(n = Inf)\n\n# A tibble: 24 × 5\n   Name                                  Station             Walk ScoreN Score\n   <chr>                                 <chr>              <dbl>  <dbl> <dbl>\n 1 まりお流ラーメン                      新大宮駅              20      1  5   \n 2 ぶ～け                                奈良駅                11      1  5   \n 3 麺屋 あまのじゃく 本店                富雄駅                 2      2  4.5 \n 4 らーめん きみちゃん                   京終駅                14      2  4.5 \n 5 彩華ラーメン 奈良店                   尼ヶ辻駅              17      3  4.33\n 6 つけめん らーめん元喜神 押熊店        学研奈良登美ヶ丘駅    12      4  4.12\n 7 無鉄砲がむしゃら                      帯解駅                15      2  4   \n 8 河童ラーメン本舗 押熊店               学研奈良登美ヶ丘駅    28      1  4   \n 9 紀州和歌山らーめんきぶんや 奈良富雄店 富雄駅                 4      1  4   \n10 彩華ラーメン 田原本店                 石見駅                15      1  4   \n11 らーめん食堂 よってこや 平群店        元山上口駅            10      1  4   \n12 神座 大和高田店                       大和高田駅            17      2  3.75\n13 彩華ラーメン 本店                     前栽駅                12      5  3.6 \n14 天下一品 東生駒店                     東生駒駅              19      1  3.5 \n15 力皇                                  天理駅                13      1  3.5 \n16 博多長浜らーめん夢街道 奈良土橋店     真菅駅                11      1  3.5 \n17 ラーメン家 みつ葉                     富雄駅                 4      1  3.5 \n18 丸源ラーメン 橿原店                   金橋駅                 8      1  3.5 \n19 天理スタミナラーメン本店              櫟本駅                11      2  3.25\n20 麺屋 一徳                             天理駅                 7      1  3   \n21 どうとんぼり神座 奈良柏木店           西ノ京駅              22      1  3   \n22 彩華ラーメン 桜井店                   大福駅                18      1  3   \n23 天下一品 新大宮店                     新大宮駅               6      1  3   \n24 博多長浜らーめん 夢街道 四条大路店    新大宮駅              29      4  2.88\n\n\n　ソートの基準はarrange()内において先に指定された変数の順番となります。「口コミ評価も評価数も同じなら、駅から近いところにしたい」場合は変数が3つとなり、Score、ScoreN、Walkの順で入れます。\n\ndf %>%\n  filter(Pref == \"奈良県\", !is.na(Station), ScoreN > 0) %>%\n  select(Name, Station, Walk, ScoreN, Score) %>%\n  arrange(desc(Score), desc(ScoreN), Walk) %>%\n  print(n = Inf)\n\n# A tibble: 24 × 5\n   Name                                  Station             Walk ScoreN Score\n   <chr>                                 <chr>              <dbl>  <dbl> <dbl>\n 1 ぶ～け                                奈良駅                11      1  5   \n 2 まりお流ラーメン                      新大宮駅              20      1  5   \n 3 麺屋 あまのじゃく 本店                富雄駅                 2      2  4.5 \n 4 らーめん きみちゃん                   京終駅                14      2  4.5 \n 5 彩華ラーメン 奈良店                   尼ヶ辻駅              17      3  4.33\n 6 つけめん らーめん元喜神 押熊店        学研奈良登美ヶ丘駅    12      4  4.12\n 7 無鉄砲がむしゃら                      帯解駅                15      2  4   \n 8 紀州和歌山らーめんきぶんや 奈良富雄店 富雄駅                 4      1  4   \n 9 らーめん食堂 よってこや 平群店        元山上口駅            10      1  4   \n10 彩華ラーメン 田原本店                 石見駅                15      1  4   \n11 河童ラーメン本舗 押熊店               学研奈良登美ヶ丘駅    28      1  4   \n12 神座 大和高田店                       大和高田駅            17      2  3.75\n13 彩華ラーメン 本店                     前栽駅                12      5  3.6 \n14 ラーメン家 みつ葉                     富雄駅                 4      1  3.5 \n15 丸源ラーメン 橿原店                   金橋駅                 8      1  3.5 \n16 博多長浜らーめん夢街道 奈良土橋店     真菅駅                11      1  3.5 \n17 力皇                                  天理駅                13      1  3.5 \n18 天下一品 東生駒店                     東生駒駅              19      1  3.5 \n19 天理スタミナラーメン本店              櫟本駅                11      2  3.25\n20 天下一品 新大宮店                     新大宮駅               6      1  3   \n21 麺屋 一徳                             天理駅                 7      1  3   \n22 彩華ラーメン 桜井店                   大福駅                18      1  3   \n23 どうとんぼり神座 奈良柏木店           西ノ京駅              22      1  3   \n24 博多長浜らーめん 夢街道 四条大路店    新大宮駅              29      4  2.88\n\n\n\n私たちのR 私たちのR 13  データハンドリング [拡張] 11  関数の自作 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR - 12  データハンドリング [抽出] 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "私たちのR",
    "section": "",
    "text": "紹介\n『私たちのR』はSONG Jaehyun と 矢内勇生 が共同で執筆するRプログラミングの「入門書」である。統計学の本ではない。\nまた、本書はデータ分析の手法の解説書でもない。Rを用いたデータ分析については他の本を参照されたい。私たちが専門とする政治学におけるデータ分析については、以下の本を勧める。\n本書が想定するのは、次のような希望をもつ読者である。\n本書を読んでも統計学やデータ分析を理解することはできない。本書の目的は、統計学やデータ分析についての知識を持った方々と、Rを使ってもっと効率的にデータ分析をする方法を共有することである。また、統計学やデータ分析を勉強する際に、プログラミングについての副読本として読むことも想定している。\n本書を読み終える頃には、Rなしでは生活できなくなっていることだろう。\n本書の執筆環境については本書の最後を参照されたい。"
  },
  {
    "objectID": "index.html#RN4E著者紹介",
    "href": "index.html#RN4E著者紹介",
    "title": "私たちのR",
    "section": "著者紹介",
    "text": "著者紹介\n\n\n\n\n事例研究をこよなく愛する著者 (Portland, OR. 2016年2月)\n\n\n\n\nSong Jaehyun（宋 財泫 [ソン ジェヒョン]; 写真左）はR黒帯の大学教員。猫好き。 主な著書：真に驚くべき業績を残しているが、この余白はそれを書くには狭すぎる。 公開したRパッケージ: BalanceR, PRcalc, SimpleConjoint, woRdleなど\n\n\n関西大学 総合情報学部 准教授\nEmail: song@kansai-u.ac.jp\n\nWebpage: https://www.jaysong.net\n\nTwitter: @Tintstyle\n\nGitHub: https://github.com/JaehyunSong\n\n\n矢内勇生（やない ゆうき; 写真右）はR歴15年の大学教員。猛猫。主な著書：『Rによる計量政治学』（共著, オーム社, 2018年）, 『政治経済学』（共著, 有斐閣, 2020年） 公開したRパッケージ：rgamer\n\n\n高知工科大学 経済・マネジメント学群 准教授\nEmail: yanai.yuki@kochi-tech.ac.jp\n\nWebpage: https://yukiyanai.github.io\n\nTwitter: @yuki871\n\nGitHub: https://github.com/yukiyanai"
  },
  {
    "objectID": "index.html#RN4Eデータのダウンロード",
    "href": "index.html#RN4Eデータのダウンロード",
    "title": "私たちのR",
    "section": "データのダウンロード",
    "text": "データのダウンロード\n本書のデータは全て筆者の GitHub リポジトリから入手可能である。データは以下の手順でダウンロードできる。\n\n本書のGitHubリポジトリ にアクセスする。\n\nリポジトリのURL: https://github.com/JaehyunSong/RBook\n\n\nDataフォルダーを選択する。\nダウンロードするファイル名を選択する。\n「Raw」を右クリックし、「Save Linked Contents As…」を選択する。\n保存するフォルダーを指定して、ダウンロードする。"
  },
  {
    "objectID": "index.html#RN4E本書における表記法",
    "href": "index.html#RN4E本書における表記法",
    "title": "私たちのR",
    "section": "本書における表記法",
    "text": "本書における表記法\n\nコードは以下のように背景に色が付けられている部分である。\n\n\nprint(\"Hello!\")\n\n\nコードの中で#で始まる内容はコメントであり、分析に影響を与えない。ただし、\"や'で囲まれた#はコメントではない。また、行の途中から#が入る場合、#以降は実行されない。\n\n\n# Hello!を出力するコード\nprint(\"Hello!\")\n\n# \"や'内の#はコメントではない\nprint(\"この#はコメントではありません\")\n\nprint(\"Hello World!\") # Hellow World!を出力\n\n\n出力結果は灰色の枠線で囲まれた領域である。\n\n\n\n[1] \"Hello!\"\n\n\n\nオブジェクト名は変数名や関数名()のように文中の色付き背景で示された部分である。\nパッケージ名は{}で囲む。tidyverseパッケージの場合、{tidyverse}と表記する1。"
  },
  {
    "objectID": "index.html#RN4E著作権",
    "href": "index.html#RN4E著作権",
    "title": "私たちのR",
    "section": "著作権",
    "text": "著作権\n本著作物は クリエイティブ・コモンズ 表示-非営利-改変禁止 4.0国際ライセンスの下に提供されています。"
  },
  {
    "objectID": "index.html#RN4E進捗状況",
    "href": "index.html#RN4E進捗状況",
    "title": "私たちのR",
    "section": "進捗状況",
    "text": "進捗状況\n章立ては未定。著者が書きたいものから書く予定 (全部で30~35章くらいになる見込み)。\n\n第1部: Rの導入\n\n第1章: R? (75%)\n第2章: Rのインストール (0%)\n第3章: IDEの導入 (0%)\n第4章: 分析環境のカスタマイズ (0%)\n第5章: Rパッケージ (70%)\n\n\n第2部: Rの基礎\n\n第6章: 基本的な操作 (80%)\n第7章: データの入出力 (70%)\n第8章: データ型 (85%)\n第9章: データ構造 (80%)\n第10章: Rプログラミングの基礎 (85%)\n第11章: 関数の自作 (70%)\n\n\n第3部: データハンドリング\n\n第12章: データハンドリング [抽出] (85%)\n第13章: データハンドリング [拡張] (85%)\n第14章: データハンドリング [factor型] (85%)\n第15章: 整然データ構造 (85%)\n第16章: 文字列の処理 (0%)\n\n\n第4部: 可視化\n\n第17章: 可視化[理論] (85%)\n第18章: 可視化[基礎] (85%)\n第19章: 可視化[応用] (85%)\n第20章: 可視化[発展] (85%)\n第21章: モデルの可視化 (0%)\n\n\n第5部: 再現可能な研究\n\n第22章: R Markdown [基礎] (85%)\n第23章: R Markdown [応用] (1%)\n第24章: Quarto入門 (1%)\n第25章: 表の作成 (1%)\n第26章: 分析環境の管理 (0%)\n\n\n第6部: 中級者向け\n\n第27章: 反復処理 (75%)\n第28章: オブジェクト指向プログラミング (80%)\n第29章: モンテカルロ・シミュレーション (50%)\n第30章: スクレイピング (0%)\n第31章: API (0%)\n\n\n\n\n私たちのR 私たちのR 1  R? 紹介 Rの導入 1  R? 2  Rのインストール 3  IDEの導入 4  分析環境のカスタマイズ 5  Rパッケージ Rの基礎 6  基本的な操作 7  データの入出力 8  データ型 9  データ構造 10  Rプログラミングの基礎 11  関数の自作 データハンドリング 12  データハンドリング [抽出] 13  データハンドリング [拡張] 14  データハンドリング [factor型] 15  整然データ構造 16  文字列の処理 可視化 17  可視化 [理論] 18  可視化 [基礎] 19  可視化 [応用] 20  可視化 [発展] 21  モデルの可視化 再現可能な研究 22  R Markdown [基礎] 23  R Markdown [応用] 24  Quarto入門 25  表の作成 26  分析環境の管理 中級者向け 27  反復処理 28  オブジェクト指向プログラミング 29  モンテカルロ・シミュレーション 30  スクレイピング 31  API 付録 R Tips 本書の執筆環境 参考文献 Copyright 2022, Jaehyun Song and Yuki Yanai\n\n\n私たちのR 私たちのR: ベストプラクティスの探求 私たちのR: ベストプラクティスの探求 私たちのR"
  }
]