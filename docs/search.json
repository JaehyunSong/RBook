[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "私たちのR",
    "section": "",
    "text": "紹介\n『私たちのR』は宋財泫（SONG Jaehyun）と 矢内勇生が共同で執筆するRプログラミングの「入門書」である。統計学の本ではない。\nまた、本書はデータ分析の手法の解説書でもない。Rを用いたデータ分析については他の本を参照されたい。私たちが専門とする政治学におけるデータ分析については、以下の本を勧める。\n本書が想定するのは、次のような希望をもつ読者である。\n本書を読んでも統計学やデータ分析を理解することはできない。本書の目的は、統計学やデータ分析についての知識を持った方々と、Rを使ってもっと効率的にデータ分析をする方法を共有することである。また、統計学やデータ分析を勉強する際に、プログラミングについての副読本として読むことも想定している。\n本書を読み終える頃には、Rなしでは生活できなくなっていることだろう。\n本書の執筆環境については本書の最後を参照されたい。"
  },
  {
    "objectID": "index.html#著者紹介",
    "href": "index.html#著者紹介",
    "title": "私たちのR",
    "section": "著者紹介",
    "text": "著者紹介\n\n\n\n事例研究をこよなく愛する著者 (Portland, OR. 2016年2月)\n\n\n宋財泫（そん じぇひょん[SONG Jaehyun]; 写真左）はR黒帯の大学教員。宗ではなく、宋。猫好き。 主な著書：真に驚くべき業績を残しているが、この余白はそれを書くには狭すぎる。 公開したRパッケージ: BalanceR, PRcalc, SimpleConjoint, woRdleなど\n\n関西大学 総合情報学部 准教授\nEmail: song@kansai-u.ac.jp\nWebpage: https://www.jaysong.net\nTwitter: @Tintstyle\nGitHub: https://github.com/JaehyunSong\n\n矢内勇生（やない ゆうき; 写真右）はR歴15年の大学教員。猛猫。主な著書：『Rによる計量政治学』（共著, オーム社, 2018年）, 『政治経済学』（共著, 有斐閣, 2020年） 公開したRパッケージ：rgamer\n\n高知工科大学 経済・マネジメント学群 准教授\nEmail: yanai.yuki@kochi-tech.ac.jp\nWebpage: https://yukiyanai.github.io\nTwitter: @yuki871\nGitHub: https://github.com/yukiyanai"
  },
  {
    "objectID": "index.html#データのダウンロード",
    "href": "index.html#データのダウンロード",
    "title": "私たちのR",
    "section": "データのダウンロード",
    "text": "データのダウンロード\n　本書のデータ付録の「データセット」から入手可能である。もう一つの方法は、筆者（宋）の GitHub リポジトリからダウンロードすることだ。データは以下の手順でダウンロードできる。\n\n本書のGitHubリポジトリ にアクセスする。\n\nリポジトリのURL: https://github.com/JaehyunSong/RBook\n\nDataフォルダーを選択する。\nダウンロードするファイル名を選択する。\n「Raw」を右クリックし、「Save Linked Contents As…」を選択する。\n保存するフォルダーを指定して、ダウンロードする。"
  },
  {
    "objectID": "index.html#本書における表記法",
    "href": "index.html#本書における表記法",
    "title": "私たちのR",
    "section": "本書における表記法",
    "text": "本書における表記法\n\nコードは以下のように背景に色が付けられている部分である。\n\n\nprint(\"Hello!\")\n\n\nコードの中で#で始まる内容はコメントであり、分析に影響を与えない。ただし、\"や'で囲まれた#はコメントではない。また、行の途中から#が入る場合、#以降は実行されない。\n\n\n# Hello!を出力するコード\nprint(\"Hello!\")\n\n# \"や'内の#はコメントではない\nprint(\"この#はコメントではありません\")\n\nprint(\"Hello World!\") # Hellow World!を出力\n\n\nコードの右端に表示される丸付き数字（、など）は各行の解説を意味する。数字部分にマウスのカーソルを乗せると解説が表示される。\n\n\ndf |&gt; \n1   select(ID, Col1:Col3, Col8) |&gt;\n2   filter(ID &lt;= 100) |&gt;\n   print(n = Inf)\n\n\n1\n\ndfからID列、Col1からCol3列、Col8列を抽出する。\n\n2\n\nIDの値が100以下の行を抽出する。\n\n\n\n\n\n出力結果は灰色の枠線で囲まれた領域である。\n\n\n\n[1] \"Hello!\"\n\n\n\nオブジェクト名は変数名や関数名()のように文中の色付き背景で示された部分である。\nパッケージ名は{}で囲む。tidyverseパッケージの場合、{tidyverse}と表記する1。"
  },
  {
    "objectID": "index.html#著作権",
    "href": "index.html#著作権",
    "title": "私たちのR",
    "section": "著作権",
    "text": "著作権\n本著作物は クリエイティブ・コモンズ 表示-非営利-改変禁止 4.0国際ライセンスの下に提供されています。"
  },
  {
    "objectID": "index.html#進捗状況",
    "href": "index.html#進捗状況",
    "title": "私たちのR",
    "section": "進捗状況",
    "text": "進捗状況\n章立ては未定。著者が書きたいものから書く予定 (全部で30~35章くらいになる見込み)。\n\n第1部: Rの導入\n\n第1章: R?\n第2章: Rのインストール\n第3章: IDEの導入\n第4章: 分析環境のカスタマイズ\n第5章: Rパッケージ\n\n第2部: Rの基礎\n\n第6章: プロジェクト管理\n第7章: 基本的な操作\n第8章: データの入出力\n第9章: データ型\n第10章: データ構造\n第11章: Rプログラミングの基礎\n第12章: 関数の自作\n\n第3部: データハンドリング\n\n第13章: データハンドリング [抽出]\n第14章: データハンドリング [拡張]\n第15章: データハンドリング [factor型]\n第16章: 整然データ構造\n第17章: 文字列の処理\n\n第4部: 可視化\n\n第18章: 可視化[理論]\n第19章: 可視化[基礎]\n第20章: 可視化[応用]\n第21章: 可視化[発展]\n第22章: 表の作成\n\n第5部: 再現可能な研究\n\n第23章: R Markdown [基礎]\n第24章: R Markdown [応用]\n第25章: Quarto入門\n第26章: 分析環境の管理\n\n第6部: 中級者向け\n\n第27章: 反復処理\n第28章: オブジェクト指向プログラミング\n第29章: モンテカルロ・シミュレーション\n第30章: スクレイピング\n\n付録\n\nデータセット\nファイルシステム\nR Tips\n本書の執筆環境\n参考文献"
  },
  {
    "objectID": "aboutr.html#sec-aboutr-intro",
    "href": "aboutr.html#sec-aboutr-intro",
    "title": "1  R?",
    "section": "1.1 Rとは",
    "text": "1.1 Rとは\n\n\n\n図 1.1: R Logo\n\n\n　Rは統計、データ分析、作図のためのインタープリタープログラミング言語である。Rという名前は二人の開発者 Ross Ihaka と Robert Clifford Gentleman のイニシャルに由来する。R言語は完全にゼロベースから開発されたものではなく、1976年に開発されたS言語に起源をもつ。S言語もR言語同様、統計やデータ分析に特化した言語であり、S言語の開発が中止された現在、RはSの正当な後継者であると言ってよいだろう。\n　R以外にも、統計・データ分析のために利用可能なソフトウェアはたくさんある。社会科学におけるデータ分析の授業を履修したことがあるなら、SPSS や Stata という名前をきいたことがあるかもしれない。工学系ならMATLAB が有名かもしれない。企業ではSAS という高価なソフトもよく使われる1。\n　これらのソフト（アプリ）は基本的に有料だが、お金がないとデータ分析のソフトウェアが使えないわけではない。無料でありながら優れたソフトウェアも多く公開されている。以下にその一部を示す。\n\n\n\nソフト・言語名\n備考\n\n\n\n\nPSPP\nSPSSにとてもよく似た無料ソフトウェア。\n\n\nJASP/jamovi\n裏で動いているのはR。詳細は本章の後半で\n\n\ngretl\n時系列分析など、計量経済学で利用される手法に特化したソフト。\n\n\nGNU Octave\nMATLAB とほぼ同じ文法をもつ無料言語\n\n\nHAD\n清水裕士 先生が開発しているExcelベースのデータ分析マクロ\n\n\n\n　統計分析に特化したプログラミング言語としてRの競合相手になるのは Julia と Python だろう。Julia言語は一見Rによく似ているが、計算速度が Rより速いと言われている2。ただし、比較的新しい言語であるため、パッケージと解説書がRよりも少ないという難点がある。Pythonは現在のデータサイエンス界隈において、Rとともに最も広く使われている言語である3。Pythonは統計・データ分析に特化した言語ではないが、統計・データ分析のライブラリが非常に充実しており、機械学習（とくに、コンピュータービジョン）ではRよりも広く使われている。Python以外の言語、たとえば C や Java、Ruby、Fortranでも統計・データ分析は可能ある。実際、RやPythonのパッケージの一部はCやJavaで作成されている。ただし、RやPythonに比べると、データ分析の方法を解説したマニュアル・参考書があまりないのがつらいところだ。ひとつの言語だけでなく、複数の言語を使えるようになったほうが良いことは言うまでもない。本書はRについて解説するが、他の言語にもぜひ挑戦してほしい。"
  },
  {
    "objectID": "aboutr.html#sec-aboutr-why-r",
    "href": "aboutr.html#sec-aboutr-why-r",
    "title": "1  R?",
    "section": "1.2 Why R?",
    "text": "1.2 Why R?\n　私たちRユーザにとっての神のような存在であるHadley Wickham（通称：羽鳥先生）は Advanced R (2nd Ed.) で次のように仰せられた。\n\n\nIt’s free, open source, and available on every major platform. As a result, if you do your analysis in R, anyone can easily replicate it, regardless of where they live or how much money they earn.\n\n\n\nRは無料で、オープンソースで、多くのプラットフォーム（訳注: macOS, Linux, Windowsなど）で利用できます。よって、Rを使って分析すれば、どこに住んでいるか、いくらお金を稼いでいるかに関係なく、誰でも簡単にその分析を再現できることができます。\n\n\n\nR has a diverse and welcoming community, both online (e.g. the #rstats twitter community) and in person (like the many R meetups). Two particularly inspiring community groups are rweekly newsletter which makes it easy to keep up to date with R, and R-Ladies which has made a wonderfully welcoming community for women and other minority genders.\n\n\n\nオンライン (twitterの#rstatなど)、オフライン (訳注：日本では Tokyo.R が有名。筆者たちが開催している KUT.R もある)　の両方で、多様なRコミュニティがあります。他にも最新のRをキャッチアップするためのニュースレターであるrweeklyや、女性や性的マイノリティーにやさしい R-Ladies も活発に活動しています。\n\n\n\nA massive set of packages for statistical modelling, machine learning, visualisation, and importing and manipulating data. Whatever model or graphic you’re trying to do, chances are that someone has already tried to do it and you can learn from their efforts.\n\n\n\n統計モデリング、機械学習、可視化、データ読み込みおよびハンドリングのための膨大なパッケージが用意されています。どのようなモデルやグラフでも、既に誰かがその実装を試みた可能性が高く、先人らの努力に学ことができます。\n\n\n\nPowerful tools for communicating your results. R Markdown makes it easy to turn your results into HTML files, PDFs, Word documents, PowerPoint presentations, dashboards and more. Shiny allows you to make beautiful interactive apps without any knowledge of HTML or javascript.\n\n\n\n分析結果を伝達する強力なツールを提供しています。R Makrdownは分析結果をHTML、PDF、Word、PowerPoint、Dashboard 形式に変換してくれます。HTMLや JavaScript の知識がなくても、Shinyを使って美しい対話型のアプリケーションを開発することができます。\n\n\n\nRStudio, the IDE, provides an integrated development environment, tailored to the needs of data science, interactive data analysis, and statistical programming.\n\n\n\n代表的な統合開発環境であるRStudioはデータサイエンス、対話型のデータ分析、そして統計的プログラミングが必要とするものに最適化されています。\n\n\n\nCutting edge tools. Researchers in statistics and machine learning will often publish an R package to accompany their articles. This means immediate access to the very latest statistical techniques and implementations.\n\n\n\nRは最先端のツールです。多くの統計学や機械学習の研究者は自分の研究成果とRパッケージを同時に公開しています。これは最先端の方法を誰よりも早く実施可能にします。\n\n\n\nDeep-seated language support for data analysis. This includes features like missing values, data frames, and vectorisation.\n\n\n\nデータ分析を根強くサポートする言語です。欠損値、データフレーム、ベクトル化などがその例です。\n\n\n\nA strong foundation of functional programming. The ideas of functional programming are well suited to the challenges of data science, and the R language is functional at heart, and provides many primitives needed for effective functional programming.\n\n\n\nRはデータサイエンスに非常に有効である関数型プログラミングのための最適な環境を提供しています。\n\n\n\nRStudio, the company, which makes money by selling professional products to teams of R users, and turns around and invests much of that money back into the open source community (over 50% of software engineers at RStudio work on open source projects). I work for RStudio because I fundamentally believe in its mission.\n\n\n\nRStudio社は営利企業ですが、その収益の多くをオープンソースコミュニティーに投資しています。\n\n\n\nPowerful metaprogramming facilities. R’s metaprogramming capabilities allow you to write magically succinct and concise functions and provide an excellent environment for designing domain-specific languages like ggplot2, dplyr, data.table, and more.\n\n\n\nメタプログラミングが強力です。Rが持つメタプログラミング能力はあなたのコードを劇的に簡潔にするだけでなく、統計/データ分析に特化したggplot2、dplyr、data.tableなどの開発も可能にしました。\n\n\n\nThe ease with which R can connect to high-performance programming languages like C, Fortran, and C++.\n\n\n\nRはC、C++、Fortranのようなハイパフォーマンス言語と容易に結合できるように設計されています。\n\n　しかし、他のプログラミング言語と同様、Rは完璧な言語ではありません。以下はR言語の短所の一部です。その多くはRそのものの問題というよりも、(プログラマーではなく)データ分析の研究者が中心となっているRユーザーから起因する問題です。\n\n\nMuch of the R code you’ll see in the wild is written in haste to solve a pressing problem. As a result, code is not very elegant, fast, or easy to understand. Most users do not revise their code to address these shortcomings.\n\n\n\nあなたが普段見る多くのRコードは「今の」問題を解決するために迅速に書かれたものです。この場合、コードはあまりエレガントでも、速くも、読みやすくありません。ほとんどのユーザーはこの短所を克服するためのコード修正を行っておりません。\n\n\n\nCompared to other programming languages, the R community is more focussed on results than processes. Knowledge of software engineering best practices is patchy. For example, not enough R programmers use source code control or automated testing.\n\n\n\n他のプログラミング言語に比べ、Rコミュニティーは過程よりも結果に注目する傾向があります。多くのユーザーにおいて、ソフトウェアエンジニアリングの知識を蓄えるための方法が不完全です。たとえば、(GitHubなどの) コード管理システムや自動化された検証を使用するRプログラマーは多くありません。\n\n\n\nMetaprogramming is a double-edged sword. Too many R functions use tricks to reduce the amount of typing at the cost of making code that is hard to understand and that can fail in unexpected ways.\n\n\n\nRの長所でもあるメタプログラミングは諸刃の剣です。あまりにも多くのR関数はコーディングのコストを減らすようなトリックを使用しており、その代償としてコードの理解が難しく、予期せぬ失敗の可能性があります。\n\n\n\nInconsistency is rife across contributed packages, and even within base R. You are confronted with over 25 years of evolution every time you use R, and this can make learning R tough because there are so many special cases to remember.\n\n\n\n開発されたパッケージは、R内蔵のパッケージさえも一貫性が乏しいです。あなたはRを使う度にこの25年を超えるRの進化に直面することになります。また、Rには覚えておくべきの特殊なケースが多く、これはR学習の妨げとなっています。\n\n\n\nR is not a particularly fast programming language, and poorly written R code can be terribly slow. R is also a profligate user of memory.\n\n\n\nRは格別に速い言語ではありません。下手に書かれたコードは驚くほど遅いです。また、Rはメモリの浪費が激しい言語と知られています。"
  },
  {
    "objectID": "aboutr.html#sec-aboutr-gui-cui",
    "href": "aboutr.html#sec-aboutr-gui-cui",
    "title": "1  R?",
    "section": "1.3 GUIとCUI",
    "text": "1.3 GUIとCUI\n　現在、多くのソフトウェアはGUIを採用している。GUI とは Graphical User Interface の略で、ソフトウェア上の入力および出力にグラフィックを利用する。単純にいうと「マウスでポチポチするだけで操作できる環境」のことだ。一方、Rでは基本的にCUI (Character User Interface) を利用する4。これは全ての操作を文字列ベースで行う、つまりキーボードで行うことを意味する5。\n　身近な例として、あるラーメン屋での注文（呪文）システムを考えてみよう。無料トッピングを指定するときに「決まった言い方」で指定するのがCUI方式である。一文字でも間違うとオーダーは通りらない。たとえば、「野菜マッシマッシ!」とか「野菜MashMash!」と言ってしまうと、店長さんに「は？」と言われ、周りの客から白い目で見られる6。他方、食券の自動発売機でトッピングを指定できるのがGUI方式だ7。この場合、そもそも間違いは起きない。誰でも簡単に注文できるのがGUI式のメリットだが、自分で注文するものが決まっていて、注文の仕方を知っているなら CUI式のほうが早い。毎回同じ注文をするなら、注文内容を録音しておいて、次回はそれを再生することも可能である。GUI方式では、注文方法を再現するのは難しい。\n\n\n\n図 1.2: CUIとGUIの比較\n\n\n　CUIとGUIを比べたとき、一見するとGUIのほうが優れているように見える。マウスでポチポチするだけで操作できるほうが楽に見えるし、間違いの心配もなさそうな気がする。キーボードで長いコマンドを打つCUIよりも、ボタンをクリックしたほうが手早く済みそうにも思える8。そして、CUIのコマンドを覚えるのはしんどい9。\n　しかし、CUIにはCUIなりの長所がある。まず、コードが記録できる。マウスでポチポチした操作は、パソコンの画面全体を録画しない限り記録できない。よって、GUIでは自分の分析プロセスを記録することが難しい。他方、すべてコマンドで操作した場合、入力したコマンドを文字列として記録することは容易である。また、CUIはGUIよりも柔軟である。先ほどのラーメン屋の例で考えると、CUIでは「一応」野菜ちょいマシのような注文（呪文）のカスタマイズもできる10。しかし、GUI（券売機）だと注文の自由なカスタマイズはできない。店が用意したボタンしか押せない（ソフトがメニューに表示しているコマンドしか実行できない）。また、コマンドの入力の時間や暗記も、それほど難しくはない。後で説明するように、Rユーザにとっての超有能な秘書であるRStudio (IDEの1種) がコマンド入力を助けてくれる。スペルが間違っていたり、うろ覚えのコマンドなどがあっても、RStudio （あるいはその他のIDE）が瞬時に正解に導いてくれる。\n　本書はCUIとしてのRについて解説する。Rは統計ソフトでありながら、言語でもある。外国語の勉強に喩えるなら、CUIを使うのは単語や熟語を覚え、文法やよく使う表現を学習して自分で考えて話すことであるのに対し、GUIを使うのは AI に翻訳を頼み、外国語については自分で一切考えないことに似ている。たいして興味のない国になぜか旅行で訪れることになった場合にはGUI方式で済ますのも良いだろう。しかし、それでその言語を「勉強した」とか「理解した」などという人はいないはずだ。Rを「理解」したいなら、CUI以外の選択肢はない11。\n　それでもやはりGUIのほうがとっつきやすいという頑固なあなたのために代表的なRの GUI を紹介するので、以下のリストを確認したらこの本は閉じていただきたい。またいつかどこかでお会いしましょう。CUIを使う覚悟ができたあなたは、以下のリストを読みとばし、引き続き一緒にRの世界を楽しみましょう！\n\n\n\n図 1.3: R Commander\n\n\n\n\n\n図 1.4: RKWard\n\n\n\n\n\n図 1.5: JASP\n\n\n\n\n\n図 1.6: jamovi\n\n\n\n\n\n図 1.7: R AnalyticFlow"
  },
  {
    "objectID": "installation.html#自分のpcにインストール",
    "href": "installation.html#自分のpcにインストール",
    "title": "2  Rのインストール",
    "section": "2.1 自分のPCにインストール",
    "text": "2.1 自分のPCにインストール\n　Rのバージョン、使用するOSのバージョンによってインストール方法が変更される可能性がある。したがって、最新情報はネット上の解説記事等を参照されたい。以下の内容はmacOS 13（Ventura）、Ubuntu 22 LTS、Windows 11にR 4.3.0をインストールする方法である。Rのインストールが終わったら、統合開発環境（IDE）であるRStudioのインストールを推奨する。RStudioのインストール方法は第3章を参照すること。\n\n2.1.1 macOS\n\nXcode\nCommand Line Tools（CLT）\nXquartz\nR\nRStudio\n\n\n\n2.1.2 Windows\n\nユーザー名の確認\n\n今は日本語のユーザー名でもインストールの問題はないと考えられるが、パッケージのインストールができない場合がある。\nhttp://nineworks2.blog.fc2.com/blog-entry-123.html\n\nR\nRtools\nRStudio\n\n\n\n2.1.3 Ubuntu\nDebian系（Debian / Ubuntu / Mint等）共通\n$ sudo apt update\n$ sudo apt install -y gdebi-core wget\n$ sudo apt install -y fonts-ipaexfont\n$ fc-cache -f -v\n$ fc-list | grep IPAex\n$ sudo apt install -y build-essential\n$ sudo apt install -y libcurl4-openssl-dev\n$ sudo apt install -y libcurl4-gnutls-dev\n$ sudo apt install -y libxml2-dev\n$ sudo apt install -y libssl-dev\n$ sudo apt install -y libx11-dev\n$ sudo apt install -y libglu1-mesa-dev\n$ sudo apt install -y libmagick++-dev\n$ sudo apt install -y libudunits2-0\n$ sudo apt install -y libudunits2-dev\n$ sudo apt install -y libgdal-dev libproj-dev\n$ sudo apt install -y libgmp3-dev\n$ sudo apt install -y curl\n$ sudo apt install -y poppler-utils\n$ sudo apt install -y poppler-data\n\nR\nRStudio"
  },
  {
    "objectID": "installation.html#クラウド版の利用",
    "href": "installation.html#クラウド版の利用",
    "title": "2  Rのインストール",
    "section": "2.2 クラウド版の利用",
    "text": "2.2 クラウド版の利用\n　自分のPCでなく、クラウドでRとRStudioを使うこともできる。この場合、インターネットさえ繋がっていれば、どのPCでも使用可能だ。また、自分のPCのスペックが低い場合でも、快適な分析ができる1。そして何より複雑なインストール手順が不要という点が最大のメリットである。\n\n2.2.1 RStudio Cloud\n　RStudio CloudはRStudioの開発元であるPosit社が提供するクラウドサービスである。会員登録さえすればすぐにRとRStudioが使える。無料のプランもあるが、月25時間までしか使用できず、性能面での制約も大きい。有料のプランはいくつか用意されており、最も安い月5米ドルのプラン（Cloud Plus）だと無料プランと同じ性能で月75時間まで使用可能だ。\n\n\n2.2.2 JDCat分析ツール\n　JDCat分析ツールは国立情報学研究所（NII）が提供するクラウド版のR + RStudioであり、ac.jp、またはgo.jpで終わるメールアドレスを持っている場合のみ使用可能だ。有料のプランは存在せず、全て無料である。また、稼働時間の制約もないため、おすすめだ。また、Rだけでなく、Python + Jupyterも使えるのも長所の一つだ。ただし、常に最新版が使えるわけではなく、RとRStudioは半年〜1年遅れてアップデートされる。\n\n\n\n\n\n\n「導入」は1回だけで十分\n\n\n\n　以下は「導入」と「再利用」について解説するが、「導入」はインストールに該当する内容であり、1回だけで十分だ。2回以上行っても良いが、新しいサーバーを立ち上げることになる（サーバー間のデータ転送はできない）。また、一人が生成可能な最大サーバー数は10個までだ。特段の事情が無い限り、「導入」は1回のみ実行し、次回からは「最利用」の手順に従ってJDCat分析ツールを起動すること。\n\n\n\n2.2.2.1 導入\n\nOpenIdPのホームーページへ作成し、アカウントを作成する。登録に使用するメールアドレスは必ずac.jpまたはgo.jpで終わるメールアドレスを入力する必要がある。\n\nhttps://openidp.nii.ac.jp/\nOpenIdPアカウントの作り方：https://meatwiki.nii.ac.jp/confluence/pages/viewpage.action?pageId=88607831\n\nアカウントが発行されたら、以下のURLへアクセスする。『私たちのR』で使用するパッケージを事前にインストールするように設定したレポジトリである。\n\nhttps://binder.cs.rcos.nii.ac.jp/v2/gh/JaehyunSong/Binder_R/HEAD\n\n所属機関の選択で「OpenIdP」を入力し、選択する。\nOpenIdPのアカウント情報を入力し、ログインする。\n送信属性の選択画面が表示されたら、そのまま「同意」を選択する。\nしばらく待つとJupyter Hubのホーム画面が表示される（〜5分所要）。\nRStudio Serverの起動は画面右上の「▼」をクリックし、RStudioを選択すれば良い。\n\n\n\n\nRStudioの起動\n\n\n\n\n2.2.2.2 再利用\n\n以下のURLへアクセスする。ブラウザーのお気に入りに追加しておいても良いだろう。\n\nhttps://jupyter.cs.rcos.nii.ac.jp/\n\n所属機関の選択で「OpenIdP」を入力し、選択する。\nOpenIdPのアカウント情報を入力し、ログインする。\n送信属性の選択画面が表示されたら、そのまま「同意」を選択する。\nサーバーリストにあるURLをクリックすると、Jupyter Hubのホーム画面が表示される。RStudioの起動は画面右上の「▼」をクリックし、RStudioを選択すれば良い。\n\n\n\n\n起動するサーバーの選択画面"
  },
  {
    "objectID": "ide.html#sec-ide-intro",
    "href": "ide.html#sec-ide-intro",
    "title": "3  IDEの導入",
    "section": "3.1 IDEとは",
    "text": "3.1 IDEとは\n　プログラミングは基本的にコードを書く作業の連続だが、コードを書く他にも様々な作業を行うことになる。たとえば、自分が書いたコードの結果が正しく動作するかの確認作業や、なにか問題がある場合の対処（デバッグ）などがある。また、コードを書く際、誤字やミスなどがないかも確認する必要がある。他にもプログラムで使用されるファイルを管理しなければならない。これらの仕事を手助けしてくれるのが統合開発環境（integrated development environment; IDE）と呼ばれるものである。\n　プログラマにとって優れたIDEを使うということは、優れた秘書を雇用するようなものだ。ファイルの管理、うろ覚えのコマンドの補完入力、コードの色分けなどを自動的に行ってくれる。さらに、コードの実行結果の画面をコードと同時に表示してくれたり、これまでの作業を記録してくれるなど、多くの作業を手助けしてくれる。Rにはいくつかの優れたIDEが用意されている。本書では代表的なIDEである RStudio を使うことにする。ただし、プログラミングにIDEは必須ではない。IDEをインストールしなくても、本書を読む上で特に問題はない（RStudioに関する説明の部分を除く）が、Rの実行環境に特にこだわりがないならRStudioの導入を強く推奨する。むろん、RStudio以外にも選択肢は多くある。魔界において圧倒的なシェアを誇ると噂されるWindowsという名のOSを使用しているなら、R Tools for Visual Studio もまたRStudioの代替候補の一つだ。\n　他にも、自分が使い慣れたテキストエディタをIDEとして使うことも可能である。Sublime Text や Atom はむろん、伝統のある Emacs や Vim を使うこともできる。近年、人気のテキストエディターであるVisual Studio CodeをIDEとして使用する人も増えている。\n\n\n\n\n\n\nRStudio\n\n\n\n \n\n\n\n\nR Tools for Visual Studio\n\n\n\n \n\n\n\n\nVisual Studio Code\n\n\n\n図 3.1: 様々な開発環境"
  },
  {
    "objectID": "ide.html#ide-install",
    "href": "ide.html#ide-install",
    "title": "3  IDEの導入",
    "section": "3.2 RStudioのインストール",
    "text": "3.2 RStudioのインストール\n　RStudioはposit社が無料で提供しているRのIDEであり、最も人気のあるIDEだ。以下ではRStudioのインストール手順を画像を示しながら解説するが、posit社ホームページのレイアウトなどは随時変更される可能性がある。以下は画像は2023年6月現在の画像である。\n\n3.2.1 インストーラーのダウンロード\nStep 1: positのホームページ（https://posit.co/）へアクセスする。あるいはRStudioダウンロードページ（https://posit.co/download/rstudio-desktop/）へ直接アクセスする。この場合はStep 4へ飛ぶ。\nStep 2: 画面右上の「DOWNLOAD RSTUDIO」をクリックする。\n\nStep 3: 画面を下へスクロールし、RStudio Desktopパネルの「Download」をクロックする。\n\n\n\n\n\nStep 4: 画面を下へスクロールし、自分が使用するOSにインストーラーをダウンロードする。macOSは.dmgファイル、Windowsは.exeファイル、Ubuntu（Debian）なら.debファイルだ。Ubuntu（Debian）の場合、自分のOSはバージョンを確認してからダウンロードすること。画面をもう少し下へスクロールすると、.zipや.tar.gz形式のインストーラーもあるが、こちらは推奨しない。\n\n\n\n3.2.2 macOSの場合\n　ダウンロードした.dmgファイルをクリックすると以下のような画面が表示される。\n\n\n\n\n\n　あとはRStudio.appのアイコンをクリックしたまま、Applicationsフォルダーへ移動させる（ドラッグ・アンド・ドロップ）だけだ。すでにRStudioがインストールされている場合は上書きするかと聞かれるが、そのまま上書きしても問題ない（既存のRStudioの設定は引き継がれる）。\n\n\n3.2.3 Linux（Ubuntu）の場合\n　.debファイルのインストールは、ターミナルを使う必要がある。たとえば、ダウンロードしたインストーラーのファイル名がrstudio-2023.03.1-446-amd64.debであり、Downloadフォルダーに保存されていると仮定する。ターミナルを開き、以下のように入力する。\n1$ cd Downloads\n2$ sudo apt install rstudio-2022.02.0-443-amd64.deb\n\n1\n\nDownloadフォルダーへ移動\n\n2\n\nrstudio-2023.03.1-446-amd64.debファイルを管理者権限（sudo）でインストール（apt install）する。\n\n\n　もし、gdebiがインストール済みならnautilus (UbuntuベースのディストリビューションであるLinux MintならNemo/Caja)で.debファイルをダブルクリックしてインストールすることもできる。\n\n\n3.2.4 Windowsの場合\n　Windowsの場合、ダウンロードしたファイル（たとえば、RStudio-2023.03.1-446.exe）を開き、指示に従うだけでインストールできる。基本的に「はい」、「次へ」をクリックするだけで良い。"
  },
  {
    "objectID": "r_customize.html#general",
    "href": "r_customize.html#general",
    "title": "4  分析環境のカスタマイズ",
    "section": "4.1 General",
    "text": "4.1 General\n　GeneralのBasicタブはOther以外の項目はすべてチェックを外すことを推奨する（Other項目も外しても良い）。また、「Save workspace to .RData on exit:」をNeverに変更する。\n\n\n\n図 4.2: General &gt; Basic\n\n\n　GeneralのGraphicsタブは既定値でも良いが、グラフの文字化けに悩みたくない場合は「Backend:」をAGGに変更する。ただし、予め{ragg}パッケージをインストールしておく必要がある（読み込みは不要）1。{ragg}については第19章を参照すること。\n\n\n\n図 4.3: General &gt; Graphics"
  },
  {
    "objectID": "r_customize.html#code",
    "href": "r_customize.html#code",
    "title": "4  分析環境のカスタマイズ",
    "section": "4.2 Code",
    "text": "4.2 Code\n　CodeのEditingは以下のように設定する。「Insert spaces for Tab」の「Tab width」は2か4で良い。大きめのモニター、または小さめのフォントを使う場合は4でも良い。\n\n\n\n図 4.4: Code &gt; Editing\n\n\n　CodeのDisplayはコード編集画面の見た目に関わる部分なので、好みで良いが、以下のように設定するとより読みやすくなる（と宋は思う）。ただし、「Show margin」は好みの領域であり、チェックを外している人も多い。\n\n\n\n図 4.5: Code &gt; Display\n\n\n　CodeのSavingは自分が書いたコードの保存に関する設定である。今は多くのOSがUTF-8をベースとしているので、既定値のままでも良いが、念の為に「Default text encoding:」をUTF-8にしておくことを推奨する。\n\n\n\n図 4.6: Code &gt; Saving"
  },
  {
    "objectID": "r_customize.html#console",
    "href": "r_customize.html#console",
    "title": "4  分析環境のカスタマイズ",
    "section": "4.3 Console",
    "text": "4.3 Console\n　Consoleに直接コードを入力する場面はあまり多くないので、こちらはスキップしても良いが、「Show syntax highlighting in console input」と「Different color for error or message output (requires restart)」にチェックを入れておくと、出力結果が読みやすくなる。\n\n\n\n図 4.7: Console"
  },
  {
    "objectID": "r_customize.html#appearance",
    "href": "r_customize.html#appearance",
    "title": "4  分析環境のカスタマイズ",
    "section": "4.4 Appearance",
    "text": "4.4 Appearance\n　ここは完全に好みの領域である。好きなテーマ、フォント、フォントサイズ、ハイライトテーマ（Editor theme）を選択すること。\n\n\n\n図 4.8: Appearance"
  },
  {
    "objectID": "r_customize.html#pane-layout",
    "href": "r_customize.html#pane-layout",
    "title": "4  分析環境のカスタマイズ",
    "section": "4.5 Pane Layout",
    "text": "4.5 Pane Layout\n　ここも好みの領域ではあるが、RStudio愛好家の中では以下のような設定が定番である。具体的には左上はSource、右上はConsole、左下はすべてのチェックを外し、右下はすべてチェックを付ける。デフォルトはこのような2行2列の構成であるが、ワイドモニターを使う場合は「Add Column」をクリックすることで2行3列のような構成もできる。\n\n\n\n図 4.9: Pane Layout"
  },
  {
    "objectID": "r_customize.html#packages",
    "href": "r_customize.html#packages",
    "title": "4  分析環境のカスタマイズ",
    "section": "4.6 Packages",
    "text": "4.6 Packages\n　こちらも既定値のままで使用に不便はないが、「Primary CRAN repository:」を日本（Japan）にすることで、パッケージのダウンロードがやや速くなる。\n\n\n\n図 4.10: Packages &gt; Management"
  },
  {
    "objectID": "r_customize.html#r-markdown",
    "href": "r_customize.html#r-markdown",
    "title": "4  分析環境のカスタマイズ",
    "section": "4.7 R Markdown",
    "text": "4.7 R Markdown\n　R MarkdownのBasicで優先的に設定するところは「Show output preview in:」をViewer Paneに変更することだ。Windowだとknit/renderする度に新しいウィンドウが表示されるため、不便だ。また、画像や数式を入力する際、編集画面にプレビューが表示されるが、こちらを消したい場合は「Show output inline for all R Markdown documents」のチェックを外し、「Show equation and image previews:」をNeverに変更しよう。\n\n\n\n図 4.11: R Markdown &gt; Basic\n\n\n　最後にR MarkdownのAdvancedは見た目に関するものなので、好みで良いが、個人的には「Enable chunk background highlight」と「Use rainbow fenced divs」のチェックはおすすめだ。とりわけ、Quartoを使用する場合、後者は非常に便利である。\n\n\n\n図 4.12: R Markdown &gt; Advanced\n\n\n　すべての設定が終わったらOKをクリックする。"
  },
  {
    "objectID": "packages.html#sec-packages_intro",
    "href": "packages.html#sec-packages_intro",
    "title": "5  Rパッケージ",
    "section": "5.1 パッケージとは",
    "text": "5.1 パッケージとは\n　Rには様々な関数 (functions) が提供されている。平均値を求めるmean()、合計を求めるsum()、線形回帰分析を行うlm()、平均値の検定を行うt.test()などがあり、全てを列挙することはできない。しかし、データ分析の技術は日々発展し、Rがデフォルトで提供する関数では不可能ではないが、かなり長いコードが必要な分析を使わざる得ないケースもあろう。Rは開発元だけでなく、誰でも関数を作ることができる。通常なら数百行のコードが必要な分析を一行のコードで実行可能とする関数を多くのRユーザーが作ってきた。これらの関数を集めたのがパッケージである。Rにはグラフ作成に特化したパッケージ、機械学習に特化したパッケージ、テキスト分析に特化したパッケージなど、数千のパッケージが開発されている。このパッケージの豊富さがRの最大のメリットでもある。誰かが新しい分析手法を提案したら、数日内、あるいはその手法が論文として出版される前からRパッケージとして公開されるケースが多い。\n　本章ではパッケージをインストールし、読み込む方法について説明する。また、パッケージの管理をアシストするパッケージ、{pacman}の使い方についても紹介する。"
  },
  {
    "objectID": "packages.html#sec-packages_install",
    "href": "packages.html#sec-packages_install",
    "title": "5  Rパッケージ",
    "section": "5.2 パッケージのインストール",
    "text": "5.2 パッケージのインストール\n　Rの環境は何かを作るための作業台に似ている。作業台にはモノを作るために材料だけでなく、工具・道具セットなども置いたりもする。この作業台がRにおける「環境 (environment) 」であり、材料がベクトルや行列、データフレームなどのデータ、工具セットがパッケージになる。データについては後で説明するとし、ここではパッケージについて考えたい。\n　モノを作るためには素材・材料だけでは不十分だろう。多くの場合、なんらかの道具セットが必要となる。Rには既にいくつかの必須道具セットを用意されているが、他にも様々な道具セットがある。そして、これら道具セットには、一般的に複数の道具が含まれている。一つ一つの道具のことを、ここでは「関数 (function) 」と呼ぶ。これらの道具セットを購入し、作業台の収納に入れておくことがパッケージをインストールすることである。\n\ninstall.packages(\"パッケージ名\")\n\n　これらのパッケージは基本的にCRANというRの公式道具屋からダウンロード・インストールされる。もう一つの大きな道具屋としてはGitHubがある1。GitHubは個人経営の道具屋が集まっているモールのようなものである。GitHub道具屋を使用するためには、予めCRANから{devtools}、または{remotes}というパッケージをインストールしておく必要がある。\n　ここでは{devtools}というパッケージをインストールしてみよう。{devtools}はCRANに登録されているため、install.pcakges()関数でインストールできる。パッケージ名を\"で囲むことを忘れないこと。\n\ninstall.packages(\"devtools\")\n\n　もし、CRANに登録されていないパッケージをGitHubからインストールするなら、{devtools}パッケージ、または{remotes}のinstall_github()関数を使う。\n\n# あらかじめ{devtools}、または{remotes}をインストールしておく\n# {remotes}をインストールした場合は、remotes::install_github()を使用する\ndevtools::install_github(\"作成者のGitHubのID/パッケージ名\")\n\n　たとえば、筆者 (Song) が作成しました{BalanceR}パッケージがインストールしたいなら、以下のように打つ。\n\n# {remotes}をインストールした場合は、\n# remotes::install_github(\"JaehyunSong/BalanceR\")\ndevtools::install_github(\"JaehyunSong/BalanceR\")\n\n　ここでJaehyunSongはSongのGitHub IDであり、BalanceRはパッケージ名である。"
  },
  {
    "objectID": "packages.html#sec-packages_library",
    "href": "packages.html#sec-packages_library",
    "title": "5  Rパッケージ",
    "section": "5.3 パッケージの読み込み",
    "text": "5.3 パッケージの読み込み\n　先ほど述べたように、パッケージのインストールは道具セットの購入と収納に似ている。ただし、実際に道具セットを使うためには、それを自分の作業台上に載せた方が効率がいいだろう2 3。この作業がパッケージの読み込み (load) である。インストールしたパッケージを読み込むにはlibrary()またはrequire()関数を使う。require()は関数内に使う目的で設計された関数だが、パッケージを読み込むという点では全く同じである。\n\n\n\n図 5.1: Rパッケージと作業環境\n\n\n\nlibrary(\"パッケージ名\")\n#または\nrequire(\"パッケージ名\")\n\n　読み込まれたパッケージはセッションが開かれている時のみに有効である。一通りの作業が終わり、作業部屋から退出すると、作業台上の道具セットは収納に自動的に戻される。つまり、RまたはRStudioを閉じると読み込まれたパッケージは自動的に取り外されるということである。しかし、作業の途中に読み込んだパッケージをセッションから取り外したい時があるかも知れない。この場合、detach()関数を使う。\n\ndetach(\"パッケージ名\")"
  },
  {
    "objectID": "packages.html#sec-packages_update",
    "href": "packages.html#sec-packages_update",
    "title": "5  Rパッケージ",
    "section": "5.4 パッケージのアップデート",
    "text": "5.4 パッケージのアップデート\n　Rパッケージはバグが修正されたり、新しい機能 (=関数) が追加されるなど、日々更新される。できる限りパッケージは最新版に維持した方が良いだろう。パッケージのアップデートはパッケージのインストールと同じである。{dplyr}というパッケージを最新版にアップデートしたい場合、install.packages(\"dplyr\")で十分である。\n　しかし、Rを使っていくうちに数十個のパッケージをインストールしていくこととなり、一つ一つアップデートするのは面倒だろう。そもそも既に最新版が入っていて (または開発休止/中止)、アップデートが不要なパッケージがあるかも知れない。実はRStudioを使えば、アップデートが必要なパッケージのリストが表示され、一気にアップデートすることができる。RStudioのPackagesペインにある「Update」をクリックしてみれば、アップデート可能なパッケージの一覧が表示される。ここでアップデートしたいパッケージの左にチェックをするか、下段の「Select All」を選択して「Install Updates」をクリックすれば、チェックされているパッケージがアップデートされる。\n　ただし、場合によってはアップデート時、以下のようなメッセージがコンソールに表示されるかも知れない。\n  There are binary versions available but the source versions\n  are later:\n      binary source needs_compilation\nterra 1.5-17 1.5-21              TRUE\nyaml   2.2.2  2.3.4              TRUE\n\nDo you want to install from sources the packages which need compilation? (Yes/no/cancel)\n　コンソールにYes、no、cancelのいずれかを入力してReturnキー (Enterキー)を押す必要がある。どうしても最新のパッケージが欲しい場合はYesを入力すれば良いが、インストールに時間がかかる場合がある。一方、noを入力した場合は、若干古いバージョンがインストールされるが、インストールに必要な時間が短いため、基本的にはnoでも問題ないだろう。cancelを入力した場合はアップデートが全てキャンセルされる。"
  },
  {
    "objectID": "packages.html#sec-packages_pacman",
    "href": "packages.html#sec-packages_pacman",
    "title": "5  Rパッケージ",
    "section": "5.5 {pacman}によるパッケージ管理",
    "text": "5.5 {pacman}によるパッケージ管理\n　CRANとGitHubなどには数千のRパッケージが公開されており、Rの使用歴が長くなればインストールされているパッケージが増えたり、一つのスクリプト内で使用するパッケージも増えていくだろう。また、パッケージは他のパッケージの機能に依存することがほとんどなので、自分の想像以上の数のパッケージがインストールされているかも知れない。このように膨大な数のパッケージを管理するためのパッケージが{pacman}である。{pacman}はCRANから入手可能である。\n\ninstall.packages(\"pacman\")\n\n\n5.5.1 インストール\n　パッケージをCRANからインストールにはp_install()関数を使用する。使い方はinstall.packages()と同じであり、複数のパッケージをインストールしたい場合はパッケージ名の箇所にc(パッケージ名1, パッケージ名2, ...)を入れる。パッケージ名は\"で囲んでも、囲まなくても良い。GitHubに公開されているパッケージはp_install_gh()関数を使用する。これは{devtools}、または{remotes}のinstall_github()と同じ使い方となり、必ず\"で囲む必要がある。\n　これらの関数を使う際、わざわざlibrary(pacman)を使う必要はない。パッケージのインストールや、読み込みなどはコード内に何回も使われることがほとんどないため、{pacman}を読み込まずpacman::関数名()で当該関数を使うことができる。\n\n# CRANからインストール\npacman::p_install(パッケージ名)\n# githubからインストール\npacman::p_install_gh(\"作成者のGitHubのID/パッケージ名\") \n\n\n\n5.5.2 読み込み\n　パッケージの読み込みにはp_load()関数を使い、実はこの関数は{pacman}を使う最も大きな要素である。p_load()関数の使い方は以下の通りである。\n\npacman::p_load(パッケージ名)\n\n　p_load()の便利なところは (1) 複数のパッケージが指定可能であることと、 (2) インストールされていないパッケージはCRANから自動的にインストールして読み込んでくれる点だ。たとえば、{tidyverse}と{broom}、{estimatr}という3つのパッケージを読み込む場合、library()関数を使うと以下のようになる。\n\n# library() を使う場合\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(estimatr)\n\n　一方、{pacman}のp_load()を使えば、以下のように3つのパッケージを読み込むことができる。\n\n# {pacman}のp_load() を使う場合\npacman::p_load(tidyverse, broom, estimatr)\n\n　また、p_load()内のパッケージがインストールされていない場合、CRANのパッケージリストから検索し、そのパッケージをインストールしてくれる。したがって、上で紹介したp_install()は実質的に使うケースはほぼない。\n　ただし、GitHub上のパッケージは自動的にインストールしてくれない。たとえば、GitHub上のみにて公開されている{BlanceR}パッケージがインストールされていない場合、p_load(BalanceR)を実行しても{BalanceR}はインストールされない。あらかじめp_install_gh()でインストールしておく必要がある。しかし、GitHub上のパッケージを検索し、インストール&読み込みをするp_load_gh()という関数もある。ユーザー名JaehyunSongのBalanceRレポジトリーのパッケージを読み込む場合は以下のように入力する。\n\npacman::p_load_gh(\"JaehyunSong/BalanceR\")\n\n　このコードは{BalanceR}パッケージがインストールされていると読み込みのみ行い、インストールされていない場合はJaehyunSongのBalanceRレポジトリからパッケージをインストールし、読み込む。書くのがやや面倒であるが、便利な関数である。\n\n\n5.5.3 アップデート\n　{pacman}にはアップデートが可能なパッケージを全てアップデートしてくれるp_update()という関数も用意されている。使い方は簡単で、コンソール上にp_update()のみの入力すれば良い。ただし、一部のパッケージのみをアップデートしたいのであれば、RStudioが提供するアップデート機能を使った方が良いかも知れない4。\n　また、同じ機能の関数としてp_up()があるが、コードの可読性のためにp_update()の方を推奨したい。\n\npacman::p_update()"
  },
  {
    "objectID": "packages.html#sec-packages_tidyverse",
    "href": "packages.html#sec-packages_tidyverse",
    "title": "5  Rパッケージ",
    "section": "5.6 必須パッケージのインストール",
    "text": "5.6 必須パッケージのインストール\n　ここでは現在のRにおいて必須パッケージである{tidyverse}をインストールする。{tidyverse}は{dplyr}、{ggplot2}、{tidyr}など、Rにおいて不可欠なパッケージを含むパッケージ群である。また、上で紹介した{devtools}も今のうちにインストールしておこう。既に導入済みの読者は走らせなくても良い。\n\ninstall.packages(\"tidyverse\")\ninstall.packages(\"devtools\")"
  },
  {
    "objectID": "project.html#sec-project-intro",
    "href": "project.html#sec-project-intro",
    "title": "6  プロジェクト管理",
    "section": "6.1 「プロジェクト」のすゝめ",
    "text": "6.1 「プロジェクト」のすゝめ\n　Rを使ったプログラミングやデータ分析を進めていくと、自分が書いたRスクリプトや作成した図表だけでなく、 Rが自動的に生成するファイルもどんどん溜まる。そう遠くない将来、ドライブ内のファイル数が数万に達しても不思議ではない。効率よくプログラミングを行うために、ファイルの管理方法を明確にしておいたほうが良い。そのためには、フォルダの階層化を利用してファイルを管理することが必要である。\n　しかし、フォルダによる階層化を導入すればファイルの管理が楽になるかというと、必ずしもそうとは限らない。かえって不便になる部分もある。前の節で見たとおり、フォルダを階層化すると、絶対パスが長く（複雑に）なる。ファイルを階層化によって整理したとしても、ファイルを利用するたびに長い絶対パスの入力が必要なら、ファイル管理の効率が上がったとは言えないだろう。\n　Rを使う場合にファイル管理の効率化を助けてくれるのが、RStudio の「プロジェクト」機能である。"
  },
  {
    "objectID": "project.html#sec-project-create",
    "href": "project.html#sec-project-create",
    "title": "6  プロジェクト管理",
    "section": "6.2 プロジェクトの作り方",
    "text": "6.2 プロジェクトの作り方\n　Rの既定（デフォルト）の作業フォルダはホームフォルダある。分析に使うデータが、ホームフォルダの中の Documents フォルダの中の R フォルダの中の Analysis1 フォルダ内の Data フォルダにある data.csv だとしたら、このファイルにアクセスするためには、\"Documents/R/Analysis1/Data/data.csv\"と入力する必要がある1 \\(^,\\) 2。新たに作った図を “histogram.pdf” という名前でホームフォルダの中の Documents フォルダの中の R フォルダの中の Analysis1 フォルダ内の Figures というフォルダに保存するためには、\"Documents/R/Analysis1/Figures/historam.pdf\"と入力する必要がある。どちらもかなり面倒で、効率が悪い。\n　しかし、作業フォルダが、~/Documents/R/Analysis1/ だとすれば、相対パスにより、\"Data/data.csv\" や\"Figures/historam.pdf\" だけで済む。よって、作業フォルダを明示的に指定すればいいわけだが、作業フォルダを毎回指定するのも面倒だ。\n　そこで利用できるのが、RStudio のプロジェクト機能である。 プロジェクトとは、特定のフォルダを作業フォルダに設定し、すべての作業をそのフォルダと下位フォルダのみに限定してくれる機能である3。プロジェクト機能さえ使えば、ユーザが意識しなくても、ユーザが書いたコード、保存したデータ、作成した図などが作業フォルダ内に集約され、管理が楽になる。\n　では、ここからプロジェクトの作り方を説明しよう。\n\nまずはRStudio を起動する。\nRStudio が起動したら、“File” から “New Project” を選択する。\n\n\n\n\n図 6.1: FileからNew Project…\n\n\n\n下の画面が表示されたら、 “New Directory” を選択する。ただし、既存のフォルダを利用したい場合は、 “Existing Directory” を選ぶ。\n\n\n\n\n図 6.2: New Directoryを選択\n\n\n\n下の画面が表示されたら、“New Project” を選択する。\n\n\n前の手順で “Existing Directory” を選択した場合、この画面は表示されない。\n\n\n\n\n図 6.3: New Projectを選択\n\n\n\n下の画面が表示されたら、“Directory name:” にプロジェクト名を入力する。これがフォルダ名になるので、半角英数字のみの 名前を付ける。ここでは第4章のコードということで、“Ch04” にした。統計学の授業用プロジェクトなら “statistics”、計量政治学の授業なら “quant_methods_ps” などの名前を付ければ良いだろう。英語が嫌なら “tokeigaku” のようにすれば良い。また、“Create project as subdirectory of:” では、プロジェクトのフォルダをどのフォルダの中に設置するかを指定する。 “Browse…” をクリックし、親フォルダを選ぶ。ここでは ~/Dropbox/RStudy にプロジェクトのフォルダを入れることにする。ここまでできたら、“Create Project” をクリックする。\n\n\n手順3で “Existing Directory” を選んだ場合、プロジェクトのフォルダとして使う既存フォルダを選択する画面が表示される。\n\n\n\n\n図 6.4: プロジェクト名と保存場所の指定\n\n\n\n以上の手順でプロジェクトができる。RStudio 右上に、プロジェクト名が表示されているはずだ。 また、Console に getwd() と入力すると、プロジェクトまでの絶対パスが表示される。\n\n　念のため、Finder（Macの場合）やエクスプローラー （Windows の場合）で、指定した場所にプロジェクトのフォルダ（上の例では Ch04）が生成されていることを確認しよう。 プロジェクトフォルダを開いてみると、Ch04.Rproj というファイルが生成されていることがわかる（ 図 6.5 ）。\n\n\n\n図 6.5: プロジェクトの確認"
  },
  {
    "objectID": "project.html#sec-project-open",
    "href": "project.html#sec-project-open",
    "title": "6  プロジェクト管理",
    "section": "6.3 プロジェクトの開き方",
    "text": "6.3 プロジェクトの開き方\n　RStudioを終了すると開かれていたプロジェクトも閉じられ、もう一度RStudioを起動するとプロジェクト無しの状態へ戻る4。これはプロジェクトフォルダーがなくなったわけではなく、もう一度開けば良い。作成したプロジェクトを開く（=再開する）方法は、（1）.Rprojファイルを立ち上げる方法と、（2）RStudio内で開く方法がある。\n　たとえば、先ほど作成したCh04プロジェクトを開くには、 図 6.5 のCh04.Rproj ファイルをダブルクリックすれば良い。RStudioが起動していない場合でも、指定のプロジェクトを開いた状態でRStudioが起ち上がる。\n　すでにRStudioを開いた状態であれば、わざわざFinder/エクスプローラーを開く必要はなく、RStudio内でプロジェクトを開くこともできる。RStudioメニューのFile &gt; Open Project…（ 図 6.6 ）を選択すると新しいウィンドウが表示されるが、ここで開きたいプロジェクトの.Rprojファイルを選択すれば良い。\n\n\n\n図 6.6: File &gt; Open Projects…\n\n\n　このやり方だと、プロジェクトフォルダーを探す手間が必要だからやや面倒である。しかし、よく使うプロジェクト（=最近使ったことのあるプロジェクト）なら簡単に開くこともできる。 図 6.7 のようにFile &gt; Recent Projectsを選択すると最近使用したプロジェクトのリストが表示され、それを選択するだけで当該プロジェクトが開かれるようになる。\n\n\n\n図 6.7: File &gt; Recnet Projects\n\n\n　もう一つの方法はRStudioの右上にあるプロジェクトボタンを使うことだ（ 図 6.8 ）。ここでOpen Project…はFile &gt; Open Project…と同じ機能であり、下の方には最近使ったプロジェクトの一覧が表示されるのでかなり便利だ。\n\n\n\n図 6.8: RStudio右上のボタンを使う方法\n\n\n　以上の方法はすでにプロジェクトを開いている状態で、別プロジェクトへ切り替えたい場合でも使える。現在作業中のプロジェクトは置いたまま、新しいRStuioで開きたい場合は、「Open Project in New Session…」を選択すれば良い。"
  },
  {
    "objectID": "project.html#sec-project-check",
    "href": "project.html#sec-project-check",
    "title": "6  プロジェクト管理",
    "section": "6.4 プロジェクトの確認",
    "text": "6.4 プロジェクトの確認\n　RStudio 右上の表示が “Project: (None)” となっているとき（ 図 6.9 (a) ）は、プロジェクトが開かれていないことを意味する。一方、プロジェクトが開かれている場合は当該箇所にプロジェクト名が表示される（ 図 6.9 (b) ）。RStudio を使う場合には、必ず右上の表示を見て、プロジェクトが開かれていることを確認しよう。プロジェクトが開かれていない場合には、既存のプロジェクトを開くか、新たばプロジェクトを作ろう。むろん、簡単な計算や電卓用途、計算・分析結果を残す必要がない場合は無理してプロジェクト機能を使う必要はない。\n\n\n\n\n \n\n\n\n\n\n(a) プロジェクトが開かれていない状態\n\n\n\n\n \n\n\n\n\n\n(b) Homework_01プロジェクト使用中\n\n\n\n\n \n\n\n図 6.9: 比較"
  },
  {
    "objectID": "r_basic.html#sec-rbasic-calc",
    "href": "r_basic.html#sec-rbasic-calc",
    "title": "7  基本的な操作",
    "section": "7.1 電卓としてのR",
    "text": "7.1 電卓としてのR\n　ここからはRを使っていこう。まず、新しい　R Script を開くために、Cmd/Ctrl + Shift + N を入力する1（“File” メニューから “New File” - “R Script” を選んでも良い）。すると、 左上の Source Pane に “Untitled1” というタブが登場し、その pane 上でコードが入力できるようになる。ここで 3 + 3 と入力し、その行にカーソルを留めたまま command + return（Mac）または Ctrl + Enter を押してみよう。command + return というのは、command キーを押したまま、return キーも押すという意味である。\n\n\n\n図 7.1: コード入力の例\n\n\n　Source ペイン (Untitled1) に入力したコードが Console（本書の説明どおりにカスタマイズしていれば、RStudio 内の右上画面）に転送され、計算結果が表示される。Rのコードは Console に直接打ち込むこともできるが、Sourceペインで入力してから Console に転送する方法が基本である2。 Source ペインの内容をファイルに保存すれば、後でもう1度同じコードを実行したり、コードを他のプロジェクトで再利用することができるようになる。先ほど 3 + 3　を入力した画面にカーソルを合わせ、Cmd/Ctrl + S を押してみよう。ファイルの保存を促されるので、ファイル名をつけて保存しよう。このとき、.R というファイル名拡張子を付ける。これにより、ファイルがRスクリプトとして認識される。例えば、“practice01.R” という名前をつけて保存しよう。Sourceペインの上部に表示されるタブの名前が、“Untitled1” から “practice01.R” に変わることが確認できるはずだ。\n　以下にRで計算する例を示すので、コードを practice01.R に入力し、command + return （Ctrl + Enter） で Console に送り、実行結果を確認しよう。背景が灰色になっている部分に示されているのが、Rのコマンドである。ただし、##から始まる部分は計算結果である。また、コードブロックのうち、 #（ハッシュ記号）で始まる部分はコメントであり、Rで評価（計算）されない。コメントの使い方については第23章で詳しく解説する。\n\n7.1.1 算術演算子\n　まずは、簡単な足し算と掛け算を実行してみよう。\n\n3 + 3\n\n[1] 6\n\n8 * 2\n\n[1] 16\n\n\nこれ以外の基本的な演算は以下のとおりである。\n\n\n\n演算子\n意味\n例\n結果\n\n\n\n\n+\n和\n2 + 5\n7\n\n\n-\n差\n2 - 8\n-6\n\n\n*\n積\n7 * 3\n21\n\n\n/\n商\n16 / 5\n3.2\n\n\n^、**\n累乗（べき乗）\n2^3または2 ** 3\n8\n\n\n%%\n剰余 (モジュロ)\n18 %% 7\n4\n\n\n%/%\n整数商\n18 %/% 7\n2\n\n\n\n\n\n7.1.2 論理演算子\n　論理演算子とは、入力した式が真か偽かを判定する演算子である。返り値（戻り値）は　TRUE（真の場合）または FALSE（偽の場合）のいずれかとなる。たとえば、「3 &gt; 2」は真なので、TRUE が返される。しかし、「2 + 3 = 1」は偽なので、FALSEが返される。実際にやってみよう。\n\n3 &gt; 2\n\n[1] TRUE\n\n2 + 3 == 1\n\n[1] FALSE\n\n\n　このように、等しいかどうかを表す記号は = ではなく ==（二重等号）なので注意されたい。\n　論理演算子にも、いくつかの種類がある。\n\n\n\n\n演算子\n意味\n例\n結果\n\n\n\n\n1\nx &lt; y\nxはyより小さい\n3 &lt; 1\nFALSE\n\n\n2\nx &lt;= y\nxはyと等しいか、小さい\n2 &lt;= 2\nTRUE\n\n\n3\nx &gt; y\nxはyより大きい\n6 &gt; 5\nTRUE\n\n\n4\nx &gt;= y\nxはyと等しいか、大きい\n4 &gt;= 5\nFALSE\n\n\n5\nx == y\nxとyは等しい\n(2 + 3) == (4 + 1)\nTRUE\n\n\n6\nx != y\nxとyは等しくない\n((2 * 3) + 1) != (2 * (3 + 1))\nTRUE\n\n\n\n　6番目の例について少し説明する。通常の数式同様、Rも括弧()内の記述を優先的に計算する。したがって、!=左側の((2 * 3) + 1) は 6 + 1 = 7 であり、右側の (2 * (3 + 1)) は 2 * 4 = 8 である。したがって、7 != 8 が判定対象となり、TRUEが返される。! 記号は、「否定」を表すために使われるもので、!= は左右が等しくないときに TRUE を返す\n　上に挙げた論理演算子は基本的に数字を対象に使うが、TRUEとFALSE を対象に使うものもある。それが and を表す & と or を表す| である。。& は、&　を挟む左右の両側が TRUE の場合のみ TRUE を返し、| は少なくとも一方が TRUE なら TRUE を返す。\n\n\n\n\n演算子\n意味\n例\n結果\n\n\n\n\n1\nx | y\nxまたはy\n(2 + 3 == 5) | (1 * 2 == 3)\nTRUE\n\n\n2\nx & y\nxかつy\n(2 + 3 == 5) & (1 * 2 == 3)\nFALSE\n\n\n\n　1番の例では、|の左側は(2 + 3 == 5)であり、TRUE である。一方、右側の(1 * 2 == 3) は FALSE だ。判定対象はTRUE | FALSE となり、TRUE が返される。 2番目の例は TRUE & FALSE なので、返り値は FALSE になる。"
  },
  {
    "objectID": "r_basic.html#sec-rbasic-input",
    "href": "r_basic.html#sec-rbasic-input",
    "title": "7  基本的な操作",
    "section": "7.2 格納とオブジェクトの作成",
    "text": "7.2 格納とオブジェクトの作成\n\nまず、123454321 * 2 を計算しよう。\n次に、123454321 * 3 を計算しよう。\n最後に、123454321 * 4 を計算しよう。\n\n　これらの計算は簡単にできるだろう。しかし、123454321を3回入力するのが面倒だっただろう3。123454321という数字をxとかaに代入し、数字の代わりに x や a が使えるなら、上の計算は楽になる。ここではその方法を説明する。\n　xというものに123454321という数字を入れるには、&lt;- という演算子を使う。この演算子により、xという名のもの （オブジェクト）に123454321という数字を代入することができる。ここでは「代入」という表現を使ったが4、&lt;-の役割は代入よりも広いので、これからは「格納」という表現を使う。\n　&lt;- は、&lt; と- という2つの記号をスペースなしで入力することで作ることができる。 RStudioでは、 option + - [マイナス, ハイフン] (macOS 場合) または Alt + - （Windows の場合）で、&lt;- が入力できる。その際、演算子の前後に半角スペースが1つずつ挿入されるので、このショートカットは必ず使うべきである。\n　Rを起動した時点では、x というオブジェクトは存在しない。RStudio 右下のペインにある Environment タブを開くと、現時点では何も表示されていないはずだ。しかし、x に何かを格納することで、x というオブジェクトができる。 実際に xに、123454321を格納してみよう。\n\nx &lt;- 123454321  # xに123454321を格納\n\nEnvironment タブに、x が登場し、格納した数字が右側に表示されていることが確認できるだろう。\n　オブジェクトの中身は、オブジェクト名をそのまま入力することで表示できる。\n\nx\n\n[1] 123454321\n\n\n　print(x) でも同じ結果が得られるが、タイプする文字数を減らしたいので xのみにする。ただし、状況やオブジェクトの型（型については後で詳しく説明する）によっては、print() を表示しないと中身が表示されない場合もあるので、R Markdown ファイルで論文などを作成していて、結果を確実に表示したい場合には print(x) とするほうが安全である。\n　ちなみに、格納と同時にそのオブジェクトの中身を表示することもできる。そのためには、格納コマンド全体を() で囲む。例えば、次のようにする。\n\n(y &lt;- 2) 　# yに2を格納し、中身を表示\n\n[1] 2\n\n\n　値が格納されたオブジェクトは計算に利用できるので、先ほどの計算は、次のようにできる。\n\nx * 2\n\n[1] 246908642\n\nx * 3\n\n[1] 370362963\n\nx * 4\n\n[1] 493817284\n\n\n　文字列を格納することもできる。ただし、文字列は必ず \"\" か '' で囲む必要がある。\n\nx &lt;- \"猫の恋 やむとき閨の 朧月（芭蕉）\"\nx\n\n[1] \"猫の恋 やむとき閨の 朧月（芭蕉）\"\n\n\n　オブジェクトに格納できるのは1つの数値や文字列だけではない。複数の数値や文字列を格納することもできる。そのためには c() という関数を使う。c() のc は concatenate または combine の頭文字で、複数の要素からベクトル (vector) を作るのに使われる関数である。 c() に含む要素はカンマ (,) で区切る。\n\n# ある日の Lions の打順をベクトルに格納する\nnumeric_vec1  &lt;- c(73, 6, 5, 3, 99, 10, 22, 9, 7)\nnumeric_vec1\n\n[1] 73  6  5  3 99 10 22  9  7\n\n\n　複数の文字列を格納することもできる。\n\ncharacter_vec &lt;- c('cat', 'cheetah', 'lion',  'tiger')\ncharacter_vec\n\n[1] \"cat\"     \"cheetah\" \"lion\"    \"tiger\"  \n\n\n　ひとつひとつの要素を指定する代わりに、様々な方法でベクトルを作ることが可能である。 たとえば、seq() 関数を使うと、一連の数字からなるベクトルを作ることができる。from で数列の初項を、to で数列の最終項を指定し、by で要素間の差（第2要素は第1要素に by を加えた値になる ）を指定するか、length.out で最終的にできるベクトルの要素の数を指定する。Rのベクトルの length とは、要素の数のことなので、注意されたい。\n　いくつか例を挙げる。\n\n# 1から20までの整数。1:20 でも同じ\nseq(from =  1, to = 20, by = 1)\n\n [1]  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20\n\n# 1から19までの奇数\nseq(from = 11, to = 20, by = 2)\n\n[1] 11 13 15 17 19\n\n# 2から20までの偶数\nseq(from =  2, to = 20, by = 2)\n\n [1]  2  4  6  8 10 12 14 16 18 20\n\n# 降順、間隔は5\nseq(from = 20, to = 1, by = -5)\n\n[1] 20 15 10  5\n\n# 最小値が1、最大値が100で、長さが10のベクトル\nseq(from = 1, to = 100, length.out = 10)\n\n [1]   1  12  23  34  45  56  67  78  89 100\n\n# 73から1つずつ数が小さくなる長さが10のベクトル\nseq(from = 73, by = -1, length.out = 8)\n\n[1] 73 72 71 70 69 68 67 66\n\n\n　このように1つの関数でも指定する内容は、by になったりlength.out になったりする。by や length.out、from、to などのように、関数で指定する対象になっているもののことを 仮引数 (parameter) と呼ぶ。また、by = 1 の1や、length.out = 10 の10のように、仮引数に実際に渡される値のことを実引数 (argument) と呼ぶ。特に誤解が生じないと思われる場合には、仮引数と実引数を区別せずに引数（ひきすう）と呼ぶ。 Rでは、1つの関数で使う引数の数が複数あることが多いので、仮引数を明示する習慣を身につけたほうがよい。 ただし、第1引数（関数で最初に指定する引数）として必ず入力すべきものは決められている場合がほとんどなので、第1引数の仮引数は省略されることが多い。仮引数が省略される代わりに、第1引数の実引数はほぼ必ず入力する（いくつかの例外もある）。\n　seq(from = x, to = y, by = 1) の場合はより単純に x:y とすることができる。\n\n21:30  # 21 から30までの整数\n\n [1] 21 22 23 24 25 26 27 28 29 30\n\n10:1   # 10 から1までの整数（降順）\n\n [1] 10  9  8  7  6  5  4  3  2  1\n\n\n　また、rep() 関数も便利である。例を挙げよう。\n\n# 3が10個のベクトル\nrep(3, times = 10)\n\n [1] 3 3 3 3 3 3 3 3 3 3\n\n# aが3つ, bが1つ, cが2つのベクトル\nrep(c('a', 'b', 'c'), times = c(3, 1, 2))\n\n[1] \"a\" \"a\" \"a\" \"b\" \"c\" \"c\"\n\n# C, A, T を2つずつ\nrep(c('C', 'A', 'T'), each = 2)\n\n[1] \"C\" \"C\" \"A\" \"A\" \"T\" \"T\"\n\n\n　アルファベットのベクトルは、あらかじめ用意されている。\n\nLETTERS  # 大文字\n\n [1] \"A\" \"B\" \"C\" \"D\" \"E\" \"F\" \"G\" \"H\" \"I\" \"J\" \"K\" \"L\" \"M\" \"N\" \"O\" \"P\" \"Q\" \"R\" \"S\"\n[20] \"T\" \"U\" \"V\" \"W\" \"X\" \"Y\" \"Z\"\n\nletters  # 小文字\n\n [1] \"a\" \"b\" \"c\" \"d\" \"e\" \"f\" \"g\" \"h\" \"i\" \"j\" \"k\" \"l\" \"m\" \"n\" \"o\" \"p\" \"q\" \"r\" \"s\"\n[20] \"t\" \"u\" \"v\" \"w\" \"x\" \"y\" \"z\""
  },
  {
    "objectID": "r_basic.html#sec-rbasic-extract",
    "href": "r_basic.html#sec-rbasic-extract",
    "title": "7  基本的な操作",
    "section": "7.3 要素の抽出",
    "text": "7.3 要素の抽出\n　オブジェクト名（ベクトル）の後に [抽出する要素のインデクス] を付けると、ベクトルの特定の要素を抽出することができる。ちなみに [ は関数である。Console にhelp(\"[\") と打てば、これが Extract と言う名前の関数であることがわかる（help(\"[]\") ではないので注意）。\n　ベクトルの要素を取り出してみよう。Rのインデクスは、他の多くのプログラミング言語（例えば、C, C++, Pythonなど）とは異なり「1」から始まるので注意されたい。\n\n# numeric_vec1の5番目の要素を抽出\nnumeric_vec1[5]\n\n[1] 99\n\n# numeric_vec1の2, 4, 6番目の要素を抽出\nnumeric_vec1[c(2, 4, 6)]\n\n[1]  6  3 10\n\n# numeric_vec1の1番目と4番目「以外」の要素を抽出\nnumeric_vec1[-c(1, 4)]\n\n[1]  6  5 99 10 22  9  7\n\n# numeric_vec1の5番目から7番目の要素を抽出\nnumeric_vec1[5:7]\n\n[1] 99 10 22\n\n\n　c()や:だけでなく、seq()も使える。\n\nnumeric_vec2 &lt;- 1:20\n# numeric_vec2 の奇数番目の要素を抽出\nnumeric_vec2[seq(1, 20, by = 2)]\n\n [1]  1  3  5  7  9 11 13 15 17 19\n\n\n　さらに、TRUEとFALSEを使うこともできる。この場合、抽出したい要素の場所を指定するのではなく、それぞれの場所について抽出する (TRUE) か、しない (FALSE) かを指定する。たとえば、character_vecから1, 3, 4番目の要素を抽出するなら、[c(TRUE, FALSE, TRUE, TRUE)]と指定する。\n\ncharacter_vec[c(TRUE, FALSE, TRUE, TRUE)]\n\n[1] \"cat\"   \"lion\"  \"tiger\"\n\n\n　TRUEとFALSEが使えるので、論理演算子を[]の中で使うこともできる。たとえば、numeric_vec1の各要素が偶数かどうかを判定するためには、インデックスが2で割り切れるかどうか（2で割った余りが0かどうか）を確認すれば良い。\n\n(numeric_vec1 %% 2) == 0  # 偶数かどうかの判定\n\n[1] FALSE  TRUE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE\n\n\nこれを利用すれば、numeric_vec1から偶数のみを抽出できる。\n\nnumeric_vec1[(numeric_vec1 %% 2) == 0]\n\n[1]  6 10 22\n\n\n　[ と格納（代入）を組み合わせれば、「ベクトルの一部の要素を書き換える」ことができる。たとえば、numeric_vec1の2番目の要素は5だが、これを100に書き換えたい場合、置換したい要素の場所を[]で指定し、&lt;-で代入すれば良い。\n\nnumeric_vec1[2] &lt;- 100\nnumeric_vec1\n\n[1]  73 100   5   3  99  10  22   9   7\n\n\n　複数の要素を置換することもできる。たとえば、偶数を全て0に置換したい場合、以下のようにする。\n\nnumeric_vec1[(numeric_vec1 %% 2) == 0] &lt;- 0\nnumeric_vec1\n\n[1] 73  0  5  3 99  0  0  9  7"
  },
  {
    "objectID": "io.html#sec-io-read",
    "href": "io.html#sec-io-read",
    "title": "8  データの入出力",
    "section": "8.1 データの読み込み",
    "text": "8.1 データの読み込み\n\n8.1.1 csvファイルの場合\n　csv は、comma separated values の略である。多くの人に馴染みがあると思われる Excelファイル (.xlsx) と同じように、表形式（行列形式）のデータを保存できる。しかし、Excelファイルとは異なり、文字の大きさ、セルの背景色、複数のセルの結合のような情報はもたず、純粋にデータに含まれる変数の名前と各変数の値（数値・文字列）のみが格納されているため、ファイルサイズが小さい。また、文字データしかもたないテキストファイルであり、テキストエディタで開くことができる。テキストファイルで csv ファイルを開けば、“csv” と呼ばれる理由がわかるだろう。csvフォーマットはデータを保存のための標準フォーマットの1つであり、多くのデータがcsv形式で保存されている。データ分析ソフトでcsv ファイルを開けないものはおそらくないだろう。\n　Rでもcsv形式のファイルは簡単に読み込める。実際にやっててみよう。データのダウンロード方法については本書の巻頭を参照されたい。csvファイルを読み込むにはread.csv()またはreadr::read_csv()関数を使う1。読み込む際は前章のベクトルの生成同様、何らかの名前を付けて作業環境に保存する。Dataフォルダーにある FIFA_Women.csv ファイルを読み込み、my_df1と名付ける場合、以下のようなコードを実行する2。以下のコードでmy_df1 &lt;-　の部分を入力しないと、データが画面に出力され、自分の作業スペースには保存されないので注意されたい。\n\nmy_df1 &lt;- read.csv(\"Data/FIFA_Women.csv\")\n\n　読み込まれたデータの中身を見るには、ベクトルの場合と同様にprint()関数を使うか、オブジェクト名を入力する。\n\nmy_df1\n\n     ID                   Team Rank Points Prev_Points Confederation\n1     1                Albania   75   1325        1316          UEFA\n2     2                Algeria   85   1271        1271           CAF\n3     3         American Samoa  133   1030        1030           OFC\n4     4                Andorra  155    749         749          UEFA\n5     5                 Angola  121   1117        1117           CAF\n6     6    Antigua and Barbuda  153    787         787      CONCACAF\n7     7              Argentina   32   1659        1659      CONMEBOL\n8     8                Armenia  126   1103        1104          UEFA\n9     9                  Aruba  157    724         724      CONCACAF\n10   10              Australia    7   1963        1963           AFC\n11   11                Austria   22   1792        1797          UEFA\n12   12             Azerbaijan   76   1321        1326          UEFA\n13   13                Bahrain   84   1274        1274           AFC\n14   14             Bangladesh  134   1008        1008           AFC\n15   15               Barbados  135   1002        1002      CONCACAF\n16   16                Belarus   53   1434        1437          UEFA\n17   17                Belgium   17   1819        1824          UEFA\n18   18                 Belize  150    824         824      CONCACAF\n19   19                Bermuda  136    987         987      CONCACAF\n20   20                 Bhutan  154    769         769           AFC\n21   21                Bolivia   91   1236        1236      CONMEBOL\n22   22 Bosnia and Herzegovina   59   1411        1397          UEFA\n23   23               Botswana  148    848         848           CAF\n24   24                 Brazil    8   1958        1956      CONMEBOL\n25   25               Bulgaria   79   1303        1303          UEFA\n26   26               Cameroon   51   1455        1486           CAF\n27   27                 Canada    8   1958        1958      CONCACAF\n28   28                  Chile   37   1640        1637      CONMEBOL\n29   29               China PR   15   1867        1842           AFC\n30   30         Chinese Taipei   40   1589        1584           AFC\n31   31               Colombia   25   1700        1700      CONMEBOL\n32   32                Comoros  156    731         731           CAF\n33   33                  Congo  104   1178        1178           CAF\n34   34               Congo DR  110   1159        1159           CAF\n35   35           Cook Islands  103   1194        1194           OFC\n36   36             Costa Rica   36   1644        1630      CONCACAF\n37   37          Côte d'Ivoire   63   1392        1392           CAF\n38   38                Croatia   52   1453        1439          UEFA\n39   39                   Cuba   88   1240        1240      CONCACAF\n40   40                 Cyprus  123   1114        1123          UEFA\n41   41         Czech Republic   29   1678        1678          UEFA\n42   42                Denmark   16   1851        1839          UEFA\n43   43     Dominican Republic  105   1173        1173      CONCACAF\n44   44            El Salvador  109   1164        1164      CONCACAF\n45   45                England    6   1999        2001          UEFA\n46   46      Equatorial Guinea   71   1356        1356           CAF\n47   47                Estonia   95   1210        1206          UEFA\n48   48               Eswatini  151    822         822           CAF\n49   49               Ethiopia  111   1151        1151           CAF\n50   50          Faroe Islands   86   1259        1262          UEFA\n51   51                   Fiji   66   1373        1373           OFC\n52   52                Finland   30   1671        1678          UEFA\n53   53                 France    3   2036        2033          UEFA\n54   54                  Gabon  130   1066        1066           CAF\n55   55                 Gambia  113   1143        1183           CAF\n56   56                Georgia  115   1138        1145          UEFA\n57   57                Germany    2   2090        2078          UEFA\n58   58                  Ghana   60   1401        1404           CAF\n59   59                 Greece   62   1396        1395          UEFA\n60   60                   Guam   82   1282        1282           AFC\n61   61              Guatemala   80   1290        1290      CONCACAF\n62   62                  Haiti   64   1391        1368      CONCACAF\n63   63               Honduras  116   1136        1136      CONCACAF\n64   64              Hong Kong   74   1329        1335           AFC\n65   65                Hungary   43   1537        1526          UEFA\n66   66                Iceland   19   1817        1821          UEFA\n67   67                  India   55   1432        1432           AFC\n68   68              Indonesia   94   1222        1222           AFC\n69   69                IR Iran   70   1358        1358           AFC\n70   70                 Israel   67   1369        1371          UEFA\n71   71                  Italy   14   1889        1882          UEFA\n72   72                Jamaica   50   1460        1461      CONCACAF\n73   73                  Japan   11   1937        1942           AFC\n74   74                 Jordan   58   1419        1419           AFC\n75   75             Kazakhstan   77   1318        1318          UEFA\n76   76                  Kenya  137    986         986           CAF\n77   77              Korea DPR   10   1940        1940           AFC\n78   78         Korea Republic   18   1818        1812           AFC\n79   79                 Kosovo  125   1104        1109          UEFA\n80   80        Kyrgyz Republic  120   1118        1118           AFC\n81   81                 Latvia   93   1223        1223          UEFA\n82   82                Lebanon  141    967         967           AFC\n83   83                Lesotho  147    850         850           CAF\n84   84              Lithuania  107   1169        1168          UEFA\n85   85             Luxembourg  119   1124        1124          UEFA\n86   86             Madagascar  158    691         691           CAF\n87   87                 Malawi  145    887         887           CAF\n88   88               Malaysia   90   1238        1238           AFC\n89   89               Maldives  142    966         966           AFC\n90   90                   Mali   83   1276        1276           CAF\n91   91                  Malta  101   1197        1195          UEFA\n92   92              Mauritius  159    357         357           CAF\n93   93                 Mexico   27   1686        1699      CONCACAF\n94   94                Moldova   92   1228        1229          UEFA\n95   95               Mongolia  123   1114        1114           AFC\n96   96             Montenegro   97   1201        1206          UEFA\n97   97                Morocco   81   1289        1280           CAF\n98   98             Mozambique  152    814         814           CAF\n99   99                Myanmar   45   1511        1527           AFC\n100 100                Namibia  143    956         956           CAF\n101 101                  Nepal   99   1200        1200           AFC\n102 102            Netherlands    4   2032        2035          UEFA\n103 103          New Caledonia   96   1208        1208           OFC\n104 104            New Zealand   23   1757        1760           OFC\n105 105              Nicaragua  122   1116        1116      CONCACAF\n106 106                Nigeria   38   1614        1614           CAF\n107 107        North Macedonia  129   1072        1073          UEFA\n108 108       Northern Ireland   55   1432        1433          UEFA\n109 109                 Norway   12   1930        1929          UEFA\n110 110              Palestine  117   1131        1131           AFC\n111 111                 Panama   60   1401        1437      CONCACAF\n112 112       Papua New Guinea   46   1504        1504           OFC\n113 113               Paraguay   48   1490        1490      CONMEBOL\n114 114                   Peru   65   1376        1376      CONMEBOL\n115 115            Philippines   67   1369        1369           AFC\n116 116                 Poland   28   1683        1677          UEFA\n117 117               Portugal   32   1659        1667          UEFA\n118 118            Puerto Rico  106   1172        1172      CONCACAF\n119 119    Republic of Ireland   31   1666        1665          UEFA\n120 120                Romania   44   1535        1542          UEFA\n121 121                 Russia   24   1708        1708          UEFA\n122 122                 Rwanda  144    899         899           CAF\n123 123                  Samoa  107   1169        1169           OFC\n124 124               Scotland   21   1804        1794          UEFA\n125 125                Senegal   87   1247        1245           CAF\n126 126                 Serbia   41   1558        1553          UEFA\n127 127              Singapore  128   1089        1089           AFC\n128 128               Slovakia   47   1501        1500          UEFA\n129 129               Slovenia   49   1471        1467          UEFA\n130 130        Solomon Islands  114   1140        1140           OFC\n131 131           South Africa   53   1434        1434           CAF\n132 132                  Spain   13   1915        1900          UEFA\n133 133              Sri Lanka  140    968         968           AFC\n134 134    St. Kitts and Nevis  131   1050        1054      CONCACAF\n135 135              St. Lucia  138    982         982      CONCACAF\n136 136               Suriname  127   1093        1093      CONCACAF\n137 137                 Sweden    5   2007        2022          UEFA\n138 138            Switzerland   20   1815        1817          UEFA\n139 139                 Tahiti  102   1196        1196           OFC\n140 140             Tajikistan  132   1035        1035           AFC\n141 141               Tanzania  139    978         978           CAF\n142 142               Thailand   39   1596        1620           AFC\n143 143                  Tonga   88   1240        1240           OFC\n144 144    Trinidad and Tobago   72   1354        1354      CONCACAF\n145 145                Tunisia   78   1304        1313           CAF\n146 146                 Turkey   69   1365        1361          UEFA\n147 147                 Uganda  146    868         868           CAF\n148 148                Ukraine   26   1692        1697          UEFA\n149 149   United Arab Emirates   97   1201        1201           AFC\n150 150                Uruguay   73   1346        1346      CONMEBOL\n151 151      US Virgin Islands  149    843         843      CONCACAF\n152 152                    USA    1   2181        2174      CONCACAF\n153 153             Uzbekistan   42   1543        1543           AFC\n154 154                Vanuatu  117   1131        1131           OFC\n155 155              Venezuela   57   1425        1425      CONMEBOL\n156 156                Vietnam   35   1657        1665           AFC\n157 157                  Wales   34   1658        1659          UEFA\n158 158                 Zambia  100   1198        1167           CAF\n159 159               Zimbabwe  111   1151        1151           CAF\n\n\n　しかし、通常はデータが読み込まれているかどうかを確認するためにデータ全体を見る必要はない。最初の数行のみで問題ないはずだ。そのために、head() 関数を使う。これは最初の6行 (n で表示行数を変える) を表示してくれる。\n\nhead(my_df1)\n\n  ID                Team Rank Points Prev_Points Confederation\n1  1             Albania   75   1325        1316          UEFA\n2  2             Algeria   85   1271        1271           CAF\n3  3      American Samoa  133   1030        1030           OFC\n4  4             Andorra  155    749         749          UEFA\n5  5              Angola  121   1117        1117           CAF\n6  6 Antigua and Barbuda  153    787         787      CONCACAF\n\n\n　同様に、最後の n行はtail() で表示する。\n\ntail(my_df1, n = 9)\n\n     ID              Team Rank Points Prev_Points Confederation\n151 151 US Virgin Islands  149    843         843      CONCACAF\n152 152               USA    1   2181        2174      CONCACAF\n153 153        Uzbekistan   42   1543        1543           AFC\n154 154           Vanuatu  117   1131        1131           OFC\n155 155         Venezuela   57   1425        1425      CONMEBOL\n156 156           Vietnam   35   1657        1665           AFC\n157 157             Wales   34   1658        1659          UEFA\n158 158            Zambia  100   1198        1167           CAF\n159 159          Zimbabwe  111   1151        1151           CAF\n\n\n　ただし、今後、特殊な事情がない限り、データの読み込みはread.csv()を使用せず、read_csv()を使用しますが、使い方は同じです。read_csv()は{tidyverse}の一部である{readr}パッケージに含まれている関数であるため、あらかじめ{tidyverse}を読み込んでおく必要があります。\n\npacman::p_load(tidyverse)\nmy_df1 &lt;- read_csv(\"Data/FIFA_Women.csv\")\n\nmy_df1\n\n# A tibble: 159 × 6\n      ID Team                 Rank Points Prev_Points Confederation\n   &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;        \n 1     1 Albania                75   1325        1316 UEFA         \n 2     2 Algeria                85   1271        1271 CAF          \n 3     3 American Samoa        133   1030        1030 OFC          \n 4     4 Andorra               155    749         749 UEFA         \n 5     5 Angola                121   1117        1117 CAF          \n 6     6 Antigua and Barbuda   153    787         787 CONCACAF     \n 7     7 Argentina              32   1659        1659 CONMEBOL     \n 8     8 Armenia               126   1103        1104 UEFA         \n 9     9 Aruba                 157    724         724 CONCACAF     \n10    10 Australia               7   1963        1963 AFC          \n# ℹ 149 more rows\n\n\n　同じファイルが読み込まれましたが、データを出力する際、最初の10行のみが表示されます。また、画面に収まらない横長のデータであれば、適宜省略し、見やすく出力してくれます。read_csv()で読み込まれた表形式データはtibbleと呼ばれるやや特殊なものとして格納されます。Rがデフォルトで提供する表形式データの構造はdata.frameですが、tibbleはその拡張版です。詳細は第10.4章を参照してください。\n\n\n8.1.2 エンコーディングの話\n　Vote_ShiftJIS.csv はShift-JIS でエンコーディングされた csvファイルである。このファイルを read.csv() 関数で読み込んでみよう。\n\nShiftJIS_df &lt;- read.csv(\"Data/Vote_ShiftJIS.csv\")\n\nError in type.convert.default(data[[i]], as.is = as.is[i], dec = dec, : invalid multibyte string at '&lt;96&gt;k&lt;8a&gt;C&lt;93&gt;&lt;b9&gt;'\n\n\n　Windowsならなんの問題なく読み込まれるだろう。しかし、macOSの場合、以下のようなエラーが表示され、読み込めない。\n## Error in type.convert.default(data[[i]], as.is = as.is[i], dec = dec, :  '&lt;96&gt;k&lt;8a&gt;C&lt;93&gt;&lt;b9&gt;' に不正なマルチバイト文字があります\n　このファイルは、read.csv()の代わりに readrパッケージのread_csv()を使えば読み込むことができる3。read_csv()で読み込み、中身を確認してみよう。\n\nShiftJIS_df1 &lt;- read_csv(\"Data/Vote_ShiftJIS.csv\")\nhead(ShiftJIS_df1)\n\n# A tibble: 6 × 11\n     ID Pref           Zaisei Over65 Under30   LDP   DPJ Komei Ishin   JCP   SDP\n  &lt;dbl&gt; &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1 \"\\x96k\\x8aC\\x…  0.419   29.1    24.7  32.8  30.6 13.4   3.43 11.4   1.68\n2     2 \"\\x90\\xc2\\x90…  0.332   30.1    23.9  40.4  24.6 12.8   3.82  8.92  3.41\n3     3 \"\\x8a\\xe2\\x8e…  0.341   30.4    24.5  34.9  22.4  8.61  5.16 11.2   5.29\n4     4 \"\\x8b{\\x8f\\xe…  0.596   25.8    27.3  36.7  25.4 13.4   3.97  9.99  3.62\n5     5 \"\\x8fH\\x93c\\x…  0.299   33.8    21.4  43.5  22.7 11.2   5.17  7.56  5.12\n6     6 \"\\x8eR\\x8c`\\x…  0.342   30.8    24.8  42.5  21.5 11.8   4.3   7.6   5.2 \n\n\n　2列目のPref列には日本語で都道府県名が入っているはずだが、謎の文字列が表示される。read.csv()の場合、少なくともWindowsでは問題なく読み込めたはずだ。なぜならread.csv()はWindowsの場合、Shift-JISで、macOSの場合UTF-8でファイルを読み込む。一方、read_csv()はOSと関係なく世界標準であるUTF-8でファイルを読み込むからだ。\n　正しい都道府県名を表示する方法はいくつかあるが、ここでは3つの方法を紹介する。\n1. read.csv()関数のfileEncoing引数の指定\n　一つ目の方法は、read.csv()関数の fileEncoding 引数を追加するというものだる。この引数に、指定したファイルのエンコーディングを指定すればよいが、Shift-JISの場合、\"Shift_JIS\"　を指定する。ハイフン (-)ではなく、アンダーバー (_) であることに注意されたい。この\"Shift_JIS\"は\"cp932\" に書き換えても良い。それではやってみよう。\n\nShiftJIS_df2 &lt;- read.csv(\"Data/Vote_ShiftJIS.csv\", \n                         fileEncoding = \"Shift_JIS\")\nhead(ShiftJIS_df2)\n\n  ID   Pref  Zaisei Over65 Under30   LDP   DPJ Komei Ishin   JCP  SDP\n1  1 北海道 0.41903  29.09   24.70 32.82 30.62 13.41  3.43 11.44 1.68\n2  2 青森県 0.33190  30.14   23.92 40.44 24.61 12.76  3.82  8.92 3.41\n3  3 岩手県 0.34116  30.38   24.48 34.90 22.44  8.61  5.16 11.24 5.29\n4  4 宮城県 0.59597  25.75   27.29 36.68 25.40 13.42  3.97  9.99 3.62\n5  5 秋田県 0.29862  33.84   21.35 43.46 22.72 11.19  5.17  7.56 5.12\n6  6 山形県 0.34237  30.76   24.75 42.49 21.47 11.78  4.30  7.60 5.20\n\n\n　Pref列の日本語が正常に表示された。むろん、WindowsならfileEncoding引数がなくても読み込める。むしろ、UTF-8で書かれたファイルが読み込めない可能性がある。この場合はfileEncoding = \"UTF-8\"を指定すれば良い。\n2. read_csv()関数のlocale引数の指定\n　二つ目の方法は read_csv() 関数のlocale 引数を指定する方法である。read_csv()には　fileEncoding　引数がないが、代わりに locale があるので、locale = locale(encoding = \"Shift_JIS\")を追加すれば良い。\n\nShiftJIS_df3 &lt;- read_csv(\"Data/Vote_ShiftJIS.csv\", \n                         locale = locale(encoding = \"Shift_JIS\"))\nhead(ShiftJIS_df3)\n\n# A tibble: 6 × 11\n     ID Pref   Zaisei Over65 Under30   LDP   DPJ Komei Ishin   JCP   SDP\n  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1 北海道  0.419   29.1    24.7  32.8  30.6 13.4   3.43 11.4   1.68\n2     2 青森県  0.332   30.1    23.9  40.4  24.6 12.8   3.82  8.92  3.41\n3     3 岩手県  0.341   30.4    24.5  34.9  22.4  8.61  5.16 11.2   5.29\n4     4 宮城県  0.596   25.8    27.3  36.7  25.4 13.4   3.97  9.99  3.62\n5     5 秋田県  0.299   33.8    21.4  43.5  22.7 11.2   5.17  7.56  5.12\n6     6 山形県  0.342   30.8    24.8  42.5  21.5 11.8   4.3   7.6   5.2 \n\n\n3. LibreOfficeなどを利用した方法\n　第三の方法は、そもそも Shift-JISでではなく、より一般的な UTF-8 でエンコーディングされたファイルを用意し、それを読み込むことである。ただし、この作業のためにはR以外のソフトが必要である。テキストエディタには文字コードを変更する機能がついているものが多いので、その機能を利用して文字コードを Shift-JISからUTF-8に変えれば良い。また、オープンソースのオフィススイートである LibreOffice は、CSVを開く際に文字コードを尋ねてくれるので、Shift-JIS を指定して上で使った csv ファイルを開こう。その後、文字コードをUTF-8に変更し、別名でcsvファイルを保存すれ、文字コード以外の中身が同じファイルができる。そのようにして作ったのが、Vote.csv である。これを読み込んでみよう。\n\nUTF8_df &lt;- read.csv(\"Data/Vote.csv\") # macOSの場合\nUTF8_df &lt;- read.csv(\"Data/Vote.csv\", fileEncoding = \"UTF-8\") # Windowsの場合\n\n\nhead(UTF8_df)\n\n  ID   Pref  Zaisei Over65 Under30   LDP   DPJ Komei Ishin   JCP  SDP\n1  1 北海道 0.41903  29.09   24.70 32.82 30.62 13.41  3.43 11.44 1.68\n2  2 青森県 0.33190  30.14   23.92 40.44 24.61 12.76  3.82  8.92 3.41\n3  3 岩手県 0.34116  30.38   24.48 34.90 22.44  8.61  5.16 11.24 5.29\n4  4 宮城県 0.59597  25.75   27.29 36.68 25.40 13.42  3.97  9.99 3.62\n5  5 秋田県 0.29862  33.84   21.35 43.46 22.72 11.19  5.17  7.56 5.12\n6  6 山形県 0.34237  30.76   24.75 42.49 21.47 11.78  4.30  7.60 5.20\n\n\n　第1引数以外の引数を何を指定しなくても、ファイルが正しく読み込まれ、都道府県名が日本語で表示されている。ただし、Windowsで文字化けが生じる場合はファイルのエンコーディングをUTF-8に指定して読み込もう。\n\n\n8.1.3 その他のフォーマット\n　データ分析で用いられるデータの多くは表の形で保存されている。表形式のデータは、.csv以外に、.xlsx (Excel)、.dta (Stata)、.sav (SPSS)、.ods (LibreOfficeなど)　などのファイル形式で保存されることがある。ここでは接する機会が多い Excel 形式のファイルと Stata 形式のファイルの読み込みについて説明しよう4。\n　Excelファイルを読み込むためにはreadxlパッケージを使う。インストールされていない場合、コンソール上でinstall.packages(\"readxl\")を入力し、インストールする（上で pacman::p_load(readxl) を実行したのでインストールされているはずだが）。以下ではreadxlパッケージがインストールされていると想定し、Soccer.xlsxファイルを読み込み、Excel_DFと名付けてみよう。\n\nExcel_DF &lt;- read_xlsx(\"Data/Soccer.xlsx\", sheet = 1)\n\n　Excelファイルには2つ以上のシートが含まれる場合が多いので、どのシートを読み込むかをsheetIndex で指定する。実際、Soccer.xlsxファイルをExcelまたはLibreOffice Calc で開いてみると、シートが3つある。そのうち、必要なデータは1つ目のシートにあるので、ここでは1を指定した。きちんと読み込たか確認してみよう。\n\nhead(Excel_DF)\n\n# A tibble: 6 × 6\n     ID Team                 Rank Points Prev_Points Confederation\n  &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;        \n1     1 Albania                75   1325        1316 UEFA         \n2     2 Algeria                85   1271        1271 CAF          \n3     3 American Samoa        133   1030        1030 OFC          \n4     4 Andorra               155    749         749 UEFA         \n5     5 Angola                121   1117        1117 CAF          \n6     6 Antigua and Barbuda   153    787         787 CONCACAF     \n\n\n　Stataの.dtaファイルはhavenパッケージのread_dta() 関数を使って読み込む。Stata形式で保存された Soccer.dta を読み込み、Stata_DFと名付けてみよう。\n\nStata_DF &lt;- read_dta(\"Data/Soccer.dta\")\nhead(Stata_DF)\n\n# A tibble: 6 × 6\n     id team                 rank points prev_points confederation\n  &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;        \n1     1 Albania                75   1325        1316 UEFA         \n2     2 Algeria                85   1271        1271 CAF          \n3     3 American Samoa        133   1030        1030 OFC          \n4     4 Andorra               155    749         749 UEFA         \n5     5 Angola                121   1117        1117 CAF          \n6     6 Antigua and Barbuda   153    787         787 CONCACAF     \n\n\nExcel形式のデータと同じ内容のデータであること確認できる（ただし、変数名は少し異なる）。\n　実際の社会科学の場合、入手するデータの多くは.csv、.xlsx (または.xls)、.dtaであるため、以上のやり方で多くのデータの読み込みができる。\n\n\n8.1.4 RDataファイルの場合\n　データ分析には表形式以外のデータも使われる。データ分析でよく使われるデータの形として、ベクトルや行列のほかにlist型とがある。表形式だけでなく、Rで扱える様々なデータを含むファイル形式の1つが.RDataフォーマットである。.RDataにはRが扱える形式のデータを格納するだけでなく、表形式のデータを複数格納することができる。また、データだけでなく、分析結果も保存することができる。.RData形式のファイルはRでしか読み込めないため、データの保存方法としては推奨できないが、1つのファイルにさまざまなデータが格納できるという大きな長所があるため、分析の途中経過を保存するためにしばしば利用される。\n　ここではDataフォルダにあるScores.RDataを読み込んでみよう。このファイルには学生5人の数学と英語の成績に関するデータがそれぞれMathScoreとEnglishScoreという名で保存されている。このデータを読み込む前に、現在の実行環境にどのようなオブジェクトがあるかを ls() 関数を使って確認してみよう5。\n\nls()\n\n[1] \"Excel_DF\"        \"has_annotations\" \"my_df1\"          \"ShiftJIS_df1\"   \n[5] \"ShiftJIS_df2\"    \"ShiftJIS_df3\"    \"Stata_DF\"        \"UTF8_df\"        \n\n\n　現在の実行環境に8個のオブジェクトがあることがわかる。\n　では、Scores.RDataを読み込んでみよう。.RData は、load() 関数で読み込む。ただし、これまでのファイルの読み込みとは異なり、保存先のオブジェクト名は指定しない。なぜなら、.Rdata の中に既にオブジェクトが保存されているからだ。\n\nload(\"Data/Scores.RData\")\n\n　ここでもう一度実行環境上にあるオブジェクトのリストを確認してみよう。\n\nls()\n\n [1] \"EnglishScore\"    \"Excel_DF\"        \"has_annotations\" \"MathScore\"      \n [5] \"my_df1\"          \"ShiftJIS_df1\"    \"ShiftJIS_df2\"    \"ShiftJIS_df3\"   \n [9] \"Stata_DF\"        \"UTF8_df\"        \n\n\n　MathScoreとEnglishScoreという名前のオブジェクトが追加されていることが分かる。\n　このように、load()による.RData の読み込みは、.csvファイルや.xlsxファイルの読み込みと異なる。以下の2点が重要な違いである。\n\n.RData は、1つのファイルに複数のデータを含むことができる。\n.RDataの中にRのオブジェクトが保存されているので、ファイルの読み込みと同時に名前を付けて格納する必要がない。\n\n　問題なく読み込まれているか確認するため、それぞれのオブジェクトの中身を見てみよう。\n\nMathScore # MathScoreの中身を出力\n\n  ID    Name Score\n1  1 Caracal   100\n2  2 Cheetah    37\n3  3  Jaguar    55\n4  4 Leopard    69\n5  5  Serval    95\n\nEnglishScore # EnglishScoreの中身を出力\n\n  ID    Name Score\n1  1 Caracal    90\n2  2 Cheetah    21\n3  3  Jaguar    80\n4  4 Leopard    45\n5  5  Serval    99"
  },
  {
    "objectID": "io.html#sec-io-export",
    "href": "io.html#sec-io-export",
    "title": "8  データの入出力",
    "section": "8.2 データの書き出し",
    "text": "8.2 データの書き出し\n　データを手に入れた時点でそのデータ（生データ）が分析に適した状態であることは稀である。多くの場合、分析をするためには手に入れたデータを分析に適した形に整形する必要がある。この作業を「データクリーニング」と呼ぶが、データ分析の作業全体に占めるデータクリーニングの割合は5から7割ほどで、大部分の作業時をクリーニングに費やすことになる。（クリーニングの方法については、データハンドリングの章で説明する。）\n　データクリーニングが終わったら、生データとクリーニングに使ったコード、クリーニング済みのデータをそれぞれ保存しておこう。クリーニングのコードさえあればいつでも生データからクリーニング済みのデータに変換することができるが、時間的にあまり効率的ではないので、クリーニング済みのデータも保存したほうが良い。そうすれば、いつでもそのデータを読み込んですぐに分析作業に取り組無ことができる6。\n\n8.2.1 csvファイル\n　データを保存する際にまず考えるべきフォーマットは.csv である。データが表の形をしていない場合には次節で紹介する.RDataフォーマットが必要になるが、多くの場合、データは表の形をしている。読み込みのところで説明したとおり、.csvファイルは汎用的なテキストファイルであり、ほとんどの統計ソフトおよび表計算ソフトで読み込むことができるので、特にこだわりがなければ業界標準のフォーマットとも言える csv 形式でデータ保存しておくのが安全だ7。\n　まずは、架空のデータを作ってみよう。Rにおける表形式のデータは data.frame型で表現する。（詳細については第10章で説明する。）\n\nmy_data &lt;- data.frame(\n    ID    = 1:5,\n    Name  = c(\"Aさん\", \"Bさん\", \"Cさん\", \"Dさん\", \"Eさん\"),\n    Score = c(50, 75, 60, 93, 51)\n)\n\n　上のコードを実行すると、my_dataというオブジェクトが生成され、中には以下のようなデータが保持される。\n\nmy_data\n\n  ID  Name Score\n1  1 Aさん    50\n2  2 Bさん    75\n3  3 Cさん    60\n4  4 Dさん    93\n5  5 Eさん    51\n\n\n　このデータをmy_data.csvという名前のcsvファイルで保存するには、write.csv()という関数を使う。必須の引数は2つで、1つ目の引数は保存するオブジェクト名、2つ目の引数 file は書き出すファイル名。もし、プロジェクトフォルダの下位フォルダ、たとえば、Dataフォルダーに保存するなら、ファイル名を\"Data/my_ata.csv\"のように指定する。他によく使う引数としてrow.namesがあり、デフォルトはTRUEだが、FALSEにすることを推奨する。TRUEのままだと、データの1列目に行番号が保存される。\n\nwrite.csv(my_data, file = \"Data/my_data.csv\", row.names = FALSE)\n\n　これを実行すると、プロジェクトのフォルダの中にある Data フォルダにmy_data.csvが生成される。LibreOfficeやNumbers、Excelなどを使ってmy_data.csvを開いてみると、先ほど作成したデータが保存されていることが確認できる。\n\n\n\n\n\n図 8.1: 保存したcsvファイルの中身\n\n\n\n\n\n\n8.2.2 RDataファイル\n最後に.RData形式でデータを書き出してみよう。今回は先ほど作成したmy_dataと、以下で作成するnumeric_vec1、numeric_vec2、character_vecをmy_RData.RDataという名のファイルとして Dataフォルダに書き出す。使用する関数は save() である。引数として保存するオブジェクト名をすべてカンマ区切りで書き、最後にfile　引数でファイル名を指定すればよい。\n\nnumeric_vec1  &lt;- c(1, 5, 3, 6, 99, 2, 8)\nnumeric_vec2  &lt;- 1:20\ncharacter_vec &lt;- c('cat', 'cheetah', 'lion',　'tiger')\nsave(my_data, numeric_vec1, numeric_vec2, character_vec, \n     file = \"Data/my_RData.RData\")\n\n　実際にmy_RData.Rdataファイルが生成されているかを確認してみよう。ファイルの保存がうまくいっていれば、my_RData.Rdataを読み込むだけで、my_data、numeric_vec1、numeric_vec2、character_vec という4つのオブジェクトを一挙に作業スペースに読み込むことができるはずだ。実際にできるか確認しよう。そのために、まず現在の実行環境上にあるmy_ata、numeric_vec1、numeric_vec2、character_vecを削除する。そのために rm() 関数を使う。\n\nrm(my_data)\nrm(numeric_vec1)\nrm(numeric_vec2)\nrm(character_vec)\n\n　このコードは以下のように1行のコードに書き換えられる。\n\nrm(list = c(\"my_data\", \"numeric_vec1\", \"numeric_vec2\", \"character_vec\"))\n\n　4のオブジェクトが削除されたか、ls()関数で確認しよう。\n\nls()\n\n [1] \"EnglishScore\"    \"Excel_DF\"        \"has_annotations\" \"MathScore\"      \n [5] \"my_df1\"          \"ShiftJIS_df1\"    \"ShiftJIS_df2\"    \"ShiftJIS_df3\"   \n [9] \"Stata_DF\"        \"UTF8_df\"        \n\n\nそれではDataフォルダー内のmy_RData.RDataを読み込み、4つのオブジェクトが実行環境に読み込まれるか確認しよう。\n\nload(\"Data/my_RData.RData\") # Dataフォルダー内のmy_RData.RDataを読み込む\nls()                        # 作業スペース上のオブジェクトのリストを確認する\n\n [1] \"character_vec\"   \"EnglishScore\"    \"Excel_DF\"        \"has_annotations\"\n [5] \"MathScore\"       \"my_data\"         \"my_df1\"          \"numeric_vec1\"   \n [9] \"numeric_vec2\"    \"ShiftJIS_df1\"    \"ShiftJIS_df2\"    \"ShiftJIS_df3\"   \n[13] \"Stata_DF\"        \"UTF8_df\""
  },
  {
    "objectID": "datatype.html#sec-type-intro",
    "href": "datatype.html#sec-type-intro",
    "title": "9  データ型",
    "section": "9.1 データ型とは",
    "text": "9.1 データ型とは\nここではRにおけるデータ型について説明します。第10章で説明するデータ「構造」とデータ「型」は異なる概念です。次章でも説明しますが、Rにおけるデータの最小単位はベクトルです。c(1, 2, 3, 4, 5)やc(\"Yanai\", \"Song\", \"Hadley\")もベクトルですが、30とか\"R\"もベクトルです。後者のように要素が1つのベクトルは原子ベクトル (atomic vector)とも呼ばれますが、本質的には普通ベクトルです。このベクトルの要素の性質がデータ型です。たとえばc(2, 3, 5, 7, 11)は数値型ですし、c(\"R\", \"Python\", \"Julia\")は文字型です。他にも第7章で紹介したFALSEやTRUEは論理型と呼ばれています。一つのベクトルは複数の要素で構成されることも可能ですが、必ず同じデータ型である必要があります。\nしかし、データ分析を行う際はベクトル以外のデータも多いです。行列や表がその典型例です。しかし、行列でも表でも中身の一つ一つの要素は長さ1のベクトルに過ぎません。たとえば、以下のような2行5列のベクトルがあるとします。ここで1行3列目の要素は11であり、長さ1の数値型ベクトルです。あるいは5列目はc(23, 29)であり、長さ2の数値型ベクトルです。\n\n\n     [,1] [,2] [,3] [,4] [,5]\n[1,]    2    5   11   17   23\n[2,]    3    7   13   19   29\n\n\n表についても考えてみましょう。以下の表の3行2列目の要素は\"American Samoa\"という長さ1の文字型ベクトルです。また、6列目はc(\"UEFA\", \"CAF\", \"OFC\", \"UEFA\", \"CAF\", \"CONCACAF\")であり、これは長さ6の文字型ベクトルです。このようにRで扱う全てのデータは複数のベクトルが集まっているものです。\n\n\n  ID                Team Rank Points Prev_Points Confederation\n1  1             Albania   75   1325        1316          UEFA\n2  2             Algeria   85   1271        1271           CAF\n3  3      American Samoa  133   1030        1030           OFC\n4  4             Andorra  155    749         749          UEFA\n5  5              Angola  121   1117        1117           CAF\n6  6 Antigua and Barbuda  153    787         787      CONCACAF\n\n\nつまり、複数のベクトルを綺麗に、または分析しやすく集めたのが行列や表であり、これがデータ構造に該当します。データ型ごとの処理方法については本書を通じて紹介して行きますので、本章は軽く読んで頂いても構いません。ただし、Factor型とDate & Datetime型の処理はやや特殊ですので、手を動かしながら読み進めることをおすすめします。\nここではデータ型について紹介し、次章ではデータ構造について解説します。"
  },
  {
    "objectID": "datatype.html#sec-type-logical",
    "href": "datatype.html#sec-type-logical",
    "title": "9  データ型",
    "section": "9.2 Logical",
    "text": "9.2 Logical\nLogical型はTRUEとFALSEのみで構成されたデータ型です。練習としてなにかの長さ5の論理型ベクトルを作ってみましょう。\n\nlogical_vec1 &lt;- c(TRUE, FALSE, TRUE, TRUE, FALSE)\n\nlogical_vec1\n\n[1]  TRUE FALSE  TRUE  TRUE FALSE\n\n\n注意すべきこととしては、TRUEとFALSEは\"で囲まないことです。\"TRUE\"、\"FALSE\"と入力してしまえばlogical 型として認識されません。もし、一つ間違えて2番目の要素であるFALSEを\"FALSE\"と入力したらどうなるでしょうか。\n\nlogical_vec2 &lt;- c(TRUE, \"FALSE\", TRUE, TRUE, FALSE)\n\nlogical_vec2\n\n[1] \"TRUE\"  \"FALSE\" \"TRUE\"  \"TRUE\"  \"FALSE\"\n\n\n2番目の要素だけでなく、他の全ての要素も\"で囲まれるようになりました。実際に、この2つのベクトルのデータ型を確認してみましょう。ベクトルのデータ型を確認する関数はclass()関数です。\n\nclass(logical_vec1)\n\n[1] \"logical\"\n\nclass(logical_vec2)\n\n[1] \"character\"\n\n\nlogical_vec1はlogical型ですが、logical_vec2はcharacter型と認識されます。\n他にも、is.logical()関数を使ってあるベクトルがlogical型か否かを判定することも可能です。もし、ベクトルがlogical型ならTRUEが、logical型以外ならFALSEが返って来ます。\n\nis.logical(logical_vec1)\n\n[1] TRUE\n\nis.logical(logical_vec2)\n\n[1] FALSE\n\n\nLogical型は様々な場面で使われますが、代表的な使い方は第7.1章で紹介しました要素の抽出と第11章で紹介する予定の条件分岐 (if()やifelse())、条件反復 (while())があります。"
  },
  {
    "objectID": "datatype.html#sec-type-numeric",
    "href": "datatype.html#sec-type-numeric",
    "title": "9  データ型",
    "section": "9.3 Numeric",
    "text": "9.3 Numeric\nNumeric型は数値型ですが、まずはnumeric型のベクトルnumeric_vec1を作成し、データ型を確認してみましょう。\n\nnumeric_vec1 &lt;- c(2, 0, 0, 1, 3)\n\nclass(numeric_vec1)\n\n[1] \"numeric\"\n\n\nis.logical()に似た関数is.numeric()も使用可能です。\n\nis.numeric(numeric_vec1)\n\n[1] TRUE\n\nis.numeric(logical_vec1)\n\n[1] FALSE\n\n\nもうちょっと詳しく分けるとinteger型とdouble型があります。以下の内容はあまり意識的に区分して使う場面が稀ですので、(読み)飛ばしても構いません。\nintegerは整数型であり、doubleは実数型です。これはclass()関数では確認できず、typeof()関すを使います。\n\ntypeof(numeric_vec1)\n\n[1] \"double\"\n\n\n一般的に作成するnumeric型のベクトルは全てdouble型です。もし、整数型のベクトルを作成したい場合、数値の後ろにLを付けます。\n\ninteger_vec1 &lt;- c(2L, 0L, 0L, 1L, 3L)\ntypeof(integer_vec1)\n\n[1] \"integer\"\n\n\nここでも注意すべき点としては、一つでもLが付かない要素が含まれる場合、自動的にdouble型に変換されるという点です。\n\ninteger_vec2 &lt;- c(2L, 0L, 0, 1L, 3L)\ntypeof(integer_vec2)\n\n[1] \"double\"\n\n\nもちろんですが、小数点のある数値にLを付けてもinteger型にはならず、勝手にdouble型になります。また、integer型同士の割り算の結果もdouble型になります。これは2L/1Lのような場合でも同じです。足し算、引き算、掛け算はinteger型になります。\n\ntypeof(2.3L)\n\n[1] \"double\"\n\ntypeof(3L / 12L)\n\n[1] \"double\"\n\ntypeof(3L / 1L)\n\n[1] \"double\"\n\ntypeof(3L + 1L)\n\n[1] \"integer\"\n\ntypeof(3L - 4L)\n\n[1] \"integer\"\n\ntypeof(3L * 6L)\n\n[1] \"integer\"\n\n\n一般的な分析において整数と実数を厳格に区別して使う場面は多くないと考えられますので、今のところはあまり気にしなくても問題ないでしょう。"
  },
  {
    "objectID": "datatype.html#sec-type-complex",
    "href": "datatype.html#sec-type-complex",
    "title": "9  データ型",
    "section": "9.4 Complex",
    "text": "9.4 Complex\nComplex型は複素数を表すデータ型であり、実数部+虚数部iのように表記します。まず、複素数のベクトルcomplex_vec1を作成し、データ型を確認してみましょう。\n\ncomplex_vec1 &lt;- c(1+3i, 3+2i, 2.5+7i)\ncomplex_vec1\n\n[1] 1.0+3i 3.0+2i 2.5+7i\n\nclass(complex_vec1)\n\n[1] \"complex\"\n\n\nあまりおすすめはできませんが、虚数部i+実数部のような書き方も可能です。\n\ncomplex_vec2 &lt;- c(3i+1, 2i+3, 7i+2.5)\ncomplex_vec2\n\n[1] 1.0+3i 3.0+2i 2.5+7i\n\nclass(complex_vec2)\n\n[1] \"complex\"\n\n\ncomplex_vec1とcomplex_vec2は同じベクトルであることを確認してみましょう。\n\ncomplex_vec1 == complex_vec2\n\n[1] TRUE TRUE TRUE\n\n\nもし、ベクトル内にnumeric型とcomplex型が混在している場合、強制的にcomplex型に変換されます。変換された後の値は実数部+0iのようになります。\n\ncomplex_vec3 &lt;- c(2+7i, 5, 13+1i)\ncomplex_vec3\n\n[1]  2+7i  5+0i 13+1i\n\nclass(complex_vec3)\n\n[1] \"complex\""
  },
  {
    "objectID": "datatype.html#sec-type-character",
    "href": "datatype.html#sec-type-character",
    "title": "9  データ型",
    "section": "9.5 Character",
    "text": "9.5 Character\nCharacter型は文字列で構成されているデータ型です。Rを含む多くの言語は文字列を表現するために、中身を\"で囲みます。\"abc\"はcharacter型ですが、\"1\"や\"3+5i\"もcharacter型です。数字であっても\"で囲んだらそれは文字列となります。それではいくつかのcharacter型ベクトルを作っていみましょう。\n\nchar_vec1 &lt;- c(\"Yanai\", \"Song\", \"Shigemura\", \"Tani\")\nchar_vec2 &lt;- c(1, 2, 3, 4)\nchar_vec3 &lt;- c(\"1\", \"2\", \"3\", \"4\")\n\nchar_vec1\n\n[1] \"Yanai\"     \"Song\"      \"Shigemura\" \"Tani\"     \n\nchar_vec2\n\n[1] 1 2 3 4\n\nchar_vec3\n\n[1] \"1\" \"2\" \"3\" \"4\"\n\n\nchar_vec2とchar_vec3の違いは通じを\"で囲んだか否かです。ベクトルの中身を見ても、char_vec2は\"で囲まれていません。データ型を見てみましょう。\n\nclass(char_vec1)\n\n[1] \"character\"\n\nclass(char_vec2)\n\n[1] \"numeric\"\n\nclass(char_vec3)\n\n[1] \"character\"\n\n\nやはりchar_vec3もcharacter型になっていることが分かります。"
  },
  {
    "objectID": "datatype.html#sec-type-factor",
    "href": "datatype.html#sec-type-factor",
    "title": "9  データ型",
    "section": "9.6 Factor",
    "text": "9.6 Factor\nFactor型はラベル付きの数値型データです。Factor型の見た目はcharacter型とほぼ同じですし、分析の場面においてもcharacter型とほぼ同じ扱いになります。Factor型とcharacter型との違いは、「順序が付いている」点です。例えば、以下の質問文に対するアンケートの結果を考えてみましょう。\n\nあなたは猫がすきですか。\n\nめちゃめちゃ好き\nめちゃ好き\n好き\nどちらかといえば好き\n\n\n以下の 表 9.1 は5人の結果です。\n\n\n\n\n表 9.1: 猫好きの度合い\n\n\nID\nName\nCat\n\n\n\n\n1\nYanai\nめちゃめちゃ好き\n\n\n2\nSong\nめちゃめちゃ好き\n\n\n3\nShigemura\nどちらかといえば好き\n\n\n4\nTani\nめちゃ好き\n\n\n5\nHadley\n好き\n\n\n\n\n\n\n\n\n人間としてはこの表から、重村という人がどれだけ猫が嫌いなのかが分かります。ただし、Rはそうではありません。Rは日本語どころか、人間の言葉は理解できません。各項目ごとに順番を付けてあげる必要がありますが、そのために使われるのがfactor型です。\n実習のために 表 9.1 のCat列のみのベクトルを作ってみましょう。\n\nfactor_vec1 &lt;- c(\"めちゃめちゃ好き\", \"めちゃめちゃ好き\", \n                 \"どちらかといえば好き\", \"めちゃ好き\", \"好き\")\n\nfactor_vec1\n\n[1] \"めちゃめちゃ好き\"     \"めちゃめちゃ好き\"     \"どちらかといえば好き\"\n[4] \"めちゃ好き\"           \"好き\"                \n\nclass(factor_vec1)\n\n[1] \"character\"\n\n\nfactor_vec1は普通の文字列ベクトルであることが分かります。これをfactor型に変換するためにはfactor()関数を使います。\n\nfactor_vec2 &lt;- factor(factor_vec1, ordered = TRUE,\n                      levels = c(\"どちらかといえば好き\", \"好き\",\n                                 \"めちゃ好き\", \"めちゃめちゃ好き\"))\nclass(factor_vec2)\n\n[1] \"ordered\" \"factor\" \n\n\nデータ型がfactor型に変換されています。\"ordered\"というものも付いていますが、これについては後ほど説明します。それでは中身をみましょう。\n\nfactor_vec2\n\n[1] めちゃめちゃ好き     めちゃめちゃ好き     どちらかといえば好き\n[4] めちゃ好き           好き                \nLevels: どちらかといえば好き &lt; 好き &lt; めちゃ好き &lt; めちゃめちゃ好き\n\n\nいくつかの点で異なります。まず、文字列であるにもかかわらず、\"で囲まれていいない点です。そして3行目に4 Levels:というのが追加されている点です。このlevelは「水準」と呼ばれるものです。4 Levelsですから、factor_vec2は4つの水準で構成されていることを意味します。Factor型の値は予め指定された水準以外の値を取ることはできません。たとえば、2番目の要素を「超好き」に変えてみましょう。\n\nfactor_vec2[2] &lt;- \"超好き\"\n\nWarning in `[&lt;-.factor`(`*tmp*`, 2, value = \"超好き\"): invalid factor level, NA\ngenerated\n\nfactor_vec2\n\n[1] めちゃめちゃ好き     &lt;NA&gt;                 どちらかといえば好き\n[4] めちゃ好き           好き                \nLevels: どちらかといえば好き &lt; 好き &lt; めちゃ好き &lt; めちゃめちゃ好き\n\n\n警告が表示され、2番目の要素が後ほど紹介する欠損値となっていることが分かります。それでは普通に「好き」を入れてみましょう。\n\nfactor_vec2[2] &lt;- \"好き\"\nfactor_vec2\n\n[1] めちゃめちゃ好き     好き                 どちらかといえば好き\n[4] めちゃ好き           好き                \nLevels: どちらかといえば好き &lt; 好き &lt; めちゃ好き &lt; めちゃめちゃ好き\n\n\n今回は問題なく置換できましたね。このようにfactor型の取りうる値は既に指定されています。また、## 4 Levels: どちらかといえば好き &lt; 好き &lt; ... &lt; めちゃめちゃ好きからも分かるように、その大小関係の情報も含まれています。猫好きの度合いは「どちらかといえば好き-好き-めちゃ好き-めちゃめちゃ好き」の順で高くなることをRも認識できるようになりました。\nFactor型はこのように順序付きデータを扱う際に便利なデータ型ですが、順序情報を含まないfactor型もあります。これはfactor()を使う際、ordered = TRUE引数を削除するだけでできます。\n\nfactor_vec3 &lt;- factor(factor_vec1,\n                      levels = c(\"どちらかといえば好き\", \"好き\",\n                                 \"めちゃ好き\", \"めちゃめちゃ好き\"))\nfactor_vec3\n\n[1] めちゃめちゃ好き     めちゃめちゃ好き     どちらかといえば好き\n[4] めちゃ好き           好き                \nLevels: どちらかといえば好き 好き めちゃ好き めちゃめちゃ好き\n\nclass(factor_vec3)\n\n[1] \"factor\"\n\n\n今回は3行目が## Levels: どちらかといえば好き 好き めちゃ好き めちゃめちゃ好きとなり、順序に関する情報がなくなりました。また、class()で確認しましたデータ型に\"ordered\"が付いていません。これは順序なしfactor型であることを意味します。「順序付けしないならfactor型は要らないのでは…?」と思うかも知れませんが、これはこれで便利です。その例を考えてみましょう。\n分析においてfactor型はcharacter型に近い役割を果たしますが、factor型なりの長所もあります。それは図や表を作成する際です。例えば、横軸が都道府県名で、縦軸がその都道府県の財政力指数を表す棒グラフを作成するとします。たとえば、 表 9.2 のようなデータがあるとします。このデータは3つの列で構成されており、IDとZaisei列はnumeric型、Pref列はcharacter型です。\n\n\n\n\n表 9.2: 5都道府県のH29財政力指数\n\n\nID\n都道府県\n財政力指数\n\n\n\n\n1\nHokkaido\n0.44396\n\n\n2\nTokyo\n1.19157\n\n\n3\nAichi\n0.92840\n\n\n4\nOsaka\n0.78683\n\n\n5\nFukuoka\n0.64322\n\n\n\n\n\n\n\n\n可視化については第18章以降で詳しく解説しますが、このPref列をcharacter型にしたままグラフにしますと 図 9.1 のようになります。\n\n\n\n\n\n図 9.1: 5都道府県のH29財政力指数\n\n\n\n\nこのようにアルファベット順で横軸が並び替えられます。別にこれでも問題ないと思う方もいるかも知れませんが、基本的に日本の都道府県は北から南の方へ並べるのが一般的な作法です1。北海道と東京、大阪の間には順序関係はありません。しかし、表示される順番は固定したい。この場合、Pref列を順序なしfactor型にすれば良いです2。データフレームの列を修正する方法は第10章で詳しく説明します。\n\nzaisei_df$Pref &lt;- factor(zaisei_df$Pref,\n                         levels = c(\"Hokkaido\", \"Tokyo\", \"Aichi\", \"Osaka\", \"Fukuoka\"))\n\nzaisei_dfのPref列をfactor型にしてから同じ図を描くと 図 9.2 のようになります。\n\n\n\n\n\n図 9.2: 5都道府県のH29財政力指数\n\n\n\n\n都道府県以外にもこのような例は多くあります。順序尺度で測定された変数が代表的な例です。他にも政党名を議席数順で表示させたい場合もfactor型は有効でしょう。"
  },
  {
    "objectID": "datatype.html#sec-type-date",
    "href": "datatype.html#sec-type-date",
    "title": "9  データ型",
    "section": "9.7 Date",
    "text": "9.7 Date\n\n9.7.1 なぜDate型があるのか\nDate型は年月日を表すデータ型3です。この2つのデータ型はかなり複雑ですが、ここでは簡単に説明します。Date型は日付の情報を含むため、順序関係が成立します。その意味では順序付きFactor型とあまり挙動は変わらないかもしれませんが、実際はそうではありません。\nたとえば、Songの1週間4の睡眠時間を記録したデータSongSleepがあるとします。Dateという列には日付が、Sleep列には睡眠時間が記録されています。睡眠時間の単位は「分」です。\n\nSongSleep &lt;- data.frame(\n    Date  = c(\"2017-06-17\", \"2017-06-18\", \"2017-06-19\", \"2017-06-20\", \n              \"2017-06-21\", \"2017-06-22\", \"2017-06-23\"),\n    Sleep = c(173, 192, 314, 259, 210, 214, 290)   \n)\n\n中身をみると、以下のようになります。\n\nSongSleep\n\n        Date Sleep\n1 2017-06-17   173\n2 2017-06-18   192\n3 2017-06-19   314\n4 2017-06-20   259\n5 2017-06-21   210\n6 2017-06-22   214\n7 2017-06-23   290\n\n\n日付を横軸に、睡眠時間を縦軸にした散布図を描く 図 9.3 のようになります。{ggplot2}を利用した作図については第18章で解説しますので、ここではDate型の特徴のみ理解してもらえたら十分です。\n\nggplot(SongSleep, \n       mapping = aes(x = Date, y = Sleep)) +\n    geom_point() +\n    labs(x = \"日付\", y = \"睡眠時間 (分)\") +\n    theme_gray(base_size = 12)\n\n\n\n\n図 9.3: Songの睡眠時間\n\n\n\n\nこの図は全く問題ないように見えます。それでは、Date列をそれぞれDate型に変換し、SoongSleepデータのDateDとしてみます。データフレームの列追加については第10.4章で解説します。\n\nSongSleep$DateD &lt;- as.Date(SongSleep$Date)\n\n中身を見てみますが、あまり変わっていないようです。DateとDateD列は全く同じように見えますね。\n\nSongSleep\n\n        Date Sleep      DateD\n1 2017-06-17   173 2017-06-17\n2 2017-06-18   192 2017-06-18\n3 2017-06-19   314 2017-06-19\n4 2017-06-20   259 2017-06-20\n5 2017-06-21   210 2017-06-21\n6 2017-06-22   214 2017-06-22\n7 2017-06-23   290 2017-06-23\n\n\n図にすると実は先ほどの図と同じものが得られます。\n\nggplot(SongSleep, \n       mapping = aes(x = DateD, y = Sleep)) +\n    geom_point() +\n    labs(x = \"日付\", y = \"睡眠時間 (分)\") +\n    theme_gray(base_size = 12)\n\n\n\n\nSongの睡眠時間\n\n\n\n\nしかし、Songがうっかり6月19日に記録するのを忘れたとします。つまり、SongSleepデータの3行目が抜けている状況を考えてみましょう。データフレームの要素抽出については第10.4章で解説します。\n\nSongSleep2 &lt;- SongSleep[-3, ]\n\n中身をみると、以下のようになります。DateもDateDも同じように見えます。\n\nSongSleep2\n\n        Date Sleep      DateD\n1 2017-06-17   173 2017-06-17\n2 2017-06-18   192 2017-06-18\n4 2017-06-20   259 2017-06-20\n5 2017-06-21   210 2017-06-21\n6 2017-06-22   214 2017-06-22\n7 2017-06-23   290 2017-06-23\n\n\nこの状態で横軸をDateにしたらどうなるでしょうか（ 図 9.4 ）。\n\nggplot(SongSleep2, \n       mapping = aes(x = Date, y = Sleep)) +\n    geom_point() +\n    labs(x = \"日付\", y = \"睡眠時間 (分)\") +\n    theme_gray(base_size = 12)\n\n\n\n\n図 9.4: Songの睡眠時間\n\n\n\n\n一方、横軸をDateDにしたものが 図 9.5 です。\n\nggplot(SongSleep2, \n       mapping = aes(x = DateD, y = Sleep)) +\n    geom_point() +\n    labs(x = \"日付\", y = \"睡眠時間 (分)\") +\n    theme_gray(base_size = 12)\n\n\n\n\n図 9.5: Songの睡眠時間\n\n\n\n\n違いが分かりますかね。違いは抜けている6月19日です。 図 9.4 を見ると、横軸の6月18日の次が20日になっています。一方、 図 9.5 は19日になっており、ちゃんと空けてくれますね。これはDate型でない場合、データにないものは図に表示されないことを意味します。一方、Date型は抜けている日があっても、図に表示表示されます。一般のcharacter型またはfactor型でこのようなことを再現するためには、6月19日の列を追加し、睡眠時間を欠損値として指定する必要があります。たとえば、SongSleepデータにおいて6月19日の行は温存したまま、睡眠時間だけを欠損値にしてみましょう。\n\nSongSleep3 &lt;- SongSleep\nSongSleep3$Sleep[SongSleep$Date == \"2017-06-19\"] &lt;- NA\n\nSongSleep3\n\n        Date Sleep      DateD\n1 2017-06-17   173 2017-06-17\n2 2017-06-18   192 2017-06-18\n3 2017-06-19    NA 2017-06-19\n4 2017-06-20   259 2017-06-20\n5 2017-06-21   210 2017-06-21\n6 2017-06-22   214 2017-06-22\n7 2017-06-23   290 2017-06-23\n\n\nこのように日付はあるが、睡眠時間が欠損している場合、図にしたものが 図 9.6 です。\n\nggplot(SongSleep3, \n       mapping = aes(x = Date, y = Sleep)) +\n    geom_point() +\n    labs(x = \"日付\", y = \"睡眠時間 (分)\") +\n    theme_bw()\n\nWarning: Removed 1 rows containing missing values (`geom_point()`).\n\n\n\n\n\n図 9.6: Songの睡眠時間\n\n\n\n\n横軸上に6月19日が表示されます。このようにDate型でなくてもDate型と同じように動かすことは可能ですが、非常に面倒です。その意味でDate型は時系列データを扱う際に非常に便利なデータ型です。\n\n\n9.7.2 Date型の作り方\nDate型を作成方法はいくつかあります。\n\ncharacter型をDate型にする\nnumeric型をDate型にする\n\n主に使う方法は1であり、既に前節でお見せしましたas.Date()関数を使います。方法2もまたas.Date()を使いますが、これは「xxxx年xx月xx日から何日目」という書き方となり、起点となる日付 (origin)5を指定する必要があります。\nここでは方法1について解説します。日付を表すいくつかのベクトルを作ってみましょう。\n\nDate1 &lt;- \"2020-05-21\"\nDate2 &lt;- \"2020-5-21\"\nDate3 &lt;- \"2020/5/21\"\nDate4 &lt;- \"20/05/21\"\nDate5 &lt;- \"20200521\"\nDate6 &lt;- \"2020 05 21\"\nDate7 &lt;- \"2020.05.21\"\n\n\nas.Date(Date1)\n\n[1] \"2020-05-21\"\n\nas.Date(Date2)\n\n[1] \"2020-05-21\"\n\nas.Date(Date3)\n\n[1] \"2020-05-21\"\n\nas.Date(Date4, \"%y/%m/%d\")\n\n[1] \"2020-05-21\"\n\nas.Date(Date5, \"%Y%m%d\")\n\n[1] \"2020-05-21\"\n\nas.Date(Date6, \"%Y %m %d\")\n\n[1] \"2020-05-21\"\n\nas.Date(Date7, \"%Y.%m.%d\")\n\n[1] \"2020-05-21\"\n\n\nDate1、Date2、Date3のようなベクトルの場合、as.Date()のみでDate型に変換できます。つまり、日付が数字のみで構成され、年が4桁となっており、年月日が-または/で区切られている場合はこれでだけで十分です。しかし、年が2桁になっていたり、その他の記号が使われたり、区切られていない場合は、fotmat =引数を指定する必要があります。たとえばDate4は年が2桁となっているます。2桁の年は%yと表記します。この表記法の一部を以下の表で紹介します。\n\n\n\n表記\n説明\n例\n\n\n\n\n%y\n年 (2桁)\n20\n\n\n%Y\n年 (4桁)\n2020\n\n\n%m\n月 (数字)\n5, 10\n\n\n%b\n月 (文字)\nJan\n\n\n%B\n月 (文字)\nJanuary\n\n\n%d\n日\n5, 05, 13\n\n\n\n他にも様々な表記法がありますが、詳細は?strptimeで確認してみてください。\n他にも、日本では使わない表記法ですが、月を英語で表記したり、日月年の順で表記する場合があります。後者はformat =引数の順番を変えるだけで問題有りませんが、問題は前者です。そこで使うのが%bまたは%Bです。%bは3文字の月表記で、%Bはフルネームです。\n\nas.Date(\"21may2020\",   format = \"%d%b%Y\")\n\n[1] \"2020-05-21\"\n\nas.Date(\"May/21/2020\", format = \"%b/%d/%Y\")\n\n[1] \"2020-05-21\"\n\n\nうまくいかないですね。これはシステムの時間ロケールが日本になっているのが原因です。ロケール設定はSys.getlocale()で確認できます。\n\nSys.getlocale(category = \"LC_TIME\")\n\n[1] \"en_US.UTF-8\"\n\n\nこれをSys.setlocale()を使って、\"C\"に変更します。\n\nSys.setlocale(category = \"LC_TIME\", locale = \"C\")\n\n[1] \"C\"\n\n\nそれではもう一回やってみましょう。\n\nas.Date(\"21may2020\",   format = \"%d%b%Y\")\n\n[1] \"2020-05-21\"\n\nas.Date(\"May/21/2020\", format = \"%b/%d/%Y\")\n\n[1] \"2020-05-21\"\n\n\nうまく動くことが確認できました。念の為に、ロケールを戻しておきます。\n\nSys.setlocale(category = \"LC_TIME\", locale = \"ja_JP.UTF-8\")\n\n[1] \"ja_JP.UTF-8\"\n\n\n\n\n9.7.3 POSIXct、POSIXlt型について\nPOSIXct、POSIXlt型は日付だけでなく時間の情報も含むデータ型です。これらはas.POSIXct()、as.POSIXlt()関数で作成することができます。どちらも見た目は同じデータ型ですが、内部構造がことなります6。詳細は?as.POSIXctまたは?as.POSIXltを参照してください。"
  },
  {
    "objectID": "datatype.html#sec-type-na",
    "href": "datatype.html#sec-type-na",
    "title": "9  データ型",
    "section": "9.8 NA",
    "text": "9.8 NA\nNAは欠損値と呼ばれます。これは本来は値があるはずなのがなんらかの理由で欠損していることを意味します。 表 9.3 の例を考えてみましょう。\n\n\n\n\n表 9.3: 4人の支持政党\n\n\nID\n名前\n支持政党の有無\n支持政党\n\n\n\n\n1\nYanai\nない\nNA\n\n\n2\nSong\nある\nラーメン大好き党\n\n\n3\nShigemura\nある\n鹿児島第一党\n\n\n4\nTani\nない\nNA\n\n\n\n\n\n\n\n\n3列目で支持政党があるケースのみ、4列目に値があります。YanaiとTaniの場合、支持する政党がないため、政治政党名が欠損しています。実際、多くのデータには欠損値が含まれています。世論調査データの場合はもっと多いです。理由としては「Q2で”はい”を選んだ場合のみQ3に進み、それ以外はQ4へ飛ばす」のようなのもありますが、単に回答を拒否した場合もあります。\nまずは欠損値が含まれたベクトルna_vec1を作ってみましょう。\n\nna_vec1 &lt;- c(1, NA, 3, NA, 5, 6)\nna_vec1\n\n[1]  1 NA  3 NA  5  6\n\n\nつづいて、データ型を確認してみましょう。\n\nclass(na_vec1)\n\n[1] \"numeric\"\n\n\nNAが含まれていてもデータ型はnumericのままです。これは「一応、欠損しているが、ここに何らかの値が割り当てられるとしたらそれはnumeric型だろう」とRが判断しているからです。ある要素がNAか否かを判定するにはis.na()関数を使います。\n\nis.na(na_vec1)\n\n[1] FALSE  TRUE FALSE  TRUE FALSE FALSE\n\n\n2番目と4番目の要素が欠損していることが分かります。\n欠損値も要素の一つとしてカウントされるため、ベクトルの長さは6になります。ベクトルの長さはlength()関数で確認できます。\n\nlength(na_vec1)\n\n[1] 6\n\n\n欠損値の取り扱い\n欠損値を含むデータの処理方法はやや特殊です。まず、na_vec1の要素全てに1を足してみましょう。\n\nna_vec1 + 1\n\n[1]  2 NA  4 NA  6  7\n\n\nこの場合、欠損値の箇所には1が足されず、それ以外の要素のみに1を足した結果が返ってきます。これは直感的に考えると自然です。問題になるのは欠損値が含まれるベクトルを関数に入れた場合です。たとえば、numeric型ベクトル内の要素の総和を求めるにはsum()関数を使います。sum(c(1, 3, 5))を入力すると9が返されます。na_vec1は欠損していない要素が1, 3, 5, 6であるため、総和は15のはずです。確認してみましょう。\n\nsum(na_vec1)\n\n[1] NA\n\n\nこのように欠損値を含むベクトルの総和はNAとなります。もし、欠損値を除いた要素の総和を求めるには、まずベクトルから欠損値を除去する必要があります。そのためにはis.na()関数を使ってna_vec1の要素を抽出します。ただし、is.na()を使うと、欠損値であるところがTRUEになるため、これを反転する必要があります。この場合は!is.na()関数を使います。それではis.na()と!is.na()を使って要素を抽出してみましょう。\n\nna_vec1[is.na(na_vec1)]\n\n[1] NA NA\n\nna_vec1[!is.na(na_vec1)]\n\n[1] 1 3 5 6\n\n\n!is.na()を使うことで欠損値を除いた要素のみを取り出すことができました。これならsum()関数も使えるでしょう。\n\nsum(na_vec1[!is.na(na_vec1)])\n\n[1] 15\n\n\nこれで欠損値を除いた要素の総和を求めることができました。ただし、一部の関数には欠損値を自動的に除去するオプションを持つ場合があります。sum()関数のその一部であり、na.rm = TRUEオプションを付けると、欠損値を除いた総和を返します。\n\nsum(na_vec1, na.rm = TRUE)\n\n[1] 15\n\n\n欠損値の使い方\n主に欠損値を扱うのは入手したデータに含まれる欠損値に対してですが、NAをこちらから生成することもあります。それは空ベクトルを用意する時です。第11章では関数の作り方について解説します。関数内で何らかの処理を行い、その結果を返すことになりますが、その結果を格納するベクトルを事前に作っておくこともできます。こちらの方がメモリの観点からは効率的です。以下は第11章を読んでから読んでも構いません。\nもし、長さ10のベクトルresult_vec1を返すとします。ベクトルの要素として1から10の数字が入るとします。一つ目の方法としてはまず、result_vec1に1を代入し、次はc()を使って要素を一つずつ足して行く手順です。\n\nresult_vec1 &lt;- 1\nresult_vec1 &lt;- c(result_vec1, 2)\nresult_vec1 &lt;- c(result_vec1, 3)\nresult_vec1 &lt;- c(result_vec1, 4)\nresult_vec1 &lt;- c(result_vec1, 5)\nresult_vec1 &lt;- c(result_vec1, 6)\nresult_vec1 &lt;- c(result_vec1, 7)\nresult_vec1 &lt;- c(result_vec1, 8)\nresult_vec1 &lt;- c(result_vec1, 9)\nresult_vec1 &lt;- c(result_vec1, 10)\n\n二つ目の方法はまず、10個のNAが格納されたベクトルReuslt.Vec2を作っておいて、その中に要素を置換してく方法です。\n\nresult_vec2     &lt;- rep(NA, 10)\nresult_vec2[1]  &lt;- 1\nresult_vec2[2]  &lt;- 2\nresult_vec2[3]  &lt;- 3\nresult_vec2[4]  &lt;- 4\nresult_vec2[5]  &lt;- 5\nresult_vec2[6]  &lt;- 6\nresult_vec2[7]  &lt;- 7\nresult_vec2[8]  &lt;- 8\nresult_vec2[9]  &lt;- 9\nresult_vec2[10] &lt;- 10\n\n以上の手順を第11章で紹介するfor()を使って反復処理するとしたら、以下のようなコードになります。\n\n# 方法1\nresult_vec1 &lt;- 1\n\nfor (i in 2:10) {\n    result_vec1 &lt;- c(result_vec1, i)\n}\n\n# 方法2\nresult_vec2 &lt;- rep(NA, 10)\n\nfor (i in 1:10) {\n    result_vec2[i] &lt;- i\n}\n\n結果を確認してみましょう。\n\nresult_vec1\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\nresult_vec2\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\n\nコードの書き方は異なりますが、どれも結果は同じです。また、どちらが早いかというと、これくらいの計算ならどの方法でも同じです。ただし、より大規模の反復作業を行う場合、後者の方が時間が節約でき、コードの可読性も高いです。"
  },
  {
    "objectID": "datatype.html#sec-type-null",
    "href": "datatype.html#sec-type-null",
    "title": "9  データ型",
    "section": "9.9 NULL",
    "text": "9.9 NULL\nNULLは「存在しない」、空っぽであることを意味します。先ほどのNAはデータは存在するはずなのに、何らかの理由で値が存在しない、または割り当てられていないことを意味しますが、NULLは「存在しません」。したがって、NULLが含まれたベクトルを作成しても表示されません。NULLが含まれたnull_vec1を作ってみましょう。\n\nnull_vec1 &lt;- c(1, 3, NULL, 5, 10)\nnull_vec1\n\n[1]  1  3  5 10\n\n\n3番目の要素であるNULLは表示されません。ということはNAと違って、データの長さも5ではなく4でしょう。確認してみます。\n\nlength(null_vec1)\n\n[1] 4\n\n\nこのnull_vec1のデータ型は何でしょう。\n\nclass(null_vec1)\n\n[1] \"numeric\"\n\n\nis.null()関数もありますが、どうでしょうか。\n\nis.null(null_vec1)\n\n[1] FALSE\n\n\nNULLは存在しないことを意味するため、null_vec1は要素が4のnumeric型ベクトルです。is.null()でNULLが判定できるのはis.null(NULL)のようなケースです。\n図 9.7 はNA型とNULL型の違いについてまとめたものです。\n\n\n\n\n\n図 9.7: NAとNULLの違い\n\n\n\n\nこのNULLはいつ使うのでしょうか。実際、使う機会はあまりありません。強いて言えば、空っぽのリストを作成する際に使うケースがあります。リストについては第10章で説明します。以下の例は第10章を読み終わってから目を通して下さい。\n\nnull_list1 &lt;- list(Room1 = 1:3,\n                   Room2 = c(\"Yuki\", \"Jaehyun\", \"Hadley\"),\n                   Room3 = NULL)\n\nnull_list1\n\n$Room1\n[1] 1 2 3\n\n$Room2\n[1] \"Yuki\"    \"Jaehyun\" \"Hadley\" \n\n$Room3\nNULL\n\n\nこのように予めリストの要素は作っておきたいが、とりあえず空けておく際に使います。続く分析の段階でnull_list1[[\"Room3\"]]に何かを格納したりすることに使えるでしょう。ちなみにこの場合はis.null()が使用可能です。\n\nis.null(null_list1[[\"Room3\"]])\n\n[1] TRUE"
  },
  {
    "objectID": "datatype.html#sec-type-nan",
    "href": "datatype.html#sec-type-nan",
    "title": "9  データ型",
    "section": "9.10 NaN",
    "text": "9.10 NaN\nNaNはnumeric型、中でもdouble型の一種ですが、これは計算できない値を意味します。つまり、NaN値を直接入力することはめったにありませんが、計算の結果としてNaNが返されるケースがあります。代表的な例が0を0で割った場合です。実際、0を0で割ることはできません。ここでは0を0で割った値を含むnan_vec1作ってみましょう。\n\nnan_vec1 &lt;- c(2/5, 0/12, 0/0)\nnan_vec1\n\n[1] 0.4 0.0 NaN\n\nclass(nan_vec1)\n\n[1] \"numeric\"\n\n\n先ほどせつめいしましたように、NaNはnumeric型の一部ですので、データ型としてはnumeircになります。ある値がNaNか否かを判定するにはis.nan()関数を使います。\n\nis.nan(nan_vec1)\n\n[1] FALSE FALSE  TRUE"
  },
  {
    "objectID": "datatype.html#sec-type-inf",
    "href": "datatype.html#sec-type-inf",
    "title": "9  データ型",
    "section": "9.11 Inf",
    "text": "9.11 Inf\nInfもまたnumeric型、中でもdouble型の一部ですが、これは無限大を意味します。Infも通常、自分から作成するケースはあまりなく、結果として帰ってくる場合があります。一つの例が0以外の数値を0で割った場合です。それではなんらかの数値を0を割った値が含まれるベクトルinf_vec1を作ってみましょう。\n\ninf_vec1 &lt;- c(28/95, 3/0, -12/0, 0/0)\ninf_vec1\n\n[1] 0.2947368       Inf      -Inf       NaN\n\nclass(inf_vec1)\n\n[1] \"numeric\"\n\n\n正の値を0で割ったらInfが負の値を0で割ったら-Infが返ってきます。これは正の無限大、負の無限大を意味します。データ型はNaNと同様、numeric型ですが、is.infinite()を使うと、無限大か否かが判定できます。\n\nis.infinite(inf_vec1)\n\n[1] FALSE  TRUE  TRUE FALSE"
  },
  {
    "objectID": "datastructure.html#sec-datastructure_intro",
    "href": "datastructure.html#sec-datastructure_intro",
    "title": "10  データ構造",
    "section": "10.1 データ構造とは",
    "text": "10.1 データ構造とは\nデータ構造 (data structure)とは最小単位であるベクトルを何らかの形で集めたものです。ベクトル自体もデータ構造であり、同じデータ型のベクトルを積み重ねた行列、異なるデータ型の縦ベクトルを横に並べたデータフレームなど、Rでは様々なデータ構造を提供しています。また、R内臓のデータ構造以外にも、パッケージ等で提供される独自のデータ構造もあります。ここではRが基本的に提供している代表的なデータ構造について、その作り方と操作方法について解説します。"
  },
  {
    "objectID": "datastructure.html#sec-datastructure_vector",
    "href": "datastructure.html#sec-datastructure_vector",
    "title": "10  データ構造",
    "section": "10.2 ベクトル (vector)",
    "text": "10.2 ベクトル (vector)\n\n10.2.1 ベクトルの作り方\nRにおいてベクトルとは同じデータ型が一つ以上格納されているオブジェクトを意味します。たとえば、以下のmyVec1は長さ1のベクトルです。\n\nmyVec1 &lt;- \"R is fun!\"\nmyVec1\n\n[1] \"R is fun!\"\n\n\nむろん、2つ以上の文字列、または数字を格納することも可能です。以下のmyVec2は長さ5のベクトルです。\n\nmyVec2 &lt;- c(1, 3, 5, 6, 7)\nmyVec2\n\n[1] 1 3 5 6 7\n\n\n注意すべきところは、ベクトル内の要素は必ず同じデータ型である必要があるということです。たとえば、数字と文字が混在したmyVec3を考えてみましょう。\n\nmyVec3 &lt;- c(\"A\", \"B\", \"C\", 1, 2, 3)\nmyVec3\n\n[1] \"A\" \"B\" \"C\" \"1\" \"2\" \"3\"\n\n\n数字であるはずの1, 2, 3が\"で囲まれ、文字列に自動的に変換されていることが分かります。実際に、デーが型を確認してみましょう。\n\nclass(myVec3)\n\n[1] \"character\"\n\n\n\"character\"、つまりデータ型が文字列になっていることが分かります。これはcharacter型がnumeric型よりも優先順位が高いからです。それではnumericとlogical型はどうでしょうか。\n\nmyVec4 &lt;- c(1, 2, 3, TRUE, FALSE)\nmyVec4\n\n[1] 1 2 3 1 0\n\nclass(myVec4)\n\n[1] \"numeric\"\n\n\nTRUEが1、FALSEが0となり、自動的にnumeric型になりました。一般的によく使われるデータ型はlogical、numeric、characterですが、優先順位はlogical &lt; numeric &lt; characterの関係になります。ここで重要なのは優先順位ではなく、異なるデータ型が含まれるベクトルの場合、自動的にデータ型が統一されるということです。ベクトルを作成する際は、全ての要素が同じ型になるようにしましょう。\n\n\n10.2.2 ベクトルの操作\nベクトルの長さ\nベクトルの長さはベクトルに含まれている要素の数です。ベクトルの長さはlength()関数で調べることができます。それでは前節で作成した4つのベクトルの長さを調べてみましょう。\n\nlength(myVec1) # \"R is fun!\"\n\n[1] 1\n\nlength(myVec2) # c(1, 3, 5, 6, 7)\n\n[1] 5\n\nlength(myVec3) # c(\"A\", \"B\", \"C\", \"1\", \"2\", \"3\")\n\n[1] 6\n\nlength(myVec4) # c(1, 2, 3, 1, 0)\n\n[1] 5\n\n\nそれぞれのベクトルの長さは1、5、6、5ということが分かりますね。\n要素の抽出\nこれは既に説明しましたので、第7.3を参照してください。\nベクトルの加減乗除\nここではnumeric型のベクトルを用いた加減乗除について考えたいと思います。Rにおいてベクトルは自動的に反復作業を行います。たとえば、c(1, 2, 3, 4)というベクトルがあり、ここに5を足すと、ベクトルの全ての要素に対して同じ計算を行います。これは引き算でも、掛け算でも、割り算でも同じです。むろん、べき乗などの様々な操作に対しても同じです。それではmyVec2に対して、5を足したり、引いたり、色々してみましょう。\n\nmyVec2 + 5\n\n[1]  6  8 10 11 12\n\nmyVec2 - 5\n\n[1] -4 -2  0  1  2\n\nmyVec2 * 5\n\n[1]  5 15 25 30 35\n\nmyVec2 / 5\n\n[1] 0.2 0.6 1.0 1.2 1.4\n\nmyVec2 ^ 5\n\n[1]     1   243  3125  7776 16807\n\n\nまた、ベクトル同士の演算も可能です。まず、myVec2と同じ長さを持つmyVec4との計算を考えてみましょう。これは長さが同じであるため、それぞれ同じ位置の要素同士の計算となります。つまり、足し算の場合、myVec2[1]とmyVec4[1]の和、myVec2[2]とmyVec4[2]の和、…といった形です。\n\nmyVec2 + myVec4\n\n[1] 2 5 8 7 7\n\nmyVec2 - myVec4\n\n[1] 0 1 2 5 7\n\nmyVec2 * myVec4\n\n[1]  1  6 15  6  0\n\nmyVec2 / myVec4\n\n[1] 1.000000 1.500000 1.666667 6.000000      Inf\n\n\nもし、ベクトルの長さが異なる場合はどうなるでしょう。たとえば、長さ2のベクトルmyVec5とmyVec2の足し算を考えてみましょう。\n\n(myVec5 &lt;- c(1, 10))\n\n[1]  1 10\n\n(myVec6 &lt;- myVec2 + myVec5)\n\nWarning in myVec2 + myVec5: longer object length is not a multiple of shorter\nobject length\n\n\n[1]  2 13  6 16  8\n\n\n警告メッセージは表示されますが、計算自体はできます。同じ長さのベクトル同士なら、同じ位置の要素同士の計算になりますが、この場合は、短い方のベクトルを繰り返すことにより、長さを合わせることになります。myVec5の例だと、c(1, 10, 1, 10, 1)のように扱われます。具体的には以下の表のような関係となります。\n\n\n\nmyVec6[1]\nmyVec6[2]\nmyVec6[3]\nmyVec6[4]\nmyVec6[5]\n\n\n\n\nmyVec2[1]\nmyVec2[2]\nmyVec2[3]\nmyVec2[4]\nmyVec2[5]\n\n\n+\n+\n+\n+\n+\n\n\nmyVec5[1]\nmyVec5[2]\nmyVec5[1]\nmyVec5[2]\nmyVec5[1]\n\n\n\n実際は長さが異なるベクトル同士の計算を行うことは滅多にありません。例外としては長さ1のベクトルの計算くらいですね。\n文字列ベクトルの扱い方はより複雑ですので、第17章で詳細に解説します。"
  },
  {
    "objectID": "datastructure.html#sec-datastructure_matrix",
    "href": "datastructure.html#sec-datastructure_matrix",
    "title": "10  データ構造",
    "section": "10.3 行列 (matrix)",
    "text": "10.3 行列 (matrix)\n行列は名前とおり、行と列で構成されたデータ構造です。ただし、我々が一般に考える「表」とは異なる点があります。それは行列内部の要素に制約がある点です。具体的に、行列の要素となり得るデータ型はnumeric、complex、NA型のみです。ここではnumeric型のみで構成された行列の作成および操作方法について解説します。\n\n10.3.1 行列の作り方\n行列を作成するにはmatrix()関数を使います。引数として、行列に入る数値と行または列の数は必須です。数値はベクトルであり、行・列の数は整数です。以下のような行列を作るにはいくつかの方法があります。\n\\[\n\\left[\n\\begin{matrix}\n1 & 2 & 3 & 4 \\\\\n5 & 6 & 7 & 8 \\\\\n9 & 10 & 11 & 12\n\\end{matrix}\n\\right]\n\\]\n\n# 方法1: 行数を指定する\nMatrix1 &lt;- matrix(c(1, 5, 9, 2, 6, 10, 3, 7, 11, 4, 8, 12), nrow = 3)\nMatrix1\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12\n\n# 方法2: 列数を指定する\nMatrix2 &lt;- matrix(c(1, 5, 9, 2, 6, 10, 3, 7, 11, 4, 8, 12), ncol = 4)\nMatrix2\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12\n\n\nいずれも同じ結果が得られます。注意してもらいたいところは、第一引数の書き方です。我々は「左から右へ、そして上から下へ」という順番で読むのになれていますが、Rの行列は「上から下へ、そして左から右へ」の順番です。もし、「左から右へ、そして上から下へ」のような、より我々にとって読みやすい書き方をするためにはもう一つの引数が必要であり、それがbyrow =です。\n\n(matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), nrow = 3, byrow = TRUE))\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12\n\n\nむろん、初項1、公差1、最大値12の等差数列ですのて、1:12のような書き方も可能です。\n\n(matrix(1:12, nrow = 3, byrow = TRUE))\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    2    3    4\n[2,]    5    6    7    8\n[3,]    9   10   11   12\n\n\nデータ構造も確認してみましょう。\n\nclass(Matrix1)\n\n[1] \"matrix\" \"array\" \n\n\nR 4.0.0からの仕様変更により行列型はmatrix構造以外にもarrayの構造も持つようになりました。array型については第10.6章で解説します。\n単位行列\n最後にちょっと特殊な行列である単位行列 (indetity matrix)の作り方について説明します。単位行列とは行と列の数が同じである正方形の行列ですが、対角線上は全て1、その他は全て0となっている行列です。たとえば大きさが4の単位行列は、\n\\[\n\\left[\n\\begin{matrix}\n1 & 0 & 0 & 0 \\\\\n0 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 0 \\\\\n0 & 0 & 0 & 1 \\\\\n\\end{matrix}\n\\right]\n\\]\nです。これはmatrix(c(1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1), nrow = 4)で作成することも可能ですが、diag()関数を使えば簡単に出来ます。サイズが4の単位行列はdiag(4)です。\n\n(diag(4))\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    0    0    0\n[2,]    0    1    0    0\n[3,]    0    0    1    0\n[4,]    0    0    0    1\n\n\n\n\n10.3.2 行列の操作\nまず、以下のような行列Aを作ってみましょう。\n\\[\nA = \\left[\n\\begin{matrix}\n1 & 2 & 3 & 4 \\\\\n5 & 6 & 7 & 8 \\\\\n9 & 10 & 11 & 12\n\\end{matrix}\n\\right]\n\\]\n\nA &lt;- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), \n            nrow = 3, byrow = TRUE)\n\n行列のサイズ\n行列の大きさ (行と列の数)を求める際はdim()関数を使います。\n\ndim(A)\n\n[1] 3 4\n\n\n結果は長さ2のベクトルですが、1番目の要素が行数、2番目の要素が列数になります。もし、行列の行数のみ確認したい場合はdim(A)[1]、列数ならdim(A)[2]で確認することができます。また、全く同じ機能を持つ関数があり、それがnrow()とncol()関数です。\n\nnrow(A) # 行列の行数を確認: dim(A)[1]と同じ\n\n[1] 3\n\nncol(A) # 列列の列数を確認: dim(A)[2]と同じ\n\n[1] 4\n\n\ndim()およびnrow()、ncol()関数は第10.4章で紹介するデータフレームでも使用可能です。\n要素の抽出\nベクトルと同様、要素の抽出は[]を使います。ただし、行列は横と縦の2次元構成となりますので、行と列のそれぞれの位置を指定する必要があります。たとえば、Aの2行目、3列目の要素を抽出するためには、\n\nA[2, 3]\n\n[1] 7\n\n\nのように書きます。行か列の位置を省略した場合、指定した列・行全てが抽出されます。2行目の要素全てを抽出するならA[2, ]、3列目の要素全てを抽出するならA[, 3]となります。\n\nA[2, ]\n\n[1] 5 6 7 8\n\nA[, 3]\n\n[1]  3  7 11\n\n\nこの場合、返される値のデータ構造はいずれも行列でなく、ベクトルです。確認してみましょう。\n\nis.vector(A[2, 3])\n\n[1] TRUE\n\nis.vector(A[2, ])\n\n[1] TRUE\n\nis.vector(A[, 3])\n\n[1] TRUE\n\n\n例外は複数の行と複数の列を同時に抽出した場合です。たとえば、行列Aの1・2行目と2・3列目の要素を全て抽出するとします。その場合はA[1:2, 2:3]のように書きます。むろん、:を使わずにA[c(1, 2), c(2, 3)]のような書き方も可能です。抽出後、返された結果のデータ構造も確認してみましょう。\n\nA[1:2, 3:4]\n\n     [,1] [,2]\n[1,]    3    4\n[2,]    7    8\n\nclass(A[1:2, 3:4])\n\n[1] \"matrix\" \"array\" \n\n\nこの場合、返された結果のデータ構造は行列であることが分かります。\n行列の足し算と引き算\n行列の足し算 (引き算)には\n\n行列内の全要素に対して同じ数字を足す (引く)\n同じサイズの2つの行列から対応する要素を足す (引く)\n\n2パタンがあります。例えば、行列Aの全要素に5を足す場合は以下のように入力します。\n\n(A_plus_5 &lt;- A + 5)\n\n     [,1] [,2] [,3] [,4]\n[1,]    6    7    8    9\n[2,]   10   11   12   13\n[3,]   14   15   16   17\n\n\n同様に、Aから10を引く場合は-演算子を使います。\n\n(A_minus_10 &lt;- A - 10)\n\n     [,1] [,2] [,3] [,4]\n[1,]   -9   -8   -7   -6\n[2,]   -5   -4   -3   -2\n[3,]   -1    0    1    2\n\n\n二つ目は同じサイズの行列同士の足し算と引き算です。行列Aは3 \\(\\times\\) 4の行列ですので、同じサイズの行列Bを作成してみましょう。\n\n(B &lt;- matrix(c(3, 2, 1, 4, 5, 9, 7, 11, 6, 12, 8, 10), \n             nrow = 3, byrow = TRUE))\n\n     [,1] [,2] [,3] [,4]\n[1,]    3    2    1    4\n[2,]    5    9    7   11\n[3,]    6   12    8   10\n\n\nこの行列AとBの足し算はそれぞれ同じ位置の要素同士の和を行列をして返し、これは引き算も同じです。\n\nA + B\n\n     [,1] [,2] [,3] [,4]\n[1,]    4    4    4    8\n[2,]   10   15   14   19\n[3,]   15   22   19   22\n\nA - B\n\n     [,1] [,2] [,3] [,4]\n[1,]   -2    0    2    0\n[2,]    0   -3    0   -3\n[3,]    3   -2    3    2\n\n\n注意すべき点は、2つの行列は同じ大きさでなければならない点です。たとえば、行列Bの1列から3列までを抽出した3 \\(\\times\\) 3行列Cを作成し、A + Cをしてみましょう。\n\n(C &lt;- B[, 1:3])\n\n     [,1] [,2] [,3]\n[1,]    3    2    1\n[2,]    5    9    7\n[3,]    6   12    8\n\nA + C\n\nError in A + C: non-conformable arrays\n\n\nこのように足し算ができなくなり、これは引き算でも同じです。\n行列の掛け算\nやや特殊なのは行列の掛け算です。行列Aの全要素を2倍にしたい場合、これは足し算・引き算と同じやり方で十分です。\n\nA * 2\n\n     [,1] [,2] [,3] [,4]\n[1,]    2    4    6    8\n[2,]   10   12   14   16\n[3,]   18   20   22   24\n\n\nただし、問題は行列同士の掛け算です。行列AとBの掛け算といえば、直感的には足し算や引き算同様、同じ位置の要素の積と考えるかも知れません。実際A * Bはそのように計算を行います。\n\nA * B\n\n     [,1] [,2] [,3] [,4]\n[1,]    3    4    3   16\n[2,]   25   54   49   88\n[3,]   54  120   88  120\n\n\nただし、このような掛け算は「アダマール積 (Hadamard product)」と呼ばれる計算方法であり1、一般的に使う掛け算ではありません。実際、数学において\\(A \\times B\\)はアダマール積を意味すのではなく、アダマール積は\\(A \\circ B\\)または\\(A \\odot B\\)と表記します。\nそれでは一般的な行列の積は何でしょう。詳しいことは線形代数の入門書に譲りますが、以下のような2つの行列CとDを考えてみましょう。\n\\[\nC = \\left[\n\\begin{matrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6\n\\end{matrix}\n\\right],\nD = \\left[\n\\begin{matrix}\n2 & 7  & 17 \\\\\n3 & 11 & 19 \\\\\n5 & 13 & 23\n\\end{matrix}\n\\right]\n\\]\n行列の大きさが異なりますね。行列Cの大きさは2 \\(\\times\\) 3、Dは3 \\(\\times\\) 3です。実はこれが正しいです。行列の積は\\(n \\times m\\)の行列と\\(m \\times p\\)の行列同士でないと計算できません。\\(n\\)と\\(p\\)は同じでも、同じでなくても構いません。その意味で\\(C \\times D\\)は計算可能でも、\\(D \\times C\\)は計算できません。そして、2つの行列の積の大きさは\\(n \\times p\\)です。したがって、\\(C \\times D\\)の大きさは\\(2 \\times 3\\)です。\n行列の積がどのように求められるかを確認するために、まず行列CとDを作成してみましょう。\n\n(C &lt;- matrix(c(1, 2, 3, 4, 5, 6), nrow = 2,byrow = TRUE))\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n\n(D &lt;- matrix(c(2, 7, 17, 3, 11, 19, 5, 13, 23), nrow = 3,byrow = TRUE))\n\n     [,1] [,2] [,3]\n[1,]    2    7   17\n[2,]    3   11   19\n[3,]    5   13   23\n\n\nこの2つの積は%*%演算子で計算されますが、まずその結果から見ましょう。\n\n(E &lt;- C %*% D)\n\n     [,1] [,2] [,3]\n[1,]   23   68  124\n[2,]   53  161  301\n\n\n2行2列の行列ができました。これらの数字、どうやった計算されたのでしょうか。Eの[1, 1]は23であり、[1, 2]は68、[2, 1]は53、[2, 2]は161です。各値は以下のように求まります。\n\nE[1, 1] = (C[1, 1] * D[1, 1]) + (C[1, 2] * D[2, 1]) + (C[1, 3] * D[3, 1]) = 23\nE[1, 2] = (C[1, 1] * D[1, 2]) + (C[1, 2] * D[2, 2]) + (C[1, 3] * D[3, 2]) = 68\nE[1, 3] = (C[1, 1] * D[1, 3]) + (C[1, 2] * D[2, 3]) + (C[1, 3] * D[3, 3]) = 124\nE[2, 1] = (C[2, 1] * D[1, 1]) + (C[2, 2] * D[2, 1]) + (C[2, 3] * D[3, 1]) = 53\nE[2, 2] = (C[2, 1] * D[1, 2]) + (C[2, 2] * D[2, 2]) + (C[2, 3] * D[3, 2]) = 161\nE[2, 3] = (C[2, 1] * D[1, 3]) + (C[2, 2] * D[2, 3]) + (C[2, 3] * D[3, 3]) = 301\n\n大きさ\\(n \\times m\\)行列Cのi行目j列目の要素を\\(C_{i,j}\\)と表記し、大きさ\\(n \\times p\\)行列Dのi行目j列目の要素を\\(D_{i,j}\\)と表記した場合、以下のような関係が成り立ちます。\n行列Eのi行目j列目の要素を\\(e_{i,j}\\)と表記した場合、以下のような関係が成り立ちます。\n\\[\ne_{i, j} = \\sum_{k = 1}^m C_{i, k} \\cdot D_{k, j}.\n\\]\nしたがって、行列\\(C\\)と\\(D\\)の積は\n\\[\\begin{align}\nCD = E & = \\left[\n\\begin{matrix}\ne_{1, 1} & e_{1, 2} & e_{1, 3} \\\\\ne_{2, 1} & e_{2, 2} & e_{2, 3}\n\\end{matrix}\n\\right] \\\\\n& = \\left[\n\\begin{matrix}\n\\sum_{k = 1}^m C_{1, k} \\cdot D_{k, 1} & \\sum_{k = 1}^m C_{1, k} \\cdot D_{k, 2} & \\sum_{k = 1}^m C_{1, k} \\cdot D_{k, 3} \\\\\n\\sum_{k = 1}^m C_{2, k} \\cdot D_{k, 1} & \\sum_{k = 1}^m C_{2, k} \\cdot D_{k, 2} & \\sum_{k = 1}^m C_{2, k} \\cdot D_{k, 3}\n\\end{matrix}\n\\right].\n\\end{align}\\]\nこのように業績同士の積はかなり求めるのが面倒ですが、Rを使えば一瞬で終わります。\n行列式\n行列式 (determinant)は\\(n \\times n\\)の正方行列のみに対して定義される値の一つです。主に一次方程式において解が存在するか否かを判断するために用いられる数値ですが2、その詳しい意味や求め方については線形代数の入門書を参照してください。\n行列\\(A\\)の行列式は一般的に\\(\\text{det}(A)\\)、または\\(|A|\\)と表記されます。行列式を求めるRの関数はdet()です。それでは適当に正方行列Fを作成し、その行列を求めてみましょう。\n\n(F &lt;- matrix(c(2, -6, 4, 7, 2, 3, 8, 5, -1), nrow = 3, byrow = 3))\n\n     [,1] [,2] [,3]\n[1,]    2   -6    4\n[2,]    7    2    3\n[3,]    8    5   -1\n\ndet(F)\n\n[1] -144\n\n\n行列Fの行列式は-144です。この場合、以下の一次方程式に何らかの一組の解が存在することを意味します (\\(p\\), \\(q\\), \\(r\\)は任意の実数)。\n\\[\\begin{align}\n2x - 6y + 4z = & p, \\\\\n7x + 2y + 3z = & q, \\\\\n8x + 5y - 1z = & r.\n\\end{align}\\]\nしかし、以下のような連立方程式はいかがでしょう。これは二組以上の解が存在する方程式です3。\n\\[\\begin{align}\n2x - 6y + 4z = & p, \\\\\n1x - 3y + 2z = & q, \\\\\n5x + 9y + 3z = & r.\n\\end{align}\\]\n実際に行列Gを作成し、det(G)を計算してみましょう。\n\n(G &lt;- matrix(c(2, -6, 4, 1, -3, 2, 5, 9, 3), nrow = 3, byrow = 3))\n\n     [,1] [,2] [,3]\n[1,]    2   -6    4\n[2,]    1   -3    2\n[3,]    5    9    3\n\ndet(G)\n\n[1] 0\n\n\n\\(|G|\\)は0であることが分かりますね。\n階数\n行列の特徴を表す代表的な数値の一つが階数 (rank)です。詳しい説明は省きますが、一次方程式の例だと、階数が行列の行数と一致する場合、一組の解が存在することを意味します。階数を求める方法はqr(行列)$rankであり、行列FとGの階数を確認してみましょう。\n\nqr(F)$rank\n\n[1] 3\n\nqr(G)$rank\n\n[1] 2\n\n\nどれも3行の行列ですが、行列Fの階数は3、行列Gの階数は2です。Gの階数はGの行数より小さいため、連立方程式に一組の解がないことが分かります。\n階数の活用先は様々であり、行列式とは違って、正方行列でなくても計算可能です。\n逆行列\n逆行列とは掛け算すると単位行列となる行列を意味します。行列\\(A\\)の逆行列は一般的に\\(A^{\\prime}\\)と表記し、\\(A \\times A^{\\prime} = I\\)となります。この逆行列の求め方は非常に複雑であり、一定以上の大きさの行列になると手計算で解くのはほぼ不可能です。しかし、Rでは逆行列を計算するsolve()関数が内蔵されております。\n以下の行列\\(A\\) (A)の逆行列、\\(A^{\\prime}\\) (Ap)を求めてみましょう。そして\\(A \\times A^{\\prime}\\)が単位行列になるかまで確認してみます。\n\n# 行列Aの作成\n(A  &lt;- matrix(c(1, -2, 2, 0, 1, -1, 1, 0, 1), nrow = 3))\n\n     [,1] [,2] [,3]\n[1,]    1    0    1\n[2,]   -2    1    0\n[3,]    2   -1    1\n\n# 行列Aの逆行列を計算し、Apに格納\n(Ap &lt;- solve(A))\n\n     [,1] [,2] [,3]\n[1,]    1   -1   -1\n[2,]    2   -1   -2\n[3,]    0    1    1\n\n# AとApの積が単位行列であることを確認\nA %*% Ap\n\n     [,1] [,2] [,3]\n[1,]    1    0    0\n[2,]    0    1    0\n[3,]    0    0    1\n\n\nちゃんと単位行列ができましたね。\n転置\n行列\\(A\\)の転置行列は\\(A^T\\)と表記され、以下のような関係となります。\n\\[\nA = \\left[\n\\begin{matrix}\n1 & 2 & 3 \\\\\n4 & 5 & 6 \\\\\n7 & 8 & 9\n\\end{matrix}\n\\right],\nA^T = \\left[\n\\begin{matrix}\n1 & 4 & 7 \\\\\n2 & 5 & 8 \\\\\n3 & 6 & 9\n\\end{matrix}\n\\right]\n\\]\n正方行列の場合、対角成分を除き、全ての要素が対角成分を中心に反転していることが分かりますね。このような転置行列の作成にはt()関数を使います。それでは行列Aとその転置行列Atを作ってみましょう。\n\nA  &lt;- matrix(1:9, byrow = TRUE, nrow = 3)\nA\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\nAt &lt;- t(A)\n\nちなみに転置行列は正方行列でなくても作成できます。"
  },
  {
    "objectID": "datastructure.html#sec-datastructure-dataframe",
    "href": "datastructure.html#sec-datastructure-dataframe",
    "title": "10  データ構造",
    "section": "10.4 データフレーム (data.frame)",
    "text": "10.4 データフレーム (data.frame)\nデータフレームはデータ分析の際に最もよく見るデータ構造です。我々が一般的に考える表形式のデータはデータフレームです。行列も見た目は表に近いですが、行列は中身の要素がnumericまたはcomplex型に限定されるに対して4、データフレームはcharacterやfactor、Dateなど様々なデータ型が許容されます。\n\n10.4.1 データフレームの作成\nまずは、 表 10.1 のようなデータフレームを作成して見ましょう。データフレームを作成する際はdata.frame()関数を使います。\n\n\n\n\n表 10.1: myDFの中身\n\n\nID\nName\nMath\nStat\n\n\n\n\n1\nYanai\n50\n25\n\n\n2\nSong\n90\n5\n\n\n3\nShigemura\n100\n100\n\n\n4\nTani\n80\n85\n\n\n\n\n\n\n\n\n\nmyDF &lt;- data.frame(\n    ID   = 1:4,\n    Name = c(\"Yanai\", \"Song\", \"Shigemura\", \"Tani\"),\n    Math = c(50, 90, 100, 80),\n    Stat = c(25, 5, 100, 85)\n    )\n\nmyDF\n\n  ID      Name Math Stat\n1  1     Yanai   50   25\n2  2      Song   90    5\n3  3 Shigemura  100  100\n4  4      Tani   80   85\n\n\nデータ構造を確認してみましょう。\n\nclass(myDF)\n\n[1] \"data.frame\"\n\n\nデータフレームを作成する際、事前にベクトルを用意してから作成することも可能です。\n\nmyDF_ID   &lt;- 1:4\nmyDF_Name &lt;- c(\"Yanai\", \"Song\", \"Shigemura\", \"Tani\")\nmyDF_Math &lt;- c(50, 90, 100, 80)\nmyDF_Stat &lt;- c(25, 5, 100, 85)\n\nmyDF2 &lt;- data.frame(myDF_ID, myDF_Name, myDF_Math, myDF_Stat)\n\nmyDF2\n\n  myDF_ID myDF_Name myDF_Math myDF_Stat\n1       1     Yanai        50        25\n2       2      Song        90         5\n3       3 Shigemura       100       100\n4       4      Tani        80        85\n\n\nこの場合、列の名前はベクトル名そのままになります。もし、列名を指定したい場合は以下のように作成します。\n\nmyDF3 &lt;- data.frame(\n    ID   = myDF_ID, \n    Name = myDF_Name, \n    Math = myDF_Math, \n    Stat = myDF_Stat\n    )\n\nmyDF3\n\n  ID      Name Math Stat\n1  1     Yanai   50   25\n2  2      Song   90    5\n3  3 Shigemura  100  100\n4  4      Tani   80   85\n\n\n以上をコードを考えてみると、データフレームは複数のベクトルを横方向にくっつけたものになります。注意すべき点としては各ベクトルの長さが一致している点です。myDFの場合、4つのベクトルで構成されていますが、全てのベクトルの長さは4です。むろん、長さが異なる場合もデータフレームは作成できます。この場合、長さが足りないベクトルは最も長さが長いベクトルに合わせて繰り返されます。例としてmyDF4を作ってみましょう。\n\nmyDF4 &lt;- data.frame(\n    ID   = 1:4,\n    Name = c(\"Yanai\", \"Song\", \"Shigemura\", \"Tani\"),\n    Math = c(50, 90, 100, 80),\n    Stat = c(25, 5, 100, 85),\n    City = \"Kobe\",\n    Food = c(\"Ramen\", \"Udon\")\n    )\n\nmyDF4\n\n  ID      Name Math Stat City  Food\n1  1     Yanai   50   25 Kobe Ramen\n2  2      Song   90    5 Kobe  Udon\n3  3 Shigemura  100  100 Kobe Ramen\n4  4      Tani   80   85 Kobe  Udon\n\n\nCity列はすべて\"Kobe\"が入り、Food列は長さが足りない3, 4番目の要素に1, 2番目の要素が代入されます。実際はあまり使わない使い方ですが、ある列の要素が全て同じ場合、このような使い方をすることがあります。\n\n\n10.4.2 データフレームの操作\nデータフレームの大きさ\n行列と同様、dim()から行と列の数を、nrow()からは行数を、ncol()から列数を計算することができます。\n\ndim(myDF4)\n\n[1] 4 6\n\nnrow(myDF4)\n\n[1] 4\n\nncol(myDF4)\n\n[1] 6\n\n\n要素の抽出\nまず、データフレーム内要素の抽出についてですが、行列型と同じやり方で問題ありません。つまり、[行番号, 列番号]で要素の抽出が可能です。これに加え、データフレームには$を使った抽出方法があります。\nまず、行列と同じやり方でmyDF4の2行目、6列目の要素を抽出してみましょう。\n\nmyDF4[2, 6]\n\n[1] \"Udon\"\n\n\n行を丸ごと抽出したい場合は、列を指定しません。myDF4の3, 4行目を抽出してみましょう。\n\nmyDF4[3:4, ] # myDF4[c(3, 4), ]も同じ\n\n  ID      Name Math Stat City  Food\n3  3 Shigemura  100  100 Kobe Ramen\n4  4      Tani   80   85 Kobe  Udon\n\n\n同じやり方で列を抽出すことも可能です。好きな食べ物 (Food)列を抽出してみましょう。\n\nmyDF4[, 6]\n\n[1] \"Ramen\" \"Udon\"  \"Ramen\" \"Udon\" \n\n\n列を抽出する場合は、列名を指定することも可能です。やり方は[, \"列名\"]による方法、$列名による方法があります。Name列を抽出してみましょう。\n\nmyDF4[, \"Name\"]\n\n[1] \"Yanai\"     \"Song\"      \"Shigemura\" \"Tani\"     \n\nmyDF4$Name\n\n[1] \"Yanai\"     \"Song\"      \"Shigemura\" \"Tani\"     \n\n\nどれも同じ結果が返されます。後者の方が簡単ですが、一つの列しか抽出できない限界があります。それに比べ、前者はc()を使うことで複数の列を同時に抽出することも可能です。それぞれの場面に応じて使い分けていきましょう。\nまた、$で列を抽出した場合、抽出されたものはベクトル扱いになるため、[]を使った要素の抽出が可能です。例えばmyDF4のName列の2番目の要素を抽出してみましょう。\n\nmyDF4$Name[2]\n\n[1] \"Song\"\n\n\nあまり意識する必要はありませんが、抽出後のデータ構造について簡単に説明します。データフレームから一部の要素を抽出した結果物は必ずしもデータフレームにはなりません。\n\n\n\n\n操作\n返されるデータ型\n\n\n\n\n1\n1行を抽出する\nデータフレーム\n\n\n2\n複数の行を抽出する\nデータフレーム\n\n\n3\n1列を抽出する\nベクトル\n\n\n4\n複数の列を抽出する\nデータフレーム\n\n\n\n注目するのは3番目の例ですが、これはRの最小単位がベクトルであり、データフレームもベクトルの集めだからです。データフレームは「縦」ベクトルを横に並べたものです。もし、行を抽出した場合、その要素は全て同じデータ型だとは限りません。実際、myDF4の3行目を抽出しても、中にはcharacter型とnumeric型と混在しています。しかし、一つの列のみを抽出した場合、全ての要素は必ず同じデータ型となるため、ベクトルとして扱うことが可能です。同様に、行列型の一列を抽出した場合も結果はベクトルとなります。ただし、行列は全ての要素がNAを除き、同じであるため、一行を抽出しても結果はベクトル型となります。\nセルの修正\n特定のセルの修正する方法は簡単です。先ほど、データフレームから一つのセルを取り出すにはデータフレーム名[行番号, 列番号]だけでした。そのセルを修正するにはベクトルと同様、データフレーム名[行番号, 列番号] &lt;- 新しい値のように入力します。\nたとえば、重村さんが数学試験で不正が発覚し、0点になるとします。そのためには、myDF4の3行・3列目の要素を0に修正する必要がありますが、以下のようなコマンドで修正可能です。\n\nmyDF4[3, 3] &lt;- 0\nmyDF4\n\n  ID      Name Math Stat City  Food\n1  1     Yanai   50   25 Kobe Ramen\n2  2      Song   90    5 Kobe  Udon\n3  3 Shigemura    0  100 Kobe Ramen\n4  4      Tani   80   85 Kobe  Udon\n\n\nちゃんと重村さんの数学点数が0点になりました。ざまあみろですね！\nもう一つのやり方としては、一旦、列を取り出し、ベクトルにおける要素の置換操作を行う方法です。矢内大先生が神戸から離れ、高知県へ移住し、小物の宋は京都へ移住したとします。myDF4のCity列の1・2番目要素をc(\"Kochi\", \"Kyoto\")に修正する必要があります。そのためには以下のように入力します。\n\nmyDF4$City[c(1, 2)] &lt;- c(\"Kochi\", \"Kyoto\")\nmyDF4\n\n  ID      Name Math Stat  City  Food\n1  1     Yanai   50   25 Kochi Ramen\n2  2      Song   90    5 Kyoto  Udon\n3  3 Shigemura    0  100  Kobe Ramen\n4  4      Tani   80   85  Kobe  Udon\n\n\n修正した要素が反映されました。\n列の追加・修正\nまずは、データフレームに列を追加する方法について紹介します。方法は\nデータフレーム名$新しい列名 &lt;- ベクトル\nのように入力するだけです。たとえば、4人を対象に英語試験を行い、それぞれの点数が95点、50点、80点、5点だとします。この英語試験の成績をmyDF4のEnglish列として追加してみましょう。\n\nmyDF4$English &lt;- c(95, 50, 80, 5)\n\nむろん、以下のように予めベクトルを作成してから代入することも可能です。\nEnglish_Score &lt;- c(95, 50, 80, 5)\nmyDF4$English &lt;- English_Score\nどれも同じ結果になりますが、結果を見てみましょう。\n\nmyDF4\n\n  ID      Name Math Stat  City  Food English\n1  1     Yanai   50   25 Kochi Ramen      95\n2  2      Song   90    5 Kyoto  Udon      50\n3  3 Shigemura    0  100  Kobe Ramen      80\n4  4      Tani   80   85  Kobe  Udon       5\n\n\n「EnglishがStatの次じゃなくて気持ち悪い！」と思う方もいるかも知れませんが、列順番の変更については第13章で解説します。まずは、これで我慢しましょう。\n次は、列の置換についてです。実はよく考えてみるとこれは列の追加と全く同じです。たとえば、英語試験において配点が5点の問題にミスが見つかり、全生徒の英語成績に5点を上乗せるとします。そのためにはベクトルmyDF4$Englishの全ての要素に5を足し、それをもう一回myDf4$Englishに代入すれば良いです。\n\nmyDF4$English &lt;- myDF4$English + 5\nmyDF4\n\n  ID      Name Math Stat  City  Food English\n1  1     Yanai   50   25 Kochi Ramen     100\n2  2      Song   90    5 Kyoto  Udon      55\n3  3 Shigemura    0  100  Kobe Ramen      85\n4  4      Tani   80   85  Kobe  Udon      10\n\n\nこれでEnglish列の修正ができました。\n行の追加・修正はなるべくしない\n行の追加はなるべくしない方が良いです。その理由について考えてみましょう。今は4人の生徒のデータがありますが、ここにもう一人の生徒のデータを追加するとします。そのためにはmyDF4の5行目に生徒のID、名前、数学・統計学の成績、居住地域、好きな食べ物、英語の成績を入れれば良いでしょう。新しい学生、吐合さんの数学・統計学・英語成績は50, 50, 50点、居住地域は芦屋、好きな食べ物は二郎だとします。早速追加してみましょう。\n\nmyDF4[5, ] &lt;- c(5, \"Hakiai\", 50, 50, \"Ashiya\", \"Jiro\", 50)\nmyDF4\n\n  ID      Name Math Stat   City  Food English\n1  1     Yanai   50   25  Kochi Ramen     100\n2  2      Song   90    5  Kyoto  Udon      55\n3  3 Shigemura    0  100   Kobe Ramen      85\n4  4      Tani   80   85   Kobe  Udon      10\n5  5    Hakiai   50   50 Ashiya  Jiro      50\n\n\n問題なく吐合さんのデータが追加されたように見えますが、実は問題があります。myDF4のStat列を取り出して見ましょう。\n\nmyDF4$Stat\n\n[1] \"25\"  \"5\"   \"100\" \"85\"  \"50\" \n\n\n異常に気づきましたか。それではこのベクトルのデータ型を確認してみましょう。\n\nclass(myDF4$Stat)\n\n[1] \"character\"\n\n\n元々はnumeric型であるはずのStat列がcharacter型になりました。その理由は明白です。ベクトルの要素は全て同じデータ型だからです。そして、numericとcharacter型が混在している場合は、自動的に（優先順位の高い）character型になります。以下の2つのコマンドが同じであることは理解できるでしょう。\n# Case 1\nmyDF4[5, ] &lt;- c(5, \"Hakiai\", 50, 50, \"Ashiya\", \"Jiro\", 50)\n\n# Case 2\nHakiai_Data &lt;- c(5, \"Hakiai\", 50, 50, \"Ashiya\", \"Jiro\", 50)\nmyDF4[5, ]  &lt;- Hakiai_Data\nここのベクトルHakiai_Dataが強制的にcharacter型になるため、myDF4の5行目の要素は全てcharacter型になります。また、データフレームは縦ベクトルを横に並べたものであるなら、myDF4$Math列にcharacter型の要素が追加されることによって、列も全てcharacter型になってしまいます。したがって、データフレームにcharacter型とnumeric型が混在している状況において新しい行の追加は全ての要素をcharacter型に変えてしまうのです。むろん、データフレームの全要素がnumeric型であれば、このような問題は生じますが、numeric型のみで構成されたデータフレームはなかなかないでしょう。\n5行目を消しても問題は解決しないので、結局は列のデータ型を強制的に変更する必要があります。\n\nmyDF4$ID      &lt;- as.numeric(myDF4$ID)\nmyDF4$Math    &lt;- as.numeric(myDF4$Math)\nmyDF4$Stat    &lt;- as.numeric(myDF4$Stat)\nmyDF4$English &lt;- as.numeric(myDF4$English)\n\nclass(myDF4$Math)\n\n[1] \"numeric\"\n\n\nこれでやっと元通りになりましたね。\nどうしても行を追加したい場合は、以下のようなやり方もありますが、おすすめはできません。\n\nmyDF4[6, ] &lt;- rep(NA, 7) # myDF4の6行目を追加し、7つの欠損値を代入\n\nmyDF4$ID[6]      &lt;- 6           # myDF4$IDの6番目の要素に6を代入\nmyDF4$Name[6]    &lt;- \"Yukawa\"    # myDF4$Nameの6番目の要素にYukawaを代入\nmyDF4$Math[6]    &lt;- 80          # 以下、省略\nmyDF4$Stat[6]    &lt;- 30\nmyDF4$City[6]    &lt;- \"Hiroshima\"\nmyDF4$Food[6]    &lt;- \"Ramen\"\nmyDF4$English[6] &lt;- 90\n\nmyDF4\n\n  ID      Name Math Stat      City  Food English\n1  1     Yanai   50   25     Kochi Ramen     100\n2  2      Song   90    5     Kyoto  Udon      55\n3  3 Shigemura    0  100      Kobe Ramen      85\n4  4      Tani   80   85      Kobe  Udon      10\n5  5    Hakiai   50   50    Ashiya  Jiro      50\n6  6    Yukawa   80   30 Hiroshima Ramen      90\n\nclass(myDF4$English)\n\n[1] \"numeric\"\n\n\n欠損値 (NA)はどのようなデータ型にも対応できる特徴を利用すれば、このような操作も可能ですが、かなり面倒です。そもそも実際の分析において任意の行を追加することは滅多にないはずです。\n\n\n10.4.3 tibble型\ndata.frameに似ているデータ型としてtibbleがあります。これはR内蔵のデータ型ではありませんが、Rの必須パッケージとも言えるtidyverse内に含まれているデータ型であり、これからもどんどん普及していくでしょう。tibbleとdata.frameの違いを説明するために、同じデータをそれぞれのデータ型で読み込んでみましょう。\nとりあえずread.csv()で読み込み、VoteDF1と名付けましょう。\n\nVoteDF1 &lt;- read.csv(\"Data/Vote.csv\")\n\n続いてVoteDF1をas_tibble()関数を使ってtibble型にし、VoteDF2と名付けます。そして、それぞれのデータ構造を確認してみます。\n\nVoteDF2 &lt;- as_tibble(VoteDF1)\n\nclass(VoteDF1)\n\n[1] \"data.frame\"\n\nclass(VoteDF2)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n全く同じデータですが、VoteDF2にはtblとtbl_dfというクラスが追加されていることが分かります。それではデータの中身を覗いてみましょう。まずは、data.frame型から\n\nVoteDF1\n\n   ID     Pref  Zaisei Over65 Under30   LDP   DPJ Komei Ishin   JCP   SDP\n1   1   北海道 0.41903  29.09   24.70 32.82 30.62 13.41  3.43 11.44  1.68\n2   2   青森県 0.33190  30.14   23.92 40.44 24.61 12.76  3.82  8.92  3.41\n3   3   岩手県 0.34116  30.38   24.48 34.90 22.44  8.61  5.16 11.24  5.29\n4   4   宮城県 0.59597  25.75   27.29 36.68 25.40 13.42  3.97  9.99  3.62\n5   5   秋田県 0.29862  33.84   21.35 43.46 22.72 11.19  5.17  7.56  5.12\n6   6   山形県 0.34237  30.76   24.75 42.49 21.47 11.78  4.30  7.60  5.20\n7   7   福島県 0.50947  28.68   25.23 33.82 28.31 10.96  3.43 10.45  3.24\n8   8   茨城県 0.63309  26.76   26.60 40.64 18.95 15.05  6.67 10.07  2.88\n9   9   栃木県 0.62166  25.87   26.78 38.78 21.63 12.42 10.88  7.00  2.05\n10 10   群馬県 0.60277  27.60   26.59 42.06 19.31 13.85  5.61 10.00  2.44\n11 11   埼玉県 0.76548  24.82   27.66 32.30 20.40 16.00  7.23 13.94  1.91\n12 12   千葉県 0.77694  25.86   26.71 37.79 21.70 13.98  5.46 11.34  2.01\n13 13   東京都 1.00321  22.67   27.39 34.37 19.76 11.44  7.34 14.21  2.82\n14 14 神奈川県 0.91745  23.86   27.84 34.92 21.49 12.18  7.77 12.46  2.79\n15 15   新潟県 0.43519  29.86   25.23 43.66 25.25  8.27  4.39  8.00  3.76\n16 16   富山県 0.45307  30.54   24.88 44.16 24.22  9.81  5.06  5.79  5.02\n17 17   石川県 0.46812  27.87   27.25 48.09 18.54 11.00  6.36  7.07  2.36\n18 18   福井県 0.37820  28.63   26.70 45.29 17.52 10.91 13.09  5.66  2.09\n19 19   山梨県 0.37876  28.41   26.37 37.36 28.04 12.83  4.32  9.20  1.67\n20 20   長野県 0.47586  30.06   25.52 35.27 27.69 10.70  4.23 12.61  3.59\n21 21   岐阜県 0.52358  28.10   27.22 39.71 23.62 12.33  5.51  9.41  1.98\n22 22   静岡県 0.70999  27.79   26.28 37.47 24.13 12.68  7.99  9.59  2.22\n23 23   愛知県 0.92052  23.79   29.44 34.32 29.27 11.67  6.41  9.55  2.14\n24 24   三重県 0.57544  27.90   26.74 33.67 34.23 13.07  5.09  7.59  1.76\n25 25   滋賀県 0.53932  24.15   29.96 37.85 22.25  9.57 12.82 11.44  1.41\n26 26   京都府 0.56713  27.51   27.76 31.18 19.93 12.25 11.16 18.50  1.55\n27 27   大阪府 0.74980  26.15   27.55 22.12  9.30 16.39 34.86 11.37  1.25\n28 28   兵庫県 0.62062  27.09   26.94 31.71 15.84 15.37 19.50 10.30  2.01\n29 29   奈良県 0.41269  28.70   26.86 33.51 18.41 13.44 18.94  9.17  1.66\n30 30 和歌山県 0.31955  30.89   25.08 39.61 12.10 18.00 13.51 10.43  1.23\n31 31   鳥取県 0.25486  29.71   25.86 41.62 20.93 16.71  5.98  7.14  2.56\n32 32   島根県 0.24170  32.48   24.59 48.24 19.14 13.43  4.75  7.50  2.51\n33 33   岡山県 0.50096  28.66   27.44 37.87 19.91 17.18 10.67  7.87  1.60\n34 34   広島県 0.58581  27.53   27.46 39.93 18.53 15.20  9.69  8.52  2.35\n35 35   山口県 0.42560  32.07   24.91 46.75 17.27 16.50  5.31  7.39  1.78\n36 36   徳島県 0.32018  30.95   24.31 38.44 17.72 16.87  9.46  9.10  1.81\n37 37   香川県 0.46060  29.93   25.29 44.07 16.60 15.14  6.20  7.56  5.07\n38 38   愛媛県 0.41181  30.62   24.75 43.57 19.28 14.82  6.77  6.97  2.40\n39 39   高知県 0.24472  32.85   23.60 37.01 16.95 15.83  3.93 17.41  2.91\n40 40   福岡県 0.61836  25.90   28.21 36.52 19.08 17.15  7.03 10.78  3.33\n41 41   佐賀県 0.32938  27.68   27.97 43.53 21.10 15.48  4.85  5.67  4.16\n42 42   長崎県 0.31562  29.60   25.84 41.70 20.68 16.86  5.12  6.27  3.48\n43 43   熊本県 0.38688  28.78   27.18 46.54 19.29 15.27  4.53  6.32  2.60\n44 44   大分県 0.35828  30.45   25.65 39.44 18.37 13.26  4.42  6.85 13.05\n45 45   宮崎県 0.32034  29.49   26.26 40.11 14.50 17.11  5.74  7.27  6.81\n46 46 鹿児島県 0.32140  29.43   26.04 45.97 16.19 14.49  6.47  6.52  3.62\n47 47   沖縄県 0.31535  19.63   33.37 27.82 13.29 15.09  7.66 15.64 12.13\n\n\nつづいて、tibble型\n\nVoteDF2\n\n# A tibble: 47 × 11\n      ID Pref   Zaisei Over65 Under30   LDP   DPJ Komei Ishin   JCP   SDP\n   &lt;int&gt; &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1     1 北海道  0.419   29.1    24.7  32.8  30.6 13.4   3.43 11.4   1.68\n 2     2 青森県  0.332   30.1    23.9  40.4  24.6 12.8   3.82  8.92  3.41\n 3     3 岩手県  0.341   30.4    24.5  34.9  22.4  8.61  5.16 11.2   5.29\n 4     4 宮城県  0.596   25.8    27.3  36.7  25.4 13.4   3.97  9.99  3.62\n 5     5 秋田県  0.299   33.8    21.4  43.5  22.7 11.2   5.17  7.56  5.12\n 6     6 山形県  0.342   30.8    24.8  42.5  21.5 11.8   4.3   7.6   5.2 \n 7     7 福島県  0.509   28.7    25.2  33.8  28.3 11.0   3.43 10.4   3.24\n 8     8 茨城県  0.633   26.8    26.6  40.6  19.0 15.0   6.67 10.1   2.88\n 9     9 栃木県  0.622   25.9    26.8  38.8  21.6 12.4  10.9   7     2.05\n10    10 群馬県  0.603   27.6    26.6  42.1  19.3 13.8   5.61 10     2.44\n# ℹ 37 more rows\n\n\n同じデータですが、表示画面がやや異なります。data.frameは全ての列と行が表示されましたが、tibbleの場合、「画面に収まる」程度しか表示されません。表示されなかった行や列に関しては最後に表示されています。たとえば、VoteDF2の場合、下段にこのように書かれていますね (画面の大きさによって変わります)。\n## # … with 37 more rows, and 1 more variable: SDP &lt;dbl&gt;\nこれは表示されなかった行が37行あり、SDPという変数も表示されていないということです。他の違いとしては、tibbleの場合、最初にデータのサイズ (47行11列)が、各変数名の下にデータ型 (&lt;int&gt;、&lt;chr&gt;、&lt;dbl&gt;など)が表示されるという点です。\n本書はtibbleとdata.frameを区別して解説はしませんが、一部の章・節においてはtibbleを念頭において解説をします。tibble型の作り方は先ほどのようにas_tibble()使う方法もありますが、readr::read_csv()を使う方法もあります5。read_csv()を使うと各列がどのようなデータ型として読み込まれたかも表示されるので便利です。readrパッケージはtidyverseに含まれているため、普段では以下のような使い方で十分です。\n\nVoteDF3 &lt;- read_csv(\"Data/Vote.csv\")\n\nRows: 47 Columns: 11\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Pref\ndbl (10): ID, Zaisei, Over65, Under30, LDP, DPJ, Komei, Ishin, JCP, SDP\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nclass(VoteDF3) # VoteDF3の構造\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\ntibbleとdata.frameの最も大きな違いは、data.frameの一つのセルには長さ1のベクトルしか入らない一方、tibbleは何でも入るという点です。つまり、tibbleなら一つのセルに数字や文字列だけでなく、長さ2以上のベクトル、後述するリスト型、行列、さらにはtibbleも入れることが出来ます。これについては本書の中盤以降に解説します。\n本書で「データフレーム」と書いた場合、それはtibbleでも適用可能です。ただし、tibbleと明示した場合、データフレームでは適用不可能です。"
  },
  {
    "objectID": "datastructure.html#sec-datastructure_list",
    "href": "datastructure.html#sec-datastructure_list",
    "title": "10  データ構造",
    "section": "10.5 リスト (list)",
    "text": "10.5 リスト (list)\nリスト型は「様々なデータ構造を集めたもの」です。これは複数のデータフレームが格納されたオブジェクト、複数のベクトルが格納されたオブジェクト、行列とデータフレームが混在したオブジェクトなどを意味します。また、リスト型データはリスト型データを含むことも可能であり、非常に柔軟なデータ構造です。\n\n10.5.1 リスト型データの作成\nここではまず、2つのデータフレームを含むリストを作成してみます。それぞれのデータフレームはFIFA国別サッカーランキングであり6、本書のサンプルデータのFIFA_Women.csvとFIFA_Men.csvです。まずは、2つのデータを読み込み、Soccer_WとSoccer_Mという名のオブジェクトに格納しましょう。また、ここでは単に例を見せるだけなので、全データを利用するのではなく、最初の10行のみを利用します。\n\nSoccer_W &lt;- read.csv(\"Data/FIFA_Women.csv\")\nSoccer_M &lt;- read.csv(\"Data/FIFA_Men.csv\")\n\nSoccer_W &lt;- Soccer_W[1:10, ]\nSoccer_M &lt;- Soccer_M[1:10, ]\n\nリストの作成にはlist()関数に入れたいオブジェクト名を指定するだけです。それではList1という名前でSoccer_WとSoccer_Mデータフレームを入れてみましょう。格納後はList1のデータ構造をclass()で確認します\n\nList1 &lt;- list(Soccer_W, Soccer_M)\nclass(List1)\n\n[1] \"list\"\n\nList1\n\n[[1]]\n   ID                Team Rank Points Prev_Points Confederation\n1   1             Albania   75   1325        1316          UEFA\n2   2             Algeria   85   1271        1271           CAF\n3   3      American Samoa  133   1030        1030           OFC\n4   4             Andorra  155    749         749          UEFA\n5   5              Angola  121   1117        1117           CAF\n6   6 Antigua and Barbuda  153    787         787      CONCACAF\n7   7           Argentina   32   1659        1659      CONMEBOL\n8   8             Armenia  126   1103        1104          UEFA\n9   9               Aruba  157    724         724      CONCACAF\n10 10           Australia    7   1963        1963           AFC\n\n[[2]]\n   ID                Team Rank Points Prev_Points Confederation\n1   1         Afghanistan  149   1052        1052           AFC\n2   2             Albania   66   1356        1356          UEFA\n3   3             Algeria   35   1482        1482           CAF\n4   4      American Samoa  192    900         900           OFC\n5   5             Andorra  135   1082        1082          UEFA\n6   6              Angola  124   1136        1136           CAF\n7   7            Anguilla  210    821         821      CONCACAF\n8   8 Antigua and Barbuda  126   1127        1127      CONCACAF\n9   9           Argentina    9   1623        1623      CONMEBOL\n10 10             Armenia  102   1213        1213          UEFA\n\n\n一つのオブジェクトに2つのデータフレームが入っていますね。これは2つのデータフレームで構成された長さ2のリストです。ただし、どちらが女性ランキングで、どちらが男子ランキングか区別が難しいです。この場合、各データフレームに名前を付けることも可能です。\n\nList2 &lt;- list(Women = Soccer_W, Men = Soccer_M)\nList2\n\n$Women\n   ID                Team Rank Points Prev_Points Confederation\n1   1             Albania   75   1325        1316          UEFA\n2   2             Algeria   85   1271        1271           CAF\n3   3      American Samoa  133   1030        1030           OFC\n4   4             Andorra  155    749         749          UEFA\n5   5              Angola  121   1117        1117           CAF\n6   6 Antigua and Barbuda  153    787         787      CONCACAF\n7   7           Argentina   32   1659        1659      CONMEBOL\n8   8             Armenia  126   1103        1104          UEFA\n9   9               Aruba  157    724         724      CONCACAF\n10 10           Australia    7   1963        1963           AFC\n\n$Men\n   ID                Team Rank Points Prev_Points Confederation\n1   1         Afghanistan  149   1052        1052           AFC\n2   2             Albania   66   1356        1356          UEFA\n3   3             Algeria   35   1482        1482           CAF\n4   4      American Samoa  192    900         900           OFC\n5   5             Andorra  135   1082        1082          UEFA\n6   6              Angola  124   1136        1136           CAF\n7   7            Anguilla  210    821         821      CONCACAF\n8   8 Antigua and Barbuda  126   1127        1127      CONCACAF\n9   9           Argentina    9   1623        1623      CONMEBOL\n10 10             Armenia  102   1213        1213          UEFA\n\n\nこれでどれが女性ランキングか、男性ランキングかが区別しやすくなりました。ここでは2つのデータフレームを入れましたが、様々なデータ構造が混在したリストも可能です。様々なデータ構造が混在したリストを自分で作成する場面はあまりありません。自分で作成した独自クラスを利用するパッケージを開発する際はよく使いますが、ここでは省略します。ただし、様々なデータ構造が含まれたリスト型を見ることはよくあります。たとえば、lm()関数で回帰分析を行った際、その結果はリスト型であり、中にはベクトル、データフレーム、リストなどが混在しています。これについては今後詳細に解説していきたいと思います。\n\n\n10.5.2 リスト型データの操作\nリスト型の中身は何でもあり得るので、なんらかの操作方法があるわけではありません。リスト型の操作というのはリスト内の要素をどのように抽出するかであり、各要素 (データフレーム、行列、ベクトルなど)の操作はこれまで説明してきた方法と同じです。したがって、ここではリストを構成する要素を抽出する方法についてのみ解説します。\n要素の番号を利用する方法\nList1は各要素に名前が付いていないため、番号で抽出します。たとえば、あるリストのi番目の要素を抽出するにはリスト名[[i]]で抽出します。[]ではなく、[[]]であることに注意してください。それではList1の1番目の要素を抽出してみましょう。\n\nList1[[1]]\n\n   ID                Team Rank Points Prev_Points Confederation\n1   1             Albania   75   1325        1316          UEFA\n2   2             Algeria   85   1271        1271           CAF\n3   3      American Samoa  133   1030        1030           OFC\n4   4             Andorra  155    749         749          UEFA\n5   5              Angola  121   1117        1117           CAF\n6   6 Antigua and Barbuda  153    787         787      CONCACAF\n7   7           Argentina   32   1659        1659      CONMEBOL\n8   8             Armenia  126   1103        1104          UEFA\n9   9               Aruba  157    724         724      CONCACAF\n10 10           Australia    7   1963        1963           AFC\n\n\nこのようにList1内の1番目のデータが抽出されました。こちらのデータ構造は何でしょうか。\n\nclass(List1[[1]])\n\n[1] \"data.frame\"\n\n\n既に予想したかと思いますが、データフレームとして抽出されました。ここから更に、3行目のデータを抽出するには、[[]]の後に[3, ]を付けます。\n\nList1[[1]][3, ]\n\n  ID           Team Rank Points Prev_Points Confederation\n3  3 American Samoa  133   1030        1030           OFC\n\n\n先ほどリストの要素の抽出には「[]でなく、[[]]です」と申しましたが、実は[]も使用可能です。やってみましょう。\n\nList1[1]\n\n[[1]]\n   ID                Team Rank Points Prev_Points Confederation\n1   1             Albania   75   1325        1316          UEFA\n2   2             Algeria   85   1271        1271           CAF\n3   3      American Samoa  133   1030        1030           OFC\n4   4             Andorra  155    749         749          UEFA\n5   5              Angola  121   1117        1117           CAF\n6   6 Antigua and Barbuda  153    787         787      CONCACAF\n7   7           Argentina   32   1659        1659      CONMEBOL\n8   8             Armenia  126   1103        1104          UEFA\n9   9               Aruba  157    724         724      CONCACAF\n10 10           Australia    7   1963        1963           AFC\n\n\n[[]]を使った抽出とあまり変わらないですね。しかし、重要な違いが一つあります。それはデータ構造です。\n\nclass(List1[1])\n\n[1] \"list\"\n\n\n[]で抽出したリストの要素のデータ構造もまたリスト型です。この場合、先ほどのように[x, ]を使って、x行目のデータを抽出することはできません。なぜなら、[行, 列]による要素の抽出はデータフレームのためのものであって、リスト型のためのものではないからです。\n\nList1[1][3, ]\n\nError in List1[1][3, ]: incorrect number of dimensions\n\n\nこのようにエラーが表示されます。\n要素の名前を利用する方法\nList2のようにリストの要素に名前を付けた場合、これまでの方法に加え[[\"要素名\"]]と$要素名を使った操作が可能です7。List2から男子ランキング (Men)を抽出してみましょう。\n\nList2[[\"Men\"]]\n\n   ID                Team Rank Points Prev_Points Confederation\n1   1         Afghanistan  149   1052        1052           AFC\n2   2             Albania   66   1356        1356          UEFA\n3   3             Algeria   35   1482        1482           CAF\n4   4      American Samoa  192    900         900           OFC\n5   5             Andorra  135   1082        1082          UEFA\n6   6              Angola  124   1136        1136           CAF\n7   7            Anguilla  210    821         821      CONCACAF\n8   8 Antigua and Barbuda  126   1127        1127      CONCACAF\n9   9           Argentina    9   1623        1623      CONMEBOL\n10 10             Armenia  102   1213        1213          UEFA\n\nList2$Men\n\n   ID                Team Rank Points Prev_Points Confederation\n1   1         Afghanistan  149   1052        1052           AFC\n2   2             Albania   66   1356        1356          UEFA\n3   3             Algeria   35   1482        1482           CAF\n4   4      American Samoa  192    900         900           OFC\n5   5             Andorra  135   1082        1082          UEFA\n6   6              Angola  124   1136        1136           CAF\n7   7            Anguilla  210    821         821      CONCACAF\n8   8 Antigua and Barbuda  126   1127        1127      CONCACAF\n9   9           Argentina    9   1623        1623      CONMEBOL\n10 10             Armenia  102   1213        1213          UEFA\n\n\nどれも結果は同じです。また、それぞれのデータ構造もデータフレームです。\n\nclass(List2[[\"Men\"]])\n\n[1] \"data.frame\"\n\nclass(List2$Men)\n\n[1] \"data.frame\"\n\n\nしたがって、[行番号, 列番号]のようにデータフレームの操作が可能です。Men要素から10行目のデータを抽出してみましょう。\n\nList2[[\"Men\"]][10, ]\n\n   ID    Team Rank Points Prev_Points Confederation\n10 10 Armenia  102   1213        1213          UEFA\n\nList2$Men[10, ]\n\n   ID    Team Rank Points Prev_Points Confederation\n10 10 Armenia  102   1213        1213          UEFA\n\n\nもちろん、名前を付けた場合であっても、要素の番号を利用した操作も可能です。自分でリスト型を作成する際には各要素に名前を付けた方が分かりやすくて良いでしょう。"
  },
  {
    "objectID": "datastructure.html#sec-datastructure_array",
    "href": "datastructure.html#sec-datastructure_array",
    "title": "10  データ構造",
    "section": "10.6 配列 (array)",
    "text": "10.6 配列 (array)\n配列は行列の拡張版であり、行列は配列の特殊な形です。これまでのRでは行列と配列は区別されてきましたが、R 4.0.0以降、行列は配列の属するデータ構造となりました。\n配列型は簡単にいうと、同じサイズの行列を数枚重ねたものです。 図 10.1 は配列型のイメージを表したものです。\n\n\n\n図 10.1: 配列型データのイメージ\n\n\nしたがって、配列型は行と列以外にも、層の要素も持つことになります。複数の行列で構成されている点では、リスト型と類似していますが、配列型は同じサイズの行列のみで構成されている点が特徴です。\n配列型は普段、扱う機会があまりありませんが、マルコフ連鎖モンテカルロ法 (MCMC)でベイジアン推定を行った後の事後分布データは配列型で格納される場合があります。\n\n10.6.1 配列型データの作成\n各行列は3行4列とし、4層構造とします。まずは、同じサイズの行列を作成し、それぞれMat1、Mat2、Mat3、Mat4と名付けます。\n\nMat1 &lt;- matrix(sample(1:12, 12, replace = TRUE), byrow = TRUE, nrow = 3)\nMat2 &lt;- matrix(sample(1:12, 12, replace = TRUE), byrow = TRUE, nrow = 3)\nMat3 &lt;- matrix(sample(1:12, 12, replace = TRUE), byrow = TRUE, nrow = 3)\nMat4 &lt;- matrix(sample(1:12, 12, replace = TRUE), byrow = TRUE, nrow = 3)\n\nsample()関数は初めてですね。これは与えられたベクトルの要素から無作為に要素を抽出する関数です。sample(1:12, n)ならc(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11,1 2)から無作為にn個の要素を抽出するという意味です。replace = TRUEを指定すると、反復抽出、つまり、一回抽出された要素であっても抽出される可能性があることを意味します。デフォルトはFALSEですが、この場合、一旦抽出された要素は二度と抽出されません。それではそれぞれの行列の中身を見てみましょう。\n\nMat1\n\n     [,1] [,2] [,3] [,4]\n[1,]   11    2    8    4\n[2,]    1   11    5    3\n[3,]   12    1    6    1\n\nMat2\n\n     [,1] [,2] [,3] [,4]\n[1,]    5   12    4    5\n[2,]    6    3    7    5\n[3,]   12    5    4    3\n\nMat3\n\n     [,1] [,2] [,3] [,4]\n[1,]   12    8   10    9\n[2,]    9    1    4    6\n[3,]    3    1    1    2\n\nMat4\n\n     [,1] [,2] [,3] [,4]\n[1,]    4    7   10   10\n[2,]    6    1   12    8\n[3,]    9    5    3    1\n\n\n配列型データを作成するにはarray()関数を使います。引数としては行列名をc()で繋ぎ8、dim =でarrayの大きさを指定するだけです。配列を作成した後はそのデータ構造も確認してみましょう。\n\nArray1 &lt;- array(c(Mat1, Mat2, Mat3, Mat4), dim = c(3, 4, 4))\nclass(Array1)\n\n[1] \"array\"\n\n\ndim = c(m, n, z)の部分ですが、これは「m行n列の行列がz枚重ねる」という意味です。今回は3行4列の行列を4枚重ねるのでdim = c(3, 4, 4)です。それではArray1の中身を見てみます。\n\nArray1\n\n, , 1\n\n     [,1] [,2] [,3] [,4]\n[1,]   11    2    8    4\n[2,]    1   11    5    3\n[3,]   12    1    6    1\n\n, , 2\n\n     [,1] [,2] [,3] [,4]\n[1,]    5   12    4    5\n[2,]    6    3    7    5\n[3,]   12    5    4    3\n\n, , 3\n\n     [,1] [,2] [,3] [,4]\n[1,]   12    8   10    9\n[2,]    9    1    4    6\n[3,]    3    1    1    2\n\n, , 4\n\n     [,1] [,2] [,3] [,4]\n[1,]    4    7   10   10\n[2,]    6    1   12    8\n[3,]    9    5    3    1\n\n\nこのように一つのオブジェクト内に複数の行列が格納されたオブジェクトが生成されます。\n\n\n10.6.2 配列型データの操作\n配列型データの操作は行列型に似ていますが、層というもう一つの次元があるため、行列名[行番号, 列番号]ではなく、配列名[行番号, 列番号, 層番号]を使います。たとえば、Array1の3番目の行列を抽出したい場合、Array1[, , 3]と入力します。\n\nArray1[, , 3]\n\n     [,1] [,2] [,3] [,4]\n[1,]   12    8   10    9\n[2,]    9    1    4    6\n[3,]    3    1    1    2\n\n\nまた、2番目の行列の3行目・1列目の要素を抽出するならArray1[3, 1, 2]と入力します。\n\nArray1[3, 1, 2]\n\n[1] 12\n\n\n配列型における操作の特徴の一つは全ての行列が同じ大きさを持つため、層を貫通した操作ができるという点です。たとえば、全ての層の2行目を抽出するなら、層番号を指定せず、行番号のみで抽出します。\n\nArray1[2, , ]\n\n     [,1] [,2] [,3] [,4]\n[1,]    1    6    9    6\n[2,]   11    3    1    1\n[3,]    5    7    4   12\n[4,]    3    5    6    8\n\n\nただ、返された結果は配列型でなく行列型であることに注意しましょう。たとえば、1番目の行列の2行目の要素は1, 11, 5, 3ですが、これは先ほど抽出された行列の1列目に該当します。また、2番目の行列の2行目の要素は6, 3, 7, 5であり、これは先ほどの抽出された行列の2列目となります。全層において特定の一列を抽出しても同じです。これは各層において抽出されたデータが行列でなく、ベクトルだからです。\n一方、複数の行または列を抽出した場合、結果は配列型です。Array1の各層から1・2行目と1・2列目の要素、つまり大きさが2 \\(\\times\\) 2の行列を抽出してみましょう。\n\nArray1[1:2, 1:2, ]\n\n, , 1\n\n     [,1] [,2]\n[1,]   11    2\n[2,]    1   11\n\n, , 2\n\n     [,1] [,2]\n[1,]    5   12\n[2,]    6    3\n\n, , 3\n\n     [,1] [,2]\n[1,]   12    8\n[2,]    9    1\n\n, , 4\n\n     [,1] [,2]\n[1,]    4    7\n[2,]    6    1\n\n\nこのように各層において抽出されたデータが行列だからです。自分の操作から得られた結果がどのようなデータ型・データ構造かを予め知っておくことで分析の効率が上がるでしょう。\n行列に名前を付けたい\n今回は各行列に1, 2, 3, 4という番号のみ割り当てましたが、実は行列に名前を付けることも可能です。そのためには配列データ作成時、dimnames =引数を指定する必要があります。\n\nArray2 &lt;- array(c(Mat1, Mat2, Mat3, Mat4), dim = c(3, 4, 4),\n                dimnames = list(NULL, \n                                NULL, \n                                c(\"M1\", \"M2\", \"M3\", \"M4\"))\n                )\n\ndimnames =引数は必ず長さ3のリスト型である必要があります。1番目と2番目の要素は行名と列名ですが、行列において一般的に使われないため、ここではNULLにし、3番目の要素、つまり各層の名前だけを指定します。ここではそれぞれの層をM1、M2、M3、M4と名付けました。ここでM4のみを抽出する場合は、以下のように操作します。\n\nArray2[, , \"M4\"]\n\n     [,1] [,2] [,3] [,4]\n[1,]    4    7   10   10\n[2,]    6    1   12    8\n[3,]    9    5    3    1\n\n\nむろん、これまでと同様、番号で抽出することも可能です。\n\nArray2[, , 4]\n\n     [,1] [,2] [,3] [,4]\n[1,]    4    7   10   10\n[2,]    6    1   12    8\n[3,]    9    5    3    1"
  },
  {
    "objectID": "programming.html#sec-programming_intro",
    "href": "programming.html#sec-programming_intro",
    "title": "11  Rプログラミングの基礎",
    "section": "11.1 R言語の基礎概念",
    "text": "11.1 R言語の基礎概念\n\n11.1.1 オブジェクト\n　これまで「オブジェクト」や「関数」などという概念を定義せずに使ってきたが、ここではR言語の構成する基本的な概念についてもう少し詳細に解説する。これらは、プログラミングをする上である程度は意識的に使う必要があるものである。\n　まず、オブジェクト (object) とはメモリに割り当てられた「何か」である。「何か」に該当するのは、ベクトル (vector)、行列 (matrix)、データフレーム (data frame)、リスト (list)、関数 (function) などである。一般的に、オブジェクトにはそれぞれ固有の（つまり、他のオブジェクトと重複しない）名前が付いている。\n　たとえば、1から5までの自然数の数列を\n\nmy_vec1 &lt;- c(1, 2, 3, 4, 5)  # my_vec1 &lt;- 1:5  でも同じ\n\nのようにmy_vec1という名前のオブジェクトに格納する。オブジェクトに名前をつけてメモリに割り当てると、その後 my_vec1 と入力するだけでそのオブジェクトの中身を読み込むことができるようになる。\n　ここで、次のように my_vec1の要素を2倍にする操作を考えてみよう。\n\nmy_vec1 * 2\n\n[1]  2  4  6  8 10\n\n\nmy_vec1は、先ほど定義したオブジェクトである。では2はどうだろうか。2はメモリに割り当てられていないので、オブジェクトではないのだろうか。実は、この数字 2 もオブジェクトである。計算する瞬間のみ2がメモリに割り当てられ、計算が終わったらメモリから消されると考えれば良い。「Rに存在するあらゆるものはオブジェクトである (Everything that exists in R is an object)」 (Chambers 2016)。* のような演算子でさえもオブジェクトである。\n\n\n11.1.2 クラス\n　クラス (class) とはオブジェクトを特徴づける属性である。既に何度か class() 関数を使ってデータ型やデータ構造を確認したが、class()関数でオブジェクトのクラスを確認することができる。先ほど、my_vec1も*も2もオブジェクトであると説明した。これらがすべてオブジェクトであるということは、何らかのクラス属性を持っているというこである。また、class()関数そのものもオブジェクトなので、何らかのクラスをもつ。確認してみよう。\n\nclass(my_vec1)\n\n[1] \"numeric\"\n\nclass(`*`)\n\n[1] \"function\"\n\nclass(2)\n\n[1] \"numeric\"\n\nclass(class)\n\n[1] \"function\"\n\n\n　統計分析をする際に、Rのクラスを意識することはあまりない。しかし、Rでパッケージを開発したり、複雑な関数を自作する場合、オブジェクト指向プログラミング (Object-oriented Programming; OOP) の考え方が重要で、オブジェクトのクラスを厳密に定義する必要がある5。\n　自分でパッケージを開発しないとしても、クラスの概念は知っておいたほうが良い。この後説明する関数には引数というものがあるが、引数には特定のクラスのオブジェクトしか指定できない。関数の使い方がわからないときには?関数名 でヘルプを表示するが、ヘルプには各引数に使うべきクラスが書かれている。クラスについて何も知らないと、ヘルプを読んでも意味がわからないかもしれない。\n　たとえば、Rコンソール上で?meanを入力して実行すると、 図 11.1 のような mean() 関数のヘルプが表示される。ヘルプに示されているとおり、mean()関数に必要な引数は x、trim、na.rmである。仮引数xの説明を読むと、x の実引数にはnumeric または logical のベクトルクラスが使えることが分かる。さらに、date、date-time、time interval が使えることも教えてくれる。\n\n\n\n図 11.1: mean()関数のヘルプ画面\n\n\n　回帰分析を行うlm()関数の場合、data という仮引数があるが、dataの実引数に指定できるのは data.frame クラスまたは tibbleクラスのオブジェクトである6。通常はクラスを意識せずにRを使っても問題ないが、\n\n全てのオブジェクトにはクラスが付与されており、\n関数 (の引数) ごとに実引数として使えるクラスが異なる\n\nという2点は覚えておこう。\n\n\n11.1.3 関数と引数\n　関数 (function) は、入力されたデータを内部で決められた手順に従って処理し、その結果を返すものである。「Rで起こるあらゆることは関数の呼び出しである (Everything that happens in R is a function call)」(Chambers 2016)。\n　関数は 関数名(関数の入力となるオブジェクト) のように使う。たとえば、class(my_vec1)はmy_vec1というオブジェクトのクラスを返す関数である。また、sum(my_vec1)はmy_vec1の要素の総和を計算して返す関数である。\n　関数は自分で作成することもできる（次章で説明する）。複雑な作業を繰り返す場合、その作業を関数として記述することで、一行でその作業を再現することが可能になる。「2度以上同じことを繰り返すなら関数を作れ」というのが、Rユーザの心得である。\n　関数を使うためには、 引数 (ひきすう) と呼ばれるものが必要である。例えば、sum() 関数はこれだけだと何もできない。何らかのオブジェクトがが入力として与えられないと、結果を返すことができない。sum(my_vec1)のようにすることではじめて結果が返される。ここでmy_vec1がsum()関数の引数である。\n　関数は引数は複数持つことができる。たとえば、欠測値を含む以下のmy_vec2を考えてみよう。\n\nmy_vec2 &lt;- c(1, 2, 3, NA, 5)\n\n　この数列の総和を sum()関数で求めようとすると、結果は欠測値 NA になる。\n\nsum(my_vec2)\n\n[1] NA\n\n\n　これはsum()の基本仕様が「入力に欠測値が含まれている場合は欠測値を返す」ことになっているためである。入力されたデータのなかで欠測値を除いたものの総和を求めるために、sum()はもう1つの引数が用意されている。それが na.rm である。na.rm = TRUEを指定すると、欠測値を除外した総和を返す。\n\nsum(my_vec2, na.rm = TRUE)\n\n[1] 11\n\n\n　第7章で説明したとおり、na.rm などのように引数を区別するために関数によって用意されたものを仮引数 (parameter) と呼び、TRUE のように引数の中身としてユーザが指定するものを実引数 (argument) と呼ぶ。my_vec2 は実引数である。\n　引数を指定するとき、my_vec2のように仮引数を明示しないこともある。多くの場合、それがなければ関数がそもそも動かないという第1引数の仮引数は明示しないことが多い。そもそも、第1引数には仮引数がない（名前がない）場合もある。sum() 関数の第1引数はnumeric または complex 型のベクトルだが、仮引数がそもそもない（... で定義されている）。\n　しかし、第1引数以外については、na.rm = TRUE のように仮引数を明示すべきである。関数によっては数十個の引数をとるものもあり、仮引数を明示しないと、どの実引数がどの仮引数に対応するのかわかりにくい。\n　多くの引数は関数によって定義された既定値 (default value) をもっている。たとえば、sum()関数の na.rm の既定値は FALSE である。既定値が用意されている場合、その引数を指定せずに関数を使うことができる。\n　ある関数がどのような引数を要求しているか、その既定値は何か、引数として何か決められたデータ型/データ構造があるかを調べたいときは ?関数名 （()がないことに注意）または help(関数名）をコンソールに入力する。多くの関数に詳細なヘルプが付いているので、ネットで検索したり、誰かに質問する前にひとまずヘルプを読むべきである。"
  },
  {
    "objectID": "programming.html#sec-programming_style",
    "href": "programming.html#sec-programming_style",
    "title": "11  Rプログラミングの基礎",
    "section": "11.2 Rのコーディングスタイル",
    "text": "11.2 Rのコーディングスタイル\n　Rコードの書き方に唯一の正解はない。文法が正しければ、つまり、Rが意図どおりの実行結果を出してくれさえすれば、それは「正しい」コードである。しかし、コードというのは、一度書けば二度と読まないというものではない。最初に「書く」とき以外に、「修正する」ときや「再利用」するときなどに繰り返し読むことになる。また、共同研究をする場合には共同研究者がコードを読む。さらに、近年では研究成果を報告する際に分析に利用したコードを後悔公開することも当たり前になりつつあり、その場合には自分で書いたコードを世界中の人が読む可能性がある。\n　ここで大事なのは、Rコードを読むのはRだけではないということである。人間も重要な「読者」である。Rコードを書くときは人間に優しいコードを書くように心がえよう。唯一の正解がなくても、読みやすく、多くの人が採用している標準的な書き方はある。ここでは、人間に優しいコードを書くためのコーディングスタイルについて説明しよう。\n\n11.2.1 オブジェクト名\n　ベクトル、データフレーム、自作の関数などのすべてのオブジェクトには名前をつける必要がある（ラムダ式などの無名関数を除く）。名前はある程度自由に付けることができるが、大事な原則がある。それは、\n\nオブジェクト名は英数字と限られた記号のみにする\n数字で始まる変数名は避ける\n\n1つ目は原則にすぎない。よって、日本語やハングルの変数名をつけることもできる。しかし、それは推奨しない。英数字以外（マルチバイト文字）は文字化けの可能性がある（文字コードの問題が発生する）し、コードを書く際列がずれる原因にもなる\n\nvar1 &lt;- c(2, 3, 5, 7, 11)      # 推奨\n\n\n変数1 &lt;- c(2, 3, 5, 7, 11)     # 非推奨\n\n\nvar1\n\n[1]  2  3  5  7 11\n\n\n\n変数1\n\n[1]  2  3  5  7 11\n\n\n　2つ目のルールは必ず守る必要がある。つまり、数字で始まるオブジェクト名は作成できない。\n\n100A &lt;- \"R\"\n\nError: &lt;text&gt;:1:4: unexpected symbol\n1: 100A\n       ^\n\n\n予約語を避ける\n　Rが提供する組込の関数やオブジェクトと重複する名前を自分で作成するオブジェクトに付けるのは避けよう。例えば、Rには円周率 (\\(\\pi\\)) がpiという名前で用意されている。\n\npi\n\n[1] 3.141593\n\n\npiという名前で新しい変数を作ることはできる。\n\npi  &lt;- 777\n\nしかし、既存のpiが上書きされてしまうので避けたほうが良い。\n\npi   # もはや円周率ではない\n\n[1] 777\n\n\n元の円周率を使うこともできるが、手間が増える。\n\nbase::pi\n\n[1] 3.141593\n\n\n　また、ユーザが自由に使えない名前もある。それらの名前を「予約語」と呼ぶ。予約語の使用は禁止されている。\n\nif  &lt;- \"YY\"\n\nError: &lt;text&gt;:1:5: unexpected assignment\n1: if  &lt;-\n        ^\n\n\n\nfor &lt;- \"JS\"\n\nError: &lt;text&gt;:1:5: unexpected assignment\n1: for &lt;-\n        ^\n\n\n\nTRUE &lt;- \"いつもひとつ！\"\n\nError in TRUE &lt;- \"いつもひとつ！\": invalid (do_set) left-hand side to assignment\n\n\nこのように、予約語はそもそも使えないので、それほど意識する必要はない。\n　ただし、以下のコードのようなことが起こるので注意してほしい。\n\nvals &lt;- 1:5\nvals[c(TRUE, TRUE, FALSE, FALSE, TRUE)]\n\n[1] 1 2 5\n\nvals[c(T, T, F, F, T)]\n\n[1] 1 2 5\n\n\nここから、T は TRUE、F は FALSE と同じ働きをしていることがわかる。ここで、次のコードを実行してみよう。\n\nT &lt;- \"Taylor\"\nF &lt;- \"Fourier\"\nvals[c(T, T, F, F, T)]\n\n[1] NA NA NA NA NA\n\n\nこのように、T とFはあらかじめ使える状態で用意されているものの、予約語ではないので値が代入できてしまう。しかし、T とF を自分で定義したオブジェクトの名前に使うと混乱の元になるので、使用は避けるのが無難である。\n　また、TRUE と FALSE を T やF で済ませる悪習は廃して常に完全にスペルすべきである。\n「短さ」と「分かりやすさ」を重視する\nオブジェクト名を見るだけでその中にどのようなデータが含まれているか推測できる名前をつけるべきである。たとえば、性別を表す変数を作るなら、\n\nvar2 &lt;- c(\"female\", \"male\", \"male\", \"female\")\n\nではなく、\n\ngender &lt;- c(\"female\", \"male\", \"male\", \"female\")\n\nとしたほうが良い。gender という名前がついていれば、「この変数には性別に関する情報が入っているだろう」と容易に想像できる。\n　また、オブジェクト名は、短くて読みやすいほうが良い。数学の成績データをもつ次のオブジェクトについて考えよう。\n\nmathematicsscore &lt;- c(30, 91, 43, 77, 100)\n\nオブジェクト名から、中にどのような情報が含まれるか想像することはできる。しかし、この名前は長く、読みにくい。そこで、次のように名前を変えたほうが良い。\n\nMathScore  &lt;- c(30, 91, 43, 77, 100)\nmathScore  &lt;- c(30, 91, 43, 77, 100)\nmath_score &lt;- c(30, 91, 43, 77, 100)\n\nこれらの例では、mathematics を math に縮め、mathとscoreの間に区切りを入れて読みやすくしている。大文字と小文字の組み合わせで区切る方法はキャメルケース (camel case)と呼ばれ、大文字から始まるキャメルケースを大文字キャメルケース (upper camel case)、小文字から始まるキャメルケースを小文字キャメルケース (lower camel case) と呼ぶ。また、_（アンダーバー, アンスコ） で区切る方法はスネークケース (snake case) と呼ばれる。キャメルケースとスネークケースは、一貫した方法で使えばどちらを使っても良いだろう。\n　かつては “.” を使って単語を繋ぐのが標準的だった時代もあり、組込関数には “.” を使ったものも多い。data.frame() や read.csv() などがその例である。しかし、“.” はクラスのメソッドとして使われることがあり、混乱するので使うのは避けたほうが良い。{tidyverse} では、readr::read_csv() のように、スネークケースが採用されている。他にも -（ハイフン）で区切るチェーンケース (chain case)というのもあるが、Rで-は「マイナス（減算演算子）」であり、チェーンケースは使えない7。\n\n\n11.2.2 改行\n　コードは1行が長すぎないように適宜改行する。Rやパッケージなどが提供している関数のなかには10個以上の引数を必要とするものもあり。コードを1行で書こうとするとコードの可読性が著しく低くなってしまう。\n　1行に何文字入れるべきかについて決まったルールはないが、1行の最大文字数を半角80字にするという基準が伝統的に使われてきた。これま昔のパソコンで使ったパンチカード ( 図 11.2 )では1行に80個の穴を開けることができたことに由来する。\n\n\n\n図 11.2: パンチカードの例\n\n\n最近は昔と比べてモニタのサイズが大きく、解像度も高いので、80文字にこだわる必要はない。自分のRStudioのSource Paneに収まるよう、切りがいいところで改行しよう。\n\n\n11.2.3 スペースとインデント\n　適切なスペースはコードの可読性を向上させる。以下の2つのコードは同じ内容を実行するが、後者にはスペースがないので読にくい。\n\n# 良い例\nsum(my_vec2, na.rm = TRUE)\n\n# 悪い例\nsum(my_vec2,na.rm=TRUE)\n\n　どこにスペースを入れるかについてのルールは特になり。Rは「半角スペース」を無視するので、プログラムの動作に関して言えば、半角スペースはあってもなくても同じである。標準的なルールとして、「,の後にスペース」、「演算子の前後にスペース」などが考えらえる。ただし、^の前後にはスペースを入れないことが多い。また、後ほど紹介するfor(){}、while(){}、if(){}などのように、関数以外の ()の前後にはスペースを入れる。それに対し、sum() や read.csv() などのように、関数のかっこの場合には、関数名と()の間にスペースを入れない。\n　また、スペースを2回以上入れることもある。たとえば、あるデータフレームを作る例を考えよう。\n\n# 良い例\ndata.frame(\n  name     = c(\"Song\",  \"Yanai\", \"Wickham\"),\n  favorite = c(\"Ramen\", \"Cat\",   \"R\"),\n  gender   = c(\"Male\",  \"Male\",  \"Male\")\n)\n\n# 悪い例\ndata.frame(\n  name = c(\"Song\", \"Yanai\", \"Hadley\"),\n  favorite = c(\"Ramen\", \"Cat\", \"R\"),\n  gender = c(\"Male\", \"Male\", \"Male\")\n)\n\n上の2つのコードの内容は同じだが、前者のほうが読みやすい。\n　ここでもう1つ注目してほしいのは、「字下げ (indent)」の使い方である。上のコードは次のように一行にまとめることができるが、読みにくい。\n\n# 邪悪な例\ndata.frame(name=c(\"Song\",\"Yanai\",\"Hadley\"),favorite=c(\"Ramen\",\"Cat\",\"R\"),fender=c(\"Male\",\"Male\",\"Male\"))\n\nこのように1行のコードが長い場合、「改行」が重要である。しかし、Rの最も基本的なルールは「1行に1つのコード」なので、改行するとこのルールを破ることになってしまう。そこで、コードの途中で改行するときは、2行目以降を字下げすることで、1つのコードが前の行から続いていることを明確にしよう。前の行の続きの行は2文字（または4文字）分字下げする。こうすることで、「この行は上の行の続き」ということが「見て」わかるようになる。\n\n# 良い例\ndata.frame(\n  name     = c(\"Song\",  \"Yanai\", \"Hadley\"),\n  favorite = c(\"Ramen\", \"Cat\",   \"R\"),\n  gender   = c(\"Male\",  \"Male\",  \"Male\")\n)\n\n# 悪い例\ndata.frame(\nname     = c(\"Song\",  \"Yanai\", \"Hadley\"),\nfavorite = c(\"Ramen\", \"Cat\",   \"R\"),\ngender   = c(\"Male\",  \"Male\",  \"Male\")\n)\n\n　RStudioは自動的に字下げをしてくれるので、RStudioを使っているならあまり意識する必要はない。自動で字下げしてくれないエディタを使っている場合は、字下げに気をつけよう。\n\n\n11.2.4 代入\nオブジェクトに値を代入する演算子として、これまで &lt;- を使ってきたが、=を使うこともできる。R以外の多くのプログラミング言語では、代入演算子として=を採用している。しかし、引数の指定と代入を区別するためん、本書では&lt;-の使用を推奨する。また、既に説明したとおり、option + -（macOSの場合）または Alt + -（Windows の場合）というショートカットを使うと、&lt;- だけでなく、その前後のスペースを自動的に挿入してくれる。コードが読みやすくなるので、代入演算子は常にショートカットで入力する習慣をつけよう。\n　この節で説明したコードの書き方は、コーディングスタイルの一部に過ぎない。本書では、できるだけ読みやすいコードを例として示すことを心がけている。最初は本書（あるいは他の本やウェブサイトに掲載されているもののなかで気に入ったもの）のスタイルを真似して書いてみてほしい。コードを書き写しているうちに、自にとって最善の書き方が見えてくるだろう。\n　コーディングスタイルについては、以下の2つの資料がさらに詳しい。とりわけ、羽鳥先生が書いたThe tidyverse style guide は事実上の業界標準であり、Google’s Style Guide も このガイドをベースにしている。かなりの分量だが、パッケージ開発などを考えているなら一度は目を通しておいたほうが良いだろう。\n\nThe tidyverse style guide\nGoogle’s Style Guide"
  },
  {
    "objectID": "programming.html#sec-programming_iteration",
    "href": "programming.html#sec-programming_iteration",
    "title": "11  Rプログラミングの基礎",
    "section": "11.3 反復",
    "text": "11.3 反復\n　人間があまり得意ではないが、コンピュータが得意とする代表的な作業が「反復作業」である。普通の人間なら数時間から数年かかるような退屈な反復作業でも、コンピュータを使えば数秒で終わることが多い。Rでもさまざまな反復作業を行うことができる。\n　反復作業を行うときは、反復作業を「いつ終わらせるか」を考えなくてはならない。終わりを規程する方法として、以下の2つが考えられる。\n\n処理を繰り返し回数を指定し、その回数に達したら終了する: for 文を使う\n一定の条件を指定し、その条件が満たされるときに処理を終了する: while 文を使う\n\nこの節では、これら2つのケースのそれぞれについて解説する。\n\n11.3.1 for による反復\n　forを利用した反復を、forループ と呼ぶ。まず、forループの雛形をみてみよう。\nfor (任意の変数 in ベクトル) {\n  処理内容\n}\n任意の変数の選び方はいろいろ考えられるが、よく使うのはインデクス (index) i である。このインデクスはforループの内部で使うために用いられる変数である。そして、in の後の「ベクトル」には長さ1以上のベクトルを指定する。ベクトルは必ずしもnumeric型である必要はないが、インデクスを利用したforループではインデクスを指定する正の整数を要素にもつベクトルを使う。\n　また、{}内の内容が1行のみの場合には、{}は省略しても良い。その場合、処理内容を()の直後に書。つまり、以下のような書き方もできる。\nfor (任意の変数 in ベクトル) 処理内容\nこれはforだけでなく、ifやfunction()など、{}で処理内容を囲む関数に共通である。処理内容が2行以上の場合は、必ず{}で囲むようにしよう。\n　例として、インデクス \\(i\\) の内容を画面に表示することをN回繰り返すforループを書いてみよう。繰り返し回数を指定するために、for (i in 1:N)と書く。5回繰り返すならfor (i in 1:5)とする。1:5はc(1, 2, 3, 4, 5)と同じなので、for (i in c(1, 2, 3, 4, 5))でもいいが、1:5 を使って書いたほうが、コードが読みやすい。\n　以下コードを作成し、実行してみよう。このコードは3行がひとつのかたまりになったコードである。forの行（あるいは最後の}の行）にカーソルを置いた状態で Cmd/Ctrl + Return/Enter を押せば、forループ全体が一挙に実行される。\n\n# 以下のコードはこのように書くことも可能\n# for(i in 1:5) print(i)\nfor (i in 1:5) {\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\n1から5までの数字が表示された。\n　ここで、このforループがどのような順番で処理を実行したのか確認してみよう。上のコードは、次のようなステップを踏んで1から5までの数字を画面に表示している。\n\niにベクトル1:5の最初の要素を代入 (i &lt;- 1)\nprint(i)を実行\n{}中身の処理が終わったらiにベクトル1:5内の次の要素を代入 (i &lt;- 2)\nprint(i)を実行\n{}中身の処理が終わったらiにベクトル1:5内の次の要素を代入 (i &lt;- 3)\nprint(i)を実行\n{}中身の処理が終わったらiにベクトル1:5内の次の要素を代入 (i &lt;- 4)\nprint(i)を実行\n{}中身の処理が終わったらiにベクトル1:5内の次の要素を代入 (i &lt;- 5)\nprint(i)を実行\n{}中身の処理が終わったらiにベクトル1:5内の次の要素を代入するが、5が最後の要素なので反復終了\n\nこの手順を要約すると、次のようになる。\n\n任意の変数 (ここではi)にベクトル (ここでは1:5)の最初の要素が格納され、{}内の処理を行う。\n{}内の処理が終わったら、ベクトル (ここでは1:5)の次の要素を任意の変数 (ここではi)に格納し、{}内の処理を行う。\n格納できる要素がなくなったら反復を終了する。\n\nしたがって、反復はベクトル (ここでは1:5)の長さだけ実行される (ここでは5回)。\n\n\n　反復回数はベクトルの長さで決まる。既に述べたとおり、1:5のような書き方でなく、普通のベクトルを指定しても問題ない。たとえば、長さ6の dmg_vals というベクトルを作り、その要素を出力するコードを書いてみよう。\n\ndmg_vals &lt;- c(24, 64, 31, 46, 81, 102)\n\nfor (damage in dmg_vals) {\n  x &lt;- paste0(\"トンヌラに\", damage, \"のダメージ!!\")\n  print(x)\n}\n\n[1] \"トンヌラに24のダメージ!!\"\n[1] \"トンヌラに64のダメージ!!\"\n[1] \"トンヌラに31のダメージ!!\"\n[1] \"トンヌラに46のダメージ!!\"\n[1] \"トンヌラに81のダメージ!!\"\n[1] \"トンヌラに102のダメージ!!\"\n\n\n　スライムくらいなら一撃で撃破できそうな立派な勇者である。\n　ちなみに、paste0()は引数を空白なし8で繋いだ文字列を返す関数である。詳細は第17で解説するが、簡単な例だけ示しておこう。\n\npaste0(\"Rは\", \"みんなの\", \"ともだち\")\n\n[1] \"Rはみんなのともだち\"\n\npaste0(\"私の\", \"HP/MPは\", 500, \"/\", 400, \"です。\")\n\n[1] \"私のHP/MPは500/400です。\"\n\n\n　文字列のベクトルを使ったforループもできる。10個の都市名が格納されたcitiesの要素を1つずつ出力するコードは次のように書ける。\n\ncities &lt;- c(\"Sapporo\", \"Sendai\", \"Tokyo\", \"Yokohama\", \"Nagoya\",\n            \"Kyoto\", \"Osaka\", \"Kobe\", \"Hiroshima\", \"Fukuoka\")\nfor (i in seq_along(cities)) {\n  x &lt;- paste0(\"現在、cityの値は\", cities[i], \"です。\")\n  print(x)\n}\n\n[1] \"現在、cityの値はSapporoです。\"\n[1] \"現在、cityの値はSendaiです。\"\n[1] \"現在、cityの値はTokyoです。\"\n[1] \"現在、cityの値はYokohamaです。\"\n[1] \"現在、cityの値はNagoyaです。\"\n[1] \"現在、cityの値はKyotoです。\"\n[1] \"現在、cityの値はOsakaです。\"\n[1] \"現在、cityの値はKobeです。\"\n[1] \"現在、cityの値はHiroshimaです。\"\n[1] \"現在、cityの値はFukuokaです。\"\n\n\n　ここでは for (i in 1:10) ではなく、for (i in seq_along(cities))と表記。この例からわかるように、seq_along() を使うと、ベクトルのインデクス自動的に作ってくれる。上の例では、seq_along(ten_cities) が自動的にベクトル長さを計算し、1:length(ten_cities) すなわち 1:10 と同じ処理をしてくれる。ベクトルの長さが自明でないとき（ベクトルが非常に長いとき）には、seq_along() を使うのが便利である。後で cities の中身を書き換えたときに、cities の長さが変わることも考えられるので、ベクトルのインデクス指定には seq_along() を使おう。\n　また、インデクスを使わないforループも書ける。上と同じ結果は、次のコードで実現することができる。\n\nfor (city in cities) {\n  x &lt;- paste0(\"現在、cityの値は\", city, \"です。\")\n  print(x)\n}\n\n[1] \"現在、cityの値はSapporoです。\"\n[1] \"現在、cityの値はSendaiです。\"\n[1] \"現在、cityの値はTokyoです。\"\n[1] \"現在、cityの値はYokohamaです。\"\n[1] \"現在、cityの値はNagoyaです。\"\n[1] \"現在、cityの値はKyotoです。\"\n[1] \"現在、cityの値はOsakaです。\"\n[1] \"現在、cityの値はKobeです。\"\n[1] \"現在、cityの値はHiroshimaです。\"\n[1] \"現在、cityの値はFukuokaです。\"\n\n\nこのように、ベクトルの中身が数字でない場合でも、forループでベクトルの要素を1つずつ順番に利用することができる。\n　次に、\"1番目の都市名はSapporoです\"、\"2番目の都市名はSendaiです\"、…　のように出力する方法を考えよう。これまでは出力する文字列のなかで1箇所（都市名）のみを変えながら表示したが、今回は「i」と「city」の2箇所を同時に変える。これは、インデクス iを使って反復を実行しながら、cities のi番目要素を呼び出すことで実現できる。以下のコードを実行してみよう。\n\nfor (i in seq_along(cities)) {\n  msg &lt;- paste0(i, \"番目の都市名は\", cities[i], \"です。\")\n  print(msg)\n}\n\n[1] \"1番目の都市名はSapporoです。\"\n[1] \"2番目の都市名はSendaiです。\"\n[1] \"3番目の都市名はTokyoです。\"\n[1] \"4番目の都市名はYokohamaです。\"\n[1] \"5番目の都市名はNagoyaです。\"\n[1] \"6番目の都市名はKyotoです。\"\n[1] \"7番目の都市名はOsakaです。\"\n[1] \"8番目の都市名はKobeです。\"\n[1] \"9番目の都市名はHiroshimaです。\"\n[1] \"10番目の都市名はFukuokaです。\"\n\n\nこのように、インデクスとそれに対応するベクトルの要素を抽出すれば、望みどおりの処理ができる。\n多重forループ\n　forループの中でさらにforループを使うともできる。最初はやや難しいかもしれないが、多重反復はプログラミング技術としてよく使われるので9、この機会に勉強しよう。\n　多重forループを理解するためにうってつけの例は掛け算九九である。積算演算子 * の「左の数」と「右の数」 のそれぞれに1から9までの数字を代入するすべての組み合わせを考えるためには、2つのforループが必要だ10。i * jでiとjそれぞれに1から9を代入しながら結果を出力するコードは次のように書ける。\n\nfor (i in 1:9) {\n  for (j in 1:9) {\n    print(paste(i, \"*\", j, \"=\", i * j))\n  }\n}\n\n[1] \"1 * 1 = 1\"\n[1] \"1 * 2 = 2\"\n[1] \"1 * 3 = 3\"\n[1] \"1 * 4 = 4\"\n[1] \"1 * 5 = 5\"\n[1] \"1 * 6 = 6\"\n[1] \"1 * 7 = 7\"\n[1] \"1 * 8 = 8\"\n[1] \"1 * 9 = 9\"\n[1] \"2 * 1 = 2\"\n[1] \"2 * 2 = 4\"\n[1] \"2 * 3 = 6\"\n[1] \"2 * 4 = 8\"\n[1] \"2 * 5 = 10\"\n[1] \"2 * 6 = 12\"\n[1] \"2 * 7 = 14\"\n[1] \"2 * 8 = 16\"\n[1] \"2 * 9 = 18\"\n[1] \"3 * 1 = 3\"\n[1] \"3 * 2 = 6\"\n[1] \"3 * 3 = 9\"\n[1] \"3 * 4 = 12\"\n[1] \"3 * 5 = 15\"\n[1] \"3 * 6 = 18\"\n[1] \"3 * 7 = 21\"\n[1] \"3 * 8 = 24\"\n[1] \"3 * 9 = 27\"\n[1] \"4 * 1 = 4\"\n[1] \"4 * 2 = 8\"\n[1] \"4 * 3 = 12\"\n[1] \"4 * 4 = 16\"\n[1] \"4 * 5 = 20\"\n[1] \"4 * 6 = 24\"\n[1] \"4 * 7 = 28\"\n[1] \"4 * 8 = 32\"\n[1] \"4 * 9 = 36\"\n[1] \"5 * 1 = 5\"\n[1] \"5 * 2 = 10\"\n[1] \"5 * 3 = 15\"\n[1] \"5 * 4 = 20\"\n[1] \"5 * 5 = 25\"\n[1] \"5 * 6 = 30\"\n[1] \"5 * 7 = 35\"\n[1] \"5 * 8 = 40\"\n[1] \"5 * 9 = 45\"\n[1] \"6 * 1 = 6\"\n[1] \"6 * 2 = 12\"\n[1] \"6 * 3 = 18\"\n[1] \"6 * 4 = 24\"\n[1] \"6 * 5 = 30\"\n[1] \"6 * 6 = 36\"\n[1] \"6 * 7 = 42\"\n[1] \"6 * 8 = 48\"\n[1] \"6 * 9 = 54\"\n[1] \"7 * 1 = 7\"\n[1] \"7 * 2 = 14\"\n[1] \"7 * 3 = 21\"\n[1] \"7 * 4 = 28\"\n[1] \"7 * 5 = 35\"\n[1] \"7 * 6 = 42\"\n[1] \"7 * 7 = 49\"\n[1] \"7 * 8 = 56\"\n[1] \"7 * 9 = 63\"\n[1] \"8 * 1 = 8\"\n[1] \"8 * 2 = 16\"\n[1] \"8 * 3 = 24\"\n[1] \"8 * 4 = 32\"\n[1] \"8 * 5 = 40\"\n[1] \"8 * 6 = 48\"\n[1] \"8 * 7 = 56\"\n[1] \"8 * 8 = 64\"\n[1] \"8 * 9 = 72\"\n[1] \"9 * 1 = 9\"\n[1] \"9 * 2 = 18\"\n[1] \"9 * 3 = 27\"\n[1] \"9 * 4 = 36\"\n[1] \"9 * 5 = 45\"\n[1] \"9 * 6 = 54\"\n[1] \"9 * 7 = 63\"\n[1] \"9 * 8 = 72\"\n[1] \"9 * 9 = 81\"\n\n\n　上のコードがどのような処理をしているか考えてみよう。まず、iに1が代入される。次に、jに1から9までの数順番に1つずつ代入され、1 * 1、1 * 2、1 * 3、…、1 * 9が計算される。1 * 9の計算が終わったら、iに2が代入される。そして再び内側のforループが実行され、2 * 1、2 * 2、2 * 3、…、2 * 9が計算される。これを9の段まで繰り返す。段の順番を降順にして9の段を最初に計算し、1の段を最後に計算したい場合は、i in 1:9をi in 9:1に変えればよい。\n\nfor (i in 9:1) {\n  for (j in 1:9) {\n    print(paste(i, \"*\", j, \"=\", i * j))\n  }\n}\n\n[1] \"9 * 1 = 9\"\n[1] \"9 * 2 = 18\"\n[1] \"9 * 3 = 27\"\n[1] \"9 * 4 = 36\"\n[1] \"9 * 5 = 45\"\n[1] \"9 * 6 = 54\"\n[1] \"9 * 7 = 63\"\n[1] \"9 * 8 = 72\"\n[1] \"9 * 9 = 81\"\n[1] \"8 * 1 = 8\"\n[1] \"8 * 2 = 16\"\n[1] \"8 * 3 = 24\"\n[1] \"8 * 4 = 32\"\n[1] \"8 * 5 = 40\"\n[1] \"8 * 6 = 48\"\n[1] \"8 * 7 = 56\"\n[1] \"8 * 8 = 64\"\n[1] \"8 * 9 = 72\"\n[1] \"7 * 1 = 7\"\n[1] \"7 * 2 = 14\"\n[1] \"7 * 3 = 21\"\n[1] \"7 * 4 = 28\"\n[1] \"7 * 5 = 35\"\n[1] \"7 * 6 = 42\"\n[1] \"7 * 7 = 49\"\n[1] \"7 * 8 = 56\"\n[1] \"7 * 9 = 63\"\n[1] \"6 * 1 = 6\"\n[1] \"6 * 2 = 12\"\n[1] \"6 * 3 = 18\"\n[1] \"6 * 4 = 24\"\n[1] \"6 * 5 = 30\"\n[1] \"6 * 6 = 36\"\n[1] \"6 * 7 = 42\"\n[1] \"6 * 8 = 48\"\n[1] \"6 * 9 = 54\"\n[1] \"5 * 1 = 5\"\n[1] \"5 * 2 = 10\"\n[1] \"5 * 3 = 15\"\n[1] \"5 * 4 = 20\"\n[1] \"5 * 5 = 25\"\n[1] \"5 * 6 = 30\"\n[1] \"5 * 7 = 35\"\n[1] \"5 * 8 = 40\"\n[1] \"5 * 9 = 45\"\n[1] \"4 * 1 = 4\"\n[1] \"4 * 2 = 8\"\n[1] \"4 * 3 = 12\"\n[1] \"4 * 4 = 16\"\n[1] \"4 * 5 = 20\"\n[1] \"4 * 6 = 24\"\n[1] \"4 * 7 = 28\"\n[1] \"4 * 8 = 32\"\n[1] \"4 * 9 = 36\"\n[1] \"3 * 1 = 3\"\n[1] \"3 * 2 = 6\"\n[1] \"3 * 3 = 9\"\n[1] \"3 * 4 = 12\"\n[1] \"3 * 5 = 15\"\n[1] \"3 * 6 = 18\"\n[1] \"3 * 7 = 21\"\n[1] \"3 * 8 = 24\"\n[1] \"3 * 9 = 27\"\n[1] \"2 * 1 = 2\"\n[1] \"2 * 2 = 4\"\n[1] \"2 * 3 = 6\"\n[1] \"2 * 4 = 8\"\n[1] \"2 * 5 = 10\"\n[1] \"2 * 6 = 12\"\n[1] \"2 * 7 = 14\"\n[1] \"2 * 8 = 16\"\n[1] \"2 * 9 = 18\"\n[1] \"1 * 1 = 1\"\n[1] \"1 * 2 = 2\"\n[1] \"1 * 3 = 3\"\n[1] \"1 * 4 = 4\"\n[1] \"1 * 5 = 5\"\n[1] \"1 * 6 = 6\"\n[1] \"1 * 7 = 7\"\n[1] \"1 * 8 = 8\"\n[1] \"1 * 9 = 9\"\n\n\n　九九を覚えるときにはこれで良いが、実数どうしの掛け算で i * jとj * i は同じ（交換法則が成り立つ）なので、2つの数字の積を知りたいだけなら片方だけ出力すれば十分だろう。そこで、for (j in 1:9) を for (j in i:9) に変えてみよう。\n\nfor (i in 1:9) {\n  for (j in i:9) {\n    print(paste(i, \"*\", j, \"=\", i * j))\n  }\n}\n\n[1] \"1 * 1 = 1\"\n[1] \"1 * 2 = 2\"\n[1] \"1 * 3 = 3\"\n[1] \"1 * 4 = 4\"\n[1] \"1 * 5 = 5\"\n[1] \"1 * 6 = 6\"\n[1] \"1 * 7 = 7\"\n[1] \"1 * 8 = 8\"\n[1] \"1 * 9 = 9\"\n[1] \"2 * 2 = 4\"\n[1] \"2 * 3 = 6\"\n[1] \"2 * 4 = 8\"\n[1] \"2 * 5 = 10\"\n[1] \"2 * 6 = 12\"\n[1] \"2 * 7 = 14\"\n[1] \"2 * 8 = 16\"\n[1] \"2 * 9 = 18\"\n[1] \"3 * 3 = 9\"\n[1] \"3 * 4 = 12\"\n[1] \"3 * 5 = 15\"\n[1] \"3 * 6 = 18\"\n[1] \"3 * 7 = 21\"\n[1] \"3 * 8 = 24\"\n[1] \"3 * 9 = 27\"\n[1] \"4 * 4 = 16\"\n[1] \"4 * 5 = 20\"\n[1] \"4 * 6 = 24\"\n[1] \"4 * 7 = 28\"\n[1] \"4 * 8 = 32\"\n[1] \"4 * 9 = 36\"\n[1] \"5 * 5 = 25\"\n[1] \"5 * 6 = 30\"\n[1] \"5 * 7 = 35\"\n[1] \"5 * 8 = 40\"\n[1] \"5 * 9 = 45\"\n[1] \"6 * 6 = 36\"\n[1] \"6 * 7 = 42\"\n[1] \"6 * 8 = 48\"\n[1] \"6 * 9 = 54\"\n[1] \"7 * 7 = 49\"\n[1] \"7 * 8 = 56\"\n[1] \"7 * 9 = 63\"\n[1] \"8 * 8 = 64\"\n[1] \"8 * 9 = 72\"\n[1] \"9 * 9 = 81\"\n\n\nこのコードは、1の段は1 * 1から1 * 9 までのすべてを計算するが、2の段は2 * 2から、3の段は3 * 3から計算を始めて出力するコードである。2の段の場合、2 * 1は1の段で 1 * 2 が計算済みなのでスキップする。3の段の場合、3 * 1 は1の段で、3 * 2 は2の段でそれぞれ計算済みなのでとばす。 それぞれの段で同様の処理を続け、最後の9の段では9 * 9 のみが計算される。\n　このように多重forループは複数のベクトルの組み合わせて処理を行う場合に便利である。\n　複数のベクトルでなく、データフレームなどの2次元以上データにも多重forループは使われる。データフレームは複数のベクトルで構成されている（各列が1つのベクトル）ため、実質的には複数のベクトルを扱うことになる。\n　例として、FIFA_Men.csv を利用し、それぞれの国のチーム名、FAFAランキング、ポイントをまとめて表示するコードを書いてみよう。すべてのチームを表示すると結果が長くなるので、対象をOFC (オセアニアサッカー連盟) 所属チームに限定する。\n\n# read_csv()を使用するために{tidyverse}を読み込む\npacman::p_load(tidyverse)\n# FIFA_Men.csvを読み込み、myDFという名で保存\nmy_df &lt;- read_csv(\"Data/FIFA_Men.csv\")\n# my_dfのConfederation列がOFCの行だけを抽出\nmy_df &lt;- my_df[my_df$Confederation == \"OFC\", ]\n\nmy_df\n\n# A tibble: 10 × 6\n      ID Team              Rank Points Prev_Points Confederation\n   &lt;dbl&gt; &lt;chr&gt;            &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;        \n 1     4 American Samoa     192    900         900 OFC          \n 2    69 Fiji               163    996         996 OFC          \n 3   135 New Caledonia      156   1035        1035 OFC          \n 4   136 New Zealand        122   1149        1149 OFC          \n 5   147 Papua New Guinea   165    991         991 OFC          \n 6   159 Samoa              194    894         894 OFC          \n 7   171 Solomon Islands    141   1073        1073 OFC          \n 8   185 Tahiti             161   1014        1014 OFC          \n 9   191 Tonga              203    862         862 OFC          \n10   204 Vanuatu            163    996         996 OFC          \n\n\nOFCに10チーム加盟していることがわかる。\n　以下のような内容が表示されるコードを書きたい。\n=====1番目のチーム情報=====\nTeam: American Samoa\nRank: 192\nPoints: 900\n=====2番目のチーム情報=====\nTeam: Fiji\nRank: 163\nPoints: 996\n=====3番目のチーム情報=====\nTeam: New Caledonia\n...\nこれは1つのforループでも作成できるが、勉強のために2つのforループを使って書いてみよう。\n\nfor (i in 1:nrow(my_df)) {\n  print(paste0(\"=====\", i, \"番目のチーム情報=====\"))\n  \n  for (j in c(\"Team\", \"Rank\", \"Points\")) {\n    print(paste0(j, \": \", my_df[i, j]))\n  }\n}\n\n以上のコードを実行すると以下のような結果が表示される（全部掲載すると長くなるので、ここでは最初の2チームのみ掲載する。\n\n\n[1] \"=====1番目のチーム情報=====\"\n[1] \"Team: American Samoa\"\n[1] \"Rank: 192\"\n[1] \"Points: 900\"\n[1] \"=====2番目のチーム情報=====\"\n[1] \"Team: Fiji\"\n[1] \"Rank: 163\"\n[1] \"Points: 996\"\n\n\nこのコードについて説明しよう。まず、外側のforループでは任意の変数としてインデクスiを、内側のforループではインデクスjを使っている。Rは、コードを上から順番に処理する（同じ行なら、カッコの中から処理する）。したがって、まず処理されるのは外側のforループである。iにはベクトル1:nrow(my_df)の要素が順番に割り当てられる。nrow() は行列またはデータフレームの行数を求める関数で、my_dfは10行のデータなので1:10になる。つまり、外側のforループはiに1, 2, 3, …, 10の順で値を格納しながらループ内の処理を繰り返す。ここで、外側のforループの中身を見てみよう。まず、print() を使って \"=====i番目のチーム情報=====\" というメッセージを出力している。最初はiが1なので、\"=====1番目のチーム情報=====\"が表示される。\n　次に実行されるのが内側のforループである。ここではjにc(\"Team\", \"Rank\", \"Points\")を格納しながら内側のforループの内のコードをが3回繰り返し処理される。内側のコードの内容は、たとえば、i = 1の状態で、j = \"Team\"なら、print(paste0(\"Team\", \": \", my_df[1, \"Team\"]))である。第10.4章で説明した通り、my_df[1, \"Team\"]はmy_dfのTeam 列の1番目の要素を意味する。この処理が終わると、次はjに\"Rank\"が代入され、同じコードを処理する。そして、j = \"Points\"まで処理が終わったら、内側のforループは一度終了する。\n　内側のforループが終わっても、外側のforループはまだ終わっていない。次は、i に 2 が格納され、\"=====2番目のチーム情報=====\" を表示し、再度内側のforループを最初から処理する。 i = 10の状態で内側のforループが終了ると外側のforループも終了する。多重forループはこのように反復処理を実行する。\n　チーム名の次に所属連盟も表示したいときはどう直せば良いだろうか。正解はc(\"Team\", \"Rank\", \"Points\")のベクトルで、\"Team\"と\"Rank\"の間に\"Confederation\"を追加するだけである。実際にやってみよう (スペースの関係上、最初の2チームの結果のみ掲載する)。\n\nfor (i in 1:nrow(my_df)) {\n  print(paste0(\"=====\", i, \"番目のチーム情報=====\"))\n  \n  for (j in c(\"Team\", \"Confederation\", \"Rank\", \"Points\")) {\n    print(paste0(j, \": \", my_df[i, j]))\n  }\n}\n\n\n\n[1] \"=====1番目のチーム情報=====\"\n[1] \"Team: American Samoa\"\n[1] \"Confederation: OFC\"\n[1] \"Rank: 192\"\n[1] \"Points: 900\"\n[1] \"=====2番目のチーム情報=====\"\n[1] \"Team: Fiji\"\n[1] \"Confederation: OFC\"\n[1] \"Rank: 163\"\n[1] \"Points: 996\"\n\n\n　ちなみに、1つのforループで同じ結果を実現するには次のようにする。結果は掲載しないが、自分で試してみてほしい。また、cat()関数の使い方については?catを参照されたい。ちなみに\\nは改行コードである。\n\nfor (i in 1:nrow(my_df)) {\n  cat(paste0(\"=====\", i, \"番目のチーム情報=====\\n\"))\n  cat(paste0(\"Team:\",   my_df$Team[i], \"\\n\",\n             \"Rank:\",   my_df$Rank[i], \"\\n\",\n             \"Points:\", my_df$Points[i], \"\\n\"))\n}\n\n　リスト型を対象とした多重forループの例も確認しておこう。複数のベクトルを含むリストの場合、3番目のベクトルの5番目の要素を抽出するには、リスト名[[3]][5] のように2つの位置を指定する必要がある。たとえば、3人で構成されたグループが3つあり、それぞれのグループにおける id （例：学籍番号）の順番で名前が格納されている my_listを考えてみよう。\n\nmy_list &lt;- list(A = c(\"Song\", \"Wickham\", \"Yanai\"),\n                B = c(\"Watanabe\", \"Toyoshima\", \"Fujii\"),\n                C = c(\"Abe\", \"Moon\", \"Xi\"))\n\nここで、まず各クラスの出席番号1番の人の名字をすべて出力し、次は2番の人、最後に3番の人を表示するにはどうすれば良いだろうか。以下のコードを見てみよう。\n\nfor (i in 1:3) {\n  \n  for (j in names(my_list)) {\n    print(my_list[[j]][i])\n  }\n  \n  print(paste0(\"===ここまでが出席番号\", i, \"番の人です===\"))\n}\n\n[1] \"Song\"\n[1] \"Watanabe\"\n[1] \"Abe\"\n[1] \"===ここまでが出席番号1番の人です===\"\n[1] \"Wickham\"\n[1] \"Toyoshima\"\n[1] \"Moon\"\n[1] \"===ここまでが出席番号2番の人です===\"\n[1] \"Yanai\"\n[1] \"Fujii\"\n[1] \"Xi\"\n[1] \"===ここまでが出席番号3番の人です===\"\n\n\nこのコードは以下のように動く。\n\n1行目: 任意の変数をiとし、1から3までの数字をiに格納しながら、3回反復作業を行う。\n3行目: 任意の変数をjとし、ここにはリストの要素名（A, B, C）を格納しながら、リストの長さだけ処理を繰り返す。names(my_list)はc(\"A\", \"B\", \"C\")である。\n4行目: my_list[[j]][i]の内容を出力する。最初はi = 1、j = \"A\"なので、print(my_list[[\"A\"]][1])、つまり、my_listから\"A\"を取り出し、そこの1番目の要素を出力する\n7行目: 各ベクトルからi番目の要素を出力し、print(paste0(\"===ここまでが出席番号\", i, \"番の人です===\"))を実行する。iに次の要素を入れ、作業を反復する。iに格納する要素がなくなったら、反復を終了する。\n\n　多重forループは3重、4重にすることも可能だが、コードの可読性が低下するため、多くても3重、できれば最大二重までにしておいたほうがよい。3重以上にforループを重ねる場合は、内側のforループを後ほど解説する関数でまとめたほうがいいだろう。\n　上の例では、リストの各要素に名前 (A, B, C) が付けられていることを利用した。リストに名前がない場合はどうすれば良いだろうか（そもそも、名前のないリストなど作らないほうが良いのだが…）。例えば、次のような場合である。\n\nmy_list &lt;- list(c(\"Song\", \"Wickham\", \"Yanai\"),\n                c(\"Watanabe\", \"Toyoshima\", \"Fujii\"),\n                c(\"Abe\", \"Moon\", \"Xi\"))\n\nこの場合には、次のようにすればよい。\n\nfor (i in 1:3) {\n  \n  for (j in seq_along(my_list)) {\n    print(my_list[[j]][i])\n  }\n  \n  print(paste0(\"===ここまでが出席番号\", i, \"番の人です===\"))\n}\n\n[1] \"Song\"\n[1] \"Watanabe\"\n[1] \"Abe\"\n[1] \"===ここまでが出席番号1番の人です===\"\n[1] \"Wickham\"\n[1] \"Toyoshima\"\n[1] \"Moon\"\n[1] \"===ここまでが出席番号2番の人です===\"\n[1] \"Yanai\"\n[1] \"Fujii\"\n[1] \"Xi\"\n[1] \"===ここまでが出席番号3番の人です===\"\n\n\n内側のforループでリストの要素名を使う代わりに、リストの要素を位置で指定している。\n\n\n11.3.2 whileによる反復\n　forによるループは任意の変数にベクトルの要素を1つずつ代入し、ベクトルの要素を使い尽くすまで反復処理を行う。したがって、ベクトルの長さによってループの回数が決まる。\n　それに対し、「ある条件が満たされる限り、反復し続ける」あるいは「ある条件が満たされるまで、反復し続ける」ことも可能である。そのときに使うのが、whileによる whileループである。whileループの書き方はforループにとてもよく似ている。\n　基本的な使い方は、以下のとおりである。\nwhile (条件) {\n  条件が満たされた場合の処理内容\n}\nforがwhileに変わり、()内の書き方が(任意の変数 in ベクトル)から(条件)に変わった。この()内の条件が満たされる間は{}内の内容を処理が繰り返し実行される。1から5までの整数を表示するコードは、forループを使うと次のように書ける。\n\nfor (i in 1:5) {\n  print(i)\n}\n\n　これをwhileループを使って書き直すと、次のようになる。\n\ni &lt;- 1\nwhile (i &lt; 6) {\n  print(i)\n  i &lt;- i + 1\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\nwhileループを繰り返す条件はi &lt; 6である。これにより、「iが6未満」なら処理が繰り返される。注意すべき点として、i が6未満か否かの判断をループの開始時点で行うので、あらかじめ変数 i を用意する必要があることがあげられる。1行めにある i &lt;- 1 がそれである。そして、{}内の最終行に i &lt;- i + 1 があり、iを1ずつ増やしている。i = 5 の時点では print(i) が実行されるが、i = 6になると、ループをもう1ど実行する条件が満たされないので、反復が停止する。\n　i &lt;- i + 1のように内容を少しずつ書き換えるさいは、そのコードを置く位置にも注意が必要だ。先ほどのコードのうち、i &lt;- i + 1 を print(i)の前に移動してみよう。\n\ni &lt;- 1\n\nwhile (i &lt; 6) {\n  i &lt;- i + 1\n  print(i)\n}\n\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n[1] 6\n\n\n2から6までの整数が出力された。これはiを出力する前にiに1が足されるためである。i &lt;- i + 1の位置をこのままにして、先ほどと同じように1から5までの整数を表示するには、次のようにコードを書き換える。\n\ni &lt;- 0\n\nwhile (i &lt; 5) {\n  i &lt;- i + 1\n  print(i)\n}\n\n[1] 1\n[1] 2\n[1] 3\n[1] 4\n[1] 5\n\n\n変更点したのは、\n1.iの初期値を0にした 2. ()内の条件を(i &lt; 6)から(i &lt; 5)にした\nという2点である。\n　whileループは慣れないとややこしいと感じるだろう。forループで代替できるケースも多い。それでもwhile文が必要になるケースもある。それは先述した通り、「目標は決まっているが、その目標が達成されるまでは処理を何回繰り返せばいいか分からない」場合である。\n　たとえば、6面のサイコロ投げを考えよう。投げる度に出た目を記録し、その和が30以上に達したときサイコロ投げを中止するにはどうすればいいだろうか。何回サイコロを投げればいいかがあらかじめわからないと、forループは使えない。連続で6が出るなら5回で十分かもしれないが、1が出続けるなら30回投げる必要がある。このように、「反復処理は行うが、何回行えばいいか分からない。ただし、停止条件は知っている」場合にwhileループを使う。\n　サイコロ投げの例は、以下のコードで実行できる。\n\ntotal &lt;- 0\ntrial &lt;- 1\n\nwhile (total &lt; 30) {\n  die  &lt;- sample(1:6, size = 1)\n  total &lt;- total + die\n  \n  print(paste0(trial, \"回目のサイコロ投げの結果: \", die,\n               \"（これまでの総和: \", total, \"）\"))\n  \n  # print()文は以下のような書き方も可能\n  # Result &lt;- sprintf(\"%d回目のサイコロ投げの結果: %d （これまでの総和: %d）\", \n  #                   trial, die, total)\n  # print(Result)\n  \n  trial &lt;- trial + 1\n}\n\n[1] \"1回目のサイコロ投げの結果: 1（これまでの総和: 1）\"\n[1] \"2回目のサイコロ投げの結果: 6（これまでの総和: 7）\"\n[1] \"3回目のサイコロ投げの結果: 4（これまでの総和: 11）\"\n[1] \"4回目のサイコロ投げの結果: 4（これまでの総和: 15）\"\n[1] \"5回目のサイコロ投げの結果: 1（これまでの総和: 16）\"\n[1] \"6回目のサイコロ投げの結果: 3（これまでの総和: 19）\"\n[1] \"7回目のサイコロ投げの結果: 2（これまでの総和: 21）\"\n[1] \"8回目のサイコロ投げの結果: 3（これまでの総和: 24）\"\n[1] \"9回目のサイコロ投げの結果: 3（これまでの総和: 27）\"\n[1] \"10回目のサイコロ投げの結果: 1（これまでの総和: 28）\"\n[1] \"11回目のサイコロ投げの結果: 1（これまでの総和: 29）\"\n[1] \"12回目のサイコロ投げの結果: 6（これまでの総和: 35）\"\n\n\nこのコードの中身を説明しよう。まず、これまで出た目の和を記録する変数totalを用意し、初期値として0を格納する。また、何回目のサイコロ投げかを記録するためにtrialという変数を用意し、初期値として1を格納する（コードの1、2行目）。\n　次に、while文を書く。反復する条件はtotalが30未満と設定する。つまり、totalが30以上になったら反復を終了する（コードの4行目）。\n　続いて、サイコロを投げ、出た目をdieという変数に格納します。サイコロ投げは1から6の間の整数から無作為に1つを値を抽出することでシミュレートできる。そこで使われるのが sample()関数である（コードの5行目）。sample() 関数は与えられたベクトル内の要素を無作為に抽出する。sample(c(1, 2, 3, 4, 5, 6), size = 1)は「c(1, 2, 3, 4, 5, 6)から1つの要素を無作為に抽出せよ」という意味である（乱数生成を利用したシミュレーションについては後の章で詳しく説明する）。サイコロの目が出たら、その目をtotalの値に足す (コードの6行目)。\n　その後、「1回目のサイコロ投げの結果: 5 (これまでの総和: 5)」のように、1回の処理の結果を表示する。 (コードの8行目)。最後にtrialの値を1増やし (コードの14行目)、1度の処理が終了する。\n　1度の処理が終わったら、whileループの条件判断に戻り、条件が満たされていれば再び処理を繰り返す。これを条件が満たされなくなるまで繰り返す。\n　この反復処理は、forループで再現することもできる。次のようにすればよい。\n\ntotal &lt;- 0\n\nfor (trial in 1:30) {\n  die  &lt;- sample(1:6, 1)\n  total &lt;- total + die\n  \n  # print()の代わりにsprintf()を使うことも可能\n  result &lt;- sprintf(\"%d回目のサイコロ投げの結果: %d （これまでの総和: %d）\",\n                    trial, die, total)\n  print(result)\n  \n  if (total &gt;= 30)  break() # ()は省略可能\n}\n\n[1] \"1回目のサイコロ投げの結果: 6 （これまでの総和: 6）\"\n[1] \"2回目のサイコロ投げの結果: 4 （これまでの総和: 10）\"\n[1] \"3回目のサイコロ投げの結果: 1 （これまでの総和: 11）\"\n[1] \"4回目のサイコロ投げの結果: 2 （これまでの総和: 13）\"\n[1] \"5回目のサイコロ投げの結果: 1 （これまでの総和: 14）\"\n[1] \"6回目のサイコロ投げの結果: 6 （これまでの総和: 20）\"\n[1] \"7回目のサイコロ投げの結果: 2 （これまでの総和: 22）\"\n[1] \"8回目のサイコロ投げの結果: 4 （これまでの総和: 26）\"\n[1] \"9回目のサイコロ投げの結果: 6 （これまでの総和: 32）\"\n\n\nこのコードの中身を説明しよう。事前にサイコロを投げる回数はわからないが、6面サイコロの場合30回以内には必ず合計が30になるので、trial in 1:30としておく。あとはwhileループの書き方とほぼ同じだが、forループではiが自動的に更新されるのでi &lt;- i + 1は不要である。さらに、一定の条件が満たされるときにループを停止する必要がある。そこで登場するのが条件 if とbreak()である。条件分岐は次節で説明するが、ifから始まる行のコードは、「totalが30以上になったらループから脱出せよ」ということを意味する。このようにループからの脱出を指示する関数が break()だ。break() 関数は()を省略して breakと書いてもよい。\n　これは余談だが、結果の表示に今回はこれまで使ってきたprint()とpaste0()（またはpaste()）の代わりに、sprintf()を使っている。sprintf() 内の%dはその位置に指定された変数の値を整数として代入することを意味する。sprintf()にの引数にはまず出力する文字列を指定し、次に代入する変数を順番に入力する。%sは文字 (string) 型、%fは実数 (floating-point number) を意味する。%fでは小数の桁数も指定可能であり、小数第2位まで表示させるには %.2f のように表記する。以下のコードは3つの変数の値と文字列を結合する処理をprint(paste0())とsprintf()を用いて書いたもので、同じ結果が得られる。\n\nname   &lt;- \"Song\"\nbowls  &lt;- 50\nheight &lt;- 176.2\n\nprint(paste0(name, \"がひと月に食べるラーメンは\", bowls, \"杯で、身長は\", height, \"cmです。\"))\n\n[1] \"Songがひと月に食べるラーメンは50杯で、身長は176.2cmです。\"\n\n# %sにnameを、%dにbowlsを、%.1fにheightを小数第1位まで格納し、出力\nsprintf(\"%sがひと月に食べるラーメンは%d杯で、身長は%.1fcmです。\", name, bowls, height)\n\n[1] \"Songがひと月に食べるラーメンは50杯で、身長は176.2cmです。\"\n\n\nただし、{}内のsprintf()はそのまま出力されないため、一旦、オブジェクトとして保存し、それをprint()を使って出力する必要がある。詳細については、?sprintfを参照されたい。\n　今回例として挙げたサイコロ投げは「多くても30回以内に終わる」ことが分かっていたの forループで書き換えることができた。しかし、終了までに必要な反復回数は未知であることもある。目的に応じて forとwhileを使い分けることが求められる。"
  },
  {
    "objectID": "programming.html#sec-programming_condition",
    "href": "programming.html#sec-programming_condition",
    "title": "11  Rプログラミングの基礎",
    "section": "11.4 条件分岐",
    "text": "11.4 条件分岐\n\n11.4.1 if、else if、else による条件分岐\nこの節では条件分岐について説明する。条件分岐は、条件に応じて異なる処理を行いときに利用する。if による条件分岐の基本形は次のとおりである。\nif (条件) {\n  条件が満たされた場合のみ実行される処理の内容\n}\nwhileを使ったループによく似ているが、while文は条件が満たされる限り{}の内容を繰り返し実行するのに対し、if 文では条件が満たされれときに{}の内容が1回だけ実行されて処理が終了するという違いがある。たとえば、名前が格納されているオブジェクトnameの中身が\"Song\"なら「ラーメン大好き」と出力されるコードを考えてみよう。\n\nname &lt;- \"Song\"\n\nif (name == \"Song\") {\n  print(\"ラーメン大好き\")\n}\n\n[1] \"ラーメン大好き\"\n\n\nif文の ()内の条件は、「nameの中身が\"Song\"」の場合のみ{}内の処理を実行せよということを意味する。nameの中身が\"Yanai\"ならどうなるだろうか。\n\nname &lt;- \"Yanai\"\n\nif (name == \"Song\") {\n  print(\"ラーメン大好き\")\n}\n\n何も表示されない。このように、if文単体だと、条件が満たされない場合には何も実行されない。\n条件にに応じて異なる処理を実行するために、else を使う。これはifとセットで使われるもので、ifの条件が満たされなかった場合の処理内容を指定することができる。elseを加えると、次のようなコードが書ける。\nif (条件) {\n  条件が満たされた場合の処理内容\n} else {\n  条件が満たされなかった場合の処理内容\n}\nelse文は、以下のように改行して書くこともできる。\nif (条件) {\n  条件が満たされた場合の処理内容\n} \nelse {\n  条件が満たされなかった場合の処理内容\n}\nしかし、この書き方はあまり良くない。else は必ず if とセットで用いられるので、if の処理の終わりである } の直後に半角スペースを1つ挟んで書くのが標準的なコーディングスタイルである。\n　それでは nameが\"Song\"でない場合には、「ラーメン好きじゃない」表示されるコードを書いてみよう。\n\nname &lt;- \"Song\"\n\nif (name == \"Song\") {\n  print(\"ラーメン大好き\")\n} else {\n  print(\"ラーメン好きじゃない\")\n}\n\n[1] \"ラーメン大好き\"\n\n\nnameが\"Song\"の場合、前と変わらず「ラーメン大好き」が出力される。nameを\"Yanai\"に変えてみよう。\n\nname &lt;- \"Yanai\"\n\nif (name == \"Song\") {\n  print(\"ラーメン大好き\")\n} else {\n  print(\"ラーメン好きじゃない\")\n}\n\n[1] \"ラーメン好きじゃない\"\n\n\n「ラーメン好きじゃない」が表示される。\n　しかし、世の中はと「ラーメン大好き」と「ラーメン好きじゃない」のみで構成されているわけではない。「ラーメン大好き」なのはSong と Koike、「ラーメン好きじゃない」のは Yanai のみで、それ以外の人は「ラーメンそこそこ好き」だとしよう。つまり3つのパタンがある。それぞれに別の処理を実行するには、3つ以上の条件に対応できる条件分岐が必要になる。\n　そのような場合には else ifをifとelseの間に挿入する。\nif (条件1) {\n  条件1が満たされた場合の処理内容\n} else if (条件2) {\n  条件1が満たされず、条件2が満たされた場合の処理内容\n} else if (条件3) {\n  条件1, 2が満たされず、条件3が満たされた場合の処理内容\n} else {\n  条件が全て満たされなかった場合の処理内容\n}\nこのように条件分岐を書くと、if文の条件が満たされれば最初の{}内の処理を実行し、満たされなかったら次のelse ifの条件を判定する。その条件が満たされれば{}の処理を実行し、満たされなければ次のelse ifへ移動…を順に実施する。どの条件も満たされないときは、最終的に else の内容が実行される。\n　それでは実際にコードを書いてみよう。\n\nname &lt;- \"Song\"\n\nif (name == \"Song\" | name == \"Koike\") {\n  # 上の条件は、(name %in% c(\"Song\", \"Koike\"))  でもOK\n  print(\"ラーメン大好き\")\n} else if (name == \"Yanai\") {\n  print(\"ラーメン好きじゃない\")\n} else {\n  print(\"ラーメンそこそこ好き\")\n}\n\n[1] \"ラーメン大好き\"\n\n\nこのコードでは、まずnameが\"Song\" または \"Koike\" か否かを判定し、TRUEなら「ラーメン大好き」を表示する。FALSE なら次の else if文へ移動する。ここではNameが\"Yanai\"かどうかを判定する。\n　最初の条件に登場する |は「OR （または）」を意味する論理演算子であり、第7章で解説した。このように、条件の中で|や&などの論理演算子を使うことで、複数の条件を指定することができる。また、name == \"Song\" | name == \"Koike\"はname %in% c(\"Song\", \"Koike\")に書き換えることがでる。x %in% yはxがyに含まれているか否かを判定する演算子である。たとえば、\"A\" %in% c(\"A\", \"B\", \"C\")の結果はTRUEだが、\"Z\" %in% c(\"A\", \"B\", \"C\")の結果はFALSEになる。\n　それではnameを\"Yanai\"、\"Koike\"、\"Shigemura\"、\"Hakiai\"に変えながら結果を確認してみよう。\n\nname &lt;- \"Yanai\"\n\nif (name %in% c(\"Song\", \"Koike\")) {\n  print(\"ラーメン大好き\")\n} else if (name == \"Yanai\") {\n  print(\"ラーメン好きじゃない\")\n} else {\n  print(\"ラーメンそこそこ好き\")\n}\n\n[1] \"ラーメン好きじゃない\"\n\n\n\nname &lt;- \"Koike\"\n\nif (name %in% c(\"Song\", \"Koike\")) {\n  print(\"ラーメン大好き\")\n} else if (name == \"Yanai\") {\n  print(\"ラーメン好きじゃない\")\n} else {\n  print(\"ラーメンそこそこ好き\")\n}\n\n[1] \"ラーメン大好き\"\n\n\n\nname &lt;- \"Shigemura\"\n\nif (name %in% c(\"Song\", \"Koike\")) {\n  print(\"ラーメン大好き\")\n} else if (name == \"Yanai\") {\n  print(\"ラーメン好きじゃない\")\n} else {\n  print(\"ラーメンそこそこ好き\")\n}\n\n[1] \"ラーメンそこそこ好き\"\n\n\n\nname &lt;- \"Hakiai\"\n\nif (name %in% c(\"Song\", \"Koike\")) {\n  print(\"ラーメン大好き\")\n} else if (name == \"Yanai\") {\n  print(\"ラーメン好きじゃない\")\n} else {\n  print(\"ラーメンそこそこ好き\")\n}\n\n[1] \"ラーメンそこそこ好き\"\n\n\n　if文が単独で使われることもそれほど多くない。if文は主に反復処理を行うforループまたはwhile()ループの中、もしくは次節で説明する自作関数内に使われることが多い。上の例では名前からラーメンに対する情熱を判定するために何度も同じコードを書いてきたが、同じコードを繰り返し書くのは効率が悪い。繰り返し行う作業を関数としてまとめれば便利である。関数の作成については第12章で説明する。\n　ここではforループと条件分岐の組み合わせについて考えてみよう。学生10人の成績が入っているベクトルscoresがあるとしよう。そして、成績が60点以上なら「合格」を、未満なら「不合格」を返すようなコードを書く。この作業を効率的に行うために、 forループとif文を組み合わせる方法を考える。forループではインデクス変数iに1から10までの数字を代入することを繰り返す。ここでの10はベクトルscoresの長さなので、seq_along() を使う。そして、scoresのi番目要素に対して60点以上か否かの判定を行い、「合格」または「不合格」という結果を返す。\n　以上の内容を実行するコードは、次のように書ける。\n\nscores &lt;- c(58, 100, 81, 97, 71, 61, 47, 60, 73, 85)\n\nfor (i in seq_along(scores)) {\n  if (scores[i] &gt;= 60) {\n    print(paste0(\"学生\", i, \"の判定結果: 合格\"))\n  } else {\n    print(paste0(\"学生\", i, \"の判定結果: 不合格\"))\n  }\n}\n\n[1] \"学生1の判定結果: 不合格\"\n[1] \"学生2の判定結果: 合格\"\n[1] \"学生3の判定結果: 合格\"\n[1] \"学生4の判定結果: 合格\"\n[1] \"学生5の判定結果: 合格\"\n[1] \"学生6の判定結果: 合格\"\n[1] \"学生7の判定結果: 不合格\"\n[1] \"学生8の判定結果: 合格\"\n[1] \"学生9の判定結果: 合格\"\n[1] \"学生10の判定結果: 合格\"\n\n\nこのコードは、以下の処理を行っている。\n\n1行目: まず、ベクトルscoresを定義する。\n3行目: for文でループを作る。任意の変数としてインデクスiを使う。ベクトルの各要素をのインデクスを入れ替えながら反復を行います。したがって、i in 1:10でも問題ないが、ここではi in seq_along(scores)を利用する。こうすることで、scoresベクトルの長さが変わっても、forの内容を修正する必要がなくなる。\n4, 5行目: scoresのi番目要素が60点以上かどうかを判定し、TRUEなら「学生iの判定結果: 合格」を表示する。\n6-8行目: scores のi番目要素が60点以上でない場合、「学生iの判定結果: 不合格」を表示する。\n\nprint()内でpaste0()を使うとコードの可読性がやや落ちるので、sprintf()を使ってもよいかもしれない（第13章で説明するパイプ演算子 |&gt; を使えば、可読性の問題は解決する）。\n\nscores &lt;- c(58, 100, 81, 97, 71, 61, 47, 60, 73, 85)\n\nfor (i in seq_along(scores)) {\n  if (scores[i] &gt;= 60) {\n    result &lt;- sprintf(\"学生%dの判定結果: 合格\", i)\n  } else {\n    result &lt;- sprintf(\"学生%dの判定結果: 不合格\", i)\n  }\n  \n  print(result)\n}\n\n[1] \"学生1の判定結果: 不合格\"\n[1] \"学生2の判定結果: 合格\"\n[1] \"学生3の判定結果: 合格\"\n[1] \"学生4の判定結果: 合格\"\n[1] \"学生5の判定結果: 合格\"\n[1] \"学生6の判定結果: 合格\"\n[1] \"学生7の判定結果: 不合格\"\n[1] \"学生8の判定結果: 合格\"\n[1] \"学生9の判定結果: 合格\"\n[1] \"学生10の判定結果: 合格\"\n\n\n　次に、結果を出力するのではなく、結果を別のベクトルに格納する例を考えてみよう。あらかじめ scores と同じ長さの空ベクトルpfを用意します。ここに各学生について合否判定の結果を「合格」または「不合格」として格納する処理を行う。以下のようなコードが書ける。\n\nscores &lt;- c(58, 100, 81, 97, 71, 61, 47, 60, 73, 85)\npf     &lt;- rep(NA, length(scores))\n\nfor (i in seq_along(scores)) {\n  if (scores[i] &gt;= 60) {\n    pf[i] &lt;- \"合格\"\n  } else {\n    pf[i] &lt;- \"不合格\"\n  }\n}\n\nこのコードでは、scores を定義した後、中身がNAのみで構成される長さがscores と同じベクトルpfを定義する。rep(NA, length(scores))はNAをlength(Scores)個（ここでは10個）並べたベクトルを生成する。 続いて、点数によって条件分岐を行い、メッセージを出力するのではなく、pfのi番目に\"合格\"か\"不合格\"を入れる。結果を確認してみよう。\n\npf\n\n [1] \"不合格\" \"合格\"   \"合格\"   \"合格\"   \"合格\"   \"合格\"   \"不合格\" \"合格\"  \n [9] \"合格\"   \"合格\"  \n\n\n　このように、if文は反復処理を行うforループまたはwhileループと組み合わせることでその本領を発揮する。実は、今回の例については次に説明するifelse()を使えば1行で処理することができる。しかし、複雑な処理を伴う反復と条件分岐を組み合わせるには、今回のようにforループとif文を組み合わせるのが有効である。\n\n\n11.4.2 ifelse()による条件分岐\nifelse()は与えられたベクトル内の各要素に対して条件分岐を行い、それをベクトルの全要素について繰り返す関数である。簡単な条件分岐と反復処理を同時に行う非常に便利な関数である。ifelse()の基本的な書き方は以下のとおり。\nifelse(条件, 条件がTRUEの場合の処理、条件がFALSEの場合の処理)\n　たとえば、学生10人の成績が入っているベクトルscoresに対し、60点以上の場合に合格 (\"Pass\")、60点未満の場合に不合格 (\"Fail\") の値を割り当て、pfというベクトルに格納しよう。\n\nscores &lt;- c(58, 100, 81, 97, 71, 61, 47, 60, 73, 85)\npf &lt;- ifelse(scores &gt;= 60, \"Pass\", \"Fail\")\npf\n\n [1] \"Fail\" \"Pass\" \"Pass\" \"Pass\" \"Pass\" \"Pass\" \"Fail\" \"Pass\" \"Pass\" \"Pass\"\n\n\n条件はscoresの値が60以上か否かであり、60以上なら\"Pass\"を、それ以外なら\"Fail\"を返す。\n　返す値として新しい値を与える代わりに、一定の条件が満たされたら現状の値を保持し、それ以外なら指定した値に変更して返すこともできる。たとえば、世論調査では以下のように「答えたくない」または「わからない」を9や99などで記録することが多い。この値はこのままでは分析するのが難しいので、欠損値として扱いたいことがある。例として、次の質問を考えよう。\nQ. あなたはラーメンが好きですか。\n\n1.大好き\n2.そこそこ好き\n3.好きではない\n9.答えたくない\n\nこの質問に対する10人の回答が格納されたデータフレーム (Ramen) があるとしよう。このデータフレームには2つの列があり、id 列は回答者のID（識別番号）、ramen 列にはは上の質問に対する答えが入ってる。\n\nRamen &lt;- data.frame(\n  id    = 1:10,\n  ramen = c(1, 1, 2, 1, 3, 1, 9, 2, 1, 9)\n)\n\n\nRamen\n\n   id ramen\n1   1     1\n2   2     1\n3   3     2\n4   4     1\n5   5     3\n6   6     1\n7   7     9\n8   8     2\n9   9     1\n10 10     9\n\n\n　このramen列に対し、ramen == 9ならNAを割り当て、それ以外の場合は元の値をそのまま残したいとしよう。そしてその結果をRamenのramen列に上書する。これは次のコードで実行できる。\n\nRamen$ramen &lt;- ifelse(Ramen$ramen == 9, NA, Ramen$ramen)\nRamen\n\n   id ramen\n1   1     1\n2   2     1\n3   3     2\n4   4     1\n5   5     3\n6   6     1\n7   7    NA\n8   8     2\n9   9     1\n10 10    NA\n\n\n　3つ以上のパタンに分岐させたいときは、ifelse()の中でifelse()を使うこともできる。scoresベクトルの例を考えてよう。ここで90点以上ならS、80点以上ならA、70点以上ならB、60点以上ならCを割り当て、それ以外はFを返すことにしよう。そして、その結果をgrade という変数に格納してみよう。\n\ngrade &lt;- ifelse(scores &gt;= 90, \"S\", \n                ifelse(scores &gt;= 80, \"A\",\n                       ifelse(scores &gt;= 70, \"B\",\n                              ifelse(scores &gt;= 60, \"C\", \"F\"))))\n\nこのコードでは、ifelse()の条件がFALSEの場合、次のifelse()での判定を行う。結果を確認しておこう。\n\ngrade\n\n [1] \"F\" \"S\" \"A\" \"S\" \"B\" \"C\" \"F\" \"C\" \"B\" \"A\"\n\n\n　この例からもわかるとおり、ifelse()を使いすぎるとコードの可読性が低くなるので、このようなコードはあまり推奨できない。複数の条件に応じて返す値を変える処理は、{dplyr}パッケージのcase_when()関数で行うのがよいだろう。この関数については、第14章で詳細に説明するが、ここでは上のコードと同じ処理を実施する例のみ示す。\n\ngrade2 &lt;- dplyr::case_when(scores &gt;= 90 ~ \"S\",\n                           scores &gt;= 80 ~ \"A\",\n                           scores &gt;= 70 ~ \"B\",\n                           scores &gt;= 60 ~ \"C\",\n                           TRUE         ~ \"F\")\n\ngrade2\n\n [1] \"F\" \"S\" \"A\" \"S\" \"B\" \"C\" \"F\" \"C\" \"B\" \"A\"\n\n\n\n\n11.4.3 switch()による条件分岐\n　switch()は、与えられた長さ1の文字列11を用いた条件分岐を行う。これが単体で使われうことはほとんどなく、通常は関数のなかで使われる。したがって、初めて本書を読む場合はこの節を一旦とばし、第12章を読んだ後に必要に応じて戻ってきてほしい。\n　ここでは2つの数値xとyの加減乗除を行う関数m_calc という名前の関数を作る。この関数はx とy以外にoperationという引数をもち、このoperationの値によって行う処理が変わる。たとえば、operation = \"+\"なら足し算を、operation = \"*\"なら掛け算を行う。\n\nmy_calc &lt;- function(x, y, operation) {\n  switch(operation,\n         \"+\" = x + y,\n         \"-\" = x - y,\n         \"*\" = x * y,\n         \"/\" = x / y,\n         stop(\"operation の値に使えるのは +, -, *, / のみです。\")\n         )\n}\n\nこのコードの中身を確認しよう。重要なのは2行目から8行目の部分である。switch()の最初の引数は条件を判定する長さ1のベクトルである。ここではこれがoperationである。そして、operationに指定される実引数の値によって異なる処理を行う。\"+\" = x + yは「operationの値が\"+\"なら、x + yを実行する」ことを意味する。これを他の演算子に対しても指定する。最後の引数は、どの条件にも合わない場合の処理である。ここでは, operation の値に使えるのは +, -, *, / のみです。\"というエラーメッセージを表示し、関数の実行を停止するために stop() 関数を指定している。\n　上のコードは、if、else if、 elseを使って書き換えることができる。\n\nmy_calc2 &lt;- function(x, y, operation = c(\"+\", \"-\", \"*\", \"/\")) {\n  \n  operation &lt;- match.arg(operation)\n  \n  if (operation == \"+\") {\n    return(x + y)\n  } else if (operation == \"-\") {\n    return(x - y)\n  } else if (operation == \"*\") {\n    return(x * y)\n  } else {\n    return(x / y)\n  } \n}\n\n先ほどと異なる点は、function()の中でoperationのデフォルト値をベクトルとしてした与えたことだ。これは「operation引数の値がこれらの値以外になることは許さない」ということを意味する。match.arg()関数は、operation引数が予め指定された引数の値と一致するか否かを判断する。指定された引数と一致しない場合、エラーを表示し、処理を中断する。ちなみに、match.arg()はswith()文と組み合わせて使うこともできる。\n　今回の例の場合、switch()を使ったほうがコードの内容がわかりやすく、読みやすいが、ifによる条件分岐でも十分に対応可能である。また、条件によって行う処理が複雑な場合にはswitch()よりもifのほうが使いやすい。\n　作った関数を使ってみよう。\n\nmy_calc(5, 3, operation = \"+\")\n\n[1] 8\n\nmy_calc(5, 3, operation = \"-\")\n\n[1] 2\n\nmy_calc(5, 3, operation = \"*\")\n\n[1] 15\n\nmy_calc(5, 3, operation = \"/\")\n\n[1] 1.666667\n\n\nでは\"+\"、\"-\"、\"*\"、\"/\"以外の値をoperationに与えるとうなるだろうか。ためしに\"^\"を入れてみよう。\n\nmy_calc(5, 3, operation = \"^\")\n\nError in my_calc(5, 3, operation = \"^\"): operation の値に使えるのは +, -, *, / のみです。\n\n\nstop()内に書いたエラーメッセージが表示され、処理が中止される。"
  },
  {
    "objectID": "programming.html#sec-programming_exercise",
    "href": "programming.html#sec-programming_exercise",
    "title": "11  Rプログラミングの基礎",
    "section": "11.5 練習問題",
    "text": "11.5 練習問題\n問1\n\n3つの6面サイコロ投げを考える。3つの目の和が15になるまでサイコロ投げを繰り返す。どのような目が出て、その合計はいくつか。そして、何回目のサイコロ投げかを表示するコードを　\n\nforループを用いて書きなさい\nwhileループを用いて書きなさい\n上の2つのコードが同じ結果を表示することを確認したうえで、どちらの方法がより効率的か考察しなさい。\n\n\n\n\n[1] \"1目のサイコロ投げの結果: 4, 2, 6 (合計: 12)\"\n[1] \"2目のサイコロ投げの結果: 5, 4, 1 (合計: 10)\"\n[1] \"3目のサイコロ投げの結果: 5, 6, 4 (合計: 15)\"\n\n\n問2\n\n以下のような長さ5の文字型ベクトルcauseがある。「肥満の原因はXXでしょう。」というメッセージを表示するコードを書きなさい。ただし、「XX」の箇所にはベクトルの各要素を代入すること。表示されるメッセージは5個でなければならない。\n\n\ncause &lt;- c(\"喫煙\", \"飲酒\", \"食べすぎ\", \"寝不足\", \"ストレス\")\n\n\n\n[1] \"肥満の原因は喫煙でしょう。\"\n[1] \"肥満の原因は飲酒でしょう。\"\n[1] \"肥満の原因は食べすぎでしょう。\"\n[1] \"肥満の原因は寝不足でしょう。\"\n[1] \"肥満の原因はストレスでしょう。\"\n\n\n\n長さ4の文字型ベクトルeffectを以下のように定義する。このとき、「YYの原因はXXでしょう。」というメッセージを表示するコードを書きなさい。ただし、「YY」にはeffectの要素を、「XX」にはcauseの要素を代入すること。出力されるメッセージは20個でなければならない。\n\n\neffect &lt;- c(\"肥満\", \"腹痛\", \"不人気\", \"金欠\")\n\n\n長さ3の文字型ベクトルsolutionを以下のように定義する。このとき、「YYの原因はXXですが、ZZ改善されるでしょう。」というメッセージを出力するコードを書きなさい。ただし、「YY」にはeffectの要素を、「XX」にはcauseの要素を、「ZZ」にはsolutionの要素を代入すること。出力されるメッセージは60個でなければならない。\n\n\nsolution &lt;- c(\"この薬を飲めば\", \"一日一麺すれば\", \"神戸大に登山すれば\")\n\n問3\n\n長さ2のnumericベクトルdataについて考える。条件分岐を用いてdataの1番目の要素 (data[1]) が2番目の要素 (data[2]) より大きい場合、1番目の要素と2番目の順番を逆転させる条件分岐を作成せよ。たとえば、data &lt;- c(5, 3)なら、条件分岐後のdataの値がc(3, 5)になるようにするコードを書きなさい。\n\n\n\n\n\nChambers, John M. 2016. Extending R. Boca Raton, FL: CRC Press."
  },
  {
    "objectID": "functions.html#sec-func_intro",
    "href": "functions.html#sec-func_intro",
    "title": "12  関数の自作",
    "section": "12.1 関数の作成",
    "text": "12.1 関数の作成\n　これまでclass()や、sum()、print()など、様々な関数 (functions) を使ってきた。「Rで起こるあらゆることは関数の呼び出しである (Everything that happens in R is a function call)」(Chambers 2016) と言われるように、「Rを使う」ということは、「Rの関数を使う」ということである。\n　関数は関数名() ように括弧とセットで表記されることが多い。1つの関数でも、括弧の中に異なる引数を指定することで、さまざまな結果を出すことができる。例として、第7章でも説明したseq()関数について考えてみよう。この関数を使うと、一連の数字からなるベクトルを作ることができる。from で数列の初項を、to で数列の最終項を指定し、by で要素間の差（第2要素は第1要素に by を加えた値になる ）を指定するか、length.out で最終的にできるベクトルの要素の数を指定する。\n　Rを含むプログラミングにおける関数は、何かを入力すると何かを出力する箱のようなものである。関数を使うだけなら、関数という箱の中で何が起こっているかを理解する必要はない。例えば、mean() という関数に実数のベクトルを入力すると、平均値を実数として返すということを知っていれば、mean() が具体的にどのような計算を行っているかを知らなくても、実用上は問題ない。つまり、関数をブラックボックスとして扱うことができる。\nこのように1つの関数でも指定する内容は、by になったりlength.out になったりする。by や length.out、from、to などのように、関数で指定する対象になっているもののことを 仮引数 (parameter) と呼ぶ。また、by = 1 の1や、length.out = 10 の10のように、仮引数に実際に渡される値のことを実引数 (argument) と呼ぶ。特に誤解が生じないと思われる場合には、仮引数と実引数を区別せずに引数（ひきすう）と呼ぶ。 Rでは、1つの関数で使う引数の数が複数あることが多いので、仮引数を明示する習慣を身につけたほうがよい。 ただし、第1引数（関数で最初に指定する引数）として必ず入力すべきものは決められている場合がほとんどなので、第1引数の仮引数は省略されることが多い。仮引数が省略される代わりに、第1引数の実引数はほぼ必ず入力する（いくつかの例外もある）。\n関数とは()内の引数のデータを関数内部の手続きに沿って処理し、その結果を返すものです。あるデータを引数として受け付ける関数であれば、その引数を変えるだけで「先ほどとは異なるデータに対し、同じ処理を行う」ことが可能となり、コーディングの労力が省けます。\nここでは、ベクトルc(1, 2, 3, 4, 5)の総和を計算する方法について考えてみましょう。まず、1つ目は単純に足し算をする方法があります。\n\n1 + 2 + 3 + 4 + 5\n\n[1] 15\n\n\n他にも反復処理を使うことも可能です。とりわけ、1:100のようなベクトルを1つ目の方法で記述するのは時間の無駄でしょう。for()文を使った方法は以下のようになります。\n\nResult &lt;- 0\n\nfor (i in 1:5) {\n  Result &lt;- Result + i  \n}\n\n\nResult\n\n[1] 15\n\n\n数個の数字を足すだけなら方法1の方が楽でしょうし、数百個の数字の場合は方法2の方が効率的です。それでもやはりsum()関数の方が数倍は効率的です。また、関数を使うことで、スクリプトの量をへらすこともできます。1から100までの総和なら、方法2のfor (i in 1:5)をfor (i in 1:100)に変えることで対応可能ですが、それでも全体としては数行のコードで書かなくてもなりません。一方、sum(1:100)なら一行で済みます。\nsum()はまだマシな方です。たとえば、回帰分析をしたい場合、毎回回帰分析のコードを一から書くのはあまりにも非効率的です。lm()関数を使うと、データや回帰式などを指定するだけで、一連の作業を全て自動的に行い、その結果を返してくれます。中には回帰式の係数も計算してくれますが、他にも残差や決定係数なども計算してくれます。その意味で、lm()という関数は複数の機能を一つの関数としてまとめたものでもあります。\nこれらの関数は既にR開発チームが書いた関数ですが、ユーザー側から関数を作成することも可能です。長いコードを書く、同じ作業を繰り返す場合、関数の作成はほぼ必須とも言えます。ここではまず、簡単な関数を作成してみましょう。与えられた数字を二乗し、その結果を返すmyPower()関数を作ってみましょう。\n\nmyPower &lt;- function(x) {\n  x^2\n}\n\n\n# 引数が一つしかないので、myPower(24)も可能\nmyPower(x = 24)\n\n[1] 576\n\n\nそれではコードを解説します。関数は以下のように定義されます。\n関数名 &lt;- function (引数名) {\n  処理内容\n}\nまず、関数名をmyPowerとし、それが関数であることを宣言します。そして、この関数の引数の名前はxとします。それが\nmyPower &lt;- function (x)\nの部分です。続いて、{}内に処理内容を書きます。今回はx^2であり、これはxの2乗を意味します。そして、関数の処理結果が返されますが、{}内の最後の行が結果として返されます。x^2の部分はreturn(x^2)と書き換えることも可能です。return()は「この結果を返せよ」という意味の関数ですが、返す結果が最後の行である場合、省略可能であり、Hadely先生もこのような書き方を推奨しています。\nそれでは、もうちょっと複雑な関数を作成してみましょう。ベクトルを引数とし、その和を計算するmySum()という関数です。要するにsum()関数を再現したものです。\n\n# mySum関数を定義し、引数はxのみとする\nmySum &lt;- function(x) {\n  # 結果を格納するベクトルResultを生成し、0を入れておく\n  Result &lt;- 0\n  \n  # xの要素をiに一つずつ入れながら反復処理\n  for (i in x) {\n    # Resultに既存のResultの値にiを足した結果を上書きする\n    Result &lt;- Result + i\n  }\n  \n  # Resultを返す\n  Result\n}\n\n\nmySum(1:5)\n\n[1] 15\n\n\n普通のsum()関数と同じ動きをする関数が出来上がりました。よく見ると、上で説明した総和を計算する方法2のコードを丸ごと関数内に入っているだけです。変わったところがあるとすれば、for()文であり、for (i in 1:5)がfor (i in x)に変わっただけです。ここのxはmySum &lt;- function (x)のxを意味します。このように関数を一回作成しておくと、これからは総和を出す作業を1行に短縮することができます。\nこのmySum()ですが、一つ問題があります。それはxに欠損値が含まれている場合、結果がNAになることです。\n\nmySum(c(1, 2, 3, NA, 5))\n\n[1] NA\n\n\n実際、R内蔵関数であるsum()も同じですが、sum()にはna.rm =というもう一つの引数があり、これをTRUEにすることで欠損値を除いた総和が計算できます。つまり、関数は複数の引数を持つことができます。それでは、mySum()を改良してみましょう。ここにもna.rmという関数を追加し、na.rm引数がTRUEの場合、xから欠損値を除いた上で総和を計算するようにしましょう。\n\nmySum &lt;- function(x, na.rm = FALSE) {\n  if (na.rm == TRUE) {\n    x &lt;- x[!is.na(x)]\n  }\n  \n  Result &lt;- 0\n  \n  for (i in x) {\n      Result &lt;- Result + i\n  }\n  \n  Result\n}\n\n\nmySum(c(1, 2, 3, NA, 5))\n\n[1] NA\n\nmySum(c(1, 2, 3, NA, 5), na.rm = FALSE)\n\n[1] NA\n\nmySum(c(1, 2, 3, NA, 5), na.rm = TRUE)\n\n[1] 11\n\n\n変わったところは、まずfunction (x)がfunction (x, na.rm = FALSE)になりました。これはxとna.rmの引数が必要であるが、na.rmのデフォルト値はFALSEであることを意味します。デフォルト値が指定されている場合、関数を使用する際、その引数は省略できます。実際、sum()関数のna.rm引数もFALSEがデフォルトとなっており、省略可能となっています。\n次は最初に条件分岐が追加されました。ここではna.rmがTRUEの場合、xから欠損値を抜いたベクトルをxに上書きするように指定しました。もし、FALSEならこの処理は行いません。\nこれでR開発チームが作成したsum()関数と同じものが出来上がりました。それでは引数の順番について簡単に解説し、もうちょっと複雑な関数を作ってみましょう。引数の順番は基本的にfunction()の()内で定義した順番であるなら、引数名を省略することも可能です。\n\nmySum(c(1, 2, 3, NA, 5), TRUE)\n\n[1] 11\n\n\nただし、順番を逆にすると、以下のようにわけのわからない結果が返されます。\n\nmySum(TRUE, c(1, 2, 3, NA, 5))\n\nError in if (na.rm == TRUE) {: the condition has length &gt; 1\n\n\n任意の順番で引数を指定する場合、引数名を指定する必要があります。\n\nmySum(na.rm = TRUE, x = c(1, 2, 3, NA, 5))\n\n[1] 11\n\n\n自分で関数を作成し、他の人にも使ってもらう場合、引数名、順番、デフォルト値を適切に設定しておくことも大事です。"
  },
  {
    "objectID": "functions.html#sec-func_adv",
    "href": "functions.html#sec-func_adv",
    "title": "12  関数の自作",
    "section": "12.2 ちょっと複雑な関数",
    "text": "12.2 ちょっと複雑な関数\nそれではちょっとした遊び心を込めた関数を作ってみましょう。その名もドラクエ戦闘シミュレーターです。\n以下はドラクエ11のダメージ公式です。\n\nダメージの基礎値 = (攻撃力 / 2) - (守備力 / 4)\n\n0未満の場合、基礎値は0とする\n\nダメージの幅 = (ダメージの基礎値 / 16) + 1\n\n端数は切り捨てます (floor()関数使用)\n\n\nダメージの最小値は「ダメージの基礎値 - ダメージの幅」、最大値は「ダメージの基礎値 - ダメージの幅」となります。この最小値が負になることもありますが、その場合は0扱いになります。実際のダメージはこの範囲内でランダムに決まります (runif()関数使用)。\n\n# DQ_Attack関数を定義\nDQ_Attack &lt;- function(attack, defence, hp, enemy) {\n  ## 引数一覧\n  ## attack: 勇者の力 + 武器の攻撃力 (長さ1の数値型ベクトル)\n  ## defence: 敵の守備力 (長さ1の数値型ベクトル)\n  ## hp: 敵のHP (長さ1の数値型ベクトル)\n  ## enemy: 敵の名前 (長さ1の文字型ベクトル)\n  \n  # ダメージの基礎値\n  DefaultDamage &lt;- (attack / 2) - (defence / 4)\n  # ダメージの基礎値が負の場合、0とする\n  DefaultDamage &lt;- ifelse(DefaultDamage &lt; 0, 0, DefaultDamage)\n  # ダメージの幅\n  DamageWidth   &lt;- floor(DefaultDamage / 16) + 1\n  \n  # ダメージの最小値\n  DamageMin     &lt;- DefaultDamage - DamageWidth\n  # ダメージの最小値が負の場合、0とする\n  DamageMin     &lt;- ifelse(DamageMin &lt; 0, 0, DamageMin)\n  # ダメージの最大値\n  DamageMax     &lt;- DefaultDamage + DamageWidth\n  \n  # 敵の残りHPを格納する\n  CurrentHP     &lt;- hp\n  \n  # 残りHPが0より大きい場合、以下の処理を繰り返す\n  while (CurrentHP &gt; 0) {\n    # ダメージの最小値から最大値の間の数値を1つ無作為に抽出する\n    Damage &lt;- runif(n = 1, min = DamageMin, max = DamageMax)\n    # 小数点1位で丸める\n    Damage &lt;- round(Damage, 0)\n    # 残りのHPを更新する\n    CurrentHP &lt;- CurrentHP - Damage\n    # メッセージを表示\n    print(paste0(enemy, \"に\", Damage, \"のダメージ!!\"))\n  }\n  \n  # 上記の反復処理が終わったら勝利メッセージを出力\n  paste0(enemy, \"をやっつけた！\")\n}\n\n初めて見る関数が3つありますね。まず、floor()関数は引数の端数は切り捨てる関数です。たとえば、floor(2.1)もfloor(2.6)も結果は2です。続いて、runif()関数は指定された範囲の一様分布から乱数を生成する関数です。引数は生成する乱数の個数 (n)、最小値 (min)、最大値 (max)の3つです。runif(5, 3, 10)なら最小値3、最大値10の乱数を5個生成するという意味です。正規分布は平均値周辺の値が生成されやすい一方、一様分布の場合、ある値が抽出される確率は同じです。最後にround()関数は四捨五入の関数です。引数は2つあり、1つ目の引数は数値型のベクトルです。2つ目は丸める小数点です。たとえば、round(3.127, 1)の結果は3.1であり、round(3.127, 2)の結果は3.13となります。\nそれでは「ひのきのぼう」を装備したレベル1の勇者を考えてみましょう。ドラクエ5の場合、Lv1勇者の力は11、「ひのきのぼう」の攻撃力は2ですので、攻撃力は13です。まずは定番のスライムから狩ってみましょう。スライムのHPと守備力は両方7です。\n\nDQ_Attack(13, defence = 7, hp = 7, \"スライム\")\n\n[1] \"スライムに5のダメージ!!\"\n[1] \"スライムに4のダメージ!!\"\n\n\n[1] \"スライムをやっつけた！\"\n\n\nまぁ、こんなもんでしょう。それではスライムナイト (=ピエール)はどうでしょう。スライムナイトのHPのは40、守備力は44です。\n\nDQ_Attack(13, defence = 44, hp = 40, \"スライムナイト\")\n\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに0のダメージ!!\"\n[1] \"スライムナイトに1のダメージ!!\"\n\n\n[1] \"スライムナイトをやっつけた！\"\n\n\nこれだと「なんと　スライムナイトが　おきあがりなかまに　なりたそうに　こちらをみている！」のメッセージを見る前に勇者ご一行が全滅しますね。エスターク (HP: 9000 / 守備力: 250)は計算するまでもないでしょう…\n以上の関数に条件分岐を追加することで「かいしんの　いちげき！」を入れることもできますし1、逆に敵からの攻撃を計算して誰が先に倒れるかをシミュレーションすることも可能でしょうね。色々遊んでみましょう。"
  },
  {
    "objectID": "functions.html#sec-func_in_func",
    "href": "functions.html#sec-func_in_func",
    "title": "12  関数の自作",
    "section": "12.3 関数 in 関数",
    "text": "12.3 関数 in 関数\n当たり前かも知れまっせんが、自作関数を他の自作関数に含めることもできます。ここでは乱数を生成する関数を作ってみましょう。パソコンだけだと完全な乱数を作成することは不可能ですが2、乱数に近いものは作れます。このようにソフトウェアで生成された乱数は擬似乱数と呼ばれ、様々なアルゴリズムが提案されています。天才、フォン・ノイマン大先生も乱数生成では天才ではなかったらしく、彼が提案した平方採中法 (middle-square method)は使い物になりませんので、ここではもうちょっとマシな方法である線形合同法 (linear congruential generators; 以下、LCG)を採用します。平方採中法よりは式が複雑ですが、それでも非常に簡単な式で乱数が生成可能であり、Rによる実装に関しては平方採中法より簡単です。ちなみに、線形合同法にも様々な問題があり、Rのデフォルトは広島大学の松本眞先生と山形大学の西村拓士先生が開発しましたメルセンヌ・ツイスタ (Mersenne twister)を採用しています。それでは、LCGのアルゴリズムから見ましょう。\n乱数の列があるとし、\\(n\\)番目の乱数を\\(X_n\\)とします。この場合、\\(X_{n+1}\\)は以下のように生成されます。\n\\[\nX_{n+1} = (aX_n + c) \\text{ mod } m\n\\]\n\\(\\text{mod}\\)は余りを意味し、\\(5 \\text{mod} 3\\)は5を3で割った際の余りですので、2となります。\\(a\\)と\\(c\\)、\\(m\\)は以下の条件を満たす任意の数です。\n\\[\\begin{align}\n0 &lt; &  m, \\\\\n0 &lt; &  a &lt; m, \\\\\n0 \\leq &  c &lt; m.\n\\end{align}\\]\nベストな\\(a\\)、\\(c\\)、\\(m\\)も決め方はありませんが、ここではTurbo Cの設定を真似て\\(a = 22695477\\)、\\(c = 1\\)、\\(m = 2^{32}\\)をデフォルト値として設定します3。そして、もう一つ重要なのが最初の数、つまり\\(X_n\\)をどう決めるかですが、これは自由に決めて問題ありません。最初の数 (\\(X_0\\))はシード (seed)と呼ばれ、最終的には使わない数字となります。それではseedという引数からある乱数を生成する関数rng_number()を作ってみましょう。\n\nrng_number &lt;- function(seed, a = 22695477, c = 1, m = 2^32) {\n  (a * seed + c) %% m\n}\n\n簡単な四則演算のみで構成された関数ですね。ちなみに%%は余りを計算する演算子です。とりあえず、seedを12345に設定し、一つの乱数を生成してみましょう。\n\nrng_number(12345)\n\n[1] 1002789326\n\n\nかなり大きい数字が出ました。ちなみに線形合同法で得られる乱数の最大値は\\(m\\)、最小値は0です。次は、今回得られた乱数1.0027893^{9}を新しいseedとし、新しい乱数を作ってみましょう。\n\nrng_number(1002789326)\n\n[1] 3785644968\n\n\nこの作業を繰り返すと、(疑似)乱数の数列が得られます。続いて、この作業をn回繰り返し、長さnの乱数ベクトルを返す関数LCGを作ってみましょう。いかがコードになります。\n\nLCG &lt;- function(n, seed, a = 22695477, c = 1, m = 2^32) {\n  rng_vec    &lt;- rep(NA, n + 1) # seedも入るので長さn+1の空ベクトルを生成\n  rng_vec[1] &lt;- seed           # 1番目の要素にseedを入れる\n  \n  # iに2からn+1までの値を順次的に投入しながら、反復処理\n  for (i in 2:(n+1)) {\n    # rng_vecのi番目にi-1番目の要素をseedにした疑似乱数を格納\n    rng_vec[i] &lt;- rng_number(rng_vec[i - 1], a, c, m)\n  }\n  \n  rng_vec &lt;- rng_vec[-1] # 1番目の要素 (seed)を捨てる\n  rng_vec &lt;- rng_vec / m # 最小値0、最大値1になるように、mで割る\n  \n  rng_vec # 結果を返す\n}\n\nそれでは、詳細に解説します。\n\n1行目: 関数LCGを定義し、必要な引数としてnとseedを設定する。\n2行目: 結果を格納する空ベクトルrng_vecを生成。ただし、1番目にはseedが入るので、長さをn+1とする。\n3行目: rng_vecの1番目にseedを格納する。\n6行目: 疑似乱数をn回生成し、格納するように反復作業を行う。任意の変数はiとし、iに代入される値は2からn+1までである。\n8行目: rng_vecのi-1番目要素をseedにした疑似乱数を生成し、rng_vecのi番目に格納する。1回目の処理だとi=2であるため、rng_vec[1] (= seed)をseedにした疑似乱数が生成され、rng_vec[2]に格納される。\n11行目: rng_vecの1番目の要素はseedであるため、捨てる。\n12行目: 乱数が最小値0、最大値1になるように、調整する。具体的には得られた乱数をm (デフォルトは\\(2^{32}\\))で割るだけである。\n14行目: 結果ベクトルを返す。\n\nそれでは、seedを19861008とした疑似乱数10000個を生成し、LCG_Numbersという名のベクトルに格納してみましょう。結果を全て表示させるのは無理があるので、最初の20個のみを確認してみます。\n\nLCG_Numbers &lt;- LCG(10000, 19861008)\nhead(LCG_Numbers, 20)\n\n [1] 0.58848246 0.09900449 0.21707060 0.89462981 0.23421890 0.72341249\n [7] 0.55965400 0.59552685 0.96594972 0.69050965 0.98383344 0.20136551\n[13] 0.25856502 0.37569497 0.50086451 0.03986446 0.89291806 0.24760102\n[19] 0.27912510 0.24493750\n\n\n正直、これが乱数かどうかは見るだけでは分かりませんね。簡単な確認方法としては、これらの乱数列のヒストグラムを見れば分かります。得られた数列が本当に乱数(に近いもの)なら、その分布は一様分布に従っているからです。ただし、一様分布に従っていることが乱数を意味するものではありません。\n可視化については第18章以降で解説しますが、ここでは簡単にhist()関数を使ってみましょう。必要な引数はnumeric型のベクトルのみです。以下のコードにあるxlab =などはラベルを指定する引数ですが、省略しても構いません。\n\nhist(LCG_Numbers, xlab = \"乱数\", ylab = \"度数\", \n     main = \"生成された乱数10000個のヒストグラム\")\n\n\n\n\n\n\n\n\nややギザギザしているように見えますが4、これなら一様分布だと考えて良いでしょう。"
  },
  {
    "objectID": "functions.html#sec-func_exercise",
    "href": "functions.html#sec-func_exercise",
    "title": "12  関数の自作",
    "section": "12.4 練習問題",
    "text": "12.4 練習問題\n問1\n\n長さ2のnumericベクトルDataについて考える。条件分岐を用いてDataの1番目の要素 (Data[1])が2番目の要素 (Data[2])より大きい場合、1番目の要素と2番目の順番を逆転させる条件分岐を作成せよ。たとえば、Data &lt;- c(5, 3)なら、条件分岐後のDataの値がc(3, 5)になること。\n\n問2\n\n与えられた正の実数の平方根を求めるmy_sqrt()を作成する。平方根を計算する方法はHero of Alexandriaの近似法5を使用する。\n\n平方根を求めるx、任意の初期値g、非常に小さい正の実数eを入力する。eの既定値は0.001とする。\ngの2乗を計算し、x - g^2の絶対値をgapとする（gapの初期値はInfとする）。\ngapがeより小さい場合、gをxの平方根として返す。\ngapがeより大きい場合、g + (x / g)を新しいgとする。\n2へ戻る。\n\nwhile()関数を使えば簡単である。\n\n\n# Rのsqrt()関数\nsqrt(29)\n\n[1] 5.385165\n\n# 計算例1\nmy_sqrt(29, 5) # 29の平方根。初期値は5\n\n[1] 5.385185\n\n# 計算例2\nmy_sqrt(29, 5, e = 0.00001) # 29の平方根。初期値は5。eは0.00001\n\n[1] 5.385165\n\n# 計算例3\nmy_sqrt(-3, 5, e = 0.00001) # あえてエラーを出してみる\n\nError in my_sqrt(-3, 5, e = 1e-05): xは正の実数でなければなりません。\n\n\n問3\n\n問3ではベクトルの1番目要素と2番目の要素を比較し、前者が大きい場合において順番を入れ替える条件分岐を行った。これを長さ3以上のベクトルにも適用したい。長さ4のnumeric型ベクトルDataがある場合の計算手順について考えてみよう。\n\nData[1]とData[2]の要素を比較し、Data[1] &gt; Data[2]の場合、入れ替える。\nData[2]とData[3]の要素を比較し、Data[2] &gt; Data[3]の場合、入れ替える。\nData[3]とData[4]の要素を比較し、Data[3] &gt; Data[4]の場合、入れ替える。この段階でData[4]はDataの最大値が格納される。\n続いて、Data[1]とData[2]の要素を比較し、Data[1] &gt; Data[2]の場合、入れ替える。\nData[2]とData[3]の要素を比較し、Data[2] &gt; Data[3]の場合、入れ替える。この段階でData[3]にはDataの2番目に大きい数値が格納される。\n最後にData[1]とData[2]の要素を比較し、Data[1] &gt; Data[2]の場合、入れ替える。ここで並び替えは終了\n\nヒント: 2つのfor()文が必要となる。これは「バブルソート」と呼ばれる最も簡単なソートアルゴリズムである。イメージとしては、長さNのベクトルの場合、n番目の要素とn+1番目の要素を比較しながら、大きい方を後ろの方に追い込む形である。最初は、Data[4]最後の要素に最大値を格納し、続いて、Data[3]に次に大きい数値を、Data[2]に次に大きい数値を入れる仕組みである。\n\n最初はData[1]とData[2]、Data[2]とData[3]、Data[3]とData[4]の3ペアの比較を行う。\n続いて、Data[1]とData[2]、Data[2]とData[3]の2ペアの比較を行う\n最後に、Data[1]とData[2]の1ペアの比較を行う\nつまり、外側のfor()文は「Dataの長さ-1」回繰り返すことになる。\n内側のfor()文は3, 2, 1ペアの比較を行うことになる。\n\n\n問4\n\n「問4」の練習問題で作成したコードを関数化せよ。関数名はmySort()であり、引数は長さ2以上のnumeric型ベクトルのみである。引数名は自由に決めても良いし、dataやxなどを使っても良い。\n\n問5\n\n既に作成したDQ_Attack関数を修正してみよう。今の関数は通常攻撃のみであるが、稀に「会心の一撃」が発生するように修正する。\n\n会心の一撃が発生する確率は1/32とする (Hint: 0から1の間の乱数を生成し、その乱数が1/32以下であるか否かで条件分岐させる)。乱数の生成はrunif()または、自作関数のLCG()でも良い。\n会心の一撃のダメージの最小値は攻撃力の95%、最大値は105%とする。\n会心の一撃が発生したら、\"かいしんのいちげき! スライムに10のダメージ!!\"のようなメッセージを出力させること。\n\n\n問6\n\n与えられたベクトルxからn個の要素を無作為に抽出する関数、mySample()を定義せよ。mySample()の引数はxとn、seedとし、xは長さ1以上のベクトルとする。nは長さ1の整数型ベクトルである。\n\n以下の場合、エラーメッセージを出力し、処理を中止させること。\n\nnとseedが長さ1ベクトルでない場合、\nseedがnumeric型でない場合\nnが整数でない場合 (floor(n) == nで判定)\n\nヒント: LCG()関数を用いて乱数を生成した場合、生成された擬似乱数は0以上1以下である。ベクトルxの長さをlength(x)とした場合、擬似乱数にlength(x)を掛けると、擬似乱数は0以上length(x)以下になる。これらの値を切り上げると (ceiling()関数)、その値は1以上length(x)以下の整数となる。\n\n\n\n\n\n\nChambers, John M. 2016. Extending R. Boca Raton, FL: CRC Press."
  },
  {
    "objectID": "datahandling1.html#sec-handling1-intro",
    "href": "datahandling1.html#sec-handling1-intro",
    "title": "13  データハンドリング [抽出]",
    "section": "13.1 データハンドリングとtidyverse",
    "text": "13.1 データハンドリングとtidyverse\n\nThe tidyverse is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. (Tidyverseホームページから)\n\n　Tidyverseとはデータサイエンスのために考案された、強い信念と思想に基づいたRパッケージの集合です。Tidyverseに属するパッケージは思想、文法およびデータ構造を共有しています。Tidyverseの中核をなすパッケージは{ggplot2}(第18、19、20、21章)、{dplyr}(第13、14章)、{tidyr}(第16章)、{readr}(第8.1章)、{purrr} (第27章)、{tibble}(第10.4章)、{stringr} (第17章)、{forcats} (第15章)などがあり、このパッケージを支える数十のパッケージが含まれています。これらのパッケージは個別に読み込む必要はなく、{tidyverse}パッケージを読み込むだけで十分です。\n\nlibrary(tidyverse)\n\n　Rにおけるデータハンドリング (データ操作)の標準が{dplyr}と{tidyr}中心となり、文字列の処理は{stringr}、factor型の操作は{forcats}、大量のモデルを自動的に分析し、結果を処理するためには{tibble}と{purrr}、可視化は{ggplot2}が主に使われています。これらのパッケージ間、あるいはパッケージ内におけるオブジェクトのやり取りは全てパイプ演算子を通じて行われています。また、これらのパッケージは整然データ (tidydata)を想定するか、整然データの作成するに特化しています。\n　Tidyverseの思想に基づいた「tidyverse流のコーディング」は現在のRそのものと言っても過言ではありません。ただし、tidyverseじゃないと出来ないデータハンドリング、可視化などはありません。tidyverseはデータサイエンスの思想に近いものであり、「異なる思想を持っているからこのような分析はできない」といったものはありません。tidyverseという概念が提唱される前にもRは存在し、tidyverse無き世界で今と同じことをやってきました。ただし、tidyverse流で書かれたRコードは可読性が優れ、コードを書く手間も短くなります。tidyverseの考え方がRのける「標準語」として定着しつつあるのは否めない事実であり、学習する誘引としては十分すぎるでしょう。"
  },
  {
    "objectID": "datahandling1.html#sec-handling1-pipe",
    "href": "datahandling1.html#sec-handling1-pipe",
    "title": "13  データハンドリング [抽出]",
    "section": "13.2 パイプ演算子 (|>)",
    "text": "13.2 パイプ演算子 (|&gt;)\n\n\n\n\n\n\n旧パイプ演算子%&gt;%\n\n\n\n　R4.1が公開されるまでのパイプ演算子は以下で紹介する|&gt;でなく、{magrittr}パッケージが提供する%&gt;%であった。現時点においてインターネット上の記事、書籍での主流は%&gt;%であるが、最近の流れはR内蔵（native）パイプ演算子の|&gt;である。しかし、使い方はほぼ同じであるため、|&gt;の箇所を%&gt;%に置換しても問題ない。ただし、位置指定子（placeholder）の記号が|&gt;では_、%&gt;%では.であることには注意されたい。\n\n\n　{dplyr}パッケージを利用する前にパイプ演算子について説明します。パイプ演算子は{dplyr}に含まれている演算子ではなく、{magrittr}という別のパッケージから提供される演算子ですが、{tidyverse}パッケージを読み込むと自動的に読み込まれます。パイプ演算子はx |&gt; y()のような書き方となりますが、これは「xをy()の第一引数として渡す」ことを意味します。xの部分はベクトルやデータフレームのようなオブジェクトでも、関数でも構いません。なぜなら、関数から得られた結果もまたベクトルやデータフレームといったものになるからです。つまり、x() |&gt; y()という使い方も可能です。そして、パイプは無限に繋ぐこともできます。「データdfを関数x()で処理をし、その結果をまた関数y()で処理する」ことは、パイプを使うとdf |&gt; x() |&gt; y()のような書き方となります。\n　たとえば、「paste(3, \"+\", 5, \"=\", 8)を実行し、その結果をrep()関数を使って3回複製し、それをprint()を使って出力する」コードを考えてみましょう。方法としては2つ考えられます。まずは、それぞれの処理を別途のオブジェクトに格納する方法です。そして二つ目は関数の中に関数を使う方法です。\n\n# 方法1: 一関数一オブジェクト\nResult1 &lt;- paste(3, \"+\", 5, \"=\", 8)\nResult2 &lt;- rep(Result1, 3)\nprint(Result2)\n\n[1] \"3 + 5 = 8\" \"3 + 5 = 8\" \"3 + 5 = 8\"\n\n# 方法2: 関数の中に関数の中に関数\nprint(rep(paste(3, \"+\", 5, \"=\", 8), 3))\n\n[1] \"3 + 5 = 8\" \"3 + 5 = 8\" \"3 + 5 = 8\"\n\n\n　どれも結果は同じです。コードを書く手間を考えれば、後者の方が楽かも知れませんが、可読性があまりよくありません。一方、前者は可読性は良いものの、コードも長くなり、オブジェクトを2つも作ってしまうのでメモリの無駄遣いになります。\n　コードの可読性と書く手間、両方を満足する書き方がパイプ演算子|&gt;です。まずは、例から見ましょう。\n\n# パイプを使う場合\npaste(3, \"+\", 5, \"=\", 8) |&gt; rep(3) |&gt; print()\n\n[1] \"3 + 5 = 8\" \"3 + 5 = 8\" \"3 + 5 = 8\"\n\n\n　まず、結果は先ほどと同じです。それではコードの説明をしましょう。まずは、paste(3, \"+\", 5, \"=\", 8)を実行します。そしてその結果をそのままrep()関数の第一引数として渡されます。つまり、rep(paste(3, \"+\", 5, \"=\", 8), 3)になるわけです。ここではrep(3)と書きましたが、第一引数が渡されたため、3は第二引数扱いになります (パイプ演算子前のオブジェクトを第二、三引数として渡す方法は適宜説明します。)。そして、これをまたprint()関数に渡します。結果としてはprint(rep(paste(3, \"+\", 5, \"=\", 8), 3))となります。\n　関数を重ねると読む順番は「カッコの内側から外側へ」になりますが、パイプ演算子を使うと「左 (上)から右 (下)へ」といったより自然な読み方が可能になります。また、以下のコードのように、パイプ演算子後に改行を行うことでより読みやすいコードになります。これからはパイプ演算子の後は必ず改行をします。\n\n# 改行 (+字下げ)したらもっと読みやすくなる\npaste(3, \"+\", 5, \"=\", 8) |&gt; \n    rep(3) |&gt; \n    print()\n\n　これらの話をまとめてみましょう。あるデータを関数1に渡し、その結果を関数2に渡し、その結果を関数3に渡したものを最終結果として格納するとします。まず、パイプ演算子を使わない方法としては2つが考えられます。1つ目の方法は各処理の結果を、別途のオブジェクトとして格納する方法であり、コードで示すと以下のようになります。\n\n結果1 &lt;- 関数1(データ)\n結果2 &lt;- 関数2(結果1)\n結果  &lt;- 関数3(結果2)\n\n　これを可視化したものが 図 13.1 です。一回の処理ごとに結果を保存し、それをまた次の処理時においてデータとして使うイメージです。\n\n\n\n図 13.1: パイプ演算子を使わない場合（1）\n\n\n　こちらはコードの読みやすさはある程度確保されますが、コードが比較的長くなり、最終的には使わない結果1と結果2がメモリに残るといった短所があります1。\n　次の方法は、関数から得られた結果を、そのまま別の関数の引数として渡す方法であり、コードで示すと以下のようになります。\n\n結果 &lt;- 関数3(関数2(関数1(データ)))\n\n　これを可視化したものが 図 13.2 です。\n\n\n\n図 13.2: パイプ演算子を使わない場合（2）\n\n\n　こちらはメモリの無駄遣いもなく、コードも短くなりましたが、既に指摘したとおり、コードの可読性が低くなります（書き方と読み方が逆になる）。パイプ演算子を使うということは、コードの短くし、メモリを効率的に使い、可読性を高めるとこととなります。先ほどのコードをパイプ演算子を使って整理すると以下のようになります。\n\n結果 &lt;- データ |&gt; \n  関数1() |&gt; \n  関数2() |&gt; \n  関数3()\n\n　このコードを可視化したものが 図 13.3 です。\n\n\n\n図 13.3: パイプ演算子を使う場合\n\n\n　処理後の結果を保存せず、すぐに次のプロセスに渡すことで、メモリ（ 図 13.1 のボウル）無駄を減らすことができます。またコードの書き方と読み方が一致します（格納の部分だけ逆）。パイプ演算子はたしかに便利で、「今どき」のRの書き方を象徴するようなものですが、一つの結果を出すまであまりにも多くのパイプ演算子を使うことはあ望ましくありません。\n　データハンドリングもこれと同様に、様々な作業を順に沿って行う必要があります。例えば、「（1）列を選択して、（2）欠損値を含む列を除去して、（3）ある変数の値を100倍にして、（4）ある変数の値がが小さい行から大きい順へ並び替える」といった手順です。これらの作業はパイプ演算子を使えば、スムーズに行うことが可能です。"
  },
  {
    "objectID": "datahandling1.html#sec-handling1-select",
    "href": "datahandling1.html#sec-handling1-select",
    "title": "13  データハンドリング [抽出]",
    "section": "13.3 列の抽出",
    "text": "13.3 列の抽出\n　それでは今回の実習用データを読み込みましょう。Ramen.csvには「ぐるなび」から取得したラーメン屋6292店舗の情報が入っています。具体的には東京、神奈川、千葉、埼玉、大阪、京都、兵庫、奈良、和歌山それぞれ都府県にあるラーメン屋の中から最大1000店舗の情報を抽出したものです。東京都は、ぐるなびに登録したラーメン屋が3000店舗以上ですが、1000店舗の基準はぐるなびの「おすすめ」の順で上位1000店舗となります。また、店側またはぐるなびが登録したカテゴリを基準に抽出したため、実際はラーメン屋ではないにもかかわらずラーメン屋としてデータ内に含まれている可能性があります。\n　まず、このデータを読み込み、dfという名付けます。\n\ndf &lt;- read_csv(\"Data/Ramen.csv\")\n\n　データの中身を確認してみましょう。\n\ndf\n\n# A tibble: 6,292 × 14\n   ID     Name  Pref  Zipcode Latitude Longitude Line  Station  Walk   Bus   Car\n   &lt;chr&gt;  &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 e5396… 居酒… 東京… 1040031     35.7      140. 地下… 銀座一…     3    NA    NA\n 2 gfeb6… 本格… 東京… 1100005     35.7      140. 地下… 仲御徒…     1    NA    NA\n 3 ggt59… 食べ… 東京… 1250041     35.8      140. ＪＲ… 金町駅      2    NA    NA\n 4 g1813… 博多… 東京… 1920904     35.7      139. ＪＲ  八王子…     1    NA    NA\n 5 ggww1… まさ… 東京… 1500042     35.7      140. 地下… 渋谷駅      7    NA    NA\n 6 gdzk5… 完全… 東京… 1000013     35.7      140. 地下… 虎ノ門…     3    NA    NA\n 7 ga2g2… 鶏そ… 東京… 1760006     35.7      140. 西武… 江古田…     2    NA    NA\n 8 gg9m1… 宴会… 東京… 1010021     35.7      140. ＪＲ  秋葉原…     4    NA    NA\n 9 gdvk2… 中国… 東京… 1000006     35.7      140. ＪＲ  有楽町…     1    NA    NA\n10 gggb2… 中国… 東京… 1140002     35.8      140. 地下… 王子駅      2    NA    NA\n# ℹ 6,282 more rows\n# ℹ 3 more variables: Budget &lt;dbl&gt;, ScoreN &lt;dbl&gt;, Score &lt;dbl&gt;\n\n\n　1行目の# A tibble: 2,000 x 12から、ケース数 (店舗数)は2000、変数は12個あることが分かります。各変数の詳細は 表 13.1 の通りです。\n\n\n\n\n\n表 13.1:  Ramen.csvの詳細 \n  \n    \n    \n      変数名\n      説明\n    \n  \n  \n    ID\n\n店舗ID\n    Name\n\n店舗名\n    Pref\n\n店舗の所在地 (都府県)\n    Zipcode\n\n店舗の郵便番号\n    Latitude\n\n緯度\n    Longitude\n\n経度\n    Line\n\n最寄りの駅の路線\n    Station\n\n最寄りの駅\n    Walk\n\n最寄りの駅からの距離 (徒歩; 分)\n    Bus\n\n最寄りの駅からの距離 (バス; 分)\n    Car\n\n最寄りの駅からの距離 (車; 分)\n    Budget\n\n平均予算 (円)\n    ScoreN\n\n口コミの数\n    Score\n\n口コミ評価の平均値\n  \n  \n  \n\n\n\n\n\n　それではここからはdfを用いた{dplyr}の様々な機能を紹介していきます。\n\n13.3.1 特定の列を抽出する\n　まずは、データフレームから特定の列のみを残す、除去する方法について紹介します。たとえば、dfからID、Name、Pref、Scoreのみを残すとします。{dplyr}を使わない方法と{dplyr}のselect()関数を使った方法を紹介します。\n\n# dplyrを使わない方法\ndf[, c(\"ID\", \"Name\", \"Pref\", \"Score\")]\n\n# A tibble: 6,292 × 4\n   ID      Name                                                     Pref   Score\n   &lt;chr&gt;   &lt;chr&gt;                                                    &lt;chr&gt;  &lt;dbl&gt;\n 1 e539604 居酒屋 龍記 京橋店                                       東京都 NA   \n 2 gfeb600 本格上海料理 新錦江 上野御徒町本店                       東京都  4.5 \n 3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ）               東京都 NA   \n 4 g181340 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル）併設 東京都 NA   \n 5 ggww100 まさ屋 渋谷店                                            東京都 NA   \n 6 gdzk500 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店              東京都 NA   \n 7 ga2g202 鶏そば きらり                                            東京都 NA   \n 8 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店                    東京都  3.33\n 9 gdvk200 中国料理 宝龍                                            東京都  2.5 \n10 gggb200 中国料理 天安門                                          東京都 NA   \n# ℹ 6,282 more rows\n\n# dplyr::select()を使う方法\n# select(df, ID, Name, Pref, Score)でもOK\ndf |&gt;\n  select(ID, Name, Pref, Score)\n\n# A tibble: 6,292 × 4\n   ID      Name                                                     Pref   Score\n   &lt;chr&gt;   &lt;chr&gt;                                                    &lt;chr&gt;  &lt;dbl&gt;\n 1 e539604 居酒屋 龍記 京橋店                                       東京都 NA   \n 2 gfeb600 本格上海料理 新錦江 上野御徒町本店                       東京都  4.5 \n 3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ）               東京都 NA   \n 4 g181340 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル）併設 東京都 NA   \n 5 ggww100 まさ屋 渋谷店                                            東京都 NA   \n 6 gdzk500 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店              東京都 NA   \n 7 ga2g202 鶏そば きらり                                            東京都 NA   \n 8 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店                    東京都  3.33\n 9 gdvk200 中国料理 宝龍                                            東京都  2.5 \n10 gggb200 中国料理 天安門                                          東京都 NA   \n# ℹ 6,282 more rows\n\n\n　どれも結果は同じですが、select()関数を使った方がより読みやすいコードになっているでしょう。むろん、select()関数を使わない方がスッキリする方も知るかも知れません。実際、自分でパッケージなどを作成する際はselect()を使わない場合が多いです。ただし、一般的な分析の流れではselect()の方がコードも意味も明確となり、パイプ演算子でつなぐのも容易です。\n　select()関数の使い方は非常に簡単です。第一引数はデータフレームですが、パイプ演算子を使う場合は省略可能です。第二引数以降の引数はデータフレームの変数名です。つまり、ここには残す変数名のみを書くだけで十分です。\n　また、select()関数を使って列の順番を変えることもできます。たとえば、ID、Pref、Name、Scoreの順で列を残すなら、この順番で引数を書くだけです。\n\ndf |&gt;\n  select(ID, Pref, Name)\n\n# A tibble: 6,292 × 3\n   ID      Pref   Name                                                    \n   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;                                                   \n 1 e539604 東京都 居酒屋 龍記 京橋店                                      \n 2 gfeb600 東京都 本格上海料理 新錦江 上野御徒町本店                      \n 3 ggt5900 東京都 食べ飲み放題×中華ビストロ NOZOMI（のぞみ）              \n 4 g181340 東京都 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル）併設\n 5 ggww100 東京都 まさ屋 渋谷店                                           \n 6 gdzk500 東京都 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店             \n 7 ga2g202 東京都 鶏そば きらり                                           \n 8 gg9m100 東京都 宴会個室×餃子酒場 北京飯店 秋葉原本店                   \n 9 gdvk200 東京都 中国料理 宝龍                                           \n10 gggb200 東京都 中国料理 天安門                                         \n# ℹ 6,282 more rows\n\n\n\n\n13.3.2 特定の列を抽出し、列名を変更する\n　また、特定の列を残す際、変数名を変更することも可能です。今回もID、Name、Pref、Scoreのみを残しますが、Pref列はPrefectureに変えてみましょう。\n\ndf |&gt;\n  select(ID, Name, Prefecture = Pref, Score)\n\n# A tibble: 6,292 × 4\n   ID      Name                                                Prefecture Score\n   &lt;chr&gt;   &lt;chr&gt;                                               &lt;chr&gt;      &lt;dbl&gt;\n 1 e539604 居酒屋 龍記 京橋店                                  東京都     NA   \n 2 gfeb600 本格上海料理 新錦江 上野御徒町本店                  東京都      4.5 \n 3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ）          東京都     NA   \n 4 g181340 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル… 東京都     NA   \n 5 ggww100 まさ屋 渋谷店                                       東京都     NA   \n 6 gdzk500 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店         東京都     NA   \n 7 ga2g202 鶏そば きらり                                       東京都     NA   \n 8 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店               東京都      3.33\n 9 gdvk200 中国料理 宝龍                                       東京都      2.5 \n10 gggb200 中国料理 天安門                                     東京都     NA   \n# ℹ 6,282 more rows\n\n\n　抽出する際、変数を新しい変数名 = 既存の変数名にするだけで、変数名が簡単に変更できました。もし、特定の列は抽出しないものの、変数名を変えるにはどうすれば良いでしょうか。ここではdfのPrefをPrefectureに、WalkをDistanceに変更してみます。{dplyr}を使わない場合と{dplyr}のrename()関数を使う場合を両方紹介します。\n　まずは、name()関数についてですが、これはデータフレームの変数名をベクトルとして出力する関数です。\n\nnames(df)\n\n [1] \"ID\"        \"Name\"      \"Pref\"      \"Zipcode\"   \"Latitude\"  \"Longitude\"\n [7] \"Line\"      \"Station\"   \"Walk\"      \"Bus\"       \"Car\"       \"Budget\"   \n[13] \"ScoreN\"    \"Score\"    \n\n\n　察しの良い読者は気づいたかも知れませんが、names(データフレーム名)の結果はベクトルであり、上書きも可能です。つまり、names(df)の3番目と9番目の要素を\"Prefecture\"と\"Distance\"に上書きすることができるということです。\n\n# dplyrを使わずに列名を変更する方法\nnames(df)[c(3, 9)] &lt;- c(\"Prefecture\", \"Distance\")\n\n# dfの中身を出力\ndf\n\n# A tibble: 6,292 × 14\n   ID      Name     Prefecture Zipcode Latitude Longitude Line  Station Distance\n   &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;      &lt;dbl&gt;\n 1 e539604 居酒屋 … 東京都     1040031     35.7      140. 地下… 銀座一…        3\n 2 gfeb600 本格上…  東京都     1100005     35.7      140. 地下… 仲御徒…        1\n 3 ggt5900 食べ飲…  東京都     1250041     35.8      140. ＪＲ… 金町駅         2\n 4 g181340 博多餃…  東京都     1920904     35.7      139. ＪＲ  八王子…        1\n 5 ggww100 まさ屋 … 東京都     1500042     35.7      140. 地下… 渋谷駅         7\n 6 gdzk500 完全個…  東京都     1000013     35.7      140. 地下… 虎ノ門…        3\n 7 ga2g202 鶏そば … 東京都     1760006     35.7      140. 西武… 江古田…        2\n 8 gg9m100 宴会個…  東京都     1010021     35.7      140. ＪＲ  秋葉原…        4\n 9 gdvk200 中国料…  東京都     1000006     35.7      140. ＪＲ  有楽町…        1\n10 gggb200 中国料…  東京都     1140002     35.8      140. 地下… 王子駅         2\n# ℹ 6,282 more rows\n# ℹ 5 more variables: Bus &lt;dbl&gt;, Car &lt;dbl&gt;, Budget &lt;dbl&gt;, ScoreN &lt;dbl&gt;,\n#   Score &lt;dbl&gt;\n\n\n　簡単に変数名の変更ができました。続いて、{dplyr}のrename()関数を使った方法です。今回は、PrefectureをPrefに、DistanceをWalkに戻して見ましょう。そして、出力するだけにとどまらず、dfに上書きしましょう。\n\n# dfのPrefectureをPrefに、DistanceをWalkに変更し、上書きする\ndf &lt;- df |&gt;\n  rename(Pref = Prefecture, Walk = Distance)\n\n　これで終わりです。実はselect()関数と使い方がほぼ同じです。ただし、残す変数名を指定する必要がなく、名前を変更する変数名と新しい変数名を入れるだけです。変数が少ないデータならselect()でもあまり不便は感じないかも知れませんが、変数が多くなるとrename()関数は非常に便利です。\n\n\n13.3.3 特定の列を除外する\n　逆に、一部の変数をデータフレームから除去したい場合もあるでしょう。たとえば、緯度 (Latitude)と経度 (Longitude)はラーメン屋の情報としては不要かもしれません。この2つの変数を除外するためにはどうすれば良いでしょうか。まず考えられるのは、この2つの変数を除いた変数を指定・抽出する方法です。\n\ndf |&gt;\n  select(ID, Name, Pref, Zipcode, \n         Line, Station, Walk, Bus, Car, Budget, ScoreN, Score)\n\n# A tibble: 6,292 × 12\n   ID    Name  Pref  Zipcode Line  Station  Walk   Bus   Car Budget ScoreN Score\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 e539… 居酒… 東京… 1040031 地下… 銀座一…     3    NA    NA   3000      0 NA   \n 2 gfeb… 本格… 東京… 1100005 地下… 仲御徒…     1    NA    NA   2000      2  4.5 \n 3 ggt5… 食べ… 東京… 1250041 ＪＲ… 金町駅      2    NA    NA   2980      0 NA   \n 4 g181… 博多… 東京… 1920904 ＪＲ  八王子…     1    NA    NA   2000      0 NA   \n 5 ggww… まさ… 東京… 1500042 地下… 渋谷駅      7    NA    NA    380      0 NA   \n 6 gdzk… 完全… 東京… 1000013 地下… 虎ノ門…     3    NA    NA   2980      0 NA   \n 7 ga2g… 鶏そ… 東京… 1760006 西武… 江古田…     2    NA    NA    850      0 NA   \n 8 gg9m… 宴会… 東京… 1010021 ＪＲ  秋葉原…     4    NA    NA   2000      3  3.33\n 9 gdvk… 中国… 東京… 1000006 ＪＲ  有楽町…     1    NA    NA   1000      2  2.5 \n10 gggb… 中国… 東京… 1140002 地下… 王子駅      2    NA    NA   2000      0 NA   \n# ℹ 6,282 more rows\n\n\n　かなり長いコードになりましたね。しかし、もっと簡単な方法があります。それは-を使う方法です。\n\ndf |&gt;\n  select(-Latitude, -Longitude) # select(-c(Latitude, Longitude))\n\n# A tibble: 6,292 × 12\n   ID    Name  Pref  Zipcode Line  Station  Walk   Bus   Car Budget ScoreN Score\n   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 e539… 居酒… 東京… 1040031 地下… 銀座一…     3    NA    NA   3000      0 NA   \n 2 gfeb… 本格… 東京… 1100005 地下… 仲御徒…     1    NA    NA   2000      2  4.5 \n 3 ggt5… 食べ… 東京… 1250041 ＪＲ… 金町駅      2    NA    NA   2980      0 NA   \n 4 g181… 博多… 東京… 1920904 ＪＲ  八王子…     1    NA    NA   2000      0 NA   \n 5 ggww… まさ… 東京… 1500042 地下… 渋谷駅      7    NA    NA    380      0 NA   \n 6 gdzk… 完全… 東京… 1000013 地下… 虎ノ門…     3    NA    NA   2980      0 NA   \n 7 ga2g… 鶏そ… 東京… 1760006 西武… 江古田…     2    NA    NA    850      0 NA   \n 8 gg9m… 宴会… 東京… 1010021 ＪＲ  秋葉原…     4    NA    NA   2000      3  3.33\n 9 gdvk… 中国… 東京… 1000006 ＪＲ  有楽町…     1    NA    NA   1000      2  2.5 \n10 gggb… 中国… 東京… 1140002 地下… 王子駅      2    NA    NA   2000      0 NA   \n# ℹ 6,282 more rows\n\n\n　除外したい変数名の前に-を付けただけです。また、-Latitudeと-Longitudeをそれぞれ指定せず、-c(Latitude, Longitude)のようにc()でまとめるのも可能です。\n\n\n13.3.4 隣接した列を指定する\n　先ほど、dfから緯度 (Latitude)と経度 (Longitude)を除外する例を考えてみましょう。-を使うと簡単ですが、場合によっては残す変数名を指定する必要もあります。\n\ndf |&gt;\n  select(ID, Name, Pref, Zipcode, \n         Line, Station, Walk, Bus, Car, Budget, ScoreN, Score)\n\n　よく考えてみれば、IDからZipcodeは隣接した列ですし、LineからScoreまでもそうです。これはnames()関数で確認できます。\n\nnames(df)\n\n [1] \"ID\"        \"Name\"      \"Pref\"      \"Zipcode\"   \"Latitude\"  \"Longitude\"\n [7] \"Line\"      \"Station\"   \"Walk\"      \"Bus\"       \"Car\"       \"Budget\"   \n[13] \"ScoreN\"    \"Score\"    \n\n\n　ここで便利な演算子が:です。これまで、xからyまでの公差1の等差数列を作成する際にx:yを使って来ましたが、これに非常に似ています。データフレームの「x列からy列まで」の表記もselect()関数内では:と書くことができます。したがって、上記のコードは以下のように短縮化可能です。\n\ndf |&gt;\n  select(ID:Zipcode, Line:Score)\n\n　「dfのIDからZipcodeまで、そしてLineからScoreまでの列を選択する」という意味です。非常に便利な演算子ですので、-と合わせて覚えておきましょう。\n\n\n13.3.5 一部の列の順番だけを変える\n　ある列の位置を替えたいとします。たとえば、ScoreとScoreNをそれぞれ1列目、2列目にしたい場合、どうすれば良いでしょうか。これまで勉強したことを考えると、以下のようなコードで問題ないでしょう。\n\ndf |&gt;\n  select(Score, ScoreN, ID:Budget)\n\n# A tibble: 6,292 × 14\n   Score ScoreN ID    Name  Pref  Zipcode Latitude Longitude Line  Station  Walk\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n 1 NA         0 e539… 居酒… 東京… 1040031     35.7      140. 地下… 銀座一…     3\n 2  4.5       2 gfeb… 本格… 東京… 1100005     35.7      140. 地下… 仲御徒…     1\n 3 NA         0 ggt5… 食べ… 東京… 1250041     35.8      140. ＪＲ… 金町駅      2\n 4 NA         0 g181… 博多… 東京… 1920904     35.7      139. ＪＲ  八王子…     1\n 5 NA         0 ggww… まさ… 東京… 1500042     35.7      140. 地下… 渋谷駅      7\n 6 NA         0 gdzk… 完全… 東京… 1000013     35.7      140. 地下… 虎ノ門…     3\n 7 NA         0 ga2g… 鶏そ… 東京… 1760006     35.7      140. 西武… 江古田…     2\n 8  3.33      3 gg9m… 宴会… 東京… 1010021     35.7      140. ＪＲ  秋葉原…     4\n 9  2.5       2 gdvk… 中国… 東京… 1000006     35.7      140. ＪＲ  有楽町…     1\n10 NA         0 gggb… 中国… 東京… 1140002     35.8      140. 地下… 王子駅      2\n# ℹ 6,282 more rows\n# ℹ 3 more variables: Bus &lt;dbl&gt;, Car &lt;dbl&gt;, Budget &lt;dbl&gt;\n\n\n　しかし、{dplyr}にはrelocate()というより便利な専用関数を提供しています。relocate()には変数名を指定するだけですが、ここで指定した変数がデータフレームの最初列の方に移動します。\n\ndf |&gt;\n  relocate(Score, ScoreN)\n\n# A tibble: 6,292 × 14\n   Score ScoreN ID    Name  Pref  Zipcode Latitude Longitude Line  Station  Walk\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt;\n 1 NA         0 e539… 居酒… 東京… 1040031     35.7      140. 地下… 銀座一…     3\n 2  4.5       2 gfeb… 本格… 東京… 1100005     35.7      140. 地下… 仲御徒…     1\n 3 NA         0 ggt5… 食べ… 東京… 1250041     35.8      140. ＪＲ… 金町駅      2\n 4 NA         0 g181… 博多… 東京… 1920904     35.7      139. ＪＲ  八王子…     1\n 5 NA         0 ggww… まさ… 東京… 1500042     35.7      140. 地下… 渋谷駅      7\n 6 NA         0 gdzk… 完全… 東京… 1000013     35.7      140. 地下… 虎ノ門…     3\n 7 NA         0 ga2g… 鶏そ… 東京… 1760006     35.7      140. 西武… 江古田…     2\n 8  3.33      3 gg9m… 宴会… 東京… 1010021     35.7      140. ＪＲ  秋葉原…     4\n 9  2.5       2 gdvk… 中国… 東京… 1000006     35.7      140. ＪＲ  有楽町…     1\n10 NA         0 gggb… 中国… 東京… 1140002     35.8      140. 地下… 王子駅      2\n# ℹ 6,282 more rows\n# ℹ 3 more variables: Bus &lt;dbl&gt;, Car &lt;dbl&gt;, Budget &lt;dbl&gt;\n\n\n　relocate()を使うとID:Budgetが省略可能となり、より短いコードになります。もう一つの例は、最初に持ってくるのではなく、「ある変数の前」または「ある変数の後」に移動させるケースです。これもrelocate()で可能ですが、もう一つの引数が必要です。PrefとZipcdoeの順番を変えるなら、まずは以下のような方法が考えられます。\n\ndf |&gt;\n  select(ID:Name, Zipcode, Pref, Latitude:Score)\n\n# A tibble: 6,292 × 14\n   ID     Name  Zipcode Pref  Latitude Longitude Line  Station  Walk   Bus   Car\n   &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 e5396… 居酒… 1040031 東京…     35.7      140. 地下… 銀座一…     3    NA    NA\n 2 gfeb6… 本格… 1100005 東京…     35.7      140. 地下… 仲御徒…     1    NA    NA\n 3 ggt59… 食べ… 1250041 東京…     35.8      140. ＪＲ… 金町駅      2    NA    NA\n 4 g1813… 博多… 1920904 東京…     35.7      139. ＪＲ  八王子…     1    NA    NA\n 5 ggww1… まさ… 1500042 東京…     35.7      140. 地下… 渋谷駅      7    NA    NA\n 6 gdzk5… 完全… 1000013 東京…     35.7      140. 地下… 虎ノ門…     3    NA    NA\n 7 ga2g2… 鶏そ… 1760006 東京…     35.7      140. 西武… 江古田…     2    NA    NA\n 8 gg9m1… 宴会… 1010021 東京…     35.7      140. ＪＲ  秋葉原…     4    NA    NA\n 9 gdvk2… 中国… 1000006 東京…     35.7      140. ＪＲ  有楽町…     1    NA    NA\n10 gggb2… 中国… 1140002 東京…     35.8      140. 地下… 王子駅      2    NA    NA\n# ℹ 6,282 more rows\n# ℹ 3 more variables: Budget &lt;dbl&gt;, ScoreN &lt;dbl&gt;, Score &lt;dbl&gt;\n\n\n　これをrelocate()で書き換えるなら、.afterまたは.before引数が必要になります。relocate(変数名1, .after = 変数名2)は「変数1を変数2の直後に移動させる」 ことを意味します。\n\ndf |&gt;\n  relocate(Pref, .after = Zipcode)\n\n# A tibble: 6,292 × 14\n   ID     Name  Zipcode Pref  Latitude Longitude Line  Station  Walk   Bus   Car\n   &lt;chr&gt;  &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 e5396… 居酒… 1040031 東京…     35.7      140. 地下… 銀座一…     3    NA    NA\n 2 gfeb6… 本格… 1100005 東京…     35.7      140. 地下… 仲御徒…     1    NA    NA\n 3 ggt59… 食べ… 1250041 東京…     35.8      140. ＪＲ… 金町駅      2    NA    NA\n 4 g1813… 博多… 1920904 東京…     35.7      139. ＪＲ  八王子…     1    NA    NA\n 5 ggww1… まさ… 1500042 東京…     35.7      140. 地下… 渋谷駅      7    NA    NA\n 6 gdzk5… 完全… 1000013 東京…     35.7      140. 地下… 虎ノ門…     3    NA    NA\n 7 ga2g2… 鶏そ… 1760006 東京…     35.7      140. 西武… 江古田…     2    NA    NA\n 8 gg9m1… 宴会… 1010021 東京…     35.7      140. ＪＲ  秋葉原…     4    NA    NA\n 9 gdvk2… 中国… 1000006 東京…     35.7      140. ＪＲ  有楽町…     1    NA    NA\n10 gggb2… 中国… 1140002 東京…     35.8      140. 地下… 王子駅      2    NA    NA\n# ℹ 6,282 more rows\n# ℹ 3 more variables: Budget &lt;dbl&gt;, ScoreN &lt;dbl&gt;, Score &lt;dbl&gt;\n\n\n　.beforeを使うことできます。この場合は「ZipcodeをPrefの直前に移動させる」 ことを指定する必要があります。結果は省略しますが、自分でコードを走らせ、上と同じ結果が得られるかを確認してみてください。\n\ndf |&gt;\n  relocate(Zipcode, .before = Pref)\n\n\n\n13.3.6 select()の便利な機能\n　select()関数は他にも便利な機能がいくつかあります。ここではいくつの機能を紹介しますが、より詳しい内容は?dplyr::selectを参照してください。\nstarts_with()とends_with()、contains()、num_range(): 特定の文字を含む変数を選択する\n　まずは、特定の文字を含む変数名を指定する方法です。starts_with(\"X\")、ends_with(\"X\")、contains(\"X\")は変数名が\"X\"で始まるか、\"X\"で終わるか、\"X\"を含むかを判断し、条件に合う変数名を返す関数です。実際の例を見ましょう。\n\n# ID、Nameに続いて、Scoreで始まる変数名を抽出\ndf |&gt;\n  select(ID, Name, starts_with(\"Score\"))\n\n# A tibble: 6,292 × 4\n   ID      Name                                                     ScoreN Score\n   &lt;chr&gt;   &lt;chr&gt;                                                     &lt;dbl&gt; &lt;dbl&gt;\n 1 e539604 居酒屋 龍記 京橋店                                            0 NA   \n 2 gfeb600 本格上海料理 新錦江 上野御徒町本店                            2  4.5 \n 3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ）                    0 NA   \n 4 g181340 博多餃子軒 八王子店 タピオカ店 Bull Pulu（ブルプル）併設      0 NA   \n 5 ggww100 まさ屋 渋谷店                                                 0 NA   \n 6 gdzk500 完全個室 上海レストラン 檸檬 霞ヶ関ビル内店                   0 NA   \n 7 ga2g202 鶏そば きらり                                                 0 NA   \n 8 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店                         3  3.33\n 9 gdvk200 中国料理 宝龍                                                 2  2.5 \n10 gggb200 中国料理 天安門                                               0 NA   \n# ℹ 6,282 more rows\n\n# eで終わる変数名を除去\ndf |&gt;\n  select(-ends_with(\"e\")) # !ends_with(\"e\")も可能\n\n# A tibble: 6,292 × 8\n   ID      Pref   Station       Walk   Bus   Car Budget ScoreN\n   &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n 1 e539604 東京都 銀座一丁目駅     3    NA    NA   3000      0\n 2 gfeb600 東京都 仲御徒町駅       1    NA    NA   2000      2\n 3 ggt5900 東京都 金町駅           2    NA    NA   2980      0\n 4 g181340 東京都 八王子駅         1    NA    NA   2000      0\n 5 ggww100 東京都 渋谷駅           7    NA    NA    380      0\n 6 gdzk500 東京都 虎ノ門駅         3    NA    NA   2980      0\n 7 ga2g202 東京都 江古田駅         2    NA    NA    850      0\n 8 gg9m100 東京都 秋葉原駅         4    NA    NA   2000      3\n 9 gdvk200 東京都 有楽町駅         1    NA    NA   1000      2\n10 gggb200 東京都 王子駅           2    NA    NA   2000      0\n# ℹ 6,282 more rows\n\n# reを含む変数名を抽出するが、ScoreNは除去する\ndf |&gt;\n  select(contains(\"re\"), -ScoreN)\n\n# A tibble: 6,292 × 2\n   Pref   Score\n   &lt;chr&gt;  &lt;dbl&gt;\n 1 東京都 NA   \n 2 東京都  4.5 \n 3 東京都 NA   \n 4 東京都 NA   \n 5 東京都 NA   \n 6 東京都 NA   \n 7 東京都 NA   \n 8 東京都  3.33\n 9 東京都  2.5 \n10 東京都 NA   \n# ℹ 6,282 more rows\n\n\n　他の使い方としてはX1、X2のような「文字+数字」の変数を選択する際、starts_with()が活躍します。たとえば、以下のようなmyDF1があるとします。\n\n# tibble()でなく、data.frame()も使用可能です。\nmyDF1 &lt;- tibble(\n  ID  = 1:5,\n  X1  = c(2, 4, 6, 2, 7),\n  Y1  = c(3, 5, 1, 1, 0),\n  X1D = c(4, 2, 1, 6, 9),\n  X2  = c(5, 5, 6, 0, 2),\n  Y2  = c(3, 3, 2, 3, 1),\n  X2D = c(8, 9, 5, 0, 1),\n  X3  = c(3, 0, 3, 0, 2),\n  Y3  = c(1, 5, 9, 1, 3),\n  X3D = c(9, 1, 3, 3, 8)\n)\n\nmyDF1\n\n# A tibble: 5 × 10\n     ID    X1    Y1   X1D    X2    Y2   X2D    X3    Y3   X3D\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     2     3     4     5     3     8     3     1     9\n2     2     4     5     2     5     3     9     0     5     1\n3     3     6     1     1     6     2     5     3     9     3\n4     4     2     1     6     0     3     0     0     1     3\n5     5     7     0     9     2     1     1     2     3     8\n\n\n　このmyDF1からID、Y1、Y2、Y3を抽出するにはどうすれば良いでしょうか。これらの変数は隣接していないため、:も使えませんが、starts_with()を使えば簡単です。\n\nmyDF1 |&gt;\n  select(ID, starts_with(\"Y\"))\n\n# A tibble: 5 × 4\n     ID    Y1    Y2    Y3\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     3     3     1\n2     2     5     3     5\n3     3     1     2     9\n4     4     1     3     1\n5     5     0     1     3\n\n\n　それでは、ID、X1、X2、X3はどうでしょうか。starts_with(\"X\")だと、X1cなども選択されてしまいますね。ここで-ends_with()の出番です。つまり、「まずはstarts_with(\"X\")でXで始まる変数を選択し、続いて、Dで終わるものを除外すればいいじゃん？」です。それでは、やってみましょうか。\n\nmyDF1 |&gt;\n  select(ID, starts_with(\"X\"), -ends_with(\"D\"))\n\n# A tibble: 5 × 3\n     X1    X2    X3\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     2     5     3\n2     4     5     0\n3     6     6     3\n4     2     0     0\n5     7     2     2\n\n\n　あらら、IDも同時になくなりましたね2。実はこのような時のために用意された関数があり、それがnum_range()です。num_range()の第一引数はstarts_with()関数と同じですが、第二引数も必要です。この第二引数にはnumeric型のベクトルが必要です。1:3でも、c(1, 2, 3)でも構いません。たとえば、ID、X1、X2、X3するには以下のように書きます。\n\nmyDF1 |&gt;\n  select(ID, num_range(\"X\", 1:3))\n\n# A tibble: 5 × 4\n     ID    X1    X2    X3\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     2     5     3\n2     2     4     5     0\n3     3     6     6     3\n4     4     2     0     0\n5     5     7     2     2\n\n\nall_of()とany_of(): 文字型ベクトルを用いた変数の選択\n　all_of()とany_of()はselect()内の変数名として文字型ベクトルを使う際に用いる関数です。これは抽出したい列名が既にcharacter型ベクトルとして用意されている場合、便利な関数です。たとえば、以下のName_Vecを考えてみましょう。\n\nName_Vec &lt;- c(\"X1\", \"X2\", \"X3\")\n\n　このName_Vecの要素と同じ列名を持つ列とID列をmyDF1から抽出する方法は以下の2通りです。\n\nmyDF1[, c(\"ID\", Name_Vec)]\n\n# A tibble: 5 × 4\n     ID    X1    X2    X3\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     2     5     3\n2     2     4     5     0\n3     3     6     6     3\n4     4     2     0     0\n5     5     7     2     2\n\nmyDF1 |&gt;\n  select(ID, all_of(Name_Vec))\n\n# A tibble: 5 × 4\n     ID    X1    X2    X3\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     2     5     3\n2     2     4     5     0\n3     3     6     6     3\n4     4     2     0     0\n5     5     7     2     2\n\n\n　今の例だと、select()を使わない前者の方が便利かも知れませんが、select()内に外の変数名も指定する場合も多いので、後者の方が汎用性は高いです。私から見れば、今の例でも後者の方が読みやすく、使いやすいと思います。\n　それでは以下のようなName_Vecはどうでしょう。今回は、myDF1に含まれていないX4とX5もあります。\n\nName_Vec &lt;- c(\"X1\", \"X2\", \"X3\", \"X4\", \"X5\")\n\nmyDF1 |&gt;\n  select(all_of(Name_Vec))\n\n## Error: Can't subset columns that don't exist.\n##   Columns `X4` and `X5` don't exist.\n　このようにエラーが出てしまします。つまり、all_of()の場合、引数の要素全てがデータフレームに存在する必要があります。もし、ないものは無視して、合致する列だけ取り出したいはどうすれば良いでしょうか。そこで登場するのがany_of()です。\n\nmyDF1 |&gt;\n  select(any_of(Name_Vec))\n\n# A tibble: 5 × 3\n     X1    X2    X3\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     2     5     3\n2     4     5     0\n3     6     6     3\n4     2     0     0\n5     7     2     2\n\n\n　any_of()の方がより使いやすいと思う方も多いでしょうが、必ずしもそうとは限りません。たとえば、Name_Vecに誤字などが含まれる場合、any_of()だと誤字が含まれている変数は取り出しません。この場合はむしろちゃんとエラーを表示してくれた方が嬉しいですね。\nlast_col(): 最後の列を選択する\n　普段あまり使わない機能ですが、最後の列を選択するlast_col()という関数もあります。\n\n# IDと最後の列のみを抽出\ndf |&gt;\n  select(ID, last_col(0))\n\n# A tibble: 6,292 × 2\n   ID      Score\n   &lt;chr&gt;   &lt;dbl&gt;\n 1 e539604 NA   \n 2 gfeb600  4.5 \n 3 ggt5900 NA   \n 4 g181340 NA   \n 5 ggww100 NA   \n 6 gdzk500 NA   \n 7 ga2g202 NA   \n 8 gg9m100  3.33\n 9 gdvk200  2.5 \n10 gggb200 NA   \n# ℹ 6,282 more rows\n\n\n　最後からk番目の列を指定することも可能です。最後の列の番号が0であり、その手前の列は1となります。つまり、last_col()の中には「最後から何番目の列か」を指定すれば良いです。最後の列は最後の列そのままなので0です。\n\n# IDと最後から2列目を抽出\ndf |&gt;\n  select(ID, last_col(1))\n\n# A tibble: 6,292 × 2\n   ID      ScoreN\n   &lt;chr&gt;    &lt;dbl&gt;\n 1 e539604      0\n 2 gfeb600      2\n 3 ggt5900      0\n 4 g181340      0\n 5 ggww100      0\n 6 gdzk500      0\n 7 ga2g202      0\n 8 gg9m100      3\n 9 gdvk200      2\n10 gggb200      0\n# ℹ 6,282 more rows\n\n\n　このlast_col()の引数を指定しないと、それは最後の列を意味します。つまり、last_col()とlast_col(0)は同じです。これを利用すれば、「ある変数の最後の列へ移動させる」こともできます。たとえば、IDを最後の列に移動させたい場合、relocate(ID, .after = last_col())のように書きます。\nwhere(): データ型から変数を選択する\n　最後に、「numeric型の列のみ抽出したい」、「character型の列だけほしい」場合に便利なwhere()関数を紹介します。where()の中に入る引数は一つだけであり、データ型を判定する関数名が入ります。たとえば、numeric型か否かを判断する関数はis.numeric()です。dfからnumeric型の変数のみを抽出したい場合は以下のように書きます。ただし、where()の中の関数は()を省略します。\n\n# numeric型の列を抽出する\ndf |&gt;\n  select(where(is.numeric))\n\n# A tibble: 6,292 × 9\n   Zipcode Latitude Longitude  Walk   Bus   Car Budget ScoreN Score\n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 1040031     35.7      140.     3    NA    NA   3000      0 NA   \n 2 1100005     35.7      140.     1    NA    NA   2000      2  4.5 \n 3 1250041     35.8      140.     2    NA    NA   2980      0 NA   \n 4 1920904     35.7      139.     1    NA    NA   2000      0 NA   \n 5 1500042     35.7      140.     7    NA    NA    380      0 NA   \n 6 1000013     35.7      140.     3    NA    NA   2980      0 NA   \n 7 1760006     35.7      140.     2    NA    NA    850      0 NA   \n 8 1010021     35.7      140.     4    NA    NA   2000      3  3.33\n 9 1000006     35.7      140.     1    NA    NA   1000      2  2.5 \n10 1140002     35.8      140.     2    NA    NA   2000      0 NA   \n# ℹ 6,282 more rows\n\n\n　!を使って条件に合致する列を除外することも可能です。もし、character型の列を除外する場合は以下のように!where(is.character)を指定します。\n\n# character型でない列を抽出する\ndf |&gt;\n  select(!where(is.character))\n\n# A tibble: 6,292 × 9\n   Zipcode Latitude Longitude  Walk   Bus   Car Budget ScoreN Score\n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 1040031     35.7      140.     3    NA    NA   3000      0 NA   \n 2 1100005     35.7      140.     1    NA    NA   2000      2  4.5 \n 3 1250041     35.8      140.     2    NA    NA   2980      0 NA   \n 4 1920904     35.7      139.     1    NA    NA   2000      0 NA   \n 5 1500042     35.7      140.     7    NA    NA    380      0 NA   \n 6 1000013     35.7      140.     3    NA    NA   2980      0 NA   \n 7 1760006     35.7      140.     2    NA    NA    850      0 NA   \n 8 1010021     35.7      140.     4    NA    NA   2000      3  3.33\n 9 1000006     35.7      140.     1    NA    NA   1000      2  2.5 \n10 1140002     35.8      140.     2    NA    NA   2000      0 NA   \n# ℹ 6,282 more rows\n\n\n　&を使って複数の条件を使うことも可能です。たとえば、ID変数に加えて「\"L\"で始まる変数の中でnumeric型の列を抽出」するコードは以下のようになります。\n\n# IDと、Lで始まるnumeric型の列を抽出する\ndf |&gt;\n  select(ID, starts_with(\"L\") & where(is.numeric))\n\n# A tibble: 6,292 × 3\n   ID      Latitude Longitude\n   &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n 1 e539604     35.7      140.\n 2 gfeb600     35.7      140.\n 3 ggt5900     35.8      140.\n 4 g181340     35.7      139.\n 5 ggww100     35.7      140.\n 6 gdzk500     35.7      140.\n 7 ga2g202     35.7      140.\n 8 gg9m100     35.7      140.\n 9 gdvk200     35.7      140.\n10 gggb200     35.8      140.\n# ℹ 6,282 more rows"
  },
  {
    "objectID": "datahandling1.html#sec-handling1-filter",
    "href": "datahandling1.html#sec-handling1-filter",
    "title": "13  データハンドリング [抽出]",
    "section": "13.4 行の抽出",
    "text": "13.4 行の抽出\n\n13.4.1 指定した行を抽出する\n　他にも特定の行を抽出する場合があります。たとえば、「dfの最初の5行」や「dfの8行目のケース」といった場合です。この操作には{dplyr}のslice_*()関数群が便利です。それではそれぞれの関数の使い方について紹介していきます。その前に、実習用データとしてdfから一部の列のみを抽出したselelct.dfを作成します。\n\nselect.df &lt;- df |&gt; \n  select(ID, Name, Pref, Budget, Score)\n\nslice(): 指定した番号の行のみ抽出する\n　select.dfから2, 8, 9行目の行を抽出したいとします。このような簡単な操作はパッケージを使わず、以下のように抽出することができます。\n\n# select.dfから2, 8, 9行目の行を抽出し、出力する\nselect.df[c(2, 8, 9),]\n\n# A tibble: 3 × 5\n  ID      Name                                  Pref   Budget Score\n  &lt;chr&gt;   &lt;chr&gt;                                 &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 gfeb600 本格上海料理 新錦江 上野御徒町本店    東京都   2000  4.5 \n2 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店 東京都   2000  3.33\n3 gdvk200 中国料理 宝龍                         東京都   1000  2.5 \n\n\n　しかし、以下のslice()関数を使うとパイプ演算子を前後に付けることが可能であり3、コードの可読性も高いです。slice()関数には以下のように抽出したい行の番号を入れるだけです。\n\n# select.dfから2, 8, 9行目の行を抽出し、出力する\nselect.df |&gt; \n  slice(2, 8, 9) # slice(c(2, 8, 9))もOK\n\n# A tibble: 3 × 5\n  ID      Name                                  Pref   Budget Score\n  &lt;chr&gt;   &lt;chr&gt;                                 &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 gfeb600 本格上海料理 新錦江 上野御徒町本店    東京都   2000  4.5 \n2 gg9m100 宴会個室×餃子酒場 北京飯店 秋葉原本店 東京都   2000  3.33\n3 gdvk200 中国料理 宝龍                         東京都   1000  2.5 \n\n\n　slice(2, 8, 9)でもslice(c(2, 8, 9))でも構いません。また、隣接した行でしたら:を使うことも可能です。たとえば、10行目から15行目まで抽出する場合はslice(10:15)のような書き方も出来ます。\nslice_head(): 最初のn行を抽出する\n\n# select.dfから最初の3行抽出し、出力する\nselect.df |&gt; \n  slice_head(n = 3)\n\n# A tibble: 3 × 5\n  ID      Name                                       Pref   Budget Score\n  &lt;chr&gt;   &lt;chr&gt;                                      &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 e539604 居酒屋 龍記 京橋店                         東京都   3000  NA  \n2 gfeb600 本格上海料理 新錦江 上野御徒町本店         東京都   2000   4.5\n3 ggt5900 食べ飲み放題×中華ビストロ NOZOMI（のぞみ） 東京都   2980  NA  \n\n\n　これはhead(データ名, n = 出力する個数)と同じ動きをする関数です。注意点としては引数n =を必ず付ける点です。たとえば、slice_head(3)にすると、select.dfの3行目のみ抽出されます。\nslice_tail(): 最後のn行を抽出する\n\n# select.dfから最後の7行を抽出し、出力する\nselect.df |&gt; \n  slice_tail(n = 7)\n\n# A tibble: 7 × 5\n  ID      Name                    Pref     Budget Score\n  &lt;chr&gt;   &lt;chr&gt;                   &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 5508852 場鶴                    和歌山県     NA    NA\n2 7113351 来来亭 橋本店           和歌山県     NA    NA\n3 6364939 ばり馬 和歌山紀三井寺店 和歌山県     NA    NA\n4 7103349 ramen BIRDMAN           和歌山県     NA    NA\n5 7315303 薩摩ラーメン 斗天王     和歌山県     NA    NA\n6 7703472 まるしげ                和歌山県     NA    NA\n7 6395035 暴豚製麺所              和歌山県     NA    NA\n\n\n　これはtail(データ名, n = 出力する個数)と同じ動きをする関数です。ちなみに、このn引数もn =を明記する必要があります。\nslice_max(): 指定した変数が大きい順でn行抽出する\n　slice_max()は指定した変数が大きい順でn行抽出する関数です。たとえば、Budgetが高い順で4店舗を抽出する場合は以下のように書きます。\n\n# select.dfからScoreの値が高い順で5行を抽出し、出力する\nselect.df |&gt; \n  slice_max(Budget, n = 4)\n\n# A tibble: 4 × 5\n  ID      Name                                              Pref    Budget Score\n  &lt;chr&gt;   &lt;chr&gt;                                             &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 g670609 横浜ベイシェラトン ホテル＆タワーズ 中国料理 彩龍 神奈川…   8000    NA\n2 g910420 JASMINE 憶江南                                    東京都    7000    NA\n3 7176666 赤坂焼鳥 鳳                                       東京都    7000    NA\n4 b612800 羽衣 銀座本店                                     東京都    6000    NA\n\n\nslice_min(): 指定した変数が小さい順でn行抽出する\n　一方、slice_min()関数が小さい順で抽出します。\n\n# select.dfからScoreの値が低い順で3行を抽出し、出力する\nselect.df |&gt; \n  slice_min(Score, n = 3)\n\n# A tibble: 4 × 5\n  ID      Name                        Pref   Budget Score\n  &lt;chr&gt;   &lt;chr&gt;                       &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 6384909 葛西大勝軒                  東京都     NA     1\n2 6929243 由丸 アトレヴィ大塚店       東京都     NA     1\n3 5816075 ラーメン戯拉戯拉            千葉県     NA     1\n4 5495086 らあめん花月嵐 坂戸わかば店 埼玉県     NA     1\n\n\n　ただし、n = 3と指定したはずなのに、4行が抽出されました。これは同点のケースがあるからです。実際、select.dfにはScoreが1のケースが4つあります。もし、同点の存在によりnに収まらない場合、slice_max()、slice_min()関数はnを超える行を出力します。これを強制的にn行に合わせるためにはwith_ties = FALSE引数を付けます。この場合、データで格納されている順でn個のみ出力されます。\n\nselect.df |&gt; \n  slice_min(Score, n = 3, with_ties = FALSE)\n\n# A tibble: 3 × 5\n  ID      Name                  Pref   Budget Score\n  &lt;chr&gt;   &lt;chr&gt;                 &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 6384909 葛西大勝軒            東京都     NA     1\n2 6929243 由丸 アトレヴィ大塚店 東京都     NA     1\n3 5816075 ラーメン戯拉戯拉      千葉県     NA     1\n\n\nslice_sample(): 無作為にn行を抽出する\n　最後に無作為にn行を抽出するslice_sample()関数です。引数はnであり、抽出したい行数を指定します。たとえば、select.dfから無作為に10行抽出したい場合は、\n\n# select.dfから無作為に5行を抽出し、出力する\nselect.df |&gt; \n  slice_sample(n = 10)\n\n# A tibble: 10 × 5\n   ID      Name                               Pref     Budget Score\n   &lt;chr&gt;   &lt;chr&gt;                              &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt;\n 1 7356411 らーめんZoot                       東京都     1000   3.5\n 2 5508315 にしのみや 宮っ子ラーメン 本店     兵庫県       NA   4.5\n 3 5401614 栗木台 大勝軒                      神奈川県     NA  NA  \n 4 7463599 当代一                             大阪府       NA  NA  \n 5 6770132 ラーメン武蔵家                     埼玉県       NA  NA  \n 6 7327123 らぁめん まるなか                  大阪府       NA  NA  \n 7 5507862 サッポロラーメン文                 大阪府       NA  NA  \n 8 7677116 麺屋 神楽                          兵庫県       NA  NA  \n 9 7181005 博多 一風堂 二子玉川ライズS．C．店 東京都      900  NA  \n10 7457016 魁力屋 茅ヶ崎店                    神奈川県     NA  NA  \n\n\nのように書きます。ブートストラップ法や機械学習における交差検証 (cross-validation)の際に有用な関数ですが、ブートストラップや機械学習のパッケージの多くはサンプル分割の関数を提供しているため、あまり使う機会はないでしょう。また、slice_sample()関数をブートストラップ法のために用いる場合は、ケースを反復抽出する必要があり、replace = TRUEを付けると反復抽出を行います。デフォルト値はFALSEです。\n\n\n13.4.2 条件に合致する行を抽出する\n　これまで見てきたslice()を用いる行の抽出は、実際あまり使う機会がありません。多くの場合、「何かの条件と合致するケースのみ抽出する」または、「何かの条件と合致しないケースのみを抽出する」やこれらの組み合わせで行の抽出を行います。そこで登場するのがdplyr()パッケージのfilter()関数です。filter()関数の使い方は以下の通りです。\n\n# dplyr::filter()の使い方\nfilter(データフレーム名, 条件1, 条件2, ...)\n\n　むろん、第一引数がデータですから、|&gt;を使うことも可能です。\n\n# dplyr::filter()の使い方 (パイプを使う方法)\nデータフレーム名 |&gt;\n  filter(条件1, 条件2, ...)\n\n　まずは、条件が一つの場合を考えてみましょう。ここでは「Prefが\"京都府\"であるケースのみに絞り、NameとStation、Score列のみを出力する」ケースを考えてみましょう。まず、filter()関数で行を抽出し、続いてselect()関数で抽出する列を指定します。むろん、今回の場合、filter()とselect()の順番は替えても構いません。\n\n# dfからPrefが\"京都府\"であるケースのみ残し、df2という名で保存\ndf2 &lt;- df |&gt;\n  filter(Pref == \"京都府\")\n\n# df2からName, Station, Score列を抽出\ndf2 |&gt;\n  select(Name, Station, Score)\n\n# A tibble: 414 × 3\n   Name                                                    Station    Score\n   &lt;chr&gt;                                                   &lt;chr&gt;      &lt;dbl&gt;\n 1 中国料理 鳳麟                                           くいな橋駅 NA   \n 2 黒毛和牛一頭買い焼肉と 炊き立て土鍋ご飯 市場小路 烏丸店 四条駅      3.19\n 3 京の中華 ハマムラ みやこみち店                          京都駅     NA   \n 4 焼肉処 真 桂店                                          桂駅       NA   \n 5 祇園京都ラーメン                                        祇園四条駅 NA   \n 6 創作料理 串カツ トンカツ jiro                           新田辺駅   NA   \n 7 祇園 晩餐のあと                                         祇園四条駅 NA   \n 8 DETAIL                                                  東山駅     NA   \n 9 めんや龍神                                              北大路駅   NA   \n10 無尽蔵 京都八条家                                       京都駅      3.5 \n# ℹ 404 more rows\n\n\n　これはdfからPref == \"京都府\"のケースのみ残したものをdf2として格納し、それをまたselect()関数を使って列を抽出するコードです。これでも問題ありませんが、これだとパイプ演算子の便利さが分かりません。パイプ演算子は複数使うことが可能です。\n\ndf |&gt;\n  filter(Pref == \"京都府\") |&gt;\n  select(Name, Station, Score)\n\n# A tibble: 414 × 3\n   Name                                                    Station    Score\n   &lt;chr&gt;                                                   &lt;chr&gt;      &lt;dbl&gt;\n 1 中国料理 鳳麟                                           くいな橋駅 NA   \n 2 黒毛和牛一頭買い焼肉と 炊き立て土鍋ご飯 市場小路 烏丸店 四条駅      3.19\n 3 京の中華 ハマムラ みやこみち店                          京都駅     NA   \n 4 焼肉処 真 桂店                                          桂駅       NA   \n 5 祇園京都ラーメン                                        祇園四条駅 NA   \n 6 創作料理 串カツ トンカツ jiro                           新田辺駅   NA   \n 7 祇園 晩餐のあと                                         祇園四条駅 NA   \n 8 DETAIL                                                  東山駅     NA   \n 9 めんや龍神                                              北大路駅   NA   \n10 無尽蔵 京都八条家                                       京都駅      3.5 \n# ℹ 404 more rows\n\n\n　全く同じ結果ですが、無駄にdf2というデータフレームを作らず済むので、メモリの観点からも嬉しいですし、何よりコードが短く、しかも可読性も上がりました。\n　今回は==を使って合致するものに絞りましたが、!=を使って合致しないものに絞ることも可能です。または、比較演算子 (&lt;、&gt;、&gt;=、&lt;=など)を使うことも可能です。それでは、組み込み数 (ScoreN)が0ではないケースを取り出し、Name、Station、ScoreN、Score列を出力させてみましょう。\n\ndf |&gt;\n  filter(ScoreN != 0) |&gt;\n  select(Name, Station, starts_with(\"Score\"))\n\n# A tibble: 1,344 × 4\n   Name                                              Station       ScoreN Score\n   &lt;chr&gt;                                             &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1 本格上海料理 新錦江 上野御徒町本店                仲御徒町駅         2  4.5 \n 2 宴会個室×餃子酒場 北京飯店 秋葉原本店             秋葉原駅           3  3.33\n 3 中国料理 宝龍                                     有楽町駅           2  2.5 \n 4 麺達 うま家                                       高田馬場駅         2  3   \n 5 刀削麺・火鍋・西安料理 XI’AN（シーアン） 後楽園店 後楽園駅           1 NA   \n 6 七志らーめん 渋谷道玄坂店                         渋谷駅             7  4.5 \n 7 永楽                                              京成小岩駅         6  4.42\n 8 よってこや お台場店                               お台場海浜公…      1  4   \n 9 ラーメン武藤製麺所                                竹ノ塚駅           4  3.5 \n10 桂花ラーメン 新宿末広店                           新宿三丁目駅       8  3   \n# ℹ 1,334 more rows\n\n\n　これで口コミ数が1以上の店舗のみに絞ることができました。ただし、店によっては口コミはあっても、評価 (Score)が付いていないところもあります。たとえば、「刀削麺・火鍋・西安料理 XI’AN（シーアン） 後楽園店」の場合、口コミはありますが、評価はありません。したがって、今回は評価が付いている店舗に絞ってみましょう。\n\ndf |&gt;\n  filter(Score != NA) |&gt;\n  select(Name, Station, starts_with(\"Score\"))\n\n# A tibble: 0 × 4\n# ℹ 4 variables: Name &lt;chr&gt;, Station &lt;chr&gt;, ScoreN &lt;dbl&gt;, Score &lt;dbl&gt;\n\n\n　あらら、何の結果も表示されませんでした。これはfilter()内の条件に合致するケースが存在しないことを意味します。しかし、先ほどの結果を見ても、評価が付いている店はいっぱいありましたね。これはなぜでしょう。\n　察しの良い読者さんは気づいているかと思いますが、第9.8章で説明した通り、NAか否かを判定する際は==や!=は使えません。is.na()を使います。filter(is.na(Score))なら「ScoreがNAであるケースに絞る」ことを意味しますが、今回は「ScoreがNAでないケースに絞る」ことが目的ですので、is.na()の前に!を付けます。\n\ndf |&gt;\n  filter(!is.na(Score)) |&gt;\n  select(Name, Station, starts_with(\"Score\"))\n\n# A tibble: 1,134 × 4\n   Name                                  Station          ScoreN Score\n   &lt;chr&gt;                                 &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;\n 1 本格上海料理 新錦江 上野御徒町本店    仲御徒町駅            2  4.5 \n 2 宴会個室×餃子酒場 北京飯店 秋葉原本店 秋葉原駅              3  3.33\n 3 中国料理 宝龍                         有楽町駅              2  2.5 \n 4 麺達 うま家                           高田馬場駅            2  3   \n 5 七志らーめん 渋谷道玄坂店             渋谷駅                7  4.5 \n 6 永楽                                  京成小岩駅            6  4.42\n 7 よってこや お台場店                   お台場海浜公園駅      1  4   \n 8 ラーメン武藤製麺所                    竹ノ塚駅              4  3.5 \n 9 桂花ラーメン 新宿末広店               新宿三丁目駅          8  3   \n10 北斗 新橋店                           新橋駅                4  2.5 \n# ℹ 1,124 more rows\n\n\n　これで口コミ評価が登録された店舗に絞ることができました。\n　続いて、複数の条件を持つケースを考えてみましょう。例えば、「京都府内の店舗で、口コミ評価が3.5以上の店舗」を出力したい場合、以下のようなコードとなります。\n\ndf |&gt;\n  filter(Pref == \"京都府\", Score &gt;= 3.5) |&gt;\n  select(Name, Station, ScoreN, Score)\n\n# A tibble: 53 × 4\n   Name               Station    ScoreN Score\n   &lt;chr&gt;              &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 無尽蔵 京都八条家  京都駅          2  3.5 \n 2 一蘭 京都河原町店  河原町駅        2  3.75\n 3 ミスター・ギョーザ 西大路駅        8  4.06\n 4 一蘭 京都八幡店    樟葉駅          3  4   \n 5 中華料理 清華園    京都駅          3  5   \n 6 まがり             &lt;NA&gt;            2  4   \n 7 魁力屋 北山店      北大路駅        2  4.25\n 8 大中BAL横店        &lt;NA&gt;            7  4.1 \n 9 こうちゃん         西舞鶴駅        1  5   \n10 大黒ラーメン       伏見桃山駅      4  4.25\n# ℹ 43 more rows\n\n\n　条件をfilter()内に追加するだけです。今回は!is.na(Score)は不要です。なぜなら、Score &gt;= 3.5という条件で既に欠損値は対象外になるからです。条件文が複数ある場合、ANDかORかを指定する必要があります。つまり、条件文AとBがある場合、「AとB両方満たすものを出力する」か「AとBどちらかを満たすものを出力するか」を指定する必要があります。今の結果ってANDでしたよね。filter()関数は、別途の指定がない場合、全てAND扱いになります。RのAND演算子は&ですので、以上のコードは以下のコードと同じです。\n\ndf |&gt;\n  filter(Pref == \"京都府\" & Score &gt;= 3.5) |&gt;\n  select(Name, Station, ScoreN, Score)\n\n# A tibble: 53 × 4\n   Name               Station    ScoreN Score\n   &lt;chr&gt;              &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 無尽蔵 京都八条家  京都駅          2  3.5 \n 2 一蘭 京都河原町店  河原町駅        2  3.75\n 3 ミスター・ギョーザ 西大路駅        8  4.06\n 4 一蘭 京都八幡店    樟葉駅          3  4   \n 5 中華料理 清華園    京都駅          3  5   \n 6 まがり             &lt;NA&gt;            2  4   \n 7 魁力屋 北山店      北大路駅        2  4.25\n 8 大中BAL横店        &lt;NA&gt;            7  4.1 \n 9 こうちゃん         西舞鶴駅        1  5   \n10 大黒ラーメン       伏見桃山駅      4  4.25\n# ℹ 43 more rows\n\n\n　AND演算子 (&)が使えるということはOR演算子 (|)も使えることを意味します。たとえば、Stationが\"高田馬場駅\"か\"三田駅\"の条件を指定したい場合、\n\ndf |&gt; \n  filter(Station == \"高田馬場駅\" | Station == \"三田駅\") |&gt;\n  select(Name, Station, ScoreN, Score)\n\n# A tibble: 14 × 4\n   Name                                 Station    ScoreN Score\n   &lt;chr&gt;                                &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 麺達 うま家                          高田馬場駅      2  3   \n 2 らぁ麺 やまぐち                      高田馬場駅      7  4.08\n 3 博多一瑞亭 三田店                    三田駅          0 NA   \n 4 つけ麺屋 ひまわり                    高田馬場駅      4  2.75\n 5 石器ラーメン 高田馬場                高田馬場駅      0 NA   \n 6 旨辛らーめん 表裏                    高田馬場駅      0 NA   \n 7 三歩一                               高田馬場駅      8  4.56\n 8 えぞ菊 戸塚店                        高田馬場駅      4  3.62\n 9 麺屋　宗                             高田馬場駅      5  4.2 \n10 とんこつラーメン 博多風龍 高田馬場店 高田馬場駅      2  3   \n11 横浜家系ラーメン 馬場壱家            高田馬場駅      0 NA   \n12 らーめん よし丸                      高田馬場駅      1  5   \n13 札幌ラーメン どさん子 三田店         三田駅          0 NA   \n14 天下一品 三田店                      三田駅          0 NA   \n\n\nのように書きます（ちなみに高田馬場の「やまぐち」は本当に美味しいです）。むろん、複数の変数を用いたORも可能です。たとえば、「Prefが\"京都府\"かScoreが3以上」のような条件も可能ですが (Pref == \"京都府\" | Score &gt;= 3)、実際、このような例はあまりありません。よく使うのは「変数Xがaかbかcか」のような例です。ただし、この場合は|を使わないもっと簡単な方法があります。それは第11.4章で紹介した%in%演算子です。以下のコードは上のコードと同じものです。\n\ndf |&gt; \n  filter(Station %in% c(\"高田馬場駅\", \"三田駅\")) |&gt;\n  select(Name, Station, ScoreN, Score)\n\n# A tibble: 14 × 4\n   Name                                 Station    ScoreN Score\n   &lt;chr&gt;                                &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 麺達 うま家                          高田馬場駅      2  3   \n 2 らぁ麺 やまぐち                      高田馬場駅      7  4.08\n 3 博多一瑞亭 三田店                    三田駅          0 NA   \n 4 つけ麺屋 ひまわり                    高田馬場駅      4  2.75\n 5 石器ラーメン 高田馬場                高田馬場駅      0 NA   \n 6 旨辛らーめん 表裏                    高田馬場駅      0 NA   \n 7 三歩一                               高田馬場駅      8  4.56\n 8 えぞ菊 戸塚店                        高田馬場駅      4  3.62\n 9 麺屋　宗                             高田馬場駅      5  4.2 \n10 とんこつラーメン 博多風龍 高田馬場店 高田馬場駅      2  3   \n11 横浜家系ラーメン 馬場壱家            高田馬場駅      0 NA   \n12 らーめん よし丸                      高田馬場駅      1  5   \n13 札幌ラーメン どさん子 三田店         三田駅          0 NA   \n14 天下一品 三田店                      三田駅          0 NA   \n\n\n　結局、|が使われるケースがかなり限定されます。あるとすれば、「変数Xがa以下か、b以上か」のようなケースですね。ただし、&と|を同時に使うケースは考えられます。たとえば、大阪駅と京都駅周辺のうまいラーメン屋を調べるとします。問題は美味しさの基準ですが、3.5点以上としましょう。ただし、京都府民はラーメンに非常に厳しく、3点以上なら美味しいと仮定します。この場合、「(Stationが\"大阪駅\"かつScore &gt;= 3.5)、または(Stationが\"京都駅\"かつScore &gt;= 3)」のような条件が必要になります。()は「()の中から判定せよ」という、普通の算数での使い方と同じです。それでは、実際に検索してみましょう。\n\ndf |&gt;\n  filter((Station == \"大阪駅\" & Score &gt;= 3.5) | (Station == \"京都駅\" & Score &gt;= 3)) |&gt;\n  select(Name, Station, Walk, ScoreN, Score)\n\n# A tibble: 6 × 5\n  Name                      Station  Walk ScoreN Score\n  &lt;chr&gt;                     &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1 Lei can ting 大阪ルクア店 大阪駅      3      3  4   \n2 神座 ルクア大阪店         大阪駅      1     10  3.94\n3 みつか坊主 醸             大阪駅     10      4  5   \n4 無尽蔵 京都八条家         京都駅      5      2  3.5 \n5 中華料理 清華園           京都駅     10      3  5   \n6 ますたに 京都拉麺小路店   京都駅      9      3  3.67\n\n\n　Songが大好きな神座がヒットして嬉しいです。"
  },
  {
    "objectID": "datahandling1.html#sec-handling1-arrange",
    "href": "datahandling1.html#sec-handling1-arrange",
    "title": "13  データハンドリング [抽出]",
    "section": "13.5 行のソート",
    "text": "13.5 行のソート\n　続いて、行のソートについて解説します。「食べログ」などのレビューサービスを利用する場合、口コミ評価が高い順で見るのが一般的でしょう4。また、サッカーのランキングも多くは1位から下の順位で掲載されるのが一般的です。ここではこのようにある変数の値順に行を並び替える方法について説明します。\n　ソートには{dplyr}パッケージのarrange()関数を使います。引数は変数名のみです。たとえば、奈良県のラーメン屋を検索してみましょう。並び替える順は駅から近い店舗を上位に、遠い店舗を下位に並べます。このような順は昇順 (ascending)と呼ばれ、ランキング表などでよく見ます。駅から近い順にソートするので、まず最寄りの駅情報が欠損でないことが必要です。また、ラーメン屋の評価も気になるので口コミが1つ以上付いている店舗に絞りましょう。表示する列は店舗名、最寄りの駅、徒歩距離、口コミ数、点数です。\n\ndf |&gt;\n  filter(Pref == \"奈良県\", !is.na(Station), ScoreN &gt; 0) |&gt;\n  select(Name, Station, Walk, ScoreN, Score) |&gt;\n  arrange(Walk) |&gt;\n  print(n = Inf)\n\n# A tibble: 24 × 5\n   Name                                  Station             Walk ScoreN Score\n   &lt;chr&gt;                                 &lt;chr&gt;              &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 麺屋 あまのじゃく 本店                富雄駅                 2      2  4.5 \n 2 紀州和歌山らーめんきぶんや 奈良富雄店 富雄駅                 4      1  4   \n 3 ラーメン家 みつ葉                     富雄駅                 4      1  3.5 \n 4 天下一品 新大宮店                     新大宮駅               6      1  3   \n 5 麺屋 一徳                             天理駅                 7      1  3   \n 6 丸源ラーメン 橿原店                   金橋駅                 8      1  3.5 \n 7 らーめん食堂 よってこや 平群店        元山上口駅            10      1  4   \n 8 天理スタミナラーメン本店              櫟本駅                11      2  3.25\n 9 博多長浜らーめん夢街道 奈良土橋店     真菅駅                11      1  3.5 \n10 ぶ～け                                奈良駅                11      1  5   \n11 つけめん らーめん元喜神 押熊店        学研奈良登美ヶ丘駅    12      4  4.12\n12 彩華ラーメン 本店                     前栽駅                12      5  3.6 \n13 力皇                                  天理駅                13      1  3.5 \n14 らーめん きみちゃん                   京終駅                14      2  4.5 \n15 無鉄砲がむしゃら                      帯解駅                15      2  4   \n16 彩華ラーメン 田原本店                 石見駅                15      1  4   \n17 神座 大和高田店                       大和高田駅            17      2  3.75\n18 彩華ラーメン 奈良店                   尼ヶ辻駅              17      3  4.33\n19 彩華ラーメン 桜井店                   大福駅                18      1  3   \n20 天下一品 東生駒店                     東生駒駅              19      1  3.5 \n21 まりお流ラーメン                      新大宮駅              20      1  5   \n22 どうとんぼり神座 奈良柏木店           西ノ京駅              22      1  3   \n23 河童ラーメン本舗 押熊店               学研奈良登美ヶ丘駅    28      1  4   \n24 博多長浜らーめん 夢街道 四条大路店    新大宮駅              29      4  2.88\n\n\n　3行まではこれまで習ってきたもので、4行目がソートの関数、arrange()です。引数はソートの基準となる変数で、今回は最寄りの駅からの徒歩距離を表すWalkです。5行目は省略可能ですが、tibbleクラスの場合、10行までしか出力されないので、print(n = Inf)で「すべての行を表示」させます。nを指定することで出力される行数が調整可能です。奈良県のラーメン屋の中で最寄りの駅から最も近い店は「麺屋 あまのじゃく 本店」で徒歩2分でした。京田辺店も駅から約2分ですし、近いですね。ちなみにSongはここの塩とんこつが好きです。世界一こってりなラーメンとも言われる「チョモランマ」で有名な「まりお流ラーメン」は新大宮駅から徒歩20分でかなり遠いことが分かります。\n　続いて、駅からの距離ではなく、評価が高い順にしてみましょう。評価が高いほど上に来るので、今回は昇順でなく、降順 (descending)でソートする必要があります。arrange()関数は基本的に、指定された変数を基準に昇順でソートします。降順にするためにはdesc()関数を更に用います。たとえば、arrange(desc(変数名))のようにです。それでは実際にやってみましょう。上のコードの4行目をarange(Walk)からarrange(desc(Score))にちょっと修正するだけです。\n\ndf |&gt;\n  filter(Pref == \"奈良県\", !is.na(Station), ScoreN &gt; 0) |&gt;\n  select(Name, Station, Walk, ScoreN, Score) |&gt;\n  arrange(desc(Score)) |&gt;\n  print(n = Inf)\n\n# A tibble: 24 × 5\n   Name                                  Station             Walk ScoreN Score\n   &lt;chr&gt;                                 &lt;chr&gt;              &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 まりお流ラーメン                      新大宮駅              20      1  5   \n 2 ぶ～け                                奈良駅                11      1  5   \n 3 麺屋 あまのじゃく 本店                富雄駅                 2      2  4.5 \n 4 らーめん きみちゃん                   京終駅                14      2  4.5 \n 5 彩華ラーメン 奈良店                   尼ヶ辻駅              17      3  4.33\n 6 つけめん らーめん元喜神 押熊店        学研奈良登美ヶ丘駅    12      4  4.12\n 7 河童ラーメン本舗 押熊店               学研奈良登美ヶ丘駅    28      1  4   \n 8 無鉄砲がむしゃら                      帯解駅                15      2  4   \n 9 紀州和歌山らーめんきぶんや 奈良富雄店 富雄駅                 4      1  4   \n10 彩華ラーメン 田原本店                 石見駅                15      1  4   \n11 らーめん食堂 よってこや 平群店        元山上口駅            10      1  4   \n12 神座 大和高田店                       大和高田駅            17      2  3.75\n13 彩華ラーメン 本店                     前栽駅                12      5  3.6 \n14 天下一品 東生駒店                     東生駒駅              19      1  3.5 \n15 力皇                                  天理駅                13      1  3.5 \n16 博多長浜らーめん夢街道 奈良土橋店     真菅駅                11      1  3.5 \n17 ラーメン家 みつ葉                     富雄駅                 4      1  3.5 \n18 丸源ラーメン 橿原店                   金橋駅                 8      1  3.5 \n19 天理スタミナラーメン本店              櫟本駅                11      2  3.25\n20 麺屋 一徳                             天理駅                 7      1  3   \n21 どうとんぼり神座 奈良柏木店           西ノ京駅              22      1  3   \n22 彩華ラーメン 桜井店                   大福駅                18      1  3   \n23 天下一品 新大宮店                     新大宮駅               6      1  3   \n24 博多長浜らーめん 夢街道 四条大路店    新大宮駅              29      4  2.88\n\n\n　よく考えてみれば、「評価が同点の場合、どうなるの?」と疑問を抱く方がいるかも知れません。たとえば、7行目の「河童ラーメン本舗 押熊店」と8行目の「無鉄砲がむしゃら」はどれも評価が4点ですが、「河童ラーメン本舗 押熊店」が先に表示されます。そのこれは簡単です。同点の場合、データセット内で上に位置する行が先に表示されます。これを確認するにはwhich()関数を使います。()内に条件文を指定することで、この条件に合致する要素の位置を返します。もし、条件に合致するものが複数あった場合は全ての位置を返します5。\n\nwhich(df$Name == \"河童ラーメン本舗 押熊店\")\n\n[1] 6021\n\nwhich(df$Name == \"無鉄砲がむしゃら\")\n\n[1] 6040\n\n\n　データ内に「河童ラーメン本舗 押熊店」がより上に位置することが分かります。「もし同点なら口コミ評価数が多いところにしたい」場合はどうすれば良いでしょうか。これはarrange()内に変数名を足すだけで十分です。\n\ndf |&gt;\n  filter(Pref == \"奈良県\", !is.na(Station), ScoreN &gt; 0) |&gt;\n  select(Name, Station, Walk, ScoreN, Score) |&gt;\n  arrange(desc(Score), desc(ScoreN)) |&gt;\n  print(n = Inf)\n\n# A tibble: 24 × 5\n   Name                                  Station             Walk ScoreN Score\n   &lt;chr&gt;                                 &lt;chr&gt;              &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 まりお流ラーメン                      新大宮駅              20      1  5   \n 2 ぶ～け                                奈良駅                11      1  5   \n 3 麺屋 あまのじゃく 本店                富雄駅                 2      2  4.5 \n 4 らーめん きみちゃん                   京終駅                14      2  4.5 \n 5 彩華ラーメン 奈良店                   尼ヶ辻駅              17      3  4.33\n 6 つけめん らーめん元喜神 押熊店        学研奈良登美ヶ丘駅    12      4  4.12\n 7 無鉄砲がむしゃら                      帯解駅                15      2  4   \n 8 河童ラーメン本舗 押熊店               学研奈良登美ヶ丘駅    28      1  4   \n 9 紀州和歌山らーめんきぶんや 奈良富雄店 富雄駅                 4      1  4   \n10 彩華ラーメン 田原本店                 石見駅                15      1  4   \n11 らーめん食堂 よってこや 平群店        元山上口駅            10      1  4   \n12 神座 大和高田店                       大和高田駅            17      2  3.75\n13 彩華ラーメン 本店                     前栽駅                12      5  3.6 \n14 天下一品 東生駒店                     東生駒駅              19      1  3.5 \n15 力皇                                  天理駅                13      1  3.5 \n16 博多長浜らーめん夢街道 奈良土橋店     真菅駅                11      1  3.5 \n17 ラーメン家 みつ葉                     富雄駅                 4      1  3.5 \n18 丸源ラーメン 橿原店                   金橋駅                 8      1  3.5 \n19 天理スタミナラーメン本店              櫟本駅                11      2  3.25\n20 麺屋 一徳                             天理駅                 7      1  3   \n21 どうとんぼり神座 奈良柏木店           西ノ京駅              22      1  3   \n22 彩華ラーメン 桜井店                   大福駅                18      1  3   \n23 天下一品 新大宮店                     新大宮駅               6      1  3   \n24 博多長浜らーめん 夢街道 四条大路店    新大宮駅              29      4  2.88\n\n\n　ソートの基準はarrange()内において先に指定された変数の順番となります。「口コミ評価も評価数も同じなら、駅から近いところにしたい」場合は変数が3つとなり、Score、ScoreN、Walkの順で入れます。\n\ndf |&gt;\n  filter(Pref == \"奈良県\", !is.na(Station), ScoreN &gt; 0) |&gt;\n  select(Name, Station, Walk, ScoreN, Score) |&gt;\n  arrange(desc(Score), desc(ScoreN), Walk) |&gt;\n  print(n = Inf)\n\n# A tibble: 24 × 5\n   Name                                  Station             Walk ScoreN Score\n   &lt;chr&gt;                                 &lt;chr&gt;              &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n 1 ぶ～け                                奈良駅                11      1  5   \n 2 まりお流ラーメン                      新大宮駅              20      1  5   \n 3 麺屋 あまのじゃく 本店                富雄駅                 2      2  4.5 \n 4 らーめん きみちゃん                   京終駅                14      2  4.5 \n 5 彩華ラーメン 奈良店                   尼ヶ辻駅              17      3  4.33\n 6 つけめん らーめん元喜神 押熊店        学研奈良登美ヶ丘駅    12      4  4.12\n 7 無鉄砲がむしゃら                      帯解駅                15      2  4   \n 8 紀州和歌山らーめんきぶんや 奈良富雄店 富雄駅                 4      1  4   \n 9 らーめん食堂 よってこや 平群店        元山上口駅            10      1  4   \n10 彩華ラーメン 田原本店                 石見駅                15      1  4   \n11 河童ラーメン本舗 押熊店               学研奈良登美ヶ丘駅    28      1  4   \n12 神座 大和高田店                       大和高田駅            17      2  3.75\n13 彩華ラーメン 本店                     前栽駅                12      5  3.6 \n14 ラーメン家 みつ葉                     富雄駅                 4      1  3.5 \n15 丸源ラーメン 橿原店                   金橋駅                 8      1  3.5 \n16 博多長浜らーめん夢街道 奈良土橋店     真菅駅                11      1  3.5 \n17 力皇                                  天理駅                13      1  3.5 \n18 天下一品 東生駒店                     東生駒駅              19      1  3.5 \n19 天理スタミナラーメン本店              櫟本駅                11      2  3.25\n20 天下一品 新大宮店                     新大宮駅               6      1  3   \n21 麺屋 一徳                             天理駅                 7      1  3   \n22 彩華ラーメン 桜井店                   大福駅                18      1  3   \n23 どうとんぼり神座 奈良柏木店           西ノ京駅              22      1  3   \n24 博多長浜らーめん 夢街道 四条大路店    新大宮駅              29      4  2.88"
  },
  {
    "objectID": "datahandling2.html#sec-handling2-summarise",
    "href": "datahandling2.html#sec-handling2-summarise",
    "title": "14  データハンドリング [拡張]",
    "section": "14.1 記述統計量の計算",
    "text": "14.1 記述統計量の計算\n\n14.1.1 summarise()による記述統計量の計算\nある変数の平均値や標準偏差、最小値、最大値などの記述統計量 (要約統計量)を計算することも可能です。これはsummarize()またはsummarise()関数を使いますが、この関数は後で紹介するgroup_by()関数と組み合わせることで力を発揮します。ここではグルーピングを考えずに、全データの記述統計量を計算する方法を紹介します。\nsummarise()関数の使い方は以下の通りです。\n\n# summarise()関数の使い方\nデータフレーム名 |&gt;\n  summarise(新しい変数名 = 関数名(計算の対象となる変数名))\n\nもし、Score変数の平均値を計算し、その結果をMeanという列にしたい場合は以下のようなコードになります。\n\ndf |&gt;\n  summarise(Mean = mean(Score))\n\n# A tibble: 1 × 1\n   Mean\n  &lt;dbl&gt;\n1    NA\n\n\nただし、mean()関数は欠損値が含まれるベクトルの場合、NAを返します。この場合方法は2つ考えられます。\n\nfilter()関数を使ってScoreが欠損しているケースを予め除去する。\nna.rm引数を指定し、欠損値を除去した平均値を求める。\n\nここでは2番目の方法を使います。\n\ndf |&gt;\n  summarise(Mean = mean(Score, na.rm = TRUE))\n\n# A tibble: 1 × 1\n   Mean\n  &lt;dbl&gt;\n1  3.66\n\n\ndfのScore変数の平均値はNAであることが分かります。また、summarise()関数は複数の記述統計量を同時に計算することも可能です。以下はScore変数の平均値、中央値、標準偏差、最小値、最大値、第一四分位点、第三四分位点を計算し、Score.Descという名のデータフレームに格納するコードです。\n\nScore.Desc &lt;- df |&gt;\n  summarize(Mean   =     mean(Score,       na.rm = TRUE),  # 平均値\n            Median =   median(Score,       na.rm = TRUE),  # 中央値\n            SD     =       sd(Score,       na.rm = TRUE),  # 標準偏差\n            Min    =      min(Score,       na.rm = TRUE),  # 最小値\n            Max    =      max(Score,       na.rm = TRUE),  # 最大値\n            Q1     = quantile(Score, 0.25, na.rm = TRUE),  # 第一四分位点\n            Q3     = quantile(Score, 0.75, na.rm = TRUE))  # 第三四分位点\n\n\nScore.Desc\n\n# A tibble: 1 × 7\n   Mean Median    SD   Min   Max    Q1    Q3\n  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  3.66   3.58 0.719     1     5     3     4\n\n\nむろん、複数の変数に対して記述統計量を計算することも可能です。たとえば、平均予算 (Budget)、口コミ数 (ScoreN)、口コミ評価 (Score)の平均値を求めるとしたら、\n\ndf |&gt;\n  summarize(Budget_Mean = mean(Budget, na.rm = TRUE), # 平均予算の平均値\n            SocreN_Mean = mean(ScoreN, na.rm = TRUE), # 口コミ数の平均値\n            Score_Mean  = mean(Score,  na.rm = TRUE)) # 評価の平均値\n\n# A tibble: 1 × 3\n  Budget_Mean SocreN_Mean Score_Mean\n        &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;\n1       1232.       0.537       3.66\n\n\nのように書きます。実はsummarise()はこれくらいで十分便利です。ただし、以上の操作はもっと簡単なコードに置換できます。ただし、ラムダ式など、やや高度な内容になるため、以下の内容は飛ばして、次の節 (グルーピング)を読んでいただいても構いません。\nまずは、複数の変数に対して同じ記述統計量を求める例を考えてみましょう。たとえば、Budget、ScoreN、Scoreに対して平均値を求める例です。これはacross()関数を使うとよりコードが短くなります。まずはacross()関数の書き方から見ましょう。\n\n# across()の使い方\nデータフレーム名 |&gt;\n  summarise(across(変数名のベクトル, ラムダ式))\n\n変数名のベクトルは長さ1以上のベクトルです。たとえば、Budget、ScoreN、Scoreの場合c(Budget, ScoreN, Score)になります。これはdf内で隣接する変数ですからBudget:Scoreの書き方も使えます。また、where()やany_of()、starts_with()のような関数を使って変数を指定することも可能です。ラムダ式は~で始まる関数であり、匿名関数とよ呼ばれます。たとえば、平均値を計算するラムダ式は~mean()であり、第一引数は.xとなります。この.xにacross()の第一引数（変数たち）が入ります。また、()内には更に引数を指定することもでき、たとえば欠損値を除外して計算するna.rm = TRUEなどが追加できます。ラムダ式の詳細は後でもう一度解説するとし、とりあえずBudget、ScoreN、Scoreの平均値を計算してみましょう1。\n\ndf |&gt;\n  summarize(across(Budget:Score, ~mean(.x, na.rm = TRUE)))\n\n# A tibble: 1 × 3\n  Budget ScoreN Score\n   &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;\n1  1232.  0.537  3.66\n\n\nacross()使わない場合、4行必要だったコードが2行になりました。変数が少ない場合はacross()を使わない方が、可読性が高くなる場合もあります。しかし、変数が多くなる場合、可読性がやや落ちてもacross()を使った方が効率的でしょう。\n次は、ある変数に対して複数の記述統計量を計算したい場合について考えます。Budget、ScoreN、Score変数の第一四分位点と第三四分位点をacross()を使わずに計算すると家のような7行のコードになります。\n\ndf |&gt;\n  summarize(Budget_Q1 = quantile(Budget, 0.25, na.rm = TRUE),\n            Budget_Q3 = quantile(Budget, 0.75, na.rm = TRUE),\n            ScoreN_Q1 = quantile(ScoreN, 0.25, na.rm = TRUE),\n            ScoreN_Q3 = quantile(ScoreN, 0.75, na.rm = TRUE),\n            Score_Q1  = quantile(Score,  0.25, na.rm = TRUE),\n            Score_Q3  = quantile(Score,  0.75, na.rm = TRUE))\n\n# A tibble: 1 × 6\n  Budget_Q1 Budget_Q3 ScoreN_Q1 ScoreN_Q3 Score_Q1 Score_Q3\n      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1       800      1000         0         0        3        4\n\n\nこの作業もacross()を使ってより短縮することができます。ここではラムダ式の知識が必要になります。ラムダ関数とは関数名を持たない無名関数 (anonymous functions)を意味しますが、詳細は割愛します。興味のある読者はWikipediaなどを参照してください。簡単にいうとその場で即席に関数を作成し、計算が終わったら破棄する関数です。ただ、Rは基本的にラムダ式を提供しているのではなく、purrrパッケージのラムダ式スタイルを使用します。まずは、書き方から確認します。\n\n# ラムダ式を用いたacross()の使い方\nデータフレーム名 |&gt;\n  summarise(across(変数名のベクトル, .fns = list(結果の変数名 = ラムダ式)))\n\n先ほどの書き方と似ていますが、関数を複数書く必要があるため、今回は関数名をlist型にまとめ、.fns引数に指定します。そして、結果の変数名は結果として出力されるデータフレームの列名を指定する引数です。たとえば、Meanにすると結果は元の変数名1_Mean、元の変数名2_Mean…のように出力されます。そして、ラムダ式が実際の関数が入る箇所です。とりあえず今回はコードを走らせ、結果から確認してみましょう。\n\ndf |&gt;\n  summarize(across(Budget:Score, \n                   .fns = list(Q1 = ~quantile(.x, 0.25, na.rm = TRUE),\n                               Q3 = ~quantile(.x, 0.75, na.rm = TRUE))))\n\n# A tibble: 1 × 6\n  Budget_Q1 Budget_Q3 ScoreN_Q1 ScoreN_Q3 Score_Q1 Score_Q3\n      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1       800      1000         0         0        3        4\n\n\n結果の列名がBudget_Q1、Budget_Q3、ScoreN_Q1…のようになり、それぞれの変数の第一四分位点と第三四分位点が出力されます。問題はラムダ式の方ですが、普通の関数に非常に近いことが分かります。across()内のラムダ式は~関数名(.x, その他の引数)のような書き方になります。関数名の前に~が付いていることに注意してください。分位数を求める関数はquantile()であり、quantile(ベクトル, 分位数)であり、必要に応じてna.rmを付けます。この分位数が0.25なら第一四分位点、0.5なら第二四分位点 (=中央値)、0.75なら第三四分位点になります。それではラムダ式~quantile(.x, 0.25, na.rm = TRUE)はどういう意味でしょうか。これは.xの箇所にBudgetやScoreN、Scoreが入ることを意味します。.xという書き方は決まりです。.yとか.Song-san-Daisukiなどはダメです。そして、0.25を付けることによって第一四分位点を出力するように指定します。また、Budget、ScoreN、Scoreに欠損値がある場合、無視するようにna.rm = TRUEを付けます。\nラムダ式を第11章で解説した自作関数で表現すると、以下のようになります。\n\n# 以下の3つは同じ機能をする関数である\n\n# ラムダ式\n~quantile(.x, 0.25, na.rm = TRUE)\n\n# 一般的な関数の書き方1\n名無し関数 &lt;- function(x) {\n  quantile(x, 0.25, na.rm = TRUE)\n}\n\n# 一般的な関数の書き方2\n名無し関数 &lt;- function(x) quantile(x, 0.25, na.rm = TRUE)\n\nこの3つは全て同じですが、ラムダ式は関数名を持たず、その場で使い捨てる関数です。むろん、ラムダ式を使わずに事前に第一四分位点と第三四分位点を求める関数を予め作成し、ラムダ式の代わりに使うことも可能です。まずは第一四分位点と第三四分位点を求める自作関数FuncQ1とFuncQ2を作成します。\n\n# ラムダ式を使わない場合は事前に関数を定義しておく必要がある\nFuncQ1 &lt;- function(x) {\n  quantile(x, 0.25, na.rm = TRUE)\n}\nFuncQ3 &lt;- function(x) {\n  quantile(x, 0.75, na.rm = TRUE)\n}\n\n後は先ほどのほぼ同じ書き方ですが、今回はラムダ式を使わないため関数名に~を付けず、関数名のみで十分です。()も不要です。\n\n# やっておくと、summarise()文は簡潔になる\ndf |&gt;\n  summarize(across(Budget:Score, list(Q1 = FuncQ1, Q3 = FuncQ3)))\n\n# A tibble: 1 × 6\n  Budget_Q1 Budget_Q3 ScoreN_Q1 ScoreN_Q3 Score_Q1 Score_Q3\n      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1       800      1000         0         0        3        4\n\n\n事前に関数を用意するのが面倒ですが、across()の中身はかなりスッキリしますね。もし、このような作業を何回も行うなら、ラムダ式を使わず、自作関数を用いることも可能です。ただし、自作関数であっても引数が2つ以上必要な場合はラムダ式を使います。\n\n\n14.1.2 summarise()に使える便利な関数\n以下の内容は後で説明するgroup_by()関数を使っているため、まだgroup_by()に馴染みのない読者はまずはここを読み飛ばし、グルーピングの節にお進みください。\nIQR(): 四分位範囲を求める\n四分位範囲は第三四分位点から第一四分位点を引いた値であり、Rの内蔵関数であるIQR()を使えば便利です。この関数はmeanやsd()関数と同じ使い方となります。\n\ndf |&gt;\n  filter(!is.na(Walk)) |&gt; # 予め欠損したケースを除くと、後でna.rm = TRUEが不要\n  group_by(Pref) |&gt;\n  summarise(Mean    = mean(Walk),\n            SD      = sd(Walk),\n            IQR     = IQR(Walk),\n            N       = n(),\n            .groups = \"drop\") |&gt;\n  arrange(Mean)\n\n# A tibble: 9 × 5\n  Pref      Mean    SD   IQR     N\n  &lt;chr&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt;\n1 東京都    4.29  4.49     4   919\n2 大阪府    5.92  6.08     6   932\n3 神奈川県  8.21  7.91    10   878\n4 京都府    8.38  6.95     9   339\n5 兵庫県    8.52  7.27    10   484\n6 奈良県   10.6   6.59    10   123\n7 千葉県   10.6   8.21    12   776\n8 埼玉県   11.6   8.99    14   817\n9 和歌山県 12.8   6.83     9   107\n\n\nfirst()、last()、nth(): n番目の要素を求める\n稀なケースかも知れませんが、データ内、またはグループ内のn番目の行を抽出する時があります。たとえば、市区町村の情報が格納されているデータセットで、人口が大きい順でデータがソートされているとします。各都道府県ごとに最も人口が大きい市区町村のデータ、あるいは最も少ない市区町村のデータが必要な際、first()とlast()関数が有効です。\nそれでは各都道府県ごとに「最も駅から遠いラーメン屋」の店舗名と最寄りの駅からの徒歩距離を出力したいとします。まずは、徒歩距離のデータが欠損しているケースを除去し、データを徒歩距離順でソートします。これはfilter()とarrange()関数を使えば簡単です。続いて、group_by()を使って都府県単位でデータをグループ化します。最後にsummarise()関数内にlast()関数を使います。データは駅から近い順に鳴っているため、各都府県内の最後の行は駅から最も遠い店舗になるからです。\n\ndf |&gt;\n  filter(!is.na(Walk)) |&gt;\n  arrange(Walk) |&gt;\n  group_by(Pref) |&gt;\n  summarise(Farthest  = last(Name),\n            Distance  = last(Walk))\n\n# A tibble: 9 × 3\n  Pref     Farthest                           Distance\n  &lt;chr&gt;    &lt;chr&gt;                                 &lt;dbl&gt;\n1 京都府   熱烈らぁめん                             30\n2 兵庫県   濃厚醤油 中華そば いせや 玉津店          43\n3 千葉県   札幌ラーメン どさん子 佐原51号店         59\n4 和歌山県 中華そば まる乃                          30\n5 埼玉県   札幌ラーメン どさん子 小鹿野店          116\n6 大阪府   河童ラーメン本舗 岸和田店                38\n7 奈良県   博多長浜らーめん 夢街道 四条大路店       29\n8 東京都   てんがら 青梅新町店                      30\n9 神奈川県 札幌ラーメン どさん子 中津店             73\n\n\nこのlast()をfirst()に変えると、最寄りの駅から最も近い店舗情報が表示されます。また、「n番目の情報」が必要な際はnth()関数を使います。nth(Name, 2)に変えることで2番目の店舗名が抽出できます。\nn_distinct(): ユニーク値の個数を求める\nn_distinct()は何種類の要素が含まれているかを計算する関数であり、length(unique())関数と同じ機能をします。たとえば、以下のmyVec1に対して何種類の要素があるかを確認してみましょう。\n\nmyVec1 &lt;- c(\"A\", \"B\", \"B\", \"D\", \"A\", \"B\", \"D\", \"C\", \"A\")\n\nunique(myVec1)\n\n[1] \"A\" \"B\" \"D\" \"C\"\n\n\nmyVec1は\"A\"、\"B\"、\"D\"、\"C\"の要素で構成されていることが分かります。これがmyVec1のユニーク値 (unique values)です。そして、このユニーク値の個数を調べるためにlength()を使います。\n\nlength(unique(myVec1))\n\n[1] 4\n\n\nこれでmyVec1は4種類の値が存在することが分かります。これと全く同じ機能をする関数がn_distinct()です。\n\nn_distinct(myVec1)\n\n[1] 4\n\n\nこの関数をsummarise()に使うことで、都府県ごとに駅の個数が分かります。あるいは「東京都内の選挙区に、これまでの衆院選において何人の候補者が存在したか」も分かります。ここではdf内の都府県ごとに駅の個数を計算してみましょう。最後の駅数が多い順でソートします。\n\ndf |&gt;\n  filter(!is.na(Station)) |&gt; # 最寄りの駅が欠損しているケースを除去\n  group_by(Pref) |&gt;\n  summarise(N_Station = n_distinct(Station),\n            .groups   = \"drop\") |&gt;\n  arrange(desc(N_Station))\n\n# A tibble: 9 × 2\n  Pref     N_Station\n  &lt;chr&gt;        &lt;int&gt;\n1 東京都         368\n2 大阪府         341\n3 千葉県         241\n4 神奈川県       240\n5 兵庫県         199\n6 埼玉県         185\n7 京都府         123\n8 奈良県          52\n9 和歌山県        46\n\n\n当たり前かも知れませんが、駅数が最も多いのは東京都で次が大阪府であることが分かります。\nany()、all(): 条件に合致するか否かを求める\nany()とall()はベクトル内の全要素に対して条件に合致するか否かを判定する関数です。ただし、any()は一つの要素でも条件に合致すればTRUEを、全要素が合致しない場合FALSEを返します。一方、all()は全要素に対して条件を満たせばTRUE、一つでも満たさない要素があればFALSEを返します。以下はany()とall()の例です。\n\nmyVec1 &lt;- c(1, 2, 3, 4, 5)\nmyVec2 &lt;- c(1, 3, 5, 7, 11)\n\nany(myVec1 %% 2 == 0) # myVec1を2で割った場合、一つでも余りが0か\n\n[1] TRUE\n\nall(myVec1 %% 2 == 0) # myVec1を2で割った場合、全ての余りが0か\n\n[1] FALSE\n\nall(myVec2 %% 2 != 0) # myVec2を2で割った場合、全ての余りが0ではないか\n\n[1] TRUE\n\n\nそれでは実際にdfに対してany()とall()関数を使ってみましょう。一つ目は「ある都府県に最寄りの駅から徒歩60分以上の店舗が一つでもあるか」であり、二つ目は「ある都府県の店舗は全て最寄りの駅から徒歩30分以下か」です。それぞれの結果をOver60とWithin30という列で出力してみましょう。\n\ndf |&gt;\n  group_by(Pref) |&gt;\n  summarise(Over60   = any(Walk &gt;= 60, na.rm = TRUE),\n            Within30 = all(Walk &lt;= 30, na.rm = TRUE),\n            .groups  = \"drop\")\n\n# A tibble: 9 × 3\n  Pref     Over60 Within30\n  &lt;chr&gt;    &lt;lgl&gt;  &lt;lgl&gt;   \n1 京都府   FALSE  TRUE    \n2 兵庫県   FALSE  FALSE   \n3 千葉県   FALSE  FALSE   \n4 和歌山県 FALSE  TRUE    \n5 埼玉県   TRUE   FALSE   \n6 大阪府   FALSE  FALSE   \n7 奈良県   FALSE  TRUE    \n8 東京都   FALSE  TRUE    \n9 神奈川県 TRUE   FALSE   \n\n\n埼玉県と神奈川県において、最寄りの駅から徒歩60以上の店がありました。また、京都府、東京都、奈良県、和歌山県の場合、全店舗が最寄りの駅から徒歩30分以下ということが分かります。当たり前ですがOver60がTRUEならWithin30は必ずFALSEになりますね。"
  },
  {
    "objectID": "datahandling2.html#sec-handling2-group",
    "href": "datahandling2.html#sec-handling2-group",
    "title": "14  データハンドリング [拡張]",
    "section": "14.2 グルーピング",
    "text": "14.2 グルーピング\n\n14.2.1 group_by()によるグループ化\n先ほどのsummarise()関数は確かに便利ですが、特段に便利とも言いにくいです。dfのScoreの平均値を計算するだけなら、summarise()関数を使わない方が楽です。\n\n# これまでのやり方\ndf |&gt;\n  summarise(Mean = mean(Score, na.rm = TRUE))\n\n# A tibble: 1 × 1\n   Mean\n  &lt;dbl&gt;\n1  3.66\n\n# 普通にこれでええんちゃう?\nmean(df$Score, na.rm = TRUE)\n\n[1] 3.663457\n\n\nしかし、これをグループごとに計算するならどうでしょう。たとえば、Scoreの平均値を都府県ごとに計算するとします。この場合、以下のようなコードになります。\n\nmean(df$Score[df$Pref == \"東京都\"],   na.rm = TRUE)\n\n[1] 3.674256\n\nmean(df$Score[df$Pref == \"神奈川県\"], na.rm = TRUE)\n\n[1] 3.533931\n\nmean(df$Score[df$Pref == \"千葉県\"],   na.rm = TRUE)\n\n[1] 3.715983\n\nmean(df$Score[df$Pref == \"埼玉県\"],   na.rm = TRUE)\n\n[1] 3.641573\n\nmean(df$Score[df$Pref == \"大阪府\"],   na.rm = TRUE)\n\n[1] 3.765194\n\nmean(df$Score[df$Pref == \"京都府\"],   na.rm = TRUE)\n\n[1] 3.684976\n\nmean(df$Score[df$Pref == \"兵庫県\"],   na.rm = TRUE)\n\n[1] 3.543936\n\nmean(df$Score[df$Pref == \"奈良県\"],   na.rm = TRUE)\n\n[1] 3.854762\n\nmean(df$Score[df$Pref == \"和歌山県\"], na.rm = TRUE)\n\n[1] 3.96999\n\n\n変わったのはdf$Scoreがdf$Score[df$Pref == \"東京都\"]に変わっただけです。df$Prefが\"東京都\"であるか否かをTRUEとFALSEで判定し、これを基準にdf$Scoreを抽出する仕組みです。df$Scoreとdf$Prefは同じデータフレームですから、このような書き方で問題ありません。\nこれだけでもかなり書くのが面倒ですが、これが47都道府県なら、あるいは200ヶ国ならかなり骨の折れる作業でしょう。ここで大活躍するのがdplyrパッケージのgroup_by()関数です。引数はグループ化する変数名だけです。先ほどの作業をdplyrを使うならPref変数でグループ化し、summarise()関数で平均値を求めるだけです。今回はScoreだけでなく、ScoreNの平均値も求めてみましょう。そして、評価が高い順にソートもしてみます。\n\n# ScoreNとScoreの平均値をPrefごとに求める\ndf |&gt;\n  group_by(Pref) |&gt;\n  summarise(ScoreN_Mean = mean(ScoreN, na.rm = TRUE),\n            Score_Mean  = mean(Score,  na.rm = TRUE)) |&gt;\n  arrange(desc(Score_Mean))\n\n# A tibble: 9 × 3\n  Pref     ScoreN_Mean Score_Mean\n  &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;\n1 和歌山県       0.593       3.97\n2 奈良県         0.306       3.85\n3 大阪府         0.516       3.77\n4 千葉県         0.259       3.72\n5 京都府         0.522       3.68\n6 東京都         1.16        3.67\n7 埼玉県         0.278       3.64\n8 兵庫県         0.389       3.54\n9 神奈川県       0.587       3.53\n\n\n評判が最も高い都府県は和歌山県、最も低いのは神奈川県ですね。Songも和歌山ラーメンは井出系も車庫前系も好きです。しかし、大事なのは「井出系」と「車庫前系」といった分類が正しいかどうかではありません。コードが非常に簡潔となり、ソートなども自由自在であることです。都府県ごとにScoreNとScoreの平均値を求める場合、dplyr()を使わなかったら18行のコードとなり、ソートも自分でやる必要があります。一方、group_by()関数を使うことによってコードが5行になりました。\nまた、これは2020年6月に公開されたdplyr1.0.0からの問題ですが、group_by()の後にsummarise()を使うと以下のようなメッセージが出力されます。\n## `summarise()` ungrouping output (override with `.groups` argument)\nこれはgroup_by()で指定された変数のグループ化が自動的に解除されたことを意味します。なぜならsummarise()をする際はPrefをグループ変数として使いましたが、出力された結果のPref変数はもはやグループとして機能できなくなるからです。元のdfにはPrefが\"東京都\"だったケースが1000行、\"京都府\"だったのが414行あったので、Pref変数でグループ化する意味がありました。しかし、summarise()から得られたデータフレームはPref == \"東京都\"の行が1つしかありません。これはグループ化する意味がなくなったことを意味します。したがって、自動的にグループを解除してくれます。自動的にやってくれるのはありがたいことですが、可能ならば関数内に自分で明記することが推奨されます。そこで使う引数が.groupsであり、\"drop\"を指定すると全てのグループ化変数を解除します。以下のようなコードだと先ほどのメッセージが表示されません。今後、意識的に入れるようにしましょう。\n\n# ScoreNとScoreの平均値をPrefごとに求める\ndf |&gt;\n  group_by(Pref) |&gt;\n  summarise(ScoreN_Mean = mean(ScoreN, na.rm = TRUE),\n            Score_Mean  = mean(Score,  na.rm = TRUE),\n            .groups     = \"drop\") |&gt;\n  arrange(desc(Score_Mean))\n\n# A tibble: 9 × 3\n  Pref     ScoreN_Mean Score_Mean\n  &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;\n1 和歌山県       0.593       3.97\n2 奈良県         0.306       3.85\n3 大阪府         0.516       3.77\n4 千葉県         0.259       3.72\n5 京都府         0.522       3.68\n6 東京都         1.16        3.67\n7 埼玉県         0.278       3.64\n8 兵庫県         0.389       3.54\n9 神奈川県       0.587       3.53\n\n\n続いて、一つ便利な関数を紹介します。それはグループのサイズを計算する関数、n()です。この関数をsummarise()内に使うと、各グループに属するケース数を出力します2。先ほどのコードを修正し、各グループのサイズをNという名の列として追加してみましょう。そしてソートの順番はNを最優先とし、同じ場合はScore_Meanが高い方を上に出力させます。また、ScoreN_Meanの前に、口コミ数の合計も出してみましょう。\n\n# Prefごとに口コミ数の合計、口コミ数の平均値、評価の平均値、店舗数を求める\n# 店舗数-評価の平均値順でソートする\ndf |&gt;\n  group_by(Pref) |&gt;\n  summarise(ScoreN_Sum  = sum(ScoreN,  na.rm = TRUE),\n            ScoreN_Mean = mean(ScoreN, na.rm = TRUE),\n            Score_Mean  = mean(Score,  na.rm = TRUE),\n            N           = n(),\n            .groups     = \"drop\") |&gt;\n  arrange(desc(N), desc(Score_Mean))\n\n# A tibble: 9 × 5\n  Pref     ScoreN_Sum ScoreN_Mean Score_Mean     N\n  &lt;chr&gt;         &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;\n1 大阪府          516       0.516       3.77  1000\n2 千葉県          259       0.259       3.72  1000\n3 東京都         1165       1.16        3.67  1000\n4 埼玉県          278       0.278       3.64  1000\n5 神奈川県        587       0.587       3.53  1000\n6 兵庫県          230       0.389       3.54   591\n7 京都府          216       0.522       3.68   414\n8 奈良県           45       0.306       3.85   147\n9 和歌山県         83       0.593       3.97   140\n\n\n記述統計をグループごとに求めるのは普通にあり得るケースですし、実験データの場合はほぼ必須の作業でう。統制群と処置群間においてグループサイズが均一か、共変量のバラツキが十分に小さいかなどを判断する際にgroup_by()とsummarise()関数の組み合わせは非常に便利です。\n\n\n14.2.2 複数の変数を用いたグループ化\nグループ化変数は2つ以上指定することも可能です。たとえば、都府県 (Pref)と最寄りの駅の路線 (Line)でグループ化することも可能です。それではPrefとLineでグループ化し、店舗数と口コミ数、評価の平均値を計算し、ソートの順番は店舗数、店舗数が同じなら評価の平均値が高い順にしましょう。今回もsummarise()内に.group = \"drop\"を指定し、グループ化を解除します。今回はTop 20まで出してみましょう。\n\n# ScoreNとScoreの平均値をPrefごとに求める\ndf |&gt;\n  filter(!is.na(Line)) |&gt; # Lineが欠損していないケースのみ残す\n  group_by(Pref, Line) |&gt; # PrefとLineでグループ化\n  summarise(N           = n(),\n            ScoreN_Sum  = sum(ScoreN,  na.rm = TRUE),\n            Score_Mean  = mean(Score,  na.rm = TRUE),\n            .groups     = \"drop\") |&gt;\n  arrange(desc(N), desc(Score_Mean)) |&gt;\n  print(n = 20)\n\n# A tibble: 523 × 5\n   Pref     Line                        N ScoreN_Sum Score_Mean\n   &lt;chr&gt;    &lt;chr&gt;                   &lt;int&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n 1 埼玉県   東武東上線                122         27       3.68\n 2 東京都   ＪＲ                      104        231       3.56\n 3 神奈川県 小田急小田原線             96         31       3.59\n 4 埼玉県   東武伊勢崎線               96         18       3.51\n 5 神奈川県 横浜市営ブルーライン       82         77       3.66\n 6 千葉県   京成本線                   82         29       3.34\n 7 神奈川県 京急本線                   68         40       3.33\n 8 千葉県   東武野田線                 63          2       4.75\n 9 神奈川県 小田急江ノ島線             62          8       3.79\n10 大阪府   阪急京都本線               53         32       3.67\n11 大阪府   南海本線                   52         11       4.22\n12 兵庫県   阪神本線                   52         23       3.80\n13 埼玉県   JR高崎線                   51          5       4   \n14 兵庫県   山陽電鉄本線               51         15       2.98\n15 千葉県   JR総武本線（東京-銚子）    47          8       4   \n16 埼玉県   西武新宿線                 45          8       4.17\n17 埼玉県   秩父鉄道線                 43         10       3.82\n18 大阪府   京阪本線                   43         10       3.69\n19 千葉県   新京成電鉄                 43          6       3.6 \n20 京都府   阪急京都本線               43         27       3.5 \n# ℹ 503 more rows\n\n\nぐるなびに登録されているラーメン屋が最も多い路線は埼玉県内の東武東上線で122店舗があります。東武東上線は東京都と埼玉県をまたがる路線ですので、東武東上線だけならもっと多いかも知れませんね。\nここで一つ考えたいのはsummarise()内の.groups引数です。前回はグループ化に使った変数ごとに1行しか残っていなかったのでグループ化を全て解除しました。しかし、今回は状況がやや異なります。グループ化変数に使ったPrefを考えると、まだPref == \"東京都\"であるケースがいくつかあります。やろうとすればまだグループ化出来る状態です。これはLineについても同じです。Line == \"東武東上線\"の行はここには表示されていないものの、まだデータに残っています。もし、これ以上グループ化しないなら今のように.groups = \"drop\"が正しいですが、もしもう一回グループ化したい場合はどうすればよいでしょうか。方法は2つ考えられます。\n\nもう一度パイプ演算子を使ってgroup_by()関数を使う (以下の9行目)。\n\n結果を見ると## # Groups:   Pref, Line [523]で、ちゃんとグループ化されていることが分かります。\n\n\n\ndf |&gt;\n  filter(!is.na(Line)) |&gt; \n  group_by(Pref, Line) |&gt; \n  summarise(N           = n(),\n            ScoreN_Sum  = sum(ScoreN,  na.rm = TRUE),\n            Score_Mean  = mean(Score,  na.rm = TRUE),\n            .groups     = \"drop\") |&gt;\n  arrange(desc(N), desc(Score_Mean)) |&gt;\n  group_by(Pref, Line) |&gt; # group_by()、もう一度\n  print(n = 5)\n\n# A tibble: 523 × 5\n# Groups:   Pref, Line [523]\n  Pref     Line                     N ScoreN_Sum Score_Mean\n  &lt;chr&gt;    &lt;chr&gt;                &lt;int&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 埼玉県   東武東上線             122         27       3.68\n2 東京都   ＪＲ                   104        231       3.56\n3 神奈川県 小田急小田原線          96         31       3.59\n4 埼玉県   東武伊勢崎線            96         18       3.51\n5 神奈川県 横浜市営ブルーライン    82         77       3.66\n# ℹ 518 more rows\n\n\n\n.groups引数を何とかする。\n\n推奨される方法は2番です。具体的には.groups = \"keep\"を指定するだけであり、こっちの方が無駄なコードを省けることができます。\n\ndf |&gt;\n  filter(!is.na(Line)) |&gt; \n  group_by(Pref, Line) |&gt; \n  summarise(N           = n(),\n            ScoreN_Sum  = sum(ScoreN,  na.rm = TRUE),\n            Score_Mean  = mean(Score,  na.rm = TRUE),\n            .groups     = \"keep\") |&gt;\n  arrange(desc(N), desc(Score_Mean)) |&gt;\n  print(n = 5)\n\n# A tibble: 523 × 5\n# Groups:   Pref, Line [523]\n  Pref     Line                     N ScoreN_Sum Score_Mean\n  &lt;chr&gt;    &lt;chr&gt;                &lt;int&gt;      &lt;dbl&gt;      &lt;dbl&gt;\n1 埼玉県   東武東上線             122         27       3.68\n2 東京都   ＪＲ                   104        231       3.56\n3 神奈川県 小田急小田原線          96         31       3.59\n4 埼玉県   東武伊勢崎線            96         18       3.51\n5 神奈川県 横浜市営ブルーライン    82         77       3.66\n# ℹ 518 more rows\n\n\n.groups引数は\"drop\"と\"keep\"以外にも\"drop_last\"があります。実はsummarise()に.groups引数を指定したい場合のデフォルト値は.groups == \"drop_last\"または\"keep\"ですが、ここがややこしいです。主なケースにおいてデフォルト値は\"drop\"となりますとなります。.groups == \"drop_last\"これは最後のグループ化変数のみ解除する意味です。今回の例だと、2番目のグループ化変数であるLineがグループ化変数から外され、Prefのみがグループ化変数として残る仕組みです。\nそれではデフォルト値が\"keep\"になるのはいつでしょうか。それは記述統計量の結果が長さ2以上のベクトルである場合です。平均値を求めるmean()、標準偏差を求めるsd()などは、結果として長さ1のベクトルを返します。しかし、長さ2以上ののベクトルを返す関数もあります。たとえば、分位数を求めるquantile()関数があります。quantile(ベクトル名, 0.25)の場合、第一四分位点のみ返すため、結果は長さ1のベクトルです。しかし、quantile(ベクトル名, c(0.25, 0.5, 0.75))のように第一四分位点から第三四分位点を同時に計算し、長さ3のベクトルが返されるケースもありますし、第二引数を省略すると、最小値・第一四分位点・第二四分位点・第三四分位点・最大値、つまり、長さ5のベクトルが返される場合があります。\n\n# 第一四分位点のみを求める (長さ1のベクトル)\nquantile(df$Walk, 0.25, na.rm = TRUE)\n\n25% \n  2 \n\n# 引数を省略する (長さ5のベクトル)\nquantile(df$Walk, na.rm = TRUE)\n\n  0%  25%  50%  75% 100% \n   1    2    5   12  116 \n\n\n.groupsのデフォルト値が\"keep\"になるのは、このように長さ2以上のベクトルが返されるケースです。たとえば、都府県と最寄りの駅の路線でグループ化し、店舗までの徒歩距離の平均値を求めるとします。デフォルト値の変化を見るために、ここではあえて.groups引数を省略しました。\n\ndf |&gt;\n  filter(!is.na(Walk)) |&gt;\n  group_by(Pref, Line) |&gt;\n  summarise(Mean = mean(Walk))\n\n`summarise()` has grouped output by 'Pref'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 509 × 3\n# Groups:   Pref [9]\n   Pref   Line                       Mean\n   &lt;chr&gt;  &lt;chr&gt;                     &lt;dbl&gt;\n 1 京都府 JR奈良線                   3.33\n 2 京都府 JR小浜線                  16.5 \n 3 京都府 JR山陰本線（京都-米子）    8.67\n 4 京都府 JR東海道本線（米原-神戸） 16.3 \n 5 京都府 JR片町線〔学研都市線〕     9.4 \n 6 京都府 JR舞鶴線                  19   \n 7 京都府 京福北野線                 8.36\n 8 京都府 京福嵐山本線               6.5 \n 9 京都府 京福電気鉄道嵐山本線       6   \n10 京都府 京都丹後鉄道宮福線         7.44\n# ℹ 499 more rows\n\n\n最初はPrefとLineでグループ化しましたが、summarise()の後、Lineがグループ化変数から外されました。つまり、引数が\"drop_last\"になっていることです。\nそれでは、平均値に加えて、第一四分位点と第三四分位点も計算し、Quantileという名で格納してみましょう。\n\ndf |&gt;\n  filter(!is.na(Walk)) |&gt;\n  group_by(Pref, Line) |&gt;\n  summarise(Mean     = mean(Walk),\n            Quantile = quantile(Walk, c(0.25, 0.75)))\n\nWarning: Returning more (or less) than 1 row per `summarise()` group was deprecated in\ndplyr 1.1.0.\nℹ Please use `reframe()` instead.\nℹ When switching from `summarise()` to `reframe()`, remember that `reframe()`\n  always returns an ungrouped data frame and adjust accordingly.\n\n\n`summarise()` has grouped output by 'Pref', 'Line'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 1,018 × 4\n# Groups:   Pref, Line [509]\n   Pref   Line                       Mean Quantile\n   &lt;chr&gt;  &lt;chr&gt;                     &lt;dbl&gt;    &lt;dbl&gt;\n 1 京都府 JR奈良線                   3.33     2   \n 2 京都府 JR奈良線                   3.33     5   \n 3 京都府 JR小浜線                  16.5      9.75\n 4 京都府 JR小浜線                  16.5     23.2 \n 5 京都府 JR山陰本線（京都-米子）    8.67     2   \n 6 京都府 JR山陰本線（京都-米子）    8.67    15   \n 7 京都府 JR東海道本線（米原-神戸） 16.3     16   \n 8 京都府 JR東海道本線（米原-神戸） 16.3     17   \n 9 京都府 JR片町線〔学研都市線〕     9.4      2   \n10 京都府 JR片町線〔学研都市線〕     9.4      9   \n# ℹ 1,008 more rows\n\n\n同じPref、Lineのケースが2つずつ出来ています。最初に来る数値は第一四分位点、次に来るのが第三四分位点です。そして最初のグループ化変数であったPrefとLineが、summarise()後もグループ化変数として残っていることが分かります。\n.groups引数は記述統計量だけを計算する意味ではあまり意識する必要がありません。しかし、得られた記述統計量から何らかの計算をしたり、さらにもう一回記述統計量を求めたりする際、予期せぬ結果が得られる可能性があるため注意する必要があります。出来る限り.groups引数は指定するようにしましょう。"
  },
  {
    "objectID": "datahandling2.html#sec-handling2-mutate",
    "href": "datahandling2.html#sec-handling2-mutate",
    "title": "14  データハンドリング [拡張]",
    "section": "14.3 変数の計算",
    "text": "14.3 変数の計算\n\n14.3.1 mutate()関数の使い方\n続いて、データフレーム内の変数を用いて計算を行い、その結果を新しい列として格納するmutate()関数について紹介します。まず、mutate()関数の書き方からです。\n\n# mutate()関数の使い方\nデータフレーム名 |&gt;\n  mutate(新しい変数名 = 処理内容)\n\nこれは何らかの処理を行い、その結果を新しい変数としてデータフレームに追加することを意味します。新しく出来た変数は、基本的に最後の列になります。ここでは分単位であるWalkを時間単位に変換したWalk_Hour変数を作成するとします。処理内容はWalk / 60です。最後に、都府県名、店舗名、徒歩距離 (分)、徒歩距離 (時間)のみを残し、遠い順にソートします。\n\ndf |&gt;\n  filter(!is.na(Walk)) |&gt;\n  mutate(Walk_Hour = Walk / 60) |&gt;\n  select(Pref, Name, Walk, Walk_Hour) |&gt;\n  arrange(desc(Walk_Hour))\n\n# A tibble: 5,375 × 4\n   Pref     Name                               Walk Walk_Hour\n   &lt;chr&gt;    &lt;chr&gt;                             &lt;dbl&gt;     &lt;dbl&gt;\n 1 埼玉県   札幌ラーメン どさん子 小鹿野店      116     1.93 \n 2 神奈川県 札幌ラーメン どさん子 中津店         73     1.22 \n 3 千葉県   札幌ラーメン どさん子 佐原51号店     59     0.983\n 4 神奈川県 札幌ラーメン どさん子 山際店         50     0.833\n 5 千葉県   札幌ラーメン どさん子 関宿店         49     0.817\n 6 兵庫県   濃厚醤油 中華そば いせや 玉津店      43     0.717\n 7 大阪府   河童ラーメン本舗 岸和田店            38     0.633\n 8 埼玉県   ラーメン山岡家 上尾店                35     0.583\n 9 兵庫県   濃厚醤油 中華そば いせや 大蔵谷店    35     0.583\n10 大阪府   河童ラーメン本舗 松原店              31     0.517\n# ℹ 5,365 more rows\n\n\nmutate()は3行目に登場しますが、これはWalkを60に割った結果をWalk_Hourとしてデータフレームの最後の列として格納することを意味します。もし、最後の列でなく、ある変数の前、または後にしたい場合は、.beforeまたは.after引数を追加します。これはselect()関数の.beforeと.afterと同じ使い方です。たとえば、新しく出来たWalk_HourをIDとNameの間に入れたい場合は\n\n# コードの3行名を修正 (.before使用)\nmutate(Walk_Hour = Walk / 60,\n       .before   = Name)\n\n# コードの3行名を修正 (.after使用)\nmutate(Walk_Hour = Walk / 60,\n       .after    = ID)\n\nのようにコードを修正します。\nむろん、変数間同士の計算も可能です。たとえば、以下のようなdf2があり、1店舗当たりの平均口コミ数を計算し、ScoreN_Meanという変数名でScoreN_Sumの後に格納うするとします。この場合、ScoreN_Sum変数をNで割るだけです。\n\ndf2 &lt;- df |&gt;\n  group_by(Pref) |&gt;\n  summarise(Budget_Mean = mean(Budget, na.rm = TRUE),\n            ScoreN_Sum  = sum(ScoreN, na.rm = TRUE),\n            Score_Mean  = mean(Score, na.rm = TRUE),\n            N           = n(),\n            .groups     = \"drop\")\n\n\ndf2 |&gt;\n  mutate(ScoreN_Mean = ScoreN_Sum / N,\n         .after      = ScoreN_Sum)\n\n# A tibble: 9 × 6\n  Pref     Budget_Mean ScoreN_Sum ScoreN_Mean Score_Mean     N\n  &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;\n1 京都府         1399.        216       0.522       3.68   414\n2 兵庫県         1197.        230       0.389       3.54   591\n3 千葉県         1124.        259       0.259       3.72  1000\n4 和歌山県       1252          83       0.593       3.97   140\n5 埼玉県         1147.        278       0.278       3.64  1000\n6 大阪府         1203.        516       0.516       3.77  1000\n7 奈良県         1169.         45       0.306       3.85   147\n8 東京都         1283.       1165       1.16        3.67  1000\n9 神奈川県       1239.        587       0.587       3.53  1000\n\n\nこのように、データ内の変数を用いた計算結果を新しい列として追加する場合は、mutate()が便利です。これをmutate()を使わずに処理する場合、以下のようなコードになりますが、可読性が相対的に低いことが分かります。\n\ndf2$ScoreN_Mean &lt;- df2$ScoreN_Sum / df2$N\ndf2 &lt;- df2[, c(\"Pref\", \"Budget_Mean\", \"Walk_Mean\", \n               \"ScoreN_Sum\", \"ScoreN_Mean\", \"Score_Mean\", \"N\")]\n\nむろんですが、計算には+や/のような演算子だけでなく、関数を使うことも可能です。たとえば、Budgetが1000円未満なら\"Cheap\"、1000円以上なら\"Expensive\"と示す変数Budget2を作成する場合はifelse()関数が使えます。\n\ndf |&gt; \n  mutate(Budget2 = ifelse(Budget &lt; 1000, \"Cheap\", \"Expensive\")) |&gt;\n  filter(!is.na(Budget2)) |&gt; # Budget2が欠損した店舗を除外\n  group_by(Pref, Budget2) |&gt; # PrefとBudget2でグループ化\n  summarise(N = n(),          # 店舗数を表示\n            .groups = \"drop\")\n\n# A tibble: 18 × 3\n   Pref     Budget2       N\n   &lt;chr&gt;    &lt;chr&gt;     &lt;int&gt;\n 1 京都府   Cheap        22\n 2 京都府   Expensive    28\n 3 兵庫県   Cheap        39\n 4 兵庫県   Expensive    27\n 5 千葉県   Cheap        64\n 6 千葉県   Expensive    72\n 7 和歌山県 Cheap        10\n 8 和歌山県 Expensive     5\n 9 埼玉県   Cheap        37\n10 埼玉県   Expensive    45\n11 大阪府   Cheap       104\n12 大阪府   Expensive   115\n13 奈良県   Cheap        11\n14 奈良県   Expensive    10\n15 東京都   Cheap       206\n16 東京都   Expensive   236\n17 神奈川県 Cheap        66\n18 神奈川県 Expensive    54\n\n\nこれは各都府県ごとの予算1000円未満の店と以上の店の店舗数をまとめた表となります。もし、500円未満なら\"Cheap\"、500円以上~1000円未満なら\"Reasonable\"、1000円以上なら\"Expensive\"になるBudget3変数を作るにはどうすればよいでしょうか。第11章で紹介しましたifelse()を重ねることも出来ますが、ここではcase_when()関数が便利です。まずは、ifelse()を使ったコードは以下の通りです。\n\n# ifelse()を使う場合\ndf |&gt; \n  mutate(Budget3 = ifelse(Budget &lt; 500, \"Cheap\", \n                          ifelse(Budget &gt;= 500 & Budget &lt; 1000, \"Reasonable\",\n                                 \"Expensive\"))) |&gt;\n  filter(!is.na(Budget3)) |&gt;\n  group_by(Pref, Budget3) |&gt;\n  summarise(N = n(),         \n            .groups = \"drop\")\n\ncase_when()を使うと以下のような書き方になります。\n\n# case_when()を使う場合\ndf |&gt; \n  mutate(Budget3 = case_when(Budget &lt; 500                  ~ \"Cheap\",\n                             Budget &gt;= 500 & Budget &lt; 1000 ~ \"Reasonable\",\n                             Budget &gt;= 1000                ~ \"Expensive\"),\n         # 新しく出来た変数をfactor型にその場で変換することも可能\n         Budget3 = factor(Budget3, \n                          levels = c(\"Cheap\", \"Reasonable\", \"Expensive\"))) |&gt;\n  filter(!is.na(Budget3)) |&gt;\n  group_by(Pref, Budget3) |&gt;\n  summarise(N = n(),         \n            .groups = \"drop\")\n\n書く手間の観点ではcase_when()はifelse()と大きく違いはないかも知れませんが、コードが非常に読みやすくなっています。case_when()関数の書き方は以下の通りです。\n\n# case_when()の使い方\nデータフレーム名 |&gt;\n  mutate(新変数名 = case_when(条件1 ~ 条件1を満たす場合の結果値, \n                             条件2 ~ 条件2を満たす場合の結果値, \n                             条件3 ~ 条件3を満たす場合の結果値, \n                             ...))\n\n似たような機能をする関数としてrecode()関数があります3。これは変数の値を単純に置換したい場合に便利な関数です。たとえば、都府県名をローマ字に変換するケースを考えてみましょう。\n\n# recode()を使う場合\ndf2 |&gt; \n  mutate(Pref2 = recode(Pref,\n                        \"東京都\"   = \"Tokyo\",\n                        \"神奈川県\" = \"Kanagawa\",\n                        \"千葉県\"   = \"Chiba\",\n                        \"埼玉県\"   = \"Saitama\",\n                        \"大阪府\"   = \"Osaka\",\n                        \"京都府\"   = \"Kyoto\",\n                        \"兵庫県\"   = \"Hyogo\",\n                        \"奈良県\"   = \"Nara\",\n                        \"和歌山県\" = \"Wakayama\",\n                        .default  = \"NA\"))\n\n# A tibble: 9 × 6\n  Pref     Budget_Mean ScoreN_Sum Score_Mean     N Pref2   \n  &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt; &lt;chr&gt;   \n1 京都府         1399.        216       3.68   414 Kyoto   \n2 兵庫県         1197.        230       3.54   591 Hyogo   \n3 千葉県         1124.        259       3.72  1000 Chiba   \n4 和歌山県       1252          83       3.97   140 Wakayama\n5 埼玉県         1147.        278       3.64  1000 Saitama \n6 大阪府         1203.        516       3.77  1000 Osaka   \n7 奈良県         1169.         45       3.85   147 Nara    \n8 東京都         1283.       1165       3.67  1000 Tokyo   \n9 神奈川県       1239.        587       3.53  1000 Kanagawa\n\n\n使い方は非常に直感的です。\n\n# recode()の使い方\nデータフレーム名 |&gt;\n  mutate(新変数名 = recode(元の変数名,\n                            元の値1 =  新しい値1, \n                            元の値2 =  新しい値2, \n                            元の値3 =  新しい値3, \n                            ...,\n                            .default = 該当しない場合の値))\n\n最後の.default引数は、もし該当する値がない場合に返す値を意味し、長さ1のベクトルを指定します。もし、指定しない場合はNAが表示されます。また、ここには紹介しておりませんでしたが、.missing引数もあり、これは欠損値の場合に返す値を意味します。\nもう一つ注意すべきところは、今回はcharacter型変数をcharacter型へ変換したため、「\"東京都\" = \"Tokyo\"」のような書き方をしました。しかし、numeric型からcharacter型に変換する場合は数字の部分を`で囲む必要があります。たとえば、「`1` = \"Tokyo\"」といった形式です。ただし、character型からnumeric型への場合は「\"東京都\" = 1」で構いません。\nrecode()は値をまとめる際にも便利です。たとえば、EastJapanという変数を作成し、関東なら1を、それ以外なら0を付けるとします。そして、これはPref変数の後に位置づけます。\n\n# 都府県を関東か否かでまとめる\ndf2 |&gt; \n  mutate(EastJapan = recode(Pref,\n                            \"東京都\"   = 1,\n                            \"神奈川県\" = 1,\n                            \"千葉県\"   = 1,\n                            \"埼玉県\"   = 1,\n                            \"大阪府\"   = 0,\n                            \"京都府\"   = 0,\n                            \"兵庫県\"   = 0,\n                            \"奈良県\"   = 0,\n                            \"和歌山県\" = 0,\n                            .default  = 0),\n         .after = Pref)\n\n# A tibble: 9 × 6\n  Pref     EastJapan Budget_Mean ScoreN_Sum Score_Mean     N\n  &lt;chr&gt;        &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;\n1 京都府           0       1399.        216       3.68   414\n2 兵庫県           0       1197.        230       3.54   591\n3 千葉県           1       1124.        259       3.72  1000\n4 和歌山県         0       1252          83       3.97   140\n5 埼玉県           1       1147.        278       3.64  1000\n6 大阪府           0       1203.        516       3.77  1000\n7 奈良県           0       1169.         45       3.85   147\n8 東京都           1       1283.       1165       3.67  1000\n9 神奈川県         1       1239.        587       3.53  1000\n\n\nただし、関東以外は全て0になるため、以下のように省略することも可能です。\n\n# .default引数を指定する場合\ndf3 &lt;- df2 |&gt; \n  mutate(EastJapan = recode(Pref,\n                            \"東京都\"   = 1,\n                            \"神奈川県\" = 1,\n                            \"千葉県\"   = 1,\n                            \"埼玉県\"   = 1,\n                            .default  = 0),\n         .after = Pref)\n\ndf3\n\n# A tibble: 9 × 6\n  Pref     EastJapan Budget_Mean ScoreN_Sum Score_Mean     N\n  &lt;chr&gt;        &lt;dbl&gt;       &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;\n1 京都府           0       1399.        216       3.68   414\n2 兵庫県           0       1197.        230       3.54   591\n3 千葉県           1       1124.        259       3.72  1000\n4 和歌山県         0       1252          83       3.97   140\n5 埼玉県           1       1147.        278       3.64  1000\n6 大阪府           0       1203.        516       3.77  1000\n7 奈良県           0       1169.         45       3.85   147\n8 東京都           1       1283.       1165       3.67  1000\n9 神奈川県         1       1239.        587       3.53  1000\n\n\n新しく出来たEastJapanのデータ型はなんでしょうか。\n\nclass(df3$EastJapan)\n\n[1] \"numeric\"\n\n\nEastJapanはnumeric型ですね。もし、これをfactor型にしたい場合はどうすればよいでしょうか。それはmutate()内でEastJapanを生成した後にfactor()関数を使うだけです。\n\n# EastJapan変数をfactor型にする\ndf3 &lt;- df2 |&gt; \n  mutate(EastJapan = recode(Pref,\n                            \"東京都\"   = 1,\n                            \"神奈川県\" = 1,\n                            \"千葉県\"   = 1,\n                            \"埼玉県\"   = 1,\n                            .default  = 0),\n         EastJapan = factor(EastJapan, levels = c(0, 1)),\n         .after = Pref)\n\ndf3$EastJapan\n\n[1] 0 0 1 0 1 0 0 1 1\nLevels: 0 1\n\n\nEastJapanがfactor型になりました。実は、recodeは再コーディングと同時にfactor化をしてくれる機能があります。ただし、recode()関数でなく、recode_factor()関数を使います。\n\n# recode_factor()を使う方法\ndf3 &lt;- df2 |&gt; \n  mutate(EastJapan = recode_factor(Pref,\n                                   \"東京都\"   = 1,\n                                   \"神奈川県\" = 1,\n                                   \"千葉県\"   = 1,\n                                   \"埼玉県\"   = 1,\n                                   .default  = 0),\n         .after = Pref)\n\ndf3$EastJapan\n\n[1] 0 0 1 0 1 0 0 1 1\nLevels: 1 0\n\n\nただし、levelの順番はrecode_factor()内で定義された順番になることに注意してください。factor型のより詳細な扱いについては第15章で解説します。"
  },
  {
    "objectID": "datahandling2.html#sec-handling2-rowwise",
    "href": "datahandling2.html#sec-handling2-rowwise",
    "title": "14  データハンドリング [拡張]",
    "section": "14.4 行単位の操作",
    "text": "14.4 行単位の操作\nここでは行単位の操作について考えたいと思います。第13.3章で使ったmyDF1を見てみましょう。\n\nmyDF1 &lt;- data.frame(\n  ID  = 1:5,\n  X1  = c(2, 4, 6, 2, 7),\n  Y1  = c(3, 5, 1, 1, 0),\n  X1D = c(4, 2, 1, 6, 9),\n  X2  = c(5, 5, 6, 0, 2),\n  Y2  = c(3, 3, 2, 3, 1),\n  X2D = c(8, 9, 5, 0, 1),\n  X3  = c(3, 0, 3, 0, 2),\n  Y3  = c(1, 5, 9, 1, 3),\n  X3D = c(9, 1, 3, 3, 8)\n)\n\nmyDF1\n\n  ID X1 Y1 X1D X2 Y2 X2D X3 Y3 X3D\n1  1  2  3   4  5  3   8  3  1   9\n2  2  4  5   2  5  3   9  0  5   1\n3  3  6  1   1  6  2   5  3  9   3\n4  4  2  1   6  0  3   0  0  1   3\n5  5  7  0   9  2  1   1  2  3   8\n\n\nここでX1とX2とX3の平均値を計算し、X_Meanという名の変数にする場合、以下のような書き方が普通でしょう。\n\nmyDF1 |&gt;\n  mutate(X_Mean = mean(c(X1, X2, X3)))\n\n  ID X1 Y1 X1D X2 Y2 X2D X3 Y3 X3D   X_Mean\n1  1  2  3   4  5  3   8  3  1   9 3.133333\n2  2  4  5   2  5  3   9  0  5   1 3.133333\n3  3  6  1   1  6  2   5  3  9   3 3.133333\n4  4  2  1   6  0  3   0  0  1   3 3.133333\n5  5  7  0   9  2  1   1  2  3   8 3.133333\n\n\nあら、なんかおかしくありませんか。1行目の場合、X1とX2、X3それぞれ2、5、3であり、平均値は3.333であるはずなのに3.133になりました。これは2行目以降も同じです。なぜでしょうか。\n実はdplyrは行単位の計算が苦手です。実際、データフレームというのは既に説明したとおり、縦ベクトルを横に並べたものです。列をまたがる場合、データ型が異なる場合も多いため、そもそも使う場面も多くありません。したがって、以下のような書き方が必要でした。\n\nmyDF1 |&gt;\n  mutate(X_Mean = (X1 + X2 + X3) / 3)\n\n  ID X1 Y1 X1D X2 Y2 X2D X3 Y3 X3D    X_Mean\n1  1  2  3   4  5  3   8  3  1   9 3.3333333\n2  2  4  5   2  5  3   9  0  5   1 3.0000000\n3  3  6  1   1  6  2   5  3  9   3 5.0000000\n4  4  2  1   6  0  3   0  0  1   3 0.6666667\n5  5  7  0   9  2  1   1  2  3   8 3.6666667\n\n\n先ほどのmean(c(X1, X2, X3))は(X1列とX2列、X3列)の平均値です。X1は長さ1のベクトルではなく、その列全体を指すものです。つまり、mean(c(X1, X2, X3))はmean(c(myD1F$X1, myDF1$X2, myDF1$X3))と同じことになります。だから全て3.133という結果が得られました。ただし、後者はベクトル同士の加減乗除になるため問題ありません。実際c(1, 2, 3) + c(3, 5, 0)は同じ位置の要素同士の計算になることを既に第10.2章で説明しました。\nここでmean()関数を使う場合には全ての演算を、一行一行に分けて行う必要があります。ある一行のみに限定する場合、mean(c(X1, X2, X3))のX1などは長さ1のベクトルになるため、(X1 + X2 + X3) / 3と同じことになります。この「一行単位で処理を行う」ことを指定する関数がrowwise()関数です。これは行単位の作業を行う前に指定するだけです。\n\nmyDF1 |&gt;\n  rowwise() |&gt;\n  mutate(X_Mean = mean(c(X1, X2, X3)))\n\n# A tibble: 5 × 11\n# Rowwise: \n     ID    X1    Y1   X1D    X2    Y2   X2D    X3    Y3   X3D X_Mean\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     1     2     3     4     5     3     8     3     1     9  3.33 \n2     2     4     5     2     5     3     9     0     5     1  3    \n3     3     6     1     1     6     2     5     3     9     3  5    \n4     4     2     1     6     0     3     0     0     1     3  0.667\n5     5     7     0     9     2     1     1     2     3     8  3.67 \n\n\nこれで問題なく行単位の処理ができるようになりました。今回は変数が3つのみだったので、これで問題ありませんが、変数が多くなると:やstarts_with()、num_range()などを使って変数を選択したくなります。この場合は計算する関数内にc_across()を入れます。ここではX1列からX3D列までの平均値を求めてみましょう。\n\nmyDF1 |&gt;\n  rowwise() |&gt;\n  mutate(X_Mean = mean(X1:X3D))\n\n# A tibble: 5 × 11\n# Rowwise: \n     ID    X1    Y1   X1D    X2    Y2   X2D    X3    Y3   X3D X_Mean\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1     1     2     3     4     5     3     8     3     1     9    5.5\n2     2     4     5     2     5     3     9     0     5     1    2.5\n3     3     6     1     1     6     2     5     3     9     3    4.5\n4     4     2     1     6     0     3     0     0     1     3    2.5\n5     5     7     0     9     2     1     1     2     3     8    7.5\n\n\n実はrowwise()関数、2020年6月に公開されたdplyr 1.0.0で注目された関数ですが、昔のdplyrにもrowwise()関数はありました。ただし、purrrパッケージやtidyrパッケージのnest()関数などにより使い道がなくなりましたが、なぜか華麗に復活しました。データ分析に使うデータは基本単位は列であるため、実際にrowwise()が使われる場面は今の段階では多くないでしょう。また、簡単な作業ならX1 + X2のような演算でも対応できます。それでも、覚えておけば便利な関数であることには間違いありません。"
  },
  {
    "objectID": "datahandling2.html#sec-handling2-merge",
    "href": "datahandling2.html#sec-handling2-merge",
    "title": "14  データハンドリング [拡張]",
    "section": "14.5 データの結合",
    "text": "14.5 データの結合\n\n14.5.1 行の結合\nまずは、複数のデータフレームまたはtibbleを縦に結合する方法について解説します。イメージとしては 図 14.1 のようなものです。\n\n\n\n図 14.1: 行の結合\n\n\n行を結合する際にはdplyrパッケージのbind_rows()関数を使います。この関数の使い方は以下の通りです。\n\n# 新しいデータ名ではなく、既にあるデータ名にすると上書きとなる\n新しいデータ名 &lt;-  bind_rows(データ1, データ2, ...)\n\nそれでは早速実際に使ってみましょう。実習のために、4つのtibbleを作成します (tibbleでなくデータフレームでも問題ありません)。\n\n# tibble()の代わりにdata.frame()も可\nrbind_df1 &lt;- tibble(X1 = 1:3,\n                    X2 = c(\"A\", \"B\", \"C\"),\n                    X3 = c(T, T, F)) # TRUEとFALSEはTはFと省略可能\n\nrbind_df2 &lt;- tibble(X1 = 4:6,\n                    X2 = c(\"D\", \"E\", \"F\"),\n                    X3 = c(F, T, F))\n\nrbind_df3 &lt;- tibble(X1 = 7:9,\n                    X3 = c(T, T, T),\n                    X2 = c(\"G\", \"H\", \"I\"))\n\nrbind_df4 &lt;- tibble(X1 = 10:12,\n                    X2 = c(\"J\", \"K\", \"L\"),\n                    X5 = c(\"Song\", \"Yanai\", \"Hadley\"))\n\nrbind_df1 # rbind_df1を出力\n\n# A tibble: 3 × 3\n     X1 X2    X3   \n  &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;\n1     1 A     TRUE \n2     2 B     TRUE \n3     3 C     FALSE\n\nrbind_df2 # rbind_df2を出力\n\n# A tibble: 3 × 3\n     X1 X2    X3   \n  &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;\n1     4 D     FALSE\n2     5 E     TRUE \n3     6 F     FALSE\n\nrbind_df3 # rbind_df3を出力\n\n# A tibble: 3 × 3\n     X1 X3    X2   \n  &lt;int&gt; &lt;lgl&gt; &lt;chr&gt;\n1     7 TRUE  G    \n2     8 TRUE  H    \n3     9 TRUE  I    \n\nrbind_df4 # rbind_df4を出力\n\n# A tibble: 3 × 3\n     X1 X2    X5    \n  &lt;int&gt; &lt;chr&gt; &lt;chr&gt; \n1    10 J     Song  \n2    11 K     Yanai \n3    12 L     Hadley\n\n\nまずは、rbind_df1とrbind_df2を結合してみます。この2つのデータは同じ変数が同じ順番で並んでいますね。\n\nBinded_df1 &lt;- bind_rows(rbind_df1, rbind_df2)\nBinded_df1\n\n# A tibble: 6 × 3\n     X1 X2    X3   \n  &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;\n1     1 A     TRUE \n2     2 B     TRUE \n3     3 C     FALSE\n4     4 D     FALSE\n5     5 E     TRUE \n6     6 F     FALSE\n\n\n2つのデータが結合されたことが確認できます。それではrbind_df1とrbind_df2、rbind_df3はどうでしょうか。確かに3つのデータは同じ変数を持ちますが、rbind_df3は変数の順番がX1、X3、X2になっています。このまま結合するとエラーが出るでしょうか。とりあえず、やってみます。\n\nBinded_df2 &lt;- bind_rows(rbind_df1, rbind_df2, rbind_df3)\nBinded_df2\n\n# A tibble: 9 × 3\n     X1 X2    X3   \n  &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;\n1     1 A     TRUE \n2     2 B     TRUE \n3     3 C     FALSE\n4     4 D     FALSE\n5     5 E     TRUE \n6     6 F     FALSE\n7     7 G     TRUE \n8     8 H     TRUE \n9     9 I     TRUE \n\n\nこのように変数の順番が異なっても、先に指定したデータの変数順で問題なく結合できました。これまでの作業は{dplyr}パッケージのbind_rows()を使わずに、R内蔵関数のrbind()でも同じやり方でできます。bind_rows()の特徴は、変数名が一致しない場合、つまり今回の例だとrbind_df4が含まれる場合です。rbind_df1からrbind_df3までは順番が違ってもX1、X2、X3変数で構成されていました。一方、rbind_dr4にはX3がなく、新たにX4という変数があります。これをrbind()関数で結合するとエラーが出力されます。\n\n# rbind()を使う場合\nrbind(rbind_df1, rbind_df2, rbind_df3, rbind_df4)\n\nError in match.names(clabs, names(xi)): names do not match previous names\n\n\n一方、bind_rows()はどうでしょうか。\n\nBinded_df3 &lt;- bind_rows(rbind_df1, rbind_df2, rbind_df3, rbind_df4)\nBinded_df3\n\n# A tibble: 12 × 4\n      X1 X2    X3    X5    \n   &lt;int&gt; &lt;chr&gt; &lt;lgl&gt; &lt;chr&gt; \n 1     1 A     TRUE  &lt;NA&gt;  \n 2     2 B     TRUE  &lt;NA&gt;  \n 3     3 C     FALSE &lt;NA&gt;  \n 4     4 D     FALSE &lt;NA&gt;  \n 5     5 E     TRUE  &lt;NA&gt;  \n 6     6 F     FALSE &lt;NA&gt;  \n 7     7 G     TRUE  &lt;NA&gt;  \n 8     8 H     TRUE  &lt;NA&gt;  \n 9     9 I     TRUE  &lt;NA&gt;  \n10    10 J     NA    Song  \n11    11 K     NA    Yanai \n12    12 L     NA    Hadley\n\n\nX1からX4まで全ての列が生成され、元のデータにはなかった列に関してはNAで埋められています。\n他にもbind_rows()には.idという便利な引数があります。これは結合の際に新しい列を追加し、結合前のデータごとの固有の値を割り当ててくれます。たとえば、rbind_df1とrbind_df2を結合し、それぞれ\"Data1\"、\"Data2\"という値を割り当てるとしましょう。この場合、2つの表をlist()関数でまとめ、.idには新しく追加される列名を指定します。\n\nbind_rows(list(\"Data1\" = rbind_df1, \"Data2\" = rbind_df2),\n          .id = \"Data\")\n\n# A tibble: 6 × 4\n  Data     X1 X2    X3   \n  &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;\n1 Data1     1 A     TRUE \n2 Data1     2 B     TRUE \n3 Data1     3 C     FALSE\n4 Data2     4 D     FALSE\n5 Data2     5 E     TRUE \n6 Data2     6 F     FALSE\n\n\n予めリストを作っておいて、それをbind_rows()に渡すこともできます。\n\nrbind_list &lt;- list(\"Data1\" = rbind_df1, \"Data2\" = rbind_df2)\n\nbind_rows(rbind_list, .id = \"Data\")\n\n# A tibble: 6 × 4\n  Data     X1 X2    X3   \n  &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;lgl&gt;\n1 Data1     1 A     TRUE \n2 Data1     2 B     TRUE \n3 Data1     3 C     FALSE\n4 Data2     4 D     FALSE\n5 Data2     5 E     TRUE \n6 Data2     6 F     FALSE\n\n\nこのようにbind_rows()はrbind()よりも便利です。しかし、bind_rows()の完全勝利かというと、そうとは限りません。自分で架空した複数のデータフレーム、またはtibbleを結合する際、「このデータは全て同じ変数を持っているはず」と事前に分かっているならrbind()の方が効果的です。なぜなら、変数名が異なる場合、エラーが出力されるからです。bind_rows()を使うと、コーディングミスなどにより、列名の相違がある場合でも結合してくれてしまうので、分析の結果を歪ませる可能性があります。\n\n\n14.5.2 列の結合\n実はデータ分析においてデータの結合といえば、列の結合が一般的です。これは 図 14.2 のような操作を意味します。\n\n\n\n図 14.2: 列の結合\n\n\nまずは、本章で作成したdf2をもう一回作ってみます。\n\ndf2 &lt;- df |&gt;\n  group_by(Pref) |&gt;\n  summarise(Budget_Mean = mean(Budget, na.rm = TRUE),\n            ScoreN_Sum  = sum(ScoreN, na.rm = TRUE),\n            Score_Mean  = mean(Score, na.rm = TRUE),\n            N           = n(),\n            .groups     = \"drop\")\n\ndf2\n\n# A tibble: 9 × 5\n  Pref     Budget_Mean ScoreN_Sum Score_Mean     N\n  &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;\n1 京都府         1399.        216       3.68   414\n2 兵庫県         1197.        230       3.54   591\n3 千葉県         1124.        259       3.72  1000\n4 和歌山県       1252          83       3.97   140\n5 埼玉県         1147.        278       3.64  1000\n6 大阪府         1203.        516       3.77  1000\n7 奈良県         1169.         45       3.85   147\n8 東京都         1283.       1165       3.67  1000\n9 神奈川県       1239.        587       3.53  1000\n\n\nラーメン屋の店舗ですが、たしかにデータには埼玉、東京、大阪などは1000店舗しか入っておりません。実はもっと多いですが、ぐるなびAPIの仕様上、最大1000店舗しか情報取得が出来ないからです。ここに実際の店舗数が入っている新しいデータセット、Ramen2.csvがあります。これを読み込み、df3という名で格納しましょう。\n\ndf3 &lt;- read_csv(\"Data/Ramen2.csv\")\n\nRows: 47 Columns: 15\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): Pref\ndbl (12): RamenN, Turnout, LDP, CDP, DPFP, Komei, JIP, JCP, SDP, Reiwa, NHK,...\nnum  (2): Pop, Area\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ndf3\n\n# A tibble: 47 × 15\n   Pref      Pop   Area RamenN Turnout   LDP   CDP  DPFP Komei   JIP   JCP   SDP\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 北海道 5.38e6 83424.   1454    53.8  32.3  20.8  6.65 11.7   7.78 11.6   1.31\n 2 青森県 1.31e6  9646.    336    42.9  39.8  22.0  7.24 11.3   3.4   8.31  2.36\n 3 岩手県 1.28e6 15275.    285    56.5  35.5  17.8 12.5   8.22  4.36 10.4   3.83\n 4 宮城県 2.33e6  7282.    557    51.2  39.6  17.8  9.02 11.1   4.6   7.89  2.1 \n 5 秋田県 1.02e6 11638.    301    56.3  44.5  13.5  8.64 10.6   4.48  8.09  3.77\n 6 山形県 1.12e6  9323.    512    60.7  45.2  14.9  7.37  9.87  4.28  6.51  5.08\n 7 福島県 1.91e6 13784.    550    52.4  38.2  13.6 12.1  12.8   5.31  7.99  3.01\n 8 茨城県 2.92e6  6097.    663    45.0  39.3  15.2  7.15 15.1   6.73  7.73  1.46\n 9 栃木県 1.97e6  6408.    595    44.1  40.3  18.9  9.94 12.8   4.9   5.04  1.03\n10 群馬県 1.97e6  6362.    488    48.2  40.6  16.4  9.76 12.4   4.67  7.58  1.87\n# ℹ 37 more rows\n# ℹ 3 more variables: Reiwa &lt;dbl&gt;, NHK &lt;dbl&gt;, HRP &lt;dbl&gt;\n\n\n\n\n\n\n\n表 14.1:  Ramen2.csvの詳細 \n  \n    \n    \n      変数名\n      説明\n    \n  \n  \n    Pref\n\n都道府県名\n    Pop\n\n日本人人口 (2015年国勢調査)\n    Area\n\n面積 (2015年国勢調査)\n    RamenN\n\nぐるなびに登録されたラーメン屋の店舗数\n    Turnout\n\n2019年参院選: 投票率 (比例)\n    LDP\n\n2019年参院選: 自民党の得票率 (比例)\n    CDP\n\n2019年参院選: 立憲民主党の得票率 (比例)\n    DPFP\n\n2019年参院選: 国民民主党の得票率 (比例)\n    Komei\n\n2019年参院選: 公明党の得票率 (比例)\n    JIP\n\n2019年参院選: 日本維新の会の得票率 (比例)\n    JCP\n\n2019年参院選: 日本共産党の得票率 (比例)\n    SDP\n\n2019年参院選: 社会民主党の得票率 (比例)\n    Reiwa\n\n2019年参院選: れいわ新選組の得票率 (比例)\n    NHK\n\n2019年参院選: NHKから国民を守る党の得票率 (比例)\n    HRP\n\n2019年参院選: 幸福実現党の得票率 (比例)\n  \n  \n  \n\n\n\n\n\n本データは都道府県ごとの人口、面積、ぐるなびに登録されたラーメン屋の店舗数、2019年参議院議員通常選挙の結果が格納されています。人口と面積は2015年国勢調査、ぐるなびの情報は2020年6月時点での情報です。\ndf2にデータ上の店舗数ではなく、実際の店舗数を新しい列として追加したい場合はどうすれば良いでしょうか。簡単な方法としてはdf3から情報を取得し、それを自分で入れる方法です。\n\ndf3 |&gt;\n1  filter(Pref %in% df2$Pref) |&gt;\n2  select(Pref, RamenN)\n\n\n1\n\ndf2のPrefベクトルの要素と一致するものに絞る\n\n2\n\n都道府県名とラーメン屋の店舗数のみ抽出\n\n\n\n\n# A tibble: 9 × 2\n  Pref     RamenN\n  &lt;chr&gt;     &lt;dbl&gt;\n1 埼玉県     1106\n2 千葉県     1098\n3 東京都     3220\n4 神奈川県   1254\n5 京都府      415\n6 大阪府     1325\n7 兵庫県      591\n8 奈良県      147\n9 和歌山県    140\n\n\nそして、この情報をdf2$RamenN &lt;- c(415, 1106, 1254, ...)のように追加すればいいですね。\nしかし、このような方法は非効率的です。そもそもdf3から得られた結果の順番とdf2の順番も一致しないので、一々対照しながらベクトルを作ることになります。ここで登場する関数がdplyrの*_join()関数群です。この関数群には4つの関数が含まれており、以下のような使い方になります。\n\n# 新しいデータ名ではなく、データ1またはデータ2の名前に格納すると上書きとなる\n\n# 1. データ1を基準に結合\n新しいデータ名 &lt;-  left_join(データ1, データ2, by = \"共通変数名\")\n\n# 2. データ2を基準に結合\n新しいデータ名 &lt;- right_join(データ1, データ2, by = \"共通変数名\")\n\n# 3. データ1とデータ2両方に共通するケースのみ結合\n新しいデータ名 &lt;- inner_join(データ1, データ2, by = \"共通変数名\")\n\n# 4. データ1とデータ2、どれかに存在するケースを結合\n新しいデータ名 &lt;-  full_join(データ1, データ2, by = \"共通変数名\")\n\n4つの関数の違いについて説明する前に、by引数について話したいと思います。これは主にキー (key)変数と呼ばれる変数で、それぞれのデータに同じ名前の変数がある必要があります。df2とdf3だとそれがPref変数です。どの*_join()関数でも、Prefの値が同じもの同士を結合することになります。\nデータのキー変数名が異なる場合もあります。たとえば、データ1の都道府県名はPrefという列に、データ2の都道府県名はPrefectureという列になっている場合、by = \"Pref\"でなく、by = c(\"データ1のキー変数名\" = \"データ2のキー変数名\")、つまり、by = c(\"Pref\" = \"Prefecture\")と指定します。\nそれでは、df3から都道府県名とラーメン屋の店舗数だけ抽出し、df4として格納しておきます。\n\ndf4 &lt;- df3 |&gt;\n  select(Pref, RamenN)\n\ndf4\n\n# A tibble: 47 × 2\n   Pref   RamenN\n   &lt;chr&gt;   &lt;dbl&gt;\n 1 北海道   1454\n 2 青森県    336\n 3 岩手県    285\n 4 宮城県    557\n 5 秋田県    301\n 6 山形県    512\n 7 福島県    550\n 8 茨城県    663\n 9 栃木県    595\n10 群馬県    488\n# ℹ 37 more rows\n\n\nこれから共通変数名の値をキー (key)と呼びます。今回の例だとPrefがdf2とdf4のキー変数であり、その値である\"東京都\"、\"北海道\"などがキーです。\nまずは、inner_join()の仕組みについて考えます。これはdf2とdf4に共通するキーを持つケースのみ結合する関数です。df4には\"北海道\"というキーがありますが、df2にはありません。したがって、キーが\"北海道\"のケースは結合から除外されます。これをイメージにしたものが 図 14.3 です4。それぞれ3 \\(\\times\\) 2 (3行2列)のデータですが、キーが一致するケースは2つしかないため、結合後のデータは3 \\(\\times\\) 2となります。\n\n\n\n図 14.3: inner_join()の仕組み\n\n\n実際にやってみましょう。\n\ninner_join(df2, df4, by = \"Pref\")\n\n# A tibble: 9 × 6\n  Pref     Budget_Mean ScoreN_Sum Score_Mean     N RamenN\n  &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n1 京都府         1399.        216       3.68   414    415\n2 兵庫県         1197.        230       3.54   591    591\n3 千葉県         1124.        259       3.72  1000   1098\n4 和歌山県       1252          83       3.97   140    140\n5 埼玉県         1147.        278       3.64  1000   1106\n6 大阪府         1203.        516       3.77  1000   1325\n7 奈良県         1169.         45       3.85   147    147\n8 東京都         1283.       1165       3.67  1000   3220\n9 神奈川県       1239.        587       3.53  1000   1254\n\n\n共通するキーは9つのみであり、結果として返されたデータの大きさも9 \\(\\times\\) 6です。df2に足されたdf4は2列のデータですが、キー変数であるPrefは共通するため、1列のみ足されました。キー変数を両方残す場合はkeep = TRUE引数を追加してください。\n一方、full_join()は、すべてのキーに対して結合を行います ( 図 14.4 )。たとえば、df2には\"北海道\"というキーがありません。それでも新しく出来上がるデータには北海道の列が追加されます。ただし、道内店舗の平均予算、口コミ数などの情報はないため、欠損値が代入されます。\n\n\n\n図 14.4: full_join()の仕組み\n\n\nそれでは実際、結果を確認してみましょう。今回は結合後、RamenNが大きい順で出力します。\n\nfull_join(df2, df4, by = \"Pref\") |&gt;\n  arrange(desc(RamenN)) # ぐるなびに登録された店舗の多い都道府県から出力\n\n# A tibble: 47 × 6\n   Pref     Budget_Mean ScoreN_Sum Score_Mean     N RamenN\n   &lt;chr&gt;          &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt; &lt;int&gt;  &lt;dbl&gt;\n 1 東京都         1283.       1165       3.67  1000   3220\n 2 北海道           NA          NA      NA       NA   1454\n 3 大阪府         1203.        516       3.77  1000   1325\n 4 愛知県           NA          NA      NA       NA   1255\n 5 神奈川県       1239.        587       3.53  1000   1254\n 6 埼玉県         1147.        278       3.64  1000   1106\n 7 千葉県         1124.        259       3.72  1000   1098\n 8 福岡県           NA          NA      NA       NA    985\n 9 新潟県           NA          NA      NA       NA    705\n10 静岡県           NA          NA      NA       NA    679\n# ℹ 37 more rows\n\n\ndf2にはなかった北海道や愛知県などの行ができました。そして、df2にはない情報はすべて欠損値 (NA)となりました。\n続いて、left_join()ですが、これは先に指定したデータに存在するキーのみで結合を行います ( 図 14.5 )。今回はdf2が先に指定されていますが、df2のキーはdf4のキーの部分集合であるため、inner_join()と同じ結果が得られます。\n\n\n\n図 14.5: left_join()の仕組み\n\n\n一方、right_join()はleft_join()と逆の関数であり、後に指定したデータに存在するキーを基準に結合を行います ( 図 14.6 )。後に指定されたdf4のキーはdf2のキーを完全に含むので、full_join()と同じ結果が得られます。\n\n\n\n図 14.6: right_join()`の仕組み\n\n\nこれからはdf2とdf4を結合することになりますが、この2つのtibbleの大きさが異なります。df2は9つの都府県のみであるに対し、df4は47都道府県全てのデータが入っているからです。\nここまではキー変数が一つである場合についてのみ考えましたが、複数のキー変数が必要な場合もあります。たとえば、市区町村の人口・面積データと市区町村の投票率データを結合するとします。各自治体に与えられている「全国地方公共団体コード」が両データに含まれている場合は、このコードをキー変数として使えば問題ありませんが、市区町村名をキー変数として使わざる得ないケースもあるでしょう。しかし、キー変数が複数ある場合もあります。たとえば、府中市は東京都と広島県にありますし、太子町は大阪府と兵庫県にあります。この場合、市区町村名のみでケースをマッチングすると、重複されてマッチングされる恐れがあります。この場合はキー変数を増やすことで対処できます。たとえば、同じ都道府県なら同じ市区町村は存在しないでしょう5。キー変数を複数指定する方法は簡単です。たとえば、市区町村名変数がMunip、都道府県名変数がPrefならby = c(\"Munip\", \"Pref\")と指定するだけです。\n最後に、キー変数以外の変数名が重複する場合について考えましょう。これはパネルデータを結合する時によく直面する問題です。同じ回答者に2回の調査を行った場合、回答者のIDでデータを結合することになります。ただし、それぞれのデータにおいて回答者の性別に関する変数がF1という名前の場合、どうなるでしょうか。同じデータの同じ名前の変数が複数あると、非常に扱いにくくなります。実際の結果を見てみましょう。\n\nWave1_df &lt;- tibble(ID = c(1, 2, 3, 4, 5),\n                   F1 = c(1, 1, 0, 0, 1),\n                   F2 = c(18, 77, 37, 50, 41),\n                   Q1 = c(1, 5, 2, 2, 3))\n\nWave2_df &lt;- tibble(ID = c(1, 3, 4, 6, 7),\n                   F1 = c(1, 0, 0, 0, 1),\n                   F2 = c(18, 37, 50, 20, 62),\n                   Q1 = c(1, 2, 2, 5, 4))\n\nfull_join(Wave1_df, Wave2_df, by = \"ID\")\n\n# A tibble: 7 × 7\n     ID  F1.x  F2.x  Q1.x  F1.y  F2.y  Q1.y\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     1    18     1     1    18     1\n2     2     1    77     5    NA    NA    NA\n3     3     0    37     2     0    37     2\n4     4     0    50     2     0    50     2\n5     5     1    41     3    NA    NA    NA\n6     6    NA    NA    NA     0    20     5\n7     7    NA    NA    NA     1    62     4\n\n\nそれぞれの変数名の後に.xと.yが付きます。この接尾辞 (suffix)はsuffix引数を指定することで、分析側からカスタマイズ可能です。たとえば、接尾辞を_W1、_W2にしたい場合は\n\nfull_join(Wave1_df, Wave2_df, by = \"ID\", suffix = c(\"_W1\", \"_W2\"))\n\n# A tibble: 7 × 7\n     ID F1_W1 F2_W1 Q1_W1 F1_W2 F2_W2 Q1_W2\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1     1    18     1     1    18     1\n2     2     1    77     5    NA    NA    NA\n3     3     0    37     2     0    37     2\n4     4     0    50     2     0    50     2\n5     5     1    41     3    NA    NA    NA\n6     6    NA    NA    NA     0    20     5\n7     7    NA    NA    NA     1    62     4\n\n\nのように、データ1とデータ2それぞれの接尾辞を指定するだけです。\n\n\n\n\nGrolemund, Garrett, と Hadley Wickham. 2016. R for Data Science. O’Reilly."
  },
  {
    "objectID": "factor.html#名目変数を含むグラフを作成する際の注意点",
    "href": "factor.html#名目変数を含むグラフを作成する際の注意点",
    "title": "15  データハンドリング [factor型]",
    "section": "15.1 名目変数を含むグラフを作成する際の注意点",
    "text": "15.1 名目変数を含むグラフを作成する際の注意点\nここからは楽しい可視化、つまりグラフの作成について解説します。ただし、その前に、名目変数の扱いと簡潔データ構造について話したいと思います。本章では名目変数の扱いについて解説し、次章は簡潔データ構造について解説します。\n横軸、または縦軸が気温、成績、身長のような連続変数ではなく、都道府県や国、企業のような名目変数になる場合があります。たとえば、棒グラフの横軸は 図 15.1 のように、一般的に名目変数になる場合が多いです。\n\n\n\n\n\n図 15.1: 横軸が名目変数の棒グラフ\n\n\n\n\nここでは横軸の順番に注目してください。京都府、埼玉県、神奈川県、…の順番になっていますね。「この順番で大満足だよ!」という方がいるかも知れませんが、そうでない方もおおいでしょう。普通考えられるものとしては、都道府県コードの順か、縦軸が高い順 (低い順)でしょう。都道府県コードの順だと、埼玉県、千葉県、東京都、神奈川県、京都府、大阪府、兵庫県、奈良県、和歌山県の順番になります。または、縦軸 (口コミ評価の平均値)が高い順なら和歌山県、奈良県、大阪府、…の順番になります。あるいは50音順も考えられるでしょう。アメリカの場合、州を並べる際、アルファベット順で並べます。\n自分でこの順番をコントロールするには可視化の前の段階、つまりデータハンドリングの段階で順番を決めなくてはなりません。これを決めておかない場合、Rが勝手に順番を指定します。具体的にはロケール (locale)というパソコン内の空間に文字情報が含まれているわけですが、そこに保存されている文字の順番となります。たとえば、日本語ロケールには「京」が「埼」よりも先に保存されているわけです。\nしたがって、名目変数がグラフに含まれる場合は、名目変数の表示順番を決める必要があり、そこで必要なのがfactor型です。名目変数がcharacter型の場合、ロケールに保存されている順でソートされますが、factor型の場合、予め指定した順番でソートされます。\nたとえば、前章で使用したデータを用いて、都道府県ごとの口コミ評価の平均値を計算し、その結果をScore_dfとして保存します。\n\n# tidyverseパッケージの読み込み\nlibrary(tidyverse)\n# データの読み込み\ndf &lt;- read_csv(\"Data/Ramen.csv\")\n\n\nScore_df &lt;- df |&gt;\n    group_by(Pref) |&gt;\n    summarise(Score   = mean(Score, na.rm = TRUE),\n              .groups = \"drop\")\n\nScore_df\n\n# A tibble: 9 × 2\n  Pref     Score\n  &lt;chr&gt;    &lt;dbl&gt;\n1 京都府    3.68\n2 兵庫県    3.54\n3 千葉県    3.72\n4 和歌山県  3.97\n5 埼玉県    3.64\n6 大阪府    3.77\n7 奈良県    3.85\n8 東京都    3.67\n9 神奈川県  3.53\n\n\nこの時点で勝手にロケール順になります。実際、表示されたScore_dfを見るとPrefの下に&lt;chr&gt;と表記されており1、Prefはcharacter型であることが分かります。これをこのまま棒グラフに出してみましょう。可視化の方法はこれから詳細に解説するので、ここでは結果だけに注目してください。\n\nScore_df |&gt;\n  ggplot() +\n  geom_bar(aes(x = Pref, y = Score), stat = \"identity\") +\n  labs(x = \"都府県\", y = \"口コミ評価の平均値 (1~5)\") +\n  theme(text = element_text(size = 12))\n\n\n\n\n図 15.2: Prefがcharacter型の場合 (1)\n\n\n\n\n横軸の順番があまり直感的ではありませんね。それでは、Score_dfをScoreが高い順にソートし、Score_df2で保存してから、もう一回試してみます。\n\nScore_df2 &lt;- Score_df |&gt;\n  arrange(desc(Score))\n\nScore_df2\n\n# A tibble: 9 × 2\n  Pref     Score\n  &lt;chr&gt;    &lt;dbl&gt;\n1 和歌山県  3.97\n2 奈良県    3.85\n3 大阪府    3.77\n4 千葉県    3.72\n5 京都府    3.68\n6 東京都    3.67\n7 埼玉県    3.64\n8 兵庫県    3.54\n9 神奈川県  3.53\n\n\nここでもPrefはcharacter型ですが、とりあえず、これで図を出してみます。\n\nScore_df2 |&gt;\n  ggplot() +\n  geom_bar(aes(x = Pref, y = Score), stat = \"identity\") +\n  labs(x = \"都府県\", y = \"口コミ評価の平均値 (1~5)\") +\n  theme(text = element_text(size = 12))\n\n\n\n\n図 15.3: Prefがcharacter型の場合 (2)\n\n\n\n\n結果は全く変わっておりません。それでは、Score_dfのPref列をfactor型に変換し、順番は口コミ評価の平均値が高い順番にしてみましょう。結果はScore_df_f1という名で保存します。\n\nScore_df_f1 &lt;- Score_df |&gt;\n  mutate(Pref = factor(Pref, levels = c(\"和歌山県\", \"奈良県\", \"大阪府\",\n                                        \"千葉県\", \"京都府\", \"東京都\",\n                                        \"埼玉県\", \"兵庫県\", \"神奈川県\")))\n\nScore_df_f1\n\n# A tibble: 9 × 2\n  Pref     Score\n  &lt;fct&gt;    &lt;dbl&gt;\n1 京都府    3.68\n2 兵庫県    3.54\n3 千葉県    3.72\n4 和歌山県  3.97\n5 埼玉県    3.64\n6 大阪府    3.77\n7 奈良県    3.85\n8 東京都    3.67\n9 神奈川県  3.53\n\n\n表示される順番はScore_dfとScore_df_f1も同じですが、Prefのデータ型が&lt;fct&gt;、つまりfactor型であることが分かります。実際、Pref列だけ抽出した場合、factor型として、和歌山県から神奈川県の順になっていることが確認できます。\n\nScore_df_f1$Pref\n\n[1] 京都府   兵庫県   千葉県   和歌山県 埼玉県   大阪府   奈良県   東京都  \n[9] 神奈川県\n9 Levels: 和歌山県 奈良県 大阪府 千葉県 京都府 東京都 埼玉県 ... 神奈川県\n\n\nこのScore_df_f1データを使って、 図 15.2 と全く同じコードを実行した結果が 図 15.4 です。\n\nScore_df_f1 |&gt;\n  ggplot() +\n  geom_bar(aes(x = Pref, y = Score), stat = \"identity\") +\n  labs(x = \"都府県\", y = \"口コミ評価の平均値 (1~5)\") +\n  theme(text = element_text(size = 12))\n\n\n\n\n図 15.4: Prefがcharacter型の場合 (3)\n\n\n\n\nこれまでの話をまとめるの以下の2点が分かります。\n\n変数がcharacter型である場合、自動的にロケール順でソートされる。\n変数がfactor型である場合、データ内の順番やロケール順と関係なく、指定されたレベル (水準)の順でソートされる。\n\nとくに2番目の点についてですが、これは必ずしも順序付きfactorである必要はありません。順序付きfactor型でなくても、factor()内で指定した順にソートされます。むろん、順序付きfactor型なら指定された順序でソートされます。\nこれからはfactor型変換の際に便利な関数をいくつか紹介しますが、その前に数値として表現された名目変数について話します。たとえば、Score_df_f1に関東地域なら1を、その他の地域なら0を付けたKantoという変数があるとします。\n\nScore_df_f1 &lt;- Score_df_f1 |&gt;\n  mutate(Kanto = ifelse(Pref %in% c(\"東京都\", \"神奈川県\", \"千葉県\", \"埼玉県\"), 1, 0))\n\nScore_df_f1\n\n# A tibble: 9 × 3\n  Pref     Score Kanto\n  &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt;\n1 京都府    3.68     0\n2 兵庫県    3.54     0\n3 千葉県    3.72     1\n4 和歌山県  3.97     0\n5 埼玉県    3.64     1\n6 大阪府    3.77     0\n7 奈良県    3.85     0\n8 東京都    3.67     1\n9 神奈川県  3.53     1\n\n\nKanto変数のデータ型は、&lt;dbl&gt;、つまりnumeric型です。しかし、これは明らかに名目変数ですね。これをこのままKantoを横軸にした図を出すと 図 15.5 のようになります。\n\n\n\n\n\n図 15.5: Kantoがnumeric型の場合\n\n\n\n\nこの場合、図の横軸はKantoの値が小さい順でソートされます。ただし、このような図は非常に見にくいため、1に\"関東\"、0に\"関西\"とラベルを付けたfactor型に変換した方が望ましいです。numeric型をラベル付きのfactor型にするためには、levels引数には元の数値を、labels引数にはそれぞれの数値に対応したラベルを指定します。また、関東の方を先に出したいので、factor()内のlevels引数はc(0, 1)でなく、c(1, 0)にします。\n\nScore_df_f1 &lt;- Score_df_f1 |&gt;\n  mutate(Kanto = factor(Kanto, levels = c(1, 0), labels = c(\"関東\", \"その他\")))\n\nScore_df_f1\n\n# A tibble: 9 × 3\n  Pref     Score Kanto \n  &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt; \n1 京都府    3.68 その他\n2 兵庫県    3.54 その他\n3 千葉県    3.72 関東  \n4 和歌山県  3.97 その他\n5 埼玉県    3.64 関東  \n6 大阪府    3.77 その他\n7 奈良県    3.85 その他\n8 東京都    3.67 関東  \n9 神奈川県  3.53 関東  \n\n\nKanto変数がfactor型に変換されたことが分かります。\n\nScore_df_f1$Kanto\n\n[1] その他 その他 関東   その他 関東   その他 その他 関東   関東  \nLevels: 関東 その他\n\n\nまた、\"関東\"、\"その他\"の順になっていますね。これを図として出力した結果が 図 15.6 です。\n\n\n\n\n\n図 15.6: Kantoがfactor型の場合\n\n\n\n\nこのように数値型名目変数でも、factor化することによって、自由に横軸の順番を変えることができます。それでは、factor化に使える便利な関数をいくつか紹介します。"
  },
  {
    "objectID": "factor.html#forcatsパッケージについて",
    "href": "factor.html#forcatsパッケージについて",
    "title": "15  データハンドリング [factor型]",
    "section": "15.2 forcatsパッケージについて",
    "text": "15.2 forcatsパッケージについて\n実はfactor型への変換や、順番に変更などは全てR内蔵のfactor()関数で対応可能ですが、ここではforcatsパッケージが提供しているfct_*()関数を使用します。forcatsパッケージはtidyverseを読み込む際、自動的に読み込まれるため、既にtidyverseを読み込んでいる場合、別途のコードは要りません。\n\n15.2.1 fct_relevel(): 水準の順番を変更する\nScore_df_f1のf1はScoreが高い順になっています。これを50音順に変更する際、fct_relevel()関数を使います。\n\n# 新しい変数名と元となる変数名が一致すると上書きになる\nデータフレーム名 |&gt;\n  mutate(新しい変数名 = fct_releve(元となる変数名, \n                                    \"水準1\", \"水準2\", \"水準3\", ...))\n\nここでは、Pref変数を再調整したPref2変数を作ってみましょう。\n\nScore_df_f1 &lt;- Score_df_f1 |&gt;\n  mutate(Pref2 = fct_relevel(Pref, \"大阪府\", \"神奈川県\", \"京都府\", \n                             \"埼玉県\", \"千葉県\", \"東京都\", \n                             \"奈良県\", \"兵庫県\", \"和歌山県\"))\n\nScore_df_f1\n\n# A tibble: 9 × 4\n  Pref     Score Kanto  Pref2   \n  &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;   \n1 京都府    3.68 その他 京都府  \n2 兵庫県    3.54 その他 兵庫県  \n3 千葉県    3.72 関東   千葉県  \n4 和歌山県  3.97 その他 和歌山県\n5 埼玉県    3.64 関東   埼玉県  \n6 大阪府    3.77 その他 大阪府  \n7 奈良県    3.85 その他 奈良県  \n8 東京都    3.67 関東   東京都  \n9 神奈川県  3.53 関東   神奈川県\n\n\n一見、PrefとPref2変数は同じように見えますが、水準はどうなっているでしょうか。\n\nlevels(Score_df_f1$Pref)  # Prefの水準\n\n[1] \"和歌山県\" \"奈良県\"   \"大阪府\"   \"千葉県\"   \"京都府\"   \"東京都\"   \"埼玉県\"  \n[8] \"兵庫県\"   \"神奈川県\"\n\nlevels(Score_df_f1$Pref2) # Pref2の水準\n\n[1] \"大阪府\"   \"神奈川県\" \"京都府\"   \"埼玉県\"   \"千葉県\"   \"東京都\"   \"奈良県\"  \n[8] \"兵庫県\"   \"和歌山県\"\n\n\n問題なく50音順になっていることが分かります。他にもfct_relevel()には全ての水準名を指定する必要がありません。一部の水準名も可能です。たとえば、「関東が関西の先に来るなんでけしからん！」と思う読者もいるでしょう。この場合、関西の府県名を入れると、指定した水準が最初に位置するようになります。\n\nScore_df_f1 &lt;- Score_df_f1 |&gt;\n  mutate(Pref3 = fct_relevel(Pref, \"京都府\", \"大阪府\",\n                             \"兵庫県\", \"奈良県\", \"和歌山県\"))\n\nlevels(Score_df_f1$Pref3) # Pref3の水準\n\n[1] \"京都府\"   \"大阪府\"   \"兵庫県\"   \"奈良県\"   \"和歌山県\" \"千葉県\"   \"東京都\"  \n[8] \"埼玉県\"   \"神奈川県\"\n\n\n一部の水準名のみを指定するとその水準が最初に移動されますが、after引数を指定すると、位置を調整することも可能です。after = 2の場合、元となる変数の1、3番目の水準は維持され、3番目以降に指定した水準、それに続いて指定されていない水準の順番になります。Prefは和歌山、奈良、大阪の順ですが、ここで京都と東京を、奈良と大阪の間に移動するなら、\n\nScore_df_f1 &lt;- Score_df_f1 |&gt;\n  mutate(Pref4 = fct_relevel(Pref, \"京都府\", \"東京都\", after = 2))\n\nlevels(Score_df_f1$Pref4) # Pref4の水準\n\n[1] \"和歌山県\" \"奈良県\"   \"京都府\"   \"東京都\"   \"大阪府\"   \"千葉県\"   \"埼玉県\"  \n[8] \"兵庫県\"   \"神奈川県\"\n\n\nのように書きます。afterを指定しない場合のデフォルト値は0であるため、最初に移動します。\n\n\n15.2.2 fct_recode(): 水準のラベルを変更する\nfct_recode()は水準のラベルを変更する時に使う関数で、以下のように使います。\n\n# 新しい変数名と元となる変数名が一致すると上書きになる\nデータフレーム名 |&gt;\n  mutate(新しい変数名 = fct_recode(元となる変数名, \n                                   新しいラベル1 = \"既存のラベル1\",\n                                   新しいラベル2 = \"既存のラベル2\",\n                                   新しいラベル3 = \"既存のラベル3\",\n                                   ...))\n\n注意点としては新しいラベルは\"で囲まず、既存のラベルは\"で囲む点です。それでは、Prefのラベルをローマ字に変更してみましょう。\n\nScore_df_f1 &lt;- Score_df_f1 |&gt;\n  mutate(Pref5 = fct_recode(Pref,\n                            Saitama  = \"埼玉県\",\n                            Wakayama = \"和歌山県\",\n                            Kyoto    = \"京都府\",\n                            Osaka    = \"大阪府\",\n                            Tokyo    = \"東京都\",\n                            Nara     = \"奈良県\",\n                            Kanagawa = \"神奈川県\",\n                            Hyogo    = \"兵庫県\",\n                            Chiba    = \"千葉県\"))\n\nScore_df_f1\n\n# A tibble: 9 × 7\n  Pref     Score Kanto  Pref2    Pref3    Pref4    Pref5   \n  &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;    &lt;fct&gt;    &lt;fct&gt;   \n1 京都府    3.68 その他 京都府   京都府   京都府   Kyoto   \n2 兵庫県    3.54 その他 兵庫県   兵庫県   兵庫県   Hyogo   \n3 千葉県    3.72 関東   千葉県   千葉県   千葉県   Chiba   \n4 和歌山県  3.97 その他 和歌山県 和歌山県 和歌山県 Wakayama\n5 埼玉県    3.64 関東   埼玉県   埼玉県   埼玉県   Saitama \n6 大阪府    3.77 その他 大阪府   大阪府   大阪府   Osaka   \n7 奈良県    3.85 その他 奈良県   奈良県   奈良県   Nara    \n8 東京都    3.67 関東   東京都   東京都   東京都   Tokyo   \n9 神奈川県  3.53 関東   神奈川県 神奈川県 神奈川県 Kanagawa\n\n\nfct_recode()の中に指定する水準の順番は無視されます。つまり、水準の順番はそのまま維持されるため、好きな順番で結構です。また、全ての水準を指定せず、一部のみ変更することも可能です。それではPref5の順番がPrefの順番と同じかを確認してみましょう。\n\nlevels(Score_df_f1$Pref)  # Prefの水準\n\n[1] \"和歌山県\" \"奈良県\"   \"大阪府\"   \"千葉県\"   \"京都府\"   \"東京都\"   \"埼玉県\"  \n[8] \"兵庫県\"   \"神奈川県\"\n\nlevels(Score_df_f1$Pref5) # Pref5の水準\n\n[1] \"Wakayama\" \"Nara\"     \"Osaka\"    \"Chiba\"    \"Kyoto\"    \"Tokyo\"    \"Saitama\" \n[8] \"Hyogo\"    \"Kanagawa\"\n\n\n\n\n15.2.3 fct_rev(): 水準の順番を反転させる\n水準の順番を反転することは非常によくあります。たとえば、グラフの読みやすさのために、左右または上下を反転するケースがあります。既に何回も強調しましたように、名目変数は基本的にfactor型にすべきであり、ここでfct_rev()関数が非常に便利です。たとえば、Pref2の水準は50音順でありますが、これを反転し、Pref6という名の列として追加してみましょう。\n\nScore_df_f1 &lt;- Score_df_f1 |&gt;\n  mutate(Pref6 = fct_rev(Pref2))\n\nlevels(Score_df_f1$Pref6)\n\n[1] \"和歌山県\" \"兵庫県\"   \"奈良県\"   \"東京都\"   \"千葉県\"   \"埼玉県\"   \"京都府\"  \n[8] \"神奈川県\" \"大阪府\"  \n\n\n関数一つで水準の順番が反転されました。\n\n\n15.2.4 fct_infreq(): 頻度順に順番を変更する\n続いて、水準の順番を頻度順に合わせるfct_infreq()関数です。たとえば、Scoreが欠損でないケースのみで構成されたdf2を考えてみましょう。\n\ndf2 &lt;- df |&gt;\n  filter(!is.na(Score))\n\nそして、都府県ごとのケース数を計算します。\n\ntable(df2$Pref)\n\n\n  京都府   兵庫県   千葉県 和歌山県   埼玉県   大阪府   奈良県   東京都 \n      79       85      108       24      118      175       28      298 \n神奈川県 \n     219 \n\n\nここでPrefをfactor化しますが、水準の順番を店舗数が多い方を先にするにはどうすれば良いでしょうか。fct_infreq()関数は指定された変数の各値の個数を計算し、多い順にfactorの水準を調整します。\n\ndf2 &lt;- df2 |&gt;\n  # 多く出現した値順でfactor化する\n  mutate(Pref = fct_infreq(Pref))\n\nlevels(df2$Pref) # df2のPref変数の水準を出力\n\n[1] \"東京都\"   \"神奈川県\" \"大阪府\"   \"埼玉県\"   \"千葉県\"   \"兵庫県\"   \"京都府\"  \n[8] \"奈良県\"   \"和歌山県\"\n\n\n\"東京都\"、\"神奈川県\"、\"大阪府\"、…の順で水準の順番が調整され、これはtable(df$Pref2)の順位とも一致します。\n\n\n15.2.5 fct_inorder(): データ内の出現順番に順番を変更する\n続いて、fct_inorder()ですが、これは意外と頻繁に使われる関数です。たとえば、自分でデータフレームなどを作成し、ケースの順番も綺麗に整えたとします。しかし、既に指摘した通り、データフレーム (または、tibble)での順番とグラフにおける順番は一致するとは限りません。データフレームに格納された順番でfactorの水準が設定できれば非常に便利でしょう。そこで使うのがfct_inorder()です。\nたとえば、dfのPrefは\"東京都\"が1000個並び、続いて\"神奈川県\"が1000個、\"千葉県\"が1000個、…の順番で格納されています。この順番をそのままfactorの順番にするには以下のように書きます。\n\ndf3 &lt;- df |&gt;\n  # Pref変数をfactor化し、水準は出現順とする\n  # 変換後の結果はPrefに上書きする\n  mutate(Pref = fct_inorder(Pref))\n\nlevels(df3$Pref)\n\n[1] \"東京都\"   \"神奈川県\" \"千葉県\"   \"埼玉県\"   \"大阪府\"   \"京都府\"   \"兵庫県\"  \n[8] \"奈良県\"   \"和歌山県\"\n\n\n\n\n15.2.6 fct_shift(): 水準の順番をずらす\n続いて、水準の順番をずらすfct_shift()関数を紹介します。たとえば、「1:そう思う」〜「5:そう思わない」、「9:答えたくない」の6水準で構成された変数があるとします。\n\ndf4 &lt;- tibble(\n  ID = 1:10,\n  Q1 = c(1, 5, 3, 2, 9, 2, 4, 9, 5, 1)\n) \n\ndf4 &lt;- df4 |&gt;\n  mutate(Q1 = factor(Q1, levels = c(1:5, 9),\n                     labels = c(\"そう思う\", \n                                \"どちらかと言えばそう思う\",\n                                \"どちらとも言えない\",\n                                \"どちらかと言えばそう思わない\",\n                                \"そう思わない\",\n                                \"答えたくない\")))\n\ndf4\n\n# A tibble: 10 × 2\n      ID Q1                          \n   &lt;int&gt; &lt;fct&gt;                       \n 1     1 そう思う                    \n 2     2 そう思わない                \n 3     3 どちらとも言えない          \n 4     4 どちらかと言えばそう思う    \n 5     5 答えたくない                \n 6     6 どちらかと言えばそう思う    \n 7     7 どちらかと言えばそう思わない\n 8     8 答えたくない                \n 9     9 そう思わない                \n10    10 そう思う                    \n\n\n水準の順番も「そう思う」〜「答えたくない」順で綺麗に整っています。この水準を反転するにはfct_rev()関数が便利です。Q1の水準を反転した変数をQ1_Rという新しい列として追加し、水準を確認してみましょう。\n\ndf4 &lt;- df4 |&gt;\n  mutate(Q1_R = fct_rev(Q1))\n\ndf4\n\n# A tibble: 10 × 3\n      ID Q1                           Q1_R                        \n   &lt;int&gt; &lt;fct&gt;                        &lt;fct&gt;                       \n 1     1 そう思う                     そう思う                    \n 2     2 そう思わない                 そう思わない                \n 3     3 どちらとも言えない           どちらとも言えない          \n 4     4 どちらかと言えばそう思う     どちらかと言えばそう思う    \n 5     5 答えたくない                 答えたくない                \n 6     6 どちらかと言えばそう思う     どちらかと言えばそう思う    \n 7     7 どちらかと言えばそう思わない どちらかと言えばそう思わない\n 8     8 答えたくない                 答えたくない                \n 9     9 そう思わない                 そう思わない                \n10    10 そう思う                     そう思う                    \n\nlevels(df4$Q1_R)\n\n[1] \"答えたくない\"                 \"そう思わない\"                \n[3] \"どちらかと言えばそう思わない\" \"どちらとも言えない\"          \n[5] \"どちらかと言えばそう思う\"     \"そう思う\"                    \n\n\n「答えたくない」が最初の順番に来ましてね。できれば、「そう思わない」〜「そう思う」、「答えたくない」の順番にしたいところです。ここで使うのがfct_shift()ですが、書き方がややこしいので、噛み砕いて解説します。\n\n# fct_shift()の使い方\nデータ名 |&gt;\n  mutate(新しい変数名 = fct_shift(元の変数名, n = 左方向へずらす個数))\n\n問題はn =引数ですが、その挙動については 表 15.1 を参照してください。\n\n\n\n\n\n表 15.1:  fct_shift()の仕組み \n  \n    \n    \n      \n      1番目\n      2番目\n      3番目\n      4番目\n      5番目\n      6番目\n    \n  \n  \n    n = -2\n\nE\n\nF\n\nA\n\nB\n\nC\n\nD\n\n    n = -1\n\nF\n\nA\n\nB\n\nC\n\nD\n\nE\n\n    n = 0\n\nA\n\nB\n\nC\n\nD\n\nE\n\nF\n\n    n = 1\n\nB\n\nC\n\nD\n\nE\n\nF\n\nA\n\n    n = 2\n\nC\n\nD\n\nE\n\nF\n\nA\n\nB\n\n  \n  \n  \n\n\n\n\n\n具体的には水準は左方向へn個移動します。元の水準がA, B, C, …, Fの順で、n = 1の場合、AがFの後ろへ移動し、B, C, D, E, Fが前の方へ1つずつ移動します。逆に右側へ1つ移動したい場合はn = -1のように書きます。今回は最初の水準を最後に移動させたいので、n = 1と指定します。\n\ndf4 &lt;- df4 |&gt;\n  # Q1_Rの水準を左方向で1ずらす\n  mutate(Q1_R = fct_shift(Q1_R, n = 1))\n\nlevels(df4$Q1_R)\n\n[1] \"そう思わない\"                 \"どちらかと言えばそう思わない\"\n[3] \"どちらとも言えない\"           \"どちらかと言えばそう思う\"    \n[5] \"そう思う\"                     \"答えたくない\"                \n\n\nこれで水準の反転が完了しました。fct_shift()はこのように世論調査データの処理に便利ですが、他にも曜日の処理に使えます。例えば、1週間の始まりを月曜にするか日曜にするかによって、fct_shift()を使うケースがあります。\n\n\n15.2.7 fct_shuffle(): 水準の順番をランダム化する\nあまり使わない機能ですが、水準の順番をランダム化することも可能です。使い方は非常に簡単で、fct_shuffle()に元の変数名を入れるだけです。たとえば、Score_dfのPrefの順番をランダム化し、Pref2として追加します。同じことをもう2回繰り返し、それぞれPref3とPref4という名前で追加してみましょう。\n\nScore_df &lt;- Score_df |&gt;\n  mutate(Pref2 = fct_shuffle(Pref),\n         Pref3 = fct_shuffle(Pref),\n         Pref4 = fct_shuffle(Pref))\n\nScore_df\n\n# A tibble: 9 × 5\n  Pref     Score Pref2    Pref3    Pref4   \n  &lt;chr&gt;    &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;    &lt;fct&gt;   \n1 京都府    3.68 京都府   京都府   京都府  \n2 兵庫県    3.54 兵庫県   兵庫県   兵庫県  \n3 千葉県    3.72 千葉県   千葉県   千葉県  \n4 和歌山県  3.97 和歌山県 和歌山県 和歌山県\n5 埼玉県    3.64 埼玉県   埼玉県   埼玉県  \n6 大阪府    3.77 大阪府   大阪府   大阪府  \n7 奈良県    3.85 奈良県   奈良県   奈良県  \n8 東京都    3.67 東京都   東京都   東京都  \n9 神奈川県  3.53 神奈川県 神奈川県 神奈川県\n\nlevels(Score_df$Pref2)\n\n[1] \"大阪府\"   \"神奈川県\" \"奈良県\"   \"東京都\"   \"埼玉県\"   \"和歌山県\" \"千葉県\"  \n[8] \"兵庫県\"   \"京都府\"  \n\nlevels(Score_df$Pref3)\n\n[1] \"埼玉県\"   \"神奈川県\" \"京都府\"   \"東京都\"   \"千葉県\"   \"兵庫県\"   \"大阪府\"  \n[8] \"奈良県\"   \"和歌山県\"\n\nlevels(Score_df$Pref4)\n\n[1] \"大阪府\"   \"京都府\"   \"東京都\"   \"千葉県\"   \"埼玉県\"   \"神奈川県\" \"兵庫県\"  \n[8] \"奈良県\"   \"和歌山県\"\n\n\nPrefからPref4まで同じように見えますが、水準の順番が異なります (Prefはcharacter型だから水準がありません)。\n\n\n15.2.8 fct_reorder(): 別の1変数の値を基準に水準の順番を変更する\nfct_infreq()は出現頻度順に並び替える関数でしたが、それと似たような関数としてfct_reorder()があります。ただし、これは出現頻度を基準にするのではなく、ある変数の平均値が低い順、中央値が高い順などでソートされます。まずは使い方から確認します。\n\nデータ名 |&gt;\n  mutate(新しい変数名 = fct_reorder(元の変数名, 基準となる変数, \n                                   関数名, 関数の引数))\n\n必要な引数が多いですね。解説よりも実際の例を見ながら説明します。今回もPrefをfactor変数にし、Pref_Rという列で格納しますが、平均予算が安い順でfactorの水準を決めたいと思います。\n\ndf &lt;- df |&gt;\n  mutate(Pref_R = fct_reorder(Pref, Budget, mean, na.rm = TRUE))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `Pref_R = fct_reorder(Pref, Budget, mean, na.rm = TRUE)`.\nCaused by warning:\n! `fct_reorder()` removing 5141 missing values.\nℹ Use `.na_rm = TRUE` to silence this message.\nℹ Use `.na_rm = FALSE` to preserve NAs.\n\nlevels(df$Pref_R)\n\n[1] \"千葉県\"   \"埼玉県\"   \"奈良県\"   \"兵庫県\"   \"大阪府\"   \"神奈川県\" \"和歌山県\"\n[8] \"東京都\"   \"京都府\"  \n\n\nPref_Rの水準は千葉県、埼玉県、奈良県、…の順ですが、本当にそうでしょうか。group_by()とsummarise()などを使って確認してみましょう。\n\ndf |&gt; \n  group_by(Pref) |&gt;\n  summarise(Budget  = mean(Budget, na.rm = TRUE),\n            .groups = \"drop\") |&gt;\n  arrange(Budget)\n\n# A tibble: 9 × 2\n  Pref     Budget\n  &lt;chr&gt;     &lt;dbl&gt;\n1 千葉県    1124.\n2 埼玉県    1147.\n3 奈良県    1169.\n4 兵庫県    1197.\n5 大阪府    1203.\n6 神奈川県  1239.\n7 和歌山県  1252 \n8 東京都    1283.\n9 京都府    1399.\n\n\n問題なくソートされましたね。注意点としてはfct_reorder()内に関数名を書く際、()は不要という点です。関数名の次の引数としてはその関数に別途必要な引数を指定します。引数が省略可能、あるいは不要な関数を使う場合は、省略しても構いませんし、数に制限はありません。\nまた、低い順ではなく、高い順にすることも可能です。次はScoreの中央値が高い順に水準を設定したPref_R2を作ってみましょう。\n\ndf &lt;- df |&gt;\n  mutate(Pref_R2 = fct_reorder(Pref, Score, median, na.rm = TRUE, .desc = TRUE))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `Pref_R2 = fct_reorder(Pref, Score, median, na.rm = TRUE, .desc\n  = TRUE)`.\nCaused by warning:\n! `fct_reorder()` removing 5158 missing values.\nℹ Use `.na_rm = TRUE` to silence this message.\nℹ Use `.na_rm = FALSE` to preserve NAs.\n\nlevels(df$Pref_R2)\n\n[1] \"和歌山県\" \"奈良県\"   \"千葉県\"   \"大阪府\"   \"東京都\"   \"埼玉県\"   \"京都府\"  \n[8] \"兵庫県\"   \"神奈川県\"\n\n\n変わったのはmeanの代わりにmedianを使ったこと、そして.desc引数が追加された点です。fct_reorder()には.desc = FALSEがデフォルトとして指定されており、省略した場合は昇順でfactorの水準が決まります。ここで.desc = TRUEを指定すると、降順となります。実際、Scoreの中央値順になっているかを確認してみましょう。\n\ndf |&gt; \n  group_by(Pref) |&gt;\n  summarise(Score   = median(Score, na.rm = TRUE),\n            .groups = \"drop\") |&gt;\n  arrange(desc(Score))\n\n# A tibble: 9 × 2\n  Pref     Score\n  &lt;chr&gt;    &lt;dbl&gt;\n1 和歌山県  4   \n2 奈良県    3.88\n3 千葉県    3.75\n4 大阪府    3.75\n5 東京都    3.64\n6 埼玉県    3.61\n7 京都府    3.5 \n8 兵庫県    3.5 \n9 神奈川県  3.5 \n\n\n\n\n15.2.9 fct_reorder2(): 別の2変数の値を基準に水準の順番を変更する\nこの関数は別の変数を基準に水準が調整される点ではfct_reorder()と類似しています。ただし、よく誤解されるのは「変数Aの値が同じなら変数Bを基準に…」といったものではありません。たとえば、fct_reorder(x, y, mean)の場合、yの平均値 (mean())の順でxの水準を調整するという意味です。このmean()関数に必要なデータはベクトル1つです。しかし、関数によっては2つの変数が必要な場合があります。\nこれは頻繁に直面する問題ではありませんが、このfct_reorder2()関数が活躍するケースを紹介します。以下は6月27日から7月1日までの5日間、5地域におけるCOVID-19新規感染者数を表したデータです2。入力が面倒な方はここからダウンロードして読み込んでください。\n\n# 入力が面倒ならデータをダウンロードし、\n# Reorder2_df &lt;- read_csv(\"Data/COVID19.csv\")\nReorder2_df &lt;- tibble(\n  Country = rep(c(\"日本\", \"韓国\", \"中国 (本土)\", \"台湾\", \"香港\"),\n                each = 5),\n  Date    = rep(c(\"2020/06/27\", \"2020/06/28\", \"2020/06/29\",\n                  \"2020/06/30\", \"2020/07/01\"), 5),\n  NewPat  = c(100, 93, 86, 117, 130, \n               62, 42, 43,  50,  54,\n               17, 12, 19,   3,   5,\n                0,  0,  0,   0,   0,\n                1,  2,  4,   2,  28)\n)\n\nReorder2_df &lt;- Reorder2_df |&gt;\n  mutate(Date = as.Date(Date))\n\nReorder2_df\n\n# A tibble: 25 × 3\n   Country Date       NewPat\n   &lt;chr&gt;   &lt;date&gt;      &lt;dbl&gt;\n 1 日本    2020-06-27    100\n 2 日本    2020-06-28     93\n 3 日本    2020-06-29     86\n 4 日本    2020-06-30    117\n 5 日本    2020-07-01    130\n 6 韓国    2020-06-27     62\n 7 韓国    2020-06-28     42\n 8 韓国    2020-06-29     43\n 9 韓国    2020-06-30     50\n10 韓国    2020-07-01     54\n# ℹ 15 more rows\n\n\n可視化のコードはとりあえず無視し、グラフを出力してみましょう。\n\nReorder2_df |&gt;\n  ggplot() +\n  geom_line(aes(x = Date, y = NewPat, color = Country),\n            size = 1) +\n  scale_x_date(date_labels = \"%Y年%m月%d日\") +\n  labs(x = \"年月日\", y = \"新規感染者数 (人)\", color = \"\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nこのグラフに違和感はあまりありませんが、「読みやすさ」の麺では改善の余地があります。たとえば、7月1日の時点で、新規感染者数が多いのは日本、韓国、香港、中国 (本土)、台湾の順です。しかし、右側の凡例の順番はそうではありません。この順番が一致すれば、更に図は読みやすくなるでしょう。\n\nfactor(Reorder2_df$Country)\n\n [1] 日本        日本        日本        日本        日本        韓国       \n [7] 韓国        韓国        韓国        韓国        中国 (本土) 中国 (本土)\n[13] 中国 (本土) 中国 (本土) 中国 (本土) 台湾        台湾        台湾       \n[19] 台湾        台湾        香港        香港        香港        香港       \n[25] 香港       \nLevels: 中国 (本土) 台湾 日本 韓国 香港\n\n\n実際、何も指定せずにReorder2_dfのCountryをfactor化すると、韓国、香港、台湾、…の順であり、これは上のグラフと一致します。これをグラフにおける7月1日の新規感染者数の順で並べるためには、Dateを昇順にソートし、そして最後の要素 (\"2020/07/01\")内で新規感染者数 (NewPat)を降順に並べ替えた場合の順番にする必要があります。実際、Reorder2_dfをDateで昇順、NewPatで降順にソートし、最後の5行を抽出した結果が以下のコードです。\n\nReorder2_df |&gt;\n  arrange(Date, desc(NewPat)) |&gt;\n  slice_tail(n = 5)\n\n# A tibble: 5 × 3\n  Country     Date       NewPat\n  &lt;chr&gt;       &lt;date&gt;      &lt;dbl&gt;\n1 日本        2020-07-01    130\n2 韓国        2020-07-01     54\n3 香港        2020-07-01     28\n4 中国 (本土) 2020-07-01      5\n5 台湾        2020-07-01      0\n\n\nこのように、水準を調整する際に2つの変数 (DateとNewPat)が使用されます。fct_reorder2()はfct_reorder()と買い方がほぼ同じですが、基準となる変数がもう一つ加わります。\n\nデータ名 |&gt;\n  mutate(新しい変数名 = fct_reorder2(元の変数名, \n                                    基準となる変数1, 基準となる変数2,\n                                    関数名, 関数の引数))\n\n重要なのはここの関数のところですが、fct_reorder2()はデフォルトでlast2()という関数が指定されており、まさに私たちに必要な関数です。したがって、ここでは関数名も省略できますが、ここでは一応明記しておきます。\n\nReorder2_df &lt;- Reorder2_df |&gt;\n  mutate(Country2 = fct_reorder2(Country, Date, NewPat, last2)) \n\nそれでは新しく出来たCountry2の水準を確認してみましょう。\n\nlevels(Reorder2_df$Country2)\n\n[1] \"日本\"        \"韓国\"        \"香港\"        \"中国 (本土)\" \"台湾\"       \n\n\nちゃんと7月1日の新規感染者数基準で水準の順番が調整されましたので、これを使ってグラフをもう一回作ってみます。\n\nReorder2_df |&gt;\n  ggplot() +\n  geom_line(aes(x = Date, y = NewPat, color = Country2),\n            size = 1) +\n  scale_x_date(date_labels = \"%Y年%m月%d日\") +\n  labs(x = \"年月日\", y = \"新規感染者数 (人)\", color = \"\")\n\n\n\n\n\n\n\n\nこれで図がさらに読みやすくなりました。ちなみに、forcatsパッケージはlast2()以外にもfirst2()という関数も提供しております。これを使うと、7月1日でなく、6月27日の新規感染者数の降順で水準の順番が調整されます。他にも引数を2つ使用する自作関数も使えますが、fct_reorder2()の主な使いみちはlast2()で十分でしょう。\n\n\n15.2.10 fct_collapse(): 水準を統合する\n水準数をより水準数に減らすためには、fct_recode()を使います。先ほど、fct_shift()で使ったdf4の例を考えてみましょう。df4のQ1の水準数は6つです。\n\nlevels(df4$Q1)\n\n[1] \"そう思う\"                     \"どちらかと言えばそう思う\"    \n[3] \"どちらとも言えない\"           \"どちらかと言えばそう思わない\"\n[5] \"そう思わない\"                 \"答えたくない\"                \n\n\nこれを4つに減らして見ましょう。具体的には「そう思う」と「どちらかと言えばそう思う」を「そう思う」に、「そう思わない」と「どちらかと言えばそう思わない」を「そう思わない」に統合します。これをfct_recode()で処理したのが以下のコードです。\n\n# fct_recode()を使った例\ndf4 &lt;- df4 |&gt; \n    mutate(Q1_R2 = fct_recode(Q1,\n                              そう思う          = \"そう思う\",\n                              そう思う          = \"どちらかと言えばそう思う\",\n                              どちらとも言えない  = \"どちらとも言えない\",\n                              そう思わない       = \"どちらかと言えばそう思わない\",\n                              そう思わない       = \"そう思わない\",\n                              答えたくない       = \"答えたくない\"))\n\ndf4\n\n# A tibble: 10 × 4\n      ID Q1                           Q1_R                         Q1_R2        \n   &lt;int&gt; &lt;fct&gt;                        &lt;fct&gt;                        &lt;fct&gt;        \n 1     1 そう思う                     そう思う                     そう思う     \n 2     2 そう思わない                 そう思わない                 そう思わない \n 3     3 どちらとも言えない           どちらとも言えない           どちらとも言…\n 4     4 どちらかと言えばそう思う     どちらかと言えばそう思う     そう思う     \n 5     5 答えたくない                 答えたくない                 答えたくない \n 6     6 どちらかと言えばそう思う     どちらかと言えばそう思う     そう思う     \n 7     7 どちらかと言えばそう思わない どちらかと言えばそう思わない そう思わない \n 8     8 答えたくない                 答えたくない                 答えたくない \n 9     9 そう思わない                 そう思わない                 そう思わない \n10    10 そう思う                     そう思う                     そう思う     \n\nlevels(df4$Q1_R2)\n\n[1] \"そう思う\"           \"どちらとも言えない\" \"そう思わない\"      \n[4] \"答えたくない\"      \n\n\nしかし、水準を統合するに特化したfct_collapse()を使えばより便利です。使い方は、fct_recode()に非常に似ているため省略しますが、=の右側をc()でまとめることが出来ます。\n\n# fct_collapse()を使った例\ndf4 &lt;- df4 |&gt; \n    mutate(Q1_R3 = fct_collapse(Q1,\n                                そう思う = c(\"そう思う\", \"どちらかと言えばそう思う\"),\n                                どちらとも言えない = \"どちらとも言えない\",\n                                そう思わない = c( \"どちらかと言えばそう思わない\", \"そう思わない\"),\n                                答えたくない = \"答えたくない\"))\n\ndf4\n\n# A tibble: 10 × 5\n      ID Q1                           Q1_R                         Q1_R2   Q1_R3\n   &lt;int&gt; &lt;fct&gt;                        &lt;fct&gt;                        &lt;fct&gt;   &lt;fct&gt;\n 1     1 そう思う                     そう思う                     そう思… そう…\n 2     2 そう思わない                 そう思わない                 そう思… そう…\n 3     3 どちらとも言えない           どちらとも言えない           どちら… どち…\n 4     4 どちらかと言えばそう思う     どちらかと言えばそう思う     そう思… そう…\n 5     5 答えたくない                 答えたくない                 答えた… 答え…\n 6     6 どちらかと言えばそう思う     どちらかと言えばそう思う     そう思… そう…\n 7     7 どちらかと言えばそう思わない どちらかと言えばそう思わない そう思… そう…\n 8     8 答えたくない                 答えたくない                 答えた… 答え…\n 9     9 そう思わない                 そう思わない                 そう思… そう…\n10    10 そう思う                     そう思う                     そう思… そう…\n\nlevels(df4$Q1_R3)\n\n[1] \"そう思う\"           \"どちらとも言えない\" \"そう思わない\"      \n[4] \"答えたくない\"      \n\n\nfct_recode()の結果と同じ結果が得られました。元の水準数や、減らされる水準数などによっては書く手間があまり変わらないので、好きな方を使っても良いでしょう。\n\n\n15.2.11 fct_drop(): 使われていない水準を除去する\n水準としては存在するものの、データとしては存在しないケースもあります。これをここでは「空水準 (empty levels)」と呼びます。たとえば、以下のコードはPrefをfactor化してからPref == \"奈良県\"のケースを落としたものです。\n\nScore_df_f2 &lt;- df |&gt;\n  mutate(Pref = fct_inorder(Pref)) |&gt;\n  filter(Pref != \"奈良県\") |&gt;\n  group_by(Pref) |&gt;\n  summarise(Score   = mean(Score, na.rm = TRUE),\n            .groups = \"drop\")\n\nScore_df_f2\n\n# A tibble: 8 × 2\n  Pref     Score\n  &lt;fct&gt;    &lt;dbl&gt;\n1 東京都    3.67\n2 神奈川県  3.53\n3 千葉県    3.72\n4 埼玉県    3.64\n5 大阪府    3.77\n6 京都府    3.68\n7 兵庫県    3.54\n8 和歌山県  3.97\n\n\nこのように結果としては、奈良県のデータを除外したため空水準である奈良県は表示されませんが、Pref変数はどうでしょうか。\n\nlevels(Score_df_f2$Pref)\n\n[1] \"東京都\"   \"神奈川県\" \"千葉県\"   \"埼玉県\"   \"大阪府\"   \"京都府\"   \"兵庫県\"  \n[8] \"奈良県\"   \"和歌山県\"\n\n\nこのように水準としては残っていることが分かります。使われていない水準が分析や可視化に影響を与えないケースもありますが、与えるケースもあります。これもこれまで勉強してきたfct_*()関数群で対応可能ですが、fct_drop()関数を使えば一発で終わります。実際にやってみましょう。\n\nScore_df_f2 &lt;- Score_df_f2 |&gt;\n  mutate(Pref = fct_drop(Pref))\n\n\nlevels(Score_df_f2$Pref)\n\n[1] \"東京都\"   \"神奈川県\" \"千葉県\"   \"埼玉県\"   \"大阪府\"   \"京都府\"   \"兵庫県\"  \n[8] \"和歌山県\"\n\n\n水準から奈良県が消えました。同じ機能をする関数としてはR内蔵関数であるdroplevels()関数があり、使い方はfct_drop()と同じです。\n\n\n15.2.12 fct_expand(): 水準を追加する\n一方、空水準を追加することも可能です。fct_expand()関数には元の変数名に加え、追加する水準名を入れるだけです。たとえば、dfのPrefの水準は関東と関西の9都府県名となっていますが、ここに\"滋賀県\"という水準を追加してみます。。\n\ndf5 &lt;- df |&gt;\n  mutate(Pref = fct_expand(Pref, \"滋賀県\"))\n\nlevels(df5$Pref)\n\n [1] \"京都府\"   \"兵庫県\"   \"千葉県\"   \"和歌山県\" \"埼玉県\"   \"大阪府\"  \n [7] \"奈良県\"   \"東京都\"   \"神奈川県\" \"滋賀県\"  \n\n\n\"滋賀県\"という新しい水準が出来ましたね。ただし、新しく追加された水準は最後の順番になりますので、修正が必要な場合はfct_relevel()などを使って適宜修正してください。\n新しく水準が追加されることによって、何かの変化はあるでしょうか。まずは都府県ごとにScoreの平均値とケース数を計算してみましょう。\n\ndf5 |&gt;\n  group_by(Pref) |&gt;\n  summarise(Score   = mean(Score, na.rm = TRUE),\n            N       = n(),\n            .groups = \"drop\")\n\n# A tibble: 9 × 3\n  Pref     Score     N\n  &lt;fct&gt;    &lt;dbl&gt; &lt;int&gt;\n1 京都府    3.68   414\n2 兵庫県    3.54   591\n3 千葉県    3.72  1000\n4 和歌山県  3.97   140\n5 埼玉県    3.64  1000\n6 大阪府    3.77  1000\n7 奈良県    3.85   147\n8 東京都    3.67  1000\n9 神奈川県  3.53  1000\n\n\n見た目は全く変わらず、滋賀県の行が新しく出来たわけでもありません。dplyrのgroup_by()の場合、空水準はグループ化の対象になりません。一方、多くのR内蔵関数はケースとして存在しなくても計算の対象となります。たとえば、ベクトル内のある値が何個格納されているか確認するtable()関数の例を見てみましょう。\n\ntable(df5$Pref)\n\n\n  京都府   兵庫県   千葉県 和歌山県   埼玉県   大阪府   奈良県   東京都 \n     414      591     1000      140     1000     1000      147     1000 \n神奈川県   滋賀県 \n    1000        0 \n\n\n\"滋賀県\"という列があり、合致するケースが0と表示されます。group_by()でも空の水準まで含めて出力する引数.dropがあります。デフォルトはTRUEですが、これをFALSEに指定してみます。\n\ndf5 |&gt;\n  group_by(Pref, .drop = FALSE) |&gt;\n  summarise(Score   = mean(Score, na.rm = TRUE),\n            N       = n(),\n            .groups = \"drop\")\n\n# A tibble: 10 × 3\n   Pref      Score     N\n   &lt;fct&gt;     &lt;dbl&gt; &lt;int&gt;\n 1 京都府     3.68   414\n 2 兵庫県     3.54   591\n 3 千葉県     3.72  1000\n 4 和歌山県   3.97   140\n 5 埼玉県     3.64  1000\n 6 大阪府     3.77  1000\n 7 奈良県     3.85   147\n 8 東京都     3.67  1000\n 9 神奈川県   3.53  1000\n10 滋賀県   NaN        0\n\n\n空水準も出力され、Scoreの平均値は計算不可 (NaN)、ケース数は0という結果が得られました。\n\n\n15.2.13 fct_explicit_na(): 欠損値に水準を与える\nまずは、実習用データdf6を作ってみまます。X1はnumeric型変数ですが、これをfactor化します。最初からtibble()内でfactor化しておいても問題ありませんが、練習だと思ってください。\n\ndf6 &lt;- tibble(\n  ID = 1:10,\n  X1 = c(1, 3, 2, NA, 2, 2, 1, NA, 3, NA)\n)\n\ndf6 &lt;- df6 |&gt;\n  mutate(X1 = factor(X1, \n                     levels = c(1, 2, 3),\n                     labels = c(\"ラーメン\", \"うどん\", \"そば\")))\n\ndf6\n\n# A tibble: 10 × 2\n      ID X1      \n   &lt;int&gt; &lt;fct&gt;   \n 1     1 ラーメン\n 2     2 そば    \n 3     3 うどん  \n 4     4 &lt;NA&gt;    \n 5     5 うどん  \n 6     6 うどん  \n 7     7 ラーメン\n 8     8 &lt;NA&gt;    \n 9     9 そば    \n10    10 &lt;NA&gt;    \n\n\nそれではX1をグループ化変数とし、ケース数を計算してみましょう。\n\ndf6 |&gt;\n  group_by(X1) |&gt;\n  summarise(N       = n(),\n            .groups = \"drop\")\n\n# A tibble: 4 × 2\n  X1           N\n  &lt;fct&gt;    &lt;int&gt;\n1 ラーメン     2\n2 うどん       3\n3 そば         2\n4 &lt;NA&gt;         3\n\n\nNAもグループ化の対象となります。以下はこの欠損値も一つの水準として指定する方法について紹介します。欠損値を欠損値のままにするケースが多いですが、欠損値が何らかの意味を持つ場合、分析の対象になります。たとえば、多項ロジスティック回帰の応答変数として「分からない/答えたくない」を含めたり、「分からない/答えたくない」を選択する要因を分析したい場合は、欠損値に値を与える必要があります。なぜなら、一般的な分析において欠損値は分析対象から除外されるからです。\nまずは、これまで紹介した関数を使ったやり方から紹介します。\n\ndf6 |&gt;\n         # まず、X1をcharacter型に変換し、X2という列に保存\n  mutate(X2 = as.character(X1),\n         # X2がNAなら\"欠損値\"、それ以外なら元のX2の値に置換\n         X2 = ifelse(is.na(X2), \"欠損値\", X2),\n         # X2を再度factor化する\n         X2 = factor(X2, \n                     levels = c(\"ラーメン\", \"うどん\", \"そば\", \"欠損値\")))\n\n# A tibble: 10 × 3\n      ID X1       X2      \n   &lt;int&gt; &lt;fct&gt;    &lt;fct&gt;   \n 1     1 ラーメン ラーメン\n 2     2 そば     そば    \n 3     3 うどん   うどん  \n 4     4 &lt;NA&gt;     欠損値  \n 5     5 うどん   うどん  \n 6     6 うどん   うどん  \n 7     7 ラーメン ラーメン\n 8     8 &lt;NA&gt;     欠損値  \n 9     9 そば     そば    \n10    10 &lt;NA&gt;     欠損値  \n\n\nX1をcharacter型に戻す理由3は、水準にない値が入るとfactor化が解除されるからです。factor型をcharacter型に戻さずにdf6$X1のNAを\"欠損値\"に置換すると、以下のようになります。\n\n# df6のX1がNAなら\"欠損\"、それ以外なら元のX1の値を返す\nifelse(is.na(df6$X1), \"欠損値\", df6$X1)\n\n [1] \"1\"      \"3\"      \"2\"      \"欠損値\" \"2\"      \"2\"      \"1\"      \"欠損値\"\n [9] \"3\"      \"欠損値\"\n\n\n\"ラーメン\"と\"うどん\"、\"そば\"がfactor化前の1, 2, 3に戻っただけでなく、NAが\"欠損値\"というcharacter型に置換されたため、全体がcharacter型に変換されました。このように欠損値に水準を与える作業は難しくはありませんが、面倒な作業です。そこで登場する関数がfct_exlpicit_na()関数です。使い方は、元の変数に加え、欠損値の水準名を指定するna_levelです。\n\ndf6 &lt;- df6 |&gt;\n  # na_levelのデフォルト値は\"(Missing)\"\n  mutate(X2 = fct_explicit_na(X1, na_level = \"欠損値\"))\n\nWarning: There was 1 warning in `mutate()`.\nℹ In argument: `X2 = fct_explicit_na(X1, na_level = \"欠損値\")`.\nCaused by warning:\n! `fct_explicit_na()` was deprecated in forcats 1.0.0.\nℹ Please use `fct_na_value_to_level()` instead.\n\ndf6\n\n# A tibble: 10 × 3\n      ID X1       X2      \n   &lt;int&gt; &lt;fct&gt;    &lt;fct&gt;   \n 1     1 ラーメン ラーメン\n 2     2 そば     そば    \n 3     3 うどん   うどん  \n 4     4 &lt;NA&gt;     欠損値  \n 5     5 うどん   うどん  \n 6     6 うどん   うどん  \n 7     7 ラーメン ラーメン\n 8     8 &lt;NA&gt;     欠損値  \n 9     9 そば     そば    \n10    10 &lt;NA&gt;     欠損値  \n\n\n欠損値が一つの水準になったことが分かります。\n\ndf6 |&gt;\n  group_by(X2) |&gt;\n  summarise(N       = n(),\n            .groups = \"drop\")\n\n# A tibble: 4 × 2\n  X2           N\n  &lt;fct&gt;    &lt;int&gt;\n1 ラーメン     2\n2 うどん       3\n3 そば         2\n4 欠損値       3\n\n\nむろん、group_by()を使ってもちゃんと出力されます。"
  },
  {
    "objectID": "tidydata.html#sec-tidydata-intro",
    "href": "tidydata.html#sec-tidydata-intro",
    "title": "16  整然データ構造",
    "section": "16.1 整然データ (tidy data)とは",
    "text": "16.1 整然データ (tidy data)とは\n分析や作図に適したデータの形は整然データ、または簡潔データ (tidy data)と呼ばれます。整然データの概念はtidyverse世界の産みの親であるHadely Wickham先生が提唱した概念であり、詳細は Wickham (2014) を参照してください。\n整然データは目指す到達点は非常に単純です。それは「データの構造 (structure)と意味 (semantic)を一致させる」ことです。そして、この「意味」を出来る限り小さい単位で分解します。\n例えば、3人で構成されたあるクラス内の被験者に対し、投薬前後に測定した数学成績があるとします。投薬前の成績は\"Control\"、投薬後の状況を\"Treatment\"とします。これをまとめたのが 表 16.1 です。\n\n\n\n\n\n表 16.1:  Messy Dataの例 (1) \n  \n    \n    \n      Name\n      Control\n      Treatment\n    \n  \n  \n    Hadley\n90\n90\n    Song\n80\n25\n    Yanai\n100\n95\n  \n  \n  \n\n\n\n\n\nまた、以上の表は転置も可能であり、以下のように表現することが可能です ( 表 16.2 )。\n\n\n\n\n\n表 16.2:  Messy Dataの例 (2) \n  \n    \n    \n      Treat\n      Hadely\n      Song\n      Yanai\n    \n  \n  \n    Control\n90\n80\n100\n    Treatment\n90\n25\n95\n  \n  \n  \n\n\n\n\n\n2つのデータが持つ情報は全く同じです。これは「同じ意味を持つが、異なる構造を持つ」とも言えます。このような多様性が生じる理由は行と列のあり方が各値を説明するに十分ではないからです。異なるデータ構造として表現される余地があるということです。\nたとえば、 表 16.1 の場合、各列は以下のような3つの情報があります。\n\nName: 被験者名\nControl: 投薬前の数学成績\nTreatment: 投薬後の数学成績\n\nこのデータの問題は「投薬有無」と「数学成績」が2回登場したという点です。1は問題ありませんが、2と3の値は「投薬有無 \\(\\times\\) 数学成績」の組み合わせです。一つの変数に2つの情報が含まれていますね。これによって、投薬有無を行にしても列にしてもいいわけです。「ならばこっちの方が柔軟だしいいのでは?」と思う方もいるかも知れません。しかし、パソコンはこの曖昧さが嫌いです。なぜなら、人間のような思考ができないからです。データフレームは縦ベクトルの集合であるから、各列には一つの情報のみ格納する必要があります。たとえば、以下のように列を変更するとしましょう。\n\nName: 被験者名\nTreat: 投薬有無\nMath_Score: 数学成績\n\nTreatは投薬前なら\"Control\"の値を、投薬後なら\"Treatment\"の値が入ります。Math_Socreには数学成績が入ります。これに則って表に直したのが 表 16.3 です。\n\n\n\n\n\n表 16.3:  整然データの例 \n  \n    \n    \n      Name\n      Treat\n      Math_Score\n    \n  \n  \n    Hadley\nControl\n90\n    Hadley\nTreatment\n90\n    Song\nControl\n80\n    Song\nTreatment\n25\n    Yanai\nControl\n100\n    Yanai\nTreatment\n95\n  \n  \n  \n\n\n\n\n\n表が長くなりましたが、これなら一つの列に2つ以上の情報が含まれることはありません。この場合、 表 16.1 と 表 16.2 のように、行と列を転置することができるでしょうか。\n\n\n\n\n\n表 16.4:  整然データを転置した場合 \n  \n    \n    \n      Name\n      Hadley\n      Hadley\n      Song\n      Song\n      Yanai\n      Yanai\n    \n  \n  \n    Treat\nControl\nTreatment\nControl\nTreatment\nControl\nTreatment\n    Math_Score\n90\n90\n80\n25\n100\n95\n  \n  \n  \n\n\n\n\n\nその結果が 表 16.4 ですが、いかがでしょうか。まず、列名が重複している時点でアウトですし、人間が見ても非常に分かりにくい表になりました。また、一つの列に異なるデータ (この場合、character型とnumeirc型)が混在しています。パソコンから見てはわけのわからないデータになったわけです。\nここまで来たら整然データのイメージはある程度掴めたかも知れません。具体的に整然データとは次の4つの条件を満たすデータです(Wickham 2014)。\n\n1つの列は、1つの変数を表す。\n1つの行は、1つの観測を表す。\n1つのセル（特定の列の特定の行）は、1つの値を表す。\n1つの表は、1つの観測単位 (unit of observation)をもつ（異なる観測単位が混ざっていない）。\n\n以下でも、 表 16.1 と 表 16.3 を対比しながら、以上の4条件をより詳しく説明します。\n\n16.1.1 1つの列は、1つの変数を表す\n表 16.1 と 表 16.3 に含まれる情報は以下の3つで共通しています。\n\n被験者名\n投薬有無\n数学成績\n\nこれらの情報がそれぞれデータの変数になるわけですが、整然データは一つの列が一つの変数を表します。それではまず、 表 16.1 ( 図 16.1 の左)から考えてみましょう。この図には3つの情報が全て含まれています。しかし、数学成績は2列に渡って格納されており、「1列1変数」の条件を満たしておりません。一方、 表 16.1 ( 図 16.1 の右)は投薬前後を表すTreat変数を作成し、その値に応じた数学成績が格納されており、「1列1変数」の条件を満たしています。\n\n\n\n図 16.1: 1つの列は、1つの変数を表す\n\n\n「1列1変数」は整然データの最も基本となる条件であり、整然データ作成の出発点とも言えます。\n\n\n16.1.2 1つの行は、1つの観測を表す\n図 16.2 の左は一行当たり、いくつの観察が含まれているでしょうか。それを確認するためには、このデータが何を観察しているかを考える必要があります。このデータは投薬前後の数学成績を観察し、量的に測定したものです。つまり、同じ人に対して2回観察を行ったことになります。したがって、投薬前の数学成績と投薬後の数学成績は別の観察であり、 図 16.2 の左は3行の表ですが、実は6回分の観察が含まれていることになります。1行に2つの観察が載っていることですね。\n\n\n\n図 16.2: 1つの行は、1つの観測を表す\n\n\n一方、 図 16.2 の右は6行のデータであり、観察回数とデータの行数が一致しています。つまり、1行に1観察となります。\n今回は数学成績しか測っていたいので、簡単な例ですが、実際のデータには曖昧な部分があります。たとえば、投薬によって血圧が変化する可能性があるため、最高血圧もまた投薬前後に測定したとします。それが 表 16.5 の左です。\n\n\n表 16.5: 1行1観察の例\n\n\n\n\n\n(a) 雑然データ \n  \n    \n    \n      Name\n      Treat\n      Math\n      Blood\n    \n  \n  \n    Hadley\nControl\n90\n110\n    Hadley\nTreatment\n90\n115\n    Song\nControl\n80\n95\n    Song\nTreatment\n25\n110\n    Yanai\nControl\n100\n100\n    Yanai\nTreatment\n95\n95\n  \n  \n  \n\n\n\n\n\n\n(b) 整然データ \n  \n    \n    \n      Name\n      Treat\n      Type\n      Value\n    \n  \n  \n    Hadley\nControl\nMath\n90\n    Hadley\nControl\nBlood\n110\n    Hadley\nTreatment\nMath\n90\n    Hadley\nTreatment\nBlood\n115\n    Song\nControl\nMath\n80\n    Song\nControl\nBlood\n95\n    Song\nTreatment\nMath\n25\n    Song\nTreatment\nBlood\n110\n    Yanai\nControl\nMath\n100\n    Yanai\nControl\nBlood\n100\n    Yanai\nTreatment\nMath\n95\n    Yanai\nTreatment\nBlood\n95\n  \n  \n  \n\n\n\n\n\n3人に投薬前後に数学成績と最高血圧を測定した場合の観察回数は何回でしょう。3人 \\(\\times\\) 2時点 \\(\\times\\) 2指標の測定だから12回の測定でしょうか。ならば、 表 16.5 の右が整然データでしょう。しかし、この場合、1列1変数という条件が満たされなくなります。Value列には数学成績と血圧が混在しており、2つの変数になります。ならば、どれも整然データではないということでしょうか。実は整然データは 表 16.5 の左です。なぜなら、「1観察=1値」ではないからです。データにおける観察とは観察単位ごとに測定された値の集合です。観察対象とは人や自治体、企業、国などだけでなく、時間も含まれます。たとえば、人の特徴 (性別、身長、所得、政治関心など)を測定しもの、ある日の特徴 (気温、株価など)を測定したもの全てが観察です。むろん、人 \\(\\times\\) 時間のような組み合わせが観察単位ともなり得ます。この一つ一つの観察単位から得られた値の集合が観察です。 表 16.5 の分析単位は「人 \\(\\times\\) 時間」です。成績や最高血圧は分析単位が持つ特徴や性質であって、分析単位ではありません。\n\n\n16.1.3 1つのセルは、1つの値を表す\nこの条件に反するケースはあまりないかも知れません。たとえば、「Hadleyは処置前後の数学成績が同じだし、一行にまとめよう」という意味で 図 16.3 の左のような表を作る方もいるかも知れませんが、あまりいないでしょう。\n\n\n\n図 16.3: 1つのセルは、1つの値を表す\n\n\n図 16.3 の例は「1セル1値」の条件に明らかに反します。しかし、基準が曖昧な変数もあり、その一つが日付です。\n\n\n表 16.6: 日付の扱い方\n\n\n\n\n\n(a) 雑然データ? \n  \n    \n    \n      Date\n      Stock\n    \n  \n  \n    2020/06/29\n100\n    2020/06/30\n105\n    2020/07/01\n110\n    2020/07/02\n85\n    2020/07/03\n90\n  \n  \n  \n\n\n\n\n\n\n(b) 整然データ? \n  \n    \n    \n      Year\n      Month\n      Date\n      Stock\n    \n  \n  \n    2020\n6\n29\n100\n    2020\n6\n30\n105\n    2020\n7\n1\n110\n    2020\n7\n2\n85\n    2020\n7\n3\n90\n  \n  \n  \n\n\n\n\n\n表 16.6 の左側の表はどうでしょうか。5日間の株価を記録した架空のデータですが、たしかにDate列には日付が1つずつ、Stockには株価の値が1つずつ格納されています。しかし、解釈によっては「Dateに年、月、日といった3つの値が含まれているぞ」と見ることもできます。この解釈に基づく場合、 表 16.6 の右側の表が整然データとなり、左側は雑然データとなります。このケースは第一条件であった「一列一変数」とも関係します。なぜなら、Dateという列が年・月・日といった3変数で構成されているとも解釈できるからです。\n分析によっては左側のような表でも全く問題ないケースもあります。時系列分析でトレンド変数のみ必要ならこれでも十分に整然データと呼べます。しかし、季節変動などの要素も考慮するならば、左側は雑然データになります。データとしての使い勝手は右側の方が優れているのは確かです。\nデータを出来る限り細かく分解するほど情報量が豊かになりますが、それにも限度はあるでしょう。たとえば、「Yearは実は世紀の情報も含まれているのでは…?」という解釈もできますが、これを反映してデータ整形を行うか否かは分析の目的と分析モデルによって異なります。この意味で、明らかな雑然データはあり得ますが、明らかな整然データは存在しないでしょう。どちらかといえば、整然さの度合いがあり、「これなら十分に整然データと言えないだろうか」と判断できれば十分ではないかと筆者 (Song)は考えます。\n\n\n16.1.4 1つの表は、1つの観測単位をもつ\ne-statなどから国勢調査データをダウンロードした経験はあるでしょうか。以下の 図 16.4 は2015年度国勢調査データの一部です。\n\n\n\n図 16.4: 国勢調査データ\n\n\nこのデータの観察単位はなんでしょうか。データのの1行目は全国の人口を表しています。つまり、単位は国となります。しかし、2行目は北海道の人口です。この場合の観測単位は都道府県となります。つづいて、3行目は札幌市なので単位は市区町村になります。4行目は札幌市中央区、つまり観測単位が行政区になっています。そして14行目は函館市でまた単位は市区町村に戻っています。実際、会社や政府が作成するデータには 図 16.4 や 図 16.5 のようなものが多いです。とりわけ、 図 16.5 のように、最後の行に「合計」などが表記されている場合が多いです。\n\n\n\n図 16.5: 1つの表は、1つの観測単位をもつ\n\n\nこのような表・データを作成することが悪いことではありません。むしろ、「読む」ための表ならこのような書き方が一般的でしょう。しかし、「分析」のためのデータは観察の単位を統一する必要があります。"
  },
  {
    "objectID": "tidydata.html#sec-tidydata-gather",
    "href": "tidydata.html#sec-tidydata-gather",
    "title": "16  整然データ構造",
    "section": "16.2 Wide型からLong型へ",
    "text": "16.2 Wide型からLong型へ\n以下では「1列1変数」の条件を満たすデータの作成に便利なpivot_longer()とpivot_wider()関数について解説します。この関数群はおなじみの{dplyr}でなく、{tidyr}パッケージが提供している関数ですが、どれも{tidyverse}パッケージ群に含まれているため、{tidyverse}パッケージを読み込むだけで十分です。本節ではpivot_longer()を、次節ではpivot_wider()を取り上げます。\nまず、pivot_longer()ですが、この関数は比較的に新しい関数であり、これまでは{tidyr}のgather()関数が使われてきました。しかし、gahter()関数は将来、なくなる予定の関数であり、今から{tidyr}を学習する方はpivot_*()関数群に慣れておきましょう。\nまずは{tidyverse}パッケージを読み込みます。\n\npacman::p_load(tidyverse)\n\n今回は様々な形のデータを変形する作業をするので、あるデータセットを使うよりも、架空の簡単なデータを使います。\n\ndf1 &lt;- tibble(\n  Name      = c(\"Hadley\", \"Song\", \"Yanai\"),\n  Control   = c(90, 80, 100),\n  Treatment = c(90, 25, 95),\n  Gender    = c(\"Male\", \"Female\", \"Female\")\n)\n\ndf1\n\n# A tibble: 3 × 4\n  Name   Control Treatment Gender\n  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; \n1 Hadley      90        90 Male  \n2 Song        80        25 Female\n3 Yanai      100        95 Female\n\n\nこのデータは既に指摘した通り「1列1変数」の条件を満たしております。この条件を満たすデータは以下のような形となります。\n\n\n# A tibble: 6 × 4\n  Name   Gender Treat     Math_Score\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;\n1 Hadley Male   Control           90\n2 Hadley Male   Treatment         90\n3 Song   Female Control           80\n4 Song   Female Treatment         25\n5 Yanai  Female Control          100\n6 Yanai  Female Treatment         95\n\n\nTreat変数が作成され、元々は変数名であった\"Control\"と\"Treatment\"が値として格納されます。この変数をキー変数と呼びます。そして、キー変数の値に応じた数学成績がMath_Scoreという変数でまとめられました。この変数を値変数と呼びます。\n「1列1変数」を満たさなかった最初のデータは「Wide型データ」、これを満たすようなデータは「Long型データ」と呼ばれます。これは相対的に最初のデータが横に広いから名付けた名前であって、「Wide型=雑然データ」もしくは「Long型=整然データ」ではないことに注意してください。実際、 表 16.5 はどれも同じ情報を持つ表であり、右の方がLong型データです。しかし、整然データはWide型である左の方ですね。つまり、「Long型データだから1列1変数だ」ということは間違いです。同じ情報を持つデータで、相対的にどれが横長か、縦長かの相対的な問題です。\nWide型データをLong型へ変換する関数がpivot_longer()であり、基本的な使い方は以下の通りです。\n\n# pivot_longer()の使い方\nデータ名 |&gt;\n  pivot_longer(cols      = c(まとめる変数1, まとめる変数2, ...),\n               names_to  = \"キー変数名\",\n               values_to = \"値変数名\")\n\nここでは同じ変数がControlとTreatment変数で分けられているため、まとめる変数はこの2つであり、cols = c(Control, Treatment)と指定します。ControlとTreatmentは\"で囲んでも、囲まなくても同じです。また、{dplyr}のselect()関数で使える変数選択の関数 (starts_with()、where()など)や:演算子も使用可能です。また、cols引数はpivot_longer()の第2引数であるため、cols =は省略可能です（第一引数はパイプにより既に渡されています）。\nnames_toとvalues_to引数はそれぞれキー変数名と値変数名を指定する引数で、ここは必ず\"で囲んでください。このdf1をLong型へ変換し、df1_Lと名付けるコードが以下のコードです。\n\ndf1_L &lt;- df1 |&gt;\n  pivot_longer(Control:Treatment,\n               names_to  = \"Treat\",\n               values_to = \"Math_Score\")\n\ndf1_L\n\n# A tibble: 6 × 4\n  Name   Gender Treat     Math_Score\n  &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;          &lt;dbl&gt;\n1 Hadley Male   Control           90\n2 Hadley Male   Treatment         90\n3 Song   Female Control           80\n4 Song   Female Treatment         25\n5 Yanai  Female Control          100\n6 Yanai  Female Treatment         95\n\n\nこれだけでもpivot_longer()関数を使ってWide型からLong型への変換は問題なくできますが、以下ではもうちょっと踏み込んだ使い方について解説します。「ここまでで十分だよ」という方は、ここを飛ばしても構いません。\n今回の実習データdf3は3人の体重を3日間に渡って計測したものです。ただし、ドジっ子のSongは2日目にうっかり測るのを忘れており、欠損値となっています。\n\ndf2 &lt;- tibble(\n  Name = c(\"Hadley\", \"Song\", \"Yanai\"),\n  Day1 = c(75, 120, 70),\n  Day2 = c(73,  NA, 69),\n  Day3 = c(71, 140, 71)\n)\n\ndf2\n\n# A tibble: 3 × 4\n  Name    Day1  Day2  Day3\n  &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Hadley    75    73    71\n2 Song     120    NA   140\n3 Yanai     70    69    71\n\n\nまず、これをこれまでのやり方でLong型へ変形し、df2_Lと名付けます。\n\ndf2_L &lt;- df2 |&gt;\n  pivot_longer(starts_with(\"Day\"),\n               names_to  = \"Days\",\n               values_to = \"Weight\")\n\ndf2_L\n\n# A tibble: 9 × 3\n  Name   Days  Weight\n  &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt;\n1 Hadley Day1      75\n2 Hadley Day2      73\n3 Hadley Day3      71\n4 Song   Day1     120\n5 Song   Day2      NA\n6 Song   Day3     140\n7 Yanai  Day1      70\n8 Yanai  Day2      69\n9 Yanai  Day3      71\n\n\nこれでも問題ないかも知れませんが、以下のような操作を追加に行うとします。\n\nWeightが欠損している行を除去する\nDays列の値から\"Day\"を除去し、numeric型にする\n\n以上の作業を行うには、{dplyr}が便利でしょう。ちなみにstr_remove()関数が初めて登場しましたが、これについては第17章で詳細に解説します。簡単に説明しますと、str_remove(\"X123\", \"X\")は\"X123\"から\"X\"を除去し、\"123\"のみ残す関すです。残された値が数字のみであってもデータ型はcharacter型なので、もう一回、numeric型に変換する必要があります1。{dplyr}を使ったコードは以下の通りです。\n\n# 1. WeightがNAのケースを除去\n# 2. Days変数の値から\"Day\"を除去\n# 3. Days変数をnumeric型へ変換\ndf2_L |&gt;\n  filter(!is.na(Weight)) |&gt;              # 1\n  mutate(Days = str_remove(Days, \"Day\"), # 2\n         Days = as.numeric(Days))        # 3\n\n# A tibble: 8 × 3\n  Name    Days Weight\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Hadley     1     75\n2 Hadley     2     73\n3 Hadley     3     71\n4 Song       1    120\n5 Song       3    140\n6 Yanai      1     70\n7 Yanai      2     69\n8 Yanai      3     71\n\n\n実はこの作業、pivot_longer()内で行うことも可能です。たとえば、values_toで指定した変数の値が欠損しているケースを除去するにはvalues_drop_na引数をTRUEに指定するだけです。\n\n# Weight変数がNAのケースを除去する\ndf2 |&gt;\n  pivot_longer(starts_with(\"Day\"),\n               names_to       = \"Days\",\n               values_to      = \"Weight\",\n               values_drop_na = TRUE)\n\n# A tibble: 8 × 3\n  Name   Days  Weight\n  &lt;chr&gt;  &lt;chr&gt;  &lt;dbl&gt;\n1 Hadley Day1      75\n2 Hadley Day2      73\n3 Hadley Day3      71\n4 Song   Day1     120\n5 Song   Day3     140\n6 Yanai  Day1      70\n7 Yanai  Day2      69\n8 Yanai  Day3      71\n\n\nそれでは、キー変数から共通する文字列を除去するにはどうすれば良いでしょうか。この場合、names_prefix引数を使います。これはnames_toで指定した新しく出来る変数の値における接頭詞を指定し、それを除去する引数です。今回は\"Day1\"、\"Day2\"、\"Day3\"から\"Day\"を除去するので、names_prefix = \"Day\"と指定します。こうすることで、Days列から\"Day\"が除去されます。ただし、数字だけ残っても、そのデータ型はcharacter型ですので、このデータ型を変換する必要があります。ここで使うのがnames_transform引数であり、これはlist型のオブジェクトを渡す必要があります。Days列をnumeric型にする場合はlist(Days = as.numeric)です。複数の列のデータ型を変える場合、list()の中に追加していきます。それでは実際に走らせてみましょう。\n\n# 1. Day変数の値から\"Day\"を除去する\n# 2. Day変数をinteger型に変換\n# 3. Weight変数がNAのケースを除去する\ndf2 |&gt;\n  pivot_longer(starts_with(\"Day\"),\n               names_to        = \"Days\",\n               names_prefix    = \"Day\",                   # 1\n               names_transform = list(Days = as.numeric), # 2\n               values_to       = \"Weight\",\n               values_drop_na  = TRUE)                    # 3\n\n# A tibble: 8 × 3\n  Name    Days Weight\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 Hadley     1     75\n2 Hadley     2     73\n3 Hadley     3     71\n4 Song       1    120\n5 Song       3    140\n6 Yanai      1     70\n7 Yanai      2     69\n8 Yanai      3     71\n\n\nこれでWide型をLong型が変換され、整然でありながら、より見栄の良いデータが出来上がりました。他にもpivot_longer()は様々な引数に対応しており、詳細は?pivot_longerやレファレンスページを参照してください。"
  },
  {
    "objectID": "tidydata.html#sec-tidydata-spread",
    "href": "tidydata.html#sec-tidydata-spread",
    "title": "16  整然データ構造",
    "section": "16.3 Long型からWide型へ",
    "text": "16.3 Long型からWide型へ\nご存知の通り、「Long型データ=整然データ」ではありません。実際、 表 16.5 の右はLong型データですが、1列に2つの変数が含まれており、整然データとは言えません。このようなデータはいくらでもあります。とりわけ、「分析」のためじゃなく、「読む」ための表の場合において多く発見されます。\n\n\n表 16.7: Long型データの例\n\n\n\n\n\n(a) 雑然データ \n  \n    \n    \n      都道府県\n      区分\n      人口\n      面積\n    \n  \n  \n    北海道\n総人口\n5381733\n83424.31\n    \n外国人\n21676\n83424.31\n    青森県\n総人口\n1308265\n9645.59\n    \n外国人\n3447\n9645.59\n    岩手県\n総人口\n1279594\n15275.01\n    \n外国人\n5017\n15275.01\n    宮城県\n総人口\n2333899\n7282.22\n    \n外国人\n13989\n7282.22\n  \n  \n  \n\n\n\n\n\n\n(b) 整然データ \n  \n    \n    \n      都道府県\n      総人口\n      外国人\n      面積\n    \n  \n  \n    北海道\n5381733\n21676\n83424.31\n    青森県\n1308265\n3447\n9645.59\n    岩手県\n1279594\n5017\n15275.01\n    宮城県\n2333899\n13989\n7282.22\n  \n  \n  \n\n\n\n\n\n変数名が日本語になっていますが、これは「読むための表」を読み込むことを仮定しています。このように変数名として日本語は使えますが、自分でデータセットを作成する際、変数名はローマ字にすることを強く推奨します。\n表 16.7 の左の場合、人口列に総人口と外国人人口といった2つの変数の値が格納されているため、整然データではありません。これを整然データにしたものが右の表です。本節ではLong型データをWide型データへ変換するpivot_wider()関数を紹介します。この関数は同じく{tidyr}が提供しているspread()関数とほぼ同じ関数ですが、今はpivot_wider()の使用が推奨されており、spread()はいずれか{tidyr}から外される予定です。\nまずは、実習用データを読み込みます。\n\ndf3 &lt;- read_csv(\"Data/Population2015.csv\")\n\ndf3\n\n# A tibble: 94 × 4\n   都道府県 区分      人口   面積\n   &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;\n 1 北海道   総人口 5381733 83424.\n 2 &lt;NA&gt;     外国人   21676 83424.\n 3 青森県   総人口 1308265  9646.\n 4 &lt;NA&gt;     外国人    3447  9646.\n 5 岩手県   総人口 1279594 15275.\n 6 &lt;NA&gt;     外国人    5017 15275.\n 7 宮城県   総人口 2333899  7282.\n 8 &lt;NA&gt;     外国人   13989  7282.\n 9 秋田県   総人口 1023119 11638.\n10 &lt;NA&gt;     外国人    2914 11638.\n# ℹ 84 more rows\n\n\nこのデータは2015年国勢調査から抜粋したデータであり、各変数の詳細は 表 16.8 の通りです。\n\n\n\n\n\n表 16.8:  df3の詳細 \n  \n    \n    \n      変数名\n      説明\n    \n  \n  \n    都道府県\n\n都道府県名\n\n    区分\n\n総人口/外国人人口の区分\n\n    人口\n\n人口 (人)\n\n    面積\n\n面積 (km2)\n\n  \n  \n  \n\n\n\n\n\nまずは変数名が日本語になっているので、rename()関数を使ってそれぞれPref、Type、Population、Areaに変更します。\n\ndf3 &lt;- df3 |&gt;\n  rename(\"Pref\" = 都道府県, \"Type\" = 区分, \"Population\" = 人口, \"Area\" = 面積)\n\ndf3\n\n# A tibble: 94 × 4\n   Pref   Type   Population   Area\n   &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 北海道 総人口    5381733 83424.\n 2 &lt;NA&gt;   外国人      21676 83424.\n 3 青森県 総人口    1308265  9646.\n 4 &lt;NA&gt;   外国人       3447  9646.\n 5 岩手県 総人口    1279594 15275.\n 6 &lt;NA&gt;   外国人       5017 15275.\n 7 宮城県 総人口    2333899  7282.\n 8 &lt;NA&gt;   外国人      13989  7282.\n 9 秋田県 総人口    1023119 11638.\n10 &lt;NA&gt;   外国人       2914 11638.\n# ℹ 84 more rows\n\n\n次は、Pref列の欠損値を埋めましょう。ここの欠損値は、当該セルの一つ上のセルの値で埋まりますが、これはfill()関数で簡単に処理できます。欠損値を埋めたい変数名をfill()の引数として渡すだけです。\n\ndf3 &lt;- df3 |&gt;\n  fill(Pref)\n\ndf3\n\n# A tibble: 94 × 4\n   Pref   Type   Population   Area\n   &lt;chr&gt;  &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;\n 1 北海道 総人口    5381733 83424.\n 2 北海道 外国人      21676 83424.\n 3 青森県 総人口    1308265  9646.\n 4 青森県 外国人       3447  9646.\n 5 岩手県 総人口    1279594 15275.\n 6 岩手県 外国人       5017 15275.\n 7 宮城県 総人口    2333899  7282.\n 8 宮城県 外国人      13989  7282.\n 9 秋田県 総人口    1023119 11638.\n10 秋田県 外国人       2914 11638.\n# ℹ 84 more rows\n\n\nそして、いよいよpivot_wider()関数の出番ですが、基本的に使い方は以下の通りです。\n\n# pivot_wider()の使い方\nデータ名 |&gt;\n  pivot_wider(names_from  = キー変数名,\n              values_from = 値変数名)\n\nまず、キー変数名は列として展開する変数名であり、ここではTypeになります。そして、値変数名は展開される値の変数であり、ここではPopulationになります。つまり、「PopulationをTypeごとに分けて別の列にする」ことになります。また、values_from引数は長さ2以上のベクトルを指定することで、複数の値変数を指定することも可能です。たとえば、df3にIncomeという平均所得を表す列があり、これらも総人口と外国人それぞれ異なる値を持っているとしたら、values_from = c(Population, Income)のように複数の値変数を指定することが出来ます。今回は値変数が1つのみですが、早速やってみましょう。\n\ndf3_W &lt;- df3 |&gt;\n  pivot_wider(names_from  = Type,\n              values_from = Population)\n\ndf3_W\n\n# A tibble: 47 × 4\n   Pref     Area  総人口 外国人\n   &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 北海道 83424. 5381733  21676\n 2 青森県  9646. 1308265   3447\n 3 岩手県 15275. 1279594   5017\n 4 宮城県  7282. 2333899  13989\n 5 秋田県 11638. 1023119   2914\n 6 山形県  9323. 1123891   5503\n 7 福島県 13784. 1914039   8725\n 8 茨城県  6097. 2916976  41310\n 9 栃木県  6408. 1974255  26494\n10 群馬県  6362. 1973115  37126\n# ℹ 37 more rows\n\n\nまた、日本語の変数名が出来てしまったので、それぞれTotalとForeignerに変更し、relocate()関数を使ってAreaを最後の列に移動します。\n\ndf3_W &lt;- df3_W |&gt;\n  rename(\"Total\"     = 総人口,\n         \"Foreigner\" = 外国人) |&gt;\n  relocate(Area, .after = last_col())\n\ndf3_W\n\n# A tibble: 47 × 4\n   Pref     Total Foreigner   Area\n   &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;  &lt;dbl&gt;\n 1 北海道 5381733     21676 83424.\n 2 青森県 1308265      3447  9646.\n 3 岩手県 1279594      5017 15275.\n 4 宮城県 2333899     13989  7282.\n 5 秋田県 1023119      2914 11638.\n 6 山形県 1123891      5503  9323.\n 7 福島県 1914039      8725 13784.\n 8 茨城県 2916976     41310  6097.\n 9 栃木県 1974255     26494  6408.\n10 群馬県 1973115     37126  6362.\n# ℹ 37 more rows\n\n\nこれで整然データの出来上がりです。\nこのpivot_wider()関数はpivot_longer()関数同様、様々な引数を提供しておりますが、主に使う機能は以上です。他にはpivot_wider()によって出来た欠損値を埋める引数であるvalues_fillがあり、デフォルト値はNULLです。ここに0や\"Missing\"などの長さ1のベクトルを指定すれば、指定した値で欠損値が埋まります。\npivot_wider()関数の詳細は?pivot_widerもしくは、レファレンスページを参照してください。"
  },
  {
    "objectID": "tidydata.html#sec-tidydata-separate",
    "href": "tidydata.html#sec-tidydata-separate",
    "title": "16  整然データ構造",
    "section": "16.4 列の分割",
    "text": "16.4 列の分割\n他にも「1列1変数」の条件を満たさないケースを考えましょう。pivot_longer()は1つの変数が複数の列に渡って格納されている際に使いましたが、今回は1つの列に複数の変数があるケースを考えてみましょう。たとえば、年月日が1つの列に入っている場合、これを年、月、日の3列で分割する作業です。また、これと関連して、列から文字列を除去し、数値のみ残す方法についても紹介します。\n実習用データを読み込んでみましょう。\n\ndf4 &lt;- read_csv(\"Data/COVID19_JK.csv\")\n\ndf4\n\n# A tibble: 172 × 5\n      ID Date      Week  Confirmed_Japan Confirmed_Korea\n   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;           &lt;chr&gt;          \n 1     1 2020/1/16 木    1人             &lt;NA&gt;           \n 2     2 2020/1/17 金    0人             &lt;NA&gt;           \n 3     3 2020/1/18 土    0人             &lt;NA&gt;           \n 4     4 2020/1/19 日    0人             &lt;NA&gt;           \n 5     5 2020/1/20 月    0人             1人            \n 6     6 2020/1/21 火    0人             0人            \n 7     7 2020/1/22 水    0人             0人            \n 8     8 2020/1/23 木    0人             0人            \n 9     9 2020/1/24 金    2人             1人            \n10    10 2020/1/25 土    0人             0人            \n# ℹ 162 more rows\n\n\nこのデータは2020年1月16日から2020年7月5日まで、COVID-19 (新型コロナ)の新規感染者数を日本と韓国を対象に収集したものです。データはWikipedia (日本 / 韓国)から収集しました。韓国の新規感染者数は最初の4日分が欠損値のように見えますが、最初の感染者が確認されたのが1月20日のため、1月19日までは欠損となっています。\n\n\n\n\n\n  \n    \n    \n      変数名\n      説明\n    \n  \n  \n    ID\n\nケースID\n    Date\n\n年月日\n    Week\n\n曜日\n    Confirmed_Japan\n\n新規感染者数 (日本)\n    Confirmed_Korea\n\n新規感染者数 (韓国)\n  \n  \n  \n\n\n\n\nこのデータの場合、観察単位は「国 \\(\\times\\) 日」です。しかし、df4は1行に日本と韓国の情報が格納されており「1行1観察」の条件を満たしておりません。したがって、pivot_longer()を使ってLong型へ変換し、新しいデータの名前をdf4_Lと名付けます。\n\ndf4_L &lt;- df4 |&gt;\n  pivot_longer(cols         = starts_with(\"Confirmed\"), \n               names_to     = \"Country\",\n               names_prefix = \"Confirmed_\",\n               values_to    = \"Confirmed\")\n\ndf4_L\n\n# A tibble: 344 × 5\n      ID Date      Week  Country Confirmed\n   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;    \n 1     1 2020/1/16 木    Japan   1人      \n 2     1 2020/1/16 木    Korea   &lt;NA&gt;     \n 3     2 2020/1/17 金    Japan   0人      \n 4     2 2020/1/17 金    Korea   &lt;NA&gt;     \n 5     3 2020/1/18 土    Japan   0人      \n 6     3 2020/1/18 土    Korea   &lt;NA&gt;     \n 7     4 2020/1/19 日    Japan   0人      \n 8     4 2020/1/19 日    Korea   &lt;NA&gt;     \n 9     5 2020/1/20 月    Japan   0人      \n10     5 2020/1/20 月    Korea   1人      \n# ℹ 334 more rows\n\n\n続いて、新規感染者数を表すConfirmed列から「人」を除去しましょう。人間にとってはなんの問題もありませんが、パソコンにとって1人や5人は文字列に過ぎず、分析ができる状態ではありません。ここで使う関数がparse_number()です。引数として指定した列から数値のみ抽出します。\"$1000\"や\"1, 324, 392\"のような数値でありながら、character型として保存されている列から数値のみを取り出す際に使う関数です。使い方は以下の通りです。\n\nデータ名 |&gt;\n  mutate(新しい変数名 = parse_number(数値のみ抽出する変数名))\n\n似たようなものとしてparse_character()があり、これは逆に文字列のみ抽出する関数です。\nここではConfimedから数値のみ取り出し、Confrimed列に上書きし、それをdf4_Sと名付けます。\n\ndf4_S &lt;- df4_L |&gt;\n  mutate(Confirmed = parse_number(Confirmed))\n\ndf4_S\n\n# A tibble: 344 × 5\n      ID Date      Week  Country Confirmed\n   &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1     1 2020/1/16 木    Japan           1\n 2     1 2020/1/16 木    Korea          NA\n 3     2 2020/1/17 金    Japan           0\n 4     2 2020/1/17 金    Korea          NA\n 5     3 2020/1/18 土    Japan           0\n 6     3 2020/1/18 土    Korea          NA\n 7     4 2020/1/19 日    Japan           0\n 8     4 2020/1/19 日    Korea          NA\n 9     5 2020/1/20 月    Japan           0\n10     5 2020/1/20 月    Korea           1\n# ℹ 334 more rows\n\n\nそれでは国、曜日ごとの新規感染者数を調べてみます。求める統計量は曜日ごとの新規感染者数の合計、平均、標準偏差です。まず、曜日は月から日の順になるよう、factor型に変換します。そして、国と曜日ごとに記述統計量を計算し、df4_S_Summary1という名で保存します。\n\ndf4_S &lt;- df4_S |&gt;\n  mutate(Week = factor(Week, \n                       levels = c(\"月\", \"火\", \"水\", \"木\", \"金\", \"土\", \"日\")))\n\ndf4_S_Summary1 &lt;- df4_S |&gt;\n  group_by(Country, Week) |&gt;\n  summarise(Sum     = sum(Confirmed,  na.rm = TRUE),\n            Mean    = mean(Confirmed, na.rm = TRUE),\n            SD      = sd(Confirmed,   na.rm = TRUE),\n            .groups = \"drop\")\n\ndf4_S_Summary1\n\n# A tibble: 14 × 5\n   Country Week    Sum  Mean    SD\n   &lt;chr&gt;   &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1 Japan   月     2540 106.   156.\n 2 Japan   火     2093  87.2  111.\n 3 Japan   水     2531 105.   133.\n 4 Japan   木     2704 108.   151.\n 5 Japan   金     3083 123.   172.\n 6 Japan   土     3327 133.   189.\n 7 Japan   日     3244 130.   179.\n 8 Korea   月     1609  67.0  126.\n 9 Korea   火     1641  68.4  111.\n10 Korea   水     1626  67.8  102.\n11 Korea   木     1883  78.5  137.\n12 Korea   金     2099  87.5  143.\n13 Korea   土     2194  91.4  174.\n14 Korea   日     2088  87    215.\n\n\ndf4_S_Summary1はこの状態で整然データですが、もし人間が読むための表を作るなら、韓国と日本を別の列に分けた方が良いかも知れません。pivot_wider()を使って、日本と韓国のの新規感染者数を2列に展開します。\n\ndf4_S_Summary1 |&gt;\n  pivot_wider(names_from  = Country,\n              values_from = Sum:SD)\n\n# A tibble: 7 × 7\n  Week  Sum_Japan Sum_Korea Mean_Japan Mean_Korea SD_Japan SD_Korea\n  &lt;fct&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 月         2540      1609      106.        67.0     156.     126.\n2 火         2093      1641       87.2       68.4     111.     111.\n3 水         2531      1626      105.        67.8     133.     102.\n4 木         2704      1883      108.        78.5     151.     137.\n5 金         3083      2099      123.        87.5     172.     143.\n6 土         3327      2194      133.        91.4     189.     174.\n7 日         3244      2088      130.        87       179.     215.\n\n\nこれで人間にとって読みやすい表が出来ました。今は「日本の合計」、「韓国の合計」、「日本の平均」、…の順番ですが、これを日本と韓国それぞれまとめる場合は、relocate()を使います。\n\ndf4_S_Summary1 |&gt;\n  pivot_wider(names_from  = Country,\n              values_from = Sum:SD) |&gt;\n  relocate(Week, ends_with(\"Japan\"), ends_with(\"Korea\"))\n\n# A tibble: 7 × 7\n  Week  Sum_Japan Mean_Japan SD_Japan Sum_Korea Mean_Korea SD_Korea\n  &lt;fct&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1 月         2540      106.      156.      1609       67.0     126.\n2 火         2093       87.2     111.      1641       68.4     111.\n3 水         2531      105.      133.      1626       67.8     102.\n4 木         2704      108.      151.      1883       78.5     137.\n5 金         3083      123.      172.      2099       87.5     143.\n6 土         3327      133.      189.      2194       91.4     174.\n7 日         3244      130.      179.      2088       87       215.\n\n\n新規感染者が確認されるのは金〜日曜日が多いことが分かります。\n曜日ではなく、月ごとに記述統計料を計算する場合は、まずDate列を年、月、日に分割する必要があります。具体的にはDateを\"/\"を基準に別ければいいです。そこで登場するのはseparate()関数であり、使い方は以下の通りです。\n\n# separate()の使い方\nデータ名 |&gt;\n  separate(cols = 分割する変数名,\n           into = 分割後の変数名,\n           sep  = \"分割する基準\")\n\ncolsにはDateを指定し、intoは新しく出来る列名を指定します。今回はDateが3列に分割されるので、長さ3のcharacter型ベクトルを指定します。ここではYear、Month、Dayとしましょう。最後のsep引数は分割する基準となる文字を指定します。df4のDateは\"2020/06/29\"のように年月日が\"/\"で分けられているため、\"/\"を指定します。実際にやってみましょう。\n\ndf4_S &lt;- df4_S |&gt;\n  separate(col = Date, into = c(\"Year\", \"Month\", \"Day\"), sep = \"/\")\n\ndf4_S\n\n# A tibble: 344 × 7\n      ID Year  Month Day   Week  Country Confirmed\n   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;chr&gt;       &lt;dbl&gt;\n 1     1 2020  1     16    木    Japan           1\n 2     1 2020  1     16    木    Korea          NA\n 3     2 2020  1     17    金    Japan           0\n 4     2 2020  1     17    金    Korea          NA\n 5     3 2020  1     18    土    Japan           0\n 6     3 2020  1     18    土    Korea          NA\n 7     4 2020  1     19    日    Japan           0\n 8     4 2020  1     19    日    Korea          NA\n 9     5 2020  1     20    月    Japan           0\n10     5 2020  1     20    月    Korea           1\n# ℹ 334 more rows\n\n\n新しく出来た変数は元の変数があった場所になります。ここまで来たら月ごとに新規感染者の記述統計量は計算できます。曜日ごとに行ったコードのWeekをMonthに変えるだけです。また、Monthは数字のみで構成されたcharacter型であるため、このままでも問題なくソートされます。したがって、別途factor化の必要もありません（むろん、してもいいですし、むしろ推奨されます）。\n\ndf4_S_Summary2 &lt;- df4_S |&gt;\n  group_by(Country, Month) |&gt;\n  summarise(Sum     = sum(Confirmed,  na.rm = TRUE),\n            Mean    = mean(Confirmed, na.rm = TRUE),\n            SD      = sd(Confirmed,   na.rm = TRUE),\n            .groups = \"drop\")\n\ndf4_S_Summary2\n\n# A tibble: 14 × 5\n   Country Month   Sum    Mean     SD\n   &lt;chr&gt;   &lt;chr&gt; &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;\n 1 Japan   1        17   1.06    1.34\n 2 Japan   2       213   7.34    7.81\n 3 Japan   3      1723  55.6    42.4 \n 4 Japan   4     12135 404.    146.  \n 5 Japan   5      2763  89.1    73.0 \n 6 Japan   6      1742  58.1    23.0 \n 7 Japan   7       929 186.     45.1 \n 8 Korea   1        11   0.917   1.44\n 9 Korea   2      3139 108.    203.  \n10 Korea   3      6737 217.    222.  \n11 Korea   4       887  29.6    26.6 \n12 Korea   5       729  23.5    16.2 \n13 Korea   6      1348  44.9    10.4 \n14 Korea   7       289  57.8     6.61\n\n\n\ndf4_S_Summary2 |&gt;\n  pivot_wider(names_from  = Country,\n              values_from = Sum:SD) |&gt;\n  relocate(Month, ends_with(\"Japan\"), ends_with(\"Korea\"))\n\n# A tibble: 7 × 7\n  Month Sum_Japan Mean_Japan SD_Japan Sum_Korea Mean_Korea SD_Korea\n  &lt;chr&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n1 1            17       1.06     1.34        11      0.917     1.44\n2 2           213       7.34     7.81      3139    108.      203.  \n3 3          1723      55.6     42.4       6737    217.      222.  \n4 4         12135     404.     146.         887     29.6      26.6 \n5 5          2763      89.1     73.0        729     23.5      16.2 \n6 6          1742      58.1     23.0       1348     44.9      10.4 \n7 7           929     186.      45.1        289     57.8       6.61\n\n\n平均値から見ると、日本は7都道府県を対象に緊急事態宣言が行われた4月がピークで緩やかに減少していますが、7月になって上がり気味です。韓国はカルト宗教団体におけるクラスターが発生した3月がピークで、6月からまた上がり気味ですね。傾向としては韓国が日本に1ヶ月先行しているように見えます。\nそれではseparate()関数の他の引数についても簡単に紹介します。まず、sep引数はnumeric型でも可能です。この場合、文字列内の位置を基準に分割されます。年月日が20200629のように保存されている場合は、何らかの基準となる文字がありません。この場合、sep = c(4, 6)にすると、「\"20200629\"の4文字目と5文字目の間で分割、6文字目と7文字目の間で分割」となります。また、sep = c(-4, -2)のように負の値も指定可能であり、この場合は右からの位置順で分割します。\nまた、separate()後は元の変数がなくなりますが、remove = FALSEの場合、元の変数 (ここではDate)が残ります。他にもconvert引数もあります。convert = TRUEの場合、適切なデータ型へ変換してくれます。デフォルト値はFALSEであり、この場合、character型として分割されます。先ほどの例だとYearもMonthもDayも現在はcharacter型です。separate()内でconvert = TRUEを追加すると、分割後のYear、Month、Dayはnumeric型として保存されます。\nseparate()の詳細は?separateまたは、レファレンスページを参照してください。\n\n\n\n\nWickham, Hadley. 2014. 「Tidy Data」. Journal of Statistical Software 59."
  },
  {
    "objectID": "string.html#rにおける文字列",
    "href": "string.html#rにおける文字列",
    "title": "17  文字列の処理",
    "section": "17.1 Rにおける文字列",
    "text": "17.1 Rにおける文字列\n　Rは数値だけでなく文字列 (string) も扱うことができる。近年、文字や文書をデータとして扱う機会が増えており、文字列を効率的に処理する方法を身につけることで、データとして扱う対象を拡大することができる。\n　まず、最も基本的な文字列の扱い方を確認（復習）しよう（第9章も参照されたい）。Rで文字列を使う際は、文字列を引用符 (quotation marks) で囲む（囲むというのは、文字列が始まる前とそれが終わった後にそれぞれ引用符をつけるという意味である）。例えば、「SONG Jaehyun」という文字列をauthor1というオブジェクトに格納するには、次のようにする。\n\nauthor1 &lt;- \"SONG Jaehyun\"\nauthor1\n\n[1] \"SONG Jaehyun\"\n\n\n文字列の中にスペースが含まれる場合、そのスペースもそのまま保存される。この例では、半角スペースを1つ含む文字列が保存される。\n　Rにおける文字列は、character クラス・型として扱われる。\n\nclass(author1)\n\n[1] \"character\"\n\nis.character(author1)\n\n[1] TRUE\n\ntypeof(author1)\n\n[1] \"character\"\n\nmode(author1)\n\n[1] \"character\"\n\n\n　引用符は、二重引用符\"\" でも 単一引用符'' でも良い。ただし、同じ記号をペアで使う必要がある。\n\nauthor2 &lt;- '矢内　勇生'\nprint(author2)\n\n[1] \"矢内　勇生\"\n\n\nこの例では、全角スペースを1つ含む文字列が保存される。また、''を使って文字列を作ったのに、表示結果で文字列を囲む引用符は\"\"に変わっていることがわかる。これは、文字列を作る際には二重引用符を使うことが想定されているためである。よって、特にこだわりがなければ、二重引用符\"\"を使ったほうがよいだろう。\n　引用符自体を文字列の一部として保存したいときは、次のようにする。\n\nquote1 &lt;- \"Mura'Kamisama'\"\nquote2 &lt;- 'We we\"R\"e born to use \"R.\"'\nquote1\n\n[1] \"Mura'Kamisama'\"\n\nquote2\n\n[1] \"We we\\\"R\\\"e born to use \\\"R.\\\"\"\n\n\nquote2 の表示結果を見ると、文字列に含まれる二重引用符の前にバックスラッシュ \\ が付いている。これは、文字列のエスケープと呼ばれる方法である。これについては後で詳しく説明する。この例においては、二重引用符を文字列を作るための命令として使う代わりに、単なる1つの文字として扱うために必要な処理である。cat()を使うと、保存した内容をそのまま表示することができる。\n\ncat(quote2)\n\nWe we\"R\"e born to use \"R.\"\n\n\n　上の例では文字列内で二重引用符を使うので、文字列の外側ではは単一引用符を使った。 二重引用符のみで上と同じ文字列を作りたい場合は、エスケープ処理を利用すればよい。\n\nquote3 &lt;- \"We we\\\"R\\\"e born to use \\\"R.\\\"\"\nquote3\n\n[1] \"We we\\\"R\\\"e born to use \\\"R.\\\"\"\n\ncat(quote3)\n\nWe we\"R\"e born to use \"R.\"\n\n\nエスケープ処理をしないとエラーになる。\n\nquote3 &lt;- \"We we\"R\"e born to use \"R.\"\"\n\nError: malformed raw string literal (&lt;text&gt;:1:20)\n\n\nこれは、「“We we”」で二重引用符のペアが完成し、そのすぐ後の「R」が文字列として認識されていないために起こるエラーである。\n　文字列を要素とするベクトルやリストなども、数値を要素とする場合と同じように作ることができる。\n\nauthors &lt;- c(author1, author2, \"Super Cat\")\nauthors\n\n[1] \"SONG Jaehyun\" \"矢内　勇生\"   \"Super Cat\"   \n\n\n　数値と文字列の両者を要素としてもつベクトルを作ると、すべての要素が文字として保存される。\n\nnumchar &lt;- c(1, 2, \"three\", 4, \"five\")\nnumchar\n\n[1] \"1\"     \"2\"     \"three\" \"4\"     \"five\" \n\nclass(numchar)\n\n[1] \"character\"\n\nsapply(numchar, class)\n\n          1           2       three           4        five \n\"character\" \"character\" \"character\" \"character\" \"character\" \n\n\nRでは、ベクトルのすべての要素は同じクラスになる。数値は文字として扱える一方で、一般的に文字を数値として扱うことはできないので、型が文字 (character) に統一される。\n　リストは異なる型を保存することできる。\n\nnumchar_list &lt;- list(1, 2, \"three\", 4, \"five\")\nnumchar_list\n\n[[1]]\n[1] 1\n\n[[2]]\n[1] 2\n\n[[3]]\n[1] \"three\"\n\n[[4]]\n[1] 4\n\n[[5]]\n[1] \"five\"\n\nclass(numchar_list)\n\n[1] \"list\"\n\nlapply(numchar_list, class)\n\n[[1]]\n[1] \"numeric\"\n\n[[2]]\n[1] \"numeric\"\n\n[[3]]\n[1] \"character\"\n\n[[4]]\n[1] \"numeric\"\n\n[[5]]\n[1] \"character\"\n\n\n数値を文字として扱いたいときは、as.character() を使う。\n\none &lt;- as.character(1)\none\n\n[1] \"1\"\n\none2ten &lt;- 1:10 |&gt; \n  as.character()\none2ten\n\n [1] \"1\"  \"2\"  \"3\"  \"4\"  \"5\"  \"6\"  \"7\"  \"8\"  \"9\"  \"10\"\n\nclass(one2ten)\n\n[1] \"character\"\n\n\n保存されているのが数字であっても、それが文字列として保存されているなら、そのまま計算に利用することはできない。\n\nsum(one2ten)\n\nError in sum(one2ten): invalid 'type' (character) of argument\n\n\nしかし，as.numeric() や as.integer() を使って数値に変換すれば、計算に利用することができる。\n\nas.numeric(one2ten)\n\n [1]  1  2  3  4  5  6  7  8  9 10\n\none2ten |&gt; \n  as.integer() |&gt; \n  sum()\n\n[1] 55\n\n\n\nas.numeric(\"3.35\") + as.numeric(\"4.24\") * 2\n\n[1] 11.83\n\n\n数字以外の文字を数値に変換することはできない（NAになる）。\n\nc(\"1\", \"2\", \"three\", \"4\") |&gt; \n  as.integer()\n\nWarning: NAs introduced by coercion\n\n\n[1]  1  2 NA  4\n\n\n　Rの文字列に対して、そのままスライシング操作を行うことはできない。たとえば、author1の1文字目を取り出したいときに、次のようにしても1文字目の”S”は抽出できない。\n\nauthor1[1]\n\n[1] \"SONG Jaehyun\"\n\n\nこのように、文字列全体が取り出されてしまう。これは、この文字列が長さ1のベクトル（つまり、冗長に書けばc(\"SONG Jaehyun\") である）なので、スライス操作で1番目の要素を取り出すと、ベクトルの第1要素が取り出されるためである。\nしたがって、文字列自体の長さをlength()で測ることはできない。\n\nlength(author1)\n\n[1] 1\n\nlength(author2)\n\n[1] 1\n\n\nいずれの結果も1になるのは、どちらも長さが1のベクトルだからである。\n　文字列に対して様々な処理を施す方法については、次節で説明する。"
  },
  {
    "objectID": "string.html#文字列の操作",
    "href": "string.html#文字列の操作",
    "title": "17  文字列の処理",
    "section": "17.2 文字列の操作",
    "text": "17.2 文字列の操作\nRでは、文字列に対して様々な処理を行うこができる。 文字列操作をする際に欠かせないのが、stringrパッケージである。 このパッケージは私たちが住むtidyverseに含まれているので、あらためて読み込む必要はない。\nstringrパッケージで文字列操作を行う関数は、str_xxx()のような形式の関数である（xxxの部分を、操作に応じて変える）。まず、文字列の長さ（つまり、文字数）を数えるために、str_length() を使う。\n\nstr_length(authors)\n\n[1] 12  5  9\n\n\nスペースを含む文字数が返される。\n　上で試みたように文字列の一部 (substring) を取り出すときは、str_sub()を使う。\n\nstr_sub(author1, start = 1, end = 1)\n\n[1] \"S\"\n\n\nこのように始点 (start) と終点 (end) を指定することで、文字列の一部を取り出すことができる。 5文字目から8文字目までを取り出してみよう。\n\nstr_sub(author1, start = 6, end = 8)\n\n[1] \"Jae\"\n\n\n特定の位置より後をすべて取り出したいときは、startのみを指定する。\n\nstr_sub(author1, start = 6)\n\n[1] \"Jaehyun\"\n\n\n同様に、特定の位置までを取り出したいときは、endのみを指定する。\n\nstr_sub(author1, end = 4)\n\n[1] \"SONG\"\n\n\nend に指定した位置も含めて抽出されることに注意されたい。\n文字列を分割 (split) したいときは、str_split()を使う。 patternで指定した文字の前後で文字列を分割する。 たとえば、次のようにする。\n\nauthor1_s &lt;- str_split(author1, pattern = \" \") |&gt; \n  print()\n\n[[1]]\n[1] \"SONG\"    \"Jaehyun\"\n\n\n結果として返されるのは、リストである。 2つ以上の文字列に対して同様の操作を行うと、リストで返される理由がわかるだろう。\n\nauthors_s1 &lt;- str_split(authors, pattern = \" \") |&gt; \n  print()\n\n[[1]]\n[1] \"SONG\"    \"Jaehyun\"\n\n[[2]]\n[1] \"矢内　勇生\"\n\n[[3]]\n[1] \"Super\" \"Cat\"  \n\n\nauthors は3つの文字列を要素としてもつベクトルである。 このベクトルに対して文字列分割の操作を行うと、それぞれの文字列の分割結果を要素とするリストが返される。そしてリストの各要素の中に、分割したそれぞれの文字列を要素をしてもつベクトルが保存される。\n　ここで、リストの2つ目の要素が分割されていないことに注意してほしい。これは、この文字列には半角スペースがないからだ。代わりに全角スペースがあるので、これを分割したいならpatternに全角スペースを指定する必要がある。\n\nauthors_s2 &lt;- str_split(authors, pattern = \"　\") |&gt; \n  print()\n\n[[1]]\n[1] \"SONG Jaehyun\"\n\n[[2]]\n[1] \"矢内\" \"勇生\"\n\n[[3]]\n[1] \"Super Cat\"\n\n\n今度は、2番目の文字列のみ分割された。すべて分割するには、| (or) を使って次のようにする。\n\nauthors_s3 &lt;- str_split(authors, pattern = \" |　\") |&gt; \n  print()\n\n[[1]]\n[1] \"SONG\"    \"Jaehyun\"\n\n[[2]]\n[1] \"矢内\" \"勇生\"\n\n[[3]]\n[1] \"Super\" \"Cat\"  \n\n\n上のコードでは、| の左側に半角スペース、右側に全角スペースが指定されている。\n　あるいは、次のように「空白文字」を\\\\sで指定すれば、半角・全角をまとめて扱える（これについては後で正規表現を説明する際にもう少し説明する）。\n\nauthors_s3 &lt;- str_split(authors, pattern = \"\\\\s\") |&gt; \n  print()\n\n[[1]]\n[1] \"SONG\"    \"Jaehyun\"\n\n[[2]]\n[1] \"矢内\" \"勇生\"\n\n[[3]]\n[1] \"Super\" \"Cat\"  \n\n\n　文字列操作をもう少し練習するために、以下の例文を使おう。\n\neg_Acton &lt;- \"Power tends to corrupt. Absolute power corrupts absolutely.\"\neg_Wilde &lt;- \"A little sincerity is a dangerous thing, and a great deal of it is absolutely fatal.\"\n\n　str_split()は、同じパタンが複数回出てくる場合には、すべてを分割してくれる。\n\nstr_split(eg_Acton, pattern = \"\\\\s\")\n\n[[1]]\n[1] \"Power\"       \"tends\"       \"to\"          \"corrupt.\"    \"Absolute\"   \n[6] \"power\"       \"corrupts\"    \"absolutely.\"\n\n\nこの例からわかるとおり、このような操作は英文をはじめとする単語間にスペースがある言語データをに対し、文字列を単語に分割する際に有用である。\n　特定の文字（単語）を抽出したいときは、str_extract() を使う。\n\nstr_extract(eg_Acton, pattern = \"corrupt\")\n\n[1] \"corrupt\"\n\n\neg_Actonオブジェクトには指定した文字列である “corrupt” に一致する部分があるので、関数は指定した文字列そのものを返す。 このオブジェクトには “corrupt” という文字列が2回登場するが、この関数は最初の “corrupt” を発見した時点でそれを返し、2つ目の”corrupt” には到達しない。\n　オブジェクトの中に指定した文字列が存在しない場合、NAが返される。\n\nstr_extract(eg_Acton, pattern = \"cats\")\n\n[1] NA\n\n\n　str_extract() は指定した文字列を1度しか返さないが、str_extract_all() は一致したものをすべてを返す。\n\nstr_extract_all(eg_Acton, pattern = \"corrupt\")\n\n[[1]]\n[1] \"corrupt\" \"corrupt\"\n\n\nこの例が示す通り、 str_extract_all() はリストを返す。 リストの長さは文字列が一致した回数ではなく、パタンを探す対象として渡したオブジェクトの数である。 上の例では、1つのオブジェクトで2回マッチしているので、返されたリストの長さは1であり、リストの第1要素の長さは2である。\n\nlist_corrupt &lt;- str_extract_all(eg_Acton, pattern = \"corrupt\") \nlength(list_corrupt)\n\n[1] 1\n\nlength(list_corrupt[[1]])\n\n[1] 2\n\n\n　次の例では、返されるリストの長さが2になる。\n\nlist_absolute &lt;- str_extract_all(c(eg_Acton, eg_Wilde), \n                                 pattern = \"absolute\") |&gt; \n  print()\n\n[[1]]\n[1] \"absolute\"\n\n[[2]]\n[1] \"absolute\"\n\n\n　これらの関数は、いずれも大文字と小文字を区別する (case-sensitive)。大文字、小文字の別を無視したいときはregex()を使ってignore_case = TRUE を指定する。\n\nstr_extract_all(c(eg_Acton, eg_Wilde),\n                pattern = regex(\"absolute\", ignore_case = TRUE))\n\n[[1]]\n[1] \"Absolute\" \"absolute\"\n\n[[2]]\n[1] \"absolute\"\n\n\n　オブジェクトの「先頭で」特定の文字列に一致するものを見つけたいときは、^ (the caret symbol) を次のように使う。\n\nstr_extract(eg_Acton, pattern = \"^corrupt\")\n\n[1] NA\n\n\n\nstr_extract(eg_Acton, pattern = \"^Power\")\n\n[1] \"Power\"\n\n\n同様に、文字列の「末尾で」一致を探すときは、$ を使う。\n\nstr_extract_all(c(eg_Acton, eg_Wilde), pattern = \".$\")\n\n[[1]]\n[1] \".\"\n\n[[2]]\n[1] \".\""
  },
  {
    "objectID": "string.html#正規表現",
    "href": "string.html#正規表現",
    "title": "17  文字列の処理",
    "section": "17.3 正規表現",
    "text": "17.3 正規表現\n　ウェブ上に存在するデータのほとんどはテキスト（文字）である。また、その大部分はデータセットとして利用可能な状態に構造化されていない。構造化されていない文字の集合そのものをデータとして利用する場合もあるが、たいていの場合、特定のパタンに合致する文字情報だけを取り出して利用したい。 よって、文字列の中から特定のパタンに当てはまるものを見つけてそれを取り出す必要がある。そのために使われるのが、正規表現 (regular expressions) である。\n　ここでは、基本的な正規表現を紹介する。\n\n17.3.1 一般的なパタン一致\n　ここまでは、特定の文字列に一致する文字列を見つけてきた。 しかし、正規表現を使うと、より一般的なパタンに一致する文字列を見つけることができる。 たとえば、. (dot) は正規表現ではあらゆる文字 (character) と一致する。\n\nstr_extract_all(eg_Wilde, pattern = \"i.\")\n\n[[1]]\n[1] \"it\" \"in\" \"it\" \"is\" \"in\" \"it\" \"is\"\n\n\nドット自体を取り出したいときは、バックスラッシュ と一緒にして \\. とする。\n\nstr_extract_all(eg_Wilde, pattern = '\\\\.')\n\n[[1]]\n[1] \".\"\n\n\nここで、バックスラッシュ (\\) はRで定義された文字列の意味から私たちを逃してくれるので、 エスケープ文字 (escape character) と呼ばれる。R（やその他の多くのプログラミング言語における正規表現）において . は「あらゆる文字」を意味するが、\\. はその意味から私たちを解放し、ドットそのものとの一致を探してくれる。 ただし、バックスラッシュ自体が正規表現のバックスラッシュであることをRに伝えるために、バックスラッシュを二重にする必要がある。\n　“it” または “in”を見つけるには次のようにする。\n\nstr_extract_all(eg_Wilde, pattern = \"i[tn]\")\n\n[[1]]\n[1] \"it\" \"in\" \"it\" \"in\" \"it\"\n\n\nつまり、[] で囲まれ文字のうちいずれかが入るパタンで一致を探す。\nパタンではなく、単語としての “it” と “in” のみを抜き出す（たとえば、littleに含まれる “it” は除く）には、次のようにする。\n\nstr_extract_all(eg_Wilde, pattern = \"\\\\bi[tn]\\\\b\")\n\n[[1]]\n[1] \"it\"\n\n\n\\bは、そこが単語の境界 (boundary) であることを示す。\nある文字以外を指定したいとき、たとえば、i から始まりt以外で終わる2文字の単語は、[^]を使って次のようにして取り出せる。\n\nstr_extract_all(eg_Wilde, pattern = \"\\\\bi[^t]\\\\b\")\n\n[[1]]\n[1] \"is\" \"is\"\n\n\n　これらの例からわかるように、正規表現を使えば様々な条件にあった文字列を探し出すことができる。 表 17.1 に、よく使う正規表現のパタンを示す。\n\n\n\n\n\n表 17.1:  よく使う正規表現 \n  \n    \n    \n      正規表現\n      意味\n    \n  \n  \n    [:digit:]\n数字（0, 1, 2, ..., 9）\n    [:lower:]\n小文字（a, b, c, ..., z）\n    [:upper:]\n大文字（A, B, C, ..., Z）\n    [:alpha:]\nアルファベット (a, b, ..., z と A, B, ..., Z\n    [:alnum:]\nアルファベットと数字（a, ..., z, A, ..., Z, 0, ..., 9）\n    [:punct:]\nパンクチュエーション文字（! \" # $ % & ’ ( ) * + , - . /）\n    [:blank:]\n空白文字（スペースとタブ）\n    [:space:]\nスペース文字（スペース、タブ、改行など）\n    [:print:]\n印刷可能な文字 ([:alnum:], [:punct:], [:space:])\n  \n  \n  \n\n\n\n\n\nまた、特別な意味をもつ記号を 表 17.2 に示す。 これらを使うときには \\\\w のようにバックスラッシュを1つ増やす必要がある。\n\n\n\n\n\n表 17.2:  特別な意味をもつ記号 \n  \n    \n    \n      正規表現\n      意味\n    \n  \n  \n    \\w\n文字\n    \\W\n文字以外\n    \\s\nスペース文字\n    \\S\nスペース文字以外\n    \\d\n数字\n    \\D\n数字以外\n    \\b\n単語の境界\n    \\B\n単語の境界以外\n    \\&lt;\n単語の先頭\n    \\&gt;\n単語の末尾\n    ^\n文字列の先頭\n    $\n文字列の末尾\n  \n  \n  \n\n\n\n\n\n　これらの正規表現を組み合わせて使うことで、様々なパタンに一致する文字列を探したり、抜き出したり、入れ替えたりすることができる。さらに、それぞれの正規表現に一致する回数も指定することができる。たとえば、5文字の単語を探すには、次のようにする。\n\nstr_extract_all(eg_Wilde, pattern = \"\\\\b[:alpha:]{5}\\\\b\")\n\n[[1]]\n[1] \"thing\" \"great\" \"fatal\"\n\n\n数を指定するときは、 表 17.1　に示す限量詞 (quantifier) を登場回数を指定したい表現の直後につける。\n\n\n\n\n\n表 17.3:  正規表現と一緒に使う限量詞 \n  \n    \n    \n      限量詞\n      意味\n    \n  \n  \n    ?\n直前の表現と0回以上一致（あってもなくてもよい）で、最大で1回一致\n    *\n直前の表現と0回以上一致\n    +\n直前の表現と1回以上一致\n    {m}\n直前の表現とちょうどm回一致\n    {m,}\n直前の表現とm回以上一致\n    {m,n}\n直前の表現とm回以上n回以下の一致\n  \n  \n  \n\n\n\n\n\n限量詞をつけない場合はちょうど1回一致である。\n　これらの限量詞を使うと、指定した条件に一致する範囲において貪欲マッチング (greedy matching) が実行される。貪欲マッチングとは、パタンに一致するもののうち、できるだけ長いものとマッチしようとする性質である。たとえば、以下の例を見てみよう。\n\ncats &lt;- c(\"猫猫猫猫猫猫虎猫猫虎\")\nstr_extract(cats, pattern = \".+虎\")\n\n[1] \"猫猫猫猫猫猫虎猫猫虎\"\n\n\n限量詞+で「何らかの文字」が1回以上出現した後に「虎」が1回（限量詞がないので、ちょうど1回）出現するパタンを抜き出したところ、先頭の猫から途中の虎を1回含んで最後の猫までを貪欲に抜き出した。\n　同様に、次の例を見てみよう。\n\nstr_extract(cats, pattern = \"猫+\\\\w+\")\n\n[1] \"猫猫猫猫猫猫虎猫猫虎\"\n\n\nこの例では、限量詞+で「猫」が1回以上出現した後に「何らかの文字」が1回以上出現するパタンを抜き出したところ、先頭の「猫」から6個の猫が貪欲に抜き出された後に、1回以上の何らかの文字として「虎猫猫虎」が抜き出された。結果として、文字列全体が抽出された。\n　では、「猫虎」という2文字だけを抜き出したいときはどうすればいいのだろうか。そのような処理には、怠惰マッチング (lazy matching) を使う。怠惰マッチングを実行する際には、限量詞の後に? を付ける。 　 　たとえば、次のようにする。\n\nstr_extract(cats, pattern = \".+?虎\")\n\n[1] \"猫猫猫猫猫猫虎\"\n\n\n限量詞+で「何らかの文字」が1回以上出現した後に「虎」が1回というパタンを指定しているが、前半の「1回以上」の部分を+?として怠惰マッチングにした効果として、（2回目ではなく）1回目の「虎」まででマッチングが終了している。ただし、「虎」の前についている「猫」の個数は1個ではないので注意が必要である。\n　同様に、次の例を見てみよう。\n\nstr_extract(cats, pattern = \"猫+?\\\\w+?\")\n\n[1] \"猫猫\"\n\n\nここでは、「猫」を1回以上怠惰にマッチした後に、何らかの文字を1回以上怠惰にマッチするという指示をしている。結果として、最初の2文字「猫猫」の時点で条件を満たし、マッチングが完了している。\n　+? だけでなく、*?、??、{m,n}? なども怠惰マッチングとして利用できる。\n　例を用いて、正規表現の使い方をもう少し確認してみよう。練習のために、似たような文字列をいくつか含むベクトル y_names を用意する。\n\ny_names &lt;- c(\"Yada\", \"Yano\", \"Yamada\", \"Yamaji\", \"Yamamoto\", \n             \"Yamashita\", \"Yamai\", \"Yanai\", \"Yanagi\", \"Yoshida\")\n\nこの中から、“Ya.a.+” というパタンに一致する文字列のみ抜き出そう（結果を見やすくするために、unlist()を使ってベクトルにする）。\n\ny_names |&gt; \n  str_extract_all(pattern = \"Ya.a.+\") |&gt; \n  unlist()\n\n[1] \"Yamada\"    \"Yamaji\"    \"Yamamoto\"  \"Yamashita\" \"Yamai\"     \"Yanai\"    \n[7] \"Yanagi\"   \n\n\nこれらの文字列のみが抜き出された理由はわかるだろうか？たとえば、“Yada” が抜き出されなかったのはなぜだろうか？それは、パタンで指定した”Ya.a.+” の”.+“が、”Ya.a”の後に何らかの文字が1回以上出現することを要求しているからである。 したがって、その部分を”.?“に変えると、結果が変わる。\n\ny_names |&gt; \n  str_extract_all(pattern = \"Ya.a.?\") |&gt; \n  unlist()\n\n[1] \"Yada\"  \"Yamad\" \"Yamaj\" \"Yamam\" \"Yamas\" \"Yamai\" \"Yanai\" \"Yanag\"\n\n\n　他のパタンもいくつか試してみよう。\n\ny_names |&gt; \n  str_extract_all(pattern = \"Ya.a.?i\") |&gt; \n  unlist()\n\n[1] \"Yamaji\" \"Yamai\"  \"Yanai\"  \"Yanagi\"\n\n\n\ny_names |&gt; \n  str_extract_all(pattern = \"Y.+da\") |&gt; \n  unlist()\n\n[1] \"Yada\"    \"Yamada\"  \"Yoshida\"\n\n\n\ny_names |&gt; \n  str_extract_all(pattern = \"Yama.+t.?\") |&gt; \n  unlist()\n\n[1] \"Yamamoto\"  \"Yamashita\"\n\n\n\ny_names |&gt; \n  str_extract_all(pattern = \"Ya[:alpha:]{4}$\") |&gt; \n  unlist()\n\n[1] \"Yamada\" \"Yamaji\" \"Yanagi\"\n\n\n\ny_names |&gt; \n  str_extract_all(pattern = \"^\\\\w{6,}$\") |&gt; \n  unlist()\n\n[1] \"Yamada\"    \"Yamaji\"    \"Yamamoto\"  \"Yamashita\" \"Yanagi\"    \"Yoshida\"  \n\n\n\ny_names |&gt; \n  str_extract_all(pattern = \"^[:alpha:]{6,8}$\") |&gt; \n  unlist()\n\n[1] \"Yamada\"   \"Yamaji\"   \"Yamamoto\" \"Yanagi\"   \"Yoshida\" \n\n\n\ny_names |&gt; \n  str_extract_all(pattern = \"\\\\w+m\\\\w+\") |&gt; \n  unlist()\n\n[1] \"Yamada\"    \"Yamaji\"    \"Yamamoto\"  \"Yamashita\" \"Yamai\"    \n\n\n\n\n17.3.2 文字列操作の例\n例として、全国の市区役所と町村役場のデータ Offices.csvを読み込んで利用する。\n\nOffices &lt;- read_csv(\"Data/Offices.csv\")\n\nRows: 1864 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (5): Code, Name, Zip, Address, Tel\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nhead(Offices, n = 3)\n\n# A tibble: 3 × 5\n  Code  Name   Zip      Address                        Tel         \n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;                          &lt;chr&gt;       \n1 01100 札幌市 060-8611 北海道札幌市中央区北1条西2丁目 011-211-2111\n2 01202 函館市 040-8666 北海道函館市東雲町4-13         0138-21-3111\n3 01203 小樽市 047-8660 北海道小樽市花園2-12-1         0134-32-4111\n\n\nこのデータフレームには5つの列がある。このうち、Addressに注目しよう。この列には、役所・役場の住所が記録されている。\n\nOffices$Address[1:5]\n\n[1] \"北海道札幌市中央区北1条西2丁目\" \"北海道函館市東雲町4-13\"        \n[3] \"北海道小樽市花園2-12-1\"         \"北海道旭川市6条通9丁目\"        \n[5] \"北海道室蘭市幸町1-2\"           \n\n\n練習として、ここから都道府県名のみを抜き出してみよう。 当然ながら、都道府県名の末尾は「都」「道」「府」「県」のいずれかなので、「何らかの文字列を1回以上 (\\\\w+)」含み、その後に「都または道または府まはた県を1回 ([都道府県])」というパタンを試してみよう（実は、これはうまくいかない）。 各都道府県を1回だけ抜き出すために、最後にunique()を使う。\n\ntry1 &lt;- Offices |&gt; \n  pull(Address) |&gt; \n  str_extract(pattern = \"\\\\w+[都道府県]\") |&gt; \n  unique()\nlength(try1)\n\n[1] 111\n\n\n得られた都道府県の数が111になっており、「失敗」したことがわかる。結果を一部見てみよう。\n\ntry1[1:10]\n\n [1] \"北海道\"                              \n [2] \"北海道寿都郡寿都\"                    \n [3] \"北海道寿都\"                          \n [4] \"北海道虻田郡留寿都村字留寿都\"        \n [5] \"北海道中川郡音威子府村字音威子府\"    \n [6] \"北海道常呂郡訓子府\"                  \n [7] \"青森県\"                              \n [8] \"青森県下北郡大間町大字大間字奥戸下道\"\n [9] \"青森県三戸郡三戸町大字在府\"          \n[10] \"青森県三戸郡階上町大字道\"            \n\n\n抽出したすべての文字列の末尾が「都道府県」で終わっている。 つまり、私たちのRが（いつも通り！）私たちの指示に従ってくれたという意味において、この結果は決して失敗ではない。しかし、都道府県名のみを抽出するという私たちの希望通は叶えられなかった。 パタンの指示がまずかったのだ。\n　\\\\w+[都道府県]というパタン指示では、\\\\w+の部分が貪欲マッチングになっている。 そのため、[都道府県]という文字を最後に含む文字列のうち、最も長い文字列が抽出されたのだ。\n　貪欲マッチングを怠惰マッチングに変えて、もう1度試してみよう。\n\ntry2 &lt;- Offices |&gt; \n  pull(Address) |&gt; \n  str_extract(pattern = \"\\\\w+?[都道府県]\") |&gt; \n  unique()\nlength(try2)\n\n[1] 47\n\n\n47の都道府県が抽出されたようだ。果たして、うまくいったのだろうか。 確認してみよう。\n\ntry2\n\n [1] \"北海道\"   \"青森県\"   \"岩手県\"   \"宮城県\"   \"秋田県\"   \"山形県\"  \n [7] \"福島県\"   \"茨城県\"   \"栃木県\"   \"群馬県\"   \"埼玉県\"   \"千葉県\"  \n[13] \"東京都\"   \"神奈川県\" \"新潟県\"   \"富山県\"   \"石川県\"   \"福井県\"  \n[19] \"山梨県\"   \"長野県\"   \"岐阜県\"   \"静岡県\"   \"愛知県\"   \"三重県\"  \n[25] \"滋賀県\"   \"京都\"     \"大阪府\"   \"兵庫県\"   \"奈良県\"   \"和歌山県\"\n[31] \"鳥取県\"   \"島根県\"   \"岡山県\"   \"広島県\"   \"山口県\"   \"徳島県\"  \n[37] \"香川県\"   \"愛媛県\"   \"高知県\"   \"福岡県\"   \"佐賀県\"   \"長崎県\"  \n[43] \"熊本県\"   \"大分県\"   \"宮崎県\"   \"鹿児島県\" \"沖縄県\"  \n\n\nこの結果には1つ問題がある。基本的には都道府県名が「都道府県」までを含めて抽出されているが、京都府のみ「京都」になってしまった。これは、京都の「都」が「都道府県」にマッチしたためである。今回のパタン指示の問題はどこにあったのだろうか。問題は、「都」の前の「京」のみで、怠惰マッチングである\"\\\\w+?に合致してしまった点にある。\n　こういうときには、自分がもっている知識が役に立つことがある。私たちは、日本の都道府県名（末尾の[都道府県]を除く）が、2文字または3文字であることを知っている。この知識を使えば、「京」という1文字だけが取り出されるパタンを除外することができる。2文字以上3文字以下で怠惰マッチングを実行するために{2,3}?という限量詞を使う。\n\ntry3 &lt;- Offices |&gt; \n  pull(Address) |&gt; \n  str_extract(pattern = \"\\\\w{2,3}?[都道府県]\") |&gt; \n  unique()\nlength(try3)\n\n[1] 47\n\ntry3\n\n [1] \"北海道\"   \"青森県\"   \"岩手県\"   \"宮城県\"   \"秋田県\"   \"山形県\"  \n [7] \"福島県\"   \"茨城県\"   \"栃木県\"   \"群馬県\"   \"埼玉県\"   \"千葉県\"  \n[13] \"東京都\"   \"神奈川県\" \"新潟県\"   \"富山県\"   \"石川県\"   \"福井県\"  \n[19] \"山梨県\"   \"長野県\"   \"岐阜県\"   \"静岡県\"   \"愛知県\"   \"三重県\"  \n[25] \"滋賀県\"   \"京都府\"   \"大阪府\"   \"兵庫県\"   \"奈良県\"   \"和歌山県\"\n[31] \"鳥取県\"   \"島根県\"   \"岡山県\"   \"広島県\"   \"山口県\"   \"徳島県\"  \n[37] \"香川県\"   \"愛媛県\"   \"高知県\"   \"福岡県\"   \"佐賀県\"   \"長崎県\"  \n[43] \"熊本県\"   \"大分県\"   \"宮崎県\"   \"鹿児島県\" \"沖縄県\"  \n\n\nこれで、市区町村役場（所）の住所から、47都道府県の名前を抽出することができた。\nここから、末尾の[道府県]を取り除いてみよう（北海道はそのまま残す）。str_replace() を使って、特定の文字列を\"\"（つまり、何も含まない文字列）に置換 (replace) する。\n\ntry3 |&gt; \n  str_replace(pattern = \"[都府県]\",\n              replacement = \"\")\n\n [1] \"北海道\" \"青森\"   \"岩手\"   \"宮城\"   \"秋田\"   \"山形\"   \"福島\"   \"茨城\"  \n [9] \"栃木\"   \"群馬\"   \"埼玉\"   \"千葉\"   \"東京\"   \"神奈川\" \"新潟\"   \"富山\"  \n[17] \"石川\"   \"福井\"   \"山梨\"   \"長野\"   \"岐阜\"   \"静岡\"   \"愛知\"   \"三重\"  \n[25] \"滋賀\"   \"京府\"   \"大阪\"   \"兵庫\"   \"奈良\"   \"和歌山\" \"鳥取\"   \"島根\"  \n[33] \"岡山\"   \"広島\"   \"山口\"   \"徳島\"   \"香川\"   \"愛媛\"   \"高知\"   \"福岡\"  \n[41] \"佐賀\"   \"長崎\"   \"熊本\"   \"大分\"   \"宮崎\"   \"鹿児島\" \"沖縄\"  \n\n\nほとんどの都道府県については意図通りの結果が得られたが、「京都府」については「都」が取り除かれて「京府」になってしまった。これを防ぐためには、[道府県]が末尾にあることを$で指定すればよい。次のようにする。\n\ntry3 |&gt; \n  str_replace(pattern = \"[都府県]$\",\n              replacement = \"\")\n\n [1] \"北海道\" \"青森\"   \"岩手\"   \"宮城\"   \"秋田\"   \"山形\"   \"福島\"   \"茨城\"  \n [9] \"栃木\"   \"群馬\"   \"埼玉\"   \"千葉\"   \"東京\"   \"神奈川\" \"新潟\"   \"富山\"  \n[17] \"石川\"   \"福井\"   \"山梨\"   \"長野\"   \"岐阜\"   \"静岡\"   \"愛知\"   \"三重\"  \n[25] \"滋賀\"   \"京都\"   \"大阪\"   \"兵庫\"   \"奈良\"   \"和歌山\" \"鳥取\"   \"島根\"  \n[33] \"岡山\"   \"広島\"   \"山口\"   \"徳島\"   \"香川\"   \"愛媛\"   \"高知\"   \"福岡\"  \n[41] \"佐賀\"   \"長崎\"   \"熊本\"   \"大分\"   \"宮崎\"   \"鹿児島\" \"沖縄\"  \n\n\nこれで望み通りの結果が得られた。\n次に、Offices の Telの列に注目しよう。 この列には、電話番号が記録されている。 ハイフンで番号が区切られているので、それを利用して市外局番を抜き出してみよう。 数字を1文字以上の怠惰マッチング (\\\\d+?) の後に、ハイフン1つとマッチング (-) するパタンを指定する。ただし、必要なのは数字だけなので、ハイフンまでを含む文字列を抽出した後、ハイフンを取り除く。\n\narea_code &lt;- Offices |&gt; \n  pull(Tel) |&gt; \n  str_extract(pattern = \"\\\\d+?-\") |&gt; \n  str_replace(pattern = \"-\",\n              replacement = \"\")\nhead(area_code)\n\n[1] \"011\"  \"0138\" \"0134\" \"0166\" \"0143\" \"0154\"\n\n\n0から始まる数字が抜き出されている。市外局番の桁数を調べてみよう。\n\narea_code |&gt; \n  str_length() |&gt; \n  table()\n\n\n   2    3    4    5 \n  40  500 1273   51 \n\n\n市外局番の桁数は、2桁から5桁までであることがわかる。ユニークな市外局番の個数は、\n\narea_code |&gt; \n  unique() |&gt; \n  length()\n\n[1] 379\n\n\nである。\n最後に、電話番号の下4桁を抜き出してみよう。 パタン一致の代わりに、str_sub() で最後から4文字目 (-4) から最後まで（end は指定しない）を抽出する。\n\nlast4 &lt;- Offices |&gt; \n  pull(Tel) |&gt; \n  str_sub(start = -4)\nhead(last4)\n\n[1] \"2111\" \"3111\" \"4111\" \"1111\" \"1111\" \"5151\"\n\n\n念の為、すべての結果が4桁であることを確認する。 まず、4文字であることを確認する。\n\nlast4 |&gt; \n  str_length() |&gt; \n  table()\n\n\n   4 \n1864 \n\n\nすべて4文字である。次に、すべてが数字であることを確認する。そのためにstr_count() で、特定のパタンに一致する回数を数える。ここでは、pattern = \"\\\\d\" で数字を指定し、その回数が4になることを確かめる。\n\nlast4 |&gt; \n  str_count(pattern = \"\\\\d\") |&gt; \n  table()\n\n\n   4 \n1864 \n\n\nすべの結果で数字が4回登場することが確認できた。文字の長さが4であることと合わせて、4桁の数字の抜き出しに成功したことがわかる。\nユニークな電話番号下4桁の個数は、\n\nlast4 |&gt; \n  unique() |&gt; \n  length()\n\n[1] 365\n\n\nであり、下4桁については同じ番号が多く利用されていることがわかる。\n北海道を例として、電話番号についてもう少し詳しく検討しよう。 そのために、まず北海道のデータを抜き出そう。住所 (Address) に「北海道」という文字列が含まれている行を、dplyr::filter() とstringr::str_detect() で抜き出す。\n\nH &lt;- Offices |&gt; \n  filter(str_detect(Address, pattern = \"北海道\")) \nhead(H, n = 3)\n\n# A tibble: 3 × 5\n  Code  Name   Zip      Address                        Tel         \n  &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;    &lt;chr&gt;                          &lt;chr&gt;       \n1 01100 札幌市 060-8611 北海道札幌市中央区北1条西2丁目 011-211-2111\n2 01202 函館市 040-8666 北海道函館市東雲町4-13         0138-21-3111\n3 01203 小樽市 047-8660 北海道小樽市花園2-12-1         0134-32-4111\n\ntail(H, n =3)\n\n# A tibble: 3 × 5\n  Code  Name     Zip      Address                        Tel         \n  &lt;chr&gt; &lt;chr&gt;    &lt;chr&gt;    &lt;chr&gt;                          &lt;chr&gt;       \n1 01692 中標津町 086-1197 北海道標津郡中標津町丸山2-22   0153-73-3111\n2 01693 標津町   086-1632 北海道標津郡標津町北2条西1-1-3 0153-82-2131\n3 01694 羅臼町   086-1892 北海道目梨郡羅臼町栄町100-83   0153-87-2111\n\nnrow(H)\n\n[1] 179\n\n\n北海道には179の市区町村がある。このデータに対し、先程と同じ方法で電話番号の下4桁を抽出する。\n\nH_last4 &lt;-  H |&gt; \n  pull(Tel) |&gt; \n  str_sub(start = -4)\nH_last4 |&gt; \n  unique() |&gt; \n  length()\n\n[1] 58\n\n\n179の自治体に対し、電話番号下4桁のパタンは58しかない。 下2桁はどうだろうか？\n\nH |&gt; \n  pull(Tel) |&gt; \n  str_sub(start = -2) |&gt; \n  table()\n\n\n 00  01  11  12  20  21  22  28  30  31  34  36  41  45  51  61  71  75  81  91 \n  3   5 113   1   2  19   1   1   1  15   2   1   4   2   2   2   1   1   2   1 \n\n\n下2桁は全部で20パタンあるが、ほとんどの自治体で下2桁が「11」になっていることがわかる。 入力しやすい電話番号にしようという配慮だろう。"
  },
  {
    "objectID": "string.html#文書データの分析",
    "href": "string.html#文書データの分析",
    "title": "17  文字列の処理",
    "section": "17.4 文書データの分析",
    "text": "17.4 文書データの分析\n「吾輩は猫である」\n　にゃーにゃーにゃにゃーにゃにゃにゃ！にゃーにゃー！"
  },
  {
    "objectID": "visualization1.html#sec-visual1-packages",
    "href": "visualization1.html#sec-visual1-packages",
    "title": "18  可視化 [理論]",
    "section": "18.1 可視化のためのパッケージ",
    "text": "18.1 可視化のためのパッケージ\nRによる可視化は様々な方法がありますが、可視化のために使うパッケージとして代表的なものは (1) パッケージを使わない方法、(2) {latticeパッケージ、(3) {ggplot2}パッケージがあります。ここでは、以下のデータ ( 表 18.1 )を可視化しながら、それぞれの特徴について簡単に解説します。\n\n\n\n\n表 18.1: サンプルデータの中身 (最初の10行のみ表示)\n\n\nCountry\nPPP\nHDI\nOECD\n\n\n\n\nAfghanistan\n2125\n0.496\n非加盟国\n\n\nAlbania\n13781\n0.791\n非加盟国\n\n\nAlgeria\n11324\n0.759\n非加盟国\n\n\nAngola\n6649\n0.574\n非加盟国\n\n\nArgentina\n22938\n0.830\n非加盟国\n\n\nArmenia\n12974\n0.760\n非加盟国\n\n\nAustralia\n50001\n0.938\n加盟国\n\n\nAustria\n55824\n0.914\n加盟国\n\n\nAzerbaijan\n14257\n0.754\n非加盟国\n\n\nBahrain\n43624\n0.838\n非加盟国\n\n\n\n\n\n\n\n\nこのデータは各国 (Country) の一人当たり購買力平価基準GDP (PPP)、人間開発指数 (HDI)、OECD加盟有無 (OECD)の変数で構成されています。このデータを使って横軸はPPP、縦軸はHDIとし、OECDの値によって色分けしたグラフを作成します。\n\n18.1.1 Base R\nRは統計学、データ分析に特化したプログラミング言語であるため、別途のパッケージなしで作図が可能です。後ほど紹介する{lattice}や{ggplot2}を用いた作図とは違って、Base Rによる作図は、紙にペンでグラフを書くイメージに近いです。キャンバスを用意し、そこにペンで点や線を描く感じです。これはレイヤーという概念を導入した{ggplot2}に近いかも知れませんが、{ggplot2}はレイヤーを変更出来る一方、Base Rは図が気に入らない場合、一からやり直しです。つまり、キャンバスに引いた線や点は消すことができません。また、作成した図はオブジェクトとして保存することが出来ないため、もう一度図示するためには一から書く必要があります。Base Rによる作図は短所だけでなく、メリットもあります。まず、パッケージを必要としないため、Rインストール直後から使える点です。そして、{lattice}や{ggplot2}よりも速いです。他にも人によってはBase Rの方がシンプルでかっこいいという方もいますが、これは好みの問題でしょう。\n以下の 図 18.1 はBase Rを使った散布図の例です。\n\n# Base Rを用いた作図の例\nplot(x = Country_df$PPP, y = Country_df$HDI, pch = 19, \n     col = ifelse(Country_df$OECD == \"加盟国\", \"red\", \"blue\"),\n     xlab = \"一人当たり購買力平価GDP (USD)\", ylab = \"人間開発指数\")\nlegend(\"bottomright\", pch = 19,\n       legend = c(\"OECD加盟国\", \"OECD非加盟国\"), \n       col    = c(\"red\", \"blue\"))\n\n\n\n\n図 18.1: Base Rによるグラフ\n\n\n\n\n\n\n18.1.2 {lattice}パッケージ\n{lattice}はDeepayan Sarkarによって開発された可視化パッケージです。このパッケージの最大特徴は「1つの関数で可視化が出来る」点です。作図に必要な様々な情報が1つの関数内に全て入ります。むろん、指定しない情報に関しては多くの場合、自動的に処理してくれます。\n図 18.2 を{lattice}を使って作る場合は以下のようなコードになります。\n\n# latticeを用いた作図の例\nxyplot(HDI ~ PPP, data = Country_df,\n       group = OECD, pch = 19, grid = TRUE,\n       auto.key = TRUE,\n       key = list(title     = \"OECD加盟有無\",\n                  cex.title = 1,\n                  space     = \"right\",\n                  points    = list(col = c(\"magenta\", \"cyan\"),\n                                   pch = 19),\n                  text      = list(c(\"加盟国\", \"非加盟国\"))), \n       xlab = \"一人当たり購買力平価GDP (USD)\", ylab = \"人間開発指数\")\n\n\n\n\n図 18.2: {lattice}によるグラフ\n\n\n\n\n1つの関数で全てを処理するので、関数が非常に長くなり、人間にとって読みやすいコードにはなりにくいのが短所です。しかし、{lattice}はBase Rでは出来ない、プロットのオブジェクトとしての保存ができます。Base Rは出来上がったプロットをオブジェクトとして保存することが出来ず、同じ図をもう一回出力するためには、改めてコードを書く必要があります。しかし、{lattice}はオブジェクトとして保存ができるため、いつでもリサイクルが可能です。他にも、{lattice}は条件付きプロットの作成において非常に強力です。しかし、これらの特徴は今は{ggplot2}も共有しているため、{lattice}独自の長所とは言いにくいです。\n\n\n18.1.3 {ggplot2}パッケージ\n{ggplot2}はHadely Wickhamが大学院生の時に開発した可視化パッケージであり1、 Wilkinson (2005) の「グラフィックの文法 (grammer of graphics)」の思想をR上で具現化したものです。グラフィックの文法という思想は今は{ggplot2}以外にもPlotlyやTableauなどでも採用されています。\nグラフィックの文法は後ほど詳細に解説しますが、{ggplot2}による作図の特徴は「レイヤーを重ねる」ことです。グラフの様々な要素をそれぞれ1つの層 (layer)と捉え、これを重ねられていくことでグラフが出来上がる仕組みです。これはBase Rの書き方に似ています。たとえば、{ggplot2}を使って 図 18.3 を作る場合、以下のようなコードになります。\n\n# ggplot2を用いた作図の例\nggplot(data = Country_df) +\n  geom_point(aes(x = PPP, y = HDI, color = OECD)) +\n  labs(x = \"一人あたり購買力平価GDP (USD)\", y = \"人間開発指数\",\n       color = \"OECD加盟有無\") +\n  theme_bw()\n\n\n\n\n図 18.3: {ggplot2}によるグラフ\n\n\n\n\nこのように{ggplot2}による作図コードはBase Rや{lattice}に比べ、読みやすいのが特徴です。また、書く手間も大きく省かれる場合が多く、結果として出力されるグラフも綺麗です（これは好みによりますが）。しかし、{ggplot2}にも限界はあり、代表的なものとして (1) 3次元グラフが作成でないこと、(2) 処理速度が遅い点があります。後者は多くの場合においてあまり気にならない程度ですが、3次元プロットが必要な場合はlatticeや別途のパッケージを使う必要があります。しかし、社会科学において3次元プロットが使われる機会は少なく、2次元平面であっても3次元以上のデータを表現することも可能です。本書では{ggplot2}を用いた可視化方法のみについて解説していきます。"
  },
  {
    "objectID": "visualization1.html#sec-visual1-ggplot",
    "href": "visualization1.html#sec-visual1-ggplot",
    "title": "18  可視化 [理論]",
    "section": "18.2 グラフィックの文法",
    "text": "18.2 グラフィックの文法\n\n18.2.1 グラフィックの文法\n本書では特別な事情がない限り、{ggplot2}による可視化のみを扱います。既に{ggplot2}のggが「グラフィックの文法 (grammar of graphics)」だと説明しましたが、この概念は Wilkinson (2005) によって提唱された比較的新しいものであり、{ggplot2}はHadley先生がグラフィックの文法に則った作図のプロセスをRで具現化したものです。\nグラフィックスの文法とは、グラフを構造化された方法で記述し、レイヤーを積み重ねることによってグラフを構築するフレームワークです。グラフは様々な要素で構成されています。横軸と縦軸、点、線、グラフ、凡例、図のタイトルなどがあります。横軸や縦軸は線の太さ、目盛りの間隔、数字の大きさなどに分割することも可能です。このように1つのグラフは数十、数百以上の要素の集合です。これら一つ一つの要素をレイヤーとして捉え、それを積み重ねることでグラフを作成します。これが簡単な{ggplot2}による作図のイメージですが、以下でもうちょっと目に見える形でこれを解説していきます。\n\n\n18.2.2 ggplot2のイメージ\nそれでは{ggplot2}によるグラフが出来上がる過程を見ていきます。例えば、以下のようなデータセットdfがあるとします。変数は年度を表すYear、鉄道事業者のタイプを表すCompany_Type1、一日利用者数の平均値を表すPがあります。例えば、2行目は2011年度におけるJRが管理する駅の一日平均利用者数が約7399名であることを意味します。\n\n\n\n\n表 18.2: サンプルデータの中身 (最初の10行のみ表示)\n\n\nYear\nCompany_Type1\nP\n\n\n\n\n2011\nその他\n4769\n\n\n2011\nJR\n7399\n\n\n2011\n大手私鉄\n19421\n\n\n2011\n準大手私鉄\n7683\n\n\n2012\nその他\n5014\n\n\n2012\nJR\n7289\n\n\n2012\n大手私鉄\n21286\n\n\n2012\n準大手私鉄\n10471\n\n\n2013\nその他\n5154\n\n\n2013\nJR\n7383\n\n\n\n\n\n\n\n\nこのデータdfを使って 図 18.4 のようなグラフを作成します。以下では作図のコードも載っていますが、詳しく理解しなくても結構です。理解しなくてもいいですが、必ずコードには目を通し、説明文との対応を自分で考えてください。\n\nggplot(data = df) +\n  geom_line(aes(x = Year, y = P, color = Company_Type1), \n            linewidth = 1) +\n  geom_point(aes(x = Year, y = P, color = Company_Type1), \n             size = 3, shape = 21, fill = \"white\") +\n  labs(x = \"年度\", y = \"平均利用者数 (人/日)\", color = \"事業者区分\") +\n  scale_x_continuous(breaks = 2011:2017, labels = 2011:2017) +\n  theme_minimal(base_size = 12)\n\n\n\n\n図 18.4: 鉄道駅の事業者区分による平均利用者数の推移\n\n\n\n\n\nまずは、グラフに使用するデータを指定し、空のキャンバスを用意します。\n\n\nggplot(data = df)\n\n\n\n\n図 18.5: 第1層: キャンバスを用意し、使用するデータはdf\n\n\n\n\n\n折れ線グラフを作成します。折れ線グラフは点の位置を指定すると、勝手に点と点の間を線で繋いでぐれます。したがって、必要な情報は点の情報ですが、横軸 (X軸)はYear、縦軸 (Y軸)はPにした点を出力します。この点をCompany_Type1ごとに色分けします。これで折れ線グラフが出来上がります。線の太さは1にします。\n\n\nggplot(data = df) +\n  geom_line(aes(x = Year, y = P, color = Company_Type1), \n            linewidth = 1)\n\n\n\n\n図 18.6: 第2層: X軸はYear、Y軸はPにし、Company_type1ごとに色分けした折れ線グラフを作成し、線の太さは1とする。\n\n\n\n\n\n続いて、折れ線グラフに散布図を載せます。これは線が引かれていない折れ線グラフと同じです。したがって、横軸、縦軸、色分けの情報は同じです。しかし、点と線が重なると点がよく見えないこともあるので、点の大きさを3にし、形は枠線付きの点にします。点の中身は白塗りをします。つまり、Company_Type1によって変わるのは、点の枠線です。\n\n\nggplot(data = df) +\n  geom_line(aes(x = Year, y = P, color = Company_Type1), \n            linewidth = 1) +\n  geom_point(aes(x = Year, y = P, color = Company_Type1), \n             size = 3, shape = 21, fill = \"white\")\n\n\n\n\n図 18.7: 第3層: X軸はYear、Y軸はPにし、Company_type1ごとに色分けした散布図を作成する。点の大きさは3、点のタイプは21 (外線付き)、点の中身の色は白よする。\n\n\n\n\n\n横軸と縦軸、そして凡例のタイトルを日本語に直します。日本語のレポート、論文なら図表も日本語にすべきです。横軸のラベルは\"年度\"、縦軸のラベルは\"平均利用者数 (人/日)\"にします。色の凡例タイトルは\"事業者区分\"にします。\n\n\nggplot(data = df) +\n  geom_line(aes(x = Year, y = P, color = Company_Type1), \n            linewidth = 1) +\n  geom_point(aes(x = Year, y = P, color = Company_Type1), \n             size = 3, shape = 21, fill = \"white\") +\n  labs(x = \"年度\", y = \"平均利用者数 (人/日)\", color = \"事業者区分\")\n\n\n\n\n図 18.8: 第4層: X軸、Y軸のラベルをそれぞれ「年度」、「平均利用者数 (人/日)」に凡例のcolorのラベルは「事業者区分」にする\n\n\n\n\n\n横軸のスケールを修正します。横軸は連続 (continuous)変数です。今の目盛りは2012、2014、2016になっていますが、これを1年刻みにし、それぞれの目盛りのラベルも2011、2012、2013、…にします。\n\n\nggplot(data = df) +\n  geom_line(aes(x = Year, y = P, color = Company_Type1), \n            linewidth = 1) +\n  geom_point(aes(x = Year, y = P, color = Company_Type1), \n             size = 3, shape = 21, fill = \"white\") +\n  labs(x = \"年度\", y = \"平均利用者数 (人/日)\", color = \"事業者区分\") +\n  scale_x_continuous(breaks = 2011:2017, labels = 2011:2017)\n\n\n\n\n図 18.9: 第5層: 連続変数で構成されたX軸を調整する目盛りは2011, 2012, …, 2017とし、ラベルも2011, 2012, …, 2017に\n\n\n\n\n\nテーマを変更してみます。今回は{ggplot2}がデフォルトで提供しているminimalに変更し、フォントサイズは12にします。\n\n\nggplot(data = df) +\n  geom_line(aes(x = Year, y = P, color = Company_Type1), \n            linewidth = 1) +\n  geom_point(aes(x = Year, y = P, color = Company_Type1), \n             size = 3, shape = 21, fill = \"white\") +\n  labs(x = \"年度\", y = \"平均利用者数 (人/日)\", color = \"事業者区分\") +\n  scale_x_continuous(breaks = 2011:2017, labels = 2011:2017) +\n  theme_minimal(base_size = 12)\n\n\n\n\n図 18.10: 第6層: テーマをminimalに指定し、フォントサイズは12に変更\n\n\n\n\n\nこれで図は完成ですが、コードを少し修正します。現在、折れ線グラフ（geom_line()）と散布図（geom_point()）はaes()関数内において、同じ情報を共有しています。この場合、それぞれのレイヤーではなく、ggplot()内で定義しておくと、コードをより短くすることができます。また、作図に使うデータ（ここではdf）はggplot()関数の第1引数であるので、パイプ演算子を使っても良いでしょう。\n\n\ndf |&gt;\n  ggplot(aes(x = Year, y = P, color = Company_Type1)) +\n  geom_line(linewidth = 1) +\n  geom_point(size = 3, shape = 21, fill = \"white\") +\n  labs(x = \"年度\", y = \"平均利用者数 (人/日)\", color = \"事業者区分\") +\n  scale_x_continuous(breaks = 2011:2017, labels = 2011:2017) +\n  theme_minimal(base_size = 12)\n\n\n\n\n図 18.11: コードの修正\n\n\n\n\nこれで図が出来上がりました。このように{ggplot2}では図の要素をレイヤーと捉えます。このレイヤーを生成する関数がggplot()、geom_line()、lab()などであり、これらを+演算子を用いて重ねていきます。このイメージを図にすると 図 18.12 のように表現できます。\n\n\n\n図 18.12: {ggplot2}の図が出来上がるまで (全体像)\n\n\nそれでは、グラフは具体的にどのような要素で構成されているかを以下で解説します。"
  },
  {
    "objectID": "visualization1.html#sec-visual1-structure",
    "href": "visualization1.html#sec-visual1-structure",
    "title": "18  可視化 [理論]",
    "section": "18.3 グラフィックの構成要素",
    "text": "18.3 グラフィックの構成要素\n{ggplot2}におけるプロット (plot)は「データ + 幾何オブジェクト + 座標系」で構成されます。\nここでいうデータは主にデータフレームまたはtibbleです。これは主にggplot()関数の第一引数と指定するか、パイプで渡すのが一般的です。ただし、{ggplot2}で作図するためには、データを予め整然データに整形する必要があります。\n幾何オブジェクト (geometry object)とは簡単に言うと図の種類です。散布図、折れ線グラフ、棒グラフ、ヒストグラムなど、{ggplot2}は様々なタイプの幾何オブジェクトを提供しており、ユーザー自作の幾何オブジェクトもRパッケージとして多く公開されています。幾何オブジェクトは関数の形で提供されており、geom_で始まるといった共通点があります。散布図はgeom_point()、折れ線グラフはgeom_line()のような関数を使います。\nこの幾何オブジェクトに線や点、棒などを表示する際には、どの変数が横軸で、どの変数が縦軸かを明記する必要があります。また、変数によって点や線の色が変わったりする場合も、どの変数によって変わるかを明記します。これを マッピング (mapping)と呼びます。また、必要に応じて位置 (position)と統計量 (stat)を明記する必要がありますが、これは指定しなくてもとりあえず何らかの図は出力されます。\n最後に座標系 (coordinate system)は幾何オブジェクトが表示される空間の特徴を定義します。最も重要な特徴は横軸と縦軸の下限と上限です。または、空間を回転することなどもできます。\n{ggplot2}の図は以上の3つ要素を重ねることで出来ます。\n\n\n\n図 18.13: {ggplot2}の構造の例\n\n\nただし、この中で座標系は適切だと判断される座標系に設定してくれるため、ユーザーが必ず指定すべきものはデータと幾何オブジェクトのみです。また、幾何オブジェクトはマッピングを含んでおり、これも必ず指定する必要があります。したがって、{ggplot2}で作図するための最小限のコードは以下のようになります。\n\n# ggplot2におけるプロットの基本形\n# データはggplotの第一引数と使う場合が多いため、「data =」は省略可能\n# マッピングは主に幾何オブジェクトの第一引数として使うため、「mapping =」は省略可能\nggplot(data = データ名) +\n  幾何オブジェクト関数(mapping = aes(マッピング))\n\n# パイプを使う場合\nデータ名 |&gt;\n  ggplot() +\n  幾何オブジェクト関数(mapping = aes(マッピング))\n\n注意すべき点は{ggplot2}においてレイヤーを重ねる際は|&gt;でなく、+を使う点です。パイプ演算子は左側の結果を右に渡す意味を持ちますが、{ggplot2}はデータを渡すよりも、レイヤーを足していくイメージですから、+を使います。\n以下は{ggplot2}の必須要素であるデータと幾何オブジェクト、マッピングなどについて解説し、続いて図は見栄を調整するための関数群を紹介します。\n\n18.3.1 データ\n作図のためにはデータはなくてはなりません。データはdata.frmae型、またはtibble型であり、一般的にはggplot()関数の第一引数として指定します。例えば、ggplot(data = データ名)のように書いてもいいですし、data =は省略して、ggplot(データ名)でも構いません。\nデータを指定するもう一つの方法はパイプ演算子を使うことです。この場合、データ名 |&gt; ggplot()のように書きます。書く手間はほぼ同じですが、dplyrやtidyrなどでデータを加工し、それをオブジェクトとして保存せずにすぐ作図に使う場合は便利です。\n実際、使う機会は少ないですが、1つのグラフに複数のデータを使う場合もあります。{ggplot2}は複数のデータにも対応していますが、とりあえずメインとなるデータをggplot()に指定し、追加的に必要なデータは今度説明する幾何オブジェクト関数内で指定します。この方法については適宜必要に応じて説明します。\n\n\n18.3.2 幾何オブジェクト\nしかし、データを指定しただけで図が出来上がるわけではありません。指定したデータを使ってどのような図を作るかも指定する必要があります。この図のタイプが幾何オブジェクト (geometry object)であり、geom_*()関数で表記します。たとえば、散布図を作る場合、\n\nデータ名 |&gt;\n  ggplot() +\n  geom_point()\n\nのように指定します。以上のコードは「あるデータを使って (データ名 |&gt;)、キャンバスを用意し (ggplot() +)、散布図を作成する (geom_point())。」と読むことが出来ます。\nまた、この幾何オブジェクトは重ねることも可能です。よく見る例としては、散布図の上に回帰曲線 (geom_smooth())や折れ線グラフ (geom_line())を重ねたものであり、これらの幾何オブジェクトは+で繋ぐことが可能です。\n{ggplot2}が提供する幾何オブジェクト関数は散布図だけでなく、棒グラフ (geom_bar())、ヒストグラム (geom_histogram())、折れ線グラフ (geom_line())、ヒートマップ (geom_tile())など、データ分析の場面で使われるほとんどの種類が含まれています。他にもユーザーが作成した幾何オブジェクトもパッケージとして多く公開されています（たとえば、非巡回有向グラフ作成のための{ggdag}、ネットワークの可視化のための{ggnetwork}など）。\n\n\n18.3.3 マッピング\nどのようなデータを使って、どのような図を作るかを指定した後は、変数を指定します。たとえば、散布図の場合、各点の横軸と縦軸における位置情報が必要です。ヒストグラムならヒストグラムに必要な変数を指定する必要があります。このようにプロット上に出力されるデータの具体的な在り方を指定するのをマッピング (mapping)と呼びます。\nマッピングは幾何オブジェクト関数内で行います。具体的にはgeom_*()内にmapping = aes(マッピング)で指定します。aes()も関数の一種です。散布図ならgeom_point(mapping = aes(x = X軸の変数, y = Y軸の変数))です。ヒストグラムなら横軸のみを指定すればいいのでgeom_histogram(mapping = aes(x = 変数名))で十分です。マッピングは一般的にはgeom_*()の第一引数として渡しますが、この場合、mapping =は省略可能です。\nマッピングに必要な変数、つまりaes()に必要な引数は幾何オブジェクトによって異なります。散布図や折れ線グラフならX軸とY軸の情報が必須であるため、2つ必要です (xとy)。ヒストグラムは連続変数の度数分布表を自動的に作成してからグラフが作られるから1つが必要です (x)。また、等高線図の場合、高さの情報も必要なので3つの変数が必要です (xとy、z)。これらの引数は必ず指定する必要があります。\n以上の引数に加え、追加のマッピング情報を入れることも可能です。たとえば、鉄道事業者ごとの平均利用者数を時系列で示した最初の例を考えてみましょう。これは折れ線グラフですので、mapping = aes(x = 年度, y = 利用者数)までは必須です。しかし、この図にはもう一つの情報がありますね。それは事業者のタイプです。事業者のタイプごとに線の色を変えたい場合は、aes()内にcolor = 事業者のタイプを、線の種類を変えたい場合は、linetype = 事業者のタイプのように引数を追加します。こうすると2次元のプロットに3次元の情報 (年度、利用者数、事業者タイプ)を乗せることが可能です。むろん、4次元以上にすることも可能です。たとえば、地域ごとに異なる色を、事業者タイプごとに異なる線のタイプを指定する場合は、mapping = aes(x = 年度, y = 利用者数, color = 地域, linetype = 事業者のタイプ)のように指定します。colorやlinetype以外にも大きさ (size)、透明度 (alpha)、点のタイプ (shape)、面の色 (fill)などを指定することができます。\nそれでは、最初にお見せした 図 18.4 のマッピングはどうなるでしょうか。 図 18.4 の幾何オブジェクトは折れ線グラフ (geom_line())と散布図 (geom_point())の2つです。それぞれの幾何オブジェクトのマッピング情報をまとめたのが 表 18.3 です。\n\n\n\n\n表 18.3: 図17.4のマッピング情報\n\n\n幾何オブジェクト\nマッピング要素\n変数\n引数\n\n\n\n\ngeom_line\nX軸\nYear\nx\n\n\n\nY軸\nP\ny\n\n\n\n線の色\nCompany_Type1\ncolor\n\n\ngeom_point\nX軸\nYear\nx\n\n\n\nY軸\nP\ny\n\n\n\n枠線の色\nCompany_Type1\ncolor\n\n\n\n\n\n\n\n\n先ほどマッピング引数は幾何オブジェクト関数内で指定すると言いましたが、実はggplot()内に入れ、geom_*()内では省略することも可能です。幾何オブジェクトが1つのみならどっちでも問題ありません。しかし、幾何オブジェクトが2つ以上の場合は注意が必要です。全ての幾何オブジェクトがマッピングを共有する場合はggplot()の方が書く手間が省きます。たとえば、 表 18.3 を見ると、geom_line()とgeom_point()はx、y、color引数の値が同じですから、ggplot()内にaes()を入れることも可能です。しかし、幾何オブジェクトがマッピングを共有しない場合は幾何オブジェクト関数内に別途指定する必要があります。あるいは、共有するところだけ、ggplot()に書いて、共有しない部分だけ幾何オブジェクトで指定することも可能です。したがって、上の図は以下のコードでも作成することができます。\n\n# geom_line()とgeom_point()はマッピング情報を共有しているため、\n# ggplot()内に指定\ndf |&gt;\n  ggplot(aes(x = Year, y = P, color = Company_Type1)) +\n  geom_line(size = 1) +\n  geom_point(size = 3, shape = 21, fill = \"white\") +\n  labs(x = \"年度\", y = \"平均利用者数 (人/日)\", color = \"事業者区分\") +\n  scale_x_continuous(breaks = 2011:2017, labels = 2011:2017) +\n  theme_minimal(base_size = 12)\n\n\n\n18.3.4 マッピング: その他\n以上のことさえ覚えれば、とりあえず図は作れます。最後に、必須要素ではありませんが、幾何オブジェクトに使う引数について説明します。先ほど説明しましたcolorやlinetype、sizeなどはマッピングの情報として使うことも可能ですが、aes()の外側に置くことも可能です。しかし、その挙動はかなり異なります。colorがaes()の外側にある場合は、幾何オブジェクトの全要素に対して反映されます。\nたとえば、横軸が「ゲームのプレイ時間」、縦軸が「身長」の散布図を作成しるとします ( 図 18.14 )。ここでcolor引数を追加しますが、まずはaes()の外側に入れます。\n\n# 例1: 全ての点の色が赤になる\nデータ |&gt;\n  ggplot() +\n  geom_point(aes(x = ゲームのプレイ時間, y = 身長),\n             color = \"red\")\n\n\n\n\n\n\n図 18.14: colorをaes()外側に置いた場合\n\n\n\n\nここで注目する点は\n\n散布図におけるすべての点の色がcolorで指定した色 (\"red\" = 赤)に変更された点\ncolorの引数は変数名でなく、具体的な色を指定する点\n\n以上の2点です。aes()の内側にcolorを指定する場合 ( 図 18.15 ) は、以下のように変数名を指定します。たとえば、性別ごとに異なる色を付けるとしたら、\n\n# 例2: 性別ごとに点の色が変わる\nデータ |&gt;\n  ggplot() +\n  geom_point(aes(x = ゲームのプレイ時間, y = 身長, color = 性別))\n\n\n\n\n\n\n図 18.15: colorをaes()内側に置いた場合\n\n\n\n\n以上のように書きます。aes()の内部はマッピングの情報が含まれています。言い換えると、aes()の中はある変数がグラフ上においてどのような役割を果たしているかを明記するところです。2つ目の例では性別という変数が色分けをする役割を果たすため、aes()の内側に入ります。一方、1つ目の例では色分けが行われておりません。\n\n\n18.3.5 座標系\n座標系はデータが点や線、面などで出力される空間を意味し、coord_*()関数群を用いて操作します。\n座標系のズームイン (zoom-in) やズームアウト (zoom-out) を行うcoord_cartesian()、横軸と縦軸を交換するcoord_flip()、横軸と縦軸の比率を固定するcoord_fixed()がよく使われます。座標系の説明は次章以降で詳しく解説しますが、ここでは座標系のズームインを見てみましょう。以下の 図 18.16 は各国のCOVID19の感染者数を時系列で示したものです。これを見るとアメリカ、ブラジル、インドは大変だなーくらいしかわかりません。感染者数が比較的に少ない国のデータは線としては存在しますが、なかなか区別ができません。\n\n\n\n\n\n図 18.16: ズームイン前\n\n\n\n\nここで座標系をズームインすると、一部の情報は失われますが、ズームインされた箇所はより詳細にグラフを観察できます。ズームインと言っても難しいものではありません。単に、軸の上限、下限を調整するだけです。たとえば、縦軸の上限を10万人に変更したのが 図 18.17 です。アメリカなど感染者数が10万人を超える国家の時系列情報の一部は失われましたが、日中韓などのデータはより見やすくなったかと思います2。\n\n\n\n\n\n図 18.17: ズームイン後\n\n\n\n\nまた、同じ棒グラフや散布図、折れ線グラフでも座標系を変えることによって図の見方が劇的に変わることもあります。我々にとって最も馴染みのある座標系はデカルト座標系 (直交座標系)です。このデカルト座標系に切片0、傾き1の直線を引きます。そして同じ図に対して座標系のみを極座標系 (polar coordinates system)に変更します。この2つを比較したのが 図 18.18 です。この2つの図は同じデータ、同じ変数、同じ幾何オブジェクトで構成されています。異なるのは座標系ですが、見方が劇的に変わります。\n\n\n\n\n\n図 18.18: 直交座標系と極座標系の比較 (1)\n\n\n\n\nこんな座標系を実際に使う機会は多くないかも知れませんが、極座標系は割と身近なところで見ることができます。それは積み上げ棒グラフと円グラフの関係です。 図 18.19 はデカルト座標系上の積み上げ棒グラフを極座標系に変換したものです。\n\n\n\n\n\n図 18.19: 直交座標系と極座標系の比較 (2)\n\n\n\n\n他にも軸を対数スケールなどに変換する coord_trans() 、地図の出力に使われる coord_map() や coord_sf() などがあり、適宜紹介していきます。\n\n\n18.3.6 スケール\n既に説明しました通り、{ggplot2}は様々な幾何オブジェクトがあり、これによってグラフ上におけるデータの示し方が変わります。例えば、散布図だとデータは点として表現され、折れ線グラフだと線、棒グラフやヒストグラムだと面で表現されます。これらの点、線、面などが持つ情報がスケール (scale)です。点だと縦軸上の位置、横軸上の位置が必ず含まれ、他にも点の形、点の大きさ、点の色、枠線の色、透明度などの情報を含むことが可能です。線も線が折れるポイントの横軸・縦軸上の位置、線の太さ、線の色などがあります。\nこの形、色、大きさ、太さなどを調整するためにはscale_*_*()関数群を使います。例えば、 図 18.15 の場合、点は横軸上の位置、縦軸上の位置、色の3つのスケールを持っています。横軸と縦軸は連続変数 (時間と身長)、色は名目変数 (性別)です。ここで横軸のスケールを調整するためにはscale_x_continuous()レイヤーを追加します。縦軸も同様にscale_y_continuous()を使います。ここのxとyはスケール、continuousは連続変数であることを意味します。それでは、色を調整するためにはどうすれば良いでしょうか。それはscale_color_manual()です。colorは色を、manualは手動調整を意味しますが、主に性別や都道府県のような名目変数のスケール調整に使います。\nこれらのscale_*_*()関数群は点、線、面が持つ位置情報や性別を変更することではなく、その見せ方を変更するだけです。 図 18.15 の縦軸の目盛りは「150、160、170、180」となっていますが、scale_y_continuous()を使うとこの目盛りが変わります。点の位置が変わることはありません。たとえば、以下のコードはscale_y_continuous()を使って縦軸の目盛りを5cm刻みに変更するためのコードであり、 図 18.20 はその結果です。\n\n# scale_y_continuous()の例\nデータ |&gt;\n  ggplot() +\n  geom_point(aes(x = ゲームのプレイ時間, y = 身長, color = 性別)) +\n  scale_y_continuous(breaks = c(145, 150, 155, 160, 165, 170, 175, 180),\n                     labels = c(145, 150, 155, 160, 165, 170, 175, 180))\n\n\n\n\n\n\n図 18.20: 縦軸を5cm刻みに変更\n\n\n\n\nまた、性別ごとの色を変更する際はscale_color_manual()を使います（ 図 18.21 ）。\n\n# scale_color_manual()の例\nデータ |&gt;\n  ggplot() +\n  geom_point(aes(x = ゲームのプレイ時間, y = 身長, color = 性別)) +\n  scale_y_continuous(breaks = c(145, 150, 155, 160, 165, 170, 175, 180),\n                     labels = c(145, 150, 155, 160, 165, 170, 175, 180)) +\n  scale_color_manual(values = c(\"男性\" = \"#ff9900\", \"女性\" = \"#339900\"))\n\n\n\n\n\n\n図 18.21: 更に性別の色を変bんこうする\n\n\n\n\nscale_*_*()関数群は以上のように、scale_スケールのタイプ_変数のタイプ()です。つまり、scale_x_date()、scale_y_discrete()やscale_color_contiuous()など様々な組み合わせが可能であり、{ggplot2}は様々なタイプのスケールと変数のための関数群を提供しています。むろん、ユーザーから独自のスケール関数を作ることも可能であり、パッケージとして公開することも可能です。\n\n\n18.3.7 ファセット\nファセット (facet)は日本語では「面」、「切子面」などで訳されますが、誤解を招く可能性があるため、本書ではそのままファセットと訳します。ファセットとはデータの部分集合 (subset)を対象にしたグラフを意味します。\nたとえば、フリーダムハウスでは毎年、各国を「自由」、「部分的に自由」、「不自由」と格付けをし、結果を公表しています。世界に自由な国、部分的に自由な国、不自由な国が何カ国あるかを大陸ごとに示したいとします。カテゴリごとの個数を示すには棒グラフが効果的であり、 図 18.22 のように示すことができます。\n\n\n\n\n\n図 18.22: ファセットを分けないグラフの例\n\n\n\n\nこのグラフを見ると各大陸に自由な国がどれほどあるかが分かりますが、人によっては読みにくいかも知れません。できれば大陸ごとに分けたグラフの方が見やすいでしょう。そのためにはデータを特定の大陸に絞って、そのデータを用いた棒グラフを作り、最終的には出来上がったグラフたちを結合する必要があります。\nしかし、{ggplot2}のファセットを指定するとそのような手間が省けます。これはデータを大陸ごとの部分集合に分割し、1つのプロット上に小さい複数のプロットを出力します（ 図 18.23 ）。\n\n\n\n\n\n図 18.23: 大陸ごとにファセットを分けたグラフの例\n\n\n\n\nファセットを指定するには facet_*() 関数群を使います。具体的には facet_wrap() と facet_grid() がありますが、今回のように1つの変数 (ここでは「大陸」)でファセットを分割する場合は主に facet_wrap() を、2つの変数で分割する場合は facet_grid() を使います。\nここまでが{ggplot2}の入門の入門の入門です。韓国旅行に例えると、やっと仁川国際空港の入国審査を通ったところです。The R Graph Galleryを見ると、主に{ggplot2}で作成された綺麗な図がいっぱいあります。しかし、ここまで勉強してきたものだけでは、このような図を作るのは難しいです。そもそもサンプルコードを見ても理解するのが難しいかも知れません。次章では本格的な{ggplot2}の使い方を解説します。到達目標は(1)「よく使う」グラフが作成できること、そして(2)The R Graph Galleryのサンプルコードを見て自分で真似できるようになることです。"
  },
  {
    "objectID": "visualization1.html#sec-visual1-principal",
    "href": "visualization1.html#sec-visual1-principal",
    "title": "18  可視化 [理論]",
    "section": "18.4 良いグラフとは",
    "text": "18.4 良いグラフとは\n本格的な作図に入る前に、「優れたグラフとは何か」について考えてみましょう。しかし、優れたグラフの条件を数ページでまとめるのは難しいです。筆者らがいつか暇になったら、これに関しても詳細に1つの章として解説しますが、ここでは参考になる資料をいくつかリストアップします。\n\nYau, Nathan. 2011. Visualize This: The FlowingData Guide to Design, Visualization, and Statistics. Wiley\nCairo, Alberto. 2016. The Truthful Art: Data, Charts, and Maps for Communication. New Riders.\nHealy, Kieran. 2018. Data Visualization: A Practical Introduction. New Riders. Princeton University Press.\n藤俊久仁・渡部良一. 2019. 『データビジュアライゼーションの教科書』秀和システム. (第5章以降)\n永田ゆかり. 2020. 『データ視覚化のデザイン』SBクリエイティブ.\nBBC Visual and Data Journalism cookbook for R graphics\n\n\n18.4.1 データ・インク比\n可視化が本格的に注目を浴びるようになったのはEdward R. Tufteの1983年著作、The Visual Display of Quantitative Informationからですが、この本のメッセージは単純で、「データ・インク比 (Data-ink ratio) を最大化せよ」の一言に要約できます。データ・インク比は以下のように定義されます (Tufte 2001)。\n\\[\\begin{align}\n\\text{Data-ink ratio} = & \\frac{\\text{data-ink}}{\\text{total ink used to print the graphic}} \\\\\n= & \\text{proportion of a graphic's ink devoted to the} \\\\\n  & \\text{non-redundant display of data-information} \\\\\n= & \\text{1.0 - proportion of a graphic that can be earase} \\\\\n  & \\text{without loss of data-information.}\n\\end{align}\\]\nデータ・インク比は「データ・インク」を「グラフの出力に使用されたインクの総量」で割ったものです。データ・インクとはデータの情報を含むインクの量を意味します。これを言い換えると、グラフにおいて情報損失なしに除去できるグラフの要素が占める割合を1から引いたものです。\nここで1つの例を紹介します。たとえば、G20加盟国におけるCOVID19の累積感染者数を時系列で示すとします。そこで最近、インドにおいて感染者数が急増していることを示したいとします。まず、 図 18.24 から見ましょう。\n\n\n\n\n\n図 18.24: データ・インク比の例 (改善前)\n\n\n\n\nそもそもどの線がインドを表しているのかが分かりにくいです。カテゴリが増えると使える色に制約が生じてしまうからです。実際、図からフランス、ドイツ、インド、インドネシアを区別するのは非常に難しいでしょう。現実に色分けが出来る天才的な色覚を持つ読者ならこちらの方が情報も豊富であり、いいかも知れません。しかし、インドにおける感染者数の急増を示すには無駄な情報が多すぎます。そこでインドを除く国の色をグレーにまとめたものが 図 18.25 です。\n\n\n\n\n\n図 18.25: データ・インク比の例 (改善後)\n\n\n\n\nこちらの方は多くの情報が失われています。アメリカや日本、韓国がどの線に該当するかが分かりません。しかし、図で示したいメッセージとは無関係でしょう。ここからもう一歩踏み込んで、「ならばインド以外の線を消せばいいじゃん」と思う方もいるかも知れません。しかし、インドの線のみ残している場合、比較対象がなくなるため、急増していることを示しにくくなります。この場合、示したい情報の損失が生じるため、インド以外の国の線はデータ・インクに含まれます。\nしかし、このデータ・インク比に基づく可視化は常に正しいとは言えません。そこでもう一つの例を紹介します。 図 18.26 の左は Kuznicki と McCutcheon (1979) の論文に掲載された図であり、右はTufteによる改善案です。\n\n\n\n図 18.26: データ・インク比改善の例\n\n\n確かに棒グラフは面を使用しており、高さを示すには線のみで十分かも知れません。また、エラー・バーも線の位置を若干ずらすことによって表現できます。それでは、読者の皆さんから見て、どのグラフが見やすいと思いますか。これについて興味深い研究結果があります。Inbar, Tractinsky, と Meyer (2007) は87人の学部生を対象に3つのグループに分けました。そして、学生たちは 図 18.27 を「美しさ」、「明瞭さ」、「簡潔さ」の3つの面で評価し、最後にどの図が最も好きかを尋ねました。\n\nグループ1: 図 18.27 のAとDを評価\nグループ2: 図 18.27 のAとDを評価。\n\nただし、事前にTufteスタイル ( 図 18.27 のD)の読み方について学習させる。\n\nグループ3: 図 18.27 のA、B、C、Dを評価\n\n\n\n\n図 18.27: Inbar, Tractinsky, と Meyer (2007) から抜粋\n\n\n皆さんもある程度は結果が予想できたかと思いますが、いずれのグループにおいても、Tufteが推奨する 図 18.27 のDが「美しさ」、「明瞭さ」、「簡潔さ」のすべての点において最下位でした。また、どの図が最も好きかに対しても 表 18.4 のような結果が得られました。\n\n\n\n\n表 18.4: データ・インク比の例 (改善前)\n\n\nグループ\nグラフA\nグラフB\nグラフC\nグラフD\n\n\n\n\nグループ1\n24\nNA\nNA\n3\n\n\nグループ2\n29\nNA\nNA\n2\n\n\nグループ3\n14\n3\n12\n0\n\n\n\n\n\n\n\n\n図 18.27 のDはデータ・インク比の観点から見れば最も優れた図ですが、それが分かりやすさを意味するわけではありません。今は、人々の認知の観点からも図を評価するようになり、近年の可視化の教科書ではこれらに関しても詳しく触れているものが多いです。Tufte (2001) の本は可視化を勉強する人にとって必読の書かも知れませんが、これだけでは十分ではなく、近年の教科書も合わせて読むことをおすすめします。\n\n\n18.4.2 3次元プロット\nこれまで見てきた全ての図は縦軸と横軸しか持たない2次元プロットです。しかし、実際の生活において3次元プロットを見にすることは珍しくないでしょう。3次元プロットの場合、縦軸と横軸以外に、高さ (深さ)といったもう一つの軸が含まれます。しかし、多くの場合、このもう一つの軸はグラフにおいて不要な場合が多いです。たとえば、 図 18.28 をを見てみましょう3。これはCOVID19による定額給付金の給付済み金額を時系列で並べたものです。\n\n\n\n図 18.28: 3次元プロットの例 (1)\n\n\nこの図の目的は筆者にとってはよく分かりませんが、少なくとも給付金が順調（？）に配られているということですかね。その傾向を見るにはこの図は大きな問題はありません。しかし、細かい数値を見ようとすると誤解が生じる可能性があります。たとえば、7月22日の給付済み額は12.12兆円です。しかし、 図 18.29 を見ると、7月22日の棒は12兆円に達しておりません。なぜでしょうか。\nこれは棒と壁（？）との間隔が理由です。 図 18.29 の右下にある青い円を見ればお分かりかと思いますが、棒が浮いています。この棒を壁（？）側に密着すると12の線を超えると考えられますが、このままだと12兆円に達していないのに12兆円超えてると、何かの入力ミスじゃないかと考えさせるかも知れません。\n\n\n\n図 18.29: 3次元プロットの例 (2)\n\n\nこの図において3D要素の必要性は0と言えます。2次元の棒グラフ ( 図 18.30 )、または折れ線グラフ ( 図 18.31 )の方がデータ・インク比の観点からも、分かりやすさからも優れていると言えるでしょう。\n\n\n\n\n\n図 18.30: 図 18.28 を2次元プロットに再構成した例 (棒グラフ)\n\n\n\n\n\n\n\n\n\n図 18.31: 図 18.28 を2次元プロットに再構成した例 (折れ線グラフ)\n\n\n\n\nただ、総務省の図はまだマシかも知れません。世の中には誤解を招かすために作成された3次元プロットもあります。以下の 図 18.32 は早稲田アカデミーが作成した早慶高の合格者数を年度ごとに示した図です。2001年は754人で2012年は1494人です。比較対象がないので本当に12年連続全国No.1かどうかは判断できませんが、2倍近く増加したことは分かります。ただし、棒グラフの高さを見ると、2倍どころか3倍程度に見えます。他にも一時期、合格者が減少した時期 (2002、2003年)があるにもかかわらず、あまり目立ちません。これには2つの原因があります。それは(1)多分、ベースラインが0人ではない、(2) 遠近法により遠いものは小さく見えることです。\n\n\n\n図 18.32: 3次元プロットの例 (3)\n\n\nこれを2次元棒グラフに直してものが 図 18.33 です。こちらの方が合格者をより客観的に確認することができるでしょう。\n\n\n\n\n\n図 18.33: 図 18.32 を2次元プロットに再構成した例\n\n\n\n\nむろん、3次元プロットそのものが悪いわけではありません。むしろ、3次元の方が解釈しやすい、見やすいケースもあるでしょう。それには共通点があり、深さというもう一つの軸も何らかの情報があるという点です。一方、ここでお見せしました2つの例の場合、深さは何の情報も持ちません。つまり、データ・インク比の観点から見れば望ましくない図です。\n\n\n\n\nInbar, Ohad, Noam Tractinsky, と Joachim Meyer. 2007. 「Minimalism in Information Visualization: Attitudes Towards Maximizing the Data-ink Ratio」. ECCE ’07: Proceedings of the 14th European conference on Cognitive ergonomics: invent! explore!, 185–88.\n\n\nKuznicki, James T., と N. Bruce McCutcheon. 1979. 「Cross-enhancement of the Sour Taste on Single Human Taste Papillae」. Journal of Experimental Psychology: General 108: 68–89.\n\n\nTufte, Edward R. 2001. The Visual Display of Quantitative Information (2nd Ed.). Graphics Press.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. Springer."
  },
  {
    "objectID": "visualization2.html#本章の内容",
    "href": "visualization2.html#本章の内容",
    "title": "19  可視化 [基礎]",
    "section": "19.1 本章の内容",
    "text": "19.1 本章の内容\n　前章では{ggplot2}の仕組みおよびグラフィックの文法と良いグラフについて説明しました。本章では実際に簡単なグラフを作りながら{ggplot2}に慣れて頂きたいと思います。{ggplot2}で作れる図の種類は非常に多いですが、本章では、データサイエンスで頻繁に利用される以下の5つのプロットの作り方を紹介します。\n\n棒グラフ\nヒストグラム\n箱ひげ図\n散布図\n折れ線グラフ\n\n　その他の図ついては第21章、図の細かい修正については第20章で解説します。また、使用するPCの環境によっては図の文字化けが生じる可能性があります。この場合は第19.8章を参照してください（{ragg}パッケージを使えば一発で解決できます）。"
  },
  {
    "objectID": "visualization2.html#sec-visual2-data",
    "href": "visualization2.html#sec-visual2-data",
    "title": "19  可視化 [基礎]",
    "section": "19.2 実習用データ",
    "text": "19.2 実習用データ\n　実習の前に本章で使用するデータと{ggplot2}パッケージが含まれている{tidyverse}を読み込みます。\n\nデータ1: 国家別民主主義および政治的自由データ\nデータ2: COVID-19データ\n\n　COVID19_Worldwide.csvの場合、普通に読み込むとTest_DayとTest_Totalが数値型であるにも関わらず、logical型変数として読み込まれます。read_csvはデフォルトだと最初の100行までのデータからデータ型を判断しますが、COVID19_Worldwide.csvの場合、Test_DayとTest_Totalの最初の100要素は全て欠損しており、判断不可となるため、自動的にlogical型として判断します。これを避けるために、guess_max = 10000を追加します。これは「データ型を判断するなら10000行までは読んでから判断しろ」という意味です。\n\npacman::p_load(tidyverse)\n\nCountry_df &lt;- read_csv(\"Data/Countries.csv\")\nCOVID19_df &lt;- read_csv(\"Data/COVID19_Worldwide.csv\", guess_max = 10000)\n\n　これらの変数はSONGが適当にインターネットなどで集めたデータであり、あくまでも実習用データとしてのみお使い下さい。各変数の詳細は以下の通りです。\n\n\n\n国家別民主主義および政治的自由データの詳細\n\n\n変数名\n説明\n備考\n\n\n\n\nCountry\n国名\n\n\n\nPopulation\n人口\n人\n\n\nArea\n面積\nkm$^2$\n\n\nGDP\n国内総生産 (GDP)\n100万米ドル\n\n\nPPP\nGDP (購買力平価):\n100万米ドル\n\n\nGDP_per_capita\n一人あたりGDP\n米ドル\n\n\nPPP_per_capita\n一人あたりGDP (購買力平価)\n米ドル\n\n\nG7\nG7構成国\n1:構成国, 0:構成国以外\n\n\nG20\nG20構成国\n1:構成国, 0:構成国以外\n\n\nOECD\nOECD構成国\n1:構成国, 0:構成国以外\n\n\nHDI_2018\n人間開発指数\n2018年基準\n\n\nPolity_Score\n民主主義の程度\nPolity IVから; -10:権威主義〜10:民主主義\n\n\nPolity_Type\n民主主義の程度 (カテゴリ)\n\n\n\nFH_PR\n政治的自由の指標\n2020年基準; Freedom Houseから\n\n\nFH_CL\n市民的自由の指標\n2020年基準; Freedom Houseから\n\n\nFH_Total\n政治的自由と市民的自由の合計\n2020年基準; Freedom Houseから\n\n\nFH_Status\n総合評価\nF:完全な自由; PF:一部自由; NF:不自由\n\n\nContinent\n大陸\n\n\n\n\n\n\n\n\n\n\n\nCOVID-19データの詳細\n\n\n変数名\n説明\n\n\n\n\nID\nID\n\n\nCountry\n国名\n\n\nDate\n年月日\n\n\nConfirmed_Day\nCOVID-19 新規感染者数（人）\n\n\nConfirmed_Total\nCOVID-19 累積感染者数（人）\n\n\nDeath_Day\nCOVID-19 新規死亡者数（人）\n\n\nDeath_Total\nCOVID-19 累積死亡者数（人）\n\n\nTest_Day\nCOVID-19 新規検査数（人）\n\n\nTest_Total\nCOVID-19 累積検査数（人）"
  },
  {
    "objectID": "visualization2.html#sec-visual2-barplot",
    "href": "visualization2.html#sec-visual2-barplot",
    "title": "19  可視化 [基礎]",
    "section": "19.3 棒グラフ",
    "text": "19.3 棒グラフ\n　棒グラフについては以下の2つのタイプについて説明します。\n\nある変数の数の表す棒グラフ\n各グループの統計量を表す棒グラフ\n\n　前者は「データ内にアフリカのケースはいくつあるか、アジアの行はいくつあるか」のようなものであり、後者は「大陸ごとの民主主義の度合いの平均値はいくつか」を出力するグラフです。\n\n19.3.1 ケース数のグラフ\n　まず、Country_dfのContinent変数における各値の頻度数を棒グラフとして出してみましょう。表としてまとめる簡単な方法はtable()関数があります。\n\ntable(Country_df$Continent)\n\n\n Africa America    Asia  Europe Oceania \n     54      36      42      50       4 \n\n\n　ケース数の棒グラフは、大陸名を横軸に、ケース数を縦軸にしたグラフです。それではグラフを作ってみます。データはCountry_dfであり、使う幾何オブジェクトはgeom_bar()です。ここで必要な情報は横軸、つまり大陸 (Continent)のみです。縦軸も「ケース数」という情報も必要ですが、{ggplot2}が勝手に計算してくれるので、指定しません。また、labs()レイヤーを追加します。labs()レイヤーはマッピング要素のラベルを指定するものです。これを指定しない場合、aes()内で指定した変数名がそのまま出力されます。\n\nCountry_df |&gt;\n  ggplot() +\n  geom_bar(aes(x = Continent)) +\n  labs(x = \"大陸\", y = \"ケース数\")\n\n\n\n\n\n\n\n\n　これで初めての{ggplot2}を用いたグラフが完成しましたね！\n\n\n19.3.2 記述統計量のグラフ\n　次は記述統計量のグラフを出してみます。たとえば、大陸ごとに民主主義の指標の1つであるPolity Scoreの平均値を図示するとします。まずは、{dplyr}を使って、大陸ごとにPolity Score (Polity_Score)の平均値を計算し、Bar_df1という名で保存します。\n\nBar_df1 &lt;- Country_df |&gt;\n  group_by(Continent) |&gt;\n  summarise(Democracy = mean(Polity_Score, na.rm = TRUE),\n            .groups   = \"drop\")\n\nBar_df1\n\n# A tibble: 5 × 2\n  Continent Democracy\n  &lt;chr&gt;         &lt;dbl&gt;\n1 Africa        2.48 \n2 America       6.93 \n3 Asia          0.342\n4 Europe        7.93 \n5 Oceania       7.25 \n\n\n　それでは、このBar_df1を基にグラフを作りますが、今回は縦軸の情報も必要です。横軸はContinent、縦軸はDemocracy変数に指定します。そして、重要なものとしてstat引数を指定します。これはマッピングと関係なく、棒グラフの性質に関係するものなので、aes()の外側に位置します。これを指定しない場合、geom_bar()は基本的にはケース数を計算し、図示します。Passengerの値そのものを縦軸にしたい場合はstat = \"identity\"を指定します。後は、先ほどの棒グラフと同じです。\n\nBar_df1 |&gt;\n  ggplot() +\n  geom_bar(aes(x = Continent, y = Democracy), stat = \"identity\") +\n  labs(x = \"大陸\", y = \"Polity IV スコアの平均値\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　考えてみれば、大陸名が英語になっていますね。図内の言語は統一するのが原則であり、図の言語は論文やレポート、報告書の言語とも一致させるべきです。ここはBar_df1のContinent列の値を日本語に置換するだけでいいので、recode()関数を使います。recode()の使い方は第14.3章を参照してください。また、順番はローマ字順にしたいので、fct_inorder()を使って、Bar_df1における表示順でfactor化を行います。\n\nBar_df1 |&gt;\n  mutate(Continent = recode(Continent,\n                            \"Africa\"   = \"アフリカ\",\n                            \"America\"  = \"アメリカ\",\n                            \"Asia\"     = \"アジア\",\n                            \"Europe\"   = \"ヨーロッパ\",\n                            .default   = \"オセアニア\"),\n         Continent = fct_inorder(Continent)) |&gt;\n  ggplot() +\n  geom_bar(aes(x = Continent, y = Democracy), stat = \"identity\") +\n  labs(x = \"大陸\", y = \"Polity IV スコアの平均値\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\n19.3.3 次元を追加する\n　記述統計量のグラフを見るとマッピング要素は2つであり、これは図が2つの次元、つまり大陸とPolity IVスコアの平均値で構成されていることを意味します。記述統計量のグラフはマッピング要素は1つですが、ケース数という次元が自動的に計算されるため2次元です。ここにもう一つの次元を追加してみましょう。たとえば、大陸ごとのPolity IVスコアの平均値を出しますが、これを更にOECD加盟有無で分けてみましょう。そのためには、まず大陸とOECD加盟有無でグループを分けてPolity IVスコアの平均値を計算する必要があります。\n\nBar_df2 &lt;- Country_df |&gt;\n  group_by(Continent, OECD) |&gt;\n  summarise(Democracy = mean(Polity_Score, na.rm = TRUE),\n            .groups   = \"drop\")\n\nBar_df2\n\n# A tibble: 9 × 3\n  Continent  OECD Democracy\n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 Africa        0     2.48 \n2 America       0     6.55 \n3 America       1     8.6  \n4 Asia          0    -0.314\n5 Asia          1     8    \n6 Europe        0     5.87 \n7 Europe        1     9.12 \n8 Oceania       0     4.5  \n9 Oceania       1    10    \n\n\n　続いて、ContinentとOECD列を日本語に直します。また、順番を指定するためにfactor化しましょう。\n\nBar_df2 &lt;- Bar_df2 |&gt;\n  mutate(Continent = recode(Continent,\n                            \"Africa\"   = \"アフリカ\",\n                            \"America\"  = \"アメリカ\",\n                            \"Asia\"     = \"アジア\",\n                            \"Europe\"   = \"ヨーロッパ\",\n                            .default   = \"オセアニア\"),\n         Continent = fct_inorder(Continent),\n         OECD      = recode(OECD,\n                            \"0\" = \"OECD非加盟国\",\n                            \"1\" = \"OECD加盟国\"),\n         OECD      = fct_inorder(OECD)) \n\nBar_df2\n\n# A tibble: 9 × 3\n  Continent  OECD         Democracy\n  &lt;fct&gt;      &lt;fct&gt;            &lt;dbl&gt;\n1 アフリカ   OECD非加盟国     2.48 \n2 アメリカ   OECD非加盟国     6.55 \n3 アメリカ   OECD加盟国       8.6  \n4 アジア     OECD非加盟国    -0.314\n5 アジア     OECD加盟国       8    \n6 ヨーロッパ OECD非加盟国     5.87 \n7 ヨーロッパ OECD加盟国       9.12 \n8 オセアニア OECD非加盟国     4.5  \n9 オセアニア OECD加盟国      10    \n\n\n　これで作図の準備ができました。それではこの新しい次元であるOECDをどのように表現すれば良いでしょうか。Continentは横軸の位置で表現され、Democracyは縦軸の位置として表現されているため、xとy以外の要素を考えてみましょう。棒グラフの場合、もう一つの軸が追加されるとしたらそれは、棒の色です。棒の色はfillで指定できます。colorでないことに注意してください。colorも指定可能ですが、これは棒の色ではなく、棒を囲む線の色であり、通常は「なし」となっています。それではfillをaes()内に書き加えます。\n\nBar_df2 |&gt;\n  ggplot() +\n  geom_bar(aes(x = Continent, y = Democracy, fill = OECD), \n           stat = \"identity\") +\n  labs(x = \"大陸\", y = \"Polity IV スコアの平均値\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　なんか思ったものと違うものが出てきました。たとえば、アメリカ大陸の場合、Polity IVスコアの平均値が約15ですが、明らかにおかしいです。なぜならPolity IVスコアの最大値は10だからです。これは2つの棒が積み上げられているからです。アメリカ大陸においてOECD加盟国の平均値は8.6、非加盟国のそれは6.55であり、足したら15.15になります。これをずらすためにはpositionを設定する必要があります。しかし、positionというのはBar_df2の何かと変数の値を表すわけではないため、aes()の外側に入れます。そして、その値ですが、ここでは\"dodge\"を指定します。これは棒の位置が重ならないように調整することを意味します。このpositionのデフォルト値は\"stack\"であり、言葉通り「積み上げ」です。\n\nBar_df2 |&gt;\n  ggplot() +\n  geom_bar(aes(x = Continent, y = Democracy, fill = OECD), \n           stat = \"identity\", position = \"dodge\") +\n  labs(x = \"大陸\", y = \"Polity IV スコアの平均値\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　これで私たちが期待した図が出来上がりました。「\"dodge\"の方が普通なのになぜデフォルトが\"stack\"か」と思う方もいるかも知れませんが、実は\"stack\"も頻繁に使われます。それはケース数のグラフにおいてです。\n　たとえば、大陸ごとにOECD加盟/非加盟国を計算してみましょう。\n\nBar_df3 &lt;- Country_df |&gt;\n  group_by(Continent, OECD) |&gt;\n  summarise(N = n(),\n            .groups   = \"drop\") |&gt;\n  mutate(Continent = recode(Continent,\n                            \"Africa\"   = \"アフリカ\",\n                            \"America\"  = \"アメリカ\",\n                            \"Asia\"     = \"アジア\",\n                            \"Europe\"   = \"ヨーロッパ\",\n                            .default   = \"オセアニア\"),\n         Continent = fct_inorder(Continent),\n         OECD      = recode(OECD,\n                            \"0\" = \"OECD非加盟国\",\n                            \"1\" = \"OECD加盟国\"),\n         OECD      = fct_inorder(OECD)) \n\nBar_df3\n\n# A tibble: 9 × 3\n  Continent  OECD             N\n  &lt;fct&gt;      &lt;fct&gt;        &lt;int&gt;\n1 アフリカ   OECD非加盟国    54\n2 アメリカ   OECD非加盟国    31\n3 アメリカ   OECD加盟国       5\n4 アジア     OECD非加盟国    39\n5 アジア     OECD加盟国       3\n6 ヨーロッパ OECD非加盟国    23\n7 ヨーロッパ OECD加盟国      27\n8 オセアニア OECD非加盟国     2\n9 オセアニア OECD加盟国       2\n\n\n　これを可視化したのが以下の図です。\n\nBar_df3 |&gt;\n  ggplot() +\n  geom_bar(aes(x = Continent, y = N, fill = OECD), \n           stat = \"identity\") +\n  labs(x = \"大陸\", y = \"国家数\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　この図はposition = \"dodge\"でも良いと思いますが、大陸内の比率を考えるならposition = \"stack\"でも問題ないでしょう。また、積み上げグラフの特性上、大陸ごとの国数の合計も一瞬で判別できるといった長所もあります。position = \"dodoge\"だと、それが難しいですね。むろん、積み上げ棒グラフはベースラインが一致したいため、避けるべきという人も多いですし、著者 (SONG)も同意見です。どの図を作成するかは分析者の責任で判断しましょう。"
  },
  {
    "objectID": "visualization2.html#sec-visual2-histogram",
    "href": "visualization2.html#sec-visual2-histogram",
    "title": "19  可視化 [基礎]",
    "section": "19.4 ヒストグラム",
    "text": "19.4 ヒストグラム\n　ヒストグラムは棒グラフと非常に形が似ていますが、横軸が大陸のような離散変数でなく、連続変数であるのが特徴です。連続変数をいくつの区間 (階級)に分け、その区間内に属するケース数 (度数)を示したのが度数分布表、そして度数分布表をかしかしたものがヒストグラムです。連続変数を扱っているため、棒間に隙間がありません。それでもケース数の棒グラフと非常に似通っているため、マッピングの仕方も同じです。異なるのは幾何オブジェクトがgeom_bar()でなく、geom_histogram()に変わるくらいです。世界の富がどのように分布しているかを確認するために、Country_dfのGDPのヒストグラムを作ってみます。\n\nCountry_df |&gt; \n  ggplot() +\n  geom_histogram(aes(x = GDP)) +\n  labs(x = \"国内総生産 (100万米ドル)\", y = \"度数\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　ケース数の棒グラフのコードとほぼ同じです。横軸の数値が2.0e+07になっているのは2 \\times 10^7、つまり2千万を意味します。普通に表記すると20000000になりますね。また、GDPの単位は100万ドルであるため、実際のGDPは20兆ドルになります。つまり、今のヒストグラムにおいて横軸の目盛りは5兆ドルになっています。この軸の数値を「0, 5e+06, 1e+07, 1.5e+07, 2e+07」から「0, 5, 10, 15, 20」 にし、X軸のラベルを「国内総生産 (100万米ドル)」から「国内総生産 (兆米ドル)」に替えてみましょう。ここで使うのはscale_x_continuous()関数です。これは横軸 (X軸)が連続変数 (continuous)の場合のスケール調整関数です。目盛りの再調整にはbreaksとlabels引数が必要です。breaksは新しい目盛りの位置、labelsは目盛りに表記する値です。それぞれベクトルが必要であり、breaksとlabelsの実引数の長さは必ず一致する必要があります。また、breaksは数値型ベクトルですが、labelsは数値型でも文字型でも構いません。\n\nCountry_df |&gt; \n  ggplot() +\n  geom_histogram(aes(x = GDP)) +\n  labs(x = \"国内総生産 (兆米ドル)\", y = \"度数\") +\n  scale_x_continuous(breaks = c(0, 5000000, 10000000, 15000000, 20000000),\n                     labels = c(0, 5, 10, 15, 20)) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　これで一通りヒストグラムが完成しました。ほんの一部の国は非常に高いGDPを誇っていることが分かります。GDPが10兆ドル以上の国はアメリカと中国のみであり、5兆ドルを国まで拡大しても日本が加わるだけです。そもそも1兆ドルを超える国はデータには16カ国しかなく、90%以上の国が図の非常に狭い範囲内 (0~1兆ドル)に集まっていることが分かります。\n\n\n\n\n\n\n\n\n\n　この場合、2つの方法が考えられます。1つ目は方法は情報の損失を覚悟した上で、GDPが1兆ドル未満の国でヒストグラムを書く方法です。これはデータをggplot()関数を渡す前にfilter()を使って、GDPが100万未満のケースに絞るだけで出来ます。ただし、横軸の最大値が2000万でなく、100万になるため、目盛りを調整した方が良いでしょう。\n\nCountry_df |&gt; \n  filter(GDP &lt; 1000000) |&gt;\n  ggplot() +\n  geom_histogram(aes(x = GDP)) +\n  labs(x = \"国内総生産 (兆米ドル)\", y = \"度数\") +\n  scale_x_continuous(breaks = seq(0, 1000000, 100000),\n                     labels = seq(0, 1, 0.1)) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　2つ目の方法は横軸を対数化することです。GDPを底10の対数化 (常用対数)をすると、10兆のような非常に大きい値があっても比較的に狭い範囲内にデータを収めることが出来ます。たとえば、10を常用対数化すると1, 1000は3, 10000000は7になります。自然対数 (底が\\(e\\))も可能ですが、「読む」ためのグラフとしては底が10の方が読みやすいでしょう。横軸の変数が対数化されるということは、横軸のスケールを対数化することと同じです。そのためにはscale_x_continuous()内にtrans引数を指定し、\"log10\"を渡します。\n\nCountry_df |&gt; \n  ggplot() +\n  geom_histogram(aes(x = GDP)) +\n  labs(x = \"国内総生産 (兆米ドル)\", y = \"度数\") +\n  scale_x_continuous(breaks = seq(0, 20000000, by = 5000000),\n                     labels = seq(0, 20, by = 5),\n                     trans = \"log10\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　対数化することによってGDPの分布が綺麗な形になりました。対数化すると横軸における目盛りの間隔が等間隔でないことに注意すべきです。0から5兆ドルの距離はかなり広めですが、5兆から10兆までの距離は短くなり、10兆から15兆までの距離は更に短くなります。したがって、この図から「世界のGDPは鐘型に分布している」と解釈することは出来ません。分布を可視化するには対数化する前の図が適します。\n　対数化のもう一つの方法はscale_x_continuous()の代わりにscale_x_log10()を使うことです。使い方はscale_x_continuous()と同じですが、trans = \"log10\"の指定は不要です。\n\nCountry_df |&gt; \n  ggplot() +\n  geom_histogram(aes(x = GDP)) +\n  labs(x = \"国内総生産 (兆米ドル)\", y = \"度数\") +\n  scale_x_log10() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　横軸を修正するにはscale_x_continuous()と同様、breaksとlabels引数を指定します。\n\nCountry_df |&gt; \n  ggplot() +\n  geom_histogram(aes(x = GDP)) +\n  labs(x = \"国内総生産 (兆米ドル)\", y = \"度数\") +\n  scale_x_log10(breaks = c(0, 1000, 10000, 100000, 1000000, 10000000),\n                labels = c(0, 0.001, 0.01, 0.1, 1, 10)) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　他にもcoord_*()関数群、つまり座標系の操作を用いて軸を対数化することも可能です。他にも、データをggplot()を渡す前に変数を対数化するのもありでしょう。プログラミングにおいてある結果にたどり着く方法は複数あるので、色々試してみるのも良いでしょう。\n\n19.4.1 ヒストグラムの棒の大きさを調整する\n　棒グラフのようにもう一つの次元を追加してみましょう。まず、人間開発指数 (HDI_2018)の分布を示してみましょう。\n\nCountry_df |&gt;\n  ggplot() +\n  geom_histogram(aes(x = HDI_2018)) +\n  labs(x = \"人間開発指数 (2018)\", y = \"ケース数\") +\n  scale_x_continuous(breaks = seq(0, 1, 0.1),\n                     labels = seq(0, 1, 0.1)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n　これでもヒストグラムとしては十分すぎるかも知れませんが、色々調整してみましょう。まずは、棒の枠線を白にしてみましょう。枠線はデータ内の変数に対応していないため、aes()の外側に入れます。枠線を指定する引数はcolorです。ちなみに棒の色を指定する引数はfillです。また、警告メッセージも気になるので、HDI_2018が欠損している行を除外します。\n\nCountry_df |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot() +\n  geom_histogram(aes(x = HDI_2018), color = \"white\") +\n  labs(x = \"人間開発指数 (2018)\", y = \"ケース数\") +\n  scale_x_continuous(breaks = seq(0, 1, 0.1),\n                     labels = seq(0, 1, 0.1)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n　人によってはこちらの方が見やすかも知れません。\n　これで一通りの作図は出来ましたが、これまで無視してきたメッセージについて考えてみましょう。\n## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n　これは「連続変数HDI_2018を30区間 (=階級)に分けました」という意味です。この区間数を調整する方法は2つあり、(1) 区間数を指定する、(2) 区間の幅を指定する方法があります。\n　区間数を指定することはすなわちヒストグラムの棒の数を指定することであり、bins引数で調整可能です。たとえば、棒の数を10個にするためにはgeom_histogram()内にbins = 10を指定します。むろん、棒の数もデータとは無関係であるため、aes()の外側に位置します。\n\nCountry_df |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot() +\n  geom_histogram(aes(x = HDI_2018), color = \"white\", bins = 10) +\n  labs(x = \"人間開発指数 (2018)\", y = \"ケース数\") +\n  scale_x_continuous(breaks = seq(0, 1, 0.1),\n                     labels = seq(0, 1, 0.1)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n　数えてみると棒が10個だということが分かります。\n　他にも区間の幅を指定することも可能です。区間の幅は棒の幅と一致します。たとえば、棒の幅を0.1にしてみましょう。棒の幅はbinwidthで調整可能です。\n\nCountry_df |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot() +\n  geom_histogram(aes(x = HDI_2018), color = \"white\", binwidth = 0.1) +\n  labs(x = \"人間開発指数 (2018)\", y = \"ケース数\") +\n  scale_x_continuous(breaks = seq(0, 1, 0.1),\n                     labels = seq(0, 1, 0.1)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n　ヒストグラムが出力されましたが、棒の幅がbinwidthで指定した0.1と一致することが分かります。たとえば、一番左の棒は0.35から0.45まで、つまり幅が0.1です。そして、一番右の棒は0.95から1.05に渡って位置します。ただし、ここでに疑問を持つ読者もいるでしょう「。なぜ0.3から0.4、0.4から0.5、…ではなく、0.35から0.45、0.45から0.55なのか」です。これは{ggplot2}の基本仕様です。ヒストグラムは度数分布表を基に作成されますが、本グラフの度数分布表は以下のようになります。\n\n\n\n\n\nから\nまで\n度数\n\n\n\n\n0.35\n0.45\n10\n\n\n0.45\n0.55\n26\n\n\n0.55\n0.65\n22\n\n\n0.65\n0.75\n37\n\n\n0.75\n0.85\n47\n\n\n0.85\n0.95\n37\n\n\n0.95\n1.05\n1\n\n\n\n\n\n\n\n　簡単に言うと、ヒストグラムの最初の棒は0を中央にした上で、棒の幅を0.1にしたとも言えます。これによってヒストグラムの境界線 (boundary)が、データより左右に0.05 (binwidthの半分)ずつ広くなります。もし、これを調整したい場合は、boundary引数を指定します。指定しない場合、boundaryは「棒の広さ / 2」となります。棒がデータの範囲を超えないようにするためには、geom_histogram()内にboundary = 0を指定します。\n\nCountry_df |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot() +\n  geom_histogram(aes(x = HDI_2018), color = \"white\", \n                 binwidth = 0.1, boundary = 0) +\n  labs(x = \"人間開発指数 (2018)\", y = \"ケース数\") +\n  scale_x_continuous(breaks = seq(0, 1, 0.1),\n                     labels = seq(0, 1, 0.1)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n　ここまで抑えとけば、普段使われるヒストグラムは問題なく作れるでしょう。\n\n\n19.4.2 密度を追加する\n　ヒストグラムには以下のように密度の表す線を同時に載せるケースもあります。\n\n\n\n\n\n\n\n\n\n　この密度の線を追加するにはgeom_density()という幾何オブジェクトを追加する必要があります。密度の線を示すには、横軸と縦軸両方の情報が必要です。横軸はHDI_2018で問題ないですが、縦軸はどうでしょう。縦軸には密度の情報が必要ですが、Country_dfにそのような情報はありません。幸い、{ggplot2}はy = ..density..と指定するだけで、自動的にHDI_2018のある時点における密度を計算してくれます。したがって、マッピングはaes(x = HDI_2018, y = ..density..)のように書きます。こうなるとマッピング要素xはgeom_histogram()とgeom_density()に共通するため、ggplot()に入れても問題ありません。\n\nCountry_df |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  # 全幾何オブジェクトにおいてxを共有するため、ここでマッピング指定\n  ggplot(aes(x = HDI_2018)) +\n  geom_histogram(color = \"white\", binwidth = 0.05, boundary = 0) +\n  geom_density(aes(y = ..density..), size = 1) +\n  labs(x = \"人間開発指数 (2018)\", y = \"密度\") +\n  scale_x_continuous(breaks = seq(0, 1, 0.1),\n                     labels = seq(0, 1, 0.1)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n　なんとも言えない微妙なグラフが出来ました。考えたものと全然違いますね。これはなぜでしょうか。それはgeom_density()は密度を表す一方、geom_histogram()は度数を表すからです。2つは単位が全然違います。したがって、どちらかに単位を合わせる必要があり、この場合はヒストグラムの縦軸を度数でなく、密度に調整する必要があります。ヒストグラムの縦軸を密度にするためには、y = ..density..を指定するだけです。こうなると、geom_histogram()とgeom_density()はxとyを共有するため、全部ggplot()内で指定しましょう。\n\nCountry_df |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot(aes(x = HDI_2018, y = ..density..)) +\n  geom_histogram(color = \"white\", binwidth = 0.05, boundary = 0) +\n  geom_density(size = 1) +\n  labs(x = \"人間開発指数 (2018)\", y = \"密度\") +\n  scale_x_continuous(breaks = seq(0, 1, 0.1),\n                     labels = seq(0, 1, 0.1)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n　これで密度を表す線が出来ました。\n\n\n19.4.3 次元を追加する\n　次元を追加するには棒グラフと同様、aes()内にマッピング要素を追加します。たとえば、OECD加盟有無によって人間開発指数の分布がどう異なるかを確認してみましょう。OECD変数は0/1であり、Rでは連続変数扱いになっているため、これを離散変数化するためには文字型かfactor型にする必要があります。ifelse()を使って、OECD == 1なら「OECD加盟国」、OECD == 0なら「OECD非加盟国」と置換したものをOECD2という列として追加します。そして、OECD2ごとに棒の色を変えるために、マッピング要素としてfillを追加します。\n\nCountry_df |&gt;\n  mutate(OECD2 = ifelse(OECD == 1, \"加盟国\", \"非加盟国\")) |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot() +\n  geom_histogram(aes(x = HDI_2018, fill = OECD2), \n                 color = \"white\", binwidth = 0.05, boundary = 0) +\n  # fill要素のラベルをOECDに変更\n  labs(x = \"人間開発指数 (2018)\", y = \"ケース数\", fill = \"OECD\") +\n  scale_x_continuous(breaks = seq(0, 1, 0.1),\n                     labels = seq(0, 1, 0.1)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n　ヒストグラムが出来上がりました。OECD加盟国の場合、人間開発指数が相対的に高いことが分かります。しかし、積み上げヒストグラムになっています。これはある階級においてOECD加盟国と非加盟国の比率を比較する際に有効ですが、OECD加盟国と非加盟国の分布の違いを見るにはやや物足りません。したがって、棒グラフ同様、position引数で棒の位置を調整します。ただし、ヒストグラムの場合、postion = \"dodge\"は向いていないので、ここではposition = \"identity\"を指定します。しかし、この場合、棒が重なってしまうと、一方の棒が見えなくなる可能性もあるので、alpha引数で棒の透明度を調整します。alphaの値は0から1までであり、0になると、完全透明になります。ここでは0.5くらいにしてみましょう。\n\nCountry_df |&gt;\n  mutate(OECD2 = ifelse(OECD == 1, \"OECD加盟国\", \"OECD非加盟国\")) |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot() +\n  geom_histogram(aes(x = HDI_2018, fill = OECD2), \n                 color = \"white\", alpha = 0.5, position = \"identity\",\n                 binwidth = 0.05, boundary = 0) +\n  labs(x = \"人間開発指数 (2018)\", y = \"ケース数\", fill = \"OECD\") +\n  scale_x_continuous(breaks = seq(0, 1, 0.1),\n                     labels = seq(0, 1, 0.1)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n　これで2つのヒストグラムを綺麗にオーバーラッピングできました。また、先ほど紹介しましたgeom_density()オブジェクトを重ねることも可能です。\n\nCountry_df |&gt;\n  mutate(OECD2 = ifelse(OECD == 1, \"OECD加盟国\", \"OECD非加盟国\")) |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  # xはHDI_2018、yは密度 (..density..)とする\n  ggplot(aes(x = HDI_2018, y = ..density..)) +\n  geom_histogram(aes(fill = OECD2), \n                 color = \"white\", alpha = 0.5, position = \"identity\",\n                 binwidth = 0.05, boundary = 0) +\n  # OECD2ごとに異なる色を付ける。線の太さは1、凡例には表示させない\n  geom_density(aes(color = OECD2), size = 1, show.legend = FALSE) +\n  # 縦軸のラベルを「密度」に変更\n  labs(x = \"人間開発指数 (2018)\", y = \"密度\", fill = \"OECD\") +\n  scale_x_continuous(breaks = seq(0, 1, 0.1),\n                     labels = seq(0, 1, 0.1)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n　この場合、OECD加盟国と非加盟国の密度をそれぞれ計算するため、ヒストグラムの見た目がこれまでのものと変わることに注意してください。\n　ここまで、次元拡張の方法としてヒストグラムのオーバーラッピングについて紹介しました。しかし、ヒストグラムを重なってしまうと、読みにくい人もいるかも知れません。オーバーラップ以外の方法はプロットを2つに分けることです。つまり、1つのプロットに小さいブロットを複数載せることであり、この小さいプロットをファセット (facet)と呼びます。これにはfacet_*()関数群の中の、facet_wrap()関数を使います。facet_wrap(~ 分ける変数名)を追加すると変数ごとにプロットを分割してくれます。ncolやnrow引数を指定すると、ファセットの列数や行数も指定可能です。\n　それではやってみましょう。facet_wrap(~ OECD2)を追加するだけです。2つのファセットを縦に並べるために、ncol = 1を追加します。2つのファセットを1列に並べるという意味です。\n\nCountry_df |&gt;\n  mutate(OECD2 = ifelse(OECD == 1, \"OECD加盟国\", \"OECD非加盟国\")) |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot() +\n  geom_histogram(aes(x = HDI_2018), \n                 color = \"white\",\n                 binwidth = 0.05, boundary = 0) +\n  labs(x = \"人間開発指数 (2018)\", y = \"ケース数\", fill = \"OECD\") +\n  scale_x_continuous(breaks = seq(0, 1, 0.1),\n                     labels = seq(0, 1, 0.1)) +\n  facet_wrap(~ OECD2, ncol = 1) +\n  theme_bw()\n\n\n\n\n\n\n\n\n　OECDは加盟/非加盟だけですから、オーバーラッピングされたヒストグラムで十分かも知れません。しかし、大陸のように、3つ以上のグループになると、オーバーラッピングよりもファセットで分けた方が効率的です。たとえば、大陸ごとの人間開発指数のヒストグラムを作ってみましょう。\n\nCountry_df |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot() +\n  geom_histogram(aes(x = HDI_2018), \n                 color = \"white\",\n                 binwidth = 0.1, boundary = 0) +\n  labs(x = \"人間開発指数 (2018)\", y = \"ケース数\", fill = \"OECD\") +\n  scale_x_continuous(breaks = seq(0, 1, 0.1),\n                     labels = seq(0, 1, 0.1)) +\n  facet_wrap(~ Continent, ncol = 3) +\n  theme_bw()"
  },
  {
    "objectID": "visualization2.html#sec-visual2-box",
    "href": "visualization2.html#sec-visual2-box",
    "title": "19  可視化 [基礎]",
    "section": "19.5 箱ひげ図",
    "text": "19.5 箱ひげ図\n　データの分布を示す際には、離散変数ならケース数 (度数)の棒グラフ、連続変数ならヒストグラムがよく使われますが、連続変数の場合、もう一つの方法があります。それが箱ひげ図です。箱ひげ図はヒストグラムより情報量がやや損なわれますが、データの中央値、四分位点（四分位範囲）、最小値と最大値の情報を素早く読み取れます。また、複数の変数、またはグループの分布を1つのプロットに示すにはヒストグラムより優れています。\n　まずは人間開発指数の箱ひげ図を出してみます。使用する幾何オブジェクトはgeom_boxplot()です。そして、指定するマッピング要素はyのみです。箱ひげ図から読み取れる情報は最小値・最大値、中央値、第1四分位点、第3四分位点ですが、これらの情報は縦軸として表現されます。それでは、とりあえず実際に作ってみましょう。\n\nCountry_df |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot() +\n  geom_boxplot(aes(y = HDI_2018)) +\n  labs(y = \"人間開発指数 (2018)\")\n\n\n\n\n\n\n\n\n　箱ひげ図の読み方は以下の通りです。\n\n\n\n\n\n\n\n\n\n　これで箱ひげ図は完成ですが、人間開発指数は0から1の相対を取るので、座標系の縦軸を調整してみましょう。座標系の操作はcoord_*()関数群を使いますが、現在使っているのは直交座標系（デカルト座標系）ですのでcoord_cartesian()を使います。ここで縦軸の上限と下限を指定する引数がylimであり、長さ2の数値型ベクトルが必要です。下限0、上限1ですので、ylim = c(0, 1)とします。\n\nCountry_df |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot() +\n  geom_boxplot(aes(y = HDI_2018)) +\n  labs(y = \"人間開発指数 (2018)\") +\n  coord_cartesian(ylim = c(0, 1))\n\n\n\n\n\n\n\n\n　まだまだ改善の余地はありますが、それなりの箱ひげ図の出来上がりです。しかし、一変数の箱ひげ図はあまり使われません。変数が1つだけならヒストグラムの方がより情報量は豊富でしょう。情報量が豊富ということはヒストグラムから（完璧には無理ですが）箱ひげ図を作ることは可能である一方、その逆は不可能か非常に難しいことを意味します。\n　ヒストグラムが力を発揮するのは複数の変数、または複数のグループごとの分布を比較する際です。先ほど、大陸ごとの人間開発指数の分布を確認するためにヒストグラムを5つのファセットで分割しました。箱ひげ図なら1つのグラフに5つの箱を並べるだけです。これは横軸を大陸 (Continent)にすることを意味します。先ほどのコードのマッピングにx引数を追加してみましょう。\n\nCountry_df |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot() +\n  geom_boxplot(aes(x = Continent, y = HDI_2018)) +\n  labs(x = \"大陸\", y = \"人間開発指数 (2018)\") +\n  coord_cartesian(ylim = c(0, 1))\n\n\n\n\n\n\n\n\n　いかがでしょうか。5大陸の分布を素早く確認することができました。ヨーロッパの場合、人間開発指数が高く、バラツキも小さいことが分かります。一方、アジアとアフリカはバラツキが非常に大きいですね。アメリカ大陸はバラツキは非常に小さいですが、極端に高い国や低い国が含まれています。このアメリカ大陸に3つの点がありますが、これは外れ値です。つまり、最小値より小さい、または最大値より大きいケースを表します。最小値より小さい、または最大値より大きいという表現に違和感を感じるかも知れません。実は一般的な箱ひげ図の最小値は「第1四分位点 - 1.5 \\(\\times\\) 四分位範囲」より大きい値の中での最小値です。同じく最大値は「第3四分位点 + 1.5 \\(\\times\\) 四分位範囲」より小さい値の中での最大値です。普通に分布している場合、ほとんどのケースは箱ひげ図の最小値と最大値の範囲内に収まりますが、極端に大きい値、小さい値が含まれる場合は箱ひげ図の最小値と最大値の範囲からはみ出る場合があります。\n　また、複数の箱を並べる際、それぞれの箱に異なる色を付ける場合があります。これはデータ・インク比の観点から見れば非効率的ですが、可読性を落とすこともないのでさほど問題はないでしょう。先ほどの箱ひげ図の場合、大陸ごとに異なる色を付けるにはマッピング要素としてfill = Continentを追加するだけです。この場合、色に関する凡例が自動的に出力されますが、既に横軸で大陸の情報が分かるため、この判例は不要でしょう。したがって、aes()の外側にshow.legned = FALSEを付けます。これは当該幾何オブジェクトに関する凡例を表示させないことを意味します。\n\nCountry_df |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot() +\n  geom_boxplot(aes(x = Continent, y = HDI_2018, fill = Continent),\n               show.legend = FALSE) +\n  labs(x = \"大陸\", y = \"人間開発指数 (2018)\") +\n  coord_cartesian(ylim = c(0, 1))\n\n\n\n\n\n\n\n\n　彩りどりでちょっとテンションが上がる箱ひげ図ができました。\n\n19.5.1 個別のデータを表示する\n　箱ひげ図は複数のグループや変数の分布を素早く比較できる長所がありますが、中央値、最小値、最大値、第1・3四分位点、外れ値の情報しか持ちません。人によってはもうちょっと情報量を増やすために個々の観測値を点として示す場合もあります。点を出力する幾何オブジェクトは次節で紹介するgeom_point()です。以下の内容は散布図の節を一読してから読むのをおすすめします。\n　点の幾何オブジェクトにおける必須マッピング要素は点の横軸の位置と縦軸の位置、つまりxとyです。今回の場合、点の横軸が大陸（Continent）、縦軸は人間開発指数（HDI_2018）です。つまり、geom_boxplot()のマッピングと同じです。したがって、xとyはggplot()に入れておきます。あとは大陸ごとに店の色分けをしたいので、color引数をaes()内に指定します。また、点が重なる場合、読みづらくなる可能性があるため、alpha引数をaes()外に指定して透明度を調整します。また、箱ひげ図もある程度は透明にしないと、裏にある点が見えないため、こちらもalphaを調整します。\n\nCountry_df |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  # 全幾何オブジェクトにおいてxとyは共有されるため、ここで指定\n  ggplot(aes(x = Continent, y = HDI_2018)) +\n  geom_point(aes(color = Continent), alpha = 0.5,\n             show.legend = FALSE) +\n  geom_boxplot(aes(fill = Continent),\n               alpha = 0.5, show.legend = FALSE) +\n  labs(x = \"大陸\", y = \"人間開発指数 (2018)\") +\n  coord_cartesian(ylim = c(0, 1))\n\n\n\n\n\n\n\n\n　点が透明ではあるものの、それでも重なっている箇所は相変わらず読みにくいです。この場合有効な方法がジッター（jitter）です。これは点の位置に若干のノイズを付けることによって、点が重ならないようにすることです。ジッターの方法は2つありますが、ここではジッター専用の幾何オブジェクトgeom_jitter()を使います1。geom_jitter()はノイズが追加された散布図ですので、geom_point()と使い方はほぼ同じです。\n\nCountry_df |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot(aes(x = Continent, y = HDI_2018)) +\n  geom_jitter(aes(color = Continent),\n              show.legend = FALSE) +\n  geom_boxplot(aes(fill = Continent),\n               alpha = 0.5, show.legend = FALSE) +\n  labs(x = \"大陸\", y = \"人間開発指数 (2018)\") +\n  coord_cartesian(ylim = c(0, 1))\n\n\n\n\n\n\n\n\n　これで点が重ならなくなりましたが、ちょっと散らばりすぎるという印象もあります。この散らばり具合を調整する引数がwidthとheightです。もちろん、これはデータの中身に対応する要素ではないため、aes()の外側にいれます。それぞれの実引数は0から1の間の数値になりますが、数字が大きいほど散らばり具合が大きくなり、0になるとジッター無しの散布図と同じものになります。ここでは横の散らばり具合を0.15（width = 0.15）、縦の散らばり具合は0（height = 0）にしてみましょう。そして、横軸が英語のままなので、これも日本語に直します。\n\nCountry_df |&gt;\n  mutate(Continent2 = factor(Continent,\n                             levels = c(\"Africa\", \"America\", \"Asia\",\n                                        \"Europe\", \"Oceania\"),\n                             labels = c(\"アフリカ\", \"アメリカ\", \"アジア\",\n                                        \"ヨーロッパ\", \"オセアニア\"))) |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot(aes(x = Continent2, y = HDI_2018)) +\n  geom_jitter(aes(color = Continent2),\n              width = 0.15, height = 0,\n              show.legend = FALSE) +\n  geom_boxplot(aes(fill = Continent2),\n               alpha = 0.5, show.legend = FALSE) +\n  labs(x = \"大陸\", y = \"人間開発指数 (2018)\") +\n  coord_cartesian(ylim = c(0, 1))\n\n\n\n\n\n\n\n\n\n\n19.5.2 次元を追加する\n　箱ひげ図に次元を追加する方法はこれまで見てきたように、1つのグラフに次元を追加するか、次元でファセットを分割するかの問題になります。まずは、簡単なファセット分割からやってみます。追加する次元は先進国か否かです。先進国の基準は不明瞭ですが、ここではG7、G20、OECDいずれかに加盟していれば先進国と定義しましょう。そのためにCountry_dfにDeveloped変数を追加します。この変数はG7、G20、OECDの合計が1以上の場合は1、0の場合は0とします。そして、このDeveloped変数をfactor化します。具体的にはDevelopedが1だと\"先進国\"、0だと\"その他\"にします。あとはfacet_wrap()でファセットを分割します。\n\nCountry_df |&gt;\n  mutate(Continent2 = factor(Continent,\n                             levels = c(\"Africa\", \"America\", \"Asia\",\n                                        \"Europe\", \"Oceania\"),\n                             labels = c(\"アフリカ\", \"アメリカ\", \"アジア\",\n                                        \"ヨーロッパ\", \"オセアニア\")),\n         # G7 + G20 + OECDが1以上なら1、0なら0とするDeveloped変数作成\n         Developed  = ifelse(G7 + G20 + OECD &gt;= 1, 1, 0),\n         # Developed変数のfactor化\n         Developed  = factor(Developed, levels = c(1, 0),\n                             labels = c(\"先進国\", \"その他\"),\n                             ordered = TRUE)) |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot(aes(x = Continent2, y = HDI_2018)) +\n  geom_jitter(aes(color = Continent2), alpha = 0.5,\n              width = 0.15, height = 0,\n              show.legend = FALSE) +\n  geom_boxplot(aes(fill = Continent2),\n               alpha = 0.5, show.legend = FALSE) +\n  # caption引数で図の右下にテキストを入れる\n  labs(x = \"大陸\", y = \"人間開発指数 (2018)\",\n       caption = \"先進国: G7, G20, OECDのいずれかに加盟している国\") +\n  # ファセット分割\n  facet_wrap(~ Developed) +\n  coord_cartesian(ylim = c(0, 1)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n　次の方法はファセットを分割せずに次元を追加する方法です。ファセットに分ける場合、「先進国における大陸別人間開発指数の分布」、「先進国外における大陸別人間開発指数の分布」は素早く読み取れますが、「ある大陸における先進国/その他の国の人間開発指数の分布」を比較するにはあまり向いておりません。なぜなら目の動線が長いからです。先進国とその他の国を大陸ごとに横に並べると視線の動線が短くなり比較しやすくなります。\n　やり方はあまり変わりませんが、今回は色分けをContinentでなくDevelopedでする必要があります。1つの画面に先進国とその他の国の情報が同時に出力されるため、この2つを見分けるためには色分けが有効です。したがって、geom_jitter()とgeom_boxplot()のcolorとfillをContinentからDevelopedへ変更します。\n　そしてもう一つ重要なことがあります。それはgeom_jitter()の位置です。次元ごとに横軸の位置をずらす場合、geom_bar()はposition = \"dodge\"を使いました。しかし、geom_jitter()では\"dodge\"が使えません。その代わりにpositonの実引数としてposition_jitterdodge()を指定します。この中には更にjitter.widthとjitter.height引数があり、散らばりの具合をここで調整します。なぜ、geom_jitter()でwidthとheightを指定するのではなく、position_jitter()内で指定するかですが、これはgeom_jitter()関数の仕様です。geom_jitter()の場合、positionとwidthまたはheightを同時に指定することは出来ません。 　 　それでは早速やってみましょう。\n\nCountry_df |&gt;\n  mutate(Continent2 = factor(Continent,\n                             levels = c(\"Africa\", \"America\", \"Asia\",\n                                        \"Europe\", \"Oceania\"),\n                             labels = c(\"アフリカ\", \"アメリカ\", \"アジア\",\n                                        \"ヨーロッパ\", \"オセアニア\")),\n         Developed  = ifelse(G7 + G20 + OECD &gt;= 1, 1, 0),\n         Developed  = factor(Developed, levels = c(1, 0),\n                             labels = c(\"先進国\", \"その他\"),\n                             ordered = TRUE)) |&gt;\n  filter(!is.na(HDI_2018)) |&gt;\n  ggplot(aes(x = Continent2, y = HDI_2018)) +\n  # jitterでdodgeを使うためにはposition_jitterdodgeを使う\n  geom_jitter(aes(color = Developed), alpha = 0.5,\n              position = position_jitterdodge(jitter.width = 0.5,\n                                              jitter.height = 0),\n              show.legend = FALSE) +\n  geom_boxplot(aes(fill = Developed),\n               alpha = 0.5) +\n  labs(x = \"大陸\", y = \"人間開発指数 (2018)\", fill = \"\",\n       caption = \"先進国: G7, G20, OECDのいずれかに加盟している国\") +\n  coord_cartesian(ylim = c(0, 1)) +\n  theme_bw()\n\n\n\n\n\n\n\n\n　ファセット分割と色分け、どれが良いかという正解はありません。分析者の目的に依存するものです。もし、先進国の中での比較を強調したい場合はファセット分割が有効でしょう。しかし、同じ大陸内で先進国とその他の国の比較なら色分けの方が適切です。\n\n\n19.5.3 複数の変数の場合\n　箱ひげ図はグループごとにある変数の分布を比較することもできますが、複数の変数の比較も可能です。そのためにはデータの形を変形する必要があります。たとえば、Polity IVの民主主義指標（Polity_Score）とFreedom Houseの民主主義指標（FH_Total）の分布を、大陸ごとに示したいとします。Country_dfの場合、Polity_ScoreとFH_Totalは別々の変数になっていますが、pivot_longer()を使って、これらを1つの変数にまとめる必要があります。\n\nDemocracy_df &lt;- Country_df |&gt; \n  select(Country, Continent, Polity_Score, FH_Total) |&gt;\n  filter(!is.na(Polity_Score), !is.na(FH_Total)) |&gt;\n  pivot_longer(cols      = contains(\"_\"),\n               names_to  = \"Type\",\n               values_to = \"Value\") |&gt;\n  mutate(Type = recode(Type,\n                       \"FH_Total\"     = \"Freedom House\",\n                       \"Polity_Score\" = \"Polity IV\"))\n\nDemocracy_df\n\n# A tibble: 316 × 4\n   Country     Continent Type          Value\n   &lt;chr&gt;       &lt;chr&gt;     &lt;chr&gt;         &lt;dbl&gt;\n 1 Afghanistan Asia      Polity IV        -1\n 2 Afghanistan Asia      Freedom House    27\n 3 Albania     Europe    Polity IV         9\n 4 Albania     Europe    Freedom House    67\n 5 Algeria     Africa    Polity IV         2\n 6 Algeria     Africa    Freedom House    34\n 7 Angola      Africa    Polity IV        -2\n 8 Angola      Africa    Freedom House    32\n 9 Argentina   America   Polity IV         9\n10 Argentina   America   Freedom House    85\n# ℹ 306 more rows\n\n\n　続いて、箱ひげ図の作成ですが、これは次元の追加と全く同じやり方になります。fillで色分けをするか、ファセット分割をするかですね。ここでは箱の色分けをします。\n\nDemocracy_df |&gt;\n  ggplot() +\n  geom_boxplot(aes(x = Continent, y = Value, fill = Type)) +\n  labs(x = \"大陸\", y = \"民主主義の程度\", fill = \"指標\") +\n  scale_x_discrete(breaks = c(\"Africa\", \"America\", \"Asia\",\"Europe\", \"Oceania\"), \n                   labels = c(\"アフリカ\", \"アメリカ\", \"アジア\", \"ヨーロッパ\", \"オセアニア\"))\n\n\n\n\n\n\n\n\n　しかし、1つ問題があります。それはPolity IVは-10から10までの指標なのに対して、Freedom Houseは0から100までの指標になっている点です。この場合、正確な比較が出来ません。複数の変数を1つの箱ひげ図に出す際は、変数のスケールが一致させた方が良いでしょう。たとえば、複数の人、または団体に対する感情温度はスケールが0から100であるため、使えます。しかし、今回の場合はあまり良いケースではありません。\n　もし、スケールが異なるものを示すためにはスケールを調整する必要があります。よく使われるのはスケールを平均0、標準偏差1にする「標準化」ですが、変数の分布を似通ったものにするため、あまり良くないかも知れません。ここではFreedom House指標から50を引き、そこから5で割った値を使います。こうすることで、Freedom House指標が100なら10、0なら-10になり、最小値と最大値のスケールをPolity IVに合わせることが可能です。\n\nDemocracy_df &lt;- Country_df |&gt; \n  select(Country, Continent, Polity_Score, FH_Total) |&gt;\n  # FH_Totalのすケース調整\n  mutate(FH_Total = (FH_Total - 50) / 5) |&gt;\n  filter(!is.na(Polity_Score), !is.na(FH_Total)) |&gt;\n  pivot_longer(cols      = contains(\"_\"),\n               names_to  = \"Type\",\n               values_to = \"Value\") |&gt;\n  mutate(Type2 = recode(Type,\n                        \"FH_Total\"     = \"Freedom House\",\n                        \"Polity_Score\" = \"Polity IV\"))\n\nDemocracy_df |&gt;\n  ggplot() +\n  geom_boxplot(aes(x = Continent, y = Value, fill = Type2)) +\n  labs(x = \"大陸\", y = \"民主主義の程度\", fill = \"指標\") +\n  scale_x_discrete(breaks = c(\"Africa\", \"America\", \"Asia\",\"Europe\", \"Oceania\"), \n                   labels = c(\"アフリカ\", \"アメリカ\", \"アジア\", \"ヨーロッパ\", \"オセアニア\"))\n\n\n\n\n\n\n\n\n　先よりは比較可能な図のように見えますが、あくまでも最小値と最大値を一致させたものであるため、厳密な意味ではこれもよくありません。複数の変数を1つの箱ひげ図としてまとめる場合は、スケールが一致するもののみを使うことを推奨します。"
  },
  {
    "objectID": "visualization2.html#sec-visual2-scatter",
    "href": "visualization2.html#sec-visual2-scatter",
    "title": "19  可視化 [基礎]",
    "section": "19.6 散布図",
    "text": "19.6 散布図\n　続いて、散布図の作成について解説します。散布図においてデータは点で表現され、点を表示するためには、少なくとも横軸と縦軸といった2つの情報が必要です。したがって、マッピングに使う変数は最低2つであり、横軸はx、縦軸はyで指定します。今回はCountry_dfを使って、一人当たりGDP (購買力平価基準)と人間開発指数の関係を調べてみましょう。散布図の幾何オブジェクト関数はgeom_point()です。そして、それぞれの変数はPPP_per_capita、HDI_2018であるから、マッピングはaes(x = PPP_per_capita, y = HDI_2018)になります。\n\nCountry_df |&gt;\n  ggplot() +\n  geom_point(aes(x = PPP_per_capita, y = HDI_2018)) +\n  labs(x = \"一人当たり購買力平価GDP (USD)\", y = \"人間開発指数\") +\n  theme_bw()\n\nWarning: Removed 11 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n\n\n　以下のメッセージが表示されますが、これは一人当たりGDP (購買力平価基準)または人間開発指数が欠損しているケースが11カ国あることを意味します。たとえば、教皇聖座 (Holy See; いわゆるバチカン)や西サハラ、ソマリアなどの国があります。\n## Warning: Removed 11 rows containing missing values (geom_point).\n　どのようなケースが除外されたかはdplyr::filter()関数を使えば簡単に調べられます。\n\nCountry_df |&gt; \n  filter(is.na(PPP_per_capita) | is.na(HDI_2018)) |&gt; \n  select(Country, PPP_per_capita, HDI_2018)\n\n# A tibble: 11 × 3\n   Country        PPP_per_capita HDI_2018\n   &lt;chr&gt;                   &lt;dbl&gt;    &lt;dbl&gt;\n 1 Andorra                   NA     0.857\n 2 Cuba                      NA     0.778\n 3 Holy See                  NA    NA    \n 4 Kosovo                 11078.   NA    \n 5 Liechtenstein             NA     0.917\n 6 Monaco                    NA    NA    \n 7 San Marino             62554.   NA    \n 8 Somalia                   NA     0.557\n 9 Syria                     NA     0.549\n10 Taiwan                 46145.   NA    \n11 Western Sahara            NA    NA    \n\n\n　このように何らかのケースが除外されたとメッセージが出力された場合、ちゃんとどのケースが除外されたかを確認することは重要です。この11カ国は未承認国や国内政治の不安定によりデータが正確に把握できないところがほとんどですね。\n　散布図を見ると経済力と人間開発指数の間には正の関係が確認できます。ただし、経済力が高くなるにつれ、人間開発指数の増加幅は減少していきます。どちらかと言えば対数関数のような関係でしょう。実際、scale_x_log10()や、scale_x_continuous(trans = \"log10\")などで横軸を対数化するとほぼ線形の関係が観察できます。今回は座標系を変換して横軸を対数化してみます。座標系の調整はcoord_*()関数群を使いますが、対数化にはcoord_trans()を使います。ここで変換する軸と変換方法を指定します。今回は横軸を底10の対数化を行うからx = \"log10\"と指定します。これはscale_x_log10()と全く同じですが、縦軸も対数化するなどの場面においてはcoord_trans()の方が便利でしょう。\n\nCountry_df |&gt;\n  ggplot() +\n  geom_point(aes(x = PPP_per_capita, y = HDI_2018)) +\n  labs(x = \"一人当たり購買力平価GDP (USD)\", y = \"人間開発指数\") +\n  coord_trans(x = \"log10\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n　対数化してみたら、かなり綺麗な線形関係が確認できます。事実を言うと、そもそも人間開発指数は所得も評価項目であるため、線形関係があるのは当たり前です。\n\n19.6.1 次元を追加する\n　散布図の点は横軸の数値と縦軸の数値を持っています。2次元平面で表現できる散布図は少なくとも2つの情報を持つことになります。しかし、2次元平面であっても、3つ以上の情報、つまり3次元以上の情報を示すことが可能です。たとえば、点ごとに色を変更することもできます。OECD加盟国と非加盟国に異なる色を与えると、2次元平面上であっても、3つの情報を含む散布図が作れます。他にも透明度（alpha）、点の形（shape）、大きさ（size）などで点に情報を持たせることが可能です。たとえば、国の面積に応じて点の大きさが変わる散布図を作成するならaes()内にsize = Areaを追加するだけです。面積の単位は非常に大きいので、Areaを100万で割った値を使います。また、点が大きくなると重なりやすくなるため、半透明（alpha = 0.5）にします。\n\nCountry_df |&gt;\n  mutate(Area2 = Area / 1000000) |&gt;\n  ggplot() +\n  geom_point(aes(x = PPP_per_capita, y = HDI_2018, size = Area2),\n             alpha = 0.5) +\n  labs(x = \"一人あたり購買力平価GDP (USD)\", y = \"人間開発指数\",\n       size = \"面積 (100万km2)\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n　一人当たりGDPが非常に高い国の多くは面積が小さい国が多いですね。\n　以上のコードでは、aes()だけでなく、labs()内にもsize引数を指定しました。labs()内にxとy以外の引数を指定することはヒストグラムのところでもしましたが、説明はしませんでした。ここで詳しく説明します。labs()内の引数はマッピング要素と対応します。今回はgeom_point()幾何オブジェクト内にx、y、sizeがあり、それぞれにラベルを付けることになります。これを指定しない場合、変数名がデフォルト値として出力されます。xとyは縦軸と横軸のラベルですが、その他のマッピング要素は凡例として出力される場合が多いです。凡例のラベルを修正したい時にはとりあえずlabs()から覗いてみましょう。\n　続きまして、もう一つ次元を追加してみましょう。散布図は他のグラフに比べ次元拡張が容易なグラフです。ここでは色分けをしてみましょう。たとえば、OECD加盟有無（OECD）で色分けする場合、これまでと同様、colorをaes()内に加えるだけです。\n\nCountry_df |&gt;\n  mutate(Area2 = Area / 1000000) |&gt;\n  ggplot() +\n  geom_point(aes(x = PPP_per_capita, y = HDI_2018, \n                 size = Area, color = OECD)) +\n  labs(x = \"一人あたり購買力平価GDP (USD)\", y = \"人間開発指数\",\n       size = \"面積 (100万km2)\", color = \"OECD加盟有無\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n　色分けはされていますが、凡例を見ると想像したものとやや違いますね。なぜならOECD変数が数値型になっているからです。実際のデータにはOECD = 0.5やOECD = 0.71のような値は存在しませんが、数値型である以上、その値をとること自体は出来ます。したがって、0から1までの数値に対応できるように、色分けもグラデーションになっています。これを見やすく二分するためには、OECD変数をfactor型か文字型に変換する必要があります。\n\nCountry_df |&gt;\n  mutate(Area2 = Area / 1000000,\n         OECD2 = factor(OECD, levels = 0:1, \n                      labels = c(\"非加盟国\", \"加盟国\"))) |&gt;\n  ggplot() +\n  geom_point(aes(x = PPP_per_capita, y = HDI_2018, \n                 size = Area2, color = OECD2)) +\n  labs(x = \"一人あたり購買力平価GDP (USD)\", y = \"人間開発指数\",\n       size = \"面積 (100万km2)\", color = \"OECD加盟有無\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n　これで散布図の出来上がりです。2次元座標系で表現された散布図ですが、この図から分かる情報は何があるでしょうか。\n\n一人当たり購買力平価GDP\n人間開発指数\n面積\nOECD加盟有無\n\n　1つの図から4つの情報が読み取れます。つまり、4次元グラフと言えます。ここにファセット分割、透明度の調整、点の形の変更まですると7次元のグラフもできます。ただし、あまりにも次元数の多いグラフは読みにくくなるため、必要だと思う変数のみマッピングしましょう。\n\n\n19.6.2 一部の点をハイライトする\n　これまでの図と比べ、散布図は一般的に表示される情報が多いです。棒グラフ、箱ひげ図の場合、数個、あるいは十数個程度の項目ごとに棒や箱が出力されますが、散布図の場合、データのサイズだけ点が出力されます。むろん、散布図というのは個々の点の情報よりも二変数間の関係を確認するために使われるため、これは短所ではありません。\n　しかし、散布図の中で一部の点をハイライトしたい場合もあるでしょう。たとえば、先ほどの図において日中韓だけハイライトするためにはどうすれば良いでしょうか。まず、考えられるのはcolorによるマッピングでしょう。Country変数を日本、韓国、中国、その他の4つの水準にまとめ、この値によって色分けをすればいいでしょう。実際にやってみましょう。\n\nCountry_df |&gt;\n  mutate(Area2    = Area / 1000000,\n         Country2 = case_when(Country == \"Japan\"       ~ \"Japan\",\n                              Country == \"South Korea\" ~ \"South Korea\",\n                              Country == \"China\"       ~ \"China\",\n                              TRUE                     ~ \"Other\"),\n         Country2 = factor(Country2, \n                           levels = c(\"Japan\", \"South Korea\", \"China\",\n                                      \"Other\"),\n                           labels = c(\"Japan\", \"South Korea\", \"China\",\n                                      \"Other\"))) |&gt;\n  ggplot() +\n  geom_point(aes(x = PPP_per_capita, y = HDI_2018, \n                 size = Area2, color = Country2)) +\n  labs(x = \"一人あたり購買力平価GDP (USD)\", y = \"人間開発指数\",\n       size = \"面積 (100万km2)\", color = \"国家\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n　日本と韓国を見つけるのは大変ですが、目的達成と言えるでしょう。ただ、もっと楽な方法があります。それが湯谷啓明さんが開発した{gghighlight}パッケージです。詳しい使い方は湯谷さんによる解説ページを参照して頂きますが、ここでは簡単な使い方のみ紹介します。まずは、install.packages(\"gghighlight\")でパッケージをインストールし、読み込みます。\n\npacman::p_load(gghighlight)\n\n　続いてですが、国ごとに色分けする予定ですので、散布図のcolorはCountry変数でマッピングします。そして、{gghighlight}幾何オブジェクトを追加します。まずは使い方からです。\n\n# gghighlight()の使い方\ngghighlight(条件式, label_params = list(引数1, 引数2, ...))\n\n　第一引数は条件式であり、これはdplyr::filter()の条件式をそのまま使えます。そして、label_parmsを指定しますが、実引数はリスト型です。中にはgeom_labels()幾何オブジェクトに使用する引数が使えます。たとえば、ハイライトされた点にはラベルが付きますが、size引数を入れてラベルの大きさを指定できます。それでは実際にやってみましょう。条件式はCountry %in% c(\"Japan\", \"South Korea\", \"China\")であり、ラベルの大きさは3にします。\n\nCountry_df |&gt;\n  mutate(Area2 = Area / 1000000) |&gt;\n  ggplot() +\n  geom_point(aes(x = PPP_per_capita, y = HDI_2018, \n                 size = Area2, color = Country)) +\n  gghighlight(Country %in% c(\"Japan\", \"South Korea\", \"China\"),\n              label_params = list(size = 3)) +\n  labs(x = \"一人あたり購買力平価GDP (USD)\", y = \"人間開発指数\",\n       size = \"面積 (100万km2)\", color = \"OECD加盟有無\") +\n  theme_bw()\n\n\n\n\n\n\n\n\n　非常に簡単なやり方で点のハイライトが出来ました。これは後ほど紹介する折れ線グラフだけでなく、様々な幾何オブジェクトにも対応しています。湯谷さんの解説ページを参照して下さい。"
  },
  {
    "objectID": "visualization2.html#sec-visual2-line",
    "href": "visualization2.html#sec-visual2-line",
    "title": "19  可視化 [基礎]",
    "section": "19.7 折れ線グラフ",
    "text": "19.7 折れ線グラフ\n　続きまして、折れ線グラフについて解説します。折れ線グラフは横軸が順序付き変数、縦軸は連続変数になります。横軸は順序付きであれば、年月日のような離散変数でも、連続変数でも構いません。注意すべき点は横軸上の値はグループ内において1回のみ登場するという点です。たとえば、株価のデータなら「2020年8月8日」はデータは1回だけ登場します。世界各国の株価データなら、グループ（国）内において「2020年8月8日」は一回のみ登場することになります。\n　必要なマッピング要素は線の傾きが変化しうるポイントの横軸上の位置（x）と縦軸上の位置（y）です。ここではCOVID-19の新規感染者数データを使用します。まず、Date変数が文字型になっているため、これをDate型に変換します。文字型の場合、順序関係がないからです。基本的に折れ線グラフの横軸になり得るデータ型はnumeric、順序付きfactor、Date、complex型だと考えていただいても結構です。\n\nCOVID19_df &lt;- COVID19_df |&gt;\n  mutate(Date = as.Date(Date))\n\n　それでは図を作成してみましょう。横軸は日付（Date）、縦軸は累積感染者数（Confirmed_Total）にしましょう。また、縦軸のスケールは底10の対数を取ります。感染者数が数百万人となるアメリカと、数万人の国が同じグラフになると、見にくくなるからです。\n\nCOVID19_df |&gt;\n  ggplot() +\n  geom_line(aes(x = Date, y = Confirmed_Total)) +\n  scale_y_continuous(breaks = c(10, 100, 1000, 10000, 100000, 1000000),\n                     labels = c(\"10\", \"100\", \"1000\", \"10000\", \n                                \"100000\", \"1000000\"),\n                     trans = \"log10\") +\n  labs(x = \"月\", y = \"累積感染者数 (人)\") +\n  theme_minimal()\n\nWarning: Transformation introduced infinite values in continuous y-axis\n\n\n\n\n\n\n\n\n\n　??????????????????\n　なんでしょう…。想像したものと違いますね。また、警告メッセージも出力されますが、これは0を対数化すると-Infになるから出力されるものです。大きな問題はないので、ここでは無視しましょう。\n　先ほど申し上げた通り、横軸の値はデータ内に1回のみ登場すべきです。しかし、COVID19_dfの場合、（たとえば）2020年5月1日の行が国の数だけあります。この場合は、ちゃんと国（Country）ごとに線を分けるように指定する必要があります。ここで使うマッピング要素がgroupです。groupで指定した変数の値ごとに異なる折れ線グラフを出力してくれます。\n\nCOVID19_df |&gt;\n  ggplot() +\n  geom_line(aes(x = Date, y = Confirmed_Total, group = Country)) +\n  scale_y_continuous(breaks = c(10, 100, 1000, 10000, 100000, 1000000),\n                     labels = c(\"10\", \"100\", \"1000\", \"10000\", \n                                \"100000\", \"1000000\"),\n                     trans = \"log10\") +\n  labs(x = \"月\", y = \"累積感染者数 (人)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　これで折れ線グラフは出力されましたが、どの線がどの国かが分かりませんね。groupの場合、凡例が表示されないので、groupでなく、colorで色分けしてみましょう。\n\nCOVID19_df |&gt;\n  ggplot() +\n  geom_line(aes(x = Date, y = Confirmed_Total, color = Country)) +\n  scale_y_continuous(breaks = c(10, 100, 1000, 10000, 100000, 1000000),\n                     labels = c(\"10\", \"100\", \"1000\", \"10000\", \n                                \"100000\", \"1000000\"),\n                     trans = \"log10\") +\n  labs(x = \"月\", y = \"累積感染者数 (人)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　???????????????????\n　なんか出ましたが、国数が多すぎて凡例だけで図が埋め尽くされています。この場合、方法は3つあります。1つ目の方法は図のサイズを大きくする方法です。これは保存の際、サイズを再調整するだけですので、ここでは割愛します。また、それでも凡例内の項目が非常に多いグラフをグラフの種類と関係なく推奨されません。2つ目は国を絞る方法であり、3つ目はgghighlight()で一部の国のみハイライトする方法です。まずは、G7（カナダ、フランス、ドイツ、イタリア、日本、イギリス、アメリカ）のみデータを絞って折れ線グラフを作ってみましょう。\n\nG7 &lt;- c(\"Cananda\", \"France\", \"Germany\", \"Italy\", \"Japan\", \n        \"United Kingdom\", \"United States\")\n\nCOVID19_df |&gt;\n  filter(Country %in% G7) |&gt;\n  ggplot() +\n  geom_line(aes(x = Date, y = Confirmed_Total, color = Country)) +\n  scale_y_continuous(breaks = c(10, 100, 1000, 10000, 100000, 1000000),\n                     labels = c(\"10\", \"100\", \"1000\", \"10000\", \n                                \"100000\", \"1000000\"),\n                     trans = \"log10\") +\n  labs(x = \"月\", y = \"累積感染者数 (人)\", color = \"国\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　これだけでもG7国のCOVID-19の状況が比較可能ですが、この図は改善の余地があります。それは凡例の順番です。できれば、一番最新の日付のデータを基準に凡例の順番を揃えることが出来たら、どの線がどの国かが分かりやすくなります。そこで登場するのは第15章で紹介しましたfct_reorder2関数です。実際にやってみましょう。また、線の太さも今より太めにしてみたいと思います。線の太さはlinewidthで調整可能であり、既定値は0.5です。0.5より大きい場合はより太い線になります。\n\nCOVID19_df |&gt;\n  filter(Country %in% G7) |&gt;\n  mutate(Country = fct_reorder2(Country, Date, Confirmed_Total, last2)) |&gt;\n  ggplot() +\n  geom_line(aes(x = Date, y = Confirmed_Total, color = Country),\n            linewidth = 0.75) +\n  scale_y_continuous(breaks = c(10, 100, 1000, 10000, 100000, 1000000),\n                     labels = c(\"10\", \"100\", \"1000\", \"10000\", \n                                \"100000\", \"1000000\"),\n                     trans = \"log10\") +\n  labs(x = \"月\", y = \"累積感染者数 (人)\", color = \"国\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　これでより読みやすい図が出来上がりました。\n\n19.7.1 一部の線をハイライトする\n　グループが多すぎる場合の対処法、その2つ目はデータを全て使い、一部の国のみハイライトする方法です。線のハイライトにもgghighlight()が使えます。同じく日米中韓の線のみハイライトしてみましょう。\n\nCOVID19_df |&gt;\n  ggplot() +\n  geom_line(aes(x = Date, y = Confirmed_Total, color = Country)) +\n  gghighlight(Country %in% c(\"Japan\", \"China\", \"South Korea\",\n                             \"United States\")) +\n  scale_y_continuous(breaks = c(10, 100, 1000, 10000, 100000, 1000000),\n                     labels = c(\"10\", \"100\", \"1000\", \"10000\", \n                                \"100000\", \"1000000\"),\n                     trans = \"log10\") +\n  labs(x = \"月\", y = \"累積感染者数 (人)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　情報量の損失を最小化しながら、一部の国のみをハイライトすることによって世界における日米中韓のトレンドが確認出来ました。"
  },
  {
    "objectID": "visualization2.html#sec-visual2-japanese",
    "href": "visualization2.html#sec-visual2-japanese",
    "title": "19  可視化 [基礎]",
    "section": "19.8 日本語が含まれた図について",
    "text": "19.8 日本語が含まれた図について\n(以下は作成中の内容)\n　{ggplot2}で作成した図に日本語が含まれている場合、日本語が正しく表示されない場合があります。また、RStudioのPlotsペインには日本語が表示されていても、PDF/PNG/JPGなどのファイルとして出力した場合、表示されないケースもあります。{ggplot2}の使い方を解説する前に、ここでは日本語が正しく表示/出力されない場合の対処法について紹介します。\n\n19.8.1 macOSの場合\n　今後紹介する{ggplot2}の図の最後に以下のようなレイヤーを追加すればヒラギノフォントを使用することができます。\n\ntheme(text = element_text(family = \"HiraginoSans-W3\"))\n\n　または、theme_bw()やtheme_minimal()など、特定のテーマを使用するのであればそのテーマのレイヤーにフォントを指定することもできます。たとえば、{ggplot2}のデフォルトテーマであるgrayテーマを使用するなら、{ggplot2}のオブジェクトに以下のようなレイヤーを追加する。\n\ntheme_gray(base_familiy = \"HiraginoSans-W3\")\n\n　もう一つの方法としましては、コードの最初に以下のようなコードを追加します。このコードが実行された以降の図には全てヒラギノフォントが適用されます。\n\ntheme_update(text = element_text(family = \"HiraginoSans-W3\"))\n\n　ただし、いずれの方法でも、geom_text()、geom_label()、annotate()のような文字列を出力する幾何オブジェクトを使用する際は、各レイヤーごとにフォント族を指定する必要があります (幾何オブジェクト内にfamily = \"HiraginoSans-W3\"を追加)。\n　作成した図ファイル (PDF) として出力 (保存) する際はquartz()関数とdev.off()関数の間に{ggplot2}で作成したオブジェクト名を入れるだけです。図でフォントが正しく指定されていれば、問題なく日本語を含まれたPDF形式の図が保存できます。\n\nquartz(file = \"出力するファイル名\", type = \"pdf\", width = 幅, height = 高さ)\n{ggplot2}で作成した図のオブジェクト名\ndev.off()\n\n　PNG形式の図を保存する場合は、後述する{ragg}パッケージの仕様をおすすめします。\n\n\n19.8.2 Windowsの場合\n???\n\n\n19.8.3 {ragg}の使用\n　{ragg}パッケージを使用すると、使用するOSと関係なくRStudioのPlotsペイン、R Markdown (HTML出力)の文字化けを回避することができます。{ragg}はインストールのみで十分であり、別途読み込む必要がないため、インストールだけします。\n\npacman::p_install(ragg)\n\n　RStudio上の文字化けを回避するためには、RStudioの設定を以下のように変更します。\n\nRStudioのTools&gt;Global Options…\n左のGeneral&gt;右側上段のGraphicsタブ\nGraphic DeviceのBackendでAGGを選択\n\n　R Markdown (HTML出力)の場合、YAMLヘッダーの直後に以下のようなチャンクを追加します。チャンクのオプションとしてinclude = FALSEを指定しておけば、出力結果にコードが表示されなくなるため、指定するのを推奨します。dpiは任意の値で良いですが、PNG形式の場合、解像度が低いと見た目があまり良くないため、150以上に設定することをおすすめします。Web表示だけなら150でも良いですが、印刷を考えると300がおすすめです。\n\nknitr::opts_chunk$set(dev = \"ragg_png\", dpi = 300)"
  },
  {
    "objectID": "visualization2.html#sec-visual2-save",
    "href": "visualization2.html#sec-visual2-save",
    "title": "19  可視化 [基礎]",
    "section": "19.9 図の保存",
    "text": "19.9 図の保存\n　綺麗な図も出来上がりましたので、みんなに自慢してみましょう。ただ、自慢のためにパソコンを持ち歩くのは大変なので、ファイルと保存してみんなに配りましょう。自慢する相手がいないならSONGに自慢しても結構です。図のフォーマットはPNGかPDFが一般的です。JPEGなど圧縮フォーマットは絶対にダメです。PNGとPDFは前者はピクセルベース、後者がベクトルベースで、PDFの方が拡大してもカクカクせず綺麗です。ただし、一部の文書作成ソフトウェアでPDFを図として扱えない点や、サイズの問題 (複雑な図になるほど、PDFの方がサイズが大きくなる)もあるので、PNGを使うケースも多いです。むろん、LaTeXで文章を作成するなら、PDF一択です。\n　保存方法として以下の3つを紹介します。\n\n19.9.1 ggsave()を利用した図の保存\n　ggsave()が{ggplot2}が提供する図の保存関数です。まずは、使い方から紹介します。\n\n# ggsave()を利用した保存方法\nggsave(filename = \"ファイル名\",\n       plot     = 図のオブジェクト名,\n       device   = \"pdf\"や\"png\"など,\n       width    = 図の幅,\n       height   = 図の高さ、\n       units    = \"in\"や\"cm\"など、幅/高さの単位,\n       dpi      = 図の解像度)\n\n　deviceで指定可能なフォーマットとしては\"png\"、\"eps\"、\"ps\"、\"tex\"、\"pdf\"、\"jpeg\"、\"tiff\"、\"bmp\"、\"svg\"、\"wmf\"があります。また、unitsは\"in\" (インチ)、\"cm\"、\"mm\"が指定可能です。他にもdpi引数でdpi (dots per inch; 1平方インチにどれだけのドットの表現ができるか)の指定も可能ですが、デフォルトは300となっており、出版用としては一般的なdpiとなっています。それでは、本章の最初に作成した棒グラフをBarPlot1という名で保存し、Figsフォルダー内にBarPlot1.pngとして保存してみます。幅と高さは5インチにします。\n\nBarPlot1 &lt;- Country_df |&gt;\n  ggplot() +\n  geom_bar(aes(x = Continent)) +\n  labs(x = \"大陸\", y = \"ケース数\") +\n  theme_bw()\n\nggsave(filename = \"Figs/BarPlot.png\",\n       plot     = BarPlot1,\n       device   = \"png\",\n       width    = 5,\n       height   = 5,\n       units    = \"in\")\n\n\n\n19.9.2 quartz()を利用した図の保存\n　macOSを使用し、日本語などのマルチバイトの文字が含まれる図の場合、ggsave()が正しく作動しません。この場合はquartz()とdev.off()関数を利用して図を保存します。この関数の使い方は以下の通りです。\n\n# quartz()を利用した保存方法\nquartz(type = \"pdf\", file = \"ファイル名\", width = 図の幅, height = 図の高さ)\n作図のコード、または図オブジェクトの呼び出し\ndev.off()\n\nquartz()のwidthとheight引数の場合、単位はインチ (=2.54cm)です。\n　たとえば、最初に作成した図をFigsフォルダーのBarPlot1.pdfという名で保存し、幅と高さを5インチにするなら以下のようなコードになります。\n\n# 方法1\nquartz(type = \"pdf\", file = \"Figs/BarPlot1.pdf\", width = 5, height = 5)\nCountry_df |&gt;\n  ggplot() +\n  geom_bar(aes(x = Continent)) +\n  labs(x = \"大陸\", y = \"ケース数\") +\n  theme_bw()\ndev.off()\n\n　または、予め図をオブジェクトとして保存しておいたなら (先ほどのBarPlot1オブジェクトのように)、以下のようなコードも可能です。\n\n# 方法2\nquartz(type = \"pdf\", file = \"Figs/BarPlot1.pdf\", width = 5, height = 5)\nBarPlot1\ndev.off()\n\n{ragg}が導入されている状態で、図をPNG形式のファイルとして保存 (出力) したい場合は、2つの方法があります。\n\n\n19.9.3 {ragg}が導入済みの場合\nPNG形式限定\n方法1: ragg::agg_png()を使用する。\n　これはragg::agg_png()関数とdev.off()関数の間に{ggplot2}で作成したオブジェクト名を入れる方法でmacOSのquartz()関数とほぼ同じ使い方です。ただし、仮引数名が異なるため、注意してください。また、dpiの仮引数は存在せず、代わりにresを使います。\n\nragg::agg_png(filename = \"出力するファイル名\", res = 300, \n              width = 幅, height = 高さ)\n{ggplot2}で作成した図のオブジェクト名\ndev.off()\n\n方法2: ggsave()にdevice = ragg::agg_pngを指定する。\n　この方法は{ggplot2}が提供するggsave()関数を使用する方法です。ここではdeviceにragg:agg_pngを指定すれば、日本語が文字化けせずPNG形式のファイルとして保存されます。\n\nggsave(filename = \"出力するファイル名\", \n       plot     = 図のオブジェクト名,\n       device   = ragg::agg_png,\n       dpi      = 150,\n       width    = 幅, \n       height   = 高さ)\n\n　PDFファイルとして出力したい場合は各OSごとの説明を参照してください。"
  },
  {
    "objectID": "visualization2.html#sec-visual2-summary",
    "href": "visualization2.html#sec-visual2-summary",
    "title": "19  可視化 [基礎]",
    "section": "19.10 まとめ",
    "text": "19.10 まとめ\n　以上の話をまとめると、データが与えられた場合、ある図を作成するためには少なくとも以下の情報が必要です。\n\nどの幾何オブジェクトを使用するか\nその幾何オブジェクトに必要なマッピング要素は何か\n\n　座標系や、スケール、ラベルの設定なども最終的には必要ですが、これらは設定しなくても{ggplot2}自動的に生成してくれます。しかし、幾何オブジェクトとマッピングは必須です。幾何オブジェクトはグーグルで「ggplot 棒グラフ」や「ggplot 等高線図」などで検索すれば、どのような幾何オブジェクトが必要化が分かります。問題はマッピングです。この幾何オブジェクトに使える引数は何か、そしてどの引数をaes()の中に入れるべきかなどはコンソールで?geom_barplotなどで検索すれば分かります。\n　筆者のオススメは以下のチートシートを印刷し、手元に置くことです。\n\nggplot2 cheatsheet\nggplot2 aesthetics cheatsheet\n\n　2番目の資料は非常に分かりやすい資料ですが、Google Drive経由で公開されているため、いつリンクが切れかが不明です。念の為に本ページにも資料を転載します。\n\n\n\n\n\nggplot2 aesthetics cheatsheet\n\n\n\n\n　青い点は「ほとんど」のケースにおいてaes()の中に位置する引数です。ただし、geom_bar()とgeom_histogram()は自動的に度数を計算してくれるため、xとy一方だけでも可能です。黄色い資格はaes()の中でも、外でも使うことが可能な引数です。aes()の中ならマッピング要素となるため、データの変数と対応させる必要があります。ピンク色のひし形四角形は必ずaes()の外に位置する引数です。"
  },
  {
    "objectID": "visualization2.html#sec-visual2-excersie",
    "href": "visualization2.html#sec-visual2-excersie",
    "title": "19  可視化 [基礎]",
    "section": "練習問題",
    "text": "練習問題"
  },
  {
    "objectID": "visualization3.html#sec-visual3-labs",
    "href": "visualization3.html#sec-visual3-labs",
    "title": "20  可視化 [応用]",
    "section": "20.1 labs(): ラベルの修正",
    "text": "20.1 labs(): ラベルの修正\n　既にlabs()レイヤーは第19章で使ったことがあるでしょう。ここではlabs()の仕組みについて簡単に解説します。\n　labs()関数は軸、凡例、プロットのラベル（タイトルなど）を修正する際に使用する関数です。軸ラベルは横軸（x）と縦軸（y）のラベルを意味します。指定しない場合は、マッピングで指定した変数名がそのまま出力されます。これは凡例ラベルも同じです。{ggplot2}は2次元のグラフの出力に特化したパッケージであるため、出力される図には必ず横軸と縦軸があります。したがって、引数としてxとyは常に指定可能です。\n　一方、凡例はマッピングされない場合、表示されません。幾何オブジェクトのaes()内にcolor、size、linetypeなどの要素がマッピングされてから初めて凡例で表示されます。凡例が存在することは何かの要素にマッピングがされていることを意味します。このマッピング要素名（color、size、linetypeなど）をlabs()の引数として使うことで凡例のラベルが修正されます。マッピングされていない要素に対してラベルを指定しても、図に影響はありません。たとえば、Country_dfの一人あたりGDP（GDP_per_capita）を横軸、フリーダムハウスのスコア（FH_Total）を縦軸にした散布図を作成します。\n\nCountry_df |&gt;\n    ggplot() +\n    geom_point(aes(x = FH_Total, y = GDP_per_capita)) +\n    labs(x = \"フリーダムハウススコア\",y = \"一人あたりGDP (USD)\", \n         color = \"大陸\") +\n    theme_bw(base_size = 12)\n\n\n\n\n\n\n\n\n　geom_point()は横軸と縦軸のみにマッピングをしているため、labs()にcolor =を指定しても何の変化もありません。そもそも凡例が存在しないからです。それでは大陸ごとに色分けした散布図に修正してみましょう。\n\nCountry_df |&gt;\n    ggplot() +\n    geom_point(aes(x = FH_Total, y = GDP_per_capita, color = Continent)) +\n    labs(x = \"フリーダムハウススコア\",y = \"一人あたりGDP (USD)\", \n         color = \"大陸\") +\n    theme_bw(base_size = 12)\n\n\n\n\n\n\n\n\ncolorにContinent変数をマッピングすることによって、各点の色は何らかの情報を持つようになりました。そして各色がContinentのどの値に対応しているかを示すために凡例が表示されます。凡例のラベルはデフォルトは変数名（この例の場合、「Continent」）ですが、ここでは「大陸」と修正されました。\n　ここまでが第19章で使用しましたlabs()レイヤーの使い方です。他にもlabs()はプロットのラベルを指定することもできます。ここでいう「プロットのラベル」とはプロットのタイトルとほぼ同じです。使用可能な引数はtitle、subtitle、tagです。\n\nCountry_df |&gt;\n    ggplot() +\n    geom_point(aes(x = FH_Total, y = GDP_per_capita, color = Continent)) +\n    labs(x = \"フリーダムハウススコア\",y = \"一人あたりGDP (USD)\", color = \"大陸\",\n         title = \"民主主義の度合いと所得の関係\", subtitle = \"大陸別の傾向\", \n         tag = \"(a)\") +\n    theme_bw(base_size = 12)\n\n\n\n\n\n\n\n\n　titleは図のメインタイトルとおり、プロットのタイトルを意味します。上の図だと「民主主義の度合いと所得の関係」です。また、subtitle引数を指定することでサブタイトルを付けることも可能です。上の図の「大陸別の傾向」がサブタイトルです。最後のtagは複数の図を並べる際に便利な引数です。図が横に2つ並んでいる場合、それぞれ(a)と(b)という識別子を付けると、文中において「図3(a)は…」のように、引用しやすくなります。この「(a)」がtag引数に対応します。複数の図を並べる方法は本章の後半にて説明します。\n最後にキャプションの付け方について説明します。たとえば、外部のデータを利用して作図を行った場合、図の右下に「データ出典：〜〜」や「Source: https://www.jaysong.net 」などを付ける場合があります。このキャプションはlabs()関数内にcaption引数を指定するだけで付けることができます。たとえば、先程の図に「Source: Freedom House」を付けてみましょう。\n\nCountry_df |&gt;\n    ggplot() +\n    geom_point(aes(x = FH_Total, y = GDP_per_capita, color = Continent)) +\n    labs(x = \"フリーダムハウススコア\",y = \"一人あたりGDP (USD)\", color = \"大陸\",\n         title = \"民主主義の度合いと所得の関係\", subtitle = \"大陸別の傾向\", \n         tag = \"(a)\", caption = \"Source: Freedom House\") +\n    theme_bw(base_size = 12)"
  },
  {
    "objectID": "visualization3.html#sec-visual3-coordinate",
    "href": "visualization3.html#sec-visual3-coordinate",
    "title": "20  可視化 [応用]",
    "section": "20.2 coord_*(): 座標系の調整",
    "text": "20.2 coord_*(): 座標系の調整\n　{ggplot2}はいくつかの座標系を提供しています。円グラフを作成する際に使われる極座標系（coord_polar()）や地図の出力によく使われるcoord_map()やcoord_sf()がその例です。中でも最も頻繁に使われる座標系はやはり縦軸と横軸は直交する直交座標系（デカルト座標系）でしょう。ここでは直交座標系の扱い方について解説します。\n\n20.2.1 直交座標系の操作\n　まずは座標系の上限と下限を指定する方法から考えましょう。日米中間のCOVID-19累積感染者数の折れ線グラフを作成してみましょう。\n\nFig1 &lt;- COVID19_df |&gt;\n  mutate(Date = as.Date(Date)) |&gt;\n  filter(Country %in% c(\"Japan\", \"South Korea\", \"China\", \"United States\")) |&gt;\n  ggplot() +\n  geom_line(aes(x = Date, y = Confirmed_Total, color = Country)) +\n  labs(x = \"月\", y = \"累積感染者数 (人)\") +\n  theme_minimal(base_size = 12)\n\nprint(Fig1)\n\n\n\n\n\n\n\n\n　アメリカの感染者が圧倒的に多いこともあり、日韓がほぼ同じ線に見えます。これを是正するために対数変換などを行うわけですが、対数変換したグラフは直感的ではないというデメリットがあります。それでもう一つの方法として、アメリカに関する情報は一部失われますが、縦軸の上限を10万にすることが考えられます。直交座標系の上限・下限を調整する関数がcoord_cartesian()です。横軸はxlim、縦軸はylim引数を指定し、実引数としては長さ2のnumericベクトルを指定します。たとえば、縦軸の下限を0、上限を10万にするなら、ylim = c(0, 100000)となります。先ほどの図は既にFig1という名のオブジェクトとして保存されているため、ここにcoord_cartesian()レイヤーを追加してみましょう。\n\nFig1 +\n  coord_cartesian(ylim = c(0, 100000))\n\n\n\n\n\n\n\n\n3月下旬以降、アメリカの情報は図から失われましたが、日中韓についてはよりトレンドの差が区別できるようになりました。{ggplot2}は座標系の上限と下限をデータの最小値と最大値に合わせて自動的に調整してくれます。たとえば、以下のような例を考えてみましょう。\n\nFig2 &lt;- tibble(Class = paste0(LETTERS[1:5], \"組\"),\n       Score = c(78, 80, 85, 77, 70)) |&gt;\n  ggplot() +\n  geom_bar(aes(x = Class, y = Score), stat = \"identity\") +\n  labs(x = \"クラス\", y = \"数学成績の平均 (点)\") +\n  theme_minimal(base_size = 12)\n\nprint(Fig2)\n\n\n\n\n\n\n\n\n　数学成績平均値は最大100点までありえますが、手元のデータにおける最高得点が85店であるため、棒グラフの縦軸の上限が85点程度となります。この場合、上限は満点である100点に調整した方が良いでしょう。\n\nFig2 +\n  coord_cartesian(ylim = c(0, 100))\n\n\n\n\n\n\n\n\n　このように上限を調整すると、成績の満点が何点かに関する情報が含まれ、グラフにより豊富な情報を持たせることが可能です。\n\n\n20.2.2 座標系の変換\n　続きまして座標系の変換について説明します。座標系の変換については実は第19章でも取り上げました。対数化がその例です。例えば、連続型変数でマッピングされた横軸を底が10の対数化する場合、以下のような方法が考えれます。\n\nlog10()関数を使用し、データレベルで値を対数化する\nscale_x_continuous()レイヤーを重ね、trans = \"log10\"引数を指定する\nscale_x_log10()レイヤーを重ねる\ncoord_trans()レイヤーを重ね、x = \"log10\"引数を指定する\n\n　どの方法でも得られる結果はさほど変わりませんが、coord_trans()は座標系全般を調整することができます。たとえば、xlimやylim引数を使って座標系の上限と下限を同時に指定することも可能です。たとえば、座標系の上限を横軸は[0, 100]、縦軸は[-100, 100]とし、全て対数化を行うとします。方法はいくつか考えられます。たとえば、scale_*_log10()とcoord_cartesian()を組み合わせることもできます。\n\n# coord_trans()を使用しない場合\nggplotオブジェクト +\n  scale_x_log10() +\n  scale_y_log10() +\n  coord_cartesian(xlim = c(0, 100), ylim = c(-100, 100))\n\n　しかし、上のコードはcoord_trans()を使うと一行にまとめることができます。\n\n# coord_trans()を使用する場合\nggplotオブジェクト +\n  coord_trans(x = \"log10\", y = \"log10\", xlim = c(0, 100), ylim = c(-100, 100))\n\n　coord_trans()のx、y引数は\"log10\"以外にもあります。自然対数変換の\"log\"、反転を意味する\"reverse\"、平方根へ変換する\"sqrt\"などがあります。グラフを上下、または左右に反転する\"reverse\"は覚えておいて損はないでしょう。こちらは具体的には{tidyverse}パッケージ群に含まれている{scales}パッケージにある*_trans()関数に対応することになります。詳細は{scales}パッケージのヘルプを参照してください。\n\n\n20.2.3 座標系の回転\n　続きまして座標系を反時計方向回転するcoord_flip()について紹介します。以下はCountry_dfを用い、大陸（Continent）ごとにPolity IVスコア（Polity_Score）の平均値を示した棒グラフです。\n\nFlip_Fig &lt;- Country_df |&gt;\n  group_by(Continent) |&gt;\n  summarise(Democracy = mean(Polity_Score, na.rm = TRUE),\n            .groups   = \"drop\") |&gt;\n  ggplot() +\n  geom_bar(aes(x = Continent, y = Democracy), stat = \"identity\") +\n  labs(x = \"大陸\", y = \"Polity IV スコアの平均値\") +\n  theme_minimal(base_size = 12)\n\nprint(Flip_Fig)\n\n\n\n\n\n\n\n\n　この図を反時計方向回転する場合は以上のプロットにcoord_flip()レイヤーを追加します。\n\nFlip_Fig +\n  coord_flip() # 座標系の回転\n\n\n\n\n\n\n\n\n　非常に簡単な方法で図を回転させることができました。しかし、実はこのcoord_flip()関数、最近になって使う場面がどんどん減っています。たとえば、先ほどのgeom_bar()幾何オブジェクトの場合、xをPolity IVスコアの平均値で、yを大陸名でマッピングすることが可能です。昔の{ggplot2}は横軸と縦軸にマッピングでいるデータ型が厳格に決まっていましたが、最近になってはますます柔軟となってきました1。coord_flip()を使用する前に、各幾何オブジェクトのヘルプを確認し、coord_flip()を用いた回転が必要か否かを予め調べておくのも良いでしょう。\n\n\n20.2.4 座標系のアスペクト比の固定\n　他にも地味に便利な機能として座標系比を固定するcoord_fixed()を紹介します。これは出力される座標系の「横:縦」を調整するレイヤーです。たとえば、以下のような散布図を考えてみましょう。\n\nggplot() +\n  geom_point(aes(x = 1:10, y = 1:10))\n\n\n\n\n\n\n\n\n　こちらは横と縦が同じスケールでありますが、図の大きさに応じて、見た目が変わってきます。たとえば、上の図だと、横軸における1間隔は縦軸のそれの約2倍です。もし、図を上下に大きくし、左右を縮小したら同じ図でありながら随分と見た目が変わってきます。\n\nggplot() +\n  geom_point(aes(x = 1:10, y = 1:10))\n\n\n\n\n\n\n\n\n　2つの図は本質的に同じですが、図の見せ方によって、傾きが緩やかに見せたり、急に見せたりすることができます。ここで活躍するレイヤーがcoord_fixed()です。これを追加すると横を1とした場合の縦の比率を指定することができます。\n\nggplot() +\n  geom_point(aes(x = 1:10, y = 1:10)) +\n  coord_fixed(ratio = 1)\n\n\n\n\n\n\n\n\n　ratio = 1を指定すると縦横比は1:1となり、図の高さや幅を変更してもこの軸は変わりません。たとえば、RStudioのPlotsペインの大きさを変更すると図の大きさが変わりますが、coord_fixed(ratio = 1)を指定すると1:1の比率は維持されるまま図が拡大・縮小されます。直接やってみましょう。"
  },
  {
    "objectID": "visualization3.html#sec-visual3-scale",
    "href": "visualization3.html#sec-visual3-scale",
    "title": "20  可視化 [応用]",
    "section": "20.3 scale_*_*(): スケールの調整",
    "text": "20.3 scale_*_*(): スケールの調整\n　続いてscale_*_*()関数群を用いたスケールを解説しますが、こちらの関数は非常に多く、全てのスケールレイヤーについて解説すことは難しいです。しかし、共通する部分も非常に多いです。本説ではこの共通項に注目します。\n　連続変数でマッピングされた横軸のスケールを調整する関数ははscale_x_continuous()です。ここでxが横軸を意味し、continuousが連続であることを意味します。このxの箇所は幾何オブジェクトのaes()内で指定した仮引数と一致します。つまり、scale_x_continuous()のxの箇所にはy、alpha、linetype、sizeなどがあります。そして、実引数として与えられた変数のデータ型がcontinuousの箇所に相当します。もし、離散変数ならdiscrete、時系列ならtime、全て手動で調整する場合はmanualを使います。他にも2020年10月現在、最近追加されたものとしてbinnedがあり、こちらはヒストグラムに特化したものです（scale_x_binned()とscale_y_binned()）。つまり、スケール調整関数はaes()内に登場した仮引数名とそのデータ型の組み合わせで出来ています。\n　たとえば、時系列の折れ線グラフにおいて横軸のスケールを調整するなら、sacle_x_time()を使います。また、棒グラフのように横軸が名目変数ならscale_x_manual()、順序変数のような離散変数ならscale_x_discrete()を使います。また、連続変数の縦軸のスケール調整ならscale_y_continuous()を使います。グラフによってはaes()内にxまたはyを指定しないケースもあります。前章において度数の棒グラフや1つの箱ひげ図を出す場合、前者はx、後者はyのみを指定しました。これは指定されていないyやxが存在しないことを意味しません。{ggplot2}が自動的に計算しマッピングを行ってくれることを意味します。{ggplot2}で出来上がった図は2次元座標系を持つため、横軸と縦軸は必ず存在します。したがって、aes()内の引数と関係なくscale_x_*()とscale_y_*()関数群は使用することが出来ます。\n\n20.3.1 横軸・縦軸スケールの調整\n　軸のスケールを調整する目的は1) 目盛りの調整、2) 目盛りラベルの調整、3) 第2軸の追加などがありますが、主な目的は1と2です。第2軸の追加はスケールが異なるグラフが重なる場合に使用しますが、一般的に推奨されません。したがって、ここでは1と2について説明します。\n\n20.3.1.1 連続変数の場合\n　軸に連続変数がマッピングされている場合はscale_*_continuous()レイヤーを追加します。*の箇所は横軸の場合はx、縦軸の場合はyとなります。それではCountry_dfのFH_Totalを横軸、GDP_per_capitaを縦軸にした散布図を作成し、Scale_Fig1という名のオブジェクトに格納します。\n\nScale_Fig1 &lt;- Country_df |&gt;\n    ggplot() +\n    geom_point(aes(x = FH_Total, y = GDP_per_capita)) +\n    labs(x = \"フリーダムハウススコア\",y = \"一人あたりGDP (USD)\") +\n    theme_bw(base_size = 12)\n\nprint(Scale_Fig1)\n\n\n\n\n\n\n\n\n　Scale_Fig1の横軸の場合、最小値0、最大値100であり、目盛りは25間隔となっております。ここではこの横軸を調整したいと思います。まず、プロットにおける最小値と最大値はスケールではなく座標系の問題ですので、coord_*()を使用します。ここでは目盛りを修正してみましょう。たとえば、目盛りを10間隔にし、そのラベルも0、10、20、…、100にします。FH_Totalは連続変数ですので、scale_x_continuous()を使います。使い方は以下の通りです。\n\nScale_Fig1 +\n  scale_x_continuous(breaks = 目盛りの位置,\n                     labels = 目盛りのラベル)\n\n　breaksとlabelsの実引数としては数値型ベクトルを指定します。0から100まで10刻みの目盛りとラベルなら、seq(0, 100, by = 10)、またはc(0, 10, 20, 30, 40, 50, 60, 70, 80, 90, 100)と指定します。\n\nScale_Fig1 +\n  scale_x_continuous(breaks = seq(0, 100, by = 10),\n                     labels = seq(0, 100, by = 10))\n\n\n\n\n\n\n\n\n　目盛りのラベルを文字型にすることも可能です。例えば、目盛りを0、50、100にし、それぞれ「最低」、「中間」、「最高」としたい場合は以下のようにします。\n\nScale_Fig1 +\n  scale_x_continuous(breaks = c(0, 50, 100),\n                     labels = c(\"最低\", \"中間\", \"最高\"))\n\n\n\n\n\n\n\n\n　scale_x_continuous()は目盛りの調整が主な使い道ですが、他にも様々な機能を提供しています。たとえば、座標系の最小値と最大値の指定はcoord_*()を使うと説明しましたが、実はscale_*_continuous()でもlimits引数で指定することも可能です。たとえば、縦軸の範囲を0ドルから10万ドルにしたい場合はscale_y_continuous()の中にlimits = c(0, 100000)を指定します。\n\nScale_Fig1 +\n  scale_x_continuous(breaks = seq(0, 100, by = 10),\n                     labels = seq(0, 100, by = 10)) +\n  scale_y_continuous(limits = c(0, 100000))\n\n\n\n\n\n\n\n\n　他にも目盛りと目盛りラベルの位置を変更することも可能です。これはposition引数を使います。基本的に横軸の目盛りは下（\"bottom\"）、縦軸は左（\"left\"）ですが、\"top\"や\"right\"を使うことも可能です。もし、縦軸の目盛りとラベル、軸のラベルを右側にしたい場合はscale_y_continuous()の中にposition = \"right\"を指定します。\n\nScale_Fig1 +\n  scale_y_continuous(position = \"right\")\n\n\n\n\n\n\n\n\n\n\n20.3.1.2 離散変数の場合\n　もし、軸が名目変数や順序変数のような離散変数でマッピングされている場合は、scale_*_discrete()を使います。たとえば、座標系の回転の例で使いましたFlip_Figの場合、横軸の大陸名が英語のままになっています。これを日本語にする場合、データレベルで大陸名を日本語で置換することも可能ですが、scale_x_discrete()を使うことも可能です。使い方はscale_*_continuous()と同じであり、breaksとlabels引数を指定するだけです。\n\nFlip_Fig +\n  scale_x_discrete(breaks = c(\"Africa\", \"America\", \"Asia\", \"Europe\", \"Oceania\"),\n                   labels = c(\"アフリカ\", \"アメリカ\", \"アジア\", \"ヨーロッパ\", \"オセアニア\"))\n\n\n\n\n\n\n\n\n　今回は大陸名が文字型の列でしたが、factor型の場合、いくつか便利な機能が使えます。たとえば、Polity_Typeごとに国数を計算し、棒グラフを作成するとします。\n\nScale_df1 &lt;- Country_df |&gt;\n  group_by(Polity_Type) |&gt;\n  summarise(N       = n(),\n            .groups = \"drop\")\n\nScale_df1\n\n# A tibble: 6 × 2\n  Polity_Type         N\n  &lt;chr&gt;           &lt;int&gt;\n1 Autocracy          19\n2 Closed Anocracy    23\n3 Democracy          65\n4 Full Democracy     31\n5 Open Anocracy      20\n6 &lt;NA&gt;               28\n\n\n　続きまして、Polity_Type列をfactor型にします。最もスコアの低い独裁（Autocracy）から最もスコアの高い完全な民主主義（Full Democracy）の順番のfactorにします。\n\nScale_df1 &lt;- Scale_df1 |&gt;\n  mutate(Polity_Type = factor(Polity_Type, ordered = TRUE,\n                              levels  = c(\"Autocracy\",\n                                          \"Closed Anocracy\",\n                                          \"Open Anocracy\",\n                                          \"Democracy\",\n                                          \"Full Democracy\")))\n\nScale_df1$Polity_Type\n\n[1] Autocracy       Closed Anocracy Democracy       Full Democracy \n[5] Open Anocracy   &lt;NA&gt;           \n5 Levels: Autocracy &lt; Closed Anocracy &lt; Open Anocracy &lt; ... &lt; Full Democracy\n\n\n　問題なくfactor化も出来たので、それでは作図をしてみましょう。\n\nScale_df1 |&gt; \n  ggplot() +\n  geom_bar(aes(x = Polity_Type, y = N), stat = \"identity\")\n\n\n\n\n\n\n\n\n　Polityプロジェクトの対象外があり、この場合は欠損値（NA）になります。そして、問題はこの欠損値も表示されることです。むろん、欠損値のカテゴリも出力したいケースもありますが、もし欠損値カテゴリの棒を消すにはどうすれば良いでしょうか。1つ目の方法はScale_df1 |&gt; drop_na()で欠損値を含む行を除去してから作図する方法です。2つ目の方法はscale_x_discrete()でna.translate = FALSEを指定する方法です。ここでは横軸の目盛りラベルも日本語に変更し、欠損値のカテゴリを除外してみましょう。また、地味に便利な機能として、軸ラベルもscale_*_*()で指定可能です。第1引数として長さ1の文字ベクトルを指定すると、自動的に軸ラベルが修正され、labs()が不要となります。\n\nScale_df1 |&gt; \n  ggplot() +\n  geom_bar(aes(x = Polity_Type, y = N), stat = \"identity\") +\n  scale_x_discrete(\"Polity IV スコア\", # 第1引数で軸ラベルも指定可能\n                   breaks = c(\"Autocracy\", \"Closed Anocracy\", \"Open Anocracy\",\n                              \"Democracy\", \"Full Democracy\"),\n                   labels = c(\"独裁\", \"閉じられたアノクラシー\",\n                              \"開かれたアノクラシー\", \"民主主義\",\n                              \"完全な民主主義\"),\n                   na.translate = FALSE) +\n  scale_y_continuous(\"国数\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\nこれで欠損値を除外することができました。目盛りラベルが重なる箇所があり、多少気になりますが、この問題に関しては第20.4章で取り上げます。\n\n\n\n20.3.2 colorスケールの調整\n　グラフの次元を増やす際において広く使われている方法は変数の値に応じて色分けをすることでした。この場合、幾何オブジェクトのaes()内にcolor = マッピングする変数名を指定することになります。このように色が変数でマッピングされている場合は、色分けのスケールも調整可能です。たとえば、折れ線グラフにおいて日本が赤い線だったのを青い線に変更することが考えられます。ここでもcolorにマッピングされている変数のデータ型によって使用する関数が変わります。ここでは連続変数、順序付き離散変数、順序なし離散変数について説明します。\n\n20.3.2.1 color引数が連続変数でマッピングされている場合\n　まずは、連続変数からです。横軸は底10の対数変換した一人あたりGDP（GDP_per_capita）、縦軸は人間開発指数（HDI_2018）にした散布図を作成し、Polity IVスコア（Polity_Score）で点の色分けをしてみましょう。\n\nScale_Fig2 &lt;- Country_df |&gt;\n    ggplot() +\n    geom_point(aes(x = GDP_per_capita, y = HDI_2018, color = Polity_Score)) +\n    labs(x = \"一人あたりGDP (USD)\",y = \"人間開発指数\", color = \"Polity IVスコア\") +\n    scale_x_log10() +\n    theme_bw(base_size = 12)\n\nScale_Fig2\n\n\n\n\n\n\n\n\n　これまではcolor引数を離散変数でしかマッピングしませんでしたが、このように連続変数でマッピングすることも可能です。ただし、この場合は値に応じてはっきりした色分けがされるのではなく、グラデーションで色分けされます。この例だと、青に近いほどPolity IVスコアが高く、黒に近いほど低いことが分かります。この場合、colorのスケール調整は最小値と最大値における色を指定するだけです。その間の色については{ggplot2}が自動的に計算してくれます。\n　今回使用する関数はscale_color_gradient()です。これまでの例だとscale_color_continuous()かと思う方も多いでしょう。実際、scale_color_continuous()関数も提供されており、使い方もほぼ同じです。ただし、scale_color_continuous()を使う際は引数としてtype = \"gradient\"を指定する必要があります。scale_color_gradient()の場合、最小値における色をlow、最大値のそれをhighで指定します。数値は\"red\"や\"blue\"なども可能であり、\"#132B43\"のような書き方も使えます。たとえば、先ほどのScale_Fig2においてPolity IVスコアが高いほどbrown3、低いほどcornflowerblueになるようにする場合は以下のように書きます。\n\nScale_Fig2 +\n    scale_color_gradient(high = \"brown3\", low = \"cornflowerblue\")\n\n\n\n\n\n\n\n\n　このような書き方だとどのような色名で使えるかを事前に知っておく必要があります。使える色名のリストはcolors()から確認できます。全部で657種類がありますが、ここでは最初の50個のみを出力します。\n\nhead(colors(), 50)\n\n [1] \"white\"          \"aliceblue\"      \"antiquewhite\"   \"antiquewhite1\" \n [5] \"antiquewhite2\"  \"antiquewhite3\"  \"antiquewhite4\"  \"aquamarine\"    \n [9] \"aquamarine1\"    \"aquamarine2\"    \"aquamarine3\"    \"aquamarine4\"   \n[13] \"azure\"          \"azure1\"         \"azure2\"         \"azure3\"        \n[17] \"azure4\"         \"beige\"          \"bisque\"         \"bisque1\"       \n[21] \"bisque2\"        \"bisque3\"        \"bisque4\"        \"black\"         \n[25] \"blanchedalmond\" \"blue\"           \"blue1\"          \"blue2\"         \n[29] \"blue3\"          \"blue4\"          \"blueviolet\"     \"brown\"         \n[33] \"brown1\"         \"brown2\"         \"brown3\"         \"brown4\"        \n[37] \"burlywood\"      \"burlywood1\"     \"burlywood2\"     \"burlywood3\"    \n[41] \"burlywood4\"     \"cadetblue\"      \"cadetblue1\"     \"cadetblue2\"    \n[45] \"cadetblue3\"     \"cadetblue4\"     \"chartreuse\"     \"chartreuse1\"   \n[49] \"chartreuse2\"    \"chartreuse3\"   \n\n\nscale_color_gradient()から派生した関数としてscale_color_gradient2()というものもあります。これは最小値と最大値だけでなく、mid引数を使って中間における色も指定可能な関数です。例えば、先ほどの例で真ん中をseagreenにしてみましょう。\n\nScale_Fig2 +\n    scale_color_gradient2(high = \"brown3\", mid = \"seagreen\", low = \"cornflowerblue\")\n\n\n\n\n\n\n\n\n　色は\"seagreen\"、\"red\"でなく、\"#00AC97\"、\"#FF0000\"のように具体的なRGB値で指定することもできます。これは色を赤（R）、緑（G）、青（B）の3つの原色を混ぜて様々な色を表現する方法です。\"#FF0000\"の場合、最初の#はRGB表記であることを意味し、FFは赤が255であることの16進法表記、次の00と最後の00は緑と青が0であることの16進法表記です。各原色は0から255までの値を取ります。{ggplot2}でよく見る色としては#F8766D、#00BFC4、#C77CFF、#7CAE00があります。他にもGoogleなどで「RGB color list」などを検索すれば様々な色を見ることができます。\n他にも{ggplot2}は様々なユーザー指定のパレットが使用可能であり、実際、パッケージの形式として提供される場合もあります。たとえば、ジブリ風のカラーパレットが{ghibli}パッケージとして提供されており、install.packages(\"ghibli\")でインストール可能です。\n\npacman::p_load(ghibli)\n\nScale_Fig2 +\n    # 連続変数（_c）用の「もののけ姫」パレット（medium）\n    scale_color_ghibli_c(\"MononokeMedium\")\n\n\n\n\n\n\n\n\n\n\n20.3.2.2 color引数が順序付き離散変数でマッピングされている場合\n　連続変数のようにグラデーションではあるものの、それぞれの値に対して具体的な色が指定されます。まずは先ほど作成しましたScale_Fig2の色分けを連続変数であるPolity_Scoreでなく、順序付き離散変数であるPolity_Typeにします。Polity_Typeの順序は独裁（Autocracy）、閉じられたアノクラシー（Closed Anocracy）、開かれたアノクラシー（Open Anocracy）、民主主義（Democracy）、完全な民主主義（Full Democracy）にします。また、Polity_Typeが定義されていない国もデータセットに含まれているため、drop_na(Polity_Type)を追加し、Polity_Typeが欠損している行を除去します。\n\nScale_Fig3 &lt;- Country_df |&gt;\n  mutate(Polity_Type = factor(Polity_Type, ordered = TRUE,\n                              levels  = c(\"Autocracy\",\n                                          \"Closed Anocracy\",\n                                          \"Open Anocracy\",\n                                          \"Democracy\",\n                                          \"Full Democracy\"))) |&gt;\n  drop_na(Polity_Type) |&gt;\n  ggplot() +\n  geom_point(aes(x = GDP_per_capita, y = HDI_2018, color = Polity_Type)) +\n  labs(x = \"一人あたりGDP (USD)\",y = \"人間開発指数\", color = \"Polity IVタイプ\") +\n  scale_x_log10() +\n  theme_bw(base_size = 12)\n\nScale_Fig3\n\n\n\n\n\n\n\n\n　今回は紫（独裁）から黄色（完全な民主主義）の順で色分けがされ、その間のカテゴリーも紫と黄色の間の値をとります。実は順序付き離散変数の場合、色のスケールを調整することはあまりありませんし、これまでの方法に比べてやや複雑です。ここでは色相（Hue）の範囲と強度、明るさを調整する方法について紹介します。\n　まずは、色相について知る必要があります。{ggplot2}において色相の範囲は0から360です。そして、色には強度（intensity）、または彩度という概念があり、0に近いほどグレイへ近づき、色間の区別がしにくくなります。{ggplot2}では彩度のデフォルト値は100であり、我々が普段{ggplot2}で見る図の色です。最後に明るさ（luminance）があり、0から100までの値を取ります。値が大きいほど明るくなり、{ggplot2}のデフォルト値は65です。重要なのは色相のところであり、Hueの具体的な数値がどの色なのかを確認する必要があります。そのためには、{scales}パッケージのhue_pal()とshow_col()関数を使用します。\n\n\n\n\n\n\n\n\n\n　左上が0、右下が360の色を意味します。順序変数でマッピングされた色スケールを色相に基づいて調整する際は、scale_color_hue()レイヤーを追加し、色相の範囲、彩度、明るさを指定します。たとえば、0から300までの範囲の色を使用し2、再度と明るさはデフォルトにしたい場合、以下のように書きます。\n\nScale_Fig3 +\n  scale_color_hue(h = c(0, 360), c = 100, l = 65)\n\n\n\n\n\n\n\n\n　また、direction = -1を追加することで、色の順番を逆にすることも可能です。\n\nScale_Fig3 +\n  scale_color_hue(h = c(0, 360), c = 100, l = 65, direction = -1)\n\n\n\n\n\n\n\n\n　他にもmpl colormapsというカラーマップを使うことも可能です。この場合はscale_color_hue()ではなく、scale_color_viridis_d()を使用します。具体的な色の情報はmpl colormapsを参照してください。必要な引数は色のスタート地点（begin）と終了地点（end）です。そして、optionの引数のデフォルト値は\"D\"であり、これはVIRIDIS colormapを意味します。実はscale_color_*()を付けなかった場合の色分けがこれです。たとえば、VIRIDIS colormapでなく、PLASMA colormapを使うならoption = \"C\"を付けます。\n\nScale_Fig3 +\n  # PLASMA colormapを使用する（option = \"C\"）\n  scale_color_viridis_d(begin = 0, end = 1, option = \"C\")\n\n\n\n\n\n\n\n\n\n\n20.3.2.3 color引数が順序なし離散変数でマッピングされている場合\n　最後に順序なし離散変数の場合について解説します。ここではscale_color_manual()関数を使用し、マッピングされている変数のそれぞれ値に対して具体的な色を指定する方法です。以下で説明する方法は、順序付き離散変数でも使用可能であるため、Scale_Fig3の図をそのまま利用してみたいと思います。\n　scale_color_manual()の核心となる引数はvaluesであり、ここに\"変数の値\" = \"色\"で指定します。この色は\"red\"のような具体的な色名でも、\"#FF0000\"のようなRGB表記でも構いません。\n\nggplot2オブジェクト +\n  scale_color_manual(values = c(\"変数の値1\" = \"色1\",\n                                \"変数の値2\" = \"色2\",\n                                \"変数の値3\" = \"色3\",\n                                ...))\n\n　それではPolity_Typeの値が\"Autocracy\"の場合はdarkred、\"Closed Anocracy\"はseagreen、\"Open Anocracy\"はcornflowerblue、\"Democracy\"はorchid、\"Full Democracy\"はorangeにしてみましょう。\n\nScale_Fig3 +\n  scale_color_manual(values = c(\"Autocracy\"       = \"darkred\",\n                                \"Closed Anocracy\" = \"seagreen\",\n                                \"Open Anocracy\"   = \"cornflowerblue\",\n                                \"Democracy\"       = \"orchid\",\n                                \"Full Democracy\"  = \"orange\"))\n\n\n\n\n\n\n\n\n　色を決める際は色覚多様性に気をつけるべきです。誰にとっても見やすい図にはUniversal Designが必要です。特によくある例が「緑と赤」の組み合わせです。緑も赤も暖色系であり、P型およびD型色弱の場合、両者の区別が難しいと言われています。しかも、色弱の方は意外と多いです。日本の場合、男性の5%、女性の0.2%と言われております。これには人種差もありまして、フランスや北欧の男性の場合は約10%です。一通り図を作成しましたら、色覚シミュレーターなどを使用して、誰にとっても見やすい色であるかを確認することも良いでしょう。また、{ggplot2}がデフォルトで採用しているVIRIDISは色弱に優しいカラーパレットと言われています。一般的に二色の組み合わせの場合、最も区別しやすい色は青とオレンジと言われいます。\n　{ggplot2}におけるcolorスケールは非常に細かく調整可能であり、関連関数やパッケージも多く提供されています。本書では全てを紹介することはできませんが、ここまで紹介してきました例だけでも、自分好みに色を調整できるでしょう。\n\n\n\n20.3.3 alphaスケールの調整\n　次は点・線・面の透明度を指定するalphaスケールの調整です。もし、alphaに連続変数をマッピングすれば、マッピングした変数の値に応じて透明度が変わります。一般的に、値が大きいほど不透明となり、小さいほど透明になります。しかし、このような使い方はあまり見られません。プロット上のオブジェクトを透明度を指定するのは\n\n特定箇所にオブジェクトが密集し、重なるオブジェクトの区別がつきにくい場合\n特定の点・線・面を強調するため\n\n　以上の2ケースでしょう。また、ケース1の場合、alpha引数をaes()の内部ではなく、外側に指定し、具体的な数値を指定することになります。ここで注目するのはケース2です。たとえば、横軸に一人あたりGDP、縦軸に人間開発指数をマッピングした散布図を作成し、アジアの国のみハイライトしたいとします。この場合、アジアとその他の国で色分けしたり、丸と四角といった形で分けるのも可能ですが、「強調」が目的であれば、その他の国をやや透明にすることも可能でしょう。まず、Asiaという変数を作成し、Continentの値が\"Asia\"なら\"Asia\"、その他の値なら\"Other\"の値を入れます。そして、geom_point()のaes()内にalpha引数を追加し、Asia変数でマッピングします。\n\nCountry_df |&gt;\n  mutate(Asia = if_else(Continent == \"Asia\", \"Asia\", \"Other\")) |&gt;\n  ggplot() +\n  geom_point(aes(x = GDP_per_capita, y = HDI_2018, alpha = Asia), size = 2) +\n  labs(x = \"一人あたりGDP (USD)\",y = \"人間開発指数\", alpha = \"大陸\") +\n  scale_x_log10() +\n  theme_bw(base_size = 12)\n\n\n\n\n\n\n\n\n　Asiaの値によって透明度が異なりますが、私たちの目的はAsiaを不透明にし、その他の点を透明にすることです。ここで登場するのがscale_alpha_manual()です。使い方はこれまで見てきたscale_*_manual()と非常に似ています。values引数にそれぞれの値と透明度を指定するだけです。透明度は1が不透明、0が透明です。アジアの透明度を1.0、その他の透明度を0.15とするなら、以下のように書きます。\n\nCountry_df |&gt;\n  mutate(Asia = if_else(Continent == \"Asia\", \"Asia\", \"Other\")) |&gt;\n  ggplot() +\n  geom_point(aes(x = GDP_per_capita, y = HDI_2018, alpha = Asia), size = 2) +\n  labs(x = \"一人あたりGDP (USD)\",y = \"人間開発指数\", alpha = \"大陸\") +\n  scale_x_log10() +\n  scale_alpha_manual(values = c(\"Asia\" = 1.0, \"Other\" = 0.15)) +\n  theme_bw(base_size = 12)\n\n\n\n\n\n\n\n\n　これでアジアの国々がプロット上で強調されました。透明度スケールは連続変数（scale_alpha_continuous()）や離散変数（scale_alpha_discrete()）に使うことも可能ですが、透明度を「区別」でなく「強調」の目的で使うならば、scale_alpha_manual()でも十分だと考えられます。\n　一つ注意して頂きたいのは、図をPDFで出力する際、半透明なオブジェクトが見えなかったり、逆に透明度が全く適用されない場合があります。PNGなどのビットマップ画像ならこのような問題は生じませんが、PDFの場合は注意が必要です3。この場合、画像をPNGなどの形式にするか、半透明でなく「グレーと黒」のような組み合わせで作図した方が良いかも知れません。\n\n\n20.3.4 sizeスケールの調整\n　大きさに関するマッピングは幾何オブジェクトのaes()内にsize引数を使用します。ここでの大きさというのは点の大きさと線の太さを意味します。geom_point()内のsizeは点の大きさ、geom_line()やgeom_segment()のsizeは線の太さ、geom_pointrange()では両方を意味します。ただし、実質的に変数の値に応じて線の太さを変えることは強調4を除けばあまり見られません。ここでは点の大きさに焦点を当てて解説します。\n　それでは、横軸はフリーダム・ハウスのスコア（FH_Total）、縦軸は2018年人間開発指数（HDI_2018）として散布図を作成し、一人当たり購買力平価GDP（PPP_per_capita）に応じて点の大きさを指定します。\n\nCountry_df |&gt;\n    ggplot() +\n    geom_point(aes(x = FH_Total, y = HDI_2018, size = PPP_per_capita)) +\n    labs(x = \"フリーダムハウススコア\",y = \"2018年人間開発指数\", \n         size = \"一人あたり購買力平価GDP（USD）\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\") # 凡例の図の下段にする\n\n\n\n\n\n\n\n\n　フリーダム・ハウススコアと人間開発指数は全般的には正の相関を示しています。そして、両指標が高い国（図の右上）は所得水準も高いことが分かります。ただし、フリーダム・ハウススコアが低くても人間開発指数が高い国（図の左上）もかなり見られますが、これらの国の共通点は所得水準が高いことです。つまり、人間開発指数と所得水準には強い相関関係があると考えられます（人間開発指数には所得水準も含まれるため、当たり前です）。\n　大きさをマッピングすると、点が重なる箇所が広くなりますので、alpha引数で半透明にすることも有効でしょう。\n\nCountry_df |&gt;\n    ggplot() +\n    geom_point(aes(x = FH_Total, y = HDI_2018, size = PPP_per_capita),\n               alpha = 0.5) + # 透明度の指定\n    labs(x = \"フリーダムハウススコア\",y = \"2018年人間開発指数\", \n         size = \"一人あたり購買力平価GDP（USD）\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\") \n\n\n\n\n\n\n\n\n　この大きさのスケール調整はマッピングされた変数の尺度によって、scale_size_continuous()、sclae_size_discrete()、scale_size_ordinal()などを使用し、すべてマニュアルで調整したい場合はscale_size_manual()を使います。使い方はこれまでのスケール調整とほぼ同様です。たとえば、上記の図だと、大きさの凡例が3万、6万、9万となっていますが、これを1000, 10000, 100000といった対数スケールに変更してみましょう。\n\nCountry_df |&gt;\n    ggplot() +\n    geom_point(aes(x = FH_Total, y = HDI_2018, size = PPP_per_capita),\n               alpha = 0.5) +\n    labs(x = \"フリーダムハウススコア\",y = \"2018年人間開発指数\", \n         size = \"一人あたり購買力平価GDP（USD）\") +\n    scale_size_continuous(breaks = c(1000, 10000, 100000),\n                          labels = c(\"1000\", \"10000\", \"100000\")) +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\") \n\n\n\n\n\n\n\n\n　この場合、図内の点の大きさに変化はありません。変わるのは凡例のみであり、値に応じた点のサイズに調整されます。連続変数でマッピングされている場合、一つ一つの値に応じてサイズを指定するのは非現実的であります。この場合、点の大きさ調整は{ggplot2}に任せて、凡例のサイズを調整するのが無難でしょう。\n　ただし、点の最小サイズと最大サイズを調整したいケースもあるでしょう。最も小さい点のサイズを0.1に、最も大きい点のサイズを10にする場合、range引数を指定します。range引数の実引数は長さ2の数値型ベクトルです。\n\nCountry_df |&gt;\n    ggplot() +\n    geom_point(aes(x = FH_Total, y = HDI_2018, size = PPP_per_capita),\n               alpha = 0.5) +\n    labs(x = \"フリーダムハウススコア\",y = \"2018年人間開発指数\", \n         size = \"一人あたり購買力平価GDP（USD）\") +\n    scale_size_continuous(breaks = c(1000, 10000, 100000),\n                          labels = c(\"1000\", \"10000\", \"100000\"),\n                          range = c(0.1, 10)) +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\") \n\n\n\n\n\n\n\n\n　このように範囲が広がるほど、所得水準の差がより見やすくなります。他にもsizeは離散変数でマッピングさることも可能ですが、あまり相性は良くありません。離散変数でのマッピングはこれまで紹介しましたcolorやsizeの方を参照してください。使い方は同じです。\n\n\n20.3.5 shape、linetypeスケールの調整\n　sizeは連続変数と相性が良いですが、点や線の形であるshapeとlinetypeは離散変数、とりわけ順序なし離散変数（名目変数）と相性が良いです。なぜなら、点や線の形は高低・大小の情報を持たないからです。たとえば、丸の点は四角の点より大きいとか実線は破線より小さいといった情報はありません。したがって、sizeやlinetypeは名目変数に使うのが一般的です。たとえば、フリーダムハウスのスコアを横軸、人間開発指数を縦軸とし、G20加盟有無によって点の形が異なる散布図を作成するとします。G20をcharacter型、あるいはfactor型に変換し、geom_point()の幾何オブジェクトのaes()内にshape引数を指定します。\n\nCountry_df |&gt;\n    mutate(G20 = if_else(G20 == 1, \"加盟国\", \"非加盟国\")) |&gt;\n    ggplot() +\n    geom_point(aes(x = FH_Total, y = HDI_2018, shape = G20),\n               size = 2) +\n    labs(x = \"フリーダムハウススコア\",y = \"2018年人間開発指数\", \n         shape = \"G20\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\") \n\n\n\n\n\n\n\n\n　加盟国を丸（16または19）、非加盟国をダイヤモンド型（18）にするにはscale_shape_manual()を使います。\n\nCountry_df |&gt;\n    mutate(G20 = if_else(G20 == 1, \"加盟国\", \"非加盟国\")) |&gt;\n    ggplot() +\n    geom_point(aes(x = FH_Total, y = HDI_2018, shape = G20),\n               size = 2) +\n    scale_shape_manual(values = c(\"加盟国\" = 19, \"非加盟国\" = 18)) +\n    labs(x = \"フリーダムハウススコア\",y = \"2018年人間開発指数\", \n         shape = \"G20\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\") \n\n\n\n\n\n\n\n\n　ただし、各数字がどの形に対応しているかを事前に知っておく必要があります。よく使うのは0から25までであり、それぞれ対応するshapeを示したのが以下の図です。必要に応じてこのページを参照しても良いですし、Rコンソール上で?pchを入力しても0から23までの例を見ることが出来ます。\n\n\n\n\n\n\n\n\n\n　注意していただきたいのは、shapeのマッピングが有効でない状況があるという点です。それが先ほどの例です。先ほどの散布図の場合、次元を増やすことは、新しい次元で条件づけた場合の変数の関係性を調べることとなります。しかし、新しい次元による条件付き関連性があまり見られない場合、あるいは二種類以上の点の形があまり分離されていない場合は、次元の追加がもたらす恩恵が感じにくくなるでしょう。例えば以下のような散布図を比較してみましょう。図(A)の場合、縦軸の変数が閾値を超えるともう一つの変数との関係が弱まるということが分かります。たとえば、三角の点において両変数は正の相関を持ち、丸の点においては無相関に近いことが分かります。この場合、点の形は非常に有用な情報を含んでいると判断できます。一方、図(B)の場合、点の形から読み取れる情報が少ないですね。あえて言えば、グループ間の違いがあまりないことくらいでしょう。\n\n\n\n\n\n\n\n\n\n　白黒のグラフの場合、色分けが出来ないため、次元拡張には点の形を変えることになります。しかし、色に来れば形は読み手にとって認知の負荷がかかりやすいです。下の図を見てください。100個の点がありますが、三角の点はいくつでしょうか。\n\n\n\n\n\n\n\n\n\n　正解は5つです。あまり難しい問題ではないでしょう。一方、下の図はいかがでしょうか。\n\n\n\n\n\n\n\n\n\n　どれも正解は5つです。本質的には同じ問題ですが、どの図の方が読みやすかったでしょうか。個人差はあるかも知れませんが、多くの方にとって後者の方が読みやすかったでしょう。最近、海外のジャーナルはカラーの図を使うことも可能ですので、色分けを優先的に考えましょう。白黒のみ受け付けられる場合でも、グループ数やサンプルサイズによっては点の形より、彩度や明るさの方が効果的な場合もあります。\n　続きまして、linetypeについて解説します。線の形も色分けができない場合、よく使われる次元の増やし方です。ここでは日中韓台における人口1万人あたりCOVID-19新規感染者数の折れ線グラフを作成します。COVID19_dfには人口のデータがないため、left_join()を使ってCountry_dfと結合します。left_join()の使い方に関しては第14章を参照してください。続いて、Character型であるDate変数をas.Date()関数を使ってDate型へ変換します。1万人あたり新規感染者数は新規感染者数（Confirmed_Day）を人口（Population）で割り、1万をかけます。最後にCountry列を基準にfilter()を使用し、日中韓台のデータのみ残します。後は折れ線グラフを作成しますが、geom_line()内のaes()内にlinetype引数をCountry変数でマッピングします。\n\nleft_join(COVID19_df, Country_df, by = \"Country\") |&gt; \n  mutate(Date                 = as.Date(Date),\n         Confirmed_per_capita = Confirmed_Day / Population * 10000) |&gt;\n  filter(Country %in% c(\"Japan\", \"China\", \"Taiwan\", \"South Korea\")) |&gt;\n  ggplot() +\n  geom_line(aes(x = Date, y = Confirmed_per_capita, linetype = Country)) +\n  labs(x = \"月\", y = \"1万人当たり新規感染者数\",linetype = \"国\") +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　いかがでしょうか。linetypeはcolorよりも識別性が非常に低いことが分かるでしょう。個人差もあるかも知れませんが、shapeよりも低いのではないでしょうか。実線の中国を除けば、日本、韓国、台湾の線はなかなか区別できません。したがって、linetypeは2つ、3つまでが限界だと考えられます。3つまででしたら、実線、破線、点線に分けることができるでしょう。ここでは、日本のみを実線とし、他の3カ国は「その他」として破線にしてみましょう。そのためには、日本か否かを示すJapan変数を作成します。また、geom_line()のaes()内にはgroups引数を追加し、linetypeはJapan変数でマッピングします。\n\nleft_join(COVID19_df, Country_df, by = \"Country\") |&gt; \n  mutate(Date                 = as.Date(Date),\n         Confirmed_per_capita = Confirmed_Day / Population * 10000,\n         Japan                = if_else(Country == \"Japan\", \"日本\", \"その他\")) |&gt;\n  filter(Country %in% c(\"Japan\", \"China\", \"Taiwan\", \"South Korea\")) |&gt;\n  ggplot() +\n  geom_line(aes(x = Date, y = Confirmed_per_capita, \n                group = Country, linetype = Japan)) +\n  labs(x = \"月\", y = \"1万人当たり新規感染者数\", linetype = \"国\") +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　その他の国が実線となっているので、scale_linetype_manual()でJapanの値ごとに線のタイプを指定します。\n\nleft_join(COVID19_df, Country_df, by = \"Country\") |&gt; \n  mutate(Date                 = as.Date(Date),\n         Confirmed_per_capita = Confirmed_Day / Population * 10000,\n         Japan                = if_else(Country == \"Japan\", \"日本\", \"その他\")) |&gt;\n  filter(Country %in% c(\"Japan\", \"China\", \"Taiwan\", \"South Korea\")) |&gt;\n  ggplot() +\n  geom_line(aes(x = Date, y = Confirmed_per_capita, \n                group = Country, linetype = Japan)) +\n  scale_linetype_manual(values = c(\"日本\" = 1, \"その他\" = 2)) +\n  labs(x = \"月\", y = \"1万人当たり新規感染者数\", linetype = \"国\") +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　できれば、日本とその他の順番も逆にしたいですね。こちらはJapan変数をfactor化することで対応可能です。\n\nleft_join(COVID19_df, Country_df, by = \"Country\") |&gt; \n  mutate(Date                 = as.Date(Date),\n         Confirmed_per_capita = Confirmed_Day / Population * 10000,\n         Japan                = if_else(Country == \"Japan\", \"日本\", \"その他\"),\n         Japan                = factor(Japan, levels = c(\"日本\", \"その他\"))) |&gt;\n  filter(Country %in% c(\"Japan\", \"China\", \"Taiwan\", \"South Korea\")) |&gt;\n  ggplot() +\n  geom_line(aes(x = Date, y = Confirmed_per_capita, \n                group = Country, linetype = Japan)) +\n  scale_linetype_manual(values = c(\"日本\" = 1, \"その他\" = 2)) +\n  labs(x = \"月\", y = \"1万人当たり新規感染者数\", linetype = \"国\") +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nこれで完成ですがいかがでしょうか。複数の線を識別するという意味では色分け（color）が優れていますし、ハイライトなら透明度（alpha）か線の太さ（size）の方が良いでしょう。筆者（SONG）としましてはlinetypeによる次元の追加はあまりオススメしませんが、知っといて損はないでしょう。"
  },
  {
    "objectID": "visualization3.html#sec-visual3-theme",
    "href": "visualization3.html#sec-visual3-theme",
    "title": "20  可視化 [応用]",
    "section": "20.4 theme_*()とtheme(): テーマの指定",
    "text": "20.4 theme_*()とtheme(): テーマの指定\n　続いて図全体の雰囲気を決めるtheme_*()レイヤーについて解説します。これらの使い方は非常に簡単であり、ggplotオブジェクトにtheme_*()レイヤーを+で繋ぐだけです。もし、こちらのレイヤーを追加しない場合、デフォルトテーマとしてtheme_gray()が適用されます。{ggplot2}はいくつかのテーマを提供しており、以下がその例です。\n\n\n\n\n\n\n\n\n\n　他にも{ggplot2}用のテーマをパッケージとしてまとめたものもあります。興味のある方はggthemeやggthemrページを確認してみてください。\n　theme_*()内部ではいくつかの引数を指定することができます。最もよく使われるのがbase_family引数であり、図で使用するフォントを指定する引数です。macOSユーザーだとヒラギノ角ゴジックW3が良く使われており、base_family = \"HiraginoSans-W3\"で設定可能です。他にも全体の文字サイズを指定するbase_sizeなどがあります。\n　テーマの微調整は主にtheme()レイヤーで行います。こちらでは図の見た目に関する細かい調整ができます。実はtheme_*()関数群は調整済みtheme()レイヤーとして捉えることも出来ます。theme_*()とtheme()を同時に使うことも可能であり、「全般的にはminimalテーマ（theme_minimal()）が好きだけど、ここだけはちょっと修正したい」場合に使用します。theme()では図の見た目に関する全ての部分が設定可能であるため、引数も膨大です。詳しくはコンソール上で?themeを入力し、ヘルプを確認してください。ここではいくつかの例のみを紹介します。\n　まずは実習用データとして任意の棒グラフを作成し、Theme_Figという名のオブジェクトとして保存しておきます。\n\nTheme_Fig &lt;- Country_df |&gt;\n  # Freedom HouseのStatus、Continentでグループ化\n  group_by(FH_Status, Continent) |&gt;\n  # 欠損値のある行を除き、PPP_per_capitaの平均値を計算\n  summarise(PPP     = mean(PPP_per_capita, na.rm = TRUE),\n            .groups = \"drop\") |&gt;\n  # 欠損値の行を除去\n  drop_na() |&gt;\n  # Freedom HouseのStatusを再ラベリングし、factor化\n  mutate(FH_Status = case_when(FH_Status == \"F\"  ~ \"Free\",\n                               FH_Status == \"PF\" ~ \"Partially Free\",\n                               FH_Status == \"NF\" ~ \"Not Free\"),\n         FH_Status = factor(FH_Status, levels = c(\"Free\", \"Partially Free\",\n                                                  \"Not Free\"))) |&gt;\n  ggplot() +\n  geom_bar(aes(x = FH_Status, y = PPP, fill = Continent),\n           stat = \"identity\", position = position_dodge(width = 1)) +\n  labs(x = \"Polity IV Score\", y = \"PPP per capita (USD)\")\n\nTheme_Fig\n\n\n\n\n\n\n\n\n\n20.4.1 文字の大きさ\n　図全体における文字の大きさはtheme_*()レイヤーのbase_sizeから調整することもできますが、theme()からも可能です。文字に関する調整はtext引数に対してelement_text()実引数を指定します。大きさの場合、element_text()内にsize引数を指定します。\n\nTheme_Fig +\n  theme(text = element_text(size = 16))\n\n\n\n\n\n\n\n\n　element_text()では文字の大きさ以外にも色（color）、回転の度合い（angle）などを指定することもできます。詳しくはRコンソール上で?element_textを入力し、ヘルプを確認してください。\n\n\n20.4.2 背景のグリッド\n　背景のグリッドを調整する際はpanel.gird.*引数を使います。主に使用する場面はグリッドの除去する場合ですが、この場合は実引数としてelement_blank()を使います。もし、グリッドの色や太さなどを変更したい場合はelement_line()を使用します。ここではグリッドを除去する方法について紹介します。\n　グリッドを除去する場合、どのグリッドを除去するかを決めないといけません。例えば、すべてのグリッドを除去するためにはpanel.grid = element_blank()を使います。また、メジャーグリッドの除去にはpanel.grid.major（すべて）、panel.grid.major.x（横軸のみ）、panel.grid.major.y（縦軸のみ）を指定します。マイナーグリッドの場合はmajorをminorに替えてください。以下にはいくつかの例をお見せします。\n\n# すべてのグリッドを除去\nTheme_Fig +\n  theme(panel.grid = element_blank())\n\n\n\n\n\n\n\n# x軸のメジャーグリッドを除去\nTheme_Fig +\n  theme(panel.grid.major.x = element_blank())\n\n\n\n\n\n\n\n# y軸のマイナーグリッドのみ除去\nTheme_Fig +\n  theme(panel.grid.minor.y = element_blank())\n\n\n\n\n\n\n\n\n\n\n20.4.3 目盛りラベルの回転\n　横軸の目盛りラベルが長すぎるか大きすぎると、ラベルが重なる場合があります。この場合の対処方法としてはラベルの長さを短くしたり、改行（\\n）を入れることが考えられますが、ラベルを若干回転することでも対処可能です。たとえば、横軸の目盛りラベルを調整する場合はaxis.text.x = element_text()を指定し、element_text()内にangle引数を指定します。例えば、 反時計回りで25度回転させる場合はangle = 25と指定します。\n\nTheme_Fig +\n  theme(text = element_text(size = 16),\n        axis.text.x = element_text(angle = 25))\n\n\n\n\n\n\n\n\n　この場合、ラベルは目盛りのすぐ下を基準に回転することになります。もし、ラベルの最後の文字を目盛りの下に移動させる場合はhjust = 1を追加します。\n\nTheme_Fig +\n  theme(text = element_text(size = 16),\n        axis.text.x = element_text(angle = 25, hjust = 1))\n\n\n\n\n\n\n\n\n　ちなみに、angle = 90などで指定するとラベルが重なる問題はほぼ完全に解決されますが、かなり読みづらくなるので、できればangleの値は小さめにした方が読みやすくなります。\n\n\n20.4.4 scale_*_*()を用いたラベル重複の回避\n　ラベルの重複を回避するもう一つの方法は「ラベルの位置をずらす」ことです。これは{ggplot2}3.3.0以降追加された機能であり、theme()でなく、scale_*_*()関数のguide引数で指定することが出来ます。使い方は以下の通りです。たとえば、横軸（x軸）のラベルを2行構成にしたい場合は以下のように指定します。\n\nggplot2オブジェクト名 +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2))\n\n　実際の結果を確認してみましょう。\n\nTheme_Fig +\n  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +\n  theme(text = element_text(size = 16))\n\n\n\n\n\n\n\n\n　横軸のラベルが2行構成になりました。左から最初のラベルは1行目に、2番目のラベルは2行目に、3番目のラベルは1行目になります。実際、ラベルをずらすだけならn.dodge = 2で十分ですが、この引数の挙動を調べるためにn.dodge = 3に指定してみましょう。\n\nTheme_Fig +\n  scale_x_discrete(guide = guide_axis(n.dodge = 3)) +\n  theme(text = element_text(size = 16))\n\n\n\n\n\n\n\n\n　3番目のラベルが3行目に位置することになります。もし、4つ目のラベルが存在する場合、それは1行目に位置するでしょう。\n\n\n20.4.5 凡例の表示/非表示\n　凡例を無くす方法はいくつかありますが、まずはすべての凡例を非表示する方法について紹介します。それは後ほど紹介しますlegend.positionの実引数として\"none\"を指定する方法です。\n\n# 凡例を非表示にする\nTheme_Fig +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\n　Theme_Figはxとy以外にfillにマッピングをしたため、凡例は一つのみとなります。ただし、場合によってはもっと次元を増やすことによって2つ以上の凡例が表示されるケースがあります。別途の説明なくても図だけで理解するのが理想なので凡例は出来る限り温存させた方が良いでしょう。しかし、実例はあまり多く見られないと思いますが、凡例がなくても理解に問題がないと判断される場合は一部の凡例を非表示することも考えられます。\n　たとえば、以下のようなTheme_Fig2の例を考えてみましょう。\n\nTheme_Fig2 &lt;- Country_df |&gt;\n  mutate(OECD = if_else(OECD == 1, \"OECD\", \"non-OECE\")) |&gt;\n  ggplot(aes(x = FH_Total, y = GDP_per_capita)) +\n  geom_point(aes(color = OECD)) +\n  stat_ellipse(aes(fill = OECD), geom = \"polygon\", level = 0.95, alpha = 0.2) +\n  labs(x = \"Freedom House Score\", y = \"GDP per capita (USD)\", \n       color = \"OECD\", fill = \"Cluster\")\n\nTheme_Fig2\n\n\n\n\n\n\n\n\n　colorとfillがそれぞれ別の凡例として独立しています。この例の場合、fillの凡例はなくても、図を理解するのは難しくないかも知れません。ここで考えられる一つの方法はcolorとfillの凡例をオーバラップさせる方法です。{ggplot2}の場合、同じ変数がマッピングされていれば凡例をオーバーラップさせることも可能です。ただし、凡例のタイトルが同じである必要があります。ここではcolorとfillのタイトルを\"OECD\"に統一してみましょう。\n\nTheme_Fig2 +\n  labs(color = \"OECD\", fill = \"OECD\")\n\n\n\n\n\n\n\n\n　これで十分でしょう。しかし、凡例からfillの情報を完全に消したい場合はどうすれば良いでしょうか。その時に登場するのがguides()関数です。関数の中でマッピング要素 = \"none\"を指定すると、当該凡例が非表示となります。\n\nTheme_Fig2 +\n  guides(fill = \"none\")\n\n\n\n\n\n\n\n\n　guides()関数は凡例を細かく調整できる様々な機能を提供しています。興味のある方はヘルプ（?guides）を参照してください。\n\n\n20.4.6 凡例の位置\n　凡例を図の下段に移動させる場合はlegend.position引数に\"bottom\"を指定するだけです。他にも\"top\"や\"left\"も可能ですが、凡例は一般的に図の右か下段に位置しますので、デフォルトのままに置くか、\"bottom\"くらいしか使わないでしょう。\n\n# 凡例を図の下段へ移動\nTheme_Fig +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　もし、凡例を図の内部に置く場合は、長さ2のnumeric型ベクトルを指定します。図の左下ならc(0, 0)、左上ならc(0, 1)、右上はc(1, 1)、右下はc(1, 0)となります。これは図の大きさを横縦それぞれ1とした場合の位置を意味します。ここでは凡例を右上へ置いてみましょう。\n\n# 凡例をプロットの右上へ\nTheme_Fig +\n  theme(legend.position = c(1, 1))\n\n\n\n\n\n\n\n\n　これは凡例の中央が右上に来るようになります。これを是正するためにはlegend.justification引数を更に指定する必要があります。これにも長さ2のnumeric型ベクトルを指定しますが、これは凡例の中心をどこにするかを意味します。今回の例だと、凡例の右上をc(1, 1)に位置させたいので、ここもc(1, 1)と指定します。基本的にlegend.positionとlegend.justificationは同じ値にすれば問題ないでしょう。\n\n# 凡例の中心を凡例の右上と指定\nTheme_Fig +\n  theme(legend.position = c(1, 1),\n        legend.justification = c(1, 1))\n\n\n\n\n\n\n\n\n　また、凡例の背景を透明にしたい場合はlegend.background = element_blank()を指定します。\n\n# 凡例を背景を透明に\nTheme_Fig +\n  theme(legend.position = c(1, 1),\n        legend.justification = c(1, 1),\n        legend.background = element_blank())\n\n\n\n\n\n\n\n\n　theme()関数が提供している昨日は非常に多く、それぞれの実引数として用いられるelement_text()やelement_line()、element_rect()にも様々な引数が提供されております。図を自分好みに微調整したい方はそれぞれの関数のヘルプを参照してください。"
  },
  {
    "objectID": "visualization3.html#sec-visual3-merge",
    "href": "visualization3.html#sec-visual3-merge",
    "title": "20  可視化 [応用]",
    "section": "20.5 図の結合",
    "text": "20.5 図の結合\n　{ggplot2}で作成した複数の図を一つの図としてまとめる場合、昔は{gridExtra}一択でした。しかし、今はもっと使いやすいパッケージがいくつか公開されており、ここでは{ggpubr}のggarrange()を紹介します。使い方を紹介する前に、結合する図をいくつか用意し、それぞれGrid_Fig1、Gird_Fig2、…Grid_Fig4と名付けます。\n\n# Grid_Fig1: 散布図\n# X軸: フリーダムハウス・スコア / Y軸: 一人あたり購買力平価GDP（対数）\nGrid_Fig1 &lt;- Country_df |&gt;\n  ggplot() +\n  geom_point(aes(x = FH_Total, y = PPP_per_capita)) +\n  scale_y_log10() +\n  labs(x = \"フリーダムハウススコア\", \n       y = \"一人あたり購買力平価GDP（対数）\") +\n  theme_bw(base_size = 12)\n\n# Grid_Fig2: 散布図\n# X軸: フリーダムハウス・スコア / Y軸: 2018年人間開発指数\nGrid_Fig2 &lt;- Country_df |&gt;\n  ggplot() +\n  geom_point(aes(x = FH_Total, y = HDI_2018)) +\n  labs(x = \"フリーダムハウススコア\", \n       y = \"人間開発指数（2018年）\") +\n  theme_bw(base_size = 12)\n\n# Grid_Fig4: ヒストグラム\n# X軸: フリーダムハウス・スコア\nGrid_Fig3 &lt;- Country_df |&gt;\n  ggplot() +\n  geom_histogram(aes(x = FH_Total), color = \"white\",\n                 binwidth = 5, boundary = 0) +\n  labs(x = \"フリーダムハウススコア\", y = \"国数\") +\n  theme_bw(base_size = 12)\n\n# Grid_Fig4: ヒストグラム\n# Y軸: 一人あたり購買力平価GDP（対数）\n# 時計回りで90度回転したヒストグラムを作成するために、yにマッピング\nGrid_Fig4 &lt;- Country_df |&gt;\n  ggplot() +\n  geom_histogram(aes(y = PPP_per_capita), color = \"white\",\n                 boundary = 0, bins = 15) +\n  scale_y_log10() +\n  labs(x = \"国数\", y = \"一人あたり購買力平価GDP（対数）\") +\n  theme_bw(base_size = 12)\n\n　それぞれの図は以下の通りです。左上、右上、左下、右下の順でそれぞれGrid_Fig1、Grid_Fig2、Grid_Fig3、Grid_Fig4です。\n\n\n\n\n\n\n\n\n\n　まずはGrid_Fig1とGrid_Fig2を横に並べてみましょう。まずは{ggpubr}を読み込みます。\n\npacman::p_load(ggpubr)\n\n　図を並べる際はggarrange()関数を使用し、まず、結合したい図のオブジェクトを入力します。また、2つの図を横に並べることは1行2列のレイアウトであることを意味するため、nrowとncol引数の実引数としてそれぞれ1と2を指定します。\n\nggarrange(Grid_Fig1, Grid_Fig2, nrow = 1, ncol = 2)\n\n\n\n\n\n\n\n\n　右側にあるGrid_Fig2の幅が若干広いような気がします。この場合、aling = \"hv\"を入れると綺麗に揃えられます。\n\nggarrange(Grid_Fig1, Grid_Fig2, nrow = 1, ncol = 2, align = \"hv\")\n\n\n\n\n\n\n\n\n　続きまして、3つの図を以下のように並べるとします。\n\n\n\n\n\nGrid_Fig3\n\n\n\nGrid_Fig1\nGrid_Fig4\n\n\n\n\n\n\n\n　今回は3つの図オブジェクトを入れるだけでは不十分です。なぜなら、ggarrange()関数は左上から右下の順番へ一つずつ図を入れるからです。もし、3つの図オブジェクトのみを入れると、以下のように配置されます。\n\n\n\n\n\nGrid_Fig3\nGrid_Fig1\n\n\nGrid_Fig4\n\n\n\n\n\n\n\n\n　これを回避するためには空欄とするグリッドにNULLを指定する必要があります。\n\nggarrange(Grid_Fig3, # 1行1列目\n          NULL,      # 1行2列目\n          Grid_Fig1, # 2行1列目\n          Grid_Fig4, # 2行2列目\n          nrow = 2, ncol = 2, align = \"hv\")\n\n\n\n\n\n\n\n\n　次はヒストグラムを小さく調整します。左上のGrid_Fig3の上下の幅を、右下のGrid_Fig4は左右の幅を狭くします。このためにはwidthsとheights引数が必要です。たとえば、heights = c(0.3, 0.7)だと1行目は全体の30%、2行目は全体の70%になります。今回は1行目と2行目の比率は3:7に、1列目と2列目の比は7:3とします。また、それぞれの図に(a)、(b)、(c)を付けます。空欄となるグリッドのラベルはNAか\"\"にします。NULLではないことに注意してください。\n\nggarrange(Grid_Fig3, \n          NULL, \n          Grid_Fig1, \n          Grid_Fig4,\n          nrow = 2, ncol = 2, align = \"hv\",\n          # グリットの大きさを調整\n          widths = c(0.7, 0.3), heights = c(0.3, 0.7),\n          # 各図にラベルを付ける\n          labels = c(\"(a)\", NA, \"(b)\", \"(c)\"))\n\n\n\n\n\n\n\n\n　左上のGrid_Fig3と左下のGrid_Fig1は横軸のラベルを共有しており、左下のGrid_Fig1と右下のGrid_Fig4は縦軸のラベルを共有しています。以下ではGrid_Fig3の横軸ラベル、Grid_Fig4の縦軸ラベルを消します。ggplotオブジェクトにtheme(axis.title.x = element_blank())を+で繋ぐと横軸のラベルが表示されなくなります。ggarrange()に入れるオブジェクトに直接アクセスし、それぞれの軸ラベルを消してみましょう5。\n\nggarrange(Grid_Fig3 + theme(axis.title.x = element_blank()), \n          NULL, \n          Grid_Fig1, \n          Grid_Fig4 + theme(axis.title.y = element_blank()),\n          nrow = 2, ncol = 2, align = \"hv\",\n          widths = c(0.7, 0.3), heights = c(0.3, 0.7),\n          labels = c(\"(a)\", NA, \"(b)\", \"(c)\"))\n\n\n\n\n\n\n\n\n　これで完成です。ggarrange()には他にもカスタマイズ可能な部分がいっぱいあります。詳細はコンソール上で?ggarrangeを入力し、ヘルプを参照してください。\n　他にも{egg}パッケージのggarrange()、{cowplot}のplot_grid()、{patchwork}の+、|、/演算子などがあります。それぞれ強みがあり、便利なパッケージです。興味のある読者は以下のページで使い方を確認してみてください。\n\negg\ncowplot\npatchwork"
  },
  {
    "objectID": "visualization4.html#sec-visual4-intro",
    "href": "visualization4.html#sec-visual4-intro",
    "title": "21  可視化 [発展]",
    "section": "21.1 概要",
    "text": "21.1 概要\n　第18章では{ggplot2}の仕組みについて、第19章ではよく使われる5種類のプロット（棒グラフ、散布図、折れ線グラフ、箱ひげ図、ヒストグラム）の作り方を、第20章ではスケール、座標系などの操作を通じたグラフの見た目調整について解説しました。本章では第19章の延長線上に位置づけることができ、紹介しきれなかった様々なグラフの作り方について簡単に解説します。本章で紹介するグラフは以下の通りです。\n\nバイオリンプロット\nラグプロット\nリッジプロット\nエラーバー付き散布図\nロリーポップチャート\n平滑化ライン\n文字列の出力\nヒートマップ\n等高線図\n地図\n非巡回有向グラフ\nバンプチャート\n沖積図\nツリーマップ\nモザイクプロット\n\n\n\npacman::p_load(tidyverse)\n\nCountry_df &lt;- read_csv(\"Data/Countries.csv\")\nCOVID19_df &lt;- read_csv(\"Data/COVID19_Worldwide.csv\", guess_max = 10000)"
  },
  {
    "objectID": "visualization4.html#sec-visual4-violin",
    "href": "visualization4.html#sec-visual4-violin",
    "title": "21  可視化 [発展]",
    "section": "21.2 バイオリンプロット",
    "text": "21.2 バイオリンプロット\n　バイオリンプロットは連続変数の分布を可視化する際に使用するプロットの一つです。第18章で紹介しましたヒストグラムや箱ひげ図と目的は同じです。それではバイオリンプロットとは何かについて例を見ながら解説します。\n　以下の図は対数化した一人当たり購買力平価GDP（PPP_per_capita）のヒストグラムです。\n\n\n\n\n\n\n\n\n\n　このヒストグラムをなめらかにすると以下のような図になります。\n\n\n\n\n\n\n\n\n\n　この密度曲線を上下対称にすると以下のような図となり、これがバイオリンプロットです。ヒストグラムのようにデータの分布が分かりやすくなります。\n\n\n\n\n\n\n\n\n\n　しかし、この図の場合、ヒストグラムと同様、中央値や四分位数などの情報が含まれておりません。これらの箱ひげ図を使用した方が良いでしょう。バイオリンプロットの良い点はバイオリンの中に箱ひげ図を入れ、ヒストグラムと箱ひげ図両方の長所を取ることができる点です。たとえば、バイオリンプロットを90度回転させ、中にバイオリン図を入れると以下のようになります。\n\n\n\n\n\n\n\n\n\n　それでは実際にバイオリンプロットを作ってみましょう。使い方は箱ひげ図（geom_boxplot()）と同じです。たとえば、横軸は大陸（Continent）に、縦軸は対数化した一人当たり購買力平価GDP（PPP_per_capita）にしたバイオリンプロットを作るには作るにはgeom_violin()幾何オブジェクトの中にマッピングするだけです。大陸ごとに色分けしたい場合はfill引数にContinentをマッピングします。\n\nCountry_df |&gt;\n    ggplot() +\n    geom_violin(aes(x = Continent, y = PPP_per_capita, fill = Continent)) +\n    labs(x = \"大陸\", y = \"一人当たり購買力平価GDP (対数)\") +\n    scale_y_continuous(breaks = c(0, 1000, 10000, 100000),\n                       labels = c(0, 1000, 10000, 100000),\n                       trans  = \"log10\") + # y軸を対数化\n    guides(fill = \"none\") + # fillのマッピング情報の凡例を隠す\n    theme_minimal(base_size = 16)\n\n\n\n\n\n\n\n\n　ここに箱ひげ図も載せたい場合は、geom_violin()オブジェクトの後にgeom_boxplot()オブジェクトを入れるだけで十分です。\n\nCountry_df |&gt;\n    ggplot() +\n    geom_violin(aes(x = Continent, y = PPP_per_capita, fill = Continent)) +\n    geom_boxplot(aes(x = Continent, y = PPP_per_capita),\n                 width = 0.2) +\n    labs(x = \"大陸\", y = \"一人当たり購買力平価GDP (対数)\") +\n    scale_y_continuous(breaks = c(0, 1000, 10000, 100000),\n                       labels = c(0, 1000, 10000, 100000),\n                       trans = \"log10\") +\n    guides(fill = \"none\") +\n    theme_minimal(base_size = 16)\n\n\n\n\n\n\n\n\n　箱ひげ図は四分位範囲、四分位数、最小値、最大値などの情報を素早く読み取れますが、どの値当たりが分厚いかなどの情報が欠けています。これをバイオリンプロットで補うことで、よりデータの分布を的確に把握することができます。"
  },
  {
    "objectID": "visualization4.html#sec-visual4-rug",
    "href": "visualization4.html#sec-visual4-rug",
    "title": "21  可視化 [発展]",
    "section": "21.3 ラグプロット",
    "text": "21.3 ラグプロット\n　ラグプロット（rug plot）は変数の分布を示す点ではヒストグラム、箱ひげ図、バイオリンプロットと同じ目的を持ちますが、大きな違いとしてはラグプロット単体で使われるケースがない（または、非常に稀）という点です。ラグプロットは上述しましたヒストグラムや箱ひげ図、または散布図などと組み合わせて使うのが一般的です。\n　以下はCountry_dfのPPP_per_capita（常用対数変換）のヒストグラムです。\n\n\n\n\n\n\n\n\n\n　一変数の分布を確認する場合、ヒストグラムは情報量の損失が少ない方です。それでも値一つ一つの情報は失われますね。例えば、上記のヒストグラムで左端の度数は1です。左端の棒の区間はおおよそ500から780であり、一人当たりPPPがこの区間に属する国は1カ国ということです。ちなみに、その国はブルンジ共和国ですが、ブルンジ共和国の具体的な一人当たりPPPはヒストグラムから分かりません。情報量をより豊富に持たせるためには区間を細かく刻むことも出来ますが、逆に分布の全体像が読みにくくなります。\n　ここで登場するのがラグプロットです。これは座標平面の端を使ってデータを一時現状に並べたものです。多くの場合、点ではなく、垂直線（｜）を使います。ラグプロットの幾何オブジェクトは{ggplot2}でデフォルトで提供されており、geom_rug()を使います。マッピングはxまたはyに対して行いますが、座標平面の下段にラグプロットを出力する場合はxに変数（ここではPPP_per_capita）をマッピングします。\n\n\n\n\n\n\n\n\n\nラグプロットを使うと本来のヒストグラムの外見にほぼ影響を与えず、更に情報を付け加えることが可能です。点（｜）の密度でデータの分布を確認することもできますが、その密度の相対的な比較に関してはヒストグラムの方が良いでしょう。\nラグプロットは散布図に使うことも可能です。散布図は一つ一つの点が具体的な値がマッピングされるため、情報量の損失はほぼないでしょう。それでも散布図にラグプロットを加える意味はあります。まず、Country_dfのフリーダムハウス指数（FH_Total）と一人当たりPPP（PPP_per_capita）の散布図を作ってみましょう。\n\n\n\n\n\n\n\n\n\n散布図の目的は二変量間の関係を確認することであって、それぞれの変数の分布を確認することではありません。もし、FH_TotalとPPP_per_capitaの分布が確認したいなら、それぞれのヒストグラムや箱ひげ図を作成した方が良いでしょう。しかし、ラグプロットを使えば、点（｜）の密度で大まかな分布は確認出来ますし、図の見た目にもほぼ影響を与えません。\n横軸と縦軸両方のラグプロットは、geom_rug()にxとy両方マッピングするだけです。\n\n\n\n\n\n\n\n\n\n　これでFH_Totalはほぼ均等に分布していて、PPP_per_capitaは2万ドル以下に多く密集していることが確認できます。\n　{ggExtra}のggMarginal()を使えば、ラグプロットでなく、箱ひげ図やヒストグラムを付けることも可能です。{ggplot2}で作図した図をオブジェクトとして格納し、ggMarginal()の第一引数として指定します。第一引数のみだと密度のだけ出力されるため、箱ひげ図を付けるためにはtype = \"boxplot\"を指定します（既定値は\"density\"）。ヒストグラムを出力する場合は\"histogram\"と指定します。"
  },
  {
    "objectID": "visualization4.html#sec-visual4-ridge",
    "href": "visualization4.html#sec-visual4-ridge",
    "title": "21  可視化 [発展]",
    "section": "21.4 リッジプロット",
    "text": "21.4 リッジプロット\n　リッジプロット（ridge plot）はある変数の分布をグループごとに出力する図です。大陸ごとの人間開発指数の分布を示したり、時系列データなら分布の変化を示す時にも使えます。ここでは大陸ごとの人間開発指数の分布をリッジプロットで示してみましょう。\n　リッジプロットを作成する前に、geom_density()幾何オブジェクトを用い、変数の密度曲線（density curve）を作ってみます。マッピングはxに対し、分布を出力する変数名を指定します。また、密度曲線内部に色塗り（fill）をし、曲線を計算する際のバンド幅（bw）は0.054にします。bwが大きいほど、なめらかな曲線になります。\n\nCountry_df |&gt;\n  ggplot() +\n  geom_density(aes(x = HDI_2018), fill = \"gray70\", bw = 0.054) +\n  labs(x = \"2018年人間開発指数\", y = \"大陸\") +\n  theme_minimal(base_size = 12)\n\nWarning: Removed 6 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\n\n\n\n\n　これを大陸ごとに出力する場合、ファセット分割を行います。今回は大陸ごとに1列（ncol = 1）でファセットを分割します。\n\nCountry_df |&gt;\n  ggplot() +\n  geom_density(aes(x = HDI_2018), fill = \"gray70\", bw = 0.054) +\n  labs(x = \"2018年人間開発指数\", y = \"大陸\") +\n  facet_wrap(~Continent, ncol = 1) +\n  theme_minimal(base_size = 12)\n\nWarning: Removed 6 rows containing non-finite values (`stat_density()`).\n\n\n\n\n\n\n\n\n\n　それでは上のグラフをリッジプロットとして作図してみましょう。今回は{ggridges}パッケージを使います。\n\npacman::p_load(ggridges)\n\n　使用する幾何オブジェクトはgeom_density_ridges()です。似たような幾何オブジェクトとしてgeom_ridgeline()がありますが、こちらは予め密度曲線の高さを計算しておく必要があります。一方、geom_density_ridges()は変数だけ指定すれば密度を自動的に計算してくれます。マッピングはxとyに対し、それぞれ分布を出力する変数名とグループ変数名を指定します。また、密度曲線が重なるケースもあるため、透明度（alpha）も0.5にしておきましょう。ここでは別途指定しませんが、ハンド幅も指定可能であり、aes()の外側にbandwidthを指定するだけです。\n\nCountry_df |&gt;\n  ggplot() +\n  geom_density_ridges(aes(x = HDI_2018, y = Continent), \n                      alpha = 0.5) +\n  labs(x = \"2018年人間開発指数\", y = \"大陸\") +\n  theme_minimal(base_size = 12)\n\nPicking joint bandwidth of 0.054\n\n\nWarning: Removed 6 rows containing non-finite values (`stat_density_ridges()`).\n\n\n\n\n\n\n\n\n\n先ほど作図した図と非常に似た図が出来上がりました。ファセット分割に比べ、空間を最大限に活用していることが分かります。ファセットラベルがなく、グループ名が縦軸上に位置するからです。また、リッジプロットの特徴は密度曲線がオーバラップする点ですが、以下のようにscale = 1を指定すると、オーバラップなしで作成することも可能です。もし、scale = 3にすると最大2つの密度曲線が重なることになります。たとえば最下段のアフリカはアメリカの行と若干オーバラップしていますが、scale = 3の場合、アジアの行までオーバーラップされうることになります。\n\nCountry_df |&gt;\n  ggplot() +\n  geom_density_ridges(aes(x = HDI_2018, y = Continent), \n                      scale = 1, alpha = 0.5) +\n  labs(x = \"2018年人間開発指数\", y = \"大陸\") +\n  theme_minimal(base_size = 12)\n\nPicking joint bandwidth of 0.054\n\n\nWarning: Removed 6 rows containing non-finite values (`stat_density_ridges()`).\n\n\n\n\n\n\n\n\n\n　また、横軸の値に応じて背景の色をグラデーションで表現することも可能です。この場合、geom_density_ridges()幾何オブジェクトでなく、geom_density_ridges_gradient()を使い、fillにもマッピングをする必要があります。横軸（x）の値に応じて色塗りをする場合、fill = stat(x)とします。デフォルトでは横軸の値が高いほど空色、低いほど黒になります。ここでは高いほど黄色、低いほど紫ににするため、色弱にも優しいscale_fill_viridis_c()を使い1、カラーオプションはplasmaにします（option = \"c\"）。\n\nCountry_df |&gt;\n  ggplot() +\n  geom_density_ridges_gradient(aes(x = HDI_2018, y = Continent, fill = stat(x)), \n                               alpha = 0.5) +\n  scale_fill_viridis_c(option = \"C\") +\n  labs(x = \"2018年人間開発指数\", y = \"大陸\", fill = \"2018年人間開発指数\") +\n  theme_minimal(base_size = 12) +\n  theme(legend.position = \"bottom\")\n\nWarning: `stat(x)` was deprecated in ggplot2 3.4.0.\nℹ Please use `after_stat(x)` instead.\n\n\nPicking joint bandwidth of 0.054\n\n\n\n\n\n\n\n\n\n　密度曲線は基本的にはなめらかな曲線であるため、データが存在しない箇所にも密度が高く見積もられるケースがあります。全体的な分布を俯瞰するには良いですが、情報の損失は避けられません。そこで出てくるのが点付きのリッジプロットです。HDI_2018の個々の値を点で出力するにはjittered_points = TRUEを指定するだけです。これだけで密度曲線の内側に点が若干のズレ付き（jitter）で出力されます。ただし、密度曲線がオーバーラップされるリッジプロットの特徴を考えると、グループごとに点の色分けをする必要があります（同じ色になると、どのグループの点かが分からなくなるので）。この場合、point_colorに対し、グループ変数（Continent）をマッピングします。また、密度曲線の色と合わせるために密度曲線の色塗りもfillで指定します。\n\nCountry_df |&gt;\n  ggplot() +\n  geom_density_ridges(aes(x = HDI_2018, y = Continent, fill = Continent,\n                          point_color = Continent), \n                      alpha = 0.5, jittered_points = TRUE) +\n  guides(fill = \"none\", point_color = \"none\") + # 凡例を削除\n  labs(x = \"2018年人間開発指数\", y = \"大陸\") +\n  theme_minimal(base_size = 12)\n\nPicking joint bandwidth of 0.054\n\n\nWarning: Removed 6 rows containing non-finite values (`stat_density_ridges()`).\n\n\n\n\n\n\n\n\n\n　他にも密度曲線の下側にラグプロットを付けることも可能です。こうすれば点ごとに色訳をする必要もなくなります。ラグプロットを付けるためには点の形（point_shape）を「|」にする必要があります。ただ、これだけだと「|」が密度曲線内部に散らばる（jittered）だけです。散らばりをなくす、つまり密度曲線の下段に固定する必要があり、これはaes()その外側にposition = position_points_jitter(width = 0, height = 0)を指定することで出来ます。\n\nCountry_df |&gt;\n  ggplot() +\n  geom_density_ridges(aes(x = HDI_2018, y = Continent, fill = Continent), \n                      alpha = 0.5, jittered_points = TRUE,\n                      position = position_points_jitter(width = 0, height = 0),\n                      point_shape = \"|\", point_size = 3) +\n  guides(fill = \"none\") +\n  labs(x = \"2018年人間開発指数\", y = \"大陸\") +\n  theme_minimal(base_size = 12)\n\nPicking joint bandwidth of 0.054\n\n\nWarning: Removed 6 rows containing non-finite values (`stat_density_ridges()`).\n\n\n\n\n\n\n\n\n\n　最後に密度曲線でなく、ヒストグラムで示す方法を紹介します。これはgeom_density_ridges()の内部にstat = \"binline\"を指定するだけです。\n\nCountry_df |&gt;\n  ggplot() +\n  geom_density_ridges(aes(x = HDI_2018, y = Continent), alpha = 0.5,\n                      stat = \"binline\") +\n  labs(x = \"2018年人間開発指数\", y = \"大陸\") +\n  theme_minimal(base_size = 12)\n\n`stat_binline()` using `bins = 30`. Pick better value with `binwidth`.\n\n\nWarning: Removed 6 rows containing non-finite values (`stat_binline()`)."
  },
  {
    "objectID": "visualization4.html#sec-visual4-pointrange",
    "href": "visualization4.html#sec-visual4-pointrange",
    "title": "21  可視化 [発展]",
    "section": "21.5 エラーバー付き散布図",
    "text": "21.5 エラーバー付き散布図\n　エラーバー付きの散布図は推定結果の点推定値とその不確実性（信頼区間など）を示す際によく使われる図です。以下の表はCountry_dfを用い、大陸（オセアニアを除く）ごとにフリーダムハウス・スコア（FH_Total）を一人当たりPPP GDP（PPP_per_capita）に回帰させた分析から得られたフリーダムハウス・スコア（FH_Total）の係数（以下の式の\\(\\beta_1\\)）の点推定値と95%信頼区間です。\n\\[\n\\text{PPP per capita} = \\beta_0 + \\beta_1 \\cdot \\text{FH}\\_\\text{Total} + \\varepsilon\n\\]\n\nPointrange_df &lt;- tibble(\n    Continent = c(\"Asia\", \"Europe\", \"Africa\", \"America\"),\n    Coef      = c(65.3, 588.0, 53.4, 316.0),\n    Conf_lwr  = c(-250.0, 376.0, -14.5, 128.0),\n    Conf_upr  = c(380.0, 801.0, 121.0, 504.0)\n)\n\n\nPointrange_df\n\n# A tibble: 4 × 4\n# Groups:   Continent [4]\n  Continent  Coef Conf_lwr Conf_upr\n  &lt;chr&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Asia       65.3   -250.      380.\n2 Europe    588.     376.      801.\n3 Africa     53.4    -14.5     121.\n4 America   316.     128.      504.\n\n\n　実は以上のデータは以下のようなコードで作成されています。{purrr}パッケージの使い方に慣れる必要があるので、第27章を参照してください。\n\nPointrange_df &lt;- Country_df |&gt;\n    filter(Continent != \"Oceania\") |&gt;\n    group_by(Continent) |&gt;\n    nest() |&gt;\n    mutate(Fit = map(data, ~lm(PPP_per_capita ~ FH_Total, data = .)),\n           Est = map(Fit, broom::tidy, conf.int = TRUE)) |&gt;\n    unnest(Est) |&gt;\n    filter(term == \"FH_Total\") |&gt;\n    select(Continent, Coef = estimate, \n           Conf_lwr = conf.low, Conf_upr = conf.high) \n\n　このPointrange_dfを用いて横軸は大陸（Continent）、縦軸には点推定値（Coef）と95%信頼区間（Conf_lwrとConf_upr）を出力します。ここで使う幾何オブジェクトはgeom_pointrange()です。横軸xと点推定値y、95%信頼区間の下限のymin、上限のymaxにマッピングします。エラーバー付き散布図を縦に並べたい場合はyとx、xmin、xmaxにマッピングします。\n\nPointrange_df |&gt;\n    ggplot() +\n    geom_hline(yintercept = 0, linetype = 2) +\n    geom_pointrange(aes(x = Continent, y = Coef, \n                        ymin = Conf_lwr, ymax = Conf_upr),\n                    size = 0.75, linewidth = 0.75) +\n    labs(y = expression(paste(beta[1], \" with 95% CI\"))) +\n    theme_bw(base_size = 12)\n\n\n\n\n\n\n\n\n　点の大きさと線の太さはそれぞれsizeとlinewidthで調整できます。どれも既定値は0.5です。\n　ここでもう一つの次元を追加することもあるでしょう。たとえば、複数のモデルを比較した場合がそうかもしれません。以下のPointrange_df2について考えてみましょう。\n\nPointrange_df2 &lt;- tibble(\n    Continent = rep(c(\"Asia\", \"Europe\", \"Africa\", \"America\"), each = 2),\n    Term      = rep(c(\"Civic Liverty\", \"Political Right\"), 4),\n    Coef      = c(207.747, 29.188, 1050.164, 1284.101,\n                  110.025, 93.537, 581.4593, 646.9211),\n    Conf_lwr  = c(-385.221, -609.771, 692.204, 768.209,\n                  -12.648, -53.982, 262.056, 201.511),\n    Conf_upr  = c(800.716, 668.147, 1408.125, 1801.994,\n                  232.697, 241.057, 900.863, 1092.331))\n\n\nPointrange_df2\n\n# A tibble: 8 × 5\n# Groups:   Continent [4]\n  Continent Term              Coef Conf_lwr Conf_upr\n  &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n1 Asia      Civic Liberty    208.    -385.      801.\n2 Asia      Political Right   29.2   -610.      668.\n3 Europe    Civic Liberty   1050.     692.     1408.\n4 Europe    Political Right 1285.     768.     1802.\n5 Africa    Civic Liberty    110.     -12.6     233.\n6 Africa    Political Right   93.5    -54.0     241.\n7 America   Civic Liberty    581.     262.      901.\n8 America   Political Right  647.     202.     1092.\n\n\n　このデータは以下の2つのモデルを大陸ごとに推定した\\(\\beta_1\\)と\\(\\gamma_1\\)の点推定値と95%信頼区間です。\n\\[\n\\begin{aligned}\n\\text{PPP per capita} & = \\beta_0 + \\beta_1 \\cdot \\text{FH}\\_\\text{CL} + \\varepsilon \\\\\n\\text{PPP per capita} & = \\gamma_0 + \\gamma_1 \\cdot \\text{FH}\\_\\text{PR} + \\upsilon\n\\end{aligned}\n\\]\n　どの説明変数を用いたかでエラーバーと点の色分けを行う場合、colorに対してTermをマッピングします。\n\nPointrange_df2 |&gt;\n    ggplot() +\n    geom_hline(yintercept = 0, linetype = 2) +\n    geom_pointrange(aes(x = Continent, y = Coef, \n                        ymin = Conf_lwr, ymax = Conf_upr,\n                        color = Term), \n                    size = 0.75, linewidth = 0.75) +\n    labs(y = expression(paste(beta[1], \" and \", gamma[1], \" with 95% CI\")),\n         color = \"\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　何か違いますね。この2つのエラーバーと点の位置をずらす必要があるようです。これは3次元以上の棒グラフで使ったposition引数で調整可能です。今回は実引数としてposition_dodge(0.5)を指定してみましょう。\n\nPointrange_df2 |&gt;\n    ggplot() +\n    geom_hline(yintercept = 0, linetype = 2) +\n    geom_pointrange(aes(x = Continent, y = Coef, \n                        ymin = Conf_lwr, ymax = Conf_upr,\n                        color = Term),\n                    size = 0.75, linewidth = 0.75,\n                    position = position_dodge(0.5)) +\n    labs(y = expression(paste(beta[1], \" and \", gamma[1], \" with 95% CI\")),\n         color = \"\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　これで完成です。更に、\\(\\alpha = 0.05\\)水準で統計的に有意か否かを透明度で示し、透明度の凡例を非表示にしてみましょう。\\(\\alpha = 0.05\\)水準で統計的に有意か否かは95%信頼区間の上限と下限の積が0より大きいか否かで判定できます。ggplot()にデータを渡す前に統計的有意か否かを意味するSig変数を作成し、geom_pointrage()の内部ではalphaにSigをマッピングします。\n\nPointrange_df2 |&gt;\n    mutate(Sig = if_else(Conf_lwr * Conf_upr &gt; 0, \n                         \"Significant\", \"Insignificant\")) |&gt;\n    ggplot() +\n    geom_hline(yintercept = 0, linetype = 2) +\n    geom_pointrange(aes(x = Continent, y = Coef, \n                        ymin = Conf_lwr, ymax = Conf_upr,\n                        color = Term, alpha = Sig),\n                    size = 0.75, linewidth = 0.75,\n                    position = position_dodge(0.5)) +\n    labs(y = expression(paste(beta[1], \" and \", gamma[1], \" with 95% CI\")),\n         color = \"\") +\n    scale_alpha_manual(values = c(\"Significant\" = 1, \"Insignificant\" = 0.35)) +\n    guides(alpha = \"none\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　区間を単なる線ではなく、上限と下限に「-」を付ける場合は、geom_point()とgeom_errorbar()を組み合わせます。geom_errorbar()はgeom_pointrange()から点がなくなったものになるため、yへのマッピングは不要です。また、上限と下限に着く水平線の幅はwidthで調整します。既定値のままだとかなり広めになるため、適宜調整しましょう。\n\nPointrange_df2 |&gt;\n    mutate(Sig = if_else(Conf_lwr * Conf_upr &gt; 0, \n                         \"Significant\", \"Insignificant\")) |&gt;\n    ggplot(aes(x = Continent, color = Term, alpha = Sig)) +\n    geom_hline(yintercept = 0, linetype = 2) +\n    geom_point(aes(y = Coef), \n               size = 3, position = position_dodge(0.5)) +\n    geom_errorbar(aes(ymin = Conf_lwr, ymax = Conf_upr),\n                  linewidth = 0.75, width = 0.15,\n                  position = position_dodge(0.5)) +\n    labs(y = expression(paste(beta[1], \" and \", gamma[1], \" with 95% CI\")),\n         color = \"\") +\n    scale_alpha_manual(values = c(\"Significant\" = 1, \"Insignificant\" = 0.35)) +\n    guides(alpha = \"none\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "visualization4.html#sec-visual4-lollipop",
    "href": "visualization4.html#sec-visual4-lollipop",
    "title": "21  可視化 [発展]",
    "section": "21.6 ロリーポップチャート",
    "text": "21.6 ロリーポップチャート\n　ロリーポップチャートは棒グラフの特殊な形態であり、棒がロリーポップ（チュッパチャップス）の形をしているものを指します。したがって、2つの図は本質的に同じですが、棒が多い場合はロリーポップチャートを使うケースがあります。棒が非常に多い棒グラフの場合、図を不適切に縮小するとモアレが生じるケースがあるからです。\n　まず、Country_dfを用い、ヨーロッパ諸国の一人当たりPPP GDP（PPP_per_capita）の棒グラフを作るとします。PPP_per_capitaが欠損していないヨーロッパの国は46行であり、非常に棒が多い棒グラフになります。\n\nCountry_df |&gt;\n  filter(Continent == \"Europe\") |&gt;\n  drop_na(PPP_per_capita) |&gt;\n  ggplot() +\n  geom_bar(aes(y = Country, x = PPP_per_capita), stat = \"identity\") +\n  labs(x = \"一人あたり購買力平価GDP\", y = \"国\") +\n  theme_bw(base_size = 12)\n\n\n\n\n\n\n\n\nここで登場するのがロリーポップチャートです。ロリーポップチャートの構成要素は棒とキャンディーの部分です。棒は線になるためgeom_segement()を、キャンディーは散布図geom_point()を使います。散布図については既に第19章で説明しましたので、ここではgeom_segment()について説明します。\n　geom_segment()は直線を引く幾何オブジェクトであり、線の起点（xとy）と終点（xendとyend）に対してマッピングをする必要があります。横軸上の起点は0、縦軸上の起点はCountryです。そして横軸上の終点はPPP_per_capita、縦軸上のそれはCountryです。縦軸上の起点と終点が同じということは水平線を引くことになります。\n　geom_segment()で水平線を描いたら、次は散布図をオーバーラップさせます。点の横軸上の位置はPPP_per_capita、縦軸上の位置はCountryです。\n\nCountry_df |&gt;\n  filter(Continent == \"Europe\") |&gt;\n  drop_na(PPP_per_capita) |&gt;\n  ggplot() +\n  geom_segment(aes(y = Country, yend = Country,\n                   x = 0, xend = PPP_per_capita)) +\n  geom_point(aes(y = Country, x = PPP_per_capita), color = \"orange\") +\n  labs(x = \"一人あたり購買力平価GDP (USD)\", y = \"国\") +\n  theme_bw(base_size = 12) +\n  theme(panel.grid.major.y = element_blank(),\n        panel.border = element_blank(),\n        axis.ticks.y = element_blank())\n\n\n\n\n\n\n\n\n　これで完成です。もし一人当たりPPP GDP順で並べ替えたい場合はfct_reorder()を使います。CountryをPPP_per_capitaの低い方を先にくるようにするなら、fct_reorder(Country, PPP_per_capita)です。縦に並ぶの棒グラフなら最初に来る水準が下に位置されます。もし、順番を逆にしたいなら、更にfct_rev()で水準の順番を逆転させます。\n\nCountry_df |&gt;\n  filter(Continent == \"Europe\") |&gt;\n  drop_na(PPP_per_capita) |&gt;\n  mutate(Country = fct_reorder(Country, PPP_per_capita)) |&gt; \n  ggplot() +\n  geom_segment(aes(y = Country, yend = Country,\n                   x = 0, xend = PPP_per_capita)) +\n  geom_point(aes(y = Country, x = PPP_per_capita), color = \"orange\") +\n  labs(x = \"一人あたり購買力平価GDP (USD)\", y = \"国\") +\n  theme_bw(base_size = 12) +\n  theme(panel.grid.major.y = element_blank(),\n        panel.border = element_blank(),\n        axis.ticks.y = element_blank())\n\n\n\n\n\n\n\n\n　ロリーポップロリーポップチャートで次元を追加するには点（キャンディー）の色分けが考えられます。たとえば、OECD加盟国か否かの次元を追加する場合、geom_point()においてcolorをマッピングするだけです。\n\nCountry_df |&gt;\n  filter(Continent == \"Europe\") |&gt;\n  drop_na(PPP_per_capita) |&gt;\n  mutate(Country = fct_reorder(Country, PPP_per_capita),\n         OECD    = if_else(OECD == 1, \"OECD\", \"non-OECD\"),\n         OECD    = factor(OECD, levels = c(\"OECD\", \"non-OECD\"))) |&gt; \n  ggplot() +\n  geom_segment(aes(y = Country, yend = Country,\n                   x = 0, xend = PPP_per_capita)) +\n  geom_point(aes(y = Country, x = PPP_per_capita, color = OECD)) +\n  scale_color_manual(values = c(\"OECD\" = \"orange\", \"non-OECD\" = \"royalblue\")) +\n  labs(x = \"一人あたり購買力平価GDP (USD)\", y = \"国\", color = \"\") +\n  theme_bw(base_size = 12) +\n  theme(panel.grid.major.y = element_blank(),\n        panel.border       = element_blank(),\n        axis.ticks.y       = element_blank(),\n        legend.position    = \"bottom\")\n\n\n\n\n\n\n\n\n　ファセット分割ももちろんできますが、この場合、OECD加盟国の一人当たりPPP GDPが相対的に高いことを示すなら、一つのファセットにまとめた方が良いでしょう。\n　以下のようにロリーポップを横に並べることもできますが、棒の数が多いケースがほとんどであるロリーポップチャートではラベルの回転が必要になるため、読みにくくなるかも知れません。\n\nCountry_df |&gt;\n  filter(Continent == \"Europe\") |&gt;\n  drop_na(PPP_per_capita) |&gt;\n  mutate(Country = fct_reorder(Country, PPP_per_capita),\n         Country = fct_rev(Country)) |&gt; \n  ggplot() +\n  geom_segment(aes(x = Country, xend = Country,\n                   y = 0, yend = PPP_per_capita)) +\n  geom_point(aes(x = Country, y = PPP_per_capita), color = \"orange\") +\n  labs(x = \"国\", y = \"一人あたり購買力平価GDP (USD)\") +\n  theme_bw(base_size = 12) +\n  theme(panel.grid.major.y = element_blank(),\n        panel.border = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "visualization4.html#sec-visual4-smooth",
    "href": "visualization4.html#sec-visual4-smooth",
    "title": "21  可視化 [発展]",
    "section": "21.7 平滑化ライン",
    "text": "21.7 平滑化ライン\n2次元平面上に散布図をプロットし、二変数間の関係を一本の線で要約するのは平滑化ラインです。{ggplot2}ではgeom_smooth()幾何オブジェクトを重ねることで簡単に平滑化ラインをプロットすることができます。まずは、横軸をフリーダムハウス・スコア（FH_Total）、縦軸を一人当たり購買力平価GDP（PPP_per_capita）にした散布図を出力し、その上に平滑化ラインを追加してみましょう。geom_smooth()にもマッピングが必要で、aes()の内部にxとyをマッピングします。今回はgeom_point()とgeom_smooth()が同じマッピング情報を共有するため、ggplot()内部でマッピングします。\n\nCountry_df |&gt;\n    ggplot(aes(x = FH_Total, y = PPP_per_capita)) +\n    geom_point() +\n    geom_smooth()  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n　青い線が平滑化ライン、網掛けの領域が95%信頼区間です。この線はLOESS (LOcal Estimated Scatterplot Smoothing)と呼ばれる非線形平滑化ラインです。どのようなラインを引くかはmethod引数で指定しますが、このmethod既定値が\"loess\"です。これを見るとフリーダムハウス・スコアが75以下の国では国の自由度と所得間の関係があまり見られませんが、75からは正の関係が確認できます。\n　LOESS平滑化の場合、span引数を使って滑らかさを調整することができます。spanの既定値は0.75ですが、これが小さいほど散布図によりフィットしたラインが引かれ、よりギザギザな線になります。たとえば、spanを0.25にすると以下のようなグラフが得られます。\n\nCountry_df |&gt;\n    ggplot(aes(x = FH_Total, y = PPP_per_capita)) +\n    geom_point() +\n    geom_smooth(method = \"loess\", span = 0.25)  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n　他にも定番の回帰直線を引くこともできます。methodの実引数を\"lm\"に変えるだけです。\n\nCountry_df |&gt;\n    ggplot(aes(x = FH_Total, y = PPP_per_capita)) +\n    geom_point() +\n    geom_smooth(method = \"lm\")  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n　信頼区間は既定値だと95%信頼区間が表示されますが、level引数で調整することができます。たとえば、99.9%信頼区間を表示したい場合、level = 0.999を指定します。\n\nCountry_df |&gt;\n    ggplot(aes(x = FH_Total, y = PPP_per_capita)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", level = 0.999)  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n　信頼区間を消したい場合はse = FALSEを指定します（既定値はTRUE）。\n\nCountry_df |&gt;\n    ggplot(aes(x = FH_Total, y = PPP_per_capita)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", se = FALSE)  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n　最後にデータのサブセットごとに回帰直線を引く方法について説明します。散布図で色分けを行う場合、aes()内でcolor引数を指定しますが、これだけで十分です。今回はこれまでの散布図をOECD加盟有無ごとに色分けし、それぞれ別の回帰直線を重ねてみましょう。回帰直線も色分けしたいのでcolor引数で次元を増やす必要があり、これはgeom_point()と共通であるため、ggplot()内でマッピングします。\n\nCountry_df |&gt;\n    mutate(OECD = if_else(OECD == 1, \"加盟国\", \"非加盟国\")) |&gt;\n    ggplot(aes(x = FH_Total, y = PPP_per_capita, color = OECD)) +\n    geom_point() +\n    geom_smooth(method = \"lm\")  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    coord_cartesian(ylim = c(0, 120000)) +\n    theme_bw(base_size = 12)\n\n\n\n\n\n\n\n\n　これを見ると、国の自由度と所得の間に関係が見られるのはOECD加盟国で、非加盟国では非常に関係が弱いことが分かります。\n　あまりいい方法ではないと思いますが、散布図は色（color）で分け、回帰直線は線の種類（linetype）で分けるならどうすれば良いでしょうか。この場合はcolorはgeom_point()内部で、linetypeはgeom_smooth()でマッピングします。\n\nCountry_df |&gt;\n    mutate(OECD = if_else(OECD == 1, \"加盟国\", \"非加盟国\")) |&gt;\n    ggplot(aes(x = FH_Total, y = PPP_per_capita)) +\n    geom_point(aes(color = OECD)) +\n    geom_smooth(aes(linetype = OECD), method = \"lm\", color = \"black\")  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    coord_cartesian(ylim = c(0, 120000)) +\n    theme_bw(base_size = 12)\n\n\n\n\n\n\n\n\n　{ggplot2}が提供する平滑化ラインにはLOESSと回帰直線以外にも\"glm\"や\"gam\"などがります。詳細はRコンソール上で?geom_smoothを入力し、ヘルプを参照してください。"
  },
  {
    "objectID": "visualization4.html#sec-visual4-text",
    "href": "visualization4.html#sec-visual4-text",
    "title": "21  可視化 [発展]",
    "section": "21.8 文字列の出力",
    "text": "21.8 文字列の出力\n　ここでは図の中に文字列を追加する方法について解説します。\n　まずは、geom_text()からです。これはマッピングされたxとyの箇所に文字列を付ける帰化オブジェクトです。たとえば、Country_dfを用い、大陸（Continent）ごとに人間開発指数（HDI_2018）の平均値を棒グラフで示してみましょう。\n\nbar_plot &lt;- Country_df |&gt;\n  group_by(Continent) |&gt;\n  summarise(HDI = mean(HDI_2018, na.rm = TRUE)) |&gt;\n  ggplot() +\n  geom_bar(aes(x = Continent, y = HDI), stat = \"identity\") +\n  labs(x = \"Continent\", y = \"Mean of\\nHuman Development Index (2018)\") +\n  theme_minimal(base_size = 12)\n\nbar_plot\n\n\n\n\n\n\n\n\n　この棒の上に具体的な平均値を追加するとしましょう。数字が位置する箇所は棒グラフの横軸上の位置（x）、棒グラフの高さ（y）と一致するため、xとyはそれぞれContinentとHDIでマッピングします。そして、出力する内容をlabelにマッピングします。ここではHDIの値をそのまま出力するので、label = HDIです。\n\nbar_plot +\n  geom_text(aes(x = Continent, y = HDI, label = HDI),\n            size = 4)\n\n\n\n\n\n\n\n\n　ただし、棒と文字が重なり、やや読みにくいですね。しかも小数点も3桁くらいで十分でしょう。文字の位置をやや高めにするためにy = HDIをy = HDI + 0.03に調整します。また、小数点を丸めるためにlabel = round(HDI, 3)にへんこうします。ただし、round()を使う場合、round(1.1298, 3)は1.13と出力されます。もし、1.130のように出力したい場合はround()の代わりに、第11章でも紹介しましたsprintf()を使用します。今回の例の場合、sprintf(\"%.3f\", 1.1298)のように書きます。\n\nbar_plot +\n  geom_text(aes(x = Continent, y = HDI + 0.03, label = round(HDI, 3)),\n            size = 4)\n\n\n\n\n\n\n\n\n　geom_text()とほぼ同じ機能を持つ帰化オブジェクトとしてgeom_label()があります。これは使うと文字列が四角に囲まれた形式で出力されます。見出し紙のようなものであり、使い方はgeom_text()と同じです。\n\nbar_plot +\n  geom_label(aes(x = Continent, y = HDI, label = round(HDI, 3)),\n             size = 4)\n\n\n\n\n\n\n\n\n　続いて、マッピングを行わず、任意の位置に文字列を出力するannotate()です。こちらはマッピングが必要ありません。まず、Contury_dfを用い、フリーダムハウス・スコア（FH_Total）と一人あたり購買力平価GDP（PPP_per_capita）の散布図と回帰直線を出してみましょう。\n\nlm_plot &lt;- Country_df |&gt;\n    ggplot(aes(x = FH_Total, y = PPP_per_capita)) +\n    geom_point() +\n    geom_smooth(method = \"lm\", level = 0.999)  +\n    labs(x = \"Freedom House Score\", y = \"PPP per capita (USD)\") +\n    scale_y_continuous(breaks = seq(0, 120000, by = 10000),\n                       labels = seq(0, 120000, by = 10000)) +\n    theme_minimal(base_size = 12)\n\n　ここに「注: 青い線は回帰直線を表す。」という文字列を追加します。位置はx = 0、y = 110000とします。まず、annotate()の第一引数として\"text\"を指定します2。そして、xとyに文字列の位置を指定し、labelに出力する文字列を入力します。そして、hjust = 0で文字列を左側に寄せます。これを指定しないと、文字列の真ん中がx = 0に位置することになります。最後にsizeで文字列の大きさを指定します。\n\nlm_plot +\n  annotate(\"text\", x = 0, y = 110000, label = \"注: 青い線は回帰直線を表す。\", \n           hjust = 0, size = 5)\n\n\n\n\n\n\n\n\n　図の中に数式を入れる時にはRが提供するexpression()関数を使うことも出来ますが、LaTeX文法で数式が入力できる{latex2exp}パッケージはが便利です。使い方は単純で{latex2exp}を読み込み、label引数の実引数を指定する時にTex(\"$LaTeX文法の数式$\")を使うだけです。\"\"の中に数式が入りますが更に$で囲んでください。また、LaTeX文法の数式における\\は\\\\に置換する必要があります。。\n\npacman::p_load(latex2exp)\n\nlm_plot +\n  annotate(\"text\", x = 0, y = 110000, \n           label = TeX(\"$PPP\\\\_per\\\\_capita = \\\\alpha + \\\\beta \\\\cdot Freedom\\\\_House\\\\_Score + \\\\epsilon \\\\ where \\\\ \\\\epsilon \\\\sim Normal(0, \\\\sigma).$\"), \n           hjust = 0, size = 5)"
  },
  {
    "objectID": "visualization4.html#sec-visual4-heatmap",
    "href": "visualization4.html#sec-visual4-heatmap",
    "title": "21  可視化 [発展]",
    "section": "21.9 ヒートマップ",
    "text": "21.9 ヒートマップ\n\n21.9.1 2つの離散変数の分布を表すヒートマップ\n　ヒートマップ（heat map）には2つの使い方があります。まずは、離散変数\\(\\times\\)離散変数の同時分布を示す時です。これは後ほど紹介するモザイク・プロットと目的は同じですが、モザイク・プロットはセルの面積で密度や度数を表すに対し、ヒートマップは主に色で密度や度数を表します。\n　ここでは一人当たり購買力平価GDP（PPP_per_capita）を「1万ドル未満」、「1万ドル以上・2万ドル未満」、「2万ドル以上、3万ドル未満」、「3万ドル以上」の離散変数に変換し、大陸ごとの国家数をヒートマップとして示してみたいと思います。まずは、変数のリコーディングをし、全てfactor化します。最後に国家名（Country）、大陸（Continent）、所得（Income）、フリーダム・ハウス・スコア（FH_Total）、人間開発指数（HDI_2018）列のみ抽出し、Heatmap_dfという名のオブジェクトとして格納しておきます。\n\nHeatmap_df &lt;- Country_df |&gt;\n  filter(!is.na(PPP_per_capita)) |&gt;\n  mutate(Continent = recode(Continent,\n                            \"Africa\"  = \"アフリカ\",\n                            \"America\" = \"アメリカ\",\n                            \"Asia\"    = \"アジア\",\n                            \"Europe\"  = \"ヨーロッパ\",\n                            .default  = \"オセアニア\"),\n         Continent = factor(Continent, levels = c(\"アフリカ\", \"アメリカ\", \"アジア\", \n                                                  \"ヨーロッパ\", \"オセアニア\")),\n         Income    = case_when(PPP_per_capita &lt; 10000 ~ \"1万ドル未満\",\n                               PPP_per_capita &lt; 20000 ~ \"1万ドル以上\\n2万ドル未満\",\n                               PPP_per_capita &lt; 30000 ~ \"2万ドル以上\\n3万ドル未満\",\n                               TRUE                   ~ \"3万ドル以上\"),\n         Income    = factor(Income, levels = c(\"1万ドル未満\", \"1万ドル以上\\n2万ドル未満\",\n                                               \"2万ドル以上\\n3万ドル未満\", \"3万ドル以上\"))) |&gt;\n  select(Country, Continent, Income, FH_Total, HDI_2018)\n\nHeatmap_df\n\n# A tibble: 178 × 5\n   Country             Continent  Income                     FH_Total HDI_2018\n   &lt;chr&gt;               &lt;fct&gt;      &lt;fct&gt;                         &lt;dbl&gt;    &lt;dbl&gt;\n 1 Afghanistan         アジア     \"1万ドル未満\"                    27    0.496\n 2 Albania             ヨーロッパ \"1万ドル以上\\n2万ドル未満\"       67    0.791\n 3 Algeria             アフリカ   \"1万ドル以上\\n2万ドル未満\"       34    0.759\n 4 Angola              アフリカ   \"1万ドル未満\"                    32    0.574\n 5 Antigua and Barbuda アメリカ   \"2万ドル以上\\n3万ドル未満\"       85    0.776\n 6 Argentina           アメリカ   \"2万ドル以上\\n3万ドル未満\"       85    0.83 \n 7 Armenia             ヨーロッパ \"1万ドル以上\\n2万ドル未満\"       53    0.76 \n 8 Australia           オセアニア \"3万ドル以上\"                    97    0.938\n 9 Austria             ヨーロッパ \"3万ドル以上\"                    93    0.914\n10 Azerbaijan          ヨーロッパ \"1万ドル以上\\n2万ドル未満\"       10    0.754\n# ℹ 168 more rows\n\n\n　次はgroup_by()とsummarise()を使って、各カテゴリーに属するケース数を計算し、Nという名の列として追加します。\n\nHeatmap_df1 &lt;- Heatmap_df |&gt;\n  group_by(Continent, Income) |&gt;\n  summarise(N       = n(),\n            .groups = \"drop\")\n\nHeatmap_df1\n\n# A tibble: 18 × 3\n   Continent  Income                         N\n   &lt;fct&gt;      &lt;fct&gt;                      &lt;int&gt;\n 1 アフリカ   \"1万ドル未満\"                 41\n 2 アフリカ   \"1万ドル以上\\n2万ドル未満\"     9\n 3 アフリカ   \"2万ドル以上\\n3万ドル未満\"     2\n 4 アメリカ   \"1万ドル未満\"                 10\n 5 アメリカ   \"1万ドル以上\\n2万ドル未満\"    14\n 6 アメリカ   \"2万ドル以上\\n3万ドル未満\"     6\n 7 アメリカ   \"3万ドル以上\"                  5\n 8 アジア     \"1万ドル未満\"                 17\n 9 アジア     \"1万ドル以上\\n2万ドル未満\"    10\n10 アジア     \"2万ドル以上\\n3万ドル未満\"     3\n11 アジア     \"3万ドル以上\"                 11\n12 ヨーロッパ \"1万ドル未満\"                  1\n13 ヨーロッパ \"1万ドル以上\\n2万ドル未満\"    10\n14 ヨーロッパ \"2万ドル以上\\n3万ドル未満\"     7\n15 ヨーロッパ \"3万ドル以上\"                 28\n16 オセアニア \"1万ドル未満\"                  1\n17 オセアニア \"1万ドル以上\\n2万ドル未満\"     1\n18 オセアニア \"3万ドル以上\"                  2\n\n\n　これでデータの準備は終わりました。ヒートマップを作成する幾何オブジェクトはgeom_tile()です。同時分布を示したい変数を、それぞれxとyにマッピングし、密度、または度数を表す変数をfillにマッピングします。ここでは横軸を大陸（Continent）、縦軸を一人当たり購買力平価GDP（Income）とし、fillにはN変数をマッピングします。\n\nHeatmap_df1 |&gt;\n  ggplot() +\n  geom_tile(aes(x = Continent, y = Income, fill = N)) +\n  labs(x = \"大陸\", y = \"一人当たり購買力平価GDP（ドル）\", fill = \"国家数\") +\n  theme_bw(base_size = 12) +\n  theme(panel.grid = element_blank()) # グリッドラインを消す\n\n\n\n\n\n\n\n\n　明るいほどカテゴリーに属するケースが多く、暗いほど少ないことを意味します。これを見ると世界で最も多くの割合を占めているのは、一人当たり購買力平価GDPが1万ドル未満のアフリカの国で、次は一人当たり購買力平価GDPが3万ドル以上のヨーロッパの国であることが分かります。欠損している（ケース数が0）セルは白の空白となります。\n　色をカスタマイズするにはscale_fill_gradient()です。これは第20章で紹介しましたscale_color_gradient()と使い方は同じです。scale_fill_gradient()は中間点なし、scale_fill_gradient2()は中間点ありの場合に使いますが、ここでは度数が小さい場合はcornsilk色を、大きい場合はbrown3色を使います。それぞれlowとhighに色を指定するだけです。\n\nHeatmap_df1 |&gt;\n  ggplot() +\n  geom_tile(aes(x = Continent, y = Income, fill = N)) +\n  labs(x = \"大陸\", y = \"一人当たり購買力平価GDP（ドル）\", fill = \"国家数\") +\n  scale_fill_gradient(low  = \"cornsilk\", \n                      high = \"brown3\") +\n  theme_bw(base_size = 12) +\n  theme(panel.grid = element_blank()) # グリッドラインを消す\n\n\n\n\n\n\n\n\n　気のせいかも知れませんが、先ほどよりは読みやすくなったような気がしますね。\n\n\n21.9.2 離散変数\\(\\times\\)離散変数における連続変数の値を示すヒートマップ\n　次は、離散変数\\(\\times\\)離散変数における連続変数の値を示すヒートマップを作ってみましょう。ヒートマップにおけるそれぞれのタイル（tile）は横軸上の位置と縦軸上の位置情報を持ち、これは前回と同様、離散変数でマッピングされます。そして、タイルの色は何らかの連続変数にマッピングされます。前回作成しましたヒートマップは度数、または密度であり、これも実は連続変数だったので、図の作り方は本質的には同じです。\n　ここでは大陸と所得ごとに人間開発指数の平均値を表すヒートマップを作ってみましょう。大陸（Continent）と所得（Income）でグループ化し、人間開発指数（HDI_2018）の平均値を計算したものをHeatmap_df2という名のオブジェクトとして格納します。\n\nHeatmap_df2 &lt;- Heatmap_df |&gt;\n  group_by(Continent, Income) |&gt;\n  summarise(HDI     = mean(HDI_2018, na.rm = TRUE),\n            .groups = \"drop\")\n\nHeatmap_df2\n\n# A tibble: 18 × 3\n   Continent  Income                       HDI\n   &lt;fct&gt;      &lt;fct&gt;                      &lt;dbl&gt;\n 1 アフリカ   \"1万ドル未満\"              0.510\n 2 アフリカ   \"1万ドル以上\\n2万ドル未満\" 0.697\n 3 アフリカ   \"2万ドル以上\\n3万ドル未満\" 0.798\n 4 アメリカ   \"1万ドル未満\"              0.638\n 5 アメリカ   \"1万ドル以上\\n2万ドル未満\" 0.752\n 6 アメリカ   \"2万ドル以上\\n3万ドル未満\" 0.806\n 7 アメリカ   \"3万ドル以上\"              0.841\n 8 アジア     \"1万ドル未満\"              0.624\n 9 アジア     \"1万ドル以上\\n2万ドル未満\" 0.730\n10 アジア     \"2万ドル以上\\n3万ドル未満\" 0.818\n11 アジア     \"3万ドル以上\"              0.872\n12 ヨーロッパ \"1万ドル未満\"              0.711\n13 ヨーロッパ \"1万ドル以上\\n2万ドル未満\" 0.776\n14 ヨーロッパ \"2万ドル以上\\n3万ドル未満\" 0.827\n15 ヨーロッパ \"3万ドル以上\"              0.902\n16 オセアニア \"1万ドル未満\"              0.543\n17 オセアニア \"1万ドル以上\\n2万ドル未満\" 0.724\n18 オセアニア \"3万ドル以上\"              0.930\n\n\n　作図の方法は前回と同じですが、今回はタイルの色塗り（fill）を人間開発指数の平均値（HDI）でマッピングする必要があります。他の箇所は同じコードでも良いですが、ここでは色塗りの際、中間点を指定してみましょう。たとえば人間開発指数が0.75なら色をcornsilk色とし、これより低いっほどcornflowerblue色に、高いほどbrown3色になるように指定します。中間点を持つグラデーション色塗りはscale_fill_gradient2()で調整することができます。使い方はscale_fill_gradient()とほぼ同じですが、中間点の色（mid）と中間点の値（midpoint）をさらに指定する必要があります。\n\nHeatmap_df2 |&gt;\n  ggplot() +\n  geom_tile(aes(x = Continent, y = Income, fill = HDI)) +\n  labs(x = \"大陸\", y = \"一人当たり購買力平価GDP（ドル）\", \n       fill = \"人間開発指数の平均値 (2018)\") +\n  scale_fill_gradient2(low  = \"cornflowerblue\", \n                       mid  = \"cornsilk\",\n                       high = \"brown3\",\n                       midpoint = 0.75) +\n  theme_bw(base_size = 12) +\n  theme(legend.position = \"bottom\",\n        panel.grid      = element_blank())"
  },
  {
    "objectID": "visualization4.html#sec-visual4-contour",
    "href": "visualization4.html#sec-visual4-contour",
    "title": "21  可視化 [発展]",
    "section": "21.10 等高線図",
    "text": "21.10 等高線図\n　ヒートマップを使えば、離散変数\\(\\times\\)離散変数の同時分布を可視化することは出来ますが、連続変数\\(\\times\\)連続変数の同時分布を可視化するには限界があります。むろん、一つ一つのタイルを小さくすることも出来ますが、効率的な方法ではないでしょう。ここで活躍するのが等高線図 (contour plot) です。\n　たとえば、Country_dfのFH_TotalとHDI_2018の分布は散布図を通じて可視化することができます。\n\nCountry_df |&gt;\n  ggplot() +\n  geom_point(aes(x = FH_Total, y = HDI_2018)) +\n  labs(x = \"フリーダム・ハウス・スコア\", y = \"人間開発指数 (2018)\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n　右上に点が集まっていることから、密度の高い箇所だと考えられます。この密度を示す等高線図の幾何オブジェクトはgeom_density_2d()です。マッピング要素はgeom_point()と同じなので、マッピングはggplot()内で行い、geom_density_2d()レイヤーを使いしてみましょう。\n\nCountry_df |&gt;\n  ggplot(aes(x = FH_Total, y = HDI_2018)) +\n  geom_point() +\n  geom_density_2d() +\n  labs(x = \"フリーダム・ハウス・スコア\", y = \"人間開発指数 (2018)\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n　密度に応じて色塗りをする場合はgeom_density_2d()の代わりにgeom_density_2d_filled()を使います。\n\nCountry_df |&gt;\n  ggplot(aes(x = FH_Total, y = HDI_2018)) +\n  geom_density_2d_filled() +\n  labs(x = \"フリーダム・ハウス・スコア\", y = \"人間開発指数 (2018)\",\n       fill = \"密度\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n　geom_density_2d_filled()オブジェクトの後にgeom_density_2d()オブジェクトを重ねると、区間の区画線を追加することもできます。\n\nCountry_df |&gt;\n  ggplot(aes(x = FH_Total, y = HDI_2018)) +\n  geom_density_2d_filled() +\n  geom_density_2d(color = \"black\") +\n  labs(x = \"フリーダム・ハウス・スコア\", y = \"人間開発指数 (2018)\",\n       fill = \"密度\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n　色が気に入らない場合、自分で調整することも可能です。scale_fill_manual()で各区間ごとの色を指定することもできませんが、あまり効率的ではありません。ここではscale_fill_brewer()関数を使って、ColorBrewerのパレットを使ってみましょう。引数なしでも使えますが、既定値のパレットは区間が9つまで対応します。今回の等高線図は全部で10区間ですので、あまり適切ではありません。ここでは11区間まで対応可能な\"Spectral\"パレットを使いますが、これはpalette引数で指定できます。\n\nCountry_df |&gt;\n  ggplot(aes(x = FH_Total, y = HDI_2018)) +\n  geom_density_2d_filled() +\n  scale_fill_brewer(palette = \"Spectral\") +\n  labs(x = \"フリーダム・ハウス・スコア\", y = \"人間開発指数 (2018)\",\n       fill = \"密度\") +\n  theme_minimal(base_size = 12)\n\n\n\n\n\n\n\n\n　paletteで指定可能なカラーパレットの一覧は{RColorBrewer}のdisplay.brewer.all()関数で確認することが出来ます。各パレットが何区間まで対応できるかを見てから自分でパレットを作成することも可能ですが、詳細はネット上の各種記事を参照してください。\n\nRColorBrewer::display.brewer.all()\n\n\n\n\n{RColorBrewer}が提供するパレート一覧"
  },
  {
    "objectID": "visualization4.html#sec-visual4-map",
    "href": "visualization4.html#sec-visual4-map",
    "title": "21  可視化 [発展]",
    "section": "21.11 地図",
    "text": "21.11 地図\n\n21.11.1 世界地図\n{ggplot2}で地図をプロットする方法は色々あります。理想としては各国政府が提供する地図データをダウンロードし、それを読み込み・加工してプロットすることでしょうが、ここではパッケージを使ったマッピングについて紹介します。\n　今回使用するパッケージは{rnaturalearth}、{rnaturalearthdata}、{rgeos}です。他にも使うパッケージはありますが、世界地図ならとりあえずこれで十分です。\n\npacman::p_load(rnaturalearth, rnaturalearthdata, rgeos)\n\n　世界地図を読み込む関数は{rnaturalearth}が提供するne_countries()です。とりあえず指定する引数はscaleとretunrclassです。scaleは地図の解像度であり、世界地図なら\"small\"で十分です。もう少し拡大される大陸地図なら\"medium\"が、一国だけの地図なら\"large\"が良いかも知れません。reutrnclassは\"sf\"と指定します。今回は低解像度の世界地図をsfクラスで読み込んでみましょう。\n\nworld_map &lt;- ne_countries(scale = \"small\", returnclass = \"sf\")\n\nworld_map &lt;- world_map |&gt; \n  mutate(pop_est = as.numeric(pop_est))\n\nclass(world_map)\n\n[1] \"sf\"         \"data.frame\"\n\n\n　クラスはdata.frameとsfであり、実際、world_mapを出力してみると、見た目がデータフレームであることが分かります。地図の出力はgeom_sf()幾何オブジェクトを使用します。とりあえず、やってみましょう。\n\nworld_map |&gt; \n  ggplot() +\n  geom_sf() +\n  theme_void() # 何もないテーマを指定する。ここはお好みで\n\n\n\n\n\n\n\n\n　もし、各国の人口に応じて色塗りをする場合はどうすれば良いでしょうか。実は、今回使用するデータがデータフレーム形式であることを考えると、これまでの{ggplot2}の使い方とあまり変わりません。{rnaturalearth}から読み込んだデータには既にpop_estという各国の人口データが含まれています（他にも自分で構築したデータがあるなら、データを結合して使用すれば良いですが、これについては後述します。）。この値に応じて色塗りを行うため、geom_sf()内にfill = pop_estでマッピングするだけです。また、国境線の色はcolorで指定可能です。白（\"white\"）だと少しおしゃれな感じがするのでやってみましょう。国境線は全ての国に適用されるものなので、aes()の外側で指定します。\n\nworld_map |&gt; \n  ggplot() +\n  geom_sf(aes(fill = pop_est), color = \"white\") +\n  # 人口が少ない国はcornflowerblue色に、多い国はbrown3色とする\n  scale_fill_gradient(low = \"cornflowerblue\", high = \"brown3\") +\n  labs(fill = \"人口\") +\n  theme_void()\n\n\n\n\n\n\n\n\n　もし、世界でなく一部の地域だけを出力するなら、coord_sf()で座標系を調整します。東アジアと東南アジアの一部を出力したいとします。この場合、経度は90度から150度まで、緯度は10度から50度に絞ることになります。経度はxlimで、緯度はylimで調整します。\n\nworld_map |&gt; \n  ggplot() +\n  geom_sf(aes(fill = pop_est)) +\n  scale_fill_gradient(low = \"cornflowerblue\", high = \"brown3\") +\n  labs(fill = \"人口\") +\n  coord_sf(xlim = c(90, 150), ylim = c(10, 50)) +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　他にもne_countries()内にcontinent引数を指定し、特定の大陸だけを読み込むことで可能です。ここではアジアの国のみを抽出し、asia_mapという名のオブジェクトとして格納します。解像度は中程度とします。\n\nasia_map &lt;- ne_countries(scale = \"medium\", continent = \"Asia\", \n                         returnclass = \"sf\")\n\nasia_map |&gt;\n    ggplot() +\n    # 所得グループで色塗り\n    geom_sf(aes(fill = income_grp)) +\n    theme_void() +\n    labs(fill = \"Income Group\")\n\n\n\n\n\n\n\n\n　アジアの中から更に東アジアに絞りたい場合はfilter()を使用し、subregion列を基準に抽出することも可能です。\n\nasia_map |&gt;\n    filter(subregion == \"Eastern Asia\") |&gt;\n    ggplot() +\n    geom_sf(aes(fill = income_grp)) +\n    theme_void() +\n    labs(fill = \"Income Group\")\n\n\n\n\n\n\n\n\n　subregionの値は以下のように確認可能です。\n\nunique(asia_map$subregion)\n\n[1] \"Southern Asia\"           \"Western Asia\"           \n[3] \"South-Eastern Asia\"      \"Eastern Asia\"           \n[5] \"Seven seas (open ocean)\" \"Central Asia\"           \n\n\n　これまで使用してきたデータがデータフレームと同じ見た目をしているため、{dplyr}を用いたデータハンドリングも可能です。たとえば、人口を連続変数としてでなく、factor型に変換してからマッピングをしてみましょう。\n\nasia_map |&gt; \n  mutate(Population = case_when(pop_est &lt; 10000000  ~ \"1千万未満\",\n                                pop_est &lt; 50000000  ~ \"5千万未満\",\n                                pop_est &lt; 100000000 ~ \"1億未満\",\n                                pop_est &lt; 500000000 ~ \"5億未満\",\n                                TRUE                ~ \"5億以上\"),\n         Population = factor(Population, \n                             levels = c(\"1千万未満\", \"5千万未満\", \"1億未満\",\n                                        \"5億未満\", \"5億以上\"))) |&gt;\n  ggplot() +\n  geom_sf(aes(fill = Population)) +\n  scale_fill_brewer(palette = \"Blues\", drop = FALSE) +\n  labs(fill = \"人口\") +\n  theme_void() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　scale_fill_brewer()のpalette引数は等高線図のときに紹介しましたパレート一覧を参照してください。\n\n\n21.11.2 日本地図（全体）\n　次は日本地図の出力についてです。日本全土だけを出力するなら、これまで使いましたne_countriesにcountry引数を指定するだけで使えます。たとえば、日本の地図だけなら、country = \"Japan\"を指定します。\n\nne_countries(scale = \"small\", country = \"Japan\", returnclass = \"sf\") |&gt;\n    ggplot() +\n    geom_sf() +\n    theme_void() # 空っぽのテーマ\n\n\n\n\n\n\n\n\n　これだと、物足りない感があるので、もう少し高解像度の地図にしてみましょう。高解像度の地図データを読み込む際はscale = \"large\"を指定します。\n\nne_countries(scale = \"large\", country = \"Japan\", returnclass = \"sf\") |&gt;\n    ggplot() +\n    geom_sf() +\n    theme_void() # 空っぽのテーマ\n\n\n\n\n\n\n\n\n　ただ、日本地図を出すという場合、多くは都道府県レベルでマッピングが目的でしょう。世界地図のマッピングならこれで問題ありませんが、一国だけなら、その下の自治体の境界線も必要です。したがって、先ほど使用しましたパッケージのより高解像度の地図が含まれている{rnaturalearthhires}をインストールし、読み込みましょう。2023年Jun月26日現在、{rnaturalearthhires}はCRANに登録されておらず、GitHubのropensciレポジトリーのみで公開されているため、今回は{pacman}のp_load()でなく、p_load_gh()を使用します。\n\npacman::p_load_gh(\"ropensci/rnaturalearthhires\")\n\n　地図データの抽出にはne_states()関数を使用します。第一引数として国家名を指定し、地図データのクラスはsfとします。抽出したデータの使い方は世界地図の時と同じです。\n\nJapan_Map &lt;- ne_states(\"Japan\", returnclass = \"sf\")\n\nJapan_Map |&gt;\n  ggplot() +\n  geom_sf() +\n  theme_void()\n\n\n\n\n\n\n\n\n　今回は各都道府県を人口密度ごとに色塗りをしてみましょう。ne_states()で読み込んだデータに人口密度のデータはないため、別途のデータと結合する必要があります。筆者が予め作成しておいたデータを読み込み、中身を確認してみます。\n\nJapan_Density &lt;- read_csv(\"Data/Japan_Density.csv\")\n\nJapan_Density\n\n# A tibble: 47 × 3\n    Code Name   Density\n   &lt;dbl&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1     1 北海道    66.6\n 2     2 青森県   128. \n 3     3 岩手県    79.2\n 4     4 宮城県   316. \n 5     5 秋田県    82.4\n 6     6 山形県   115. \n 7     7 福島県   133  \n 8     8 茨城県   470. \n 9     9 栃木県   302. \n10    10 群馬県   305. \n# ℹ 37 more rows\n\n\n　各都道府県の人口密度がついております、左側のCodeは何でしょうか。これは各都道府県のISOコードであり、このコードをキー変数としてデータを結合することとなります。各都道府県のコードは国土交通省のホームページから確認可能です。\n　それではデータを結合してみましょう。ne_states()で読み込んだデータの場合、地域のコードはiso_3166_2という列に格納されています。\n\nJapan_Map$iso_3166_2\n\n [1] \"JP-46\" \"JP-44\" \"JP-40\" \"JP-41\" \"JP-42\" \"JP-43\" \"JP-45\" \"JP-36\" \"JP-37\"\n[10] \"JP-38\" \"JP-39\" \"JP-32\" \"JP-35\" \"JP-31\" \"JP-28\" \"JP-26\" \"JP-18\" \"JP-17\"\n[19] \"JP-16\" \"JP-15\" \"JP-06\" \"JP-05\" \"JP-02\" \"JP-03\" \"JP-04\" \"JP-07\" \"JP-08\"\n[28] \"JP-12\" \"JP-13\" \"JP-14\" \"JP-22\" \"JP-23\" \"JP-24\" \"JP-30\" \"JP-27\" \"JP-33\"\n[37] \"JP-34\" \"JP-01\" \"JP-47\" \"JP-10\" \"JP-20\" \"JP-09\" \"JP-21\" \"JP-25\" \"JP-11\"\n[46] \"JP-19\" \"JP-29\"\n\n\n　こちらは文字列となっていますね。これを左から4番目の文字から切り取り、数値型に変換します。変換したコードは結合のためにCodeという名の列として追加しましょう。\n\nJapan_Map &lt;- Japan_Map |&gt;\n    mutate(Code = str_sub(iso_3166_2, 4),\n           Code = as.numeric(Code))\n\nJapan_Map$Code\n\n [1] 46 44 40 41 42 43 45 36 37 38 39 32 35 31 28 26 18 17 16 15  6  5  2  3  4\n[26]  7  8 12 13 14 22 23 24 30 27 33 34  1 47 10 20  9 21 25 11 19 29\n\n\n　続いて、Japan_MapとJapan_DensityをCode列をキー変数として結合します。データの中身を確認すると、Density列が最後(の直前)の列に追加されたことが分かります。\n\nJapan_Map &lt;- left_join(Japan_Map, Japan_Density, by = \"Code\")\n\nJapan_Map\n\nSimple feature collection with 47 features and 86 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 122.9382 ymin: 24.2121 xmax: 153.9856 ymax: 45.52041\nGeodetic CRS:  +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84 +towgs84=0,0,0\nFirst 10 features:\n           featurecla scalerank adm1_code diss_me iso_3166_2 wikipedia iso_a2\n1  Admin-1 scale rank         2  JPN-3501    3501      JP-46      &lt;NA&gt;     JP\n2  Admin-1 scale rank         6  JPN-1835    1835      JP-44      &lt;NA&gt;     JP\n3  Admin-1 scale rank         6  JPN-1829    1829      JP-40      &lt;NA&gt;     JP\n4  Admin-1 scale rank         6  JPN-1827    1827      JP-41      &lt;NA&gt;     JP\n5  Admin-1 scale rank         2  JPN-3500    3500      JP-42      &lt;NA&gt;     JP\n6  Admin-1 scale rank         6  JPN-1830    1830      JP-43      &lt;NA&gt;     JP\n7  Admin-1 scale rank         6  JPN-1831    1831      JP-45      &lt;NA&gt;     JP\n8  Admin-1 scale rank         6  JPN-1836    1836      JP-36      &lt;NA&gt;     JP\n9  Admin-1 scale rank         6  JPN-1833    1833      JP-37      &lt;NA&gt;     JP\n10 Admin-1 scale rank         6  JPN-1832    1832      JP-38      &lt;NA&gt;     JP\n   adm0_sr      name name_alt name_local type    type_en code_local code_hasc\n1        5 Kagoshima     &lt;NA&gt;       &lt;NA&gt;  Ken Prefecture       &lt;NA&gt;     JP.KS\n2        1      Oita     &lt;NA&gt;       &lt;NA&gt;  Ken Prefecture       &lt;NA&gt;     JP.OT\n3        1   Fukuoka  Hukuoka       &lt;NA&gt;  Ken Prefecture       &lt;NA&gt;     JP.FO\n4        1      Saga     &lt;NA&gt;       &lt;NA&gt;  Ken Prefecture       &lt;NA&gt;     JP.SG\n5        3  Nagasaki     &lt;NA&gt;       &lt;NA&gt;  Ken Prefecture       &lt;NA&gt;     JP.NS\n6        1  Kumamoto     &lt;NA&gt;       &lt;NA&gt;  Ken Prefecture       &lt;NA&gt;     JP.KM\n7        1  Miyazaki     &lt;NA&gt;       &lt;NA&gt;  Ken Prefecture       &lt;NA&gt;     JP.MZ\n8        1 Tokushima Tokusima       &lt;NA&gt;  Ken Prefecture       &lt;NA&gt;     JP.TS\n9        1    Kagawa     &lt;NA&gt;       &lt;NA&gt;  Ken Prefecture       &lt;NA&gt;     JP.KG\n10       4     Ehime     &lt;NA&gt;       &lt;NA&gt;  Ken Prefecture       &lt;NA&gt;     JP.EH\n   note hasc_maybe  region region_cod provnum_ne gadm_level check_me datarank\n1  &lt;NA&gt;      JP.NR  Kyushu    JPN-KYS          3          1       20        9\n2  &lt;NA&gt;      JP.ON  Kyushu    JPN-SHK         48          1       20        2\n3  &lt;NA&gt;      JP.NS  Kyushu    JPN-KYS         46          1       20        2\n4  &lt;NA&gt;      JP.OS    &lt;NA&gt;       &lt;NA&gt;         47          1       20        2\n5  &lt;NA&gt;      JP.OY    &lt;NA&gt;       &lt;NA&gt;          5          1       20        9\n6  &lt;NA&gt;      JP.NI  Kyushu    JPN-KYS          6          1       20        2\n7  &lt;NA&gt;      JP.OT  Kyushu    JPN-KYS         49          1       20        2\n8  &lt;NA&gt;      JP.SZ Shikoku    JPN-SHK         45          1       20        2\n9  &lt;NA&gt;      JP.SH Shikoku    JPN-SHK          4          1       20        2\n10 &lt;NA&gt;      JP.ST Shikoku    JPN-SHK         14          1       20        2\n   abbrev postal area_sqkm sameascity labelrank name_len mapcolor9 mapcolor13\n1    &lt;NA&gt;   &lt;NA&gt;         0         NA         2        9         5          4\n2    &lt;NA&gt;     OT         0          7         7        4         5          4\n3    &lt;NA&gt;     FO         0          7         7        7         5          4\n4    &lt;NA&gt;     SG         0         NA         6        4         5          4\n5    &lt;NA&gt;   &lt;NA&gt;         0         NA         2        8         5          4\n6    &lt;NA&gt;     KM         0         NA         6        8         5          4\n7    &lt;NA&gt;     MZ         0         NA         6        8         5          4\n8    &lt;NA&gt;     TS         0         NA         6        9         5          4\n9    &lt;NA&gt;     KG         0         NA         6        6         5          4\n10   &lt;NA&gt;     EH         0         NA         6        5         5          4\n   fips fips_alt   woe_id                       woe_label  woe_name latitude\n1  JA18     JA28  2345867 Kagoshima Prefecture, JP, Japan Kagoshima  29.4572\n2  JA30     JA47  2345879      Oita Prefecture, JP, Japan      Oita  33.2006\n3  JA07     JA27 58646425   Fukuoka Prefecture, JP, Japan   Fukuoka  33.4906\n4  JA33     JA32  2345882      Saga Prefecture, JP, Japan      Saga  33.0097\n5  JA27     JA31  2345876  Nagasaki Prefecture, JP, Japan  Nagasaki  32.6745\n6  JA21     JA29  2345870  Kumamoto Prefecture, JP, Japan  Kumamoto  32.5880\n7  JA25     JA30  2345874  Miyazaki Prefecture, JP, Japan  Miyazaki  32.0981\n8  JA39     JA37  2345888 Tokushima Prefecture, JP, Japan Tokushima  33.8546\n9  JA17     JA35  2345866    Kagawa Prefecture, JP, Japan    Kagawa  34.2162\n10 JA05     JA34  2345855     Ehime Prefecture, JP, Japan     Ehime  33.8141\n   longitude sov_a3 adm0_a3 adm0_label admin geonunit gu_a3   gn_id\n1    129.601    JPN     JPN          4 Japan    Japan   JPN 1860825\n2    131.449    JPN     JPN          4 Japan    Japan   JPN 1854484\n3    130.616    JPN     JPN          4 Japan    Japan   JPN 1863958\n4    130.147    JPN     JPN          4 Japan    Japan   JPN 1853299\n5    128.755    JPN     JPN          4 Japan    Japan   JPN 1856156\n6    130.834    JPN     JPN          4 Japan    Japan   JPN 1858419\n7    131.286    JPN     JPN          4 Japan    Japan   JPN 1856710\n8    134.200    JPN     JPN          4 Japan    Japan   JPN 1850157\n9    134.001    JPN     JPN          4 Japan    Japan   JPN 1860834\n10   132.916    JPN     JPN          4 Japan    Japan   JPN 1864226\n         gn_name  gns_id      gns_name gn_level gn_region gn_a1_code region_sub\n1  Kagoshima-ken -231556 Kagoshima-ken        1      &lt;NA&gt;      JP.18       &lt;NA&gt;\n2       Oita-ken -240089      Oita-ken        1      &lt;NA&gt;      JP.30       &lt;NA&gt;\n3    Fukuoka-ken -227382   Fukuoka-ken        1      &lt;NA&gt;      JP.07       &lt;NA&gt;\n4       Saga-ken -241905      Saga-ken        1      &lt;NA&gt;      JP.33       &lt;NA&gt;\n5   Nagasaki-ken -237758  Nagasaki-ken        1      &lt;NA&gt;      JP.27       &lt;NA&gt;\n6   Kumamoto-ken -234759  Kumamoto-ken        1      &lt;NA&gt;      JP.21       &lt;NA&gt;\n7   Miyazaki-ken -236958  Miyazaki-ken        1      &lt;NA&gt;      JP.25       &lt;NA&gt;\n8  Tokushima-ken -246216 Tokushima-ken        1      &lt;NA&gt;      JP.39       &lt;NA&gt;\n9     Kagawa-ken -231546    Kagawa-ken        1      &lt;NA&gt;      JP.17       &lt;NA&gt;\n10     Ehime-ken -227007     Ehime-ken        1      &lt;NA&gt;      JP.05       &lt;NA&gt;\n   sub_code gns_level gns_lang gns_adm1 gns_region min_label max_label min_zoom\n1      &lt;NA&gt;         1      jpn     JA18       &lt;NA&gt;         7        11        3\n2      &lt;NA&gt;         1      jpn     JA30       &lt;NA&gt;         7        11        3\n3      &lt;NA&gt;         1      jpn     JA07       &lt;NA&gt;         7        11        3\n4      &lt;NA&gt;         1      jpn     JA33       &lt;NA&gt;         7        11        3\n5      &lt;NA&gt;         1      jpn     JA27       &lt;NA&gt;         7        11        3\n6      &lt;NA&gt;         1      jpn     JA21       &lt;NA&gt;         7        11        3\n7      &lt;NA&gt;         1      jpn     JA25       &lt;NA&gt;         7        11        3\n8      &lt;NA&gt;         1      jpn     JA39       &lt;NA&gt;         7        11        3\n9      &lt;NA&gt;         1      jpn     JA17       &lt;NA&gt;         7        11        3\n10     &lt;NA&gt;         1      jpn     JA05       &lt;NA&gt;         7        11        3\n   wikidataid name_ar name_bn             name_de              name_en\n1      Q15701    &lt;NA&gt;    &lt;NA&gt; Präfektur Kagoshima Kagoshima Prefecture\n2     Q133924    &lt;NA&gt;    &lt;NA&gt;      Präfektur Oita      Oita Prefecture\n3     Q123258    &lt;NA&gt;    &lt;NA&gt;   Präfektur Fukuoka   Fukuoka Prefecture\n4     Q160420    &lt;NA&gt;    &lt;NA&gt;      Präfektur Saga      Saga Prefecture\n5     Q169376    &lt;NA&gt;    &lt;NA&gt;  Präfektur Nagasaki  Nagasaki Prefecture\n6     Q130308    &lt;NA&gt;    &lt;NA&gt;  Präfektur Kumamoto  Kumamoto Prefecture\n7     Q130300    &lt;NA&gt;    &lt;NA&gt;  Präfektur Miyazaki  Miyazaki Prefecture\n8     Q160734    &lt;NA&gt;    &lt;NA&gt; Präfektur Tokushima Tokushima Prefecture\n9     Q161454    &lt;NA&gt;    &lt;NA&gt;    Präfektur Kagawa    Kagawa Prefecture\n10    Q123376    &lt;NA&gt;    &lt;NA&gt;     Präfektur Ehime     Ehime Prefecture\n                   name_es                 name_fr name_el name_hi\n1  Prefectura de Kagoshima Préfecture de Kagoshima    &lt;NA&gt;    &lt;NA&gt;\n2       Prefectura de Oita       Préfecture d'Oita    &lt;NA&gt;    &lt;NA&gt;\n3    Prefectura de Fukuoka   Préfecture de Fukuoka    &lt;NA&gt;    &lt;NA&gt;\n4       Prefectura de Saga      Préfecture de Saga    &lt;NA&gt;    &lt;NA&gt;\n5   Prefectura de Nagasaki  Préfecture de Nagasaki    &lt;NA&gt;    &lt;NA&gt;\n6   Prefectura de Kumamoto  Préfecture de Kumamoto    &lt;NA&gt;    &lt;NA&gt;\n7   Prefectura de Miyazaki  Préfecture de Miyazaki    &lt;NA&gt;    &lt;NA&gt;\n8  Prefectura de Tokushima Préfecture de Tokushima    &lt;NA&gt;    &lt;NA&gt;\n9     Prefectura de Kagawa    Préfecture de Kagawa    &lt;NA&gt;    &lt;NA&gt;\n10     Prefectura de Ehime      Préfecture d'Ehime    &lt;NA&gt;    &lt;NA&gt;\n                name_hu             name_id                 name_it name_ja\n1   Kagosima prefektúra Prefektur Kagoshima prefettura di Kagoshima    &lt;NA&gt;\n2       Óita prefektúra      Prefektur Oita      prefettura di Oita    &lt;NA&gt;\n3    Fukuoka prefektúra   Prefektur Fukuoka   prefettura di Fukuoka    &lt;NA&gt;\n4      Szaga prefektúra      Prefektur Saga      Prefettura di Saga    &lt;NA&gt;\n5  Nagaszaki prefektúra  Prefektur Nagasaki  prefettura di Nagasaki    &lt;NA&gt;\n6   Kumamoto prefektúra  Prefektur Kumamoto  prefettura di Kumamoto    &lt;NA&gt;\n7   Mijazaki prefektúra  Prefektur Miyazaki  prefettura di Miyazaki    &lt;NA&gt;\n8   Tokusima prefektúra Prefektur Tokushima prefettura di Tokushima    &lt;NA&gt;\n9     Kagava prefektúra    Prefektur Kagawa    prefettura di Kagawa    &lt;NA&gt;\n10     Ehime prefektúra     Prefektur Ehime     prefettura di Ehime    &lt;NA&gt;\n   name_ko   name_nl              name_pl   name_pt name_ru             name_sv\n1     &lt;NA&gt; Kagoshima Prefektura Kagoshima Kagoshima    &lt;NA&gt; Kagoshima prefektur\n2     &lt;NA&gt;      Oita      Prefektura Oita      Oita    &lt;NA&gt;      Oita prefektur\n3     &lt;NA&gt;   Fukuoka   Prefektura Fukuoka   Fukuoka    &lt;NA&gt;   Fukuoka prefektur\n4     &lt;NA&gt;      Saga      Prefektura Saga      Saga    &lt;NA&gt;      Saga prefektur\n5     &lt;NA&gt;  Nagasaki  Prefektura Nagasaki  Nagasaki    &lt;NA&gt;  Nagasaki prefektur\n6     &lt;NA&gt;  Kumamoto  Prefektura Kumamoto  Kumamoto    &lt;NA&gt;  Kumamoto prefektur\n7     &lt;NA&gt;  Miyazaki  Prefektura Miyazaki  Miyazaki    &lt;NA&gt;  Miyazaki prefektur\n8     &lt;NA&gt; Tokushima Prefektura Tokushima Tokushima    &lt;NA&gt; Tokushima prefektur\n9     &lt;NA&gt;    Kagawa    Prefektura Kagawa    Kagawa    &lt;NA&gt;    Kagawa prefektur\n10    &lt;NA&gt;     Ehime     Prefektura Ehime     Ehime    &lt;NA&gt;     Ehime prefektur\n        name_tr   name_vi name_zh      ne_id Code     Name Density\n1  Kagosima ili Kagoshima    &lt;NA&gt; 1159315225   46 鹿児島県   172.9\n2          Oita      Oita    &lt;NA&gt; 1159311905   44   大分県   177.2\n3       Fukuoka   Fukuoka    &lt;NA&gt; 1159311899   40   福岡県  1029.8\n4          Saga      Saga    &lt;NA&gt; 1159311895   41   佐賀県   332.5\n5      Nagasaki  Nagasaki    &lt;NA&gt; 1159315235   42   長崎県   317.7\n6      Kumamoto  Kumamoto    &lt;NA&gt; 1159311901   43   熊本県   234.6\n7      Miyazaki  Miyazaki    &lt;NA&gt; 1159311903   45   宮崎県   138.3\n8     Tokushima Tokushima    &lt;NA&gt; 1159311909   36   徳島県   173.5\n9        Kagawa    Kagawa    &lt;NA&gt; 1159311907   37   香川県   506.3\n10        Ehime     Ehime    &lt;NA&gt; 1159311139   38   愛媛県   235.2\n                         geometry\n1  MULTIPOLYGON (((129.7832 31...\n2  MULTIPOLYGON (((131.2009 33...\n3  MULTIPOLYGON (((130.0363 33...\n4  MULTIPOLYGON (((129.8145 33...\n5  MULTIPOLYGON (((130.2041 32...\n6  MULTIPOLYGON (((130.3446 32...\n7  MULTIPOLYGON (((131.8723 32...\n8  MULTIPOLYGON (((134.4424 34...\n9  MULTIPOLYGON (((133.5919 34...\n10 MULTIPOLYGON (((132.6399 32...\n\n\n　それではマッピングをしてみましょう。人口密度を5つのカテゴリーに順序付きfactor化してから、そのカテゴリーに応じて色塗りをします。\n\nJapan_Map |&gt;\n    mutate(Density2 = case_when(Density &gt;= 3000 ~ \"3000人以上\",\n                                Density &gt;= 1000 ~ \"1000人以上\",\n                                Density &gt;=  500 ~ \"500人以上\",\n                                Density &gt;=  100 ~ \"100人以上\",\n                                TRUE            ~ \"100人未満\"),\n           Density2 = factor(Density2, ordered = TRUE,\n                             levels = c(\"3000人以上\", \"1000人以上\", \"500人以上\",\n                                        \"100人以上\", \"100人未満\"))) |&gt;\n    ggplot() +\n    geom_sf(aes(fill = Density2)) +\n    labs(fill = \"人口密度 (km^2)\") +\n    theme_void()\n\n\n\n\n\n\n\n\n　世界地図でも同じやり方でデータの結合が可能です。この場合はISO3コードかISO2コードがキー変数となります。ISO3コードはiso_a3、ISO2コードはiso_a2列に格納されています。他に使用可能なキー変数はiso_n3であり、こちらは各国を識別する3桁の数字となります。\n\n\n21.11.3 日本地図（特定の都道府県）\n　また日本地図のマッピングですが、今回は市区町村レベルまで見てみましょう。ne_states()では市区町村までマッピングすることはできませんので、今回は徳島大学の瓜生真也先生が公開しました{jpndistrict}を使います。\n\npacman::p_load_gh(\"uribo/jpndistrict\")\n\n　今回は大阪府の地図を出力してみましょう。特定の都道府県の地図を読み込むためにはjpn_pref()関数を使用します。都道府県はpref_codeまたはadmin_nameで指定します。大阪のコードは27であるため、pref_code = 27でも良いですし、admin_name = \"大阪府\"でも同じです。\n\n# Osaka_map &lt;- jpn_pref(admin_name = \"大阪府\") でも同じ\nOsaka_map &lt;- jpn_pref(pref_code = 27)\n\nclass(Osaka_map)\n\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n　プロットの方法は同じです。\n\nOsaka_map |&gt;\n  ggplot() +\n  geom_sf() +\n  theme_minimal()\n\n\n\n\n\n\n\n\n　ここでもデータの結合&マッピングが可能です。大阪府内自治体の人口と学生数が格納されたデータを読み込んでみましょう。こちらは2015年国勢調査の結果から取得したデータです。\n\nOsaka_Student &lt;- read_csv(\"data/Osaka_Student.csv\")\n\nOsaka_Student\n\n# A tibble: 75 × 4\n    Code Name                Pop Student\n   &lt;dbl&gt; &lt;chr&gt;             &lt;dbl&gt;   &lt;dbl&gt;\n 1 27000 大阪府          8839469  438901\n 2 27100 大阪市          2691185  104208\n 3 27102 大阪市 都島区    104727    3889\n 4 27103 大阪市 福島区     72484    2448\n 5 27104 大阪市 此花区     66656    2478\n 6 27106 大阪市 西区       92430    2633\n 7 27107 大阪市 港区       82035    3072\n 8 27108 大阪市 大正区     65141    2627\n 9 27109 大阪市 天王寺区   75729    3480\n10 27111 大阪市 浪速区     69766    1409\n# ℹ 65 more rows\n\n\n　各市区町村にもコードが指定されており、Osaka_StudentではCode列、Osaka_mapではciti_code列となります。Osaka_mapのcity_codeは文字列であるため、こちらを数値型に変換しCodeという名の列として追加しておきましょう。続いて、Code列をキー変数とし、2つのデータセットを結合します。\n\nOsaka_map &lt;- Osaka_map |&gt;\n    mutate(Code = as.numeric(city_code))\n\nOsaka_map &lt;- left_join(Osaka_map, Osaka_Student, by = \"Code\")\n\n　最後にマッピングです。ここでは人口1万人当たり学生数をStudent_Ratioという列として追加し、こちらの値に合わせて色塗りをしてみましょう。scale_fill_gradient()を使用し、人口1万人当たり学生数が少ないほど白、多いほど黒塗りします。\n\nOsaka_map |&gt;\n  mutate(Student_Ratio = Student / Pop * 10000) |&gt;\n  ggplot() +\n  geom_sf(aes(fill = Student_Ratio)) +\n  scale_fill_gradient(low = \"white\", high = \"black\") +\n  labs(fill = \"1万人当たり学生数 (人)\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")"
  },
  {
    "objectID": "visualization4.html#sec-visual4-dag",
    "href": "visualization4.html#sec-visual4-dag",
    "title": "21  可視化 [発展]",
    "section": "21.12 非巡回有向グラフ",
    "text": "21.12 非巡回有向グラフ\n　近年、因果推論の界隈でよく登場する非巡回有向グラフ（DAG）ですが、「グラフ」からも分かるように、DAGの考え方に基づく因果推論の研究には多くの図が登場します。DAGを作図するには{ggplot2}のみでも可能ですが、{dagitty}パッケージでDAGの情報を含むオブジェクトを生成し、{ggdag}で作図した方が簡単です。以下の図はDAGの一例です。\n\n\n\n\n\n\n\n\n\n　ここでX、Y、Zはノード（node）と呼ばれ、それぞれのノードをつなぐ線のことをエッジ（edge）と呼びます。また、これらのエッジには方向があります（有向）。簡単に言うと原因と結果といった関係ですが、DAGを描く際は、各ノード間の関係を記述する必要があります。\n　それではまず、以上の図を作ってみましょう。最初のステップとして{dagitty}と{ggdag}をインストールし、読み込みましょう。\n\npacman::p_load(dagitty, ggdag)\n\n　つづいて、DAGの情報を含むオブジェクトを作成します。使用する関数はdagify()であり、ここには結果 ~ 原因の形式で各ノード間の関係を記述します。先ほどの図ではXはYの原因（X ~ Y）、ZはXとYの原因（X ~ ZとY ~ Z）です。これらの情報をdagify()内で指定します。\n\nDAG_data1 &lt;- dagify(X ~ Z,\n                    Y ~ Z,\n                    Y ~ X,\n                    exposure = \"X\",\n                    outcome  = \"Y\")\n\nDAG_data1\n\ndag {\nX [exposure]\nY [outcome]\nZ\nX -&gt; Y\nZ -&gt; X\nZ -&gt; Y\n}\n\n\n　Y ~ XとY ~ ZはY ~ X + Zとまとめることも可能です。これは「Yの原因はXとZである」という意味であり、「Yの原因はXであり、Yの原因はZである」と同じ意味です。また、DAGを作図する際、dagify()内にexposureとoutcomeは不要ですが、もしadjustmentSets()関数などを使って統制変数を特定したい場合は処置変数（exposure）と応答変数（outcome）にそれぞれ変数名を指定します。ちなみに、以上のコードは以下のように書くことも可能です。\n\nDAG_data1 &lt;- dagitty(\n  \"dag{\n  X -&gt; Y\n  X &lt;- Z -&gt; Y\n  X [exposure]\n  Y [outcome]\n  }\")\n\nDAG_data1\n\ndag {\nX [exposure]\nY [outcome]\nZ\nX -&gt; Y\nZ -&gt; X\nZ -&gt; Y\n}\n\n\n　格納されたDAG_data1オブジェクトのクラスは\"dagitty\"です。\"dagitty\"の可視化には{ggdag}のggdag()を使用します。\n\nDAG_data1 |&gt;\n  ggdag()\n\n\n\n\n\n\n\n\n　DAGにおいて背景、軸の目盛り、ラベルは不要ですので、theme_dag_blank()テーマを指定して全て除去します。\n\nDAG_data1 |&gt;\n  ggdag() +\n  theme_dag_blank()\n\n\n\n\n\n\n\n\n\n21.12.1 ノードの位置を指定する\n　読者の多くは以上のグラフと異なるものが得られたかも知れません。ノード間の関係は同じはずですが、ノードの位置が異なるでしょう。また、同じコードを実行する度にノードの位置は変わります。以下ではノードの位置を固定する方法について紹介します。位置を指定するにはdagify()内でcoords引数に各ノードの情報が格納されたリスト型オブジェクトを指定する必要があります。リストの長さは2であり、それぞれの名前はxとyです。そしてリストの各要素にはベクトルが入ります。たとえば、ノードXの位置を (1, 1)、Yの位置を (3, 1)、Zの位置を (2, 2)に指定してみましょう。dagify()内で直接リストを書くことも可能ですが、コードの可読性が落ちるため、別途のオブジェクト（DAG_Pos2）として格納しておきます。\n\nDAG_Pos2  &lt;- list(x = c(X = 1, Y = 3, Z = 2),\n                  y = c(X = 1, Y = 1, Z = 2))\n\n　続いて、dagify()内でcoords引数を追加し、ノードの位置情報が格納されているDAG_Pos2を指定します。\n\nDAG_data2 &lt;- dagify(X ~ Z,\n                    Y ~ X + Z,\n                    exposure = \"X\",\n                    outcome  = \"Y\",\n                    coords   = DAG_Pos2)\n\nDAG_data2\n\ndag {\nX [exposure,pos=\"1.000,1.000\"]\nY [outcome,pos=\"3.000,1.000\"]\nZ [pos=\"2.000,2.000\"]\nX -&gt; Y\nZ -&gt; X\nZ -&gt; Y\n}\n\n\n　可視化の方法は同じです。\n\nDAG_data2 |&gt;\n  ggdag() +\n  theme_dag_blank()\n\n\n\n\n\n\n\n\n　以上の使い方だけでも、ほとんどのDAGは描けるでしょう。また、ノードを若干オシャレ（?）にするには、ggdag()内でstylized = TRUEを指定します。\n\nDAG_Pos3  &lt;- list(x = c(X1 = 3, X2 = 3, X3 = 1, T = 2, Y = 4),\n                  y = c(X1 = 1, X2 = 2, X3 = 2, T = 3, Y = 3))\n\nDAG_data3 &lt;- dagify(Y  ~ T + X1 + X2,\n                    T  ~ X3,\n                    X2 ~ T +X1 + X3,\n                    exposure = \"T\",\n                    outcome  = \"Y\",\n                    coords   = DAG_Pos3)\n\nDAG_data3 |&gt;\n  ggdag(stylized = TRUE) +\n  theme_dag_blank()\n\n\n\n\n\n\n\n\n　可視化の話ではありませんが、adjustmentSets()関数を用いると、処置変数Tの総効果（total effect）を推定するためにはどの変数を統制（調整）する必要があるかを調べることも可能です。\n\nadjustmentSets(DAG_data3, effect = \"total\")\n\n{ X3 }\n\n\n　X3変数のみ統制すれば良いという結果が得られました。また、TからYへの直接効果（direct effect）の場合、effect = \"direct\"を指定します。\n\nadjustmentSets(DAG_data3, effect = \"direct\")\n\n{ X1, X2 }\n\n\n　X1とX2を統制する必要があることが分かりますね。"
  },
  {
    "objectID": "visualization4.html#sec-visual4-bump",
    "href": "visualization4.html#sec-visual4-bump",
    "title": "21  可視化 [発展]",
    "section": "21.13 バンプチャート",
    "text": "21.13 バンプチャート\n　バンプチャート (bump chart)は順位の変化などを示す時に有効なグラフです。たとえば、G7構成国の新型コロナ感染者数の順位の変化を示すにはどうすれば良いでしょうか。そもそもどのような形式のデータが必要でしょうか。まずは必要なデータ形式を紹介したいと思います。\n　まず、{ggplot2}によるバンプチャートの作成を支援する{ggbump}パッケージをインストールし、読み込みましょう3。\n\npacman::p_load(ggbump)\n\n　ここではG7構成国の100万人当り新型コロナ感染者数の順位がどのように変化したのかを2020年4月から7月まで1ヶ月単位で表したデータが必要です。データは以下のようなコードで作成しますが、本書のサポートページからもダウンロード可能です。\n\nBump_df &lt;- left_join(COVID19_df, Country_df, by = \"Country\") |&gt;\n  select(Country, Date, Population, Confirmed_Total, G7) |&gt;\n  separate(Date, into = c(\"Year\", \"Month\", \"Day\"), sep = \"/\") |&gt;\n  mutate(Month = as.numeric(Month)) |&gt;\n  filter(Month &gt;= 4, G7 == 1) |&gt;\n  group_by(Country, Month) |&gt;\n  summarise(Population            = mean(Population),\n            New_Cases             = sum(Confirmed_Total, na.rm = TRUE),\n            New_Cases_per_million = New_Cases / Population * 1000000,\n            .groups               = \"drop\") |&gt;\n  select(Country, Month, New_Cases_per_million)\n\n\nBump_df &lt;- Bump_df |&gt;\n  group_by(Month) |&gt;\n  mutate(Rank = rank(New_Cases_per_million, ties.method = \"random\")) |&gt;\n  ungroup() |&gt;\n  select(Country, Month, Rank, New_Cases_per_million)\n\n　必要なデータは以下のような形式です。ちなみにバンプチャートを作成するためには最後のNew_Cases_per_million列 (100万人当り新型コロナ感染者数)は不要です。つまり、国名、月、順位のみで十分です。\n\n# 以上のコードを省略し、加工済みのデータを読み込んでもOK\n# Bump_df &lt;- read_csv(\"Data/Bumpchart.csv\")\nBump_df\n\n　それでは{ggbump}が提供するgeom_bump()幾何オブジェクトを使用し、簡単なバンプチャートを作成してみましょう。必要なマッピング要素はxとy、colorです。xには時間を表す変数であるMonthを、yには順位を表すRankをマッピングします。また、7本の線が出るため、月と順位、それぞれの値がどの国の値かを特定する必要があります。groupsに国名であるCountryをマッピングしても線は引けますが、どの線がどの国かが分からなくなるため、colorにCountryをマッピングし、線の色分けをします。\n\nBump_df |&gt;\n  ggplot(aes(x = Month, y = Rank, color = Country)) +\n  geom_bump()\n\n\n\n\n\n\n\n\n　これで最低限のバンプチャートはできましたが、もう少し見やすく、可愛くしてみましょう。今は線が細いのでややぶ厚めにします。これはgeom_bump()レイヤーのsize引数で指定可能です。また、各月に点を付けることによって、同時期における順位の比較をよりしやすくしてみましょう。これは散布図と同じであるため、geom_point()幾何オブジェクトを使用します。\n\nBump_df |&gt;\n  ggplot(aes(x = Month, y = Rank, color = Country)) +\n  geom_point(size = 7) +\n  geom_bump(size = 2) +\n  theme_minimal(base_size = 14)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\n　これでだいぶ見やすくなりましたが、凡例における国名の順番がやや気になりますね。7月の時点において順位が最も高い国はアメリカ、最も低い国は日本ですが、凡例の順番はアルファベット順となっています。この凡例の順番を7月時点におけるRankの値に合わせた方がより見やすいでしょう。ここで第15.2.9章で紹介しましたfct_reorder2()を使ってCountry変数の水準 (level)を7月時点におけるRankの順位に合わせます。この場合、Country変数 (.f = Country)の水準をMonthが (.x = Month)最も大きい (.fun = last2)時点におけるRankの順番に合わせる (.y = Rank)こととなります。fct_reorder2()内の引数の順番の既定値は.f、.x、.y、.funとなります。\n\nBump_df |&gt;\n  mutate(Country = fct_reorder2(Country, Month, Rank, last2)) |&gt;\n  ggplot(aes(x = Month, y = Rank, color = Country)) +\n  geom_point(size = 7) +\n  geom_bump(size = 2) +\n  theme_minimal(base_size = 14)\n\n\n\n\n\n\n\n\n　最後に縦軸の目盛りラベルを付けます。上に行くほど順位が高くなりますので、1を7に、2を6に、…、7を1に変更します。また、図内のグリッドも不要ですので、theme()を使用し、グリッドを削除します (panel.grid = element_blank())。\n\nBump_df |&gt;\n  mutate(Country = fct_reorder2(Country, Month, Rank, last2)) |&gt;\n  ggplot(aes(x = Month, y = Rank, color = Country)) +\n  geom_point(size = 7) +\n  geom_bump(size = 2) +\n  scale_y_continuous(breaks = 1:7, labels = 7:1) +\n  theme_minimal(base_size = 14) +\n  theme(panel.grid = element_blank())\n\n\n\n\n\n\n\n\n　これでバンプチャートの完成です。このままでの良いかも知れませんが、もう少し手間を掛けることでより読みやすいグラフが作れます。たとえば、今のままだと「日本のトレンド」を確認したい場合、まず凡例から日本の色を確認し、その色に該当する点と線を見つけてトレンドを見る必要がありますね。もし、ここで図の左端と右端の点の横に国名を出力すると、凡例がなくても良いですし、4月の時点から日本のトレンドを確認することも、7月の時点から遡る形で日本のトレンドを確認することも可能かも知れません。\n　図に文字列を追加するためにはgeom_text()幾何オブジェクトを使用します。マッピング要素は文字列の横軸上の位置 (x)、縦軸上の位置 (y)、そして出力する文字列 (label)です。左端に文字列を出力するのであれば、横軸上の位置は4 (= 4月)よりも若干左側が良いでしょう。ぴったり4になると、点と文字列が重なって読みにくくなりますね。縦軸上の位置は4月の時点での順位 (Rank)で、出力する文字列は国名 (Country)です。現在、使用しているデータは4月から7月までのデータですが、4月に限定したデータを使いたいので、geom_text()内にdata引数を追加し、Bump_dfからMonthの値が4の行のみを抽出したデータを割り当てます (data = filter(Bump_df, Month == 4)、またはdata = Bump_df |&gt; filter(Month == 4))。右端についても同じです。横軸上の位置は7から右方向へずらし、使用するデータは7月のデータとなります。\n　最後にもう一点調整が必要ですが、それは座標系です。図の座標系はggplot()関数で使用するデータに基づきます。Bump_dfの場合、横軸 (Month)は4から7です。しかし、文字列を追加した場合、文字列がすべて出力されないかも知れません。したがって、座標系を横方向に広める必要があります。今回は3から8までに調整します。座標系や文字列の位置調整は出力結果を見ながら、少しずつ調整していきましょう。\n\nBump_df |&gt;\n  ggplot(aes(x = Month, y = Rank, color = Country)) +\n  geom_point(size = 7) +\n  geom_bump(size = 2) +\n  # 4月の時点での行のみ抽出し、xはMonthより0.15分左方向、\n  # yはRankの値の位置に国名を出力する。揃える方向は右揃え (hjust = 1)\n  geom_text(data = filter(Bump_df, Month == 4),\n            aes(x = Month - 0.15, y = Rank, label = Country), hjust = 1) +\n  # 7月の時点での行のみ抽出し、xはMonthより0.15分右方向、\n  # yはRankの値の位置に国名を出力する。揃える方向は左揃え (hjust = 0)\n  geom_text(data = filter(Bump_df, Month == 7),\n            aes(x = Month + 0.15, y = Rank, label = Country), hjust = 0) +\n  # 座標系の調整\n  coord_cartesian(xlim = c(3, 8)) +\n  scale_x_continuous(breaks = 4:7, labels = 4:7) +\n  scale_y_continuous(breaks = 1:7, labels = 7:1) +\n  labs(y = \"Rank\", x = \"Month\") +\n  theme_minimal(base_size = 14) +\n  theme(legend.position = \"none\",\n        panel.grid      = element_blank())"
  },
  {
    "objectID": "visualization4.html#sec-visual4-alluvial",
    "href": "visualization4.html#sec-visual4-alluvial",
    "title": "21  可視化 [発展]",
    "section": "21.14 沖積図",
    "text": "21.14 沖積図\n　沖積図 (alluvial plot)は同じ対象を複数回観察したデータ（パネル・データなど）から変化を示すことに適したグラフです。たとえば、同じ回答者を対象に2回世論調査を実施し、1回目調査時の支持政党と2回目調査時の支持政党を変化を見ることも可能です。もし、変化が大きい場合は政党支持態度は弱いこととなりますし、変化が小さい場合は安定していると解釈できるでしょう。\n　ここでは2020年の選挙と2021年の選挙における有権者の投票先の変化を沖積図で確認してみたいと思います。まずは、沖積図の作成に特化した{ggalluvial}パッケージをインストールし、読み込みます。\n\npacman::p_load(ggalluvial)\n\n　続きまして、実習用データを読み込みます。データは架空のデータです。\n\nVote_2021 &lt;- read_csv(\"Data/Vote_20_21.csv\")\n\nhead(Vote_2021, 20)\n\n# A tibble: 20 × 3\n      ID Vote20 Vote21\n   &lt;dbl&gt; &lt;chr&gt;  &lt;chr&gt; \n 1     1 棄権   棄権  \n 2     2 政党A  政党A \n 3     3 政党A  政党A \n 4     4 政党B  政党A \n 5     5 政党B  政党C \n 6     6 政党A  政党C \n 7     7 その他 その他\n 8     8 政党B  政党B \n 9     9 政党A  政党A \n10    10 政党C  政党C \n11    11 棄権   政党B \n12    12 政党B  政党A \n13    13 棄権   棄権  \n14    14 政党B  政党B \n15    15 政党C  政党C \n16    16 DK     政党C \n17    17 政党B  DK    \n18    18 政党A  政党A \n19    19 政党A  政党A \n20    20 政党A  政党A \n\n\n\n\n\n変数名\n説明\n\n\n\n\nID\n回答者ID\n\n\nVote20\n2020年選挙における当該回答者の投票先\n\n\nVote21\n2021年選挙における当該回答者の投票先\n\n\n\n　たとえば、1番目の回答者は2020年に棄権し、2021年も棄権したことを意味する。また、5番目の回答者は2020年に政党Bに投票し、2021年は政党Cに投票したことを意味する。続いて、このデータを{ggalluvial}に適した形式のデータに加工します。具体的には「2020年棄権、かつ2021年棄権」、「2020年棄権、かつ2021年政党Aへ投票」、…、「2020年政党Bへ投票、かつ2021年政党Aへ投票」のように全ての組み合わせに対し、該当するケース数を計算する必要があります。今回のデータだと、投票先はいずれも政党A、政党B、政党C、政党D、その他、棄権、DK (わからない)の7であるため、49パターンができます。それぞれのパターンに該当するケース数を計算するためにはVote20とVote21でデータをグループ化し、ケース数を計算します。\n\nVote_2021 &lt;- Vote_2021 |&gt;\n  group_by(Vote20, Vote21) |&gt;\n  summarise(Freq    = n(),\n            .groups = \"drop\")\n\nVote_2021\n\n# A tibble: 47 × 3\n   Vote20 Vote21  Freq\n   &lt;chr&gt;  &lt;chr&gt;  &lt;int&gt;\n 1 DK     DK       111\n 2 DK     その他     8\n 3 DK     政党A    116\n 4 DK     政党B     29\n 5 DK     政党C     15\n 6 DK     政党D      7\n 7 DK     棄権      57\n 8 その他 DK        18\n 9 その他 その他    73\n10 その他 政党A    121\n# ℹ 37 more rows\n\n\n　2020年の調査で「わからない」と回答し、2021年の調査でも「わからない」と回答した回答者数は111名、2020年の調査で「わからない」と回答し、2021年の調査では「その他」と回答した回答者数は8名、…といったことが分かりますね。\n　続いて、グラフを作成する前に投票先変数 (Vote20とVote21)をfactor化します。可視化の際、投票先が出力される順番に決まりはありませんが、政党A、政党B、政党C、…、DKの順が自然かと思います。むろん、こちらは自分から見て分かりやいように順番を決めましょう。ただし、2変数における水準 (level)の順番は一致させた方が良いでしょう。\n\nVote_2021 &lt;- Vote_2021 |&gt;\n  mutate(Vote20 = factor(Vote20, levels = c(\"政党A\", \"政党B\", \"政党C\", \"政党D\", \n                                            \"その他\", \"棄権\", \"DK\")),\n         Vote21 = factor(Vote21, levels = c(\"政党A\", \"政党B\", \"政党C\", \"政党D\", \n                                            \"その他\", \"棄権\", \"DK\")))\n\n　それでは沖積図を描いてみましょう。使用する幾何オブジェクトはgeom_alluvium()とgeom_stratum()です。必ずこの順番でレイヤーを重ねてください。マッピングはy、axis1、axis2に対し、yには当該パターン内のケース数 (Freq)、axis1は2009年の投票先 (Vote20)、axis2は2010年の投票先 (Vote21)を指定します4。これらのマッピングはgeom_stratum()とgeom_alluvim()共通であるため、ggplot()内でマッピングした方が効率的です。\n\nVote_2021 |&gt;\n    ggplot(aes(y = Freq, axis1 = Vote20, axis2 = Vote21)) +\n    geom_alluvium() +\n    geom_stratum()\n\n\n\n\n\n\n\n\n　何かの図は出てきましたが、これだけだと、それぞれの四角形がどの政党を示しているのかが分かりませんね。四角形内に政党名を出力するためには{ggplot2}内蔵のgeom_text()を使用します。マッピング要素はggplot()内でマッピングしたものに加え、labelが必要ですが、ここではafter_stat(stratum)を指定します。そして、aes()のその側にstat = \"stratum\"を指定するだけです。もし、文字化けが生じる場合は、geom_text()内にフォントの指定が必要があり、familyを使います (たとえば、family = \"HiraginoSans-W3\"など)。theme_*()内でbase_familyを指定した場合でも必要です。\n\nVote_2021 |&gt;\n    ggplot(aes(y = Freq, axis1 = Vote20, axis2 = Vote21)) +\n    geom_alluvium() +\n    geom_stratum() +\n    geom_text(aes(label = after_stat(stratum)), \n              stat = \"stratum\")\n\n\n\n\n\n\n\n\n　これで沖積図はとりあえず完成ですが、少し読みやすく加工してみましょう。たとえば、2020年に政党Aに投票した回答者における2021年の投票先の割合を見たいとした場合、geom_alluvium()内にfill = Vote20をマッピングします。これで帯に2020年の投票先ごとの色付けができます。\n\nVote_2021 |&gt;\n    ggplot(aes(y = Freq, axis1 = Vote20, axis2 = Vote21)) +\n    geom_alluvium(aes(fill = Vote20)) +\n    geom_stratum() +\n    geom_text(aes(label = after_stat(stratum)), \n              stat = \"stratum\")\n\n\n\n\n\n\n\n\n　fill = Vote21とマッピングした場合は、感覚が変わります。実際にやってみましょう。\n\nAlluvial_Plot &lt;- Vote_2021 |&gt;\n    ggplot(aes(y = Freq, axis1 = Vote20, axis2 = Vote21)) +\n    geom_alluvium(aes(fill = Vote21)) +\n    geom_stratum() +\n    geom_text(aes(label = after_stat(stratum)), \n              stat = \"stratum\", family = \"HiraginoSans-W3\")\n\nAlluvial_Plot\n\n\n\n\n\n\n\n\n　この場合、2020年に政党Aに投票した人が2021年にどこに流れたかが分かりやすくなります。Vote20に色分けするか、Vote21に色分けするかは作成する人が決める問題であり、自分の主張・メッセージに適したマッピングをしましょう。\n　最後に、図をもう少し加工してみましょう。まず、横軸に0.8、1.2、1.6、2.0となっている目盛りを修正し、1と2の箇所に「2020年選挙」と「2021年選挙」を出力します。これはscale_x_continuous()で調整可能です。そして、theme_minimal()で余計なものを排除したテーマを適用します。最後にtheme()内で全ての凡例を削除 (legend.position = \"none\")し、パネルのグリッド (panel.grid)と縦軸・横軸のタイトル (axis.title)、縦軸の目盛りラベル (axis.text.y)を削除 (element_blank())します。\n\nAlluvial_Plot +\n    scale_x_continuous(breaks = 1:2, \n                       labels = c(\"2020年選挙\", \"2021年選挙\")) +\n    theme_minimal(base_size = 16) +\n    theme(legend.position = \"none\",\n          panel.grid = element_blank(),\n          axis.title = element_blank(),\n          axis.text.y = element_blank())\n\n\n\n\n\n\n\n\n　これでだいぶスッキリした沖積図が出来上がりました。"
  },
  {
    "objectID": "visualization4.html#sec-visual4-tree",
    "href": "visualization4.html#sec-visual4-tree",
    "title": "21  可視化 [発展]",
    "section": "21.15 ツリーマップ",
    "text": "21.15 ツリーマップ\n　ツリーマップ（tree map）は変数の値の大きさを長方形の面積として表すグラフです。全体におけるシェアを示す時に使う点で、円グラフの代替案の一つになります。円グラフは項目が多すぎると読みにくいデメリットがありますが、ツリーマップは項目が多い場合でも有効です。むろん、多すぎると読みにくいことは同じですので、注意が必要です。\n　ツリーマップを作成するためには{treemapify}パッケージのgeom_treemap()幾何オブジェクトを使用します。まず、{treemapify}をインストールし、読み込みます。\n\npacman::p_load(treemapify)\n\n　ここではCountry_dfからアジア諸国の人口（Population）をツリーマップをして可視化したいと思います。geom_treemap()の場合、各長方形は面積の情報のみを持ちます。この面積の情報をareaにマッピングします。\n\nCountry_df |&gt;\n  filter(Continent == \"Asia\") |&gt;\n  ggplot() +\n  geom_treemap(aes(area = Population))\n\n\n\n\n\n\n\n\n　これだけだと各長方形がどの国を指しているのかが分かりませんね。長方形の上に国名（Country）を追加するためにはgeom_treemap_text()幾何オブジェクトを使用します。マッピングはareaとlabelに対し、それぞれ面積を表すPopulationと国名を表すCountryを指定します。areaはgeom_treemap()とgeom_treemap_text()両方で使われるのでggplot()の内部でマッピングしても問題ありません5。また、aes()の外側にcolor = \"white\"で文字を白に指定し、place = \"center\"で長方形の真ん中にラベルが付くようにします。\n\nCountry_df |&gt;\n  filter(Continent == \"Asia\") |&gt;\n  ggplot(aes(area = Population)) +\n  geom_treemap() +\n  geom_treemap_text(aes(label = Country), color = \"white\", place = \"center\")\n\n\n\n\n\n\n\n\n　これでツリーマップが完成しました。インドと中国の存在感がかなり大きいですね。更にラベルのサイズを長方形に合わせると、その存在感をより高めることができます。ラベルの大きさを長方形に合わせるにはgeom_treepmap_text()の内部にgrow = TRUEを指定します。\n\nCountry_df |&gt;\n  filter(Continent == \"Asia\") |&gt;\n  ggplot(aes(area = Population, label = Country)) +\n  geom_treemap() +\n  geom_treemap_text(color = \"white\", place = \"center\",\n                    grow = TRUE)\n\n\n\n\n\n\n\n\n　ここで更に次元を追加するために、色塗りをしてみましょう。たとえば、G20加盟国か否かで色分けをしたい場合、fillにG20をマッピングします。ただし、今のままだとG20は連続変数扱いになりますので、character型、またはfactor型に変換します。\n\nCountry_df |&gt;\n  mutate(G20 = if_else(G20 == 1, \"Member\", \"Non-member\")) |&gt;\n  filter(Continent == \"Asia\") |&gt;\n  ggplot(aes(area = Population, fill = G20,\n             label = Country)) +\n  geom_treemap() +\n  geom_treemap_text(color = \"white\", place = \"centre\",\n                    grow = TRUE) +\n  labs(fill = \"G20\") +\n  ggtitle(\"Population in Asia\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　色塗りは連続変数に対して行うことも可能です。ここでは2018年人間開発指数（HDI_2108）の値に応じて色塗りをしてみます。また、HDI_2018が低い（low）とbrown3、高い（high）とcornflowerblue色にします。真ん中の値（midpoint）は0.7とし、色（mid）はcornsilkを使います。\n　連続変数でマッピングされた色塗り（fill）の調整にはscale_fill_gradient()、またはscale_fill_gradient2()を使います。前者は中間点なし、後者は中間点ありです。これらの使い方は第20章で紹介しましたscale_color_gradient()と同じです。\n\nCountry_df |&gt;\n  filter(Continent == \"Asia\") |&gt;\n  ggplot(aes(area = Population, fill = HDI_2018,\n             label = Country)) +\n  geom_treemap() +\n  geom_treemap_text(color = \"white\", place = \"centre\",\n                    grow = TRUE) +\n  scale_fill_gradient2(low = \"brown3\",\n                       mid = \"cornsilk\",\n                       high = \"cornflowerblue\",\n                       midpoint = 0.7) +\n  labs(fill = \"UN Human Development Index (2018)\") +\n  ggtitle(\"Population in Asia\") +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\n　ちなみに以上の図を円グラフにすると以下のようになります（国名は人口の割合が2.5%を超える国のみ表示）。ツリーマップと比較してかなり読みにくいことが分かります。\n\nCountry_df |&gt;\n  filter(Continent == \"Asia\") |&gt;\n  arrange(Population) |&gt;\n  mutate(Prop        = Population / sum(Population) * 100,\n         LabelY      = 100 - (cumsum(Prop) - 0.5 * Prop),\n         CountryName = if_else(Prop &lt; 2.5, \"\", Country),\n         Country     = fct_inorder(Country)) |&gt;\n  ggplot() +\n  geom_bar(aes(x = 1, y = Prop, group = Country, fill = HDI_2018), \n           color = \"black\", stat = \"identity\", width = 1) +\n  geom_text(aes(x = 1, y = LabelY, label = CountryName)) +\n  coord_polar(\"y\", start = 0) +\n  scale_fill_gradient2(low = \"brown3\",\n                       mid = \"cornsilk\",\n                       high = \"cornflowerblue\",\n                       midpoint = 0.7) +\n  labs(fill = \"UN Human Development Index (2018)\") +\n  ggtitle(\"Population in Asia\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\",\n        panel.grid = element_blank(),\n        axis.title = element_blank(),\n        axis.text  = element_blank())\n\n\n\n\n\n\n\n\n　ただし、ツリーマップが必ずしも円グラフより優れているとは言えません。たとえば、 Heer と Bostock (2010) の研究では円グラフとツリーマップを含む9種類のグラフを用い、被験者に大小関係を判断してもらう実験を行いましたが、ツリーマップ（四角形の面積）は円グラフ（角度）よりも判断までの所要時間が長いことが述べています。"
  },
  {
    "objectID": "visualization4.html#sec-visual4-mosaic",
    "href": "visualization4.html#sec-visual4-mosaic",
    "title": "21  可視化 [発展]",
    "section": "21.16 モザイクプロット",
    "text": "21.16 モザイクプロット\nモザイクプロットは2つの離散変数（おもに名目変数）の関係を可視化するために Hartigan と Kleiner (1984) が考案した図です。2つの名目変数間の関係を見る際によく使われるものはクロス表（クロス集計表）でしょう。\n\npacman::p_load(ggmosaic)\n\n\nMosaic_df &lt;- Country_df |&gt;\n    select(Country, Continent, Polity = Polity_Type, PPP = PPP_per_capita) |&gt;\n    mutate(Continent = factor(Continent, \n                              levels = c(\"Africa\", \"America\", \"Asia\",\n                                         \"Europe\", \"Oceania\")),\n           Polity    = factor(Polity,\n                              levels = c(\"Autocracy\", \"Closed Anocracy\",\n                                         \"Open Anocracy\", \"Democracy\",\n                                         \"Full Democracy\")),\n           PPP       = if_else(PPP &gt;= 15000, \"High PPP\", \"Low PPP\"),\n           PPP       = factor(PPP, levels = c(\"Low PPP\", \"High PPP\"))) |&gt;\n    drop_na()\n\n\nhead(Mosaic_df)\n\n# A tibble: 6 × 4\n  Country     Continent Polity          PPP     \n  &lt;chr&gt;       &lt;fct&gt;     &lt;fct&gt;           &lt;fct&gt;   \n1 Afghanistan Asia      Closed Anocracy Low PPP \n2 Albania     Europe    Democracy       Low PPP \n3 Algeria     Africa    Open Anocracy   Low PPP \n4 Angola      Africa    Closed Anocracy Low PPP \n5 Argentina   America   Democracy       High PPP\n6 Armenia     Europe    Democracy       Low PPP \n\n\n　クロス表を作成する内蔵関数としてはtable()があります。2つの変数が必要となり、第一引数が行、第二引数が列を表します。\n\nMosaic_Tab &lt;- table(Mosaic_df$Continent, Mosaic_df$Polity)\nMosaic_Tab\n\n         \n          Autocracy Closed Anocracy Open Anocracy Democracy Full Democracy\n  Africa          3              14            11        18              1\n  America         0               1             4        16              5\n  Asia           13               6             0        15              3\n  Europe          2               1             2        16             20\n  Oceania         0               0             2         0              2\n\n\n　このMosaic_Tabのクラスは\"table\"ですが、\"table\"クラスのオブジェクトをplot()に渡すと別途のパッケージを使わずモザイクプロットを作成することができます。\n\nplot(Mosaic_Tab)\n\n\n\n\n\n\n\n\n　やや地味ではありますが、モザイクプロットが出来ました。ここからはより読みやすいモザイクプロットを作成するために{ggmosaic}パッケージのgeom_mosaic()関数を使います。\n　geom_mosaic()の場合、xのみのマッピングで十分です。ただし、特定の変数を指定するのではなく、product(変数1, 変数2)をxにマッピングする必要があります。table()関数同様、変数1は行、変数2は列です。また、欠損値が含まれている行がある場合は、aes()の外側にna.rm = TRUEを指定する必要があります。今回はdrop_na()で欠損値をすべて除外しましたが、念の為に指定しておきます。\n\nMosaic_df |&gt;\n    ggplot() +\n    geom_mosaic(aes(x = product(Polity, Continent)), na.rm = TRUE) +\n    labs(x = \"Continent\", y = \"Polity Type\") +\n    theme_minimal() +\n    theme(panel.grid = element_blank())\n\nWarning: `unite_()` was deprecated in tidyr 1.2.0.\nℹ Please use `unite()` instead.\nℹ The deprecated feature was likely used in the ggmosaic package.\n  Please report the issue at &lt;\u001b]8;;https://github.com/haleyjeppson/ggmosaic\u0007https://github.com/haleyjeppson/ggmosaic\u001b]8;;\u0007&gt;.\n\n\n\n\n\n\n\n\n\n　これで出来上がりですが、\"table\"オブジェクトをplot()に渡した結果とあまり変わらないですね。続いて、この図を少し改良してみましょう。まずはセルの色分けですが、これはfillに色分けする変数をマッピングするだけです。今回は政治体制ごとにセルを色分けしましょう。また、文字を大きめにし、横軸の目盛りラベルを回転します。\n\nMosaic_df |&gt;\n    ggplot() +\n    geom_mosaic(aes(x = product(Polity, Continent), fill = Polity), \n                na.rm = TRUE) +\n    labs(x = \"Continent\", y = \"Polity Type\") +\n    theme_minimal(base_size = 16) +\n    theme(legend.position = \"none\",\n          panel.grid      = element_blank(),\n          axis.text.x     = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n\n\n　次元を追加するためにはファセット分割を使います。たとえば、一人当たりPPP GDPの高低（PPP）でファセットを分割する場合、facet_wrap(~PPP)レイヤーを足すだけです。\n\nMosaic_df |&gt;\n    ggplot() +\n    geom_mosaic(aes(x = product(Polity, Continent), fill = Polity), \n                na.rm = TRUE) +\n    labs(x = \"Continent\", y = \"Polity Type\") +\n    facet_wrap(~PPP, ncol = 2) +\n    theme_minimal(base_size = 16) +\n    theme(legend.position = \"none\",\n          panel.grid      = element_blank(),\n          axis.text.x     = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n\n\n　ただし、一つ問題があります。それは目盛りラベルの位置です。例えば、右側の横軸目盛りラベルの場合、セルの位置とラベルの位置がずれています。これは2つのファセットが同じ目盛りを共有し、左側の方に合わせられたため生じるものです。よく見ると横軸も縦軸も目盛りラベルに位置が同じであることが分かります。これを解消するためには、facet_wrap()の内部にscale = \"free\"を指定します6。これは各ファセットが独自のスケールを有することを意味します。\n\nMosaic_df |&gt;\n    ggplot() +\n    geom_mosaic(aes(x = product(Polity, Continent), fill = Polity), \n                na.rm = TRUE) +\n    labs(x = \"Continent\", y = \"Polity Type\") +\n    facet_wrap(~PPP, ncol = 2, scale = \"free\") +\n    theme_minimal(base_size = 16) +\n    theme(legend.position = \"none\",\n          panel.grid      = element_blank(),\n          axis.text.x     = element_text(angle = 90, vjust = 0.5, hjust = 1))\n\n\n\n\n\n\n\n\n　右側ファセットの横軸ラベルが重なってしまいましたが、これでとりあえず完成です。アフリカにおけるOpen AnocracyとClosed Anocracyの頻度が0であるため、これは仕方ありません。一つの対処方法としては以下のように縦軸目盛りを削除し、凡例で代替することが考えられます。\n\nMosaic_df |&gt;\n    ggplot() +\n    geom_mosaic(aes(x = product(Polity, Continent), fill = Polity), \n                na.rm = TRUE) +\n    labs(x = \"Continent\", y = \"Polity Type\", fill = \"Polity Type\") +\n    facet_wrap(~PPP, ncol = 2, scale = \"free_x\") +\n    theme_minimal(base_size = 16) +\n    theme(panel.grid  = element_blank(),\n          axis.text.y = element_blank(),\n          axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))"
  },
  {
    "objectID": "visualization4.html#sec-visual4-further",
    "href": "visualization4.html#sec-visual4-further",
    "title": "21  可視化 [発展]",
    "section": "21.17 その他のグラフ",
    "text": "21.17 その他のグラフ\nThe R Graph Galleryでは本書で紹介できなかった様々な図のサンプルおよびコードを見ることができます。ここまで読み終わった方なら問題なくコードの意味が理解できるでしょう。{ggplot2}では作成できないグラフ（アニメーションや3次元図、インタラクティブなグラフ）についても、他のパッケージを利用した作成方法について紹介されているので、「こんな図が作りたいけど、作り方が分からん！」の時には、まずThe R Graph Galleryに目を通してみましょう。\n\n\n\n\nHartigan, J. A., と Beat Kleiner. 1984. 「A Mosaic of Television Ratings」. The American Statistician 38: 32–35.\n\n\nHeer, Jeffrey, と Michael Bostock. 2010. 「Crowdsourcing Graphical Perception: Using Mechanical Turk to Assess Visualization Design」. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems."
  },
  {
    "objectID": "table.html#sec-gt-intro",
    "href": "table.html#sec-gt-intro",
    "title": "22  表の作成",
    "section": "22.1 表の出力",
    "text": "22.1 表の出力\n　{gt}では、表がタイトル、列ラベル、ホディ―などの要素で構成されている考え（ 図 22.1 ）、それぞれの要素を追加したり、修正する形で表を作成する。\n\n\n\n図 22.1: {gt}テーブルの構成要素\n\n\n　まず、これまで使ってきたdf1を使ってHTML形式の表を出力してみよう。使用する関数はgt()であり、data.frameまたはtibbleオブジェクト名が第1引数である。\n\ndf1 |&gt;\n    gt()\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n  \n  \n    Population\n41.7377735\n151.2702976\n0.000801000\n1447.47009\n186\n    Area\n69.6069247\n187.2412489\n0.000000000\n1637.68700\n186\n    GDP_per_capita\n1.6158103\n2.5710359\n0.005770007\n18.31772\n185\n    PPP_per_capita\n2.0833383\n2.0992134\n0.073314173\n11.34231\n178\n    HDI_2018\n0.7134833\n0.1528503\n0.377000000\n0.95400\n180\n    Polity_Score\n4.2594937\n6.1022919\n-10.000000000\n10.00000\n158\n    FH_Total\n57.7135135\n29.8656244\n0.000000000\n100.00000\n185"
  },
  {
    "objectID": "table.html#sec-gt-columns",
    "href": "table.html#sec-gt-columns",
    "title": "22  表の作成",
    "section": "22.2 列の操作",
    "text": "22.2 列の操作\n　これだけでも十分に綺麗な表が出来上がった。それではこちらの表を少しずつ修正してみよう。まず、Mean列からMax列だが、これを小数点3桁で丸めてみよう。これらの数字は 図 22.1 のTable Bodyに該当する。このTable Bodyのフォーマットに関わる調整はfmt_*()関数を使用する。Mean列からMax列までの数値に関する調整はfmt_number()関数を使用する。gt()で作成された表オブジェクトをそのままfmt_number()に渡し、columns引数で何列に当該内容を適用するかを指定する。たとえば、Mean列からMax列までは2〜5列目に相当するのでcolumns = 2:5、またはcolumns = c(2, 3, 4, 5)で良い。続いて、小数点の桁数を指定するdecimalsに3を指定してみよう。\n\ndf1 |&gt;\n    gt() |&gt;\n    fmt_number(columns = 2:5, decimals = 3)\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n  \n\n\n\n\n　columnsは列の番号じゃなく、列名そのままでも指定できる。\n\ndf1 |&gt;\n    gt() |&gt;\n    fmt_number(columns = c(\"Mean\", \"SD\", \"Min\", \"Max\"), decimals = 3)\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n  \n\n\n\n\n　列名の変更はcols_lable()レイヤーで行う。()内には\"元の列名\" = \"新しい列名\"のように記述する。kbl()は全ての列に対して列名を指定しないといけなかったが（つまり、変更したくない列も一応、指定が必要）、{gt}だと変更したい列のみ指定しても良いといったメリットがある。\n\ndf1 |&gt;\n    gt() |&gt;\n    fmt_number(columns = 2:5, decimals = 3) |&gt;\n    cols_label(\"Variable\" = \"変数\", \"Mean\" = \"平均値\", \"SD\" = \"標準偏差\",\n               \"Min\" = \"最小値\", \"Max\" = \"最大値\", \"Obs\" = \"有効ケース数\")\n\n\n\n\n  \n    \n    \n      変数\n      平均値\n      標準偏差\n      最小値\n      最大値\n      有効ケース数\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n  \n\n\n\n\n　もう一つ見たいこところは、各セル内のテキストの揃えだ。たとえば、文字型列のVariableは左揃え、数値型列であるその他の列は右揃えになっている。これはこのままで問題ない。しかし、どうしても特定の列を中央揃えしたい時もあるだろう。その場合、cols_align()レイヤーで修正することができる。たとえば、Variable列の値を中央揃えに変えてみよう。引数はalignで\"left\"、\"center\"、\"right\"のいずれかを、columnsには適用したい列の番号、または列名を指定する。\n\ndf1 |&gt;\n  gt() |&gt;\n  fmt_number(columns = 2:5, decimals = 3) |&gt;\n  cols_align(align = \"center\", columns = 1) # columns = Variable でもOK\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n  \n\n\n\n\n　また、各列のラベル（図 22.1 のcolumn labels）の位置も表のボディー（図 22.1 のtable body）に連動する。もし、列ラベルのみ中央揃えにしたい場合はtab_style()レイヤーを使用する。\n\ndf1 |&gt;\n  gt() |&gt;\n  fmt_number(columns = 2:5, decimals = 3) |&gt;\n1  tab_style(style     = cell_text(align = \"center\"),\n2            locations = cells_column_labels())\n\n\n1\n\nセル内のテキストを中央揃えにする。\n\n2\n\n列ラベルのみに適用\n\n\n\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n  \n\n\n\n\n　また、HTMLのCSSによって異なるが、{gt}で作成された表の幅がページの幅に強制的に調整される場合がある。本書はQuartoで執筆されているが、まさにそのケースである）。この場合は、as_raw_html()を使えば良い。一つ注意すべき点はas_raw_html()は必ず最後のレイヤーにする必要がある。as_raw_html()の後ろにレイヤーが足される場合はエラーが発生する。\n\ndf1 |&gt;\n    gt() |&gt;\n    fmt_number(columns = 2:5, decimals = 3) |&gt;\n    as_raw_html()\n\n　このas_raw_html()は必要に応じて入れる。R Markdown/Quartoを使わない場合はそもそも不要だ（RStudioのViewerペインでは問題なく表示される）。もし、R Markdown/Quartoで{gt}を使用し、表の幅が気に入らない場合のみ使うことにしよう。ちなみに本書はas_raw_html()を省略しても表の幅がページ幅に強制調整されないように設定されている。"
  },
  {
    "objectID": "table.html#sec-gt-title",
    "href": "table.html#sec-gt-title",
    "title": "22  表の作成",
    "section": "22.3 タイトル・フットノート",
    "text": "22.3 タイトル・フットノート\n　表のタイトルおよびサブタイトルはtab_header()関数のtitleとsubtitle引数で指定できる。また、表の下段に位置するフットノート（footnote）とソースノート（source note）は別の関数に対応し、それぞれtab_footnote()とtab_source_note()を使う。使用する引数はそれぞれfootnoteとsource_noteであるが、第1引数であるため、省略可能だ。\n\ndf1 |&gt;\n  gt() |&gt;\n  fmt_number(columns = 2:5, decimals = 3) |&gt;\n  tab_header(title = \"タイトル\", subtitle = \"サブタイトル\") |&gt;\n  tab_footnote(footnote = \"注: ここにはフットノートが入る\") |&gt;\n  tab_source_note(source_note = \"出典: 『私たちのR』\")\n\n\n\n\n  \n    \n      タイトル\n    \n    \n      サブタイトル\n    \n    \n      Variable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n    \n      出典: 『私たちのR』\n    \n  \n  \n    \n       注: ここにはフットノートが入る\n    \n  \n\n\n\n\n　ちなみに、tab_footnote()やtab_source_note()は複数回使用することで複数行にすることができる。\n\ndf1 |&gt;\n  gt() |&gt;\n  fmt_number(columns = 2:5, decimals = 3) |&gt;\n  tab_header(title = \"タイトル\", subtitle = \"サブタイトル\") |&gt;\n  tab_footnote(footnote = \"注1: ここにはフットノート1が入る\") |&gt;\n  tab_footnote(footnote = \"注2: ここにはフットノート2が入る\") |&gt;\n  tab_source_note(source_note = \"出典: 『私たちのR』\")\n\n\n\n\n  \n    \n      タイトル\n    \n    \n      サブタイトル\n    \n    \n      Variable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n    \n      出典: 『私たちのR』\n    \n  \n  \n    \n       注1: ここにはフットノート1が入る\n    \n    \n       注2: ここにはフットノート2が入る\n    \n  \n\n\n\n\n　また、タイトルやフットノートに限定された機能ではないが、テキストはMarkdownやHTML文法で書くこともできる。たとえば、上記のコードの『私たちのR』にリンクを貼る場合、Markdown文法だと\"『[私たちのR](https://www.jaysong.net/RBook/)』\"となるが、このままではうまくいかない。\n\ndf1 |&gt;\n  gt() |&gt;\n  fmt_number(columns = 2:5, decimals = 3) |&gt;\n  tab_header(title = \"タイトル\", subtitle = \"サブタイトル\") |&gt;\n  tab_footnote(footnote = \"注1: ここにはフットノート1が入る\") |&gt;\n  tab_footnote(footnote = \"注2: ここにはフットノート2が入る\") |&gt;\n  tab_source_note(source_note = \"出典: 『[私たちのR](https://www.jaysong.net/RBook/)』\")\n\n\n\n\n  \n    \n      タイトル\n    \n    \n      サブタイトル\n    \n    \n      Variable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n    \n      出典: 『[私たちのR](https://www.jaysong.net/RBook/)』\n    \n  \n  \n    \n       注1: ここにはフットノート1が入る\n    \n    \n       注2: ここにはフットノート2が入る\n    \n  \n\n\n\n\n　Markdown文法を使う場合は、文字列をmd()関数内で指定することでMarkdown文として解釈されるようになる。\n\ndf1 |&gt;\n  gt() |&gt;\n  fmt_number(columns = 2:5, decimals = 3) |&gt;\n  tab_header(title = \"タイトル\", subtitle = \"サブタイトル\") |&gt;\n  tab_footnote(footnote = \"注1: ここにはフットノート1が入る\") |&gt;\n  tab_footnote(footnote = \"注2: ここにはフットノート2が入る\") |&gt;\n  tab_source_note(source_note = md(\"出典: 『[私たちのR](https://www.jaysong.net/RBook/)』\"))\n\n\n\n\n  \n    \n      タイトル\n    \n    \n      サブタイトル\n    \n    \n      Variable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n    \n      出典: 『私たちのR』\n    \n  \n  \n    \n       注1: ここにはフットノート1が入る\n    \n    \n       注2: ここにはフットノート2が入る"
  },
  {
    "objectID": "table.html#sec-gt-group",
    "href": "table.html#sec-gt-group",
    "title": "22  表の作成",
    "section": "22.4 グループ化",
    "text": "22.4 グループ化\n　列をグループ化するためにはtab_spanner()関数を使う。columns引数にはグループ化する列の位置、もしくは名前を、labelにはグループ名を指定すれば良い。たとえば、df1を使う場合、MinとMax列を一つのグループとしてRangeと名付けるとしよう。columnsは列の番号でも、列名でも良い。\n\ndf1 |&gt;\n    gt() |&gt;\n    tab_spanner(columns = 4:5, label = \"Range\") |&gt;\n    fmt_number(columns = 2:5, decimals = 3)\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      \n        Range\n      \n      Obs\n    \n    \n      Min\n      Max\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n  \n\n\n\n\n　続いて、行をグループ化する方法について紹介する。まず、df2の中身を確認してみよう。\n\ndf2 |&gt;\n    gt()\n\n\n\n\n  \n    \n    \n      Continent\n      Variable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n  \n  \n    Africa\nPopulation\n24.5609472\n35.90062114\n0.098347000\n206.139589\n54\n    Africa\nArea\n54.4435111\n59.21810613\n0.046000000\n238.174000\n54\n    Africa\nGDP_per_capita\n0.2514072\n0.31334566\n0.005770007\n1.727394\n54\n    Africa\nPPP_per_capita\n0.5667087\n0.60151933\n0.073314173\n2.778814\n52\n    Africa\nHDI_2018\n0.5532642\n0.10889924\n0.377000000\n0.801000\n53\n    Africa\nPolity_Score\n2.4791667\n5.00208290\n-9.000000000\n10.000000\n48\n    Africa\nFH_Total\n41.5740741\n25.12955251\n2.000000000\n92.000000\n54\n    America\nPopulation\n28.7362271\n66.28460983\n0.053199000\n334.308644\n36\n    America\nArea\n108.1607833\n245.85173673\n0.026000000\n915.802000\n36\n    America\nGDP_per_capita\n1.2526519\n1.27016543\n0.074535927\n6.444591\n36\n    America\nPPP_per_capita\n1.8100292\n1.26006234\n0.176587508\n6.178997\n35\n    America\nHDI_2018\n0.7424722\n0.09094975\n0.466000000\n0.922000\n36\n    America\nPolity_Score\n6.9259259\n3.59407553\n-5.000000000\n10.000000\n27\n    America\nFH_Total\n71.9166667\n22.42750225\n14.000000000\n98.000000\n36\n    Asia\nPopulation\n107.3001606\n301.72686527\n0.437479000\n1447.470092\n42\n    Asia\nArea\n70.1983405\n155.92487158\n0.030000000\n938.929100\n42\n    Asia\nGDP_per_capita\n1.3167525\n1.70584531\n0.049067972\n6.368026\n42\n    Asia\nPPP_per_capita\n2.2728133\n2.40667620\n0.139610508\n9.525177\n41\n    Asia\nHDI_2018\n0.7228537\n0.12010715\n0.463000000\n0.935000\n41\n    Asia\nPolity_Score\n0.3421053\n7.48431266\n-10.000000000\n10.000000\n38\n    Asia\nFH_Total\n38.9285714\n25.15453977\n0.000000000\n96.000000\n42\n    Europe\nPopulation\n17.1127533\n29.05674254\n0.000801000\n145.934462\n50\n    Europe\nArea\n46.4618980\n230.34717622\n0.000000000\n1637.687000\n50\n    Europe\nGDP_per_capita\n3.5575266\n3.86463361\n0.296369600\n18.317721\n49\n    Europe\nPPP_per_capita\n3.7782593\n2.12763785\n0.842873869\n11.342306\n46\n    Europe\nHDI_2018\n0.8611304\n0.06306914\n0.711000000\n0.954000\n46\n    Europe\nPolity_Score\n7.9268293\n4.23314448\n-7.000000000\n10.000000\n41\n    Europe\nFH_Total\n79.4285714\n22.70187217\n10.000000000\n100.000000\n49\n    Oceania\nPopulation\n10.0465332\n10.81385119\n0.896445000\n25.499884\n4\n    Oceania\nArea\n210.4312500\n372.29122053\n1.827000000\n768.230000\n4\n    Oceania\nGDP_per_capita\n2.6577585\n2.60067976\n0.279082855\n5.461517\n4\n    Oceania\nPPP_per_capita\n2.7572651\n2.19837188\n0.417111768\n5.000127\n4\n    Oceania\nHDI_2018\n0.7815000\n0.18631604\n0.543000000\n0.938000\n4\n    Oceania\nPolity_Score\n7.2500000\n3.20156212\n4.000000000\n10.000000\n4\n    Oceania\nFH_Total\n79.0000000\n20.80064102\n60.000000000\n97.000000\n4\n  \n  \n  \n\n\n\n\n　各大陸ごとの人口、面積などの情報が含まれている表であるが、これらを大陸単位で行をグループ化してみよう。方法は簡単だ。{dplyr}のようにgt()関数に渡す前に、group_by()でデータをグループ化すれば良い。今回はContinent列の値に基づいてグループ化するため、group_by(Continent)とする。\n\ndf2 |&gt;\n    group_by(Continent) |&gt;\n    gt()\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n  \n  \n    \n      Africa\n    \n    Population\n24.5609472\n35.90062114\n0.098347000\n206.139589\n54\n    Area\n54.4435111\n59.21810613\n0.046000000\n238.174000\n54\n    GDP_per_capita\n0.2514072\n0.31334566\n0.005770007\n1.727394\n54\n    PPP_per_capita\n0.5667087\n0.60151933\n0.073314173\n2.778814\n52\n    HDI_2018\n0.5532642\n0.10889924\n0.377000000\n0.801000\n53\n    Polity_Score\n2.4791667\n5.00208290\n-9.000000000\n10.000000\n48\n    FH_Total\n41.5740741\n25.12955251\n2.000000000\n92.000000\n54\n    \n      America\n    \n    Population\n28.7362271\n66.28460983\n0.053199000\n334.308644\n36\n    Area\n108.1607833\n245.85173673\n0.026000000\n915.802000\n36\n    GDP_per_capita\n1.2526519\n1.27016543\n0.074535927\n6.444591\n36\n    PPP_per_capita\n1.8100292\n1.26006234\n0.176587508\n6.178997\n35\n    HDI_2018\n0.7424722\n0.09094975\n0.466000000\n0.922000\n36\n    Polity_Score\n6.9259259\n3.59407553\n-5.000000000\n10.000000\n27\n    FH_Total\n71.9166667\n22.42750225\n14.000000000\n98.000000\n36\n    \n      Asia\n    \n    Population\n107.3001606\n301.72686527\n0.437479000\n1447.470092\n42\n    Area\n70.1983405\n155.92487158\n0.030000000\n938.929100\n42\n    GDP_per_capita\n1.3167525\n1.70584531\n0.049067972\n6.368026\n42\n    PPP_per_capita\n2.2728133\n2.40667620\n0.139610508\n9.525177\n41\n    HDI_2018\n0.7228537\n0.12010715\n0.463000000\n0.935000\n41\n    Polity_Score\n0.3421053\n7.48431266\n-10.000000000\n10.000000\n38\n    FH_Total\n38.9285714\n25.15453977\n0.000000000\n96.000000\n42\n    \n      Europe\n    \n    Population\n17.1127533\n29.05674254\n0.000801000\n145.934462\n50\n    Area\n46.4618980\n230.34717622\n0.000000000\n1637.687000\n50\n    GDP_per_capita\n3.5575266\n3.86463361\n0.296369600\n18.317721\n49\n    PPP_per_capita\n3.7782593\n2.12763785\n0.842873869\n11.342306\n46\n    HDI_2018\n0.8611304\n0.06306914\n0.711000000\n0.954000\n46\n    Polity_Score\n7.9268293\n4.23314448\n-7.000000000\n10.000000\n41\n    FH_Total\n79.4285714\n22.70187217\n10.000000000\n100.000000\n49\n    \n      Oceania\n    \n    Population\n10.0465332\n10.81385119\n0.896445000\n25.499884\n4\n    Area\n210.4312500\n372.29122053\n1.827000000\n768.230000\n4\n    GDP_per_capita\n2.6577585\n2.60067976\n0.279082855\n5.461517\n4\n    PPP_per_capita\n2.7572651\n2.19837188\n0.417111768\n5.000127\n4\n    HDI_2018\n0.7815000\n0.18631604\n0.543000000\n0.938000\n4\n    Polity_Score\n7.2500000\n3.20156212\n4.000000000\n10.000000\n4\n    FH_Total\n79.0000000\n20.80064102\n60.000000000\n97.000000\n4\n  \n  \n  \n\n\n\n\n　このようにグループ化することができる。引き続きMean列からMax列までの値を小数点3桁目で丸めてみよう。MeanとMax列の位置は2、5列目であるかのように見える。とりあえずやってみよう。\n\ndf2 |&gt;\n    group_by(Continent) |&gt;\n    gt() |&gt;\n    fmt_number(columns = 2:5, decimals = 3)\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n  \n  \n    \n      Africa\n    \n    Population\n24.561\n35.901\n0.098\n206.139589\n54\n    Area\n54.444\n59.218\n0.046\n238.174000\n54\n    GDP_per_capita\n0.251\n0.313\n0.006\n1.727394\n54\n    PPP_per_capita\n0.567\n0.602\n0.073\n2.778814\n52\n    HDI_2018\n0.553\n0.109\n0.377\n0.801000\n53\n    Polity_Score\n2.479\n5.002\n−9.000\n10.000000\n48\n    FH_Total\n41.574\n25.130\n2.000\n92.000000\n54\n    \n      America\n    \n    Population\n28.736\n66.285\n0.053\n334.308644\n36\n    Area\n108.161\n245.852\n0.026\n915.802000\n36\n    GDP_per_capita\n1.253\n1.270\n0.075\n6.444591\n36\n    PPP_per_capita\n1.810\n1.260\n0.177\n6.178997\n35\n    HDI_2018\n0.742\n0.091\n0.466\n0.922000\n36\n    Polity_Score\n6.926\n3.594\n−5.000\n10.000000\n27\n    FH_Total\n71.917\n22.428\n14.000\n98.000000\n36\n    \n      Asia\n    \n    Population\n107.300\n301.727\n0.437\n1447.470092\n42\n    Area\n70.198\n155.925\n0.030\n938.929100\n42\n    GDP_per_capita\n1.317\n1.706\n0.049\n6.368026\n42\n    PPP_per_capita\n2.273\n2.407\n0.140\n9.525177\n41\n    HDI_2018\n0.723\n0.120\n0.463\n0.935000\n41\n    Polity_Score\n0.342\n7.484\n−10.000\n10.000000\n38\n    FH_Total\n38.929\n25.155\n0.000\n96.000000\n42\n    \n      Europe\n    \n    Population\n17.113\n29.057\n0.001\n145.934462\n50\n    Area\n46.462\n230.347\n0.000\n1637.687000\n50\n    GDP_per_capita\n3.558\n3.865\n0.296\n18.317721\n49\n    PPP_per_capita\n3.778\n2.128\n0.843\n11.342306\n46\n    HDI_2018\n0.861\n0.063\n0.711\n0.954000\n46\n    Polity_Score\n7.927\n4.233\n−7.000\n10.000000\n41\n    FH_Total\n79.429\n22.702\n10.000\n100.000000\n49\n    \n      Oceania\n    \n    Population\n10.047\n10.814\n0.896\n25.499884\n4\n    Area\n210.431\n372.291\n1.827\n768.230000\n4\n    GDP_per_capita\n2.658\n2.601\n0.279\n5.461517\n4\n    PPP_per_capita\n2.757\n2.198\n0.417\n5.000127\n4\n    HDI_2018\n0.781\n0.186\n0.543\n0.938000\n4\n    Polity_Score\n7.250\n3.202\n4.000\n10.000000\n4\n    FH_Total\n79.000\n20.801\n60.000\n97.000000\n4\n  \n  \n  \n\n\n\n\n　このようにエラーが表示される。なぜだろう。それはグルーピングに使用された変数も1つの列としてカウントされるからだ。つまり、グルーピングに使用されたContinent列は列としては見えないものの、1列目として存在する。したがって、目に見える列番号に1を足す必要がある。それではグルーピングあと、Mean列からMax列までは小数点3桁目で丸め、Min列とMax列はRangeという名でグルーピングしてみよう。\n\ndf2 |&gt;\n    group_by(Continent) |&gt;\n    gt() |&gt;\n    tab_spanner(columns = 5:6, label = \"Range\") |&gt;\n    fmt_number(columns = 3:6, decimals = 3)\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      \n        Range\n      \n      Obs\n    \n    \n      Min\n      Max\n    \n  \n  \n    \n      Africa\n    \n    Population\n24.561\n35.901\n0.098\n206.140\n54\n    Area\n54.444\n59.218\n0.046\n238.174\n54\n    GDP_per_capita\n0.251\n0.313\n0.006\n1.727\n54\n    PPP_per_capita\n0.567\n0.602\n0.073\n2.779\n52\n    HDI_2018\n0.553\n0.109\n0.377\n0.801\n53\n    Polity_Score\n2.479\n5.002\n−9.000\n10.000\n48\n    FH_Total\n41.574\n25.130\n2.000\n92.000\n54\n    \n      America\n    \n    Population\n28.736\n66.285\n0.053\n334.309\n36\n    Area\n108.161\n245.852\n0.026\n915.802\n36\n    GDP_per_capita\n1.253\n1.270\n0.075\n6.445\n36\n    PPP_per_capita\n1.810\n1.260\n0.177\n6.179\n35\n    HDI_2018\n0.742\n0.091\n0.466\n0.922\n36\n    Polity_Score\n6.926\n3.594\n−5.000\n10.000\n27\n    FH_Total\n71.917\n22.428\n14.000\n98.000\n36\n    \n      Asia\n    \n    Population\n107.300\n301.727\n0.437\n1,447.470\n42\n    Area\n70.198\n155.925\n0.030\n938.929\n42\n    GDP_per_capita\n1.317\n1.706\n0.049\n6.368\n42\n    PPP_per_capita\n2.273\n2.407\n0.140\n9.525\n41\n    HDI_2018\n0.723\n0.120\n0.463\n0.935\n41\n    Polity_Score\n0.342\n7.484\n−10.000\n10.000\n38\n    FH_Total\n38.929\n25.155\n0.000\n96.000\n42\n    \n      Europe\n    \n    Population\n17.113\n29.057\n0.001\n145.934\n50\n    Area\n46.462\n230.347\n0.000\n1,637.687\n50\n    GDP_per_capita\n3.558\n3.865\n0.296\n18.318\n49\n    PPP_per_capita\n3.778\n2.128\n0.843\n11.342\n46\n    HDI_2018\n0.861\n0.063\n0.711\n0.954\n46\n    Polity_Score\n7.927\n4.233\n−7.000\n10.000\n41\n    FH_Total\n79.429\n22.702\n10.000\n100.000\n49\n    \n      Oceania\n    \n    Population\n10.047\n10.814\n0.896\n25.500\n4\n    Area\n210.431\n372.291\n1.827\n768.230\n4\n    GDP_per_capita\n2.658\n2.601\n0.279\n5.462\n4\n    PPP_per_capita\n2.757\n2.198\n0.417\n5.000\n4\n    HDI_2018\n0.781\n0.186\n0.543\n0.938\n4\n    Polity_Score\n7.250\n3.202\n4.000\n10.000\n4\n    FH_Total\n79.000\n20.801\n60.000\n97.000\n4\n  \n  \n  \n\n\n\n\n　ややこしい話であるが、列を番号でなく、列名で指定すると、このような混乱を避けることができる。列の指定方法は好みの問題でもあるので、好きなやり方を使おう。\n\ndf2 |&gt;\n    group_by(Continent) |&gt;\n    gt() |&gt;\n    tab_spanner(columns = Min:Max, label = \"Range\") |&gt;\n    fmt_number(columns = Mean:Max, decimals = 3)\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      \n        Range\n      \n      Obs\n    \n    \n      Min\n      Max\n    \n  \n  \n    \n      Africa\n    \n    Population\n24.561\n35.901\n0.098\n206.140\n54\n    Area\n54.444\n59.218\n0.046\n238.174\n54\n    GDP_per_capita\n0.251\n0.313\n0.006\n1.727\n54\n    PPP_per_capita\n0.567\n0.602\n0.073\n2.779\n52\n    HDI_2018\n0.553\n0.109\n0.377\n0.801\n53\n    Polity_Score\n2.479\n5.002\n−9.000\n10.000\n48\n    FH_Total\n41.574\n25.130\n2.000\n92.000\n54\n    \n      America\n    \n    Population\n28.736\n66.285\n0.053\n334.309\n36\n    Area\n108.161\n245.852\n0.026\n915.802\n36\n    GDP_per_capita\n1.253\n1.270\n0.075\n6.445\n36\n    PPP_per_capita\n1.810\n1.260\n0.177\n6.179\n35\n    HDI_2018\n0.742\n0.091\n0.466\n0.922\n36\n    Polity_Score\n6.926\n3.594\n−5.000\n10.000\n27\n    FH_Total\n71.917\n22.428\n14.000\n98.000\n36\n    \n      Asia\n    \n    Population\n107.300\n301.727\n0.437\n1,447.470\n42\n    Area\n70.198\n155.925\n0.030\n938.929\n42\n    GDP_per_capita\n1.317\n1.706\n0.049\n6.368\n42\n    PPP_per_capita\n2.273\n2.407\n0.140\n9.525\n41\n    HDI_2018\n0.723\n0.120\n0.463\n0.935\n41\n    Polity_Score\n0.342\n7.484\n−10.000\n10.000\n38\n    FH_Total\n38.929\n25.155\n0.000\n96.000\n42\n    \n      Europe\n    \n    Population\n17.113\n29.057\n0.001\n145.934\n50\n    Area\n46.462\n230.347\n0.000\n1,637.687\n50\n    GDP_per_capita\n3.558\n3.865\n0.296\n18.318\n49\n    PPP_per_capita\n3.778\n2.128\n0.843\n11.342\n46\n    HDI_2018\n0.861\n0.063\n0.711\n0.954\n46\n    Polity_Score\n7.927\n4.233\n−7.000\n10.000\n41\n    FH_Total\n79.429\n22.702\n10.000\n100.000\n49\n    \n      Oceania\n    \n    Population\n10.047\n10.814\n0.896\n25.500\n4\n    Area\n210.431\n372.291\n1.827\n768.230\n4\n    GDP_per_capita\n2.658\n2.601\n0.279\n5.462\n4\n    PPP_per_capita\n2.757\n2.198\n0.417\n5.000\n4\n    HDI_2018\n0.781\n0.186\n0.543\n0.938\n4\n    Polity_Score\n7.250\n3.202\n4.000\n10.000\n4\n    FH_Total\n79.000\n20.801\n60.000\n97.000\n4\n  \n  \n  \n\n\n\n\n　最後に、グルーピングとは関係ないものの、行の名前を指定する方法について説明する。それはgt()で表を作成する際、行の名前にしたい列名をrowname_colで指定すれば良い。たとえば、Variable列を行の名前にしてみよう。\n\ndf2 |&gt;\n    group_by(Continent) |&gt;\n    gt(rowname_col = \"Variable\") |&gt;\n    tab_spanner(columns = 5:6, label = \"Range\") |&gt;\n    fmt_number(columns = 3:6, decimals = 3)\n\n\n\n\n  \n    \n    \n      \n      Mean\n      SD\n      \n        Range\n      \n      Obs\n    \n    \n      Min\n      Max\n    \n  \n  \n    \n      Africa\n    \n    Population\n24.561\n35.901\n0.098\n206.140\n54\n    Area\n54.444\n59.218\n0.046\n238.174\n54\n    GDP_per_capita\n0.251\n0.313\n0.006\n1.727\n54\n    PPP_per_capita\n0.567\n0.602\n0.073\n2.779\n52\n    HDI_2018\n0.553\n0.109\n0.377\n0.801\n53\n    Polity_Score\n2.479\n5.002\n−9.000\n10.000\n48\n    FH_Total\n41.574\n25.130\n2.000\n92.000\n54\n    \n      America\n    \n    Population\n28.736\n66.285\n0.053\n334.309\n36\n    Area\n108.161\n245.852\n0.026\n915.802\n36\n    GDP_per_capita\n1.253\n1.270\n0.075\n6.445\n36\n    PPP_per_capita\n1.810\n1.260\n0.177\n6.179\n35\n    HDI_2018\n0.742\n0.091\n0.466\n0.922\n36\n    Polity_Score\n6.926\n3.594\n−5.000\n10.000\n27\n    FH_Total\n71.917\n22.428\n14.000\n98.000\n36\n    \n      Asia\n    \n    Population\n107.300\n301.727\n0.437\n1,447.470\n42\n    Area\n70.198\n155.925\n0.030\n938.929\n42\n    GDP_per_capita\n1.317\n1.706\n0.049\n6.368\n42\n    PPP_per_capita\n2.273\n2.407\n0.140\n9.525\n41\n    HDI_2018\n0.723\n0.120\n0.463\n0.935\n41\n    Polity_Score\n0.342\n7.484\n−10.000\n10.000\n38\n    FH_Total\n38.929\n25.155\n0.000\n96.000\n42\n    \n      Europe\n    \n    Population\n17.113\n29.057\n0.001\n145.934\n50\n    Area\n46.462\n230.347\n0.000\n1,637.687\n50\n    GDP_per_capita\n3.558\n3.865\n0.296\n18.318\n49\n    PPP_per_capita\n3.778\n2.128\n0.843\n11.342\n46\n    HDI_2018\n0.861\n0.063\n0.711\n0.954\n46\n    Polity_Score\n7.927\n4.233\n−7.000\n10.000\n41\n    FH_Total\n79.429\n22.702\n10.000\n100.000\n49\n    \n      Oceania\n    \n    Population\n10.047\n10.814\n0.896\n25.500\n4\n    Area\n210.431\n372.291\n1.827\n768.230\n4\n    GDP_per_capita\n2.658\n2.601\n0.279\n5.462\n4\n    PPP_per_capita\n2.757\n2.198\n0.417\n5.000\n4\n    HDI_2018\n0.781\n0.186\n0.543\n0.938\n4\n    Polity_Score\n7.250\n3.202\n4.000\n10.000\n4\n    FH_Total\n79.000\n20.801\n60.000\n97.000\n4\n  \n  \n  \n\n\n\n\n　表としては同じ表であるが、Variable列の右側に垂直線が出力される。ちなみにこれによって、列番号がずれることはないので安心しよう。"
  },
  {
    "objectID": "table.html#sec-gt-highlight",
    "href": "table.html#sec-gt-highlight",
    "title": "22  表の作成",
    "section": "22.5 セルの色分け",
    "text": "22.5 セルの色分け\n\n22.5.1 行・列のハイライト\n　続いて、セルを色塗りする方法を紹介する。まず、gt()を使用し、df3の表を作成し、Population列からFH列までの値を小数点3桁までにする。作成した表はdf3_tblという名で格納し、出力してみよう。\n\ndf3_tbl &lt;- df3 |&gt;\n  gt() |&gt;\n  fmt_number(columns = Population:FH, decimals = 3)\n\ndf3_tbl\n\n\n\n\n  \n    \n    \n      Continent\n      Population\n      Area\n      GDP\n      PPP\n      HDI\n      Polity\n      FH\n    \n  \n  \n    Africa\n24.561\n54.444\n0.251\n0.567\n0.553\n2.479\n41.574\n    America\n28.736\n108.161\n1.253\n1.810\n0.742\n6.926\n71.917\n    Asia\n107.300\n70.198\n1.317\n2.273\n0.723\n0.342\n38.929\n    Europe\n17.113\n46.462\n3.558\n3.778\n0.861\n7.927\n79.429\n    Oceania\n10.047\n210.431\n2.658\n2.757\n0.781\n7.250\n79.000\n  \n  \n  \n\n\n\n\n　まずは、特定の行を色塗りする方法を紹介する。使用する関数は{gtExtras}のgt_highlight_rows()関数である。必須引数はrowsであり、ここにハイライトしたい行の位置を指定する。たとえば、3行目をハイライトしたい場合はrows = 3とする。\n\ndf3_tbl |&gt;\n  gt_highlight_rows(rows = 3)\n\n\n\n\n  \n    \n    \n      Continent\n      Population\n      Area\n      GDP\n      PPP\n      HDI\n      Polity\n      FH\n    \n  \n  \n    Africa\n24.561\n54.444\n0.251\n0.567\n0.553\n2.479\n41.574\n    America\n28.736\n108.161\n1.253\n1.810\n0.742\n6.926\n71.917\n    Asia\n107.300\n70.198\n1.317\n2.273\n0.723\n0.342\n38.929\n    Europe\n17.113\n46.462\n3.558\n3.778\n0.861\n7.927\n79.429\n    Oceania\n10.047\n210.431\n2.658\n2.757\n0.781\n7.250\n79.000\n  \n  \n  \n\n\n\n\n　ハイライトの色と文字の太さはそれぞれfill（既定値は\"#80BCD8\"）とfont_weight（既定値は\"bold\"）引数で指摘できる。font_weightは\"normal\"、\"bold\"、\"lighter\"、\"bolder\"のように指定することも、1以上1000以下の数値で指定することもできる。\n\ndf3_tbl |&gt;\n  gt_highlight_rows(rows = 3, fill = \"gray80\", font_weight = \"normal\")\n\n\n\n\n  \n    \n    \n      Continent\n      Population\n      Area\n      GDP\n      PPP\n      HDI\n      Polity\n      FH\n    \n  \n  \n    Africa\n24.561\n54.444\n0.251\n0.567\n0.553\n2.479\n41.574\n    America\n28.736\n108.161\n1.253\n1.810\n0.742\n6.926\n71.917\n    Asia\n107.300\n70.198\n1.317\n2.273\n0.723\n0.342\n38.929\n    Europe\n17.113\n46.462\n3.558\n3.778\n0.861\n7.927\n79.429\n    Oceania\n10.047\n210.431\n2.658\n2.757\n0.781\n7.250\n79.000\n  \n  \n  \n\n\n\n\n　また、rows引数は行の番号でなく、条件式を使うこともできる。たとえば、HDI列の値が0.75以上の行をハイライトしたい場合はrows = (HID &gt;= 0.75)のように指定する。()はなくても良いが、可読性が落ちるので入れておこう。\n\ndf3_tbl |&gt;\n  gt_highlight_rows(rows = (HDI &gt;= 0.75))\n\n\n\n\n  \n    \n    \n      Continent\n      Population\n      Area\n      GDP\n      PPP\n      HDI\n      Polity\n      FH\n    \n  \n  \n    Africa\n24.561\n54.444\n0.251\n0.567\n0.553\n2.479\n41.574\n    America\n28.736\n108.161\n1.253\n1.810\n0.742\n6.926\n71.917\n    Asia\n107.300\n70.198\n1.317\n2.273\n0.723\n0.342\n38.929\n    Europe\n17.113\n46.462\n3.558\n3.778\n0.861\n7.927\n79.429\n    Oceania\n10.047\n210.431\n2.658\n2.757\n0.781\n7.250\n79.000\n  \n  \n  \n\n\n\n\n　続いて列のハイライト方法を紹介する。使用する関数はgt_hightlight_cols()であり、これは以上にて紹介したgt_highlight_rows()と使い方は同じである。ただし、列を指定する引数がrowsでなく、columnsであることに注意すること。また、columns実引数として条件式は使用できない。以下はdf3_tblのPolity列からFH列までを\"#ACB3CC\"色にハイライトした例である。\n\ndf3_tbl |&gt;\n  gt_highlight_cols(columns = Polity:FH,\n                    fill    = \"#ACB3CC\")\n\n\n\n\n  \n    \n    \n      Continent\n      Population\n      Area\n      GDP\n      PPP\n      HDI\n      Polity\n      FH\n    \n  \n  \n    Africa\n24.561\n54.444\n0.251\n0.567\n0.553\n2.479\n41.574\n    America\n28.736\n108.161\n1.253\n1.810\n0.742\n6.926\n71.917\n    Asia\n107.300\n70.198\n1.317\n2.273\n0.723\n0.342\n38.929\n    Europe\n17.113\n46.462\n3.558\n3.778\n0.861\n7.927\n79.429\n    Oceania\n10.047\n210.431\n2.658\n2.757\n0.781\n7.250\n79.000\n  \n  \n  \n\n\n\n\n\n\n22.5.2 セルの色分け\n　以上の例は「行」と「列」のハイライトであった。ここでは「セル」に注目する。セルの色塗りには2つのケースがある。1つ目は特定のセルをハイライトすることであり、2つ目は値に応じて色分けをすることである。まず、特定のセルを強調したい場合はdata_color()関数を使用する。ただし、rows引数のみだと全列がハイライトされてしまうので、今回は更にcolumns引数も追加し、「何行目、何列目のセル」かを特定する必要がある。\n\ndf3_tbl |&gt;\n  data_color(rows = 3, columns = 6)\n\n\n\n\n  \n    \n    \n      Continent\n      Population\n      Area\n      GDP\n      PPP\n      HDI\n      Polity\n      FH\n    \n  \n  \n    Africa\n24.561\n54.444\n0.251\n0.567\n0.553\n2.479\n41.574\n    America\n28.736\n108.161\n1.253\n1.810\n0.742\n6.926\n71.917\n    Asia\n107.300\n70.198\n1.317\n2.273\n0.723\n0.342\n38.929\n    Europe\n17.113\n46.462\n3.558\n3.778\n0.861\n7.927\n79.429\n    Oceania\n10.047\n210.431\n2.658\n2.757\n0.781\n7.250\n79.000\n  \n  \n  \n\n\n\n\n　セルの値に応じて色分けをする場合もdata_color()関数を使う。たとえば、Population列（2列目）の値に応じて色分けをするなら、columns = Population、またはcolumns = 2を指定する。\n\ndf3_tbl |&gt;\n  data_color(columns = Population)\n\n\n\n\n  \n    \n    \n      Continent\n      Population\n      Area\n      GDP\n      PPP\n      HDI\n      Polity\n      FH\n    \n  \n  \n    Africa\n24.561\n54.444\n0.251\n0.567\n0.553\n2.479\n41.574\n    America\n28.736\n108.161\n1.253\n1.810\n0.742\n6.926\n71.917\n    Asia\n107.300\n70.198\n1.317\n2.273\n0.723\n0.342\n38.929\n    Europe\n17.113\n46.462\n3.558\n3.778\n0.861\n7.927\n79.429\n    Oceania\n10.047\n210.431\n2.658\n2.757\n0.781\n7.250\n79.000\n  \n  \n  \n\n\n\n\n　ちなみに、色についても説明する。デフォルトの色だと値の高低が分かりにくいため、もう少し直感的なパレットにした方が良いだろう。このパレットはpalette引数で指定することができる。特定のパッケージが提供するパレットであれば\"パッケージ名::パレット名\"と指定する。たとえば、Population列からFH列まで色分けをし、{ggsci}のblue_materialパレットを使う場合はpalette = \"ggsci::blue_material\"のように指定する必要がある。\n\ndf3_tbl |&gt;\n  data_color(Population:FH,\n             palette = \"ggsci::blue_material\")\n\n\n\n\n  \n    \n    \n      Continent\n      Population\n      Area\n      GDP\n      PPP\n      HDI\n      Polity\n      FH\n    \n  \n  \n    Africa\n24.561\n54.444\n0.251\n0.567\n0.553\n2.479\n41.574\n    America\n28.736\n108.161\n1.253\n1.810\n0.742\n6.926\n71.917\n    Asia\n107.300\n70.198\n1.317\n2.273\n0.723\n0.342\n38.929\n    Europe\n17.113\n46.462\n3.558\n3.778\n0.861\n7.927\n79.429\n    Oceania\n10.047\n210.431\n2.658\n2.757\n0.781\n7.250\n79.000\n  \n  \n  \n\n\n\n\n　このように濃いほど値が大きく、薄いほど小さいことが一目瞭然となる。{ggsci}は他にも様々なパレットを提供しているが、詳細は公式レファレンスを参照されたい。また、{ggsci}以外のパッケージが提供するパレットも使える。定番の{RColorBrewer}パッケージも様々なパレットを提供しており、以下の例はYlOrRdパレットを使った例だ。\n\ndf3_tbl |&gt;\n  data_color(Population:FH,\n             palette = \"RColorBrewer::YlOrRd\")\n\n\n\n\n  \n    \n    \n      Continent\n      Population\n      Area\n      GDP\n      PPP\n      HDI\n      Polity\n      FH\n    \n  \n  \n    Africa\n24.561\n54.444\n0.251\n0.567\n0.553\n2.479\n41.574\n    America\n28.736\n108.161\n1.253\n1.810\n0.742\n6.926\n71.917\n    Asia\n107.300\n70.198\n1.317\n2.273\n0.723\n0.342\n38.929\n    Europe\n17.113\n46.462\n3.558\n3.778\n0.861\n7.927\n79.429\n    Oceania\n10.047\n210.431\n2.658\n2.757\n0.781\n7.250\n79.000\n  \n  \n  \n\n\n\n\n　{RColorBrewer}が提供するパレットの例はコンソール上でRColorBrewer::display.brewer.all()と打つと出力される（ ?fig-table-color-6 ）。\n\nRColorBrewer::display.brewer.all()\n\n\n\n\n図 22.2: {RColorBrewer}が提供するパレット"
  },
  {
    "objectID": "table.html#画像プロットの追加",
    "href": "table.html#画像プロットの追加",
    "title": "22  表の作成",
    "section": "22.6 画像・プロットの追加",
    "text": "22.6 画像・プロットの追加\n　以下では表の中にプロットや画像を入れる方法について紹介する。まずはdf4を利用し、大陸（Continent）ごとの一人あたり購買力平価GDP（PPP_per_capita）の記述統計と分布を作成する。グループごとの記述統計を作成するため、ここではgroup_by()とsummarise()関数を使用する。平均値、標準偏差、最小値、最大値、国家数をそれぞれMean、SD、Min、Max、N列にする。そして、当該大陸に属する国のPPP_per_capitaを一つのベクトルとし、PPP列に入れる。この場合、list()関数を使えば良い。以上の結果をdf4_groupedに格納する。\n\ndf4_grouped &lt;- df4 |&gt; \n  group_by(Continent) |&gt; \n  summarise(Mean = mean(PPP_per_capita),\n            SD   = sd(PPP_per_capita),\n            Min  = min(PPP_per_capita),\n            Max  = max(PPP_per_capita),\n            N    = n(),\n            PPP  = list(PPP_per_capita))\n\n　出来上がったdf4_groupedは以下の通りだ。\n\ndf4_grouped \n\n# A tibble: 5 × 7\n  Continent   Mean     SD   Min     Max     N PPP       \n  &lt;chr&gt;      &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt; &lt;int&gt; &lt;list&gt;    \n1 Africa     5667.  6015.  733.  27788.    52 &lt;dbl [52]&gt;\n2 America   18100. 12601. 1766.  61790.    35 &lt;dbl [35]&gt;\n3 Asia      22728. 24067. 1396.  95252.    41 &lt;dbl [41]&gt;\n4 Europe    37783. 21276. 8429. 113423.    46 &lt;dbl [46]&gt;\n5 Oceania   27573. 21984. 4171.  50001.     4 &lt;dbl [4]&gt; \n\n\n　それではdf4_groupedをgt()で表にしてみよう。\n\ndf4_grouped |&gt; \n  gt()\n\n\n\n\n  \n    \n    \n      Continent\n      Mean\n      SD\n      Min\n      Max\n      N\n      PPP\n    \n  \n  \n    Africa\n5667.087\n6015.193\n733.1417\n27788.14\n52\n11324.0725, 6649.1673, 3067.3395, 17310.5769, 1799.9818, 733.1417, 6912.7516, 3506.4386, 923.5042, 1525.4869, 3006.8733, 3191.0497, 1043.4956, 3641.9578, 5071.1943, 11198.2578, 19458.2978, 1860.3065, 8633.5553, 2046.8136, 14380.1640, 2072.3368, 5097.3606, 1901.6047, 4104.9732, 3019.3082, 1461.0965, 14018.7988, 1567.1475, 1016.0831, 2208.4879, 3601.3961, 22636.5579, 7553.9970, 1246.5947, 10314.3368, 824.0225, 5018.4108, 2007.9457, 3890.9194, 3247.9262, 27788.1379, 1634.0012, 12604.8540, 1410.1588, 4062.9183, 2428.0001, 1515.5174, 10773.4423, 1716.0125, 3396.9366, 3264.8320\n    America\n18100.292\n12600.623\n1765.8751\n61789.97\n35\n21267.245, 22938.453, 35662.133, 16065.907, 7090.572, 8623.407, 14734.442, 49087.531, 24261.632, 14474.628, 19395.153, 11755.063, 17774.017, 11478.292, 8727.663, 33836.181, 8332.809, 2416.077, 9447.449, 1765.875, 5624.412, 9886.558, 19962.713, 5693.549, 30816.642, 12877.619, 12703.540, 26152.935, 13828.250, 12686.047, 15858.204, 26727.710, 61789.968, 21961.226, 17806.318\n    Asia\n22728.133\n24066.762\n1396.1051\n95251.77\n41\n2125.363, 43624.136, 4457.529, 11362.544, 60655.643, 4931.585, 4142.204, 15176.568, 6564.248, 11396.947, 13961.476, 10434.202, 41318.464, 41490.573, 9849.485, 25469.454, 39921.960, 50094.732, 5083.211, 7548.949, 16473.367, 27477.879, 18087.834, 11801.134, 3210.718, 27700.112, 4664.227, 8098.786, 93465.650, 47196.131, 95251.768, 13413.583, 46145.206, 3161.765, 18383.526, 3034.142, 65777.677, 6792.995, 7627.625, 1396.105, 3083.957\n    Europe\n37782.593\n21276.379\n8428.7387\n113423.06\n46\n13780.638, 12974.285, 55823.776, 14257.217, 19415.237, 51548.972, 15158.639, 22550.810, 27996.133, 28723.892, 40130.231, 56753.797, 36233.104, 49324.081, 45649.605, 13633.866, 53886.153, 31256.640, 31955.380, 60011.048, 83254.278, 42769.738, 11077.907, 31412.683, 36875.034, 113423.060, 47787.124, 8428.739, 21103.451, 57277.744, 16621.538, 66276.146, 31863.289, 34564.831, 29406.377, 28731.642, 62554.007, 14078.861, 32539.756, 38655.236, 40519.800, 54212.515, 68233.163, 27465.404, 12207.236, 45596.210\n    Oceania\n27572.651\n21983.719\n4171.1177\n50001.27\n4\n50001.271, 13939.907, 42178.309, 4171.118\n  \n  \n  \n\n\n\n\n　続いて、平均値から最大値までの値を小数点1桁で丸め、列名を修正し、タイトルを付ける。\n\ndf4_grouped |&gt; \n  gt() |&gt; \n  fmt_number(columns = Mean:Max, decimals = 1) |&gt; \n  cols_label(\"Continent\" = \"大陸\",\n             \"Mean\"      = \"平均値\",\n             \"SD\"        = \"標準偏差\",\n             \"Min\"       = \"最小値\",\n             \"Max\"       = \"最大値\",\n             \"N\"         = \"国家数\",\n             \"PPP\"       = \"分布\") |&gt; \n  tab_header(title = \"大陸別一人あたり購買力平価GDP\")\n\n\n\n\n  \n    \n      大陸別一人あたり購買力平価GDP\n    \n    \n    \n      大陸\n      平均値\n      標準偏差\n      最小値\n      最大値\n      国家数\n      分布\n    \n  \n  \n    Africa\n5,667.1\n6,015.2\n733.1\n27,788.1\n52\n11324.0725, 6649.1673, 3067.3395, 17310.5769, 1799.9818, 733.1417, 6912.7516, 3506.4386, 923.5042, 1525.4869, 3006.8733, 3191.0497, 1043.4956, 3641.9578, 5071.1943, 11198.2578, 19458.2978, 1860.3065, 8633.5553, 2046.8136, 14380.1640, 2072.3368, 5097.3606, 1901.6047, 4104.9732, 3019.3082, 1461.0965, 14018.7988, 1567.1475, 1016.0831, 2208.4879, 3601.3961, 22636.5579, 7553.9970, 1246.5947, 10314.3368, 824.0225, 5018.4108, 2007.9457, 3890.9194, 3247.9262, 27788.1379, 1634.0012, 12604.8540, 1410.1588, 4062.9183, 2428.0001, 1515.5174, 10773.4423, 1716.0125, 3396.9366, 3264.8320\n    America\n18,100.3\n12,600.6\n1,765.9\n61,790.0\n35\n21267.245, 22938.453, 35662.133, 16065.907, 7090.572, 8623.407, 14734.442, 49087.531, 24261.632, 14474.628, 19395.153, 11755.063, 17774.017, 11478.292, 8727.663, 33836.181, 8332.809, 2416.077, 9447.449, 1765.875, 5624.412, 9886.558, 19962.713, 5693.549, 30816.642, 12877.619, 12703.540, 26152.935, 13828.250, 12686.047, 15858.204, 26727.710, 61789.968, 21961.226, 17806.318\n    Asia\n22,728.1\n24,066.8\n1,396.1\n95,251.8\n41\n2125.363, 43624.136, 4457.529, 11362.544, 60655.643, 4931.585, 4142.204, 15176.568, 6564.248, 11396.947, 13961.476, 10434.202, 41318.464, 41490.573, 9849.485, 25469.454, 39921.960, 50094.732, 5083.211, 7548.949, 16473.367, 27477.879, 18087.834, 11801.134, 3210.718, 27700.112, 4664.227, 8098.786, 93465.650, 47196.131, 95251.768, 13413.583, 46145.206, 3161.765, 18383.526, 3034.142, 65777.677, 6792.995, 7627.625, 1396.105, 3083.957\n    Europe\n37,782.6\n21,276.4\n8,428.7\n113,423.1\n46\n13780.638, 12974.285, 55823.776, 14257.217, 19415.237, 51548.972, 15158.639, 22550.810, 27996.133, 28723.892, 40130.231, 56753.797, 36233.104, 49324.081, 45649.605, 13633.866, 53886.153, 31256.640, 31955.380, 60011.048, 83254.278, 42769.738, 11077.907, 31412.683, 36875.034, 113423.060, 47787.124, 8428.739, 21103.451, 57277.744, 16621.538, 66276.146, 31863.289, 34564.831, 29406.377, 28731.642, 62554.007, 14078.861, 32539.756, 38655.236, 40519.800, 54212.515, 68233.163, 27465.404, 12207.236, 45596.210\n    Oceania\n27,572.7\n21,983.7\n4,171.1\n50,001.3\n4\n50001.271, 13939.907, 42178.309, 4171.118\n  \n  \n  \n\n\n\n\n　それではこのPPP列をプロットにしてみよう。ここで使うのが{gtExtras}のgt_plt_dist()だ。引数はプロットにする列名で十分だ。\n\ndf4_grouped |&gt; \n  gt() |&gt; \n  fmt_number(columns = Mean:Max, decimals = 1) |&gt; \n  cols_label(\"Continent\" = \"大陸\",\n             \"Mean\"      = \"平均値\",\n             \"SD\"        = \"標準偏差\",\n             \"Min\"       = \"最小値\",\n             \"Max\"       = \"最大値\",\n             \"N\"         = \"国家数\",\n             \"PPP\"       = \"分布\") |&gt; \n  tab_header(title = \"大陸別一人あたり購買力平価GDP\") |&gt; \n  gt_plt_dist(PPP)\n\n\n\n\n  \n    \n      大陸別一人あたり購買力平価GDP\n    \n    \n    \n      大陸\n      平均値\n      標準偏差\n      最小値\n      最大値\n      国家数\n      分布\n    \n  \n  \n    Africa\n5,667.1\n6,015.2\n733.1\n27,788.1\n52\n          \n    America\n18,100.3\n12,600.6\n1,765.9\n61,790.0\n35\n          \n    Asia\n22,728.1\n24,066.8\n1,396.1\n95,251.8\n41\n          \n    Europe\n37,782.6\n21,276.4\n8,428.7\n113,423.1\n46\n          \n    Oceania\n27,572.7\n21,983.7\n4,171.1\n50,001.3\n4\n          \n  \n  \n  \n\n\n\n\n　このように密度曲線が生成される。もし、密度曲線ではなく、ヒストグラムにしたい場合はtype引数を追加し、\"histogram\"を指定すれば良い。\n\ndf4_grouped |&gt; \n  gt() |&gt; \n  fmt_number(columns = Mean:Max, decimals = 1) |&gt; \n  cols_label(\"Continent\" = \"大陸\",\n             \"Mean\"      = \"平均値\",\n             \"SD\"        = \"標準偏差\",\n             \"Min\"       = \"最小値\",\n             \"Max\"       = \"最大値\",\n             \"N\"         = \"国家数\",\n             \"PPP\"       = \"分布\") |&gt; \n  tab_header(title = \"大陸別一人あたり購買力平価GDP\") |&gt; \n  gt_plt_dist(PPP, type = \"histogram\")\n\n\n\n\n  \n    \n      大陸別一人あたり購買力平価GDP\n    \n    \n    \n      大陸\n      平均値\n      標準偏差\n      最小値\n      最大値\n      国家数\n      分布\n    \n  \n  \n    Africa\n5,667.1\n6,015.2\n733.1\n27,788.1\n52\n          \n    America\n18,100.3\n12,600.6\n1,765.9\n61,790.0\n35\n          \n    Asia\n22,728.1\n24,066.8\n1,396.1\n95,251.8\n41\n          \n    Europe\n37,782.6\n21,276.4\n8,428.7\n113,423.1\n46\n          \n    Oceania\n27,572.7\n21,983.7\n4,171.1\n50,001.3\n4\n          \n  \n  \n  \n\n\n\n\n　続いて、画像について解説する。ここではdf5を使用する。まずはgt()で中身を確認してみよう。\n\ndf5 |&gt; \n  gt()\n\n\n\n\n  \n    \n    \n      Name\n      Hex\n      Download\n    \n  \n  \n    dplyr\nhttps://github.com/rstudio/hex-stickers/blob/main/thumbs/dplyr.png?raw=true\n35720\n    quarto\nhttps://github.com/rstudio/hex-stickers/blob/main/thumbs/quarto.png?raw=true\n171\n    ggplot2\nhttps://github.com/rstudio/hex-stickers/blob/main/thumbs/ggplot2.png?raw=true\n44403\n    shiny\nhttps://github.com/rstudio/hex-stickers/blob/main/thumbs/shiny.png?raw=true\n10795\n    rmarkdown\nhttps://github.com/rstudio/hex-stickers/blob/main/thumbs/rmarkdown.png?raw=true\n23038\n    tidyverse\nhttps://github.com/rstudio/hex-stickers/blob/main/thumbs/tidyverse.png?raw=true\n39094\n  \n  \n  \n\n\n\n\n　3つの列があり、1列目はパッケージ名（Name）、2列目はHEXロゴのURL（Hex）、3列目は2023年5月9日現在のダウンロード数（Download）である。ここで{gtExtras}のgt_img_rows()関数を使用し、画像のパス・URLが格納されている列名を指定すれば、当該画像が表示される。\n\ndf5 |&gt; \n  gt() |&gt; \n  gt_img_rows(Hex)\n\n\n\n\n  \n    \n    \n      Name\n      Hex\n      Download\n    \n  \n  \n    dplyr\n\n35720\n    quarto\n\n171\n    ggplot2\n\n44403\n    shiny\n\n10795\n    rmarkdown\n\n23038\n    tidyverse\n\n39094\n  \n  \n  \n\n\n\n\n　画像の大きさはheightで調整できる。今回は50ピクセル（50px）にしてみよう。\n\ndf5 |&gt; \n  gt() |&gt; \n  gt_img_rows(Hex, height = 50)\n\n\n\n\n  \n    \n    \n      Name\n      Hex\n      Download\n    \n  \n  \n    dplyr\n\n35720\n    quarto\n\n171\n    ggplot2\n\n44403\n    shiny\n\n10795\n    rmarkdown\n\n23038\n    tidyverse\n\n39094\n  \n  \n  \n\n\n\n\n　続いて、列名を変更する。NameはPackageに、HexはLogoとする。\n\ndf5 |&gt; \n  gt() |&gt; \n  gt_img_rows(Hex, height = 50) |&gt; \n  cols_label(\"Name\" = \"Package\",\n             \"Hex\"  = \"Logo\")\n\n\n\n\n  \n    \n    \n      Package\n      Logo\n      Download\n    \n  \n  \n    dplyr\n\n35720\n    quarto\n\n171\n    ggplot2\n\n44403\n    shiny\n\n10795\n    rmarkdown\n\n23038\n    tidyverse\n\n39094\n  \n  \n  \n\n\n\n\n　ここで更にDownload列を棒グラフに変えてみよう。棒グラフの作成はgt_plt_bar()を使用する。第1引数は棒グラフにしたい列名だ。\n\ndf5 |&gt; \n  gt() |&gt; \n  gt_img_rows(Hex, height = 50) |&gt; \n  cols_label(\"Name\" = \"Package\",\n             \"Hex\"  = \"Logo\") |&gt; \n  gt_plt_bar(Download)\n\n\n\n\n  \n    \n    \n      Package\n      Logo\n      Download\n    \n  \n  \n    dplyr\n\n          \n    quarto\n\n          \n    ggplot2\n\n          \n    shiny\n\n          \n    rmarkdown\n\n          \n    tidyverse\n\n          \n  \n  \n  \n\n\n\n\n　棒グラフにすることで相対的な比較がしやすくなった。しかし、元々あった数字がなくなったので、具体的に何回ダウンロードされたかに関する情報を消えている。もし、元の列を残したい場合はkeep_column = TRUEを指定する。\n\ndf5 |&gt; \n  gt() |&gt; \n  gt_img_rows(Hex, height = 50) |&gt; \n  cols_label(\"Name\" = \"Package\",\n             \"Hex\"  = \"Logo\") |&gt; \n  gt_plt_bar(Download, keep_column = TRUE)\n\n\n\n\n  \n    \n    \n      Package\n      Logo\n      Download\n      Download\n    \n  \n  \n    dplyr\n\n35720\n          \n    quarto\n\n171\n          \n    ggplot2\n\n44403\n          \n    shiny\n\n10795\n          \n    rmarkdown\n\n23038\n          \n    tidyverse\n\n39094\n          \n  \n  \n  \n\n\n\n\n　最後にタイトルを付け、棒グラフの色を\"royalblue\"にしてみよう。棒の色はcolor引数で指定できる。また、df5をgt()に渡す前にarrange()を使って、パッケージの表示順番もダウンロード数の多いものからに並べ替えてみよう。\n\ndf5 |&gt; \n  arrange(desc(Download)) |&gt; \n  gt() |&gt; \n  gt_img_rows(Hex, height = 50) |&gt; \n  cols_label(\"Name\" = \"Package\",\n             \"Hex\"  = \"Logo\") |&gt; \n  gt_plt_bar(Download, keep_column = TRUE, color = \"royalblue\") |&gt; \n  tab_header(title = \"Number of packages downloaded on May 9, 2023\")\n\n\n\n\n  \n    \n      Number of packages downloaded on May 9, 2023\n    \n    \n    \n      Package\n      Logo\n      Download\n      Download\n    \n  \n  \n    ggplot2\n\n44403\n          \n    tidyverse\n\n39094\n          \n    dplyr\n\n35720\n          \n    rmarkdown\n\n23038\n          \n    shiny\n\n10795\n          \n    quarto\n\n171\n          \n  \n  \n  \n\n\n\n\n　{gtExtras}は他にも様々なプロットを提供し、画像の追加にもいくつかのバリエーションがある。詳細は{gtExtras}の公式マニュアルを参照されたい。"
  },
  {
    "objectID": "table.html#テーマ",
    "href": "table.html#テーマ",
    "title": "22  表の作成",
    "section": "22.7 テーマ",
    "text": "22.7 テーマ\n　{gtExtras}パッケージは8種類のテーマを提供する（バージョン0.4.5現在）。テーマはgt_theme_*()関数によって指定することができる。たとえば、以下のdf1_tblにそれぞれのテーマを適用してみよう。\n\ndf1_tbl &lt;- df1 |&gt;\n  gt() |&gt;\n  tab_spanner(columns = 4:5, label = \"Range\") |&gt;\n  fmt_number(columns = 2:5, decimals = 3) |&gt;\n  tab_style(style     = cell_text(align = \"center\"),\n            locations = cells_column_labels())\n\ndf1_tbl\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      \n        Range\n      \n      Obs\n    \n    \n      Min\n      Max\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n  \n\n\n\n\n　使い方は簡単で、{gt}で作成した表オブジェクトをgt_theme_*()関数に渡すだけだ。以下は{gtExtras}が提供する8種類のテーマをdf1_tblに適用した例である。\n\n538espnnytimesguardiandot_matrixdarkexcelpff\n\n\n\ndf1_tbl |&gt;\n  gt_theme_538()\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      \n        Range\n      \n      Obs\n    \n    \n      Min\n      Max\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n  \n\n\n\n\n\n\n\ndf1_tbl |&gt;\n  gt_theme_espn()\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      \n        Range\n      \n      Obs\n    \n    \n      Min\n      Max\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n  \n\n\n\n\n\n\n\ndf1_tbl |&gt;\n  gt_theme_nytimes()\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      \n        Range\n      \n      Obs\n    \n    \n      Min\n      Max\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n  \n\n\n\n\n\n\n\ndf1_tbl |&gt;\n  gt_theme_guardian()\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      \n        Range\n      \n      Obs\n    \n    \n      Min\n      Max\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n  \n\n\n\n\n\n\n\ndf1_tbl |&gt;\n  gt_theme_dot_matrix()\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      \n        Range\n      \n      Obs\n    \n    \n      Min\n      Max\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n  \n\n\n\n\n\n\n\n# こちらはR Markdown/QuartoのCSSによって正しく表示されない可能性がある。\n# RStudio内なら問題なし\ndf1_tbl |&gt;\n  gt_theme_dark()\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      \n        Range\n      \n      Obs\n    \n    \n      Min\n      Max\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n  \n\n\n\n\n\n\n\ndf1_tbl |&gt;\n  gt_theme_excel()\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      \n        Range\n      \n      Obs\n    \n    \n      Min\n      Max\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n  \n\n\n\n\n\n\n\ndf1_tbl |&gt;\n  gt_theme_pff()\n\n\n\n\n  \n    \n    \n      Variable\n      Mean\n      SD\n      \n        Range\n      \n      Obs\n    \n    \n      Min\n      Max\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185"
  },
  {
    "objectID": "table.html#sec-gt-export",
    "href": "table.html#sec-gt-export",
    "title": "22  表の作成",
    "section": "22.8 表の書き出し",
    "text": "22.8 表の書き出し\n　{gt}で作成した表は様々なフォーマットで出力することができる。現在（2023年06月26日; {gt} 0.9.0）、Microsoft Word（.docx）、\\(\\LaTeX\\)（.tex）、ハイパーテキスト（.html）、リッチテキスト（.rtf）、画像（.png）形式で出力可能だ。ここでは簡単な例を紹介する。\n　まず、{gt}を使って表を作成し、オブジェクトとして作業環境内に格納する。ここではgt_tableと名付けた。\n\ngt_table &lt;- df1 |&gt;\n  gt() |&gt;\n  fmt_number(columns = 2:5, decimals = 3) |&gt;\n  tab_header(title = \"タイトル\", subtitle = \"サブタイトル\") |&gt;\n  tab_footnote(footnote = \"注1: ここにはフットノート1が入る\") |&gt;\n  tab_footnote(footnote = \"注2: ここにはフットノート2が入る\") |&gt;\n  tab_source_note(source_note = md(\"出典: 『[私たちのR](https://www.jaysong.net/RBook/)』\"))\n\ngt_table\n\n\n\n\n  \n    \n      タイトル\n    \n    \n      サブタイトル\n    \n    \n      Variable\n      Mean\n      SD\n      Min\n      Max\n      Obs\n    \n  \n  \n    Population\n41.738\n151.270\n0.001\n1,447.470\n186\n    Area\n69.607\n187.241\n0.000\n1,637.687\n186\n    GDP_per_capita\n1.616\n2.571\n0.006\n18.318\n185\n    PPP_per_capita\n2.083\n2.099\n0.073\n11.342\n178\n    HDI_2018\n0.713\n0.153\n0.377\n0.954\n180\n    Polity_Score\n4.259\n6.102\n−10.000\n10.000\n158\n    FH_Total\n57.714\n29.866\n0.000\n100.000\n185\n  \n  \n    \n      出典: 『私たちのR』\n    \n  \n  \n    \n       注1: ここにはフットノート1が入る\n    \n    \n       注2: ここにはフットノート2が入る\n    \n  \n\n\n\n\n　このgt_tableを保存する関数はgtsave()である。第1引数は先ほど作成した表のオブジェクト名、第2引数は出力するファイル名である。このファイル名の拡張子によって保存されるファイルのフォーマットが変わる。結果をここで見せることは難しいが、難しい作業ではないので各自やってみよう。\n\ngtsave(gt_table, \"my_table.docx\") # Microsoft Word\ngtsave(gt_table, \"my_table.tex\")  # LaTeX\ngtsave(gt_table, \"my_table.html\") # HTML\ngtsave(gt_table, \"my_table.rtf\")  # リッチテキスト\ngtsave(gt_table, \"my_table.png\")  # 画像（PNG）\n\n　たとえば、.tex形式で書き出したファイルを開いてみると、以下のような\\(\\LaTeX\\)コードが書かれていることが確認できる。\n\\setlength{\\LTpost}{0mm}\n\\begin{longtable}{lrrrrr}\n\\caption*{\n{\\large タイトル} \\\\ \n{\\small サブタイトル}\n} \\\\ \n\\toprule\nVariable & Mean & SD & Min & Max & Obs \\\\ \n\\midrule\nPopulation & $41.738$ & $151.270$ & $0.001$ & $1,447.470$ & 186 \\\\ \nArea & $69.607$ & $187.241$ & $0.000$ & $1,637.687$ & 186 \\\\ \nGDP\\_per\\_capita & $1.616$ & $2.571$ & $0.006$ & $18.318$ & 185 \\\\ \nPPP\\_per\\_capita & $2.083$ & $2.099$ & $0.073$ & $11.342$ & 178 \\\\ \nHDI\\_2018 & $0.713$ & $0.153$ & $0.377$ & $0.954$ & 180 \\\\ \nPolity\\_Score & $4.259$ & $6.102$ & $-10.000$ & $10.000$ & 158 \\\\ \nFH\\_Total & $57.714$ & $29.866$ & $0.000$ & $100.000$ & 185 \\\\ \n\\bottomrule\n\\end{longtable}\n\\begin{minipage}{\\linewidth}\n\\textsuperscript{\\textit{NA}}注1: ここにはフットノート1が入る\\\\\n\\textsuperscript{\\textit{NA}}注2: ここにはフットノート2が入る\\\\\n出典: 『\\href{https://www.jaysong.net/RBook/}{私たちのR}』\\\\\n\\end{minipage}"
  },
  {
    "objectID": "table.html#sec-DT",
    "href": "table.html#sec-DT",
    "title": "22  表の作成",
    "section": "22.9 データの出力",
    "text": "22.9 データの出力\n　PDF、Microsoft Word形式の文書を作成する場合、生データ（raw data）を掲載することはめったにないだろう。数十行のデータなら掲載することもあろうが3、規模の大きいデータセットの場合、資源（紙）の無駄遣いとなる。しかし、HTMLフォーマットの文書なら話は別だ。ファイルの容量は大きくなるものの、生データを全て掲載することもできる。\n　そこまで大きいデータセットではないが、たとえばdf2をR Markdown / QuartoのHTML文書に掲載するとしよう。この場合、まず考えられるのは普通にdf2を出力することだ。ただし、df2のクラスによって出力結果がややことなる。たとえば、df2はread_csv()関数で読み込んだデータであるため、data.frameでなく、tibbleである。実際にクラスを確認してみよう。「クラス（class）」の概念については第28章を参照されたい。\n\nclass(df2)\n\n[1] \"spec_tbl_df\" \"tbl_df\"      \"tbl\"         \"data.frame\" \n\n\n　data.frameクラスを継承しているが、クラスに\"tbl\"や\"tbl_df\"も含まれており、これはdf2がtibble形式であることを意味する。これをこのまま出力してみよう。\n\ndf2\n\n# A tibble: 35 × 7\n   Continent Variable          Mean      SD      Min     Max   Obs\n   &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;\n 1 Africa    Population      24.6    35.9    0.0983  206.       54\n 2 Africa    Area            54.4    59.2    0.046   238.       54\n 3 Africa    GDP_per_capita   0.251   0.313  0.00577   1.73     54\n 4 Africa    PPP_per_capita   0.567   0.602  0.0733    2.78     52\n 5 Africa    HDI_2018         0.553   0.109  0.377     0.801    53\n 6 Africa    Polity_Score     2.48    5.00  -9        10        48\n 7 Africa    FH_Total        41.6    25.1    2        92        54\n 8 America   Population      28.7    66.3    0.0532  334.       36\n 9 America   Area           108.    246.     0.026   916.       36\n10 America   GDP_per_capita   1.25    1.27   0.0745    6.44     36\n# ℹ 25 more rows\n\n\n　tibble形式のデータは通常、最初の10行のみ出力される。また、小数点も2〜3桁目で丸められる。もう一つの特徴としては横に長い表の場合（つまり、列が多い場合）、一部の列は省略される（省略された列の簡単な情報は表示される）。このようにtibbleクラスのデータは読みやすく出力される長所があるものの、全てのデータが出力されないケースもある。\n　一方、read_csv()でなく、read.csv()で読み込んだ表形式データのクラスはdata.frameだ。df2をas.data.frame()関数を使ってdata.frameクラスに変更してみよう。クラスを変更したdf2はdf6_dfと名付ける。\n\ndf6_df &lt;- as.data.frame(df2)\n\nclass(df6_df)\n\n[1] \"data.frame\"\n\n\n　それではdf6_dfを出力してみよう。\n\ndf6_df\n\n   Continent       Variable        Mean           SD           Min         Max Obs\n1     Africa     Population  24.5609472  35.90062114   0.098347000  206.139589  54\n2     Africa           Area  54.4435111  59.21810613   0.046000000  238.174000  54\n3     Africa GDP_per_capita   0.2514072   0.31334566   0.005770007    1.727394  54\n4     Africa PPP_per_capita   0.5667087   0.60151933   0.073314173    2.778814  52\n5     Africa       HDI_2018   0.5532642   0.10889924   0.377000000    0.801000  53\n6     Africa   Polity_Score   2.4791667   5.00208290  -9.000000000   10.000000  48\n7     Africa       FH_Total  41.5740741  25.12955251   2.000000000   92.000000  54\n8    America     Population  28.7362271  66.28460983   0.053199000  334.308644  36\n9    America           Area 108.1607833 245.85173673   0.026000000  915.802000  36\n10   America GDP_per_capita   1.2526519   1.27016543   0.074535927    6.444591  36\n11   America PPP_per_capita   1.8100292   1.26006234   0.176587508    6.178997  35\n12   America       HDI_2018   0.7424722   0.09094975   0.466000000    0.922000  36\n13   America   Polity_Score   6.9259259   3.59407553  -5.000000000   10.000000  27\n14   America       FH_Total  71.9166667  22.42750225  14.000000000   98.000000  36\n15      Asia     Population 107.3001606 301.72686527   0.437479000 1447.470092  42\n16      Asia           Area  70.1983405 155.92487158   0.030000000  938.929100  42\n17      Asia GDP_per_capita   1.3167525   1.70584531   0.049067972    6.368026  42\n18      Asia PPP_per_capita   2.2728133   2.40667620   0.139610508    9.525177  41\n19      Asia       HDI_2018   0.7228537   0.12010715   0.463000000    0.935000  41\n20      Asia   Polity_Score   0.3421053   7.48431266 -10.000000000   10.000000  38\n21      Asia       FH_Total  38.9285714  25.15453977   0.000000000   96.000000  42\n22    Europe     Population  17.1127533  29.05674254   0.000801000  145.934462  50\n23    Europe           Area  46.4618980 230.34717622   0.000000000 1637.687000  50\n24    Europe GDP_per_capita   3.5575266   3.86463361   0.296369600   18.317721  49\n25    Europe PPP_per_capita   3.7782593   2.12763785   0.842873869   11.342306  46\n26    Europe       HDI_2018   0.8611304   0.06306914   0.711000000    0.954000  46\n27    Europe   Polity_Score   7.9268293   4.23314448  -7.000000000   10.000000  41\n28    Europe       FH_Total  79.4285714  22.70187217  10.000000000  100.000000  49\n29   Oceania     Population  10.0465332  10.81385119   0.896445000   25.499884   4\n30   Oceania           Area 210.4312500 372.29122053   1.827000000  768.230000   4\n31   Oceania GDP_per_capita   2.6577585   2.60067976   0.279082855    5.461517   4\n32   Oceania PPP_per_capita   2.7572651   2.19837188   0.417111768    5.000127   4\n33   Oceania       HDI_2018   0.7815000   0.18631604   0.543000000    0.938000   4\n34   Oceania   Polity_Score   7.2500000   3.20156212   4.000000000   10.000000   4\n35   Oceania       FH_Total  79.0000000  20.80064102  60.000000000   97.000000   4\n\n\n　今回は全ての行と列が出力された。そもそも生データを掲載するのが目的であれば、tibbleクラスよりも、data.frameクラスが目的に合致する。しかし、読みにくいという深刻な問題がある。また、世論調査データのように数千行、変数も数十列以上あるデータセットを出力するとあまりにも長い画面になってしまう。\n　ここで便利なのが{DT}パッケージのdatatable()関数だ。全ての行と列を読みやすい形式で出力してくれる。\n\ndatatable(df2)\n\n\n\n\n\n　このように情報が損失されることなく4、非常に読みやすい表になった。これで十分かも知れないが、小数点を丸めたい人もいるかも知れないので、その方法を紹介する。具体的にはdataframe()で作成した表をformatRound()関数に渡すだけだ。formatRound()関数の引数はcolumnsとdigitsがあり、それぞれ適用する列と小数点を桁数を指定すればよい。\n\ndatatable(df2) |&gt;\n    formatRound(columns = 3:6, digits = 3)"
  },
  {
    "objectID": "rmarkdown.html#rmarkdown-intro",
    "href": "rmarkdown.html#rmarkdown-intro",
    "title": "23  R Markdown [基礎]",
    "section": "23.1 R Markdownとは",
    "text": "23.1 R Markdownとは\n　R Markdownとは名前通り、RとMarkdownが結合されたものです。本書を通じてRを紹介してきましたが、Markdownは初めて出てくるものです。John GruberとAaron Swartzが2004年提案した軽量Markup言語ですが、そもそもMarkup言語とはなんでしょうか。\n　Markup言語を知るためにはプレーンテキスト（plain text）とリッチテキスト（rich text、またはマルチスタイルテキスト）の違いについて知る必要があります。プレーンテキストとは書式情報などが含まれていない純粋なテキストのみで構成されている文書です。書式情報とは文書の余白、文字の大きさ、文字の色などがあります。これまでRStudio上で書いてきたRコードもプレーンテキストです。コードに色が自動的に付けられますが、これはRStudioが色付けをしてくれただけで、ファイル自体はテキストのみで構成されています。macOSのTextEdit、Windowsのメモ帳、Linux GUI環境のgeditやKATE、CLI環境下のvim、Emacs、nanoなどで作成したファイルは全てプレーンテキストです。これらのテキストエディターには書式設定や図表の挿入などの機能は付いておりません。一方、リッチテキストとは書式情報だけでなく、図表なども含まれる文書です。Microsoft Wordとかで作成したファイルがその代表的な例です。他にもPagesやLibreOffice Writerから作成したファイルなどがあります。これらのワードプロセッサーソフトウェアは書式の設定や図表・リンクの挿入などができます。そして、Markup言語とはプレーンテキストのみでリッチテキストを作成するための言語です。\n　Markup言語の代表的な存在がHTMLです。そもそもHTMLのMLはMarkup Languageの略です。読者の皆さんがウェブブラウザから見る画面のほとんどはHTMLで書かれています。この『私たちのR』もHTMLです。この文書には図表があり、太字、見出し、水平線など、テキスト以外の情報が含んでいます。しかし、HTMLは純粋なテキストのみで書かれており、ウェブブラウザ（Firefox、Chrome、Edgeなど）がテキストファイルを読み込み、解釈して書式が付いている画面を出力してくれます。例えば、リンク（hyperlink）について考えてみましょう。「SONGのHP」をクリックすると宋のホームページに移動します。ある単語をクリックすることで、他のウェブサイトへ飛ばす機能を付けるためにはHTMLファイルの中に、以下のように入力します。\n&lt;a href=\"https://www.jaysong.net\"&gt;SONGのHP&lt;/a&gt;\n　これをウェブブラウザが自動的に「SONGのHP」と変換し、画面に出力してくれます。これは、書式情報などが必要な箇所にコードを埋め込むことによって実現されます。そして、このMarkup言語をより単純な文法で再構成したものがMarkdownです。例えば、以上のHTMLはMarkdownでは以下のように書きます。\n[SONGのHP](https://www.jaysong.net)\n　同じ意味のコードですが、Markdownの方がより簡潔に書けます。このMarkdownは最終的にHTMLやMicrosoft Word、PDF形式で変換されます。一般的にはHTML出力を使いますが、自分のPCにLaTeX環境が用意されている場合はPDF形式で出力することも可能であり、個人的には推奨しておりませんが、Microsoft Work文書ファイルへ変換することも可能です。また、HTML（+ JavaScript）へ出力可能であることを利用し、スライドショー、e-Book、ホームページの作成にもMarkdownが使えます。\n　R MarkdownはMarkdownにRコードとその結果を同時に載せることができるMarkdownです。それでもピンと来ない方も多いでしょう。それでは、とりあえず、R Markdownをサンプルコードから体験してみましょう。"
  },
  {
    "objectID": "rmarkdown.html#とりあえずknit",
    "href": "rmarkdown.html#とりあえずknit",
    "title": "23  R Markdown [基礎]",
    "section": "23.2 とりあえずKnit",
    "text": "23.2 とりあえずKnit\n　R Markdownの文法について説明する前に、とりあえずR Markdownというのがどういうものかを味見してみます。既に述べたようにR MarkdownにはRコードも含まれるため、事前にプロジェクトを生成してから進めることをおすすめします。\n　R Markdownファイルを生成するにはFile -&gt; New File -&gt; R Markdown…を選択します。Title:とAuthor:には文書のタイトルと作成者を入力します。Default Output FormatはデフォルトはHTMLとなっていますが、このままにしておきましょう。ここでの設定はいつでも変更可能ですので、何も触らずにOKを押しても大丈夫です。\n　OKを押したら自動的にR Markdownのサンプルファイルが生成されます。そしたらSourceペインの上段にあるボタン1をクリックしてみましょう。最初はファイルの保存ダイアログが表示されますが、適切な場所（プロジェクトのフォルダなど）に保存すれば、自動的にMarkdown文書を解釈し始めます。処理が終わればViewerペインに何かの文章が生成されます。これからの内容を進める前にSourceペインとViewerペインの中身をそれぞれ対応しながら、どのような関係があるのかを考えてみましょう。\n　R Markdownファイルは大きく3つの領域に分けることができます（ 図 23.1 ）。まず、最初に---と---で囲まれた領域はヘッダー（Header）と呼ばれる領域です。ここでは題目、作成者情報の入力以外にも、文書全体に通じる設定を行います。これは第23.5節で解説します。次はR Markdownの核心部であるチャンク（Chunk）です。チャンクは```{r}と```で囲まれた領域であり、Rコードが入る箇所です。チャンクに関しましては第23.3節の後半と第23.4節で解説します。その他の領域がマークダウン（Markdown）であり、文書に該当します。\n\n\n\n図 23.1: R Markdownのサンプルページ\n\n\n　まずは、文章の書き方から説明します。非常に簡単な文法で綺麗、かつ構造化された文書が作成可能であり、これに慣れるとMarkdown基盤のノートアプリなどを使って素早くノート作成、メモが出来ます。"
  },
  {
    "objectID": "rmarkdown.html#sec-rmarkdown_grammar",
    "href": "rmarkdown.html#sec-rmarkdown_grammar",
    "title": "23  R Markdown [基礎]",
    "section": "23.3 Markdown文法の基本",
    "text": "23.3 Markdown文法の基本\n　まずは、Markdownの文法について解説します。ここではMarkdown文書内に以下のようなことを作成する方法を実際の書き方と、出力画面を対比しながら解説していきます。\n\n改行\n強調: 太字、イタリック、アンダーライン、取り消し線\n箇条書き\n見出し\n区切り線\n表\n画像\nリンク\n脚注\n数式\n引用\nコメント\nRコード\n\n\n23.3.1 改行\n　Markdownにおける改行はやや特殊です。特殊といっても難しいことはありません。普段よりもう一行改行するだけです。Markdownの場合、1回の改行は改行として判定されず、同じ行の連続と認識します。たとえば、Inputのように入力するとOutputのように文章1と文章2が繋がります。\nInput:\n文章1\n文章2\nOutput:\n文章1 文章2\n　文章1と文章2を改行するためにはもう一行、改行する必要があります。以下の例を見てください。\nInput:\n文章1\n\n文章2\nOutput:\n文章1\n文章2\n　こうすることで段落間の間隔を強制的に入れることとなり、作成者側にも読みやすい文書構造になります2。\n\n\n23.3.2 強調\n文章の一部を強調する方法として太字、イタリック3、アンダーラインがあり、強調ではありませんが、ついでに取り消し線についても紹介します。いずれも強調したい箇所を記号で囲むだけです。\nInput:\n文章の一部を**太字**にしてみましょう。\n\n*イタリック*もいいですね。\n\n~~取り消し線~~はあまり使わないかも。\n\n&lt;u&gt;アンダーライン&lt;/u&gt;はHTMLタグを使います。\nOutput:\n文章の一部を太字にしてみましょう。\nイタリックもいいですね。\n取り消し線はあまり使わないかも。\nアンダーラインはHTMLタグを使います。\n\n\n23.3.3 箇条書き\n箇条書きには順序なしと順序付きがあります。順序なしの場合*または-の後に半角スペースを1つ入れるだけです。また、2文字以上の字下げで下位項目を追加することもできます。\nInput:\n- 項目1\n  - 項目1-1\n  - 項目1-2\n    - 項目1-2-1\n      - 項目1-2-1-1\n    - 項目1-2-2\n- 項目2\n- 項目3\nOutput:\n\n項目1\n\n項目1-1\n項目1-2\n\n項目1-2-1\n\n項目1-2-1-1\n\n項目1-2-2\n\n\n項目2\n項目3\n\n　続きまして順序付き箇条書きですが、これは-（または*）を数字.に換えるだけです。順序なしの場合と違って数字の後にピリオド（.）が付くことに注意してください。また、下位項目を作成する際、順序なしはスペース2つ以上が必要でしたが、順序付きの場合、少なくとも3つが必要です。\nInput:\n1. 項目1\n   1. 項目1-1\n   2. 項目1-2\n2. 項目2\n   * 項目2-1\n   * 項目2-2\n3. 項目3\nOutput:\n\n項目1\n\n項目1-1\n項目1-2\n\n項目2\n\n項目2-1\n項目2-2\n\n項目3\n\n\n\n23.3.4 見出し\n　章、節、段落のタイトルを付ける際は#を使います。#の数が多いほど文字が小さくなります。章の見出しを##にするなら節は###、小節または段落は####が適切でしょう。見出しは####まで使えます。\nInput:\n# 見出し1\n## 見出し2\n### 見出し3\n#### 見出し4\nOutput:\n\n見出し1\n\n\n見出し2\n\n\n見出し3\n\n\n見出し4\n\n\n\n23.3.5 区切り線\n区切り線は---または***を使います。\nInput:\n---\nOutput:\n\n\n\n23.3.6 表\n　Markdownの表は非常にシンプルな書き方をしています。行は改行で、列は|で区切られます。ただ、表の第1行はヘッダー（変数名や列名が表示される行）扱いとなり、ヘッダーと内容の区分は|---|で行います。以下はMarkdownを利用した簡単な表の書き方です。ここでは可読性のためにスペースを適宜入れましたが、スペースの有無は結果に影響を与えません。\nInput:\n|ID   |Name     |Math    |English |Favorite food|\n|:---:|---------|-------:|-------:|-------------|\n|1    |SONG     |15      |10      |Ramen        |\n|2    |Yanai    |100     |100     |Cat food     |\n|3    |Shigemura|80      |50      |Raw chicken  |\n|4    |Wickham  |80      |90      |Lamb         |\nOutput:\n\n\n\nID\nName\nMath\nEnglish\nFavorite food\n\n\n\n\n1\nSONG\n15\n10\nRamen\n\n\n2\nYanai\n100\n100\nCat food\n\n\n3\nShigemura\n80\n50\nRaw chicken\n\n\n4\nWickham\n80\n90\nLamb\n\n\n\n　1行目はヘッダーであり、太字かつ中央揃えになります。2行目以降はデフォルトでは左揃えになりますが。ただし。|---|をいじることによって当該列の揃えを調整できます。|:---|は左 (デフォルト)、|---:|は右、|:---:|は中央となります。また-の個数は1個以上なら問題ありません。つまり、|-|も|---|も同じです。\n\n\n23.3.7 画像\n　R Markdownに画像を入れるには![代替テキスト](ファイル名)と入力します。当たり前ですが、画像ファイルがワーキングディレクトリにない場合はパスを指定する必要があります。[代替テキスト]は画像を読み込めなかった場合のテキストを意味します。これは画像が読み込めなかった場合の代替テキストでもありますが、視覚障害者用のウェブブラウザーのためにも使われます。これらのウェブブラウザーはテキストのみ出力されるものが多く、画像の代わりには代替テキストが読み込まれます。\n　例えば、Figsフォルダー内のfavicon.pngというファイルを読み込むとしたら以下のように書きます。\nInput:\n![『私たちのR』ロゴ](Figs/favicon.png)\nOutput:\n\n\n\n『私たちのR』ロゴ\n\n\n\n\n23.3.8 リンク\n　ハイパーリンクは[テキスト](URL)のような形式で書きます。[]内は実際に表示されるテキストであり、()は飛ばすURLになります。\nInput:\n毎日1回は[SONGのホームページ](https://www.jaysong.net)へアクセスしましょう。\nOutput:\n毎日1回はSONGのホームページへアクセスしましょう。\n\n\n23.3.9 脚注\n　脚注は[^固有識別子]と[^固有識別子]: 脚注内容の2つの要素が必要です。まず、文末脚注を入れる箇所に[^xxxx]を挿入します。xxxxは任意の文字列れ構いません。しかし、同じR Markdown内においてこの識別子は被らないように注意してください。実際の脚注の内容は[^xxxx]: 内容のように入力します。これはどこに位置しても構いません。文書の途中でも、最後に入れても、脚注の内容は文末に位置します。ただし、脚注を入れる段落のすぐ後の方が作成する側としては読みやすいでしょう。\nInput:\nこれは普通の文章です[^foot1]。\n\n[^foot1]: これは普通の脚注です。\nOutput:\nこれは普通の文章です4。\n\n\n23.3.10 数式\n　インライン数式は$数式$で埋め込むことができます。数式はLaTeXの書き方とほぼ同じです。ちなみに、R Markdownの数式はMathJaxによってレンダリングされます。このMathJaxライブラリはHTMLに埋め込まれているのではないため、インターネットに接続せずにHTMLファイルを開くと数式が正しく出力されません。\nInput:\nアインシュタインと言えば、$e = mc^2$でしょう。\nOutput:\nアインシュタインと言えば、\\(e = mc^2\\)でしょう。\n　数式を独立した行として出力する場合は、$の代わりに$$を使用します。\nInput:\n独立した数式の書き方\n\n$$\ny_i \\sim \\text{Normal}(\\mathbf{X} \\boldsymbol{\\beta}, \\sigma).\n$$\nOutput:\n独立した数式の書き方\n\\[\ny_i \\sim \\text{Normal}(\\mathbf{X} \\boldsymbol{\\beta}, \\sigma).\n\\]\n　もし数式が複数の行で構成されている場合は$$内にaligned環境（\\begin{aligned}〜\\end{aligned}）を使用します。むろん、LaTeXと使い方は同じです。\nInput:\n複数の行にわたる数式の書き方\n\n$$\n\\begin{aligned}\n  Y_i      & \\sim \\text{Bernoulli}(\\theta_i), \\\\\n  \\theta_i & = \\text{logit}^{-1}(y_i^*), \\\\\n  y_i^*    & = \\beta_0 + \\beta_1 x_1 + \\beta_2 z_1.\n\\end{aligned}\n$$\nOutput:\n複数の行にわたる数式の書き方\n\\[\n\\begin{aligned}\n  Y_i      & \\sim \\text{Bernoulli}(\\theta_i), \\\\\n  \\theta_i & = \\text{logit}^{-1}(y_i^*), \\\\\n  y_i^*    & = \\beta_0 + \\beta_1 x_1 + \\beta_2 z_1.\n\\end{aligned}\n\\]\n　ここまで見ればお分かりかと思いますが、$$の中にはLaTeXコマンドが使用可能です。たとえば、行列を作成する際は以下のように\\begin{bmatrix}環境を使います。\nInput:\n行列の書き方\n\n$$\nX = \\begin{bmatrix}\n  x_{11} & x_{12} \\\\\n  x_{21} & x_{22} \\\\\n  x_{31} & x_{32}\n\\end{bmatrix}.\n$$\nOutput:\n行列の書き方\n\\[\nX = \\begin{bmatrix}\n  x_{11} & x_{12} \\\\\n  x_{21} & x_{22} \\\\\n  x_{31} & x_{32}\n\\end{bmatrix}.\n\\]\n\n\n23.3.11 引用\n　引用の際は文章の最初に&gt;を入れるだけです。&gt;の後に半角のスペースが1つ入ります。\nInput:\n「政治とは何か」についてイーストンは以下のように定義しました。\n\n&gt; [A] political system can be designated as those interactions through which values are authoritatively allocated for a society.\nOutput:\n「政治とは何か」についてイーストンは以下のように定義しました。\n\n[A] political system can be designated as those interactions through which values are authoritatively allocated for a society.\n\n\n\n23.3.12 コメント\n　R Markdownにもコメントを付けることができます。とりあえず書いたが要らなくなった段落や文章があって、消すことがもったいない場合はコメントアウトするのも1つの方法です。ただし、コメントアウトの方法はRは#でしたが、これはR Markdownでは見出しの記号です。R Markdownのコメントは&lt;!--と--&gt;で囲みます。\nInput:\n文章1\n\n&lt;!--\nここはコメントです。\n--&gt;\n\n文章2\nOutput:\n文章1\n\n文章2\n\n\n23.3.13 コード\n　以上の内容まで抑えると、R Markdownを使って、簡単な文法のみで構造化された文書が作成できます。しかし、R Markdownの意義は文章とコード、結果が統合されることです。それでは文書にRコードを入れる方法について紹介します。\n　コードは```{r}と```の間に入力します。これだけです。これでコードと結果が同時に出力されます。たとえば、print(\"Hello World!\")を走らすコードを入れてみます。\nInput:\n\"Hello World!\"を出力するコード\n\n```{r}\nprint(\"Hello World!\")\n```\nOutput:\n“Hello World!”を出力するコード\n\nprint(\"Hello World!\")\n\n[1] \"Hello World!\"\n\n\n　```{r}と```で囲まれた範囲をR Markdownではチャンク（Chunk）と呼びます。このチャンク内ではRと全く同じことが出来ます。パッケージやデータの読み込み、オブジェクトの生成、データハンドリング、可視化など、全てです。\nInput: 　\n```{r}\n# パッケージの読み込み\nlibrary(tidyverse)\n# R内蔵データセットのirisを使った可視化\niris |&gt;\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) |&gt;\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\") +\n  theme_minimal(base_family = \"HiraKakuProN-W3\")\n```\nOutput:\n\n# パッケージの読み込み\nlibrary(tidyverse)\n# R内蔵データセットのirisを使った可視化\niris |&gt;\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) |&gt;\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\") +\n  theme_minimal(base_family = \"HiraKakuProN-W3\")\n\n\n\n\n　他にも文中にRコードを埋め込むことも可能です。例えば、ベクトルX &lt;- c(2, 3, 5, 7, 12)があり、この平均値を文中で示したいとします。むろん、文中に「5.8」と書いても問題はありません。しかし、実はXの入力ミスが見つかり、実はc(2, 3, 5, 7, 11)になったらどうなるでしょうか。この「5.8」と書いた箇所を見つけて5.6と修正したいといけません。これは非常に面倒な作業であり、ミスも起こりやすいです。文中でRコードを入れるためには`rコード`のように入力します。\nInput:\n```{r}\nX &lt;- c(2, 3, 5, 7, 11)knit\n```\n\n変数`X`の平均値は`r mean(X)`です。\nOutput:\n\nX &lt;- c(2, 3, 5, 7, 11)\n\n変数Xの平均値は5.6です。\nここで`X`ですが、単に`で囲まれただけではコードと認識されません。これは主に文中に短いコードを入れる際に使う機能です。"
  },
  {
    "objectID": "rmarkdown.html#sec-rmarkdown_chunk",
    "href": "rmarkdown.html#sec-rmarkdown_chunk",
    "title": "23  R Markdown [基礎]",
    "section": "23.4 チャンクのオプション",
    "text": "23.4 チャンクのオプション\n　既に説明しましたとおり、R MakrdownはR + Markdownです。Rはチャンク、Markdownはチャンク外の部分に相当し、それぞれのカスタマイズが可能です。分析のコードと結果はチャンクにオプションを付けることで修正可能であり、文章の部分は次節で紹介するヘッダーで調整できます。ここではチャンクのオプションについて説明します。\n　チャンクは```{r}で始まりますが、実は{r}の箇所にオプションを追加することができます。具体的には{r チャンク名, オプション1, オプション2, ...}といった形です。まずはチャンク名について解説します。\n\n23.4.1 チャンク名とチャンク間依存関係\n　チャンク名は{r チャンク名}で指定し、rとチャンク名の間には,が入りません。これはチャンクに名前をしていするオプションですが、多くの場合分析に影響を与えることはありません。このチャンク名が重要となるのはcacheオプションを付ける場合です。\n　cacheオプションは処理結果を保存しておくことを意味します。チャンク内のコードはKnitする度に計算されます。もし、演算にかなりの時間を費やすコードが含まれている場合、Knitの時間も長くなります。この場合、cache = TRUEオプションを付けておくと、最初のKnit時に結果をファイルとして保存し、次回からはその結果を読み込むだけとなります。時間が非常に節約できるため、よく使われるオプションの1つです。ただし、チャンク内のコードが修正された場合、Knit時にもう一回処理を行います。コードの実質的な内容が変わらなくても、つまり、スペースを1つ入れただけでも再計算となります。\n　ここで1つ問題が生じます。たとえば、以下のようなコードを考えてみてください。\n```{r}\nX &lt;- c(2, 3, 5, 7, 10)\n```\n\n```{r, cache = TRUE}\nmean(X)\n```\n　この構造に問題はありません。しかし、ここでXの5番目の要素を11に修正したとします。そしてもう一回Knitを行ったらどうなるでしょうか。正解は「何も変わらない」です。新しいmean(X)の結果は5.6のはずですが、5.4のままです。なぜなら、2番目のチャンクの結果は既に保存されており、コードも修正していないからです。もう一回強調しておきますが、cahce = TRUEの状態で当該チャンクが修正されない場合、結果は変わりません。\n　このようにあるチャンクの内容が他のチャンク内容に依存しているケースがあります。この場合、dependsonオプションを使います。使い方はdependson = \"依存するチャンク名\"です。もし、1番目のチャンク名をdefine_Xとしたら、dependson = \"define_X\"とオプションを加えます。\n```{r define_X}\nX &lt;- c(2, 3, 5, 7, 10)\n```\n\n```{r, cache = TRUE, dependson = \"define_X\"}\nmean(X)\n```\n　このようにチャンク名とcache、dependsonオプションを組み合わせると、依存するチャンクの中身が変わったら、cache = TRUEでも再計算を行います。\n\n\n23.4.2 コードまたは結果の表示/非常時\n　次は「コードだけ見せたい」、「結果だけ見せたい」場合使うオプションを紹介します。これはあまり使わないかも知れませんが、本書のような技術書にはよく使う機能です。コードのみ出力し、計算を行わない場合はeval = FALSEオプションを、コードを見せず、結果のみ出力する場合はecho = FALSEを指定するだけです。\n他にもコードと結果を両方隠すことも可能です。つまり、チャンク内のコードは実行されるが、そのコードと結果を隠すことです。この場合に使うオプションがincludeであり、既定値はTRUEです。チャンクオプションにinclude = FALSEを追加すると、当該チャンクのコードは実行されますが、コードと結果は表示されません。\n\n\n23.4.3 プロット\n　既に見てきた通り、R Markdownは作図の結果も出力してくれます。そこで、図のサイズや解像度を変えることもできます。ここではプロットに関するいくつかのオプションを紹介します。\n\nfig.height: 図の高さ。単位はインチ。デフォルト値は7\nfig.width: 図の幅。単位はインチ。デフォルト値は7\nfig.align: 図の位置。デフォルトは\"left\"。\"center\"の場合、中央揃え、\"right\"の場合は右揃えになる。\nfig.cap: 図のキャプション\ndpi: 図の解像度。デフォルトは72。出版用の図は一般的に300以上を使う\n\n　実際に高さ5インチ、幅7インチ、中央揃え、解像度72dpiの図を作成し、キャプションとして「irisデータセットの可視化」を付けてみましょう。\nInput: 　\n```{r, fig.height = 5, fig.width = 7, fig.align = \"center\", fig.cap = \"図の例\", dpi = 72}\niris |&gt;\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) |&gt;\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\") +\n  theme_minimal(base_family = \"HiraKakuProN-W3\")\n```\nOutput:\n\niris |&gt;\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) |&gt;\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\") +\n  theme_minimal(base_family = \"HiraKakuProN-W3\")\n\n\n\n\n図の例\n\n\n\n\n\n\n23.4.4 コードの見栄\n　第11章ではスクリプトの書き方を紹介しましたが、常にその書き方に則った書き方をしているとは限りません。自分だけが見るコードなら別に推奨されない書き方でも問題ないかも知れませんが、R Markdownの結果は他人と共有するケースが多いため、読みやすいコードを書くのも大事です。ここで便利なオプションがtidyオプションです。tidy = TRUEを加えると、自動的にコードを読みやすい形に調整してくれます。たとえば、以下のコードは字下げもなく、スペースもほとんど入れていないコードですが、tidy = TRUEを付けた場合と付けなかった場合の出力結果の違いを見てみましょう。\nInput:\n```{r, eval = FALSE}\nfor(i in 1:10){\nprint(i*2)\n}\n```\nOutput:　\n\nfor(i in 1:10){\nprint(i*2)\n}\n\nInput:\n```{r, eval = FALSE, tidy = TRUE}\nfor(i in 1:10){\nprint(i*2)\n}\n```\nOutput:\n\nfor (i in 1:10) {\n    print(i * 2)\n}\n\n　tidy = TRUEを付けただけで、読みやすいコードになりました。ちなみにtidyオプションを使うためには事前にformatRパッケージをインストールしておく必要があります。ただし、formatRパッケージはR Markdwon内において読み込んでおく必要はありません。また、formatRパッケージは万能ではないため、普段から読みやすいコードを書くようにしましょう。"
  },
  {
    "objectID": "rmarkdown.html#sec-rmarkdown_header",
    "href": "rmarkdown.html#sec-rmarkdown_header",
    "title": "23  R Markdown [基礎]",
    "section": "23.5 ヘッダーのオプション",
    "text": "23.5 ヘッダーのオプション\n　R Markdownファイルを生成すると、ファイルの最上段には以下のようなヘッダー（header）というものが生成されます。\n---\ntitle: \"Untitled\"\nauthor: \"Jaehyun Song\"\ndate: \"8/6/2020\"\noutput: html_document\n---\n　基本的には4つの項目が指定されており、それぞれ文書のタイトル（title:）、作成者名（author:）、作成日（date:）、出力形式（output:）があります。タイトルと作成者名はファイル生成時に指定した内容が、作成日は今日の日付が、出力形式はHTMLで設定した場合html_documentになっています。R MarkdownヘッダーはYAML（やむる）形式で書かれています。こちらはいつでも修正可能であり、インラインRコードを埋め込むことも可能です。たとえば、作成日をファイル生成日でなく、Knitした日付にしたい場合は日付を出力するSys.Date()関数を使って、date: \"最終修正: `r Sys.Date()`\"のように書くことも可能です。他にもデフォルトでは指定されていませんが、subtitle:を使ってサブタイトルを指定したり、abstract:で要約を入れることも可能です。\n　また、R Markdownのコメントは&lt;!--と--&gt;を使いますが、ヘッダー内のコメントはRと同様、#を使います。\n　ヘッダーで設定できる項目は数十個以上ですが、ここでは頻繁に使われる項目について紹介します。\n\n23.5.1 目次の追加\n　R Markdownの文章が長くなったり、コードが多く含まれる場合、目次を入れたら文章の構造が一目で把握できるでしょう。目次は見出しに沿って自動的に生成されます。#は章、##は節といった形式です。\n---\ntitle: \"タイトル\"\nsubtitle: \"サブタイトル\"\nauthor: \"作成者名\"\ndate: \"最終修正: `r Sys.Date()`\"\noutput:\n  html_document:\n    toc: FALSE\n    toc_depth: 3\n    toc_float: FALSE\n    number_sections: FALSE\n---\n　字下げには常に注意してください。html_documentはoutput:の下位項目ですから、字下げを行います。また、tocはhtml_documentの下位項目ですので、更に字下げをします。ここでは目次と関連する項目として以下の4つを紹介します。\n\ntoc: 目次の出力有無\n\nデフォルトはFALSE、目次を出力する際はTRUEにします。\n\ntoc_depth: 目次の深さを指定\n\nデフォルトは3であり、これはどのレベルの見出しまで目次に含むかをしてします。toc_depth: 2なら##見出しまで目次に出力されます\n\ntoc_float: 目次のフローティング\n\nデフォルトはFALSEです。これをTRUEにすると、目次は文書の左側に位置するようになり、文書をスクロールしても目次が付いてきます。\n\nnumber_sections: 見出しに通し番号を付けるか\n\nデフォルトはFALSEです。これをTRUEにすると、見出しに通し番号が付きます。むろん、付いた通し番号は目次でも出力されます。\n\n\n\n\n23.5.2 コードのハイライト\n　R Markdownの場合、コードチャンク内のコードの一部に対して自動的に色付けを行います。たとえば、本書の場合、関数名は緑、引数は赤、文字列は青といった形です。これはコードの可読性を向上させる効果もあります。この色付けの詳細はhtml_document:のhighlight:から調整できます。\n---\ntitle: \"タイトル\"\nsubtitle: \"サブタイトル\"\nauthor: \"作成者名\"\ndate: \"最終修正: `r Sys.Date()`\"\noutput:\n  html_document:\n    highlight: \"tango\"\n---\nR Markdown 2.3の場合、使用可能なテーマは以下の10種類です。自分の好みでハイライトテーマを替えてみましょう。\n\n\n\nhighlightの値\n出力結果\n\n\n\n\n\"default\"\n\n\n\n\"tango\"\n\n\n\n\"pygments\"\n\n\n\n\"kate\"\n\n\n\n\"monochrome\"\n\n\n\n\"espresso\"\n\n\n\n\"zenburn\"\n\n\n\n\"haddock\"\n\n\n\n\"breezedark\"\n\n\n\n\"textmate\""
  },
  {
    "objectID": "rmarkdown.html#sec-rmarkdown_japanese",
    "href": "rmarkdown.html#sec-rmarkdown_japanese",
    "title": "23  R Markdown [基礎]",
    "section": "23.6 日本語が含まれているPDFの出力",
    "text": "23.6 日本語が含まれているPDFの出力\n　日本語が含まれているPDF出力には片桐智志さんの{rmdja}パッケージが提供するテンプレが便利です。{rmdja}パッケージの詳細は公式レポジトリに譲りますが、ここでは簡単な例をお見せします。以下の内容は自分のPCにLaTeX環境が導入されている場合を想定しています5。\n　まずは{rmdja}のインストールからです。CRANに登録されていたいため、GitHub経由でインストールします。\n# remotes::の代わりにdevtools::も可\n# pacman::p_install_gh()も可\nremotes::install_github('Gedevan-Aleksizde/rmdja')\n次はR Markdown文書を作成しますが、RStudioのFile &gt; New File &gt; R Markdown …を選択します。左側のFrom Templateを選択し、pdf article in Japaneseを選択します。OKをクリックするとサンプル文書が表示されるので、YAMLヘッダー以下の内容を修正するだけです。図表番号などの相互参照（corss reference）が初回Knitでは反映されない場合がありますが、2回目からは表示されます。"
  },
  {
    "objectID": "rmarkdown2.html#rmakrdown2-slide",
    "href": "rmarkdown2.html#rmakrdown2-slide",
    "title": "24  R Markdown [応用]",
    "section": "24.1 スライド作成",
    "text": "24.1 スライド作成\n　R Markdownを使えば、スライドを作成することもできる。代表的なパッケージは{xaringan}がある。R Markdown界隈の中心人物の一人であるYihui Xie氏が開発したパッケージだ。出力フォーマットはHTMLがデフォルトであるため、インタラクティブなスライドが作成できる。また、それをPDFに印刷することもできるためインターネットが使えない状況でもPDFリーダーさえあれば、どこでもプレゼンテーションができる。\n\n公式解説ページ：https://bookdown.org/yihui/rmarkdown/xaringan.html"
  },
  {
    "objectID": "rmarkdown2.html#rmakrdown2-book",
    "href": "rmarkdown2.html#rmakrdown2-book",
    "title": "24  R Markdown [応用]",
    "section": "24.2 書籍",
    "text": "24.2 書籍\n　あなたが今見ている『私たちのR』はウェブ書籍であるが、このようなウェブ書籍もR Markdownで作れる。{bookdown}パッケージを使えば、簡単にウェブ書籍が作成でき、HTMLフォーマットだけでなく、PDF、ePubフォーマットでも出力できる。現在、Rに関連するほとんどのウェブ書籍は{bookdown}か第25章で紹介するQuartoで作成されたものだ1。\n\n公式解説ページ：https://bookdown.org/yihui/bookdown/"
  },
  {
    "objectID": "rmarkdown2.html#rmakrdown2-homepage",
    "href": "rmarkdown2.html#rmakrdown2-homepage",
    "title": "24  R Markdown [応用]",
    "section": "24.3 ホームページ",
    "text": "24.3 ホームページ\n　R Markdownのデフォルト出力フォーマットはHTMLであり、我々が見る多くのウェブサイトもまた、HTMLフォーマットだ。つまり、R Markdownを使えば、HTML文法を知らなくてもMarkdown記法だけでホームページも簡単に作成できる。単に文書と図表のみを掲載するホームページならWordpressやWixなどのCMS（content management system）が便利かも知れないが、Rのコードを埋め込むことまで考えれば、R Markdownの方が便利だろう。R Markdownでのホームページ作成をサポートする代表なパッケージとしては{distill}と{blogdown}がある。前者の方が軽量かつ簡単であるが、機能に限界がある。後者はhugoというウェブサイトフレームワークをベースとしているため、拡張機能やテーマなどが豊富である一方、{distill}よりはやや難しい（それでも自分でゼロベースでウェブサイトを作るよりは遥かに簡単かつ効率的だ）。また、ホームページ内の各ページは同じR Markdown文法で作成されるので、移行作業もさほど難しくないだろう。\n\n{distill}の公式解説ページ：https://rstudio.github.io/distill/website.html\n{blogdown}の公式解説ページ：https://bookdown.org/yihui/blogdown/"
  },
  {
    "objectID": "rmarkdown2.html#rmakrdown2-cv",
    "href": "rmarkdown2.html#rmakrdown2-cv",
    "title": "24  R Markdown [応用]",
    "section": "24.4 履歴書",
    "text": "24.4 履歴書\n　R Markdownを使えば履歴書も作れる。日本で使われる表形式の履歴書フォーマットは対応していないが、欧米スタイル（？）の履歴書（curriculum vitae; CV）は{vitae}パッケージで作成できる。デフォルトでもいくつかのテンプレが用意されているが、自分で新しいテンプレを作ることも可能だ。\n\n公式解説ページ：https://pkg.mitchelloharawild.com/vitae/index.html"
  },
  {
    "objectID": "rmarkdown2.html#rmakrdown2-package",
    "href": "rmarkdown2.html#rmakrdown2-package",
    "title": "24  R Markdown [応用]",
    "section": "24.5 パッケージ開発",
    "text": "24.5 パッケージ開発\n　Rでパッケージを作るのは自作関数以上に面倒だ。今はパッケージ開発をサポートしてくれる様々なパッケージが公開されているため、昔に比べるとだいぶ楽になった。それでも、ちゃんとした（？）パッケージを使うことになると、{devtools}、{usethis}、{roxygen2}、{testthat}、{pkgdown}といった様々なパッケージを駆使する必要がある。これらのパッケージの使い方はかなり膨大であり、詳細は別の書籍に譲りたいが、簡単なパッケージを使うだけなら{fusen}のみでも十分だ。{fusen}のいいところは1枚のR Markdownファイルでパッケージ開発ができる点だ。たとえば「description」というラベルのチャンクではパッケージの情報が、「function-関数名」というラベルのチャンクには自作関数、「examples-関数名」には当該関数の例題コード、「tests-関数名」には当該関数の検証用コードが入る。そしてこの.Rmdファイルをビルド（build）するだけで、パッケージが出来上がる2。各関数のマニュアルも自動的に作成され、パッケージ専用のホームページまで作成してくれる。まだ開発途上のパッケージであるが、今後、{devtools}、{usethis}、{roxygen2}、{testthat}、{pkgdown}を使わなくてもそれなりの規模のパッケージが作成できるようになるかも知れない。\n\n公式解説ページ：https://thinkr-open.github.io/fusen/"
  },
  {
    "objectID": "rmarkdown2.html#rmakrdown2-tutorial",
    "href": "rmarkdown2.html#rmakrdown2-tutorial",
    "title": "24  R Markdown [応用]",
    "section": "24.6 チュートリアル",
    "text": "24.6 チュートリアル\n　インタラクティブなRチュートリアルもR Markdownで作れる。ウェブページ上でコードを入力すると、その結果が表示される。チュートリアルだからクイズを入れることもできる。また、{gradethis}パッケージとの組み合わせで結果の採点までできる。百聞は一見に如かず、興味のある方は公式ホームページのサンプルを覗いてみよう。{learnr}が提供する機能の多くはチャンクオプションをいじるだけなので、簡単に導入することができる。作成したチュートリアルは一つのパッケージとして配布することも、ウェブサイトとして公開することもできる。\n\n公式解説ページ：https://rstudio.github.io/learnr/"
  },
  {
    "objectID": "rmarkdown2.html#r-markdown生態系の複雑化",
    "href": "rmarkdown2.html#r-markdown生態系の複雑化",
    "title": "24  R Markdown [応用]",
    "section": "24.7 R Markdown生態系の複雑化?",
    "text": "24.7 R Markdown生態系の複雑化?\n　これまで見てきたように様々なパッケージを使うことで、R Markdownの可能性は無限大となる。これを言い換えれば、これらの内容を学習するためには別途のパッケージの使い方を知る必要があることを意味する。これらの問題を解決するために近年注目を集めているものがあり、それが第25章で紹介するQuartoだ。使い方は第23章で紹介したR Markdownと90%以上同じであるが、R以外の言語（Python、Julia、Observable等）が使える点以外にも、ホームページ、書籍、スライドといった様々なフォーマットを一つのパッケージでまとめた優れものである。興味のある読者は第23章の内容を熟知した上、第25章も読んでいただきたい。"
  },
  {
    "objectID": "quarto.html#sec-quarto-intro",
    "href": "quarto.html#sec-quarto-intro",
    "title": "25  Quarto入門",
    "section": "25.1 Quartoとは",
    "text": "25.1 Quartoとは\n　QuartoはPandocベースのオープンソース科学/技術出版システムである。簡単にいうと、R MarkdownのようにRコードと結果、文章を一つの文書として（HTML/PDF/Microsoft Word等）まとめてくれるものだ。目的が同じである以上、R Markdownを問題なく使いこなしているのであれば、Quartoの学習はさほど難しくないし、そもそもQuartoに乗り換える必要もあまりない。ただし、筆者（宋）は今後、QuartoがR Markdownに代わる主流になると考えているため（そうでないと考えている方も大勢にいる）、本章ではQuartoを簡単に紹介したい。\n　むろん、別の名前が付いてある以上、Quarto = R Markdownではない。文法などの違いは本章の中盤以降に説明するとして、まず両者の技術的な面での違いを紹介する。\n　一点目は使用可能なエンジンだ。たとえば、R Markdownは.Rmdをknitrエンジンを経由し、コードとその結果物が含まれた.mdファイルを生成する。ここで生成された.mdファイルはPandocを経由して最終的にはHTML、PDF、Microsoft Wordファイルに変換される（ 図 25.1 (a) ）。Quartoも基本的に同じである。ただし、knitrエンジン以外にもPython、Juliaで多用されるJupyterやJavaScripベースのObservableもエンジンとして使用可能という特徴がある（ 図 25.1 (b) ）。使用可能なエンジンが多いということはRコード以外にもPyhton、Julia、Observable JSのコードも使えるといったメリットがある。また、使用可能なエンジンは今後のアップデートで追加される可能性もある。ちなみにQuartoにはMermaid、GraphVizが実装されており、以下のようなダイアグラム作成も別途の設定なしで簡単にできる。\n\n\n\n\n\n\n\n\nflowchart LR\n  A[.Rmd] --&gt; B[knitr]\n  B --&gt; C[.md]\n  C --&gt; D{Pandoc}\n  D --&gt; E(HTML)\n  D --&gt; F(PDF)\n  D --&gt; G(Microsoft Word)\n  D --&gt; H(Etc.)\n\n\n(a) R Markdownの場合\n\n\n\n\n\n\n\n\n\n\n\nflowchart LR\n  A[.qmd] --&gt; B[knitr]\n  A --&gt; C[Jupyter]\n  A --&gt; D[Observable JS]\n  A --&gt; E[Etc]\n  B --&gt; F[.md]\n  C --&gt; F\n  D --&gt; F\n  E --&gt; F\n  F --&gt; G{Pandoc}\n  G --&gt; H(HTML)\n  G --&gt; I(PDF)\n  G --&gt; J(Microsoft Word)\n  G --&gt; K(Etc.)\n\n\n(b) Quartoの場合\n\n\n\n\n\n図 25.1: R Markdown/Quartoから文書が生成されるまで\n\n\n　二点目は様々なフォーマットが統合されている点だ。R Markdownだと文書を作成する場合は{rmarkdown}パッケージ、ホームページを作成するなら{blogdown}パッケージ、スライドを作成するなら{xaringan}等のパッケージを使うことになる。しかし、Quartoはプラスアルファのパッケージを使わず、Quarto単体で様々なフォーマットが作成できる。ここまで聞くとR Markdownの方がより拡張性に優れているように見えるが、QuartoもまたQuarto Extensionを通じて様々な拡張機能が導入できる1。また、Lua言語の知識があれば、自分で拡張機能を作成することができる。\n　三点目はIDEだ。R Markdownの場合、ほぼRStudio一度（他のIDEでももちろん出来る）であったが、QuartoだとVisual Studio CodeやJupyter、NeoVim、Emacs、SublimeTextも使用可能であり、RStudioとほぼ変わらない使用経験を提供する（ 図 25.2 ）。\n\n\n\n\n\n\nRStudio\n\n\n\n \n\n\n\n\nVS Code\n\n\n\n\n\n\n\nJupyter\n\n\n\n \n\n\n\n\nNeoVim\n\n\n\n図 25.2: 各種IDE（出典はQuarto公式ホームページ）\n\n\n　しかし、QuartoはR Markdownの上位互換でもなく、R Markdownを代替するものでもないことには注意されたい（参考）。つまり、既存のR Markdownを問題なく使っているのであれば、Quartoへの移行は不要だろう。現在のところ、QuartoはR Markdown生態系を一つに統合したものに近く、文法などもほぼ同じであるため、移行のために新しい事をゼロベースから勉強する必要はほぼない。"
  },
  {
    "objectID": "quarto.html#sec-quarto-setup",
    "href": "quarto.html#sec-quarto-setup",
    "title": "25  Quarto入門",
    "section": "25.2 セットアップ",
    "text": "25.2 セットアップ\n　Quartoを使う前に以下の3つの項目を確認する必要がある。1つ目はQuarto CLIのインストールだ。Quarto CLIは公式ホームページからダウンロードできる（https://quarto.org/docs/get-started/）。macOS、Linux、Windows版が提供されているため、自分のOSに合わせてダウンロードし、インストールしておこう。2つ目はRStudioを最新バージョンにアップデートすることだ。RStudioで本格的にQuartoが使えるようになったのはRStudio 2022.07からである。基本的に現時点での最新版をインストールしておけば問題ないだろう。2つ目はRパッケージ{quarto}のインストールだ。こちらはインストールするだけで十分で、別途読み込む必要がない。"
  },
  {
    "objectID": "quarto.html#sec-quarto-howtouse",
    "href": "quarto.html#sec-quarto-howtouse",
    "title": "25  Quarto入門",
    "section": "25.3 簡単な使い方",
    "text": "25.3 簡単な使い方\n　Quartoは基本的にR Markdownと同じ感覚で使える。たとえば、R Markdownで新しい文書を作成する際はRStudioのFile &gt; New File &gt; R Markdown…を選択するが、QuartoはFile &gt; New File &gt; Quarto Document…を選択する2くらいの違いだ。ただし、作成したファイルを文書に変換するときにはR Markdownだと「Knit」ボタンをクリックしたが、QuartoはKnit以外にもJupyterやObservableなども使用可能であるため、代わりに「Render」ボタンをクリック3しよう。\n　以下ではR MarkdownとQuartoの書き方の違いについて解説する。すべてを列挙することはできないため、よく使う機能の相違点のみを紹介する。より詳しく知りたい場合はQuartoの公式ホームページを参照すること。\n\n25.3.1 チャンクオプションの付け方\n　現時点においてR Markdownと同じ書き方でも問題ない。つまり、```{r}のrの後ろにチャンクのラベル、オプションを付けても問題なく作動する。\n```{r fig-scatter1, fig.height = 5, fig.width = 7, fig.cap = \"図の例\", cache = TRUE}\niris %&gt;%\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) %&gt;%\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\")\n```\n　しかし、Quarto特有の書き方として、チャンクオプションを{r}内に書かず、チャンク内に#|で書く方法がある。#|とオプションの間には半角スペースを入れる必要がある。チャンクオプションが多くなると、コードが非常に長くなることもあるので、こちらの書き方が読みやすいだろう（しかも、{r}内のオプションは改行もできない）。ちなみに、チャンクのラベルのオプションはlabel:で指定する必要がある。\n```{r}\n#| label: fig-scatter1\n#| fig-cap: \"図の例\"\n#| fig-height: 5\n#| fig-width: 7\n#| fig-align: \"center\"\n#| cache: true\niris %&gt;%\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) %&gt;%\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\")\n```\n　これらのチャンクオプションはR Markdownとほぼ同じであるものの、一部名称が異なるオプションがある。たとえば、図の幅を指定するR Markdownのfig.widthは、Quartoだとfig-widthを使う。また、実引数としてTRUEとFALSEは、通常のYAMLと同様、trueとfalseを使用する。これはYAMLヘッダーでも同じだ。他にも仮引数 = 実引数でなく、仮引数: 実引数で書くことにも注意しよう。\n\n\n25.3.2 相互参照について\n　図表の相互参照も方法もやや異なる。たとえば、チャンクのラベルがfig-scatter1という図がある場合、R Markdownでは図 \\@ref(fig-scatter1)、またはFigure \\@ref(fig-scatter1)と書く必要があった。しかし、Quartoだと@fig-scatter1だけで十分である。以下の例を見てみよう。\nInput:\n以下の @fig-scatter1 は萼片の長さと幅を品種ごとに分けて示した散布図である。\n\n```{r}\n#| label: fig-scatter1\n#| echo: false\n#| fig-cap: \"萼片の長さと幅の関係（品種別）\"\niris %&gt;%\n  mutate(Species2 = recode(Species,\n                           \"setosa\"     = \"セトナ\",\n                           \"versicolor\" = \"バーシクル\",\n                           \"virginica\"  = \"バージニカ\")) %&gt;%\n  ggplot() +\n  geom_point(aes(x = Sepal.Length, y = Sepal.Width, color = Species2)) +\n  labs(x = \"萼片の長さ (cm)\", y = \"萼片の幅 (cm)\", color = \"品種\")\n```\nOutput:\n　以下の 図 25.3 は萼片の長さと幅を品種ごとに分けて示した散布図である。\n\n\n\n\n\n図 25.3: 萼片の長さと幅の関係（品種別）\n\n\n\n\n　図だけでなく、表や章でも同じやり方で相互参照ができる。ただし、一点注意が必要である。相互参照に使うチャンクのラベルに制約があることだ。R Markdownではチャンクラベルの制限がなかったものの、Quartoの場合ラベルはsec-（章・節など）、fig-（図）、tbl-（表）で始まる必要がある。図表はチャンクラベルで指定できるが、章や節などの見出しの場合、以下のようにラベルを指定する。この書き方はチャンク以外の図表にラベルを付ける時も同様だ（後述）。\n## Rの素晴らしさについて {#sec-aboutR}\n　また、Quartoの既定値のままだと「Figure X」と出力される。これを「図 X」の形式にしたい場合はYAMLヘッダーにlang: jaを追加するか、language:で別途指定する必要がある4。\n\n\n25.3.3 コールアウト\n　Quartoでは5種類のコールアウト（callout）が提供される。以下はコールアウト作成のコードとその結果である。:::{.callout-*}と:::間の内容が一つのブロック（コールアウト）となり、##でブロックのタイトルを指定する。また、{}内の*の箇所にはブロックの見た目を指定し、現在、note、warning、important、tip、cautionの5種類がある。\n\nnotewarningimportanttipcaution\n\n\n\n\nInput:\n:::{.callout-note}\n## Rはみんなの友達!\n\n末永くよろしくね!\n:::\n\n\n\nOutput:\n\n\n\n\n\n\nRはみんなの友達!\n\n\n\n末永くよろしくね!\n\n\n\n\n\n\n\n\nInput:\n:::{.callout-warning}\n## Rはみんなの友達!\n\n末永くよろしくね!\n:::\n\n\n\nOutput:\n\n\n\n\n\n\nRはみんなの友達!\n\n\n\n末永くよろしくね!\n\n\n\n\n\n\n\n\nInput:\n:::{.callout-important}\n## Rはみんなの友達!\n\n末永くよろしくね!\n:::\n\n\n\nOutput:\n\n\n\n\n\n\nRはみんなの友達!\n\n\n\n末永くよろしくね!\n\n\n\n\n\n\n\n\nInput:\n:::{.callout-tip}\n## Rはみんなの友達!\n\n末永くよろしくね!\n:::\n\n\n\nOutput:\n\n\n\n\n\n\nRはみんなの友達!\n\n\n\n末永くよろしくね!\n\n\n\n\n\n\n\n\nInput:\n:::{.callout-caution}\n## Rはみんなの友達!\n\n末永くよろしくね!\n:::\n\n\n\nOutput:\n\n\n\n\n\n\nRはみんなの友達!\n\n\n\n末永くよろしくね!\n\n\n\n\n\n\n\n　.callout-*の後にcollapse=\"true\"を付けるとコールアウトの本文を隠すことができる（見出しをクリックすると本文が表示される）。\n\n\nInput:\n:::{.callout-note collapse=\"true\"}\n## Rはみんなの友達!（クリック）\n\n末永くよろしくね!\n:::\n\n\n\nOutput:\n\n\n\n\n\n\nRはみんなの友達!（クリック）\n\n\n\n\n\n末永くよろしくね!\n\n\n\n\n\n　また、.callout-*の後にicon=\"false\"を付けると見出しの左にあるアイコンを消すことができる。\n\n\nInput:\n:::{.callout-warning icon=\"false\"}\n## Rはみんなの友達!\n\n末永くよろしくね!\n:::\n\n\n\nOutput:\n\n\n\n\n\n\nRはみんなの友達!\n\n\n\n末永くよろしくね!\n\n\n\n\n\n\n25.3.4 段組み\n　Quartoの段組みは非常に簡単だ。::::{.columns}と::::で囲まれた領域内の内容が段組みの対象となり、:::{.column}と:::で囲まれた領域が一つ一つの段となる。また、.columnの次にwidth引数を追加することで、段の幅を指定することもできる。以下はコードのその結果を2段構成で示した例だ。\nInput:\n::::{.columns}\n:::{.column width=56%}\n**コード:**\n\n```{r}\n#| eval: false\nx &lt;- c(1, 2, 3, 1, 2)\ny &lt;- c(\"A\", \"A\", \"A\", \"B\", \"B\")\n\npaste0(x, y)\n```\n:::\n\n:::{.column width=2%}\n:::\n\n:::{.column width=42%}\n**結果:**\n\n```{r}\n#| echo: false\nx &lt;- c(1, 2, 3, 1, 2)\ny &lt;- c(\"A\", \"A\", \"A\", \"B\", \"B\")\n\npaste0(x, y)\n```\n:::\n::::\nOutput:\n\n\nコード\n\nx &lt;- c(1, 2, 3, 1, 2)\ny &lt;- c(\"A\", \"A\", \"A\", \"B\", \"B\")\n\npaste0(x, y)\n\n\n\n\n結果\n\n\n[1] \"1A\" \"2A\" \"3A\" \"1B\" \"2B\"\n\n\n\n\n\n\n25.3.5 パネル\n　パネルは段組みのように複数の内容を同じ行に出力する機能であるが、段組みは左右に並べる一方、パネルが異なるページへ出力する。たとえば、データセットの作成と、そのデータを使った作図のコードを示す場合、2つのチャンクを横に並べるには幅が狭いかも知れない。この場合、使えるのがパネル機能だ。使い方は段組みより簡単で、:::{.panel-tabset}と:::間に入力された内容がパネル内容になる。各パネルのタイトルは##見出しで指定でき、これが各パネルの区切りにもなる。\nInput:\n:::{.panel-tabset}\n## データ\n\n```{r}\nlibrary(tidyverse)\n\nmy_data &lt;- tibble(City = c(\"東京\", \"北京\", \"ソウル\"),\n                  Pop  = c(1396, 2154, 978))\n\nmy_data\n```\n\n## プロット\n\n```{r}\n#| fig-width: 8\n#| fig-height: 4\nmy_data %&gt;%\n  mutate(City = fct_inorder(City)) %&gt;%\n  ggplot(aes(x = City, y = Pop)) +\n  geom_col() + # geom_bar(stat = \"identity\") もOK\n  labs(x = \"都市\", y = \"人口（万人）\") +\n  theme_bw(base_size = 14)\n```\n\n:::\nOutput:\n\nデータプロット\n\n\n\nlibrary(tidyverse)\n\nmy_data &lt;- tibble(City = c(\"東京\", \"北京\", \"ソウル\"),\n                  Pop  = c(1396, 2154, 978))\n\nmy_data\n\n# A tibble: 3 × 2\n  City     Pop\n  &lt;chr&gt;  &lt;dbl&gt;\n1 東京    1396\n2 北京    2154\n3 ソウル   978\n\n\n\n\n\nmy_data %&gt;%\n  mutate(City = fct_inorder(City)) %&gt;%\n  ggplot(aes(x = City, y = Pop)) +\n  geom_col() + # geom_bar(stat = \"identity\") もOK\n  labs(x = \"都市\", y = \"人口（万人）\") +\n  theme_bw(base_size = 14)\n\n\n\n\n\n\n\n\n\n\n\n\n\n25.3.6 図表について\n　R Markdown/Quarto関係なく多くの図は{ggplot2}、{lattice}、Base Rなどで作成され、表は{knitr} + {kableExtra}、{gt}などで作成される。しかし、通常のMarkdown文法で表を作ったり、図を挿入したりするケースも多いだろう。QuartoはMarkdown文法の作成/挿入された図表のカスタマイズもより柔軟だ。\n　たとえば、図の大きさは![]()の後ろに{}を付け、widthやheight引数を指定することで修正できる。たとえば、図の幅を100ピクセルにする場合はwidth=100pxで良い。サイズの指定方法はピクセル（px; 省略可）以外にも画面の幅に対する割合（例：50%）、インチ（例：4in）もできる。\n\nサイズ調整前サイズ調整後\n\n\nInput:\n![『私たちのR』ロゴ](http://www.jaysong.net/RBook/Figs/favicon.png)\nOutput:\n\n\n\n『私たちのR』ロゴ\n\n\n\n\nInput:\n![『私たちのR』ロゴ](http://www.jaysong.net/RBook/Figs/favicon.png){width=100px}\nOutput:\n\n\n\n『私たちのR』ロゴ\n\n\n\n\n\n　他にも、![Alt Text](Image Path)で挿入される図の場合、R Markdownでは大きさの調整や中央揃えが面倒だ。しかし、Quartoの場合、後ろに{}を入れることでいくつかの修正ができる。\n\n左揃え中央揃え右揃え\n\n\nInput:\n![『私たちのR』ロゴ（左揃え）](http://www.jaysong.net/RBook/Figs/favicon.png){fig-align=\"left\"}\nOutput:\n\n\n\n『私たちのR』ロゴ（左揃え）\n\n\n\n\nInput:\n![『私たちのR』ロゴ（中央揃え）](http://www.jaysong.net/RBook/Figs/favicon.png){fig-align=\"center\"}\nOutput:\n\n\n\n『私たちのR』ロゴ（中央揃え）\n\n\n\n\nInput:\n![『私たちのR』ロゴ（右揃え）](http://www.jaysong.net/RBook/Figs/favicon.png){fig-align=\"right\"}\nOutput:\n\n\n\n『私たちのR』ロゴ（右揃え）\n\n\n\n\n\n　他にも複数のグラフを並べることもR Markdownに比べ、簡単にできる。横に並べるなら段組みでもよいが、:::{layout-ncol}がより楽だ。ncolの代わりにnrowも指定できる。以下のコードは図を3列配置する例だ（モバイルデバイスの場合、縦に並ぶように表示される）。\nInput:\n:::{layout-ncol=3}\n![左の猫](http://www.jaysong.net/RBook/Figs/favicon.png)\n\n![中央の猫](http://www.jaysong.net/RBook/Figs/favicon.png)\n\n![右の猫](http://www.jaysong.net/RBook/Figs/favicon.png)\n:::\nOutput:\n\n\n\n\n\n\n左の猫\n\n\n\n\n\n\n\n中央の猫\n\n\n\n\n\n\n\n右の猫\n\n\n\n\n\n　図の相互参照とためのラベルは![]()の後ろの{}内に#fig-で指定できる。並べた図にラベルを付けることもできる。\nInput:\n* 複数の図の相互参照: @fig-three-cats\n* 個別の図の相互参照: @fig-cat1\n\n:::{#fig-three-cats layout-ncol=3}\n![左の猫](http://www.jaysong.net/RBook/Figs/favicon.png){#fig-cat1}\n\n![中央の猫](http://www.jaysong.net/RBook/Figs/favicon.png){#fig-cat2}\n\n![右の猫](http://www.jaysong.net/RBook/Figs/favicon.png){#fig-cat3}\n\n3匹の猫\n:::\nOutput:\n\n複数の図の相互参照: 図 25.4\n個別の図の相互参照: 図 25.4 (a)\n\n\n\n\n\n\n\n\n(a) 左の猫\n\n\n\n\n\n\n\n(b) 中央の猫\n\n\n\n\n\n\n\n(c) 右の猫\n\n\n\n\n図 25.4: 3匹の猫\n\n\n　:::{layout-ncol}を使えば、複数の表を並べることもできる。相互参照についても同じだが、ラベル名は#fig-の代わりに#tbl-を使う必要がある。\nInput:\n　@tbl-two-tables は、東アジアとヨーロッパ主要都市の人口、面積、人口密度の一覧である。ただし、 @tbl-east-asia の東京は23区でなく、東京都全域であることに注意されたい。\n\n::: {#tbl-two-tables layout-ncol=2}\n| Name    | Pop.  | Area   | Density |\n|:--------|------:|-------:|--------:|\n| Tokyo   | 1,403 |  2,194 |  6,397  |\n| Beijing | 2,170 | 16,410 |  1,323  |\n| Seoul   |   949 |    605 | 15,688  |\n\n: East Asia {#tbl-east-asia}\n\n| Name   | Pop.  | Area  | Density |\n|:-------|------:|------:|--------:|\n| London | 943   | 1,569 |  5,354  |\n| Berlin | 367   |   892 |  4,114  |\n| Paris  | 215   |   105 | 20,382  |\n\n: Europe {#tbl-europe}\n\n首都の人口（万人）、面積（km&lt;sup&gt;2&lt;/sup&gt;）、人口密度（人/km&lt;sup&gt;2&lt;/sup&gt;）\n:::\nOutput:\n　表 25.1 は、東アジアとヨーロッパ主要都市の人口、面積、人口密度の一覧である。ただし、 表 25.1 (a) の東京は23区でなく、東京都全域であることに注意されたい。\n\n\n表 25.1: 首都の人口（万人）、面積（km2）、人口密度（人/km2）\n\n\n\n\n(a) East Asia\n\n\nName\nPop.\nArea\nDensity\n\n\n\n\nTokyo\n1,403\n2,194\n6,397\n\n\nBeijing\n2,170\n16,410\n1,323\n\n\nSeoul\n949\n605\n15,688\n\n\n\n\n\n\n(b) Europe\n\n\nName\nPop.\nArea\nDensity\n\n\n\n\nLondon\n943\n1,569\n5,354\n\n\nBerlin\n367\n892\n4,114\n\n\nParis\n215\n105\n20,382\n\n\n\n\n\n\n　また、この機能はチャンクで生成された図についても使用可能だ。チャンクオプションに#| layout-ncol: 2を追加すると、2つの図が横に並ぶことになる。ただし、相互参照の際、個別の図のラベルはこちら側では指定できず、自動生成される。たとえば、プロット群のラベルがfig-two-plotsなら1つ目の図のラベルはfig-two-plots-1、2つ目はfig-two-plots-2となる。\nInput:\n\n　@fig-two-plots は2つの散布図であり、 @fig-two-plots-1 は速度と停止距離との関係、 @fig-two-plots-2 は気温と気圧の関係を示す。\n\n```{r}\n#| label: fig-two-plots\n#| echo: false\n#| layout-ncol: 2\n#| fig-cap: \"散布図の例\"\n#| fig-subcap: \n#|   - \"速度と停止距離\"\n#|   - \"気温と気圧\"\ncars %&gt;%\n  ggplot(aes(x = speed, y = dist)) +\n  geom_point() +\n  labs(x = \"Speed (mph)\", y = \"Stopping distance (ft)\")\n\npressure %&gt;%\n  ggplot(aes(x = temperature, y = pressure)) +\n  geom_point() +\n  labs(x = \"Temperature (Celsious)\", y = \"Pressure (mm)\")\n```\nOutput:\n　図 25.5 は2つの散布図であり、 図 25.5 (a) は速度と停止距離との関係、 図 25.5 (b) は気温と気圧の関係を示す。\n\n\n\n\n\n\n\n(a) 速度と停止距離\n\n\n\n\n\n\n\n(b) 気温と気圧\n\n\n\n\n図 25.5: 散布図の例\n\n\n\n\n25.3.7 ハイパーリンクのターゲット\n　Markdownのハイパーリンクは以下のように書く。\n[ここ](https://www.jaysong.net)をクリックすると宋のホームページへ移動します。\n　「ここ」の文字をクリックすると宋のホームページへ飛ばされるコードである、R Markdownも、Quartoもデフォルトではそのウィンドウ/タブを使うことになる5。これを新しいウィンドウ/タブで開かせるためにはやむを得ずHTMLタグを使う必要がある。\n&lt;a href=\"https://www.jaysong.net\" target=\"_blank\"&gt;ここ&lt;/a&gt;をクリックすると宋のホームページへ移動します。\n　しかし、Quartoだと通常のMarkdown記法を使うことができる。[]()の後ろに{target=\"_blank\"}を付けるだけだ。実は書く手間としては若干軽減された程度であるが、地味に嬉しい機能だ。\n[ここ](https://www.jaysong.net){target=\"_blank\"}をクリックすると宋のホームページへ移動します。"
  },
  {
    "objectID": "quarto.html#yamlヘッダー",
    "href": "quarto.html#yamlヘッダー",
    "title": "25  Quarto入門",
    "section": "25.4 YAMLヘッダー",
    "text": "25.4 YAMLヘッダー\n　YAMLヘッダーの場合、R Markdownの書き方と大きく変わらないものの、論理値（TRUEとFALSE）の書き方が異なる点には注意されたい。R MarkdownはRに因んでTRUEとFALSEを使うが、QuartoはYAML本来の書き方であるtrueとfalseを使用する。\n　また、Quarto独自のオプションも多数用意されているので、詳細はQuarto公式ページを確認してみよう。"
  },
  {
    "objectID": "quarto.html#quartoを知り尽くす",
    "href": "quarto.html#quartoを知り尽くす",
    "title": "25  Quarto入門",
    "section": "25.5 Quartoを知り尽くす",
    "text": "25.5 Quartoを知り尽くす\n　Quartoは発展途中であり、以上の内容は1ヶ月後は古い資料になっているのかも知れない。本記事もなるべく最新情報をフォローしていく予定だが、Quartoの詳細を含め、最新情報は以下のページを参照されたい。\n\nQuarto公式HP：https://quarto.org/docs/guide/\nrstudio::conf 2022 Workshopの資料：https://rstudio-conf-2022.github.io/get-started-quarto/"
  },
  {
    "objectID": "renv.html#分析環境と再生可能な研究",
    "href": "renv.html#分析環境と再生可能な研究",
    "title": "26  分析環境の管理",
    "section": "26.1 分析環境と再生可能な研究",
    "text": "26.1 分析環境と再生可能な研究\n　{renv}はreproducible environments（再生可能な分析環境）の略で、現時点での分析環境を保存し、再生してくれるパッケージだ。なぜ分析環境の再生可能性が重要だろうか。いくつかの例を紹介しよう。\n　たとえば、古いパッケージではできなかったものが、今はできるようになっている可能性がある。たとえば、{ggplot2}のgeom_pointrange()は点（点推定値）と線（区間）を表現する幾何オブジェクトであるが、昔は点と垂直線のみが引けた。つまり、マッピングは常にx、y、ymin、ymaxに対して行う必要があった。この区間を垂直線でなく、水平線にしたい場合は、coord_flip()で座標系を90度回転する必要があった。しかし、今の{ggplot2}は、xminとxmaxにもマッピングができるため、coord_flip()が不要となる。むろん、昔の書き方もまだ使えるのでこのケースは分析の再現という観点からはあまり問題にならないだろう。\n　問題は昔はできたものの、今はできなくなっているケースだ。たとえば、{dplyr}のrowwise()関数は、現在は華麗に復活したものの、実は無くなる予定の関数だった。また、{tidyr}のgather()とspread()関数は昔のコードではよく見るが、近い将来、無くなる予定である（現在はpivot_longer()とpivot_wider()が使われている）。\n　また、関数そのものは残っていても、仕様が変わることによって仮引数名、実引数の使用可能なクラスが異なる場合もある。これは開発途上のパッケージでよく見る現象だ。たとえば、筆者（宋）が愛用するパッケージの{marginaleffects}では推定したモデルの予測値を計算するpredictions()関数と、限界効果を計算するslopes()関数が用意されている。どの関数も戻り値のクラスはデータフレーム型だ。しかし、predictions()で計算された予測値はpredictedという名の列として表示され、slopes()で計算された限界効果の点推定値はdydxという名の列だった。現在は、どの関数を使っても予測値・限界効果の点推定値はestimateという名で統一されている。単に、計算結果をデータフレームとして出力するだけなら問題ないが（見た目は変わるものの、エラーは吐かない）、計算結果を使用して作図を行う場合は話が変わってくる。昔のコードではpredicted・dydx列でマッピングした図が、現在はエラーを出してしまうのだ。\n　Rとその生態系は毎日のように更新され、改善されていく。これはRのメリットでもあるが、デメリットでもあり、昔のコード（legacy code）がもはや動かない可能性もある。また、近年、学術の界隈でも再現可能性、再生可能性が重要視されている。今すぐに{renv}をインストールしておく理由としては十分すぎる。\n\npacman::p_load(renv)"
  },
  {
    "objectID": "renv.html#分析環境の保存",
    "href": "renv.html#分析環境の保存",
    "title": "26  分析環境の管理",
    "section": "26.2 分析環境の保存",
    "text": "26.2 分析環境の保存\n　{renv}を使った分析環境の保存/再現はプロジェクト機能の使用を前提としている。プロジェクト機能を使わない場合でも{renv}は使用可能だが、相性が良くない。{renv}の使用と関係なく、プロジェクトは非常に便利な機能なので常に使用するように心がけよう。プロジェクト機能の詳細は第?sec-rbasic-project章を参照を参照されたい。\n　プロジェクトを開いた状態（RStudioの右上に「Project: (none)」と表示されたらプロジェクト未使用中）で、現在の分析環境を保存する方法から紹介する。以下は架空の例であるが、renv_testという名のプロジェクトにmy_script.Rというファイルが存在し、ファイルの中身は以下の通りであるとする。\n\n\n\nmy_script.R\n\npacman::p_load(ggdag)\n\n\n　単に{ggdag}を読み込むだけのスクリプトファイルである。この{ggdag}のバージョンを確認してみよう。\n\npackageVersion(\"ggdag\")\n\n\n\n[1] \"0.2.7\"\n\n\n　現在の{ggdag}のバージョンは0.2.7である。実は{ggdag}0.2.7はやや古いバージョンである。現時点での分析環境を保存するためにはinit()関数を使う。{renv}の関数群は使う機会が滅多にないので、コンソール上でrenv::init()と入力しよう。\n\nrenv::init()\n\n\n\n* Discovering package dependencies ... Done!\n* Linking packages into the project library ... [60/60] Done!\nThe following package(s) will be updated in the lockfile:\n\n# CRAN ===============================\n- MASS            [* -&gt; 7.3-58.3]\n- Matrix          [* -&gt; 1.5-3]\n- R6              [* -&gt; 2.5.1]\n- RColorBrewer    [* -&gt; 1.1-3]\n- Rcpp            [* -&gt; 1.0.10]\n- RcppArmadillo   [* -&gt; 0.12.0.1.0]\n- RcppEigen       [* -&gt; 0.3.3.9.3]\n- V8              [* -&gt; 4.2.2]\n- boot            [* -&gt; 1.3-28.1]\n- cli             [* -&gt; 3.6.0]\n- colorspace      [* -&gt; 2.1-0]\n- cpp11           [* -&gt; 0.4.3]\n- curl            [* -&gt; 5.0.0]\n- dagitty         [* -&gt; 0.3-1]\n- digest          [* -&gt; 0.6.31]\n- dplyr           [* -&gt; 1.1.0]\n- fansi           [* -&gt; 1.0.4]\n- farver          [* -&gt; 2.1.1]\n- forcats         [* -&gt; 1.0.0]\n- generics        [* -&gt; 0.1.3]\n- ggdag           [* -&gt; 0.2.7]\n- ggforce         [* -&gt; 0.4.1]\n- ggplot2         [* -&gt; 3.4.1]\n- ggraph          [* -&gt; 2.1.0]\n- ggrepel         [* -&gt; 0.9.3]\n- glue            [* -&gt; 1.6.2]\n- graphlayouts    [* -&gt; 0.8.4]\n- gridExtra       [* -&gt; 2.3]\n- gtable          [* -&gt; 0.3.1]\n- igraph          [* -&gt; 1.4.1]\n- isoband         [* -&gt; 0.2.7]\n- jsonlite        [* -&gt; 1.8.4]\n- labeling        [* -&gt; 0.4.2]\n- lattice         [* -&gt; 0.20-45]\n- lifecycle       [* -&gt; 1.0.3]\n- magrittr        [* -&gt; 2.0.3]\n- mgcv            [* -&gt; 1.8-42]\n- munsell         [* -&gt; 0.5.0]\n- nlme            [* -&gt; 3.1-162]\n- pacman          [* -&gt; 0.5.1]\n- pillar          [* -&gt; 1.8.1]\n- pkgconfig       [* -&gt; 2.0.3]\n- polyclip        [* -&gt; 1.10-4]\n- purrr           [* -&gt; 1.0.1]\n- remotes         [* -&gt; 2.4.2]\n- renv            [* -&gt; 0.17.1]\n- rlang           [* -&gt; 1.1.0]\n- scales          [* -&gt; 1.2.1]\n- stringi         [* -&gt; 1.7.12]\n- stringr         [* -&gt; 1.5.0]\n- systemfonts     [* -&gt; 1.0.4]\n- tibble          [* -&gt; 3.2.0]\n- tidygraph       [* -&gt; 1.2.3]\n- tidyr           [* -&gt; 1.3.0]\n- tidyselect      [* -&gt; 1.2.0]\n- tweenr          [* -&gt; 2.0.2]\n- utf8            [* -&gt; 1.2.3]\n- vctrs           [* -&gt; 0.6.0]\n- viridis         [* -&gt; 0.6.2]\n- viridisLite     [* -&gt; 0.4.1]\n- withr           [* -&gt; 2.5.0]\n\nThe version of R recorded in the lockfile will be updated:\n- R               [* -&gt; 4.2.2]\n\n* Lockfile written to '~/r_projects/renv_test/renv.lock'.\n\nRestarting R session...\n\n* Project '~/r_projects/renv_test' loaded. [renv 0.17.1]\n\n\n　{ggdag}だけでなく、{ggdag}が依存するパッケージの現時点でのバージョンが固定される。実際、{ggdag}の行を見るとバージョンが0.2.7になっている。このrenv_testプロジェクトがどのパッケージを使用するかは{renv}パッケージが自動的に判断してくれる。具体的にはプロジェクトフォルダー内に存在する全ての.R、.Rmd、.qmdファイルをスキャンし、読み込まれているパッケージを抽出する仕組みである2。これらのパッケージ情報はプロジェクトフォルダーに別途保存される。dir()関数を使用し、プロジェクトフォルダーの内部を覗いてみよう。\n\ndir()\n\n\n\n\"my_script.R\"   \"renv\"  \"renv_test.Rproj\"   \"renv.lock\"\n\n\n　普通ならrenv_test.Rprojとmy_script.Rのみ存在するはずだが、renv.lockファイルとrenvという名のフォルダーが生成されている。このrenv.lockにはパッケージのバージョンおよび依存関係の情報が書かれている（開いてみると分かる）。また、renvフォルダーにはそのパッケージがまるごと入っている。"
  },
  {
    "objectID": "renv.html#分析環境の再生",
    "href": "renv.html#分析環境の再生",
    "title": "26  分析環境の管理",
    "section": "26.3 分析環境の再生",
    "text": "26.3 分析環境の再生\n　init()で固定された分析環境情報を再生するためにはどうすればいいだろう。それを解説する前に、プロジェクトを立ち上げていない状態で{ggdag}をアップデートしてみよう。\n\ninstall.packages(\"ggdag\")\n\n　続いて、{ggdag}のバージョンを確認してみる。\n\npackageVersion(\"ggdag\")\n\n\n\n[1] \"0.2.8\"\n\n\n　{ggdag}のバージョンが0.2.8になっている。ここで、RStudioを終了し、先ほど作成したrenv_testプロジェクトをもう一度開いてみよう。最初にRのバージョン情報などのメッセージが表示されるが、ここに普段見ることのない1行が追加されている。\n\n\n* Project '~/r_projects/renv_test' loaded. [renv 0.17.1]\n\n\n　これは現在、{renv}で保存された分析環境が再生されていることを意味する。実際、0.2.8にアップデートしたはずの{ggdag}のバージョンを確認してみよう。\n\npackageVersion(\"ggdag\")\n\n\n\n[1] \"0.2.7\"\n\n\n　最初に保存した0.2.7のままになっている。むろん、{renv}を使わない別のプロジェクトを開けば{ggdag}は0.2.8になっている。RStudio + プロジェクト機能を使う場合、プロジェクトフォルダ―にrenv.lockファイルが存在すると、その情報を読み込んで分析環境を再現してくれる。RStudioさまさまだ。宗教的信念によりRStudioを使わない場合は、コンソールで直接renv::restore()と入力すれば分析環境が再生される。"
  },
  {
    "objectID": "renv.html#分析環境の更新",
    "href": "renv.html#分析環境の更新",
    "title": "26  分析環境の管理",
    "section": "26.4 分析環境の更新",
    "text": "26.4 分析環境の更新\n　{renv}を使用するプロジェクトでの作業中、パッケージの追加（install.packages()）、更新（install.packages()、update.packages()）、削除（remove.packages()）を行った場合、renv.lockファイルとrenvフォルダーの中身もそれに応じて更新する必要がある。これはコンソール上でrenv::snapshot()を打つだけで良い。\n　たとえば、先ほど分析環境を保存した際、{gtable}のバージョンは0.3.1であった。これも若干古いバージョンであるため、install.packages()を使って最新バージョンに更新してみよう。\n\ninstall.packages(\"gtable\")\n\n\n\nRetrieving 'https://cran.ism.ac.jp/bin/macosx/contrib/4.2/gtable_0.3.2.tgz' ...\n    OK [downloaded 211.1 Kb in 0.15 seconds]\nInstalling gtable [0.3.2] ...\n    OK [installed binary in 0.4 seconds]\nMoving gtable [0.3.2] into the cache ...\n    OK [moved to cache in 3.2 milliseconds]\n* Installed 1 package in 1.7 seconds.\n\n\n　これで更新は終わりだ。{renv}で再生された分析環境を使用する場合、パッケージのインストール/更新の画面も普段とやや異なるが、気にする必要はない。とにかく{gtable}のバージョンを確認してみると、0.3.2に更新されていることが分かる。\n\npackageVersion(\"gtable\")\n\n\n\n[1] \"0.3.2\"\n\n\n　これを保存された分析環境に保存してみよう。分析環境を更新するか否かを尋ねてくるが、yを入力すると更新される。\n\nrenv::snapshot()\n\n\n\nThe following package(s) will be updated in the lockfile:\n\n# CRAN ===============================\n- gtable   [0.3.1 -&gt; 0.3.2]\n\nDo you want to proceed? [y/N]: y\n* Lockfile written to '~/r_projects/renv_test/renv.lock'.\n\n\n　現在のプロジェクトを終了し、もう一度renv_testプロジェクトを開いて見ると、{gtable}のバージョンが0.3.2になっていることが確認できよう。"
  },
  {
    "objectID": "renv.html#より詳しく知るために",
    "href": "renv.html#より詳しく知るために",
    "title": "26  分析環境の管理",
    "section": "26.5 より詳しく知るために",
    "text": "26.5 より詳しく知るために\n　{renv}の詳細は{renv}開発者のページを参照されたい。\n\nhttps://rstudio.github.io/renv/articles/renv.html"
  },
  {
    "objectID": "iteration.html#sec-iteration-intro",
    "href": "iteration.html#sec-iteration-intro",
    "title": "27  反復処理",
    "section": "27.1 *apply()関数群とmap_*()関数群",
    "text": "27.1 *apply()関数群とmap_*()関数群\nまず、我らの盟友、{tidyverse}を読み込んでおきましょう。\n\npacman::p_load(tidyverse)\n\nそれでは、*apply()関数群とmap_*()関数群の動きとその仕組について調べてみましょう。まず、実習用データとして長さ5のnumericベクトルnum_vecを用意します。\n\nnum_vec &lt;- c(3, 2, 5, 4, 7)\n\nこのnum_vecの個々の要素に2を足す場合はどうすれば良いでしょうか。Rはベクトル単位での演算が行われるため、num_vec + 2だけで十分です。+の右側にある2は長さ1のベクトルですが、num_vecの長さに合わせてリサイクルされます（第10.2章を参照）。\n\nnum_vec + 2\n\n[1] 5 4 7 6 9\n\n\n賢明なRユーザーなら上のコードが正解でしょう。しかし、これからの練習のために+を使わずに、for()文を使用してみましょう（第11.3章を参照）。\n\nfor (i in num_vec) {\n    print(i + 2)\n}\n\n[1] 5\n[1] 4\n[1] 7\n[1] 6\n[1] 9\n\n\n実はこれと同じ役割をする関数がRには内蔵されており、それがlapply()関数です。\n\nlapply(オブジェクト名, 関数名, 関数の引数)\n\n以下のコードからも確認出来ますが、足し算を意味する+も関数です。ただし、演算子を関数として使う場合は演算子を`で囲む必要があり、+だと`+`と表記します。\n\n`+`(num_vec, 2)\n\n[1] 5 4 7 6 9\n\n\nしたがって、lapply()関数を使用してnum_vecの全要素に2を足す場合、以下のようなコードとなります。\n\nlapply(num_vec, `+`, 2)\n\n[[1]]\n[1] 5\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 7\n\n[[4]]\n[1] 6\n\n[[5]]\n[1] 9\n\n\nこれと同じ動きをする関数が{purrr}パッケージのmap()です。{purrr}は{tidyverse}を読み込むと自動的に読み込まれます。\n\nmap(num_vec, `+`, 2)\n\n[[1]]\n[1] 5\n\n[[2]]\n[1] 4\n\n[[3]]\n[1] 7\n\n[[4]]\n[1] 6\n\n[[5]]\n[1] 9\n\n\nただし、lapply()とmap()の場合、戻り値はリスト型となります。もし、ベクトル型の戻り値が必要な場合は更にunlist()関数を使うか、sapply()を使います。\n\n# unlist()を利用し、リストを解除する\nlapply(num_vec, `+`, 2) %&gt;% unlist()\n\n[1] 5 4 7 6 9\n\n# sapply()を利用すると戻り値はベクトルとなる\nsapply(num_vec, `+`, 2)\n\n[1] 5 4 7 6 9\n\n\nmap()関数ならunlist()でも良いですが、sapply()と同じ動きをするmap_dbl()があります。これは戻り値がdoubleのnumericベクトルになるmap()関数です。\n\n# map_dbl()を利用するとnumeric (double)のベクトルが返される\nmap_dbl(num_vec, `+`, 2)\n\n[1] 5 4 7 6 9\n\n\nもし、2を足すだけでなく、更に3で割るためにはどうすれば良いでしょうか。まず考えられるのは更にsapply()やmap_dblを使うことです。\n\nmap_dbl(num_vec, `+`, 2) %&gt;% \n    map_dbl(`/`, 3)\n\n[1] 1.666667 1.333333 2.333333 2.000000 3.000000\n\n\nもう一つの方法はsapply()やmap_dbl()の第二引数に直接関数を指定する方法です。\n\nsapply(num_vec, function(x){(x + 2) / 3})\n\n[1] 1.666667 1.333333 2.333333 2.000000 3.000000\n\nmap_dbl(num_vec, function(x){(x + 2) / 3})\n\n[1] 1.666667 1.333333 2.333333 2.000000 3.000000\n\n\n上のコードだと、num_vecの要素が第二引数で指定した関数の引数（x）として用いられます。関数が長くなる場合は、sapply()やmap()の外側に関数を予め指定して置くことも可能です。\n\nadd_two_divide_three &lt;- function(x){\n    (x + 2) / 3 \n}\nsapply(num_vec, add_two_divide_three)\n\n[1] 1.666667 1.333333 2.333333 2.000000 3.000000\n\nmap_dbl(num_vec, add_two_divide_three)\n\n[1] 1.666667 1.333333 2.333333 2.000000 3.000000\n\n\nここまでの例だとsapply()とmap_dbl()はほぼ同じ関数です。なぜわざわざ{purrr}パッケージを読み込んでまでmap_dbl()関数を使う必要があるでしょうか。それはmap_dbl()の内部にはラムダ（lambda）式、あるいは無名関数（anonymous function）と呼ばれるものが使用可能だからです。ラムダ式は第14.1章でも説明しましたが、もう一回解説します。ラムダ式は使い捨ての関数で、map_dbl()内部での処理が終わるとメモリ上から削除される関数です。使い捨てですので、関数の名前（オブジェクト名）も与えられておりません。\nこのラムダ式の作り方ですが、~で始まり、引数の部分には.xが入ります1。したがって、~(.x + 2) / 3はfunction(x){(x + 2) / 3}の簡略したものとなります。ただし、後者だと無名関数の引数に該当するxをyやjなどに書き換えても問題ありませんが、ラムダ式では必ず.xと表記する必要があります。\n\nmap_dbl(num_vec, ~(.x + 2) / 3)\n\n[1] 1.666667 1.333333 2.333333 2.000000 3.000000\n\n\nかなり短めなコードで「num_vecの全要素に2を足して3で割る」処理ができました。一方、sapply()やlapply()のような*apply()関数群だとラムダ式を使うことはできません。現在のメモリ上にある関数のみしか使うことができません。\n\nsapply(num_vec, ~(.x + 2) / 3)\n\nError in match.fun(FUN): '~(.x + 2)/3' is not a function, character or symbol\n\n\nこれまでの例は正しいコードではありますが、良いコードとは言えないでしょう。なぜならnum_vec + 2という最適解が存在するからです。*apply()とmap_*()はより複雑な処理に特化しています。たとえば、リスト型データの処理です。以下の例を考えてみましょう。\n\nnum_list &lt;- list(List1 = c(1, 3, 5, 7, 9),\n                 List2 = c(2, 4, 6, 8, 10, 13, 3),\n                 List3 = c(3, 2, NA, 5, 8, 9, 1))\n\nnum_listは3つのnumeric型ベクトルで構成されたリスト型オブジェクトです。それぞれのベクトルの平均値を求めてみましょう。これを普通にmean()関数のみで済まそうとすると、リストからベクトルを一つずつ抽出し、3回のmean()関数を使用する必要があります、\n\nmean(num_list[[\"List1\"]], na.rm = TRUE)\n\n[1] 5\n\nmean(num_list[[\"List2\"]], na.rm = TRUE)\n\n[1] 6.571429\n\nmean(num_list[[\"List3\"]], na.rm = TRUE)\n\n[1] 4.666667\n\n\nもしリストの長さが大きくなると、以下のようにfor()文の方が効率的でしょう。\n\nfor (i in names(num_list)) {\n    print(mean(num_list[[i]], na.rm = TRUE))\n}\n\n[1] 5\n[1] 6.571429\n[1] 4.666667\n\n\n計算結果をベクトルとして出力/保存する場合は予めベクトルを用意しておく必要があります。\n\n# num_listの長さと同じ長さの空ベクトルを生成\nReturn_vec &lt;- rep(NA, length(num_list))\n\nfor (i in 1:length(num_list)) {\n    Return_vec[i] &lt;- mean(num_list[[i]], na.rm = TRUE)\n}\n\nReturn_vec\n\n[1] 5.000000 6.571429 4.666667\n\n\n以上の例はsapply()、またはmap_dbl関数を使うとより短くすることができます。\n\nsapply(num_list, mean, na.rm = TRUE)\n\n   List1    List2    List3 \n5.000000 6.571429 4.666667 \n\nmap_dbl(num_list, mean, na.rm = TRUE)\n\n   List1    List2    List3 \n5.000000 6.571429 4.666667 \n\n\n*apply()もmap_*()も、それぞれの要素に対して同じ処理を行うことを得意とする関数です。他の応用としては、各ベクトルからn番目の要素を抽出することもできます。ベクトルからn番目の要素を抽出するにはベクトル名[n]と入力しますが、実はこの[も関数です。関数として使う場合は+と同様、`[`と表記します。num_list内の3つのベクトルから3番目の要素を抽出してみましょう2。\n\nmap_dbl(num_list, `[`, 3)\n\nList1 List2 List3 \n    5     6    NA \n\n\nここまで来たらmap_*()関数群の仕組みについてイメージが出来たかと思います。map_*()関数群の動きは 図 27.1 のように表すことができます。第一引数はデータであり、そのデータの各要素に対して第二引数で指定された関数を適用します。この関数に必要な（データを除く）引数は第三引数以降に指定します。この関数部（第二引数）はRやパッケージなどで予め提供されている関数でも、内部に直接無名関数を作成することもできます。この無名関数はfunction(x){}のような従来の書き方も可能ですが、map_*()関数群の場合~で始まるラムダ式を使うことも可能です。\n\n\n\n図 27.1: map関数群のイメージ\n\n\nmap()の場合、返り値はリストとなり、map_dbl()の返り値はnumeric (double)型のベクトルとなります。他にもmap_*()関数群にはmap_int()、map_lgl()、map_chr()、map_df()などがあり、それぞれ返り値のデータ型/データ構造を表しています。例えば、返り値がcharacter型のベクトルであれば、map_chr()を使います。c(1, 2, 3, 4, 5)のベクトルの各要素の前に\"ID: \"を付ける例だと以下のように書きます。\n\n# 以下のコードでもOK\n# map_chr(c(1, 2, 3, 4, 5), ~paste0(\"ID: \", .x))\nc(1, 2, 3, 4, 5) %&gt;%\n  map_chr(~paste0(\"ID: \", .x))\n\n[1] \"ID: 1\" \"ID: 2\" \"ID: 3\" \"ID: 4\" \"ID: 5\""
  },
  {
    "objectID": "iteration.html#sec-iteration-map2",
    "href": "iteration.html#sec-iteration-map2",
    "title": "27  反復処理",
    "section": "27.2 引数が2つ以上の場合",
    "text": "27.2 引数が2つ以上の場合\n{purrr}を使った本格的な例を紹介する前に、引数が2つ以上の場合を考えたいと思います。まずは引数が2つの場合です。この場合、map2_*()関数群を使用します。例えば、num_vecに長さ5のnumeric型ベクトルnum_vec2をかける例を考えてみましょう。\nこの場合、データとしてnum_vecとnum_vec2が必要となり、ラムダ式にも2つの引数が必要です。まず、num_vec2を用意します。\n\nnum_vec2 &lt;- c(1, 0, 1, 0, 1)\n\n続いてmap2_dbl()関数を使用しnum_vecとnum_vec2の掛け算を行います。map2_*()の使い方はmap_*()とほぼ同様です。\n\nmap2_dbl(データ1, データ2, 関数 or ラムダ式, 追加の引数)\n\nmap_*()との違いとしては、(1) データが2つである、(2) 関数、またはラムダ式に2つの引数が必要である点です。この2点目の引数ですが、データ2は.yと表記します。したがって、データ1とデータ2の掛け算を意味するラムダ式は~.x * .yです。\n\nmap2_dbl(num_vec, num_vec2, ~.x * .y)\n\n[1] 3 0 5 0 7\n\n\nnum_vecとnum_vec2が必ずしも同じデータ構造、データ型、同じ長さである必要がありません。数字の前に\"ID:\"を付ける先ほどの例をmap2_chr()で書いてみましょう。\n\nmap2_chr(num_vec, \"ID:\", ~paste0(.y, .x))\n\n[1] \"ID:3\" \"ID:2\" \"ID:5\" \"ID:4\" \"ID:7\"\n\n\nそれでは3つ以上の引数について考えてみましょう。たとえば、num_vecの前に\"ID\"を付けるとします。そして\"ID\"とnum_vecの間に\":\"を入れたい場合はどうすればい良いでしょう。むろん、賢い解決方法は単純にpaste()関数を使うだけです。\n\npaste(\"ID\", num_vec, sep = \":\")\n\n[1] \"ID:3\" \"ID:2\" \"ID:5\" \"ID:4\" \"ID:7\"\n\n\nこの場合、引数は3つです3。この場合の書き方はどうなるでしょうか。map2_*()はデータを2つまでしか指定できません。3つ目以降は関数/ラムダ式の後ろに書くこととなります。ただし、関数/ラムダ式の後ろに指定される引数は長さ1のベクトルでなければなりません。また、ラムダ式内の引数は.xと.yでなく、..1、..2、..3、…となります。\n今回の例だとmap2_chr()内にnum_vecがデータ1、\"ID\"がデータ2です。そして、期待される結果は、「“ID” + sepの実引数 + num_vecの値」となります。したがって、ラムダ式はpaste(..2, ..1, sep = ..3)となります。\n\nmap2_chr(num_vec, \"ID\", ~paste(..2, ..1, sep = ..3), \"-\")\n\n[1] \"ID-3\" \"ID-2\" \"ID-5\" \"ID-4\" \"ID-7\"\n\n\nデータ2である\"ID\"は長さ1のcharacter型ベクトルであるため、以下のようにmap_chr()を使うことも可能です。\n\n# データ2も長さ1なのでmap_chr()もOK\nmap_chr(num_vec, ~paste(..2, ..1, sep = ..3), \"ID\", \"-\")\n\n[1] \"ID-3\" \"ID-2\" \"ID-5\" \"ID-4\" \"ID-7\"\n\n\nそれではデータを3つ以上使うにはどうすれば良いでしょうか。そこで登場するのがpmap_*()関数です。以下の3つのベクトルを利用し、「名前:数学成績」を出力してみましょう。ただし、不正行為がある場合（cheat_vecの値が1）は成績が0点になるようにしましょう。\n\nname_vec  &lt;- c(\"Hadley\", \"Song\", \"Yanai\")\nmath_vec  &lt;- c(70, 55, 80)\ncheat_vec &lt;- c(0, 1, 0)\n\n賢い解決法は普通にpaste0()関数を使う方法です。\n\npaste0(name_vec, \":\", math_vec * (1 - cheat_vec))\n\n[1] \"Hadley:70\" \"Song:0\"    \"Yanai:80\" \n\n\n今回はあえてpmap_*()関数を使ってみましょう。pmap_*()の場合、第一引数であるデータはリスト型で渡す必要があります。したがって、3つのベクトルをlist()関数を用いてリスト化します。第二引数には既存の関数やラムダ式を入力し、各引数は..1、..2、…といった形で表記します。\n\npmap_chr(list(name_vec, math_vec, cheat_vec), \n         ~paste0(..1, \":\", ..2 * (1 - ..3)))\n\n[1] \"Hadley:70\" \"Song:0\"    \"Yanai:80\" \n\n\n第一引数はデータであるため、まずリストを作成し、パイプ演算子（%&gt;%）でpmap_*()に渡すことも可能です。\n\nlist(name_vec, math_vec, cheat_vec) %&gt;%\n  pmap_chr(~paste0(..1, \":\", ..2 * (1 - ..3)))\n\n[1] \"Hadley:70\" \"Song:0\"    \"Yanai:80\""
  },
  {
    "objectID": "iteration.html#sec-iteration-df",
    "href": "iteration.html#sec-iteration-df",
    "title": "27  反復処理",
    "section": "27.3 データフレームと{purrr}",
    "text": "27.3 データフレームと{purrr}\nmap_*()関数のデータとしてデータフレームを渡すことも可能です。ここでは5行3列のデータフレームを作成してみましょう。\n\nDummy_df &lt;- data.frame(X = seq(1,  5,  by = 1),\n                       Y = seq(10, 50, by = 10),\n                       Z = seq(2,  10, by = 2))\n\n各行のX、Y、Zの合計を計算するには{dplyr}のrowwise()とmutate()を組み合わせることで計算出来ることを第14.4章で紹介しました。\n\nDummy_df %&gt;%\n  rowwise() %&gt;%\n  mutate(Sum = sum(X, Y, Z)) %&gt;%\n  # rowwise()は1行を1グループとする関数であるため、最後にグループ化を解除\n  ungroup()\n\n# A tibble: 5 × 4\n      X     Y     Z   Sum\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     1    10     2    13\n2     2    20     4    26\n3     3    30     6    39\n4     4    40     8    52\n5     5    50    10    65\n\n\nそれでは各列の平均値を計算するにはどうすれば良いでしょうか。ここではR内蔵関数であるcolMeans()を使わないことにしましょう。\n\ncolMeans(Dummy_df)\n\n X  Y  Z \n 3 30  6 \n\n\nまず、mean(Dummy_df$X)を3回実行する方法や、{dplyr}のsummarise()関数を使う方法があります。\n\nDummy_df %&gt;%\n  summarise(X = mean(X), \n            Y = mean(Y),\n            Z = mean(Z))\n\n  X  Y Z\n1 3 30 6\n\n\n実はこの操作、map_dbl()関数を使えば、より簡単です。\n\nmap_dbl(Dummy_df, mean)\n\n X  Y  Z \n 3 30  6 \n\n\nmap_dbl()はnumeric (double) 型ベクトルを返しますが、データフレーム（具体的にはtibble）に返すならmap_df()を使います。\n\nmap_df(Dummy_df, mean)\n\n# A tibble: 1 × 3\n      X     Y     Z\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     3    30     6\n\n\nなぜこれが出来るでしょうか。これを理解するためにはデータフレームとtibbleが本質的にはリスト型と同じであることを理解する必要があります。たとえば、以下のようなリストについて考えてみましょう。\n\nDummy_list &lt;- list(X = seq(1,  5,  by = 1),\n                   Y = seq(10, 50, by = 10),\n                   Z = seq(2,  10, by = 2))\n\nDummy_list\n\n$X\n[1] 1 2 3 4 5\n\n$Y\n[1] 10 20 30 40 50\n\n$Z\n[1]  2  4  6  8 10\n\n\nこのDummy_listをas.data.frame()関数を使用して強制的にデータフレームに変換してみましょう。\n\nas.data.frame(Dummy_list)\n\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n\nDummy_dfと同じものが出てきました。逆にDummy_dfを、as.list()を使用してリストに変換するとDummy_listと同じものが返されます。\n\nas.list(Dummy_df)\n\n$X\n[1] 1 2 3 4 5\n\n$Y\n[1] 10 20 30 40 50\n\n$Z\n[1]  2  4  6  8 10\n\n\nここまで理解できれば、map_*()関数のデータがデータフレームの場合、内部ではリストとして扱われることが分かるでしょう。実際、Dummy_listをデータとして入れてもDummy_dfを入れた結果と同じものが得られます。\n\nmap_df(Dummy_list, mean)\n\n# A tibble: 1 × 3\n      X     Y     Z\n  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     3    30     6\n\n\n\n27.3.1 tibbleの話\nここまで「データフレーム」と「tibble」を区別せずに説明してきましたが、これからの話しではこの2つを区別する必要があります。tibbleは{tidyverse}のコアパッケージの一つである{tibble}が提供するデータ構造であり、データフレームの上位互換です。tibbleもデータフレーム同様、本質的にはリストですが、リストの構造をより的確に表すことが出来ます。\nデータフレームをリストとして考える場合、リストの各要素は必ずベクトルである必要があります。たとえば、Dummy_listには3つの要素があり、それぞれ長さ5のベクトルです。一方、リストの中にはリストを入れることも出来ます。たとえば、以下のようなDummy_list2について考えてみましょう。\n\nDummy_list2 &lt;- list(ID   = 1:3, \n                    Data = list(Dummy_df, Dummy_df, Dummy_df))\n\nDummy_list2\n\n$ID\n[1] 1 2 3\n\n$Data\n$Data[[1]]\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n$Data[[2]]\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n$Data[[3]]\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n\nDummy_list2には2つの要素があり、最初の要素は長さ3のベクトル、2つ目の要素は長さ3のリストです。2つ目の要素がベクトルでないため、Dummy_list2をデータフレームに変換することはできません。\n\nDummy_df2 &lt;- as.data.frame(Dummy_list2)\n\nError in (function (..., row.names = NULL, check.rows = FALSE, check.names = TRUE, : arguments imply differing number of rows: 3, 5\n\n\n一方、as_tibble()を使用してtibble型に変換することは可能です。\n\nDummy_tibble &lt;- as_tibble(Dummy_list2)\n\nDummy_tibble\n\n# A tibble: 3 × 2\n     ID Data        \n  &lt;int&gt; &lt;list&gt;      \n1     1 &lt;df [5 × 3]&gt;\n2     2 &lt;df [5 × 3]&gt;\n3     3 &lt;df [5 × 3]&gt;\n\n\n2列目の各セルには5行3列のデータフレーム（df）が格納されていることが分かります。たとえば、Dummy_tibbleのData列を抽出してみましょう。\n\nDummy_tibble$Data\n\n[[1]]\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n[[2]]\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n[[3]]\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n\n長さ3のリスト出力されます。続いて、Dummy_tibble$Dataの2番目のセルを抽出してみましょう。\n\nDummy_tibble$Data[2]\n\n[[1]]\n  X  Y  Z\n1 1 10  2\n2 2 20  4\n3 3 30  6\n4 4 40  8\n5 5 50 10\n\n\nデータフレームが出力されました。簡単にまとめるとtibbleはデータフレームの中にデータフレームを入れることが出来るデータ構造です。むろん、これまでの通り、データフレームのように使うことも可能です4。これがtibbleの強みでもあり、{purrr}との相性も非常に高いです。たとえば、Data列をmap()関数のデータとして渡せば、複数のデータセットに対して同じモデルの推定が出来るようになります。以下ではその例を紹介します。"
  },
  {
    "objectID": "iteration.html#sec-iteration-model1",
    "href": "iteration.html#sec-iteration-model1",
    "title": "27  反復処理",
    "section": "27.4 モデルの反復推定",
    "text": "27.4 モデルの反復推定\nここからはmap_*()関数群を使って複数のモデルを素早く推定する方法について解説します。サンプルデータは第19章で使いました各国の政治経済データ（Countries.csv）を使用します。csv形式データ読み込みの際、これまではR内蔵関数であるread.csv()と{readr}5のread_csv()を区別せずに使用してきました。しかし、ここからはread_csv()を使用します。2つの使い方はほぼ同じですが、read_csv()は各列のデータ型を自動的に指定してくれるだけではなく、tibble構造として読み込みます。read.csv()を使用する場合、as_tibble(データフレーム名)でデータフレームをtibbleに変換してください。\n\nCountry_df &lt;- read_csv(\"Data/Countries.csv\")\n\n\n27.4.1 サンプルの分割とモデル推定（split()利用）\nまずは、サンプルを分割し、それぞれの下位サンプルを使った分析を繰り返す方法について解説します。サンプルを分割する方法は2つありますが、最初はR内蔵関数であるsplit()関数を使った方法について紹介します。\n\n# split()の使い方\n新しいオブジェクト名 &lt;- split(データ名, 分割の基準となるベクトル)\n\nたとえば、Country_dfを大陸ごとにサンプルを分けるとします。大陸を表すベクトルはCountry_df$Continentです。したがって、以下のように入力します。\n\nSplit_Data &lt;- split(Country_df, Country_df$Continent)\n\nサンプルが分割されたSplit_Dataのデータ構造はリスト型です。\n\nclass(Split_Data)\n\n[1] \"list\"\n\n\n中身を見るとリストの各要素としてtibble（データフレーム）が格納されています。リストの中にはあらゆるデータ型、データ構造を入れることができることが分かります。\n\nSplit_Data\n\n$Africa\n# A tibble: 54 × 18\n   Country   Population   Area    GDP    PPP GDP_per_capita PPP_per_capita    G7\n   &lt;chr&gt;          &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1 Algeria     43851044 2.38e6 1.70e5 4.97e5          3876.         11324.     0\n 2 Angola      32866272 1.25e6 9.46e4 2.19e5          2879.          6649.     0\n 3 Benin       12123200 1.13e5 1.44e4 3.72e4          1187.          3067.     0\n 4 Botswana     2351627 5.67e5 1.83e4 4.07e4          7799.         17311.     0\n 5 Burkina …   20903273 2.74e5 1.57e4 3.76e4           753.          1800.     0\n 6 Burundi     11890784 2.57e4 3.01e3 8.72e3           253.           733.     0\n 7 Cabo Ver…     555987 4.03e3 1.98e3 3.84e3          3565.          6913.     0\n 8 Cameroon    26545863 4.73e5 3.88e4 9.31e4          1460.          3506.     0\n 9 Central …    4829767 6.23e5 2.22e3 4.46e3           460.           924.     0\n10 Chad        16425864 1.26e6 1.13e4 2.51e4           689.          1525.     0\n# ℹ 44 more rows\n# ℹ 10 more variables: G20 &lt;dbl&gt;, OECD &lt;dbl&gt;, HDI_2018 &lt;dbl&gt;,\n#   Polity_Score &lt;dbl&gt;, Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;, FH_CL &lt;dbl&gt;,\n#   FH_Total &lt;dbl&gt;, FH_Status &lt;chr&gt;, Continent &lt;chr&gt;\n\n$America\n# A tibble: 36 × 18\n   Country   Population   Area    GDP    PPP GDP_per_capita PPP_per_capita    G7\n   &lt;chr&gt;          &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1 Antigua …      97929 4.4 e2 1.73e3 2.08e3         17643.         21267.     0\n 2 Argentina   45195774 2.74e6 4.50e5 1.04e6          9949.         22938.     0\n 3 Bahamas       393244 1.00e4 1.28e4 1.40e4         32618.         35662.     0\n 4 Barbados      287375 4.3 e2 5.21e3 4.62e3         18126.         16066.     0\n 5 Belize        397628 2.28e4 1.88e3 2.82e3          4727.          7091.     0\n 6 Bolivia     11673021 1.08e6 4.09e4 1.01e5          3503.          8623.     0\n 7 Brazil     212559417 8.36e6 1.84e6 3.13e6          8655.         14734.     0\n 8 Canada      37742154 9.09e6 1.74e6 1.85e6         46008.         49088.     1\n 9 Chile       19116201 7.44e5 2.82e5 4.64e5         14769.         24262.     0\n10 Colombia    50882891 1.11e6 3.24e5 7.37e5          6364.         14475.     0\n# ℹ 26 more rows\n# ℹ 10 more variables: G20 &lt;dbl&gt;, OECD &lt;dbl&gt;, HDI_2018 &lt;dbl&gt;,\n#   Polity_Score &lt;dbl&gt;, Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;, FH_CL &lt;dbl&gt;,\n#   FH_Total &lt;dbl&gt;, FH_Status &lt;chr&gt;, Continent &lt;chr&gt;\n\n$Asia\n# A tibble: 42 × 18\n   Country   Population   Area    GDP    PPP GDP_per_capita PPP_per_capita    G7\n   &lt;chr&gt;          &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1 Afghanis…   38928346 6.53e5 1.91e4 8.27e4           491.          2125.     0\n 2 Bahrain      1701575 7.6 e2 3.86e4 7.42e4         22670.         43624.     0\n 3 Banglade…  164689383 1.30e5 3.03e5 7.34e5          1837.          4458.     0\n 4 Bhutan        771608 3.81e4 2.45e3 8.77e3          3171.         11363.     0\n 5 Brunei        437479 5.27e3 1.35e4 2.65e4         30789.         60656.     0\n 6 Burma       54409800 6.53e5 7.61e4 2.68e5          1398.          4932.     0\n 7 Cambodia    16718965 1.77e5 2.71e4 6.93e4          1620.          4142.     0\n 8 China     1447470092 9.39e6 1.48e7 2.20e7         10199.         15177.     0\n 9 India     1380004385 2.97e6 2.88e6 9.06e6          2083.          6564.     0\n10 Indonesia  273523615 1.81e6 1.12e6 3.12e6          4092.         11397.     0\n# ℹ 32 more rows\n# ℹ 10 more variables: G20 &lt;dbl&gt;, OECD &lt;dbl&gt;, HDI_2018 &lt;dbl&gt;,\n#   Polity_Score &lt;dbl&gt;, Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;, FH_CL &lt;dbl&gt;,\n#   FH_Total &lt;dbl&gt;, FH_Status &lt;chr&gt;, Continent &lt;chr&gt;\n\n$Europe\n# A tibble: 50 × 18\n   Country  Population   Area    GDP     PPP GDP_per_capita PPP_per_capita    G7\n   &lt;chr&gt;         &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;\n 1 Albania     2877797  27400 1.53e4  39658.          5309.         13781.     0\n 2 Andorra       77265    470 3.15e3     NA          40821.            NA      0\n 3 Armenia     2963243  28470 1.37e4  38446.          4614.         12974.     0\n 4 Austria     9006398  82409 4.46e5 502771.         49555.         55824.     0\n 5 Azerbai…   10139177  82658 4.80e4 144556.          4739.         14257.     0\n 6 Belarus     9449323 202910 6.31e4 183461.          6676.         19415.     0\n 7 Belgium    11589623  30280 5.30e5 597433.         45697.         51549.     0\n 8 Bosnia …    3280819  51000 2.00e4  49733.          6111.         15159.     0\n 9 Bulgaria    6948445 108560 6.79e4 156693.          9776.         22551.     0\n10 Croatia     4105267  55960 6.04e4 114932.         14717.         27996.     0\n# ℹ 40 more rows\n# ℹ 10 more variables: G20 &lt;dbl&gt;, OECD &lt;dbl&gt;, HDI_2018 &lt;dbl&gt;,\n#   Polity_Score &lt;dbl&gt;, Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;, FH_CL &lt;dbl&gt;,\n#   FH_Total &lt;dbl&gt;, FH_Status &lt;chr&gt;, Continent &lt;chr&gt;\n\n$Oceania\n# A tibble: 4 × 18\n  Country    Population   Area    GDP    PPP GDP_per_capita PPP_per_capita    G7\n  &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;\n1 Australia    25499884 7.68e6 1.39e6 1.28e6         54615.         50001.     0\n2 Fiji           896445 1.83e4 5.54e3 1.25e4          6175.         13940.     0\n3 New Zeala…    4842780 2.64e5 2.07e5 2.04e5         42729.         42178.     0\n4 Papua New…    8947024 4.53e5 2.50e4 3.73e4          2791.          4171.     0\n# ℹ 10 more variables: G20 &lt;dbl&gt;, OECD &lt;dbl&gt;, HDI_2018 &lt;dbl&gt;,\n#   Polity_Score &lt;dbl&gt;, Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;, FH_CL &lt;dbl&gt;,\n#   FH_Total &lt;dbl&gt;, FH_Status &lt;chr&gt;, Continent &lt;chr&gt;\n\n\nそれでは分割された各サンプルに対してPolity_ScoreとFH_Totalの相関係数を計算してみましょう。その前に相関分析の方法について調べてみましょう。Rには相関分析の関数が2つ用意されています。単純に相関係数のみを計算するならcor()、係数の不確実性（標準誤差、信頼区間など）まで計算し、検定を行うならcor.test()を使用します。ここではより汎用性の高いcor.test()の使い方について紹介します。\n\n# 相関分析: 方法1\ncor.test(~ 変数名1 + 変数名2, data = データ名)\n\n# 相関分析: 方法2\ncor.test(データ名$変数名1, データ名$変数名2)\n\nそれでは全サンプルに対して相関分析をしてみましょう。\n\nCor_fit1 &lt;- cor.test(~ Polity_Score + FH_Total, data = Country_df)\nCor_fit1\n\n\n    Pearson's product-moment correlation\n\ndata:  Polity_Score and FH_Total\nt = 19.494, df = 156, p-value &lt; 2.2e-16\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7896829 0.8821647\nsample estimates:\n      cor \n0.8420031 \n\n\nここから相関係数（0.8420031）のみを抽出するにはどうすれば良いでしょうか。それを確認するためにはCor_fit1というオブジェクトの構造を調べる必要があります。ここではR内蔵関数であるstr()を使って確認してみましょう。\n\nstr(Cor_fit1)\n\nList of 9\n $ statistic  : Named num 19.5\n  ..- attr(*, \"names\")= chr \"t\"\n $ parameter  : Named int 156\n  ..- attr(*, \"names\")= chr \"df\"\n $ p.value    : num 1.16e-43\n $ estimate   : Named num 0.842\n  ..- attr(*, \"names\")= chr \"cor\"\n $ null.value : Named num 0\n  ..- attr(*, \"names\")= chr \"correlation\"\n $ alternative: chr \"two.sided\"\n $ method     : chr \"Pearson's product-moment correlation\"\n $ data.name  : chr \"Polity_Score and FH_Total\"\n $ conf.int   : num [1:2] 0.79 0.882\n  ..- attr(*, \"conf.level\")= num 0.95\n - attr(*, \"class\")= chr \"htest\"\n\n\n相関係数は$estimateで抽出できそうですね。実際にCor_fit1から相関係数のみ抽出してみましょう。\n\nCor_fit1$estimate\n\n      cor \n0.8420031 \n\n\nそれではmap()関数を利用して分割された各サンプルを対象にPolity_ScoreとFH_Totalの相関係数を計算してみましょう。map()のデータはSplit_Dataとし、関数はラムダ式を書いてみましょう。cor.test()内data引数の実引数は.x、または..1となります。最後にmap_dbl(\"estimate\")を利用し、相関係数を抽出、numeric (double) 型ベクトルとして出力します。\n\nCor_fit2 &lt;- Split_Data %&gt;%\n  map(~cor.test(~ Polity_Score + FH_Total, data = .x))\n\n\n# Cor_fit2から相関係数のみ出力\nmap_dbl(Cor_fit2, \"estimate\")\n\n   Africa   America      Asia    Europe   Oceania \n0.7612138 0.8356899 0.8338172 0.8419547 0.9960776 \n\n\nもし、小数点3位までのp値が欲しい場合は以下のように入力します。\n\n# Cor_fit2から相関係数のp値を抽出し、小数点3位に丸める\nmap_dbl(Cor_fit2, \"p.value\") %&gt;% round(3)\n\n Africa America    Asia  Europe Oceania \n  0.000   0.000   0.000   0.000   0.004 \n\n\n\n\n27.4.2 サンプルの分割とモデル推定（nest()利用）\nそれではデータフレーム内にデータフレームが格納可能なtibble構造の長所を活かした方法について解説します。ある変数に応じてデータをグループ化する方法については第14.2章で解説しました。{tidyr}パッケージにはグループごとにデータを分割し、分割されたデータを各セルに埋め込むnest()関数を提供しています。具体的な動きを見るために、とりあえず、Country_dfを大陸（Continent）ごとに分割し、それぞれがデータが一つのセルに埋め込まれた新しいデータセット、Nested_Dataを作ってみましょう。\n\nNested_Data &lt;- Country_df %&gt;% \n  group_by(Continent) %&gt;%\n  nest()\n\nちなみにgroup_by()とnest()はgroup_nest()を使って以下のようにまとめることも可能です。\n\nNested_Data &lt;- Country_df %&gt;% \n  group_nest(Continent)\n\n\nNested_Data\n\n# A tibble: 5 × 2\n# Groups:   Continent [5]\n  Continent data              \n  &lt;chr&gt;     &lt;list&gt;            \n1 Asia      &lt;tibble [42 × 17]&gt;\n2 Europe    &lt;tibble [50 × 17]&gt;\n3 Africa    &lt;tibble [54 × 17]&gt;\n4 America   &lt;tibble [36 × 17]&gt;\n5 Oceania   &lt;tibble [4 × 17]&gt; \n\n\n2列目のdata変数の各セルにtibbleが埋め込まれたことがわかります。Nested_Dataのdata列から5つ目の要素（オセアニアのデータ）を確認してみましょう。\n\n# Nested_Data$data[5]の場合、長さ1のリストが出力される\n# tibble構造で出力する場合は[5]でなく、[[5]]で抽出\nNested_Data$data[[5]]\n\n# A tibble: 4 × 17\n  Country    Population   Area    GDP    PPP GDP_per_capita PPP_per_capita    G7\n  &lt;chr&gt;           &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;          &lt;dbl&gt;          &lt;dbl&gt; &lt;dbl&gt;\n1 Australia    25499884 7.68e6 1.39e6 1.28e6         54615.         50001.     0\n2 Fiji           896445 1.83e4 5.54e3 1.25e4          6175.         13940.     0\n3 New Zeala…    4842780 2.64e5 2.07e5 2.04e5         42729.         42178.     0\n4 Papua New…    8947024 4.53e5 2.50e4 3.73e4          2791.          4171.     0\n# ℹ 9 more variables: G20 &lt;dbl&gt;, OECD &lt;dbl&gt;, HDI_2018 &lt;dbl&gt;,\n#   Polity_Score &lt;dbl&gt;, Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;, FH_CL &lt;dbl&gt;,\n#   FH_Total &lt;dbl&gt;, FH_Status &lt;chr&gt;\n\n\nContinentがOceaniaの行のdata列にオセアニアのみのデータが格納されていることが分かります。このようなデータ構造を入れ子型データ（nested data）と呼びます。この入れ子型データはunnest()関数を使って解除することも可能です。unnest()関数を使う際はどの列を解除するかを指定する必要があり、今回はdata列となります。\n\n# 入れ子型データの解除\nNested_Data %&gt;%\n  unnest(data)\n\n# A tibble: 186 × 18\n# Groups:   Continent [5]\n   Continent Country     Population    Area       GDP       PPP GDP_per_capita\n   &lt;chr&gt;     &lt;chr&gt;            &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;\n 1 Asia      Afghanistan   38928346  652860    19101.    82737.           491.\n 2 Asia      Bahrain        1701575     760    38574.    74230.         22670.\n 3 Asia      Bangladesh   164689383  130170   302571.   734108.          1837.\n 4 Asia      Bhutan          771608   38117     2447.     8767.          3171.\n 5 Asia      Brunei          437479    5270    13469.    26536.         30789.\n 6 Asia      Burma         54409800  653290    76086.   268327.          1398.\n 7 Asia      Cambodia      16718965  176520    27089.    69253.          1620.\n 8 Asia      China       1447470092 9389291 14762792. 21967628.         10199.\n 9 Asia      India       1380004385 2973190  2875142.  9058692.          2083.\n10 Asia      Indonesia    273523615 1811570  1119191.  3117334.          4092.\n# ℹ 176 more rows\n# ℹ 11 more variables: PPP_per_capita &lt;dbl&gt;, G7 &lt;dbl&gt;, G20 &lt;dbl&gt;, OECD &lt;dbl&gt;,\n#   HDI_2018 &lt;dbl&gt;, Polity_Score &lt;dbl&gt;, Polity_Type &lt;chr&gt;, FH_PR &lt;dbl&gt;,\n#   FH_CL &lt;dbl&gt;, FH_Total &lt;dbl&gt;, FH_Status &lt;chr&gt;\n\n\n{dplyr}のgroup_by()関数と{tidyr}のnest()、unnest()関数を組み合わせることでデータを入れ子型データへ変換したり、解除することができます。以上の流れを図式化したものが以下の 図 27.2 です。\n\n\n\n図 27.2: 入れ子型データの生成過程\n\n\nそれではこの入れ子型データを使用して大陸ごとのPolity_ScoreとFH_Totalの相関係数を計算してみましょう。data列をデータとした相関係数のラムダ式はどう書けば良いでしょうか。これまでの内容が理解できましたら、答えは難しくないでしょう。cor.test()関数のdata引数の実引数として.xを指定するだけです。この結果をCor_testという列として追加し、Nested_Data2という名のオブジェクトとして保存します。\n\nNested_Data2 &lt;- Nested_Data %&gt;%\n  mutate(Cor_test = map(data, ~cor.test(~ Polity_Score + FH_Total, data = .x)))\n\nNested_Data2\n\n# A tibble: 5 × 3\n# Groups:   Continent [5]\n  Continent data               Cor_test\n  &lt;chr&gt;     &lt;list&gt;             &lt;list&gt;  \n1 Asia      &lt;tibble [42 × 17]&gt; &lt;htest&gt; \n2 Europe    &lt;tibble [50 × 17]&gt; &lt;htest&gt; \n3 Africa    &lt;tibble [54 × 17]&gt; &lt;htest&gt; \n4 America   &lt;tibble [36 × 17]&gt; &lt;htest&gt; \n5 Oceania   &lt;tibble [4 × 17]&gt;  &lt;htest&gt; \n\n\nCor_testという列が追加され、htestというクラス（S3クラス）オブジェクトが格納されていることが分かります。ちゃんと相関分析のオブジェクトが格納されているか、確認してみましょう。\n\nNested_Data2$Cor_test\n\n[[1]]\n\n    Pearson's product-moment correlation\n\ndata:  Polity_Score and FH_Total\nt = 9.0626, df = 36, p-value = 8.05e-11\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7009872 0.9107368\nsample estimates:\n      cor \n0.8338172 \n\n\n[[2]]\n\n    Pearson's product-moment correlation\n\ndata:  Polity_Score and FH_Total\nt = 9.7452, df = 39, p-value = 5.288e-12\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.7210854 0.9130896\nsample estimates:\n      cor \n0.8419547 \n\n\n[[3]]\n\n    Pearson's product-moment correlation\n\ndata:  Polity_Score and FH_Total\nt = 7.9611, df = 46, p-value = 3.375e-10\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6087424 0.8594586\nsample estimates:\n      cor \n0.7612138 \n\n\n[[4]]\n\n    Pearson's product-moment correlation\n\ndata:  Polity_Score and FH_Total\nt = 7.6082, df = 25, p-value = 5.797e-08\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.6677292 0.9226837\nsample estimates:\n      cor \n0.8356899 \n\n\n[[5]]\n\n    Pearson's product-moment correlation\n\ndata:  Polity_Score and FH_Total\nt = 15.92, df = 2, p-value = 0.003922\nalternative hypothesis: true correlation is not equal to 0\n95 percent confidence interval:\n 0.8197821 0.9999220\nsample estimates:\n      cor \n0.9960776 \n\n\n5つの相関分析結果が格納されています。続いて、ここから相関係数のみを抽出してみましょう。相関分析オブジェクトから相関係数を抽出するにはオブジェクト名$estimateだけで十分です。mpa_*()関数を使うなら第2引数として関数やラムダ式を指定せず、\"estimate\"のみ入力するだけです。\n\nNested_Data2 &lt;- Nested_Data2 %&gt;%\n  mutate(Cor_coef = map(Cor_test, \"estimate\"))\n\nNested_Data2\n\n# A tibble: 5 × 4\n# Groups:   Continent [5]\n  Continent data               Cor_test Cor_coef \n  &lt;chr&gt;     &lt;list&gt;             &lt;list&gt;   &lt;list&gt;   \n1 Asia      &lt;tibble [42 × 17]&gt; &lt;htest&gt;  &lt;dbl [1]&gt;\n2 Europe    &lt;tibble [50 × 17]&gt; &lt;htest&gt;  &lt;dbl [1]&gt;\n3 Africa    &lt;tibble [54 × 17]&gt; &lt;htest&gt;  &lt;dbl [1]&gt;\n4 America   &lt;tibble [36 × 17]&gt; &lt;htest&gt;  &lt;dbl [1]&gt;\n5 Oceania   &lt;tibble [4 × 17]&gt;  &lt;htest&gt;  &lt;dbl [1]&gt;\n\n\nCor_coef列が追加され、それぞれのセルにnumeric型の値が格納されていることが分かります。map()関数はリスト型でデータを返すため、このように出力されます。このCor_coef列の入れ子構造を解除してみましょう。\n\nNested_Data2 &lt;- Nested_Data2 %&gt;%\n  unnest(cols = Cor_coef)\n\nNested_Data2\n\n# A tibble: 5 × 4\n# Groups:   Continent [5]\n  Continent data               Cor_test Cor_coef\n  &lt;chr&gt;     &lt;list&gt;             &lt;list&gt;      &lt;dbl&gt;\n1 Asia      &lt;tibble [42 × 17]&gt; &lt;htest&gt;     0.834\n2 Europe    &lt;tibble [50 × 17]&gt; &lt;htest&gt;     0.842\n3 Africa    &lt;tibble [54 × 17]&gt; &lt;htest&gt;     0.761\n4 America   &lt;tibble [36 × 17]&gt; &lt;htest&gt;     0.836\n5 Oceania   &lt;tibble [4 × 17]&gt;  &lt;htest&gt;     0.996\n\n\nCor_coefの各列に格納された値が出力されました。以上の作業を一つのコードとしてまとめることも出来ます。また、相関係数の抽出の際にmap()でなく、map_dbl()を使えば、numeric型ベクトルが返されるのでunnest()も不要となります。\n\nCountry_df %&gt;%\n  group_by(Continent) %&gt;%\n  nest() %&gt;%\n  mutate(Cor_test = map(data, ~cor.test(~ Polity_Score + FH_Total, data = .x)),\n         Cor_coef = map_dbl(Cor_test, \"estimate\"))\n\n# A tibble: 5 × 4\n# Groups:   Continent [5]\n  Continent data               Cor_test Cor_coef\n  &lt;chr&gt;     &lt;list&gt;             &lt;list&gt;      &lt;dbl&gt;\n1 Asia      &lt;tibble [42 × 17]&gt; &lt;htest&gt;     0.834\n2 Europe    &lt;tibble [50 × 17]&gt; &lt;htest&gt;     0.842\n3 Africa    &lt;tibble [54 × 17]&gt; &lt;htest&gt;     0.761\n4 America   &lt;tibble [36 × 17]&gt; &lt;htest&gt;     0.836\n5 Oceania   &lt;tibble [4 × 17]&gt;  &lt;htest&gt;     0.996\n\n\nたった5行のコードで大陸ごとの相関分析が出来ました。これをmap_*()を使わずに処理するなら以下のようなコードとなります6。\n\nCor_Test1 &lt;- cor.test(~ Polity_Score + FH_Total, \n                      data = subset(Country_df, Country_df$Continent == \"Asia\"))\nCor_Test2 &lt;- cor.test(~ Polity_Score + FH_Total, \n                      data = subset(Country_df, Country_df$Continent == \"Europe\"))\nCor_Test3 &lt;- cor.test(~ Polity_Score + FH_Total, \n                      data = subset(Country_df, Country_df$Continent == \"Africa\"))\nCor_Test4 &lt;- cor.test(~ Polity_Score + FH_Total, \n                      data = subset(Country_df, Country_df$Continent == \"America\"))\nCor_Test5 &lt;- cor.test(~ Polity_Score + FH_Total, \n                      data = subset(Country_df, Country_df$Continent == \"Oceania\"))\n\nCor_Result &lt;- c(\"Asia\" = Cor_Test1$estimate, \"Europe\" = Cor_Test2$estimate,\n                \"Africa\" = Cor_Test3$estimate, \"America\" = Cor_Test4$estimate,\n                \"Oceania\" = Cor_Test5$estimate)\n\nprint(Cor_Result)\n\n   Asia.cor  Europe.cor  Africa.cor America.cor Oceania.cor \n  0.8338172   0.8419547   0.7612138   0.8356899   0.9960776 \n\n\nそれでは応用例として回帰分析をしてみましょう。今回もNested_Dataを使用し、PPP_per_capitaを応答変数に、FH_TotalとPopulationを説明変数とした重回帰分析を行い、政治的自由度（FH_Total）の係数や標準誤差などを抽出してみましょう。まずは、ステップごとにコードを分けて説明し、最後には一つのコードとしてまとめたものをお見せします。\n\nNested_Data %&gt;%\n  mutate(Model = map(data, \n                     ~lm(PPP_per_capita ~ FH_Total + Population, \n                         data = .x)))\n\n# A tibble: 5 × 3\n# Groups:   Continent [5]\n  Continent data               Model \n  &lt;chr&gt;     &lt;list&gt;             &lt;list&gt;\n1 Asia      &lt;tibble [42 × 17]&gt; &lt;lm&gt;  \n2 Europe    &lt;tibble [50 × 17]&gt; &lt;lm&gt;  \n3 Africa    &lt;tibble [54 × 17]&gt; &lt;lm&gt;  \n4 America   &lt;tibble [36 × 17]&gt; &lt;lm&gt;  \n5 Oceania   &lt;tibble [4 × 17]&gt;  &lt;lm&gt;  \n\n\nModel列からから推定結果の要約を抽出するにはどうすれば良いでしょうか。1つ目の方法はsummary(lmオブジェクト名)$coefficientsで抽出する方法です。\n\nlm_fit1 &lt;- lm(PPP_per_capita ~ FH_Total + Population, data = Country_df)\n\nsummary(lm_fit1)$coefficients\n\n                 Estimate   Std. Error    t value     Pr(&gt;|t|)\n(Intercept)  1.929308e+03 3.229792e+03  0.5973473 5.510476e-01\nFH_Total     3.256660e+02 4.871626e+01  6.6849553 2.979474e-10\nPopulation  -2.217793e-06 9.193256e-06 -0.2412413 8.096505e-01\n\n\nもっと簡単な方法は{broom}のtidy()関数を使う方法です。tidy()関数は推定値に関する様々な情報をデータフレームとして返す便利な関数です。デフォルトだと95%信頼区間は出力されませんが、conf.int = TRUEを指定すると信頼区間も出力されます。tidy()関数を提供する{broom}パッケージは{tidyverse}の一部ですが、{tidyverse}読み込みの際に一緒に読み込まれるものではないため、予め{broom}パッケージを読み込んでおくか、broom::tidy()で使うことができます。\n\nbroom::tidy(lm_fit1, conf.int = TRUE)\n\n# A tibble: 3 × 7\n  term             estimate     std.error statistic  p.value  conf.low conf.high\n  &lt;chr&gt;               &lt;dbl&gt;         &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 (Intercept) 1929.         3230.             0.597 5.51e- 1  -4.45e+3   8.30e+3\n2 FH_Total     326.           48.7            6.68  2.98e-10   2.30e+2   4.22e+2\n3 Population    -0.00000222    0.00000919    -0.241 8.10e- 1  -2.04e-5   1.59e-5\n\n\nそれではModel列にあるlmオブジェクトから推定値の情報を抽出し、Model2という列に格納してみましょう。今回はラムダ式を使う必要がありません。なぜなら、tidy()の第一引数がデータだからです（?tidy.lm参照）。他にも必要な引数（conf.int = TRUEなど）があれば、map()の第3引数以降で指定します。\n\nNested_Data %&gt;%\n  mutate(Model  = map(data, \n                      ~lm(PPP_per_capita ~ FH_Total + Population, \n                          data = .x)),\n         Model2 = map(Model, broom::tidy, conf.int = TRUE))\n\n# A tibble: 5 × 4\n# Groups:   Continent [5]\n  Continent data               Model  Model2          \n  &lt;chr&gt;     &lt;list&gt;             &lt;list&gt; &lt;list&gt;          \n1 Asia      &lt;tibble [42 × 17]&gt; &lt;lm&gt;   &lt;tibble [3 × 7]&gt;\n2 Europe    &lt;tibble [50 × 17]&gt; &lt;lm&gt;   &lt;tibble [3 × 7]&gt;\n3 Africa    &lt;tibble [54 × 17]&gt; &lt;lm&gt;   &lt;tibble [3 × 7]&gt;\n4 America   &lt;tibble [36 × 17]&gt; &lt;lm&gt;   &lt;tibble [3 × 7]&gt;\n5 Oceania   &lt;tibble [4 × 17]&gt;  &lt;lm&gt;   &lt;tibble [3 × 7]&gt;\n\n\nModel2列の各セルに7列のtibbleが格納されているようです。ここからはdataとModel列は不要ですのでselect()関数を使って除去し、Model2の入れ子構造を解除してみます。\n\nNested_Data %&gt;%\n  mutate(Model  = map(data, \n                      ~lm(PPP_per_capita ~ FH_Total + Population, \n                          data = .x)),\n         Model2 = map(Model, broom::tidy, conf.int = TRUE)) %&gt;%\n  select(-c(data, Model)) %&gt;%\n  unnest(cols = Model2)\n\n# A tibble: 15 × 8\n# Groups:   Continent [5]\n   Continent term        estimate std.error statistic p.value conf.low conf.high\n   &lt;chr&gt;     &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1 Asia      (Intercept)  2.13e+4   7.38e+3     2.89  6.32e-3  6.39e+3   3.63e+4\n 2 Asia      FH_Total     6.99e+1   1.56e+2     0.449 6.56e-1 -2.45e+2   3.85e+2\n 3 Asia      Population  -1.26e-5   1.26e-5    -1.00  3.23e-1 -3.81e-5   1.29e-5\n 4 Europe    (Intercept) -1.40e+4   9.41e+3    -1.48  1.45e-1 -3.29e+4   5.00e+3\n 5 Europe    FH_Total     6.29e+2   1.08e+2     5.80  7.07e-7  4.10e+2   8.48e+2\n 6 Europe    Population   1.17e-4   8.45e-5     1.39  1.73e-1 -5.33e-5   2.88e-4\n 7 Africa    (Intercept)  3.83e+3   1.84e+3     2.09  4.20e-2  1.44e+2   7.52e+3\n 8 Africa    FH_Total     5.11e+1   3.42e+1     1.49  1.42e-1 -1.77e+1   1.20e+2\n 9 Africa    Population  -1.43e-5   2.31e-5    -0.619 5.39e-1 -6.07e-5   3.21e-5\n10 America   (Intercept) -7.50e+3   5.93e+3    -1.27  2.15e-1 -1.96e+4   4.57e+3\n11 America   FH_Total     3.12e+2   7.73e+1     4.03  3.20e-4  1.54e+2   4.69e+2\n12 America   Population   9.13e-5   2.35e-5     3.89  4.77e-4  4.35e-5   1.39e-4\n13 Oceania   (Intercept) -5.10e+4   2.34e+4    -2.18  2.73e-1 -3.48e+5   2.46e+5\n14 Oceania   FH_Total     9.76e+2   3.26e+2     2.99  2.05e-1 -3.17e+3   5.12e+3\n15 Oceania   Population   1.52e-4   6.27e-4     0.242 8.49e-1 -7.81e-3   8.12e-3\n\n\n各大陸ごとの回帰分析の推定結果が一つのデータフレームとして展開されました。ここではFH_Totalの推定値のみがほしいので、filter()関数を使用し、termの値が\"FH_Total\"の行のみを残します。また、term列も必要なくなるので除外しましょう。\n\nNested_Data %&gt;%\n  mutate(Model  = map(data, \n                      ~lm(PPP_per_capita ~ FH_Total + Population, \n                          data = .x)),\n         Model2 = map(Model, broom::tidy, conf.int = TRUE)) %&gt;%\n  select(-c(data, Model)) %&gt;%\n  unnest(cols = Model2) %&gt;%\n  filter(term == \"FH_Total\") %&gt;%\n  select(-term)\n\n# A tibble: 5 × 7\n# Groups:   Continent [5]\n  Continent estimate std.error statistic     p.value conf.low conf.high\n  &lt;chr&gt;        &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 Asia          69.9     156.      0.449 0.656         -245.       385.\n2 Europe       629.      108.      5.80  0.000000707    410.       848.\n3 Africa        51.1      34.2     1.49  0.142          -17.7      120.\n4 America      312.       77.3     4.03  0.000320       154.       469.\n5 Oceania      976.      326.      2.99  0.205        -3166.      5117.\n\n\nこれで終わりです。政治的自由度と所得水準の関係はアジアとアフリカでは連関の程度が小さく、統計的有意ではありません。オセアニアの場合、連関の程度は大きいと考えられますが、サンプルサイズが小さいため統計的有意な結果は得られませんでした。一方、ヨーロッパとアメリカでは連関の程度も大きく、統計的有意な連関が確認されました。\n以上のコードをよりコンパクトにまとめると以下のようなコードとなります。\n\n# {purrr}使用\nNested_Data %&gt;%\n  mutate(Model = map(data, ~lm(PPP_per_capita ~ FH_Total + Population, data = .x)),\n         Model = map(Model, broom::tidy, conf.int = TRUE)) %&gt;%\n  unnest(cols = Model) %&gt;%\n  filter(term == \"FH_Total\") %&gt;%\n  select(-c(Data, term))\n\n{purrr}パッケージを使用しない例も紹介します。むろん、以下のコードは可能な限り面倒な書き方をしています。for()文やsplit()と*apply()関数を組み合わせると以下の例よりも簡潔なコードは作成できます。R上級者になるためには{tidyverse}的な書き方だけでなく、ネイティブRの書き方にも慣れる必要があります。ぜひ挑戦してみましょう。\n\n# {purrr}を使用しない場合\n# FH_Totalの係数と標準誤差のみを抽出する例\nlm_fit1 &lt;- lm(PPP_per_capita ~ FH_Total + Population, \n              data = subset(Country_df, Country_df$Continent == \"Asia\"))\nlm_fit2 &lt;- lm(PPP_per_capita ~ FH_Total + Population, \n              data = subset(Country_df, Country_df$Continent == \"Europe\"))\nlm_fit3 &lt;- lm(PPP_per_capita ~ FH_Total + Population, \n              data = subset(Country_df, Country_df$Continent == \"Africa\"))\nlm_fit4 &lt;- lm(PPP_per_capita ~ FH_Total + Population, \n              data = subset(Country_df, Country_df$Continent == \"America\"))\nlm_fit5 &lt;- lm(PPP_per_capita ~ FH_Total + Population, \n              data = subset(Country_df, Country_df$Continent == \"Oceania\"))\n\nlm_df &lt;- data.frame(Continent = c(\"Asia\", \"Europe\", \"Africa\", \"America\", \"Oceania\"),\n                    estimate  = c(summary(lm_fit1)$coefficients[2, 1],\n                                  summary(lm_fit2)$coefficients[2, 1],\n                                  summary(lm_fit3)$coefficients[2, 1],\n                                  summary(lm_fit4)$coefficients[2, 1],\n                                  summary(lm_fit5)$coefficients[2, 1]),\n                    se        = c(summary(lm_fit1)$coefficients[2, 2],\n                                  summary(lm_fit2)$coefficients[2, 2],\n                                  summary(lm_fit3)$coefficients[2, 2],\n                                  summary(lm_fit4)$coefficients[2, 2],\n                                  summary(lm_fit5)$coefficients[2, 2]))\n\n\n\n27.4.3 データの範囲を指定したモデル推定\nこれまでの例は名目変数でグループ化を行いましたが、連続変数を使うことも可能です。たとえば、人口1千万未満の国、1千万以上5千万未満、5千万以上1億未満、1億以上でサンプルを分割することです。まず、Country_dfからPPP_per_capita、FH_Total、Population列のみを抽出し、Country_df2に格納します。\n\nCountry_df2 &lt;- Country_df %&gt;%\n  select(PPP_per_capita, FH_Total, Population)\n\n続いて、case_when()関数を使用し、Populationの値を基準にケースがどの範囲内に属するかを表す変数Groupを作成します。\n\nCountry_df2 &lt;- Country_df2 %&gt;%\n  mutate(Group = case_when(Population &lt;  10000000  ~ \"1千万未満\",\n                           Population &lt;  50000000  ~ \"1千万以上5千万未満\",\n                           Population &lt;  100000000 ~ \"5千万以上1億未満\",\n                           Population &gt;= 100000000 ~ \"1億以上\"))\n\n中身を確認してみましょう。\n\nCountry_df2\n\n# A tibble: 186 × 4\n   PPP_per_capita FH_Total Population Group             \n            &lt;dbl&gt;    &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;             \n 1          2125.       27   38928346 1千万以上5千万未満\n 2         13781.       67    2877797 1千万未満         \n 3         11324.       34   43851044 1千万以上5千万未満\n 4            NA        94      77265 1千万未満         \n 5          6649.       32   32866272 1千万以上5千万未満\n 6         21267.       85      97929 1千万未満         \n 7         22938.       85   45195774 1千万以上5千万未満\n 8         12974.       53    2963243 1千万未満         \n 9         50001.       97   25499884 1千万以上5千万未満\n10         55824.       93    9006398 1千万未満         \n# ℹ 176 more rows\n\n\nあとはこれまでの例と同じ手順となります。まず、データをGroup変数でグループ化し、入れ子構造に変換します。\n\nCountry_df2 &lt;- Country_df2 %&gt;%\n  group_by(Group) %&gt;%\n  nest()\n\n変換後のデータを確認してみます。\n\nCountry_df2\n\n# A tibble: 4 × 2\n# Groups:   Group [4]\n  Group              data             \n  &lt;chr&gt;              &lt;list&gt;           \n1 1千万以上5千万未満 &lt;tibble [61 × 3]&gt;\n2 1千万未満          &lt;tibble [96 × 3]&gt;\n3 1億以上            &lt;tibble [14 × 3]&gt;\n4 5千万以上1億未満   &lt;tibble [15 × 3]&gt;\n\n\n続いて、data列をデータとし、map()関数でモデルの推定をしてみましょう。目的変数は所得水準、説明変数は政治的自由度とします。推定後、{broom}のtidy()変数で推定値の情報のみを抽出し、入れ子構造を解除します。最後にtermがFH_Totalの行のみを残します。\n\nCountry_df2 &lt;- Country_df2 %&gt;%\n  mutate(Model = map(data, ~lm(PPP_per_capita ~ FH_Total, data = .x)),\n         Est   = map(Model, broom::tidy, conf.int = TRUE)) %&gt;%\n  unnest(Est) %&gt;%\n  filter(term == \"FH_Total\") %&gt;%\n  select(!term)\n\nCountry_df2\n\n# A tibble: 4 × 9\n# Groups:   Group [4]\n  Group   data     Model estimate std.error statistic p.value conf.low conf.high\n  &lt;chr&gt;   &lt;list&gt;   &lt;lis&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 1千万…  &lt;tibble&gt; &lt;lm&gt;      366.      59.6      6.14 9.07e-8    246.       485.\n2 1千万…  &lt;tibble&gt; &lt;lm&gt;      246.      83.0      2.96 3.94e-3     80.8      411.\n3 1億以上 &lt;tibble&gt; &lt;lm&gt;      325.     158.       2.06 6.23e-2    -19.5      669.\n4 5千万…  &lt;tibble&gt; &lt;lm&gt;      487.     101.       4.80 3.46e-4    268.       706.\n\n\nせっかくなので推定結果を可視化してみましょう。横軸は人口規模（Group）とし、縦軸は推定値とします。係数の点推定値と95%信頼区間を同時に出力するために、geom_pointrange()幾何オブジェクトを使用します。\n\nCountry_df2 %&gt;%\n  mutate(\n    # 横軸の表示順番を指定するために、Group変数をfactor化する\n    Group = factor(Group, levels = c(\"1千万未満\", \"1千万以上5千万未満\",\n                                     \"5千万以上1億未満\", \"1億以上\")),\n    # 統計的有意か否かを表すSig変数の作成\n    Sig   = if_else(conf.low * conf.high &gt; 0, \"統計的有意\", \"統計的非有意\")\n    ) %&gt;%\n  ggplot() + \n  geom_hline(yintercept = 0, color = \"red\") +\n  geom_pointrange(aes(x = Group, y = estimate, \n                      ymin = conf.low, ymax = conf.high, color = Sig), \n                  size = 0.75) +\n  labs(x = \"人口\", y = \"政治的自由度が所得に与える影響\", color = \"\") +\n  scale_color_manual(values = c(\"統計的有意\" = \"black\",\n                                \"統計的非有意\" = \"gray70\")) +\n  theme_minimal(base_size   = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n図 27.3: 政治的自由度が所得に与える影響 (人口規模別)\n\n\n\n\n政治的自由度が高くなるほど所得水準も高くなる傾向が確認されますが、人口が1億人以上の国においてはそのような傾向が見られないことが分かります。\n上記の例は、ある行は一つのグループに属するケースです。しかし、ある行が複数のグループに属するケースもあるでしょう。たとえば、ある変数の値が一定値以上である行のみでグループ化する場合です。FH_Scoreが一定値以上のSub-sampleに対して回帰分析を行う場合、FH_Scoreが最大値（100）である国はすべてのSub-sampleに属することになります。この場合はgroup_by()でグループ化することが難しいかも知れません。しかし、{dplyr}のfilter()を使えば簡単に処理することができます。\nここでは人口を説明変数に、所得水準を応答変数とした単回帰分析を行います。データは政治的自由度が一定値以上の国家のみに限定します。FH_Scoreが0以上の国（すべてのケース）、10以上の国、20以上の国、…などにサンプルを分割してみましょう。まずはFH_Scoreの最小値のみを格納したRnage_dfを作成します。\n\nRange_df &lt;- tibble(Min_FH = seq(0, 80, by = 10))\n\nRange_df\n\n# A tibble: 9 × 1\n  Min_FH\n   &lt;dbl&gt;\n1      0\n2     10\n3     20\n4     30\n5     40\n6     50\n7     60\n8     70\n9     80\n\n\n9行1列のtibbleが出来ました。続いて、Subsetという列を生成し、ここにデータを入れてみましょう。ある変数の値を基準にサンプルを絞るには{dplyr}のfilter()関数を使用します。たとえば、Counter_dfのFH_Totalが50以上のケースに絞るにはfilter(Country_df, FH_Total &gt;= 50)となります。パイプ演算子を使った場合はCountry_df %&gt;% filter(FH_Total &gt;= 50)になりますが、ラムダ式とパイプ演算子の相性はあまり良くありませんので、ここではパイプ演算子なしとします。重要なのはMin_FHの値をデータとしたmap()関数を実行し、実行内容を「Country_dfからFH_TotalがMin_FH以上のケースのみを抽出せよ」にすることです。\n\nRange_df &lt;- Range_df %&gt;%\n  mutate(Subset = map(Min_FH, ~filter(Country_df, FH_Total &gt;= .x)))\n\nRange_df\n\n# A tibble: 9 × 2\n  Min_FH Subset               \n   &lt;dbl&gt; &lt;list&gt;               \n1      0 &lt;spc_tbl_ [185 × 18]&gt;\n2     10 &lt;spc_tbl_ [176 × 18]&gt;\n3     20 &lt;spc_tbl_ [158 × 18]&gt;\n4     30 &lt;spc_tbl_ [142 × 18]&gt;\n5     40 &lt;spc_tbl_ [126 × 18]&gt;\n6     50 &lt;spc_tbl_ [112 × 18]&gt;\n7     60 &lt;spc_tbl_ [99 × 18]&gt; \n8     70 &lt;spc_tbl_ [76 × 18]&gt; \n9     80 &lt;spc_tbl_ [61 × 18]&gt; \n\n\n入れ子構造になっているのは確認できましたが、ちゃんとフィルタリングされているかどうかも確認してみましょう。たとえば、Range_df$Subset[[9]]だとFH_Totalが80以上の国に絞られていると考えられます。18列の表ですからCountryとFH_Total列のみを確認してみましょう。\n\nRange_df$Subset[[9]] %&gt;%\n  select(Country, FH_Total)\n\n# A tibble: 61 × 2\n   Country             FH_Total\n   &lt;chr&gt;                  &lt;dbl&gt;\n 1 Andorra                   94\n 2 Antigua and Barbuda       85\n 3 Argentina                 85\n 4 Australia                 97\n 5 Austria                   93\n 6 Bahamas                   91\n 7 Barbados                  95\n 8 Belgium                   96\n 9 Belize                    86\n10 Bulgaria                  80\n# ℹ 51 more rows\n\n\n問題なくフィルタリングされているようですね。ここまで出来ればあとはこれまでの内容の復習でしょう。\n\nRange_df &lt;- Range_df %&gt;%\n  mutate(Model  = map(Subset, ~lm(PPP_per_capita ~ Population, data = .x)),\n         Model  = map(Model,  broom::tidy, conf.int = TRUE)) %&gt;%\n  unnest(cols = Model) %&gt;%\n  filter(term == \"Population\") %&gt;%\n  select(-c(Subset, term))\n\n今回も可視化してみましょう。\n\nRange_df %&gt;%\n  ggplot() +\n  geom_hline(yintercept = 0, color = \"red\") +\n  geom_pointrange(aes(x = Min_FH, y = estimate, \n                      ymin = conf.low, ymax = conf.high)) +\n  labs(x = \"データ内FH_Scoreの最小値\", y = \"Populationの係数\") +\n  scale_x_continuous(breaks = seq(0, 80, by = 10),\n                     labels = seq(0, 80, by = 10)) +\n  theme_minimal(base_size = 12)\n\n\n\n\n図 27.4: Populationの係数の推定値\n\n\n\n\n以上の例は実際の分析では多く使われる方法ではないかも知れません。しかし、ノンパラメトリック回帰不連続デザイン（Regression Discontinuity Design; RDD）の場合、感度分析を行う際、バンド幅を色々と調整しながら局所処置効果を推定します。RDDの詳細については矢内の授業資料、およびSONGの授業資料などに譲りますが、ハンド幅の調整はデータの範囲を少しずつ拡張（縮小）させながら同じ分析を繰り返すことです。以下ではアメリカ上院選挙のデータを例に、方法を紹介します。\n使用するデータは{rdrobust}パッケージが提供するrdrobust_RDsenateというデータセットです。{pacman}パッケージのp_load()関数を使ってパッケージのインストールと読み込みを行い、data()関数を使って、データを読み込みます。\n\npacman::p_load(rdrobust)  # {rdrobust}のインストール & 読み込み\ndata(\"rdrobust_RDsenate\") # rdrobust_RDsenateデータの読み込み\n\n# データをSenate_dfという名で格納\nSenate_df &lt;- as_tibble(rdrobust_RDsenate)\n\nSenate_dfの中身を確認してみます。\n\nSenate_df\n\n# A tibble: 1,390 × 2\n    margin  vote\n     &lt;dbl&gt; &lt;dbl&gt;\n 1  -7.69   36.1\n 2  -3.92   45.5\n 3  -6.87   45.6\n 4 -27.7    48.5\n 5  -8.26   51.7\n 6   0.732  39.8\n 7   3.49   53.2\n 8  -3.09   52.0\n 9   4.70   51.7\n10  -8.12   57.5\n# ℹ 1,380 more rows\n\n\n本データの詳細は Cattaneo, Frandsen, と Titiunik (2015) に譲りますが、ここでは簡単に説明します。marginはある選挙区の民主党候補者の得票率から共和党候補者の投票率を引いたものです。100なら民主党候補者の圧勝、-100なら共和党候補者の圧勝です。これが0に近いと辛勝または惜敗となり、この辺の民主党候補者と共和党候補者は候補者としての資質や資源が近いと考えられます。voteは次回の選挙における民主党候補者の得票率です。ある候補者が現職であることによるアドバンテージを調べる際、「民主党が勝った選挙区における次回選挙での民主党候補者の得票率」から「民主党が負けた選挙区における次回選挙での民主党候補者の得票率」を引くだけでは不十分でしょう。圧勝できた選挙区は次回でも得票率が高いと考えられますが、これは現職というポジションによるアドバンテージ以外にも、候補者がもともと備えている高い能力・資源にも起因するからです。だから辛勝・惜敗の選挙区のみに限定することで、現職と新人の能力・資源などを出来る限り均質にし、「現職」というポジションだけが異なる状況を見つけることになります。\n問題は辛勝と惜敗の基準をどう決めるかですが、広く使われている方法としては Imbens と Kalyanaraman (2012) の最適バンド幅（optimal bandwidth）が広く使われます。しかし、最適バンド幅を使うとしても感度分析（sensitivity analysis）を行うケースも多く、この場合、バンド幅を少しずつ変えながら現職の効果を推定することになります。推定式は以下のようになります。\\(I(\\text{margin} &gt; 0)\\)はmarginが0より大きい場合、1となる指示関数（indicator function）であす。\n\\[\n\\hat{\\text{vote}} = \\beta_0 + \\beta_1 \\cdot \\text{margin} + \\tau \\cdot I(\\text{margin} &gt; 0) \\quad \\text{where} \\quad -h \\leq \\text{margin} \\leq -h\n\\]\nそれではまずは\\(h\\)が100、つまり全データを使った分析を試しにやってみましょう。\n\nRDD_Fit &lt;- lm(vote ~ margin + I(margin &gt; 0), data = Senate_df)\n\nsummary(RDD_Fit)\n\n\nCall:\nlm(formula = vote ~ margin + I(margin &gt; 0), data = Senate_df)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-46.930  -6.402   0.132   7.191  46.443 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       47.33084    0.54192  87.340  &lt; 2e-16 ***\nmargin             0.34806    0.01335  26.078  &lt; 2e-16 ***\nI(margin &gt; 0)TRUE  4.78461    0.92290   5.184 2.51e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 11.78 on 1294 degrees of freedom\n  (93 observations deleted due to missingness)\nMultiple R-squared:  0.5781,    Adjusted R-squared:  0.5774 \nF-statistic: 886.4 on 2 and 1294 DF,  p-value: &lt; 2.2e-16\n\n\nI(margin &gt; 0)TRUEの係数4.785が現職効果です。この作業を\\(h = 100\\)から\\(h = 10\\)まで、5ずつ変えながら分析を繰り返してみます。まずは、RDD_dfというtibbleを作成し、BW列にはc(100, 95, 90, ... 10)を入れます。続いて、filter()関数を利用してSenate_dfからmarginが-BW以上、BW以下のデータを抽出し、Subsetという名の列として格納します。\n\nRDD_df &lt;- tibble(BW = seq(100, 10, by = -5))\n\nRDD_df &lt;- RDD_df %&gt;%\n  mutate(Subset = map(BW, ~filter(Senate_df, \n                                  margin &gt;= -.x & margin &lt;= .x)))\n\nRDD_df\n\n# A tibble: 19 × 2\n      BW Subset              \n   &lt;dbl&gt; &lt;list&gt;              \n 1   100 &lt;tibble [1,390 × 2]&gt;\n 2    95 &lt;tibble [1,327 × 2]&gt;\n 3    90 &lt;tibble [1,319 × 2]&gt;\n 4    85 &lt;tibble [1,308 × 2]&gt;\n 5    80 &lt;tibble [1,303 × 2]&gt;\n 6    75 &lt;tibble [1,294 × 2]&gt;\n 7    70 &lt;tibble [1,287 × 2]&gt;\n 8    65 &lt;tibble [1,270 × 2]&gt;\n 9    60 &lt;tibble [1,256 × 2]&gt;\n10    55 &lt;tibble [1,237 × 2]&gt;\n11    50 &lt;tibble [1,211 × 2]&gt;\n12    45 &lt;tibble [1,178 × 2]&gt;\n13    40 &lt;tibble [1,128 × 2]&gt;\n14    35 &lt;tibble [1,077 × 2]&gt;\n15    30 &lt;tibble [995 × 2]&gt;  \n16    25 &lt;tibble [901 × 2]&gt;  \n17    20 &lt;tibble [778 × 2]&gt;  \n18    15 &lt;tibble [639 × 2]&gt;  \n19    10 &lt;tibble [471 × 2]&gt;  \n\n\n\nRDD_df &lt;- RDD_df %&gt;%\n  mutate(\n    # 各Subsetに対し、回帰分析を実施し、Model列に格納\n    Model  = map(Subset, ~lm(vote ~ margin * I(margin &gt; 0), data = .x)),\n    # Model列の各セルから{broom}のtidy()で推定値のみ抽出\n    Est    = map(Model, broom::tidy, conf.int = TRUE)\n    ) %&gt;%\n  # Est列の入れ子構造を解除\n  unnest(Est) %&gt;% \n  # 現職効果に該当する行のみを抽出\n  filter(term == \"I(margin &gt; 0)TRUE\") %&gt;%\n  # 不要な列を削除\n  select(!c(Subset, Model, term, statistic, p.value))\n\nRDD_df\n\n# A tibble: 19 × 5\n      BW estimate std.error conf.low conf.high\n   &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n 1   100     6.04     0.942     4.20      7.89\n 2    95     5.76     0.975     3.85      7.67\n 3    90     5.90     0.981     3.98      7.83\n 4    85     5.80     0.993     3.85      7.75\n 5    80     5.10     0.999     3.14      7.06\n 6    75     5.18     1.01      3.21      7.15\n 7    70     5.57     1.01      3.58      7.55\n 8    65     5.21     1.03      3.20      7.23\n 9    60     4.89     1.04      2.86      6.93\n10    55     5.23     1.05      3.17      7.29\n11    50     5.73     1.07      3.64      7.82\n12    45     5.94     1.09      3.80      8.09\n13    40     6.12     1.12      3.92      8.33\n14    35     6.34     1.15      4.09      8.59\n15    30     7.18     1.18      4.86      9.50\n16    25     7.38     1.21      5.00      9.76\n17    20     7.03     1.32      4.43      9.62\n18    15     6.96     1.50      4.01      9.92\n19    10     6.90     1.75      3.46     10.3 \n\n\n19回の回帰分析が数行のコードで簡単に実施でき、必要な情報も素早く抽出することができました。\n以上の例は、交互作用なしの線形回帰分析による局所処置効果の推定例です。しかし、ノンパラメトリックRDDでは、割当変数（running variable）処置変数の交差項や割当変数の二乗項を入れる場合が多いです。今回の割当変数はmarginです。また、閾値（cutpoint）に近いケースには高い重みを付けることが一般的な作法であり、多く使われるのが三角（triangular）カーネルです。上記の例はすべてのケースに同じ重みを付ける矩形（rectagular）カーネルを使った例です。\n以上の理由により、やはりRDDは専用のパッケージを使った方が良いかも知れません。既に読み込んである{rdrobust}も推定可能ですが、ここでは{rdd}パッケージを使ってみましょう。{rdd}パッケージによるRDDはRDestimate()関数を使います。実際の例を確認してみましょう。map()を使う前に、オブジェクトの構造を把握しておくことは重要です。\n\n# cutpoint引数の既定値は0であるため、今回の例では省略可能\nRDestimate(応答変数 ~ 割当変数, data = データオブジェクト, cutpoint = 閾値, bw = バンド幅)\n\n\npacman::p_load(rdd) # パッケージの読み込み\n\n# バンド幅を指定したRDD推定\nRDD_Fit &lt;- RDestimate(vote ~ margin, data = Senate_df, bw = 100)\n\n# RDDの推定結果を見る\nsummary(RDD_Fit)\n\n\nCall:\nRDestimate(formula = vote ~ margin, data = Senate_df, bw = 100)\n\nType:\nsharp \n\nEstimates:\n           Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&gt;|z|) \nLATE       100        1258          5.637     0.8845      6.374    1.842e-10\nHalf-BW     50        1127          6.480     1.0040      6.455    1.084e-10\nDouble-BW  200        1297          5.842     0.8568      6.818    9.210e-12\n              \nLATE       ***\nHalf-BW    ***\nDouble-BW  ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nF-statistics:\n           F      Num. DoF  Denom. DoF  p\nLATE       316.0  3         1254        0\nHalf-BW    179.7  3         1123        0\nDouble-BW  506.0  3         1293        0\n\n\n現職効果は5.637、その標準誤差は0.884です。これらの情報はどこから抽出できるか確認してみます。\n\n# 推定値の情報がどこに格納されているかを確認\nstr(RDD_Fit)\n\nList of 12\n $ type     : chr \"sharp\"\n $ call     : language RDestimate(formula = vote ~ margin, data = Senate_df, bw = 100)\n $ est      : Named num [1:3] 5.64 6.48 5.84\n  ..- attr(*, \"names\")= chr [1:3] \"LATE\" \"Half-BW\" \"Double-BW\"\n $ bw       : num [1:3] 100 50 200\n $ se       : num [1:3] 0.884 1.004 0.857\n $ z        : num [1:3] 6.37 6.45 6.82\n $ p        : num [1:3] 1.84e-10 1.08e-10 9.21e-12\n $ obs      : num [1:3] 1258 1127 1297\n $ ci       : num [1:3, 1:2] 3.9 4.51 4.16 7.37 8.45 ...\n $ model    : list()\n $ frame    : list()\n $ na.action: int [1:93] 28 29 57 58 86 113 114 142 143 168 ...\n - attr(*, \"class\")= chr \"RD\"\n\n\n$estと$seに私たちが探している数値が入っていますね。それぞれ抽出してみると長さ3のnumericベクトルが出力され、その中で1番目の要素がLATEということが分かります。\n\n# est要素の1番目の要素がLATE\nRDD_Fit$est\n\n     LATE   Half-BW Double-BW \n 5.637474  6.480344  5.842049 \n\n# se要素の1番目の要素がLATEの標準誤差\nRDD_Fit$se\n\n[1] 0.8844541 1.0039734 0.8568150\n\n\nそれでは分析に入ります。今回も\\(h\\)を予めBWという名の列で格納したRDD_dfを作成します。\n\nRDD_df &lt;- tibble(BW = seq(100, 10, by = -5))\n\n今回はラムダ式を使わず、事前に関数を定義しておきましょう。関数の自作については第12章を参照してください。\n\n# 引数をxとするRDD_Func()の定義\nRDD_Func &lt;- function(x) {\n  # バンド幅をxにしたRDD推定\n  Temp_Est &lt;- RDestimate(vote ~ margin, data = Senate_df, bw = x)\n  # LATEとその標準誤差をtibbleとして返す\n  tibble(LATE = Temp_Est$est[1],\n         SE   = Temp_Est$se[1])\n}\n\n問題なく動くかを確認してみましょう。\n\nRDD_Func(100)\n\n# A tibble: 1 × 2\n   LATE    SE\n  &lt;dbl&gt; &lt;dbl&gt;\n1  5.64 0.884\n\n\nそれでは分析をやってみましょう。今回の場合、map()の第二引数はラムダ式ではないため~で始める必要ありません。関数名だけで十分です。\n\nRDD_df &lt;- RDD_df %&gt;%\n  mutate(RDD  = map(BW, RDD_Func)) %&gt;%\n  unnest(RDD)\n\nRDD_df\n\n# A tibble: 19 × 3\n      BW  LATE    SE\n   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n 1   100  5.64 0.884\n 2    95  5.64 0.890\n 3    90  5.63 0.897\n 4    85  5.61 0.905\n 5    80  5.65 0.913\n 6    75  5.75 0.922\n 7    70  5.81 0.934\n 8    65  5.91 0.949\n 9    60  6.07 0.963\n10    55  6.29 0.982\n11    50  6.48 1.00 \n12    45  6.67 1.03 \n13    40  6.91 1.07 \n14    35  7.19 1.11 \n15    30  7.28 1.17 \n16    25  7.10 1.26 \n17    20  7.27 1.38 \n18    15  7.49 1.57 \n19    10  7.98 1.84 \n\n\nせっかくなので可視化してみましょう。今回はgeom_pointrange()を使わず、geom_line()とgeom_ribbon()を組み合わせます。geom_line()はLATEを、geom_ribbion()は95%信頼区間を表します。作図の前に95%信頼区間を計算しておきます。\n\nRDD_df %&gt;%\n  mutate(CI_lwr = LATE + qnorm(0.025) * SE,\n         CI_upr = LATE + qnorm(0.975) * SE) %&gt;%\n  ggplot() +\n  geom_hline(yintercept = 0, color = \"red\") +\n  geom_ribbon(aes(x = BW, ymin = CI_lwr, ymax = CI_upr), alpha = 0.5) +\n  geom_line(aes(x = BW, y = LATE), size = 1) +\n  labs(x = \"Bandwidth\", y = \"Local Average Treatment Effect (%p)\") +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n図 27.5: LATEの推定値 (バンド幅別)\n\n\n\n\n\n\n27.4.4 説明・応答変数を指定したモデル推定\n続いて、同じデータに対して推定式のみを変えた反復推定をやってみましょう。たとえば、応答変数は固定し、グループ変数のみを変えながらt検定を繰り返すケースを考えてみましょう。たとえば、OECDに加盟しているかどうか（OECD）で購買力平価GDP（PPP）の差があるかを検定してみましょう。使用する関数はt.test()です。第一引数には応答変数 ~ 説明変数とし、data引数にはデータフレームやtibbleオブジェクトを指定します。\n\nDiff_test &lt;- t.test(PPP ~ G20, data = Country_df)\n\nDiff_test\n\n\n    Welch Two Sample t-test\n\ndata:  PPP by G20\nt = -3.4137, df = 18.012, p-value = 0.003094\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -7667830 -1825482\nsample estimates:\nmean in group 0 mean in group 1 \n         211287         4957943 \n\n\nここからいくつかの情報が読み取れます。まず、OECD加盟国のPPPは4957943、非加盟国は211287です。その差分は-4746656です。また、t値は-3.4136、p値は0.003です。これらの情報を効率よく抽出するにはbroom::tidy()が便利です。\n\nbroom::tidy(Diff_test)\n\n# A tibble: 1 × 10\n   estimate estimate1 estimate2 statistic p.value parameter  conf.low conf.high\n      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;\n1 -4746656.   211287.  4957943.     -3.41 0.00309      18.0 -7667830. -1825482.\n# ℹ 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\n差分、t値、p値、95%信頼区間などが抽出できます。これをOECDだけでなく、G7やG20に対しても同じ検定を繰り返してみましょう。\nt.test()の第一引数だけを変えながら推定をすれば良いでしょう。この第一引数、たとえばPPP ~ G20の方はformula型と呼ばれるRにおけるデータ型の一つです。これはcharacter型でないことに注意してください。\n\nFormula1 &lt;- \"PPP ~ G20\"\nt.test(Formula1, data = Country_df)\n\nWarning in mean.default(x): argument is not numeric or logical: returning NA\n\n\nWarning in var(x): NAs introduced by coercion\n\n\nError in t.test.default(Formula1, data = Country_df): not enough 'x' observations\n\n\nこのようにエラーが出ます。このFormulaをas.formula()関数を使ってformula型に変換し、推定をやってみると問題なく推定できることが分かります。\n\nFormula2 &lt;- as.formula(Formula1)\nt.test(Formula2, data = Country_df)\n\n\n    Welch Two Sample t-test\n\ndata:  PPP by G20\nt = -3.4137, df = 18.012, p-value = 0.003094\nalternative hypothesis: true difference in means between group 0 and group 1 is not equal to 0\n95 percent confidence interval:\n -7667830 -1825482\nsample estimates:\nmean in group 0 mean in group 1 \n         211287         4957943 \n\n\nこれから私たちがやるのは\"PPP ~ \"の次に\"G7\"、\"G20\"、\"OECD\"をpaste()やpaste0()関数を結合し、formula型に変換することです。formula型の列さえ生成できれば、あとはmap()関数にformulaを渡し、データはCountry_dfに固定するだけです。\nまずはどの変数を説明変数にするかをGroup列として格納したDiff_dfを作成します。\n\nDiff_df &lt;- tibble(Group = c(\"G7\", \"G20\", \"OECD\"))\n\nDiff_df\n\n# A tibble: 3 × 1\n  Group\n  &lt;chr&gt;\n1 G7   \n2 G20  \n3 OECD \n\n\n続いて、Formula列を作成し、\"PPP ~ \"の次にGroup列の文字列を結合します。\n\nDiff_df &lt;- Diff_df %&gt;%\n  mutate(Formula = paste0(\"PPP ~ \", Group))\n\nDiff_df\n\n# A tibble: 3 × 2\n  Group Formula   \n  &lt;chr&gt; &lt;chr&gt;     \n1 G7    PPP ~ G7  \n2 G20   PPP ~ G20 \n3 OECD  PPP ~ OECD\n\n\n今のFormula列のデータ型を確認してみましょう。\n\nclass(Diff_df$Formula[[1]])\n\n[1] \"character\"\n\n\ncharacter型ですね。続いて、map()関数を使用してFormula列をformula型に変換します。\n\nDiff_df &lt;- Diff_df %&gt;%\n  mutate(Formula = map(Formula, as.formula))\n\nDiff_df\n\n# A tibble: 3 × 2\n  Group Formula  \n  &lt;chr&gt; &lt;list&gt;   \n1 G7    &lt;formula&gt;\n2 G20   &lt;formula&gt;\n3 OECD  &lt;formula&gt;\n\n\nデータ型も確認してみましょう。\n\nclass(Diff_df$Formula[[1]])\n\n[1] \"formula\"\n\n\nformula型になっていることが分かります。それではt検定を行います。ここでもラムダ式を使います。式が入る場所には.xを指定し、データはCountry_dfに固定します。\n\nDiff_df &lt;- Diff_df %&gt;%\n  mutate(Model = map(Formula, ~t.test(.x, data = Country_df)))\n\nDiff_df\n\n# A tibble: 3 × 3\n  Group Formula   Model  \n  &lt;chr&gt; &lt;list&gt;    &lt;list&gt; \n1 G7    &lt;formula&gt; &lt;htest&gt;\n2 G20   &lt;formula&gt; &lt;htest&gt;\n3 OECD  &lt;formula&gt; &lt;htest&gt;\n\n\nbroom::tidy()で推定値の要約を抽出し、入れ子構造を解除します。\n\nDiff_df &lt;- Diff_df %&gt;%\n  mutate(Tidy = map(Model, broom::tidy)) %&gt;%\n  unnest(Tidy)\n\nDiff_df\n\n# A tibble: 3 × 13\n  Group Formula   Model    estimate estimate1 estimate2 statistic p.value\n  &lt;chr&gt; &lt;list&gt;    &lt;list&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;\n1 G7    &lt;formula&gt; &lt;htest&gt; -5363390.   507033.  5870423.     -2.14 0.0759 \n2 G20   &lt;formula&gt; &lt;htest&gt; -4746656.   211287.  4957943.     -3.41 0.00309\n3 OECD  &lt;formula&gt; &lt;htest&gt; -1166591.   475459.  1642050.     -1.96 0.0564 \n# ℹ 5 more variables: parameter &lt;dbl&gt;, conf.low &lt;dbl&gt;, conf.high &lt;dbl&gt;,\n#   method &lt;chr&gt;, alternative &lt;chr&gt;\n\n\nいくつか使用しない情報もあるので、適宜列を削除します。\n\nDiff_df &lt;- Diff_df %&gt;%\n  select(-c(Formula, Model, estimate1, estimate2, \n            p.value, method, alternative))\n\nDiff_df\n\n# A tibble: 3 × 6\n  Group  estimate statistic parameter   conf.low conf.high\n  &lt;chr&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;\n1 G7    -5363390.     -2.14      6.04 -11486296.   759515.\n2 G20   -4746656.     -3.41     18.0   -7667830. -1825482.\n3 OECD  -1166591.     -1.96     42.8   -2366187.    33005.\n\n\n以上のコードをパイプ演算子を使用し、簡潔にまとめると以下のようになります。\n\nDiff_df &lt;- tibble(Group = c(\"G7\", \"G20\", \"OECD\"))\n\nDiff_df &lt;- Diff_df %&gt;%\n  mutate(Formula = paste0(\"PPP ~ \", Group),\n         Formula = map(Formula, as.formula),\n         Model   = map(Formula, ~t.test(.x, data = Country_df)),\n         Tidy    = map(Model, broom::tidy)) %&gt;%\n  unnest(Tidy) %&gt;%\n  select(-c(Formula, Model, estimate1, estimate2, \n            p.value, method, alternative))\n\n推定結果を可視化してみましょう。\n\nDiff_df %&gt;%\n  mutate(Group = fct_inorder(Group),\n         Sig   = if_else(conf.low * conf.high &gt; 0, \"統計的有意\",\n                         \"統計的非有意\")) %&gt;%\n  ggplot() +\n  geom_vline(xintercept = 0, linetype = 2) +\n  geom_pointrange(aes(x = estimate, xmin = conf.low, xmax = conf.high,\n                      y = Group, color = Sig), size = 0.75) +\n  scale_color_manual(values = c(\"統計的有意\"   = \"black\",\n                                \"統計的非有意\" = \"gray70\")) +\n  labs(x = \"非加盟国のPPP - 加盟国のPPP\", y = \"グループ\", color = \"\") +\n  theme_bw(base_size   = 12) +\n  theme(legend.position = \"bottom\")\n\n\n\n\n図 27.6: 非加盟国と加盟国の一人当たりPPP-GDPの差分 (OECD/G20/G7)\n\n\n\n\n以上の方法を応用すると応答変数を変えながら分析を繰り返すこともできます。他にも説明変数が2つ以上のケースにも応用可能です。\n\n\n\n\nCattaneo, Matias D., Brigham R. Frandsen, と Rocío Titiunik. 2015. 「Randomization Inference in the Regression Discontinuity Design: An Application to the Study of Party Advantages in the U.S. Senate」. Journal of Causal Inference 3: 1–24.\n\n\nImbens, Guido, と Karthik Kalyanaraman. 2012. 「Optimal Bandwidth Choice for the Regression Discontinuity Estimator」. The Review of Economic Studies 79: 933–59."
  },
  {
    "objectID": "oop.html#sec-oop_intro",
    "href": "oop.html#sec-oop_intro",
    "title": "28  オブジェクト指向プログラミング",
    "section": "28.1 まずは例から",
    "text": "28.1 まずは例から\n　まずは、{tidyverse}パッケージを読み込みます。\n\npacman::p_load(tidyverse)\n\n\nVector1 &lt;- c(1, 5, 3, 7, 9, 12, 5, 4, 10, 1)\nVector2 &lt;- c(\"A\", \"B\", \"D\", \"B\", \"E\", \"A\", \"A\", \"D\", \"C\", \"C\")\n\n\nsummary(Vector1)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   1.00    3.25    5.00    5.70    8.50   12.00 \n\nsummary(Vector2)\n\n   Length     Class      Mode \n       10 character character \n\n\n　同じsummary()関数ですが、中のデータのタイプによって動きが異なります。これがオブジェクト指向プログラミングにおいて「多態性 (polymorphism)」と呼ばれる概念です。同じ関数でもデータ型、またはデータ構造に応じて異なる動きをすることです。ここでのデータ型やデータ構造を、OOPでは「クラス (class)」と呼びます。クラスはclass()関数で確認することができます。\n\nclass(Vector1)\n\n[1] \"numeric\"\n\nclass(Vector2)\n\n[1] \"character\"\n\n\n　Vector1はnumeric、Vector2はcharacterです。もし、無理矢理にVector1のクラスをcharacterに変えればどうなるでしょうか。クラスの変更はclass(オブジェクト名) &lt;- \"クラス名\"でできます。一つのオブジェクトは複数のクラスが持てますが、これはOOPの「継承 (inheritance)」概念に関係するので後で解説します。ここではまず、Vector1のクラスをcharacterにし、もう一回summary()を使ってみましょう。\n\nclass(Vector1) &lt;- \"character\"\nsummary(Vector1)\n\n   Length     Class      Mode \n       10 character character \n\n\n　データの中身は変わっていませんが、summary()関数の動き方が変わりました。このように、Rで頻繁に使うsummary()、print()、plot()などの関数は様々なクラスの対応しております。lm()関数を使った回帰分析の結果オブジェクトのクラス名はlmであり、その結果を見るためにもsummary()関数を使います。他にもplot(lmオブジェクト名)をすると回帰診断の図が表示されます。これができないと、各クラスに応じた関数を作成する必要がありますね。numeric型専用のnumeric_print()、character型専用のcharacter_print()、lm型専用のlm_plot()など…、覚えなきゃいけない関数が増えてきます。ユーザー側でも大変ですが、コードを作成する側も大変です。実際、下の 図 28.1 を見ると、プログラマーにとって最も大変な仕事は「名付け」であることが分かります1。\n\n\n\n図 28.1: Programmer’s Hardest Tasks\n\n\n　OOPの多態性にはこのような煩わしい仕事を軽減する機能があります。OOPにはここで紹介した多態性以外にも、「継承 (inheritance)」、「カプセル化 (encapsulation)」のような特徴があります。他にも人によっては「メッセージパッシング (message passing)」、「動的バインディング (dynamic binding)」などの特徴を述べたりしますが、詳しい話は専門書に譲りたいと思います。また、ここではRのS3クラスについて解説しますが、S3はカプセル化に対応しておりません。したがって、ここでは以下の概念について例と一緒に解説していきたいと思います。\n\nオブジェクト (object)\nクラス (class)\nメソッド (method)\n多態性 (polymorphism)　\n継承 (inheritance)"
  },
  {
    "objectID": "oop.html#sec-oop_about_oop",
    "href": "oop.html#sec-oop_about_oop",
    "title": "28  オブジェクト指向プログラミング",
    "section": "28.2 OOPとは",
    "text": "28.2 OOPとは\n\n28.2.1 オブジェクト\n　ここは第11章の内容の繰り返しですが、オブジェクト (object) とはメモリに割り当てられた「何か」です。「何か」に該当するのは、ベクトル (vector)、行列 (matrix)、データフレーム (data frame)、リスト (list)、関数 (function) などがあります。一般的に、オブジェクトにはそれぞれ固有の（つまり、他のオブジェクトと重複しない）名前が付いています。\n　たとえば、1から5までの自然数の数列を\n\nmy_vec1 &lt;- c(1, 2, 3, 4, 5)  # my_vec1 &lt;- 1:5 でも同じ\n\nのようにmy_vec1という名前のオブジェクトに格納します。オブジェクトに名前をつけてメモリに割り当てると、その後 my_vec1 と入力するだけでそのオブジェクトの中身を読み込むことができるようになります。\n　ここで、次のように my_vec1の要素を2倍にする操作を考えてみましょう。\n\nmy_vec1 * 2\n\n[1]  2  4  6  8 10\n\n\n　my_vec1は、先ほど定義したオブジェクトです。では2はどうでしょうか。2はメモリに割り当てられていないので、オブジェクトではないでしょうか。実は、この数字 2 もオブジェクトです。計算する瞬間のみ2がメモリに割り当てられ、計算が終わったらメモリから消されると考えれば良いでしょう。むろん、* のような演算子でさえもオブジェクトです。\n\n\n28.2.2 クラス\n　クラス (class) とはオブジェクトを特徴づける属性のことです。既に何度か class() 関数を使ってデータ型やデータ構造を確認しましたが、class()関数でオブジェクトのクラスを確認することができます。先ほど、my_vec1も*も2もオブジェクトであると説明しました。これらがすべてオブジェクトであるということは、何らかのクラス属性を持っているというこです。また、class()関数そのものもオブジェクトなので、何らかのクラスを持ちます。確認してみましょう。\n\nclass(my_vec1)\n\n[1] \"numeric\"\n\nclass(`*`)\n\n[1] \"function\"\n\nclass(2)\n\n[1] \"numeric\"\n\nclass(class)\n\n[1] \"function\"\n\n\n　統計分析をする際に、Rのクラスを意識することはあまりありません。しかし、Rでオブジェクト指向プログラミングを行う際は、オブジェクトのクラスを厳密に定義する必要があります。\n　Rにおける全てはオブジェクトであり、全てのオブジェクトは一つ以上クラスが付与されています。このクラスの考え方はプログラミング言語によって異なります。たとえば、Pythonの場合、一つのクラスの内部にはオブジェクトのデータ構造が定義され、そのクラスで使用可能な関数も含んでいます。また、データを含む場合もあります。このようにクラス内部にデータ、データ構造、専用関数などを格納することをカプセル化（encapsulation）と呼びます。\n　一方、Rの（S3）クラスにはクラス専用関数がクラス内で定義されておらず、データのみが格納されています。\n\n\n28.2.3 メソッドと多態性\n　各クラス専用の関数をメソッド（method）と呼びます。たとえば、summary()関数を考えてみましょう。lm()関数を用いた回帰分析から得られたオブジェクトのクラスはlmであり、c()で作られた数値型ベクトルのクラスはnumericです。しかし、同じsummary()関数ですが、引数のクラスがlmかnumericかによって異なる動きを見せます。その例を見ましょう。\n\nX &lt;- c(1, 3, 5, 7, 9, 11)\nY &lt;- c(1, 2, 3, 7, 11, 13)\nlm_class &lt;- lm(Y ~ X)\nclass(X)\n\n[1] \"numeric\"\n\nclass(lm_class)\n\n[1] \"lm\"\n\nsummary(X)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n    1.0     3.5     6.0     6.0     8.5    11.0 \n\nsummary(lm_class)\n\n\nCall:\nlm(formula = Y ~ X)\n\nResiduals:\n      1       2       3       4       5       6 \n 1.3333 -0.2667 -1.8667 -0.4667  0.9333  0.3333 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)  -1.6333     1.0546  -1.549  0.19637   \nX             1.3000     0.1528   8.510  0.00105 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.278 on 4 degrees of freedom\nMultiple R-squared:  0.9477,    Adjusted R-squared:  0.9346 \nF-statistic: 72.43 on 1 and 4 DF,  p-value: 0.001046\n\n\n　このように同じ関数でもクラスによって異なる動作をすることを多態性 (polymorphism)と呼びます。しかし、実はRにおいてこれらの関数は別途作られた関数です。つまり、summary()という関数がクラスごとに定義されていることを意味します。summary()関数がどのクラスで使用可能かを確認するためにはmethods()関数を使います。\n\nmethods(\"summary\")\n\n [1] summary.aov*                        summary.aovlist*                   \n [3] summary.aspell*                     summary.check_packages_in_dir*     \n [5] summary.connection*                 summary.data.frame*                \n [7] summary.Date*                       summary.default*                   \n [9] summary.Duration*                   summary.ecdf*                      \n[11] summary.factor*                     summary.ggplot*                    \n[13] summary.glm*                        summary.hcl_palettes*              \n[15] summary.infl*                       summary.Interval*                  \n[17] summary.lm*                         summary.loess*                     \n[19] summary.manova*                     summary.matrix*                    \n[21] summary.mlm*                        summary.nls*                       \n[23] summary.packageStatus*              summary.Period*                    \n[25] summary.POSIXct*                    summary.POSIXlt*                   \n[27] summary.ppr*                        summary.prcomp*                    \n[29] summary.princomp*                   summary.proc_time*                 \n[31] summary.rlang_error*                summary.rlang_message*             \n[33] summary.rlang_trace*                summary.rlang_warning*             \n[35] summary.rlang:::list_of_conditions* summary.srcfile*                   \n[37] summary.srcref*                     summary.stepfun*                   \n[39] summary.stl*                        summary.table*                     \n[41] summary.tukeysmooth*                summary.vctrs_sclr*                \n[43] summary.vctrs_vctr*                 summary.warnings*                  \nsee '?methods' for accessing help and source code\n\n\n　このように44種類のクラスに対してsummary()関数が定義されています2。この関数の内部を確認するにはどうすれば良いでしょうか。関数のコードを見るときにはコンソール上に関数名を入力するだけです（()は不要）。\n\nsummary\n\nfunction (object, ...) \nUseMethod(\"summary\")\n&lt;bytecode: 0x7fc775d0da18&gt;\n&lt;environment: namespace:base&gt;\n\n\n　しかし、多態性を持つ関数の内部を見ることはできません。そもそもsummary()関数はクラスごとに異なるコードを持っているため、summaryだけでは「どのクラスのsummary()か」が分かりません。それでもRにはsummary()関数が存在し、それをジェネリック関数（generic function）と呼びます。内部にはUseMethod(\"summary\")のみが書かれており、これは「このsummary()関数は様々なクラスのメソッドとして機能するぞ」と宣言しているだけです。各クラスに対応したメソッドの内部を見るにはgetS3method(\"メソッド名\", \"クラス名\")を使います。summary()メソッドはnumeric型が別途指定されていないため、\"defualt\"となります。\n\ngetS3method(\"summary\", \"default\")\n\nfunction (object, ..., digits, quantile.type = 7) \n{\n    if (is.factor(object)) \n        return(summary.factor(object, ...))\n    else if (is.matrix(object)) {\n        if (missing(digits)) \n            return(summary.matrix(object, quantile.type = quantile.type, \n                ...))\n        else return(summary.matrix(object, digits = digits, quantile.type = quantile.type, \n            ...))\n    }\n    value &lt;- if (is.logical(object)) \n        c(Mode = \"logical\", {\n            tb &lt;- table(object, exclude = NULL, useNA = \"ifany\")\n            if (!is.null(n &lt;- dimnames(tb)[[1L]]) && any(iN &lt;- is.na(n))) dimnames(tb)[[1L]][iN] &lt;- \"NA's\"\n            tb\n        })\n    else if (is.numeric(object)) {\n        nas &lt;- is.na(object)\n        object &lt;- object[!nas]\n        qq &lt;- stats::quantile(object, names = FALSE, type = quantile.type)\n        qq &lt;- c(qq[1L:3L], mean(object), qq[4L:5L])\n        if (!missing(digits)) \n            qq &lt;- signif(qq, digits)\n        names(qq) &lt;- c(\"Min.\", \"1st Qu.\", \"Median\", \"Mean\", \"3rd Qu.\", \n            \"Max.\")\n        if (any(nas)) \n            c(qq, `NA's` = sum(nas))\n        else qq\n    }\n    else if (is.recursive(object) && !is.language(object) && \n        (n &lt;- length(object))) {\n        sumry &lt;- array(\"\", c(n, 3L), list(names(object), c(\"Length\", \n            \"Class\", \"Mode\")))\n        ll &lt;- numeric(n)\n        for (i in 1L:n) {\n            ii &lt;- object[[i]]\n            ll[i] &lt;- length(ii)\n            cls &lt;- oldClass(ii)\n            sumry[i, 2L] &lt;- if (length(cls)) \n                cls[1L]\n            else \"-none-\"\n            sumry[i, 3L] &lt;- mode(ii)\n        }\n        sumry[, 1L] &lt;- format(as.integer(ll))\n        sumry\n    }\n    else c(Length = length(object), Class = class(object), Mode = mode(object))\n    class(value) &lt;- c(\"summaryDefault\", \"table\")\n    value\n}\n&lt;bytecode: 0x7fc775d0cda0&gt;\n&lt;environment: namespace:base&gt;\n\n\n　Rにはメソッドがクラス内部で定義されず、別途のメソッド名.クラス名()といった関数として作成されています。そしてジェネリック関数によって一つの関数の「ように」まとまっています。このように、ジェネリック関数経由でメソッドを呼び出すことをメソッド・ディスパッチ（method dispatch）と呼びます。\n\n\n28.2.4 継承\n　クラスの継承 (inheritance)は一つのオブジェクトが2つ以上のクラスを持つ場合、子クラスが親クラスの特徴を継承することを意味します。たとえば、データフレームの拡張版とも言えるtibbleの場合、複数のクラスを持っています。\n\nmy_tibble &lt;- tibble(X = 1:5, Y = 1:5)\nclass(my_tibble)\n\n[1] \"tbl_df\"     \"tbl\"        \"data.frame\"\n\n\n　このmy_tibbleはtlb_dfとtbl、data.frameといった3つのクラスを持っており、先に出てきたものが子クラス、後に出てくるものが親クラスです。tblクラスとdata.frameクラス両方に同じメソッドが定義されている場合、まず子クラスであるメソッド.tbl()が実行されます。もし、子クラスにメソッドが定義されていない場合はtblの親クラスであるdata.frameのメソッドが実行されます。tibbleはデータフレームとは異なるクラスのオブジェクトですが、データフレームと（ほぼ）同じ操作ができるのは、クラスが継承されるからです。クラスの継承ができないと、tibbleで使える全ての関数（列や行の抽出に使う[や$なども！）を全て一から定義する必要がありますが3、継承を使うことによってこのような手間を省くことが出来ます。"
  },
  {
    "objectID": "oop.html#sec-oop_in_r",
    "href": "oop.html#sec-oop_in_r",
    "title": "28  オブジェクト指向プログラミング",
    "section": "28.3 RにおけるOOP",
    "text": "28.3 RにおけるOOP\n\n28.3.1 オブジェクトに任意のクラスを付ける\n　クラスを変えるのは簡単です。class(オブジェクト) &lt;- \"新しいクラス名\"だけです。つまり、関数から何かの結果を返す直前にクラスを変更すれば良いです。\n\n# 方法1\n関数名 &lt;- function(...) {\n  \n  ...\n  \n  class(返すオブジェクト名) &lt;- \"任意のクラス名\"\n  \n  返すオブジェクト名 # return(オブジェクト名) でもOK\n}\n\n　たとえば、入力された2つのベクトル（xとy）をリスト構造とし、クラス名をScoreにするにはどうすれば良いでしょうか。\n\nMake_Score1 &lt;- function(x, y) {\n  \n  # resultリストにxとyを格納\n  result &lt;- list(Score1 = x, Score2 = y)\n  \n  # 以下は attr(result, \"class\") &lt;- \"Score\" も可\n  class(result) &lt;- \"Score\" # resultのクラスを\"Score\"とする\n  \n  result                   # resultを返す\n}\n\nMy_Score1 &lt;- Make_Score1(x = rnorm(10, 50, 10),\n                         y = rnorm(10, 50, 10))\n\nMy_Score1 # My_Score1の内部を見る\n\n$Score1\n [1] 49.13717 53.95705 36.70096 55.74090 51.51996 55.54723 56.20442 38.67140\n [9] 55.72354 58.99844\n\n$Score2\n [1] 43.41715 52.96950 42.55931 58.38497 48.87464 48.61049 41.97657 58.19639\n [9] 68.28814 58.66053\n\nattr(,\"class\")\n[1] \"Score\"\n\nclass(My_Score1) # My_Score1のクラスを表示\n\n[1] \"Score\"\n\n\n　もう一つの方法はstructure()関数を使う方法です。sturcture()の第1引数に返すオブジェクト名を指定し、class = \"クラス名\"引数でクラスを指定します。\n\nMake_Score2 &lt;- function(x, y) {\n  \n  # resultリストにxとyを格納\n  result &lt;- list(Score1 = x, Score2 = y)\n  \n  structure(result, class = \"Score\") # resultを返す\n}\n\nMy_Score2 &lt;- Make_Score2(x = rnorm(10, 50, 10),\n                         y = rnorm(10, 50, 10))\n\nMy_Score2 # My_Score2の内部を見る\n\n$Score1\n [1] 49.95522 40.82902 33.40319 38.09255 47.77633 51.73802 61.78716 54.37891\n [9] 40.53417 58.51314\n\n$Score2\n [1] 59.52045 44.18795 42.36606 65.38652 36.59465 42.22065 50.52631 54.54158\n [9] 54.20593 40.12668\n\nattr(,\"class\")\n[1] \"Score\"\n\nclass(My_Score2) # My_Score2のクラスを表示\n\n[1] \"Score\"\n\n\n　どれも同じ結果が得られます。\n\n\n28.3.2 メソッドの作り方\n\n28.3.2.1 既に存在する関数名を使う\n　先ほど作成しましたScoreクラスのオブジェクトは長さ2のリスト構造をしています。これらの要素それぞれの平均値を求める場合は、mean(My_Score1[[1]])とmean(My_Score1[[2]])を実行する必要があります。なぜなら、mean()はベクトルしか計算できないからです。ここではScoreクラスのオブジェクト要素それぞれの平均値を求める関数mean()を作成します。\n　しかし、問題があります。それはRにmean()関数が既に存在することです。ここで勝手に上書きするのは良くないでしょう。ここで出てくるのがメソッドです。Scoreクラスのメソッドは「Scoreクラス専用の関数」であり、通常のベクトルならR内蔵のmean()関数を、ScoreクラスのオブジェクトならScoreのメソッドであるmean()を実行します。\n　メソッドの作り方は自作関数と同じです。相違点としては関数名を関数名.クラス名にすることです。Scoreクラスのメソッドしてのmean()関数を定義する場合、関数名をmean.Scoreとします。\n\nmean.Score &lt;- function(x) {\n  print(mean(x$Score1))\n  print(mean(x$Score2))\n}\n\nmean(c(1, 3, 5, 7, 9, 11)) # R内蔵関数のmean()を使う\n\n[1] 6\n\nmean(My_Score1) # Scoreクラスのメソッドであるmean()を使う\n\n[1] 51.22011\n[1] 52.19377\n\n\n　mean(c(1, 3, 5, 7, 9, 11))は引数がnumeric型ベクトルであるため、既存のmean()関数が使用されます。一方、mean(My_Score1)は引数がScoreクラスであるため、mean.Score()が使用されます。このようにmean_Score()のような別途の関数を作る必要なく、既存の関数名が利用できます。実際、methods(mean)を実行すると、Scoreクラスのメソッドとしてmean()関数が用意されたことを確認できます。\n\nmethods(mean)\n\n[1] mean.Date*       mean.default*    mean.difftime*   mean.POSIXct*   \n[5] mean.POSIXlt*    mean.quosure*    mean.Score       mean.vctrs_vctr*\nsee '?methods' for accessing help and source code\n\n\n\n\n28.3.2.2 新しい関数を作る\n　もし、新しい関数名を使用し、その関数が様々なクラスに対応するとしましょう。今回はCatというクラスを作ってみましょう。Catクラスの内部は長さ1のリストで、要素の名前はNameとし、ここには長さ1のcharacter型ベクトルが入ります。このCatクラスを作成する関数をMake_Cat()とします。\n\nMake_Cat &lt;- function(name) {\n  \n  # resultリストにxを格納\n  result &lt;- list(Name = name)\n  \n  structure(result, class = \"Cat\") # resultを返す\n}\n\nMy_Cat &lt;- Make_Cat(name = \"矢内\")\nMy_Cat\n\n$Name\n[1] \"矢内\"\n\nattr(,\"class\")\n[1] \"Cat\"\n\nclass(My_Cat)\n\n[1] \"Cat\"\n\n\n　続いて、Catクラスに使うmy_func()を作成します。my_func()はそもそも存在しない関数ですので、普通にmy_func &lt;- function()で作成可能です。この関数はCatのNameの後ろに\": にゃーにゃー\"を付けて出力する関数です。実際にやってみましょう。\n\nmy_func &lt;- function(name) {\n  print(paste0(name$Name, \": にゃーにゃー\"))\n}\n\nmy_func(My_Cat)\n\n[1] \"矢内: にゃーにゃー\"\n\n\n　しかし、my_func()をCatクラス以外にも使いたい場合はどうすればいいでしょうか。普通にmy_func.クラス名()で良いでしょうか。確かにそうですが、その前に一つの手順が必要です。それは、my_func()をジェネリック関数として定義することです。この関数そのものは関数として機能はしませんが、「これからmy_func()がいろんなクラスのメソッドとして使われるぞ」と予め決めてくれます。ジェネリック関数を作成しないと関数名.クラス名は定義できません。そこで使うのがUseMethod()です。第一引数はメソッド名、第二引数は任意の引数ですが、通常、xが使われます。また、第二の引数は省略可能で、UseMethod(\"メソッド名\")でも動きます。\n\nmy_func &lt;- function(x) {\n  UseMethod(\"my_func\", x)\n}\n\n　これからはmy_func.クラス名()の関数を作るだけです。まず、Score型オブジェクトに対してはそれぞれの要素の平均値を出力するとします。\n\nmy_func.Score &lt;- function(x) {\n  print(mean(x$Score1))\n  print(mean(x$Score2))\n}\n\nmy_func.Cat &lt;- function(cat) {\n  print(paste0(cat$Name, \": にゃーにゃー\"))\n}\n\n\nmethods(my_func)\n\n[1] my_func.Cat   my_func.Score\nsee '?methods' for accessing help and source code\n\n\n　my_func()関数はScoreとCatといった2種類のクラスで使われることが確認できます。それでは問題なく作動するかを確認してみましょう。My_Score1とMy_Catを、それぞれmy_func()に渡します。\n\nmy_func(My_Score1)\n\n[1] 51.22011\n[1] 52.19377\n\nmy_func(My_Cat)\n\n[1] \"矢内: にゃーにゃー\"\n\n\n　同じ関数名でも、オブジェクトのクラスによって異なる処理が行われることが分かります。\n\n\n\n28.3.3 検証用関数を作る\n　この作業は必須ではありませんが、今後、自分でパッケージ等を作ることになったら重要になるかも知れません。\n　最初の例でもお見せしましたが、Rでは事後的にクラスを変更することができます。強制的にクラスを変更した場合、そのクラスに属するメソッドを使うことができますが、エラーが生じてしまうでしょう。例えば、任意のcharacter型ベクトルMy_Cat2を作成し、Catクラスを付与してみましょう。\n\nMy_Cat2 &lt;- \"宋\"\nclass(My_Cat2) &lt;- \"Cat\"\nclass(My_Cat2)\n\n[1] \"Cat\"\n\n\n　My_Cat2のクラスはCatであるため、my_func.Cat()メソッドが使えます。しかし、my_func.Cat()仕組みを見る限り、うまく作動しないでしょう。\n\nmy_func(My_Cat2)\n\nError in cat$Name: $ operator is invalid for atomic vectors\n\n\n　間違った動作をするよりは、エラーが出て中断される方が良いですし、これで問題ないかも知れません。しかし、可能であれば、引数として使われたオブジェクトが、Catクラスか否かを厳密にチェックする機能があれば良いでしょう。カプセル化されている場合、クラスの定義時にデータの構造が厳密に定義されているため、このような手続きの必要性はあまりありませんが、カプセル化ができないRのS3クラスでは検証用関数（Validator）が必要です。\n　それではCatクラスの特徴をいくつか考えてみましょう。\n\nオブジェクトの中にはNameという要素のみがある。\nNameは長さ1のCharacter型ベクトルである。\n\n　以上の条件を全て満たしていればメソッドを実行し、一つでも満たさない場合はメソッドの実行を中止します。それでは検証用関数Validation_Cat()を作ってみましょう。\n\nValidation_Cat &lt;- function(x) {\n  Message &lt;- \"正しいCatクラスではありません。\"\n  \n  if (length(x) != 1) {\n    stop(Message)\n  } else if (is.null(names(x))) {\n    stop(Message)\n  } else if (names(x) != \"Name\"){\n    stop(Message)\n  } else if (length(x$Name) != 1 | class(x$Name) != \"character\") {\n    stop(Message)\n  }\n}\n\n　この検証用関数をmy_func.Cat()の最初に入れておきましょう。\n\nmy_func.Cat &lt;- function(cat) {\n  Validation_Cat(cat)\n  \n  print(paste0(cat$Name, \": にゃーにゃー\"))\n}\n\n　それではMy_CatとMy_Cat2に対してmy_func()メソッドを実行してみます。\n\nmy_func(My_Cat)\n\n[1] \"矢内: にゃーにゃー\"\n\nmy_func(My_Cat2)\n\nError in Validation_Cat(cat): 正しいCatクラスではありません。\n\n\n　関数を実行する前に与えられたオブジェクトが正しいCatクラスか否かが判断され、パスされた場合のみ、メソッドが実行されることが分かります。もし、あるクラスで使用可能なメソッドが一つだけでしたら、検証用関数はメソッド内に直接書き込んでも良いですが、2つ以上のメソッドを持つ場合は別途の検証用関数を作成しておきましょう。"
  },
  {
    "objectID": "oop.html#sec-oop_example",
    "href": "oop.html#sec-oop_example",
    "title": "28  オブジェクト指向プログラミング",
    "section": "28.4 例題",
    "text": "28.4 例題\n　ここでは2つのnumeric型ベクトルとそのベクトル名入力し、相関係数を求めるMy_Cor()関数を作ってみます。単に相関係数を求めるだけならcor()やcor.test()があるので、いくつかの機能も追加してみましょう。\n　たとえば、「1日当たりゲーム時間」と「身長」といった2つのnumeric型ベクトルをそれぞれxとyで入力し、x_nameとy_nameで各ベクトルの名前も指定します。また、入力されたデータを用いて相関係数とその信頼区間を求めます。これらのデータはリスト型として格納されますが、クラスを\"My_Cor_Object\"とします。以下はその例です。\n\nCor_Obj &lt;- My_Cor(x      = rnorm(20, 2, 0.5), \n                  y      = rnorm(20, 165, 6), \n                  x_name = \"1日当たりゲーム時間\", \n                  y_name = \"身長\")\n\nclass(Cor_Obj)\n\n[1] \"My_Cor_Object\"\n\n\n　このCor_Objの構造をstr()で確認してみます。\n\nstr(Cor_Obj)\n\nList of 4\n $ data    :'data.frame':   20 obs. of  2 variables:\n  ..$ x: num [1:20] 1.47 1.34 2.11 2.85 1.38 ...\n  ..$ y: num [1:20] 179 164 173 161 164 ...\n $ var_name: chr [1:2] \"1日当たりゲーム時間\" \"身長\"\n $ cor     : Named num 0.089\n  ..- attr(*, \"names\")= chr \"cor\"\n $ cor_ci  : num [1:2] -0.368 0.511\n  ..- attr(*, \"conf.level\")= num 0.95\n - attr(*, \"class\")= chr \"My_Cor_Object\"\n\n\n　Cor_Objには元のデータがデータフレームとして格納され（$data）、それぞれの変数名（$var_name）、相関係数（$cor）、相関係数の95%信頼区間（$cor_ci）がCor_Objの中に入っています。本質的にはリスト型のデータ構造ですが、クラス名がMy_Cor_Objectになっているだけです。\n　このMy_Cor_Objectクラスには3つのメソッド（専用関数）が用意されており、print()、summary()、plot()です。print()とsummary()は同じ関数で、xとyの平均値、そして相関係数と信頼区間を出力します。plot()は散布図と相関係数を出力します。実際の例を見てみましょう。\n\nprint(Cor_Obj)\n\n1日当たりゲーム時間の平均値: 1.998\n身長の平均値: 164.401\n相関係数: 0.089 [-0.368, 0.511]\n\nsummary(Cor_Obj) # summary()はprint()と同じ\n\n1日当たりゲーム時間の平均値: 1.998\n身長の平均値: 164.401\n相関係数: 0.089 [-0.368, 0.511]\n\nplot(Cor_Obj)\n\n\n\n\n\n\n\n\n　既存のcor.test()で作成される\"htest\"クラスに比べ、\"My_Cor_Object\"クラスは各変数の平均値が名前と一緒に表示され、plot()で簡単に散布図が作成できる大変便利なクラスです。このMy_Cor_Objectクラスとそのメソッドの構造を図示したものが 図 28.2 です。\n\n\n\n図 28.2: My_Cor_Objectクラスの構造\n\n\n　それでは一つずつ作っていきましょう。まずは、\"My_Cor_Object\"クラスのオブジェクトを作成するMy_Cor()関数からです。\n\nMy_Cor &lt;- function(x, y, x_name, y_name) {\n    if (!is.numeric(x) | !is.numeric(y)) {\n        stop(\"xまたはyがnumeric型ではありません。\")\n    }\n    if (length(x) != length(y)) {\n        stop(\"xとyは同じ長さでなかればなりません。\")\n    }\n    if (!is.character(x_name) | !is.character(y_name)) {\n        stop(\"x_nameまたはy_nameがcharacter型ではありません。\")\n    }\n    \n    data     &lt;- data.frame(x = x, y = y)\n    var_name &lt;- c(x_name, y_name)\n    cor      &lt;- cor.test(x, y)$estimate\n    cor_ci   &lt;- cor.test(x, y)$conf.int\n    \n    result   &lt;- structure(list(data     = data, \n                               var_name = var_name, \n                               cor      = cor,\n                               cor_ci   = cor_ci),\n                          class = \"My_Cor_Object\")\n    \n    result\n}\n\n　最初の部分は入力されたデータがMy_Cor_Objectクラスに適した構造か否かを判断します。これは最初から想定外のMy_Cor_Objectクラスのオブジェクトが作成されることを防ぐことが目的です。むろん、R（S3）の性質上、事後的にクラスを変更することが可能ですから、検証用関数も作っておきます。ここでは以下の条件を検証します。\n\ndataという要素が存在し、2列である。\nvar_nameという要素が存在し、長さ2のcharacter型ベクトルである。\ncorという要素が存在し、長さ1のnumeric型ベクトルである。\ncor_ciという要素が存在し、長さ2のnumeric型ベクトルである。\n\n\nValidation &lt;- function (x) {\n  UseMethod(\"Validation\", x)\n}\n\nValidation.My_Cor_Object &lt;- function(x) {\n  Message &lt;- \"正しいMy_Cor_Objectクラスではございません。\"\n  \n  if (is.null(x$data) | ncol(x$data) != 2) {\n    stop(Message)\n  }\n  if (is.null(x$var_name) | length(x$var_name) != 2 | class(x$var_name) != \"character\") {\n    stop(Message)\n  }\n  if (is.null(x$cor) | length(x$cor) != 1 | class(x$cor) != \"numeric\") {\n    stop(Message)\n  }\n  if (is.null(x$cor_ci) | length(x$cor_ci) != 2 | class(x$cor_ci) != \"numeric\") {\n    stop(Message)\n  }\n}\n\n　ここではValidation()をジェネリック関数として使用しました。自分が開発するパッケージで複数のクラスを提供する予定でしたら、このようなやり方が良いでしょう。\n　検証用関数は細かく書いた方が良いです。以上のValidation()もより細かくことが出来ます。たとえば、dataが2列か否かを判定するだけでなく、numeric型であるかなども判定した方が良いでしょう。\n　つづいて、My_Cor_Objectクラス用のprint()関数（メソッド）を作成します。\n\nprint.My_Cor_Object &lt;- function(data) {\n    Valdation(data)\n    \n    cat(sprintf(\"%sの平均値: %.3f\\n\", \n                data$var_name[1],\n                mean(data$data$x)))\n    cat(sprintf(\"%sの平均値: %.3f\\n\", \n                data$var_name[2],\n                mean(data$data$y)))\n    cat(sprintf(\"相関係数: %.3f [%.3f, %.3f]\\n\", \n                data$cor, \n                data$cor_ci[1],\n                data$cor_ci[2]))\n}\n\n　次は、summary()メソッドですが、これはprint()と同じ機能をする関数です。この場合、UseMethod(\"メソッド名\")を使うと、指定したメソッドを使うことになります。\n\nsummary.My_Cor_Object &lt;- function(data) {\n  UseMethod(\"print\")\n}\n\n　最後はplot()メソッドです。\n\nplot.My_Cor_Object &lt;- function(data) {\n    Valdation(data)\n    \n    data$data |&gt;\n      ggplot(aes(x = x, y = y)) +\n      geom_point() +\n      labs(x = data$var_name[1], y = data$var_name[2]) +\n      ggtitle(sprintf(\"相関係数 = %.3f\", data[[\"cor\"]])) +\n      theme_minimal()\n}\n\n　これで相関係数の計算および可視化が便利になる関数群が完成しました。Rパッケージの開発はこれよりも数倍も複雑ですが、本記事の内容はプログラミングをより効率的に行うための入り口となります。"
  },
  {
    "objectID": "monte.html#sec-monte-intro",
    "href": "monte.html#sec-monte-intro",
    "title": "29  モンテカルロ・シミュレーション",
    "section": "29.1 モンテカルロシミュレーションとは",
    "text": "29.1 モンテカルロシミュレーションとは\n\npacman::p_load(tidyverse, ggforce)\n\n　モンテカルロ法 (Monte Carlo method)とは無作為に抽出された乱数を用い、数値計算やシミュレーションを行う手法を意味します。モンテカルロはヨーロッパのモナコ公国内の一つの地区であり、カジノで有名なところです。カジノではサイコロやルーレット、無作為に配られたカードなど、乱数が頻繁に使われることからこのように名付けられました。\n　モンテカルロ法を用いたシミュレーションがモンテカルロ・シミュレーションです。計算があまりにも複雑だったり、実質的に代数で解が得られない解析学上の問題などに強みを持つ手法です。一部、明快な例（共役事前分布が存在するなど）を除き、事後分布の計算が非常に複雑（実質、不可能）だと知られていたベイズ統計学もモンテカルロ法（マルコフ連鎖モンテカルロ法; MCMC）によって、ようやく使えるものになったなど、今になってモンテカルロ法は非常に広く用いられています。\n　モンテカルロ法から得られた結果には常に誤差が存在します。とりわけ、生成された乱数が少ない（= 試行回数が少ない）場合、この誤差は大きくなります。しかし、近年はパソコンの性能が飛躍的に発達しているため、かなり小さな誤差で、つまりより正確な結果が得られるようになりました。\n　以下ではまず、モンテカルロ法を理解するために必須知識である乱数生成について解説します。具体的には乱数生成のアルゴリズムでなく、Rで乱数を生成する方法について紹介します。続いて、モンテカルロ法を用いたシミュレーションの例として誕生日問題、モンティ・ホール問題、円周率の計算、ブートストラップ法を紹介します。"
  },
  {
    "objectID": "monte.html#sec-monte-rng",
    "href": "monte.html#sec-monte-rng",
    "title": "29  モンテカルロ・シミュレーション",
    "section": "29.2 乱数生成",
    "text": "29.2 乱数生成\n\n29.2.1 sample()によるサンプリング\n　無作為に値を抽出する方法には2つが考えられます。一つは値の集合から無作為に値を抽出する方法、もう一つは正規分布などの確率分布から値を抽出する方法です。ここではまずsample()関数を用い、値の集合から無作為に値を抽出する方法について説明します。\n\nsample(x = 値の集合ベクトル, size = 抽出の回数, \n       replace = 復元抽出の有無, prob = 各要素が抽出される確率)\n\n　replaceは復元抽出の有無を指定する引数であり、既定値はFALSE、つまり非復元抽出がデフォルトとなっています。これは一度抽出された要素は、二度と抽出されないことを意味します。値の集合が{0, 1}で、5個の値を抽出する（=sizeがxの長さより大きい）ならば、replaceは必ずTRUEに設定する必要があります。抽選などは非復元抽出であるため、replace引数は省略可能です。しかし、対数の法則やブートストラップなどは復元抽出を仮定している場合が多く、意識的にreplace関数は指定することを推奨します。probは各要素が抽出される確率を意味し、xの実引数と同じ長さのnumeric型ベクトルを指定します。probの実引数の総和は1であることが望ましいですが、総和が1でない場合、自動的に総和が1になるよう正則化を行います。つまり、c(1, 3)はc(0.25, 0.75)と同じことを意味します。\n　サイコロを3回振るコードを書くなら、値の集合（x）はc(1, 2, 3, 4, 5, 6)、または1:6で、抽出の回数（size）は3となります。また、一回出た目も抽出される可能性があるため、復元抽出を行う必要があります（replace = TRUE）。そして各目が出る確率は1/6ですが、各値が抽出される確率が等しい場合、省略可能です。\n\n# この場合、prob引数は省略可能\nsample(1:6, 3, replace = TRUE, prob = rep(1/6, 6))\n\n[1] 3 3 5\n\n\n　今回はサイコロを1万回振り、それぞれの目が出た回数を棒グラフとして示してみます。無作為に抽出された値であれば、各目が出る回数は等しいはずです。ベクトルに対してtable()関数を使うと、各要素が出現した回数が出力され、このオブジェクトをbarplot()関数に渡すと棒グラフを作成することができます。\n\nDice_vec &lt;- sample(1:6, 10^4, replace = TRUE)\ntable(Dice_vec) |&gt; barplot()\n\n\n\n\n図 29.1: 6面体サイコロを1万回投げた場合\n\n\n\n\n　1から6までの目が出た回数がほぼ同じであることが確認できます。この6つの棒の高さがすべて同じになることはありえませんが（そもそも1万を6で割ったら余りが出ますね）、ほぼ同じ割合であることから、疑似乱数とは言え、シミュレーション用としては十分でしょう。\n\n\n29.2.2 確率分布からの乱数制制\n\n\n\n関数名\n確率分布\nパラメーター\n\n\n\n\nrbeta()\nベータ分布\nn, shape1, shape2\n\n\nrbinom()\n二項分布\nn, size, prob\n\n\nrcauchy()\nコーシー分布\nn, location, scale\n\n\nrchisq()\n\\(\\chi^2\\)分布\nn, df\n\n\nrexp()\n指数分布\nn, rate\n\n\nrf()\n\\(F\\)分布\nn, df1, df2\n\n\nrgamma()\nガンマ分布\nn, shape, scale\n\n\nrgeom()\n幾何分布\nn, prob\n\n\nrhyper()\n超幾何分布\nnn, m, n, k\n\n\nrlnorm()\n対数正規分布\nn, meanlog, sdlog\n\n\nrmultinom()\n多項分布\nn, size, prob\n\n\nrnbinom()\n負の二項分布\nn, size, prob\n\n\nrnorm()\n正規分布\nn, mean, sd\n\n\nrpois()\nポアソン分布\nn, lambda\n\n\nrt()\nt分布\nn, df\n\n\nrunif()\n一様分布\nn, min, max\n\n\nrweibull()\nワイブル分布\nn, shape, scale\n\n\nmvtnorm::rmvnorm()\n多変量正規分布\nn, mean, sigma\n\n\n\n　以上の表に掲載されているパラメーター以外にも指定可能なパラメーターがあるため、詳細は各関数のヘルプを参照してください。たとえば、ガンマ分布の場合、rateで、負の二項分布の場合、muで分布の形状を指定することができます。また、多変量正規分布の乱数を抽出するには{mvtnorm}パッケージのrmvnorm()を使いますが、ここでのmeanは数値型ベクトル、sigmaは行列構造の分散共分散行列を使います1。\n\n\n29.2.3 シードについて\n　特定の分布から乱数を抽出する場合、当たり前ですが、抽出の度に値が変わります。たとえば、平均0、標準偏差1の正規分布（標準正規分布）から5つの値を抽出し、小数点3桁に丸める作業を3回繰り返しみましょう。\n\nrnorm(5) |&gt; round(3)\n\n[1]  0.477  0.410 -1.005  0.147 -0.294\n\nrnorm(5) |&gt; round(3)\n\n[1] -0.324  2.422  0.567 -0.811  1.364\n\nrnorm(5) |&gt; round(3)\n\n[1] -0.552  0.033 -0.324  2.659 -0.453\n\n\n　このように、抽出の度に結果が変わります。1回きりのシミュレーションではこれで問題ないでしょうが、同じシミュレーションから同じ結果を得るためには、乱数を固定する必要があります。そこで使うのがシード（seed）です。シードが同じなら抽出される乱数は同じ値を取ります。シードの指定はset.seed(numeric型スカラー)です。たとえば、シードを19861008にし、同じ作業をやってみましょう。\n\nset.seed(19861008)\nrnorm(5) |&gt; round(3)\n\n[1] -0.086  0.396 -1.330  0.574  0.152\n\nrnorm(5) |&gt; round(3)\n\n[1]  0.555  0.620 -1.133  0.572  0.900\n\n\n　シードを指定しても2つのベクトルは異なる値を取りますが、もう一度シードを指定してから乱数抽出をしてみましょう。\n\nset.seed(19861008)\nrnorm(5) |&gt; round(3)\n\n[1] -0.086  0.396 -1.330  0.574  0.152\n\n\n　先ほどのコードでシードを指定した直後に抽出した乱数と同じ乱数が得られました。モンテカルロ・シミュレーションにおいて乱数は非常に重要ですが、これはシミュレーションの度に異なる結果が得られることを意味します。つまり、自分が書いたコードから100%同じ結果が得られないだけでなく、自分も同じ結果を再現できないことを意味します。この場合、シードを指定すると乱数が固定され、シミュレーション結果の再現ができるようになります。\n　一つ注意すべき点は乱数を固定した後、複数回抽出を繰り返す場合、その順番も固定されるという点です。たとえば、シードを固定せずにもう一回5つの値を抽出してみましょう。\n\nrnorm(5) |&gt; round(3)\n\n[1]  0.555  0.620 -1.133  0.572  0.900\n\n\n　この結果は先ほどシード指定後、2回目の抽出結果と同じ結果となります。結果を再現するという点では大きな問題はないはずですが、仕様を理解しておくことは重要でしょう。"
  },
  {
    "objectID": "monte.html#sec-monte-birthday",
    "href": "monte.html#sec-monte-birthday",
    "title": "29  モンテカルロ・シミュレーション",
    "section": "29.3 例1: 誕生日問題",
    "text": "29.3 例1: 誕生日問題\n　まず簡単な例として誕生日問題 (birthday problem)をシミュレーションで確認してみましょう。誕生日問題とは「何人いれば、その中に誕生日が同じ2人以上がいる確率が50%を超えるか。」といった問題です。1年を365日で考えると（2月29日生まれの皆さん、すみません…）、366人がいれば確実に (= 100%)同じ誕生日の人が2人以上いることになりますね。100%でなく、50%まで基準を下げるならその半分である183人は必要じゃないかと思うかも知れません。しかし、実はたった23人が集まれば、その中で同じ誕生日の人が2人以上いる確率が50%になります。誕生日のパラドックスとも呼ばれるものですが、これをシミュレーションで確認してたいと思います。\n　学生の数をn_studentとし、1から365までの公差1の等差数列から、n_student個の値を復元抽出します。\n\nn_student &lt;- 30 # 学生数\n# 「1から365までの公差1の等差数列」からn_student個の値を復元抽出\nBirth_vec &lt;- sample(1:365, n_student, replace = TRUE)\n\nBirth_vec\n\n [1] 340 122 230 148  12 136  87  46  16 310 104 351 137  53 361  65 106 361 108\n[20] 281 299  67 342   4 338  88 156 254 192  37\n\n\n　このベクトルの中で重複する要素があるかどうかを確認するにはduplicated()関数を使います。ある要素が他の要素と重複するならTRUEが、なければFALSEが表示されます。\n\nduplicated(Birth_vec)\n\n [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE\n[25] FALSE FALSE FALSE FALSE FALSE FALSE\n\n\n　ただし、一つでもTRUEが含まれていれば、同じ誕生日の人が二人以上はいるということとなるので、更にany()関数を使います。any()内の条件文において、一つでもTRUEがあれば返り値はTRUEとなり、全てFALSEならFALSEを返す関数です。\n\nany(duplicated(Birth_vec))\n\n[1] TRUE\n\n\n　以上の作業を100回繰り返す場合、試行回数が100回となります。この場合、TRUEの結果が出る試行は何回でしょうか。\n\nn_student &lt;- 10   # 学生数\nn_trials  &lt;- 100  # 試行回数\n\n# 結果を格納する空ベクトルを用意する\nResult_vec &lt;- rep(NA, n_trials)\n\n# 反復処理\nfor (i in 1:n_trials) {\n    Birth_vec     &lt;- sample(1:365, n_student, replace = TRUE)\n    Result_vec[i] &lt;- any(duplicated(Birth_vec))\n}\n\nResult_vec\n\n  [1] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n [13] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE\n [25] FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [37] FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE\n [49] FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [61] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE FALSE FALSE FALSE FALSE\n [73] FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [85] FALSE FALSE FALSE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n [97] FALSE FALSE FALSE FALSE\n\n\n　100回の試行の中でTRUEが出たのは10回ですね。割合で考えると10%です。この試行回数を無限にすると確率として解釈できますが、無限回繰り返しは世の中が終わるまでやっても終わりませんね。ただし、十分に多い試行回数、たとえば1万回程度繰り返すと確率に近似できるでしょう。\n\nn_student &lt;- 10    # 学生数\nn_trials  &lt;- 10000 # 試行回数\n\n# 結果を格納する空ベクトルを用意する\nResult_vec &lt;- rep(NA, n_trials)\n\n# 反復処理\nfor (i in 1:n_trials) {\n    Birth_vec     &lt;- sample(1:365, n_student, replace = TRUE)\n    Result_vec[i] &lt;- any(duplicated(Birth_vec))\n}\n\nsum(Result_vec)\n\n[1] 1147\n\n\n　1万回の試行からTRUEが出た回数は1147回であり、11.5%ですね。つまり、人が10人集まれば誕生日が同じ人が2人以上いる確率は約11.5%ということになります。実はこの確率は厳密に計算可能であり、理論的な確率は約11.7%です。シミュレーションから得られた結果が理論値にかなり近似していることが分かります。\n　今回は試行回数は100に固定し、学生数を2から100まで調整しながら同じ誕生日の人が2人以上いる割合を計算してみましょう。以下では割合を計算する関数Birthday_Func()を作成し、{purrr}のmap_dbl()関数を使用して反復処理を行います。関数の作成は第12章を、{purrr}の使い方については第27章を参照してください。\n\n# 割合を計算する関数を作成する\nBirthday_Func &lt;- function (n, n_trials) {\n    \n    # 各試行の結果を格納する空ベクトルを用意する。\n    Result_vec &lt;- rep(NA, n_trials)\n    \n    # n_trials回だけ{}内コードを繰り返す。\n    for (i in 1:n_trials) {\n        # 1:365からn個の値を復元抽出\n        Birth_vec     &lt;- sample(1:365, n, replace = TRUE)\n        # 重複する要素があるかをチェックし、結果ベクトルのi番目に格納\n        Result_vec[i] &lt;- any(duplicated(Birth_vec))\n    }\n    \n    # 各試行結果が格納されたベクトルからTRUEの割合を返す\n    mean(Result_vec)\n}\n\n# 学生数をStudents列に格納したデータフレーム (tibble)を作成\nProb_df &lt;- tibble(Students = 2:100)\n\n# Students列の値に応じてBirthday_Func()を実行\nProb_df &lt;- Prob_df |&gt;\n    mutate(Probs = map_dbl(Students, ~Birthday_Func(.x, 100)))\n\n　{purrr}関数を使わずに、for()文を使用した例は以下のようになります。\n\n# {purrr}を使わない方法\nProb_df &lt;- tibble(Students = 2:100,\n                  Probs    = NA)\n\nfor (i in 1:nrow(Prob_df)) {\n    \n    Result_vec &lt;- rep(NA, n_trials)\n    \n    for (j in 1:n_trials) {\n        Birth_vec     &lt;- sample(1:365, Prob_df$Students[i], replace = TRUE)\n        Result_vec[j] &lt;- any(duplicated(Birth_vec))\n    }\n    \n    Prob_df$Probs[i] &lt;- mean(Result_vec)\n}\n\n　結果を確認してみましょう。\n\nProb_df\n\n# A tibble: 99 × 2\n   Students Probs\n      &lt;int&gt; &lt;dbl&gt;\n 1        2  0.01\n 2        3  0.02\n 3        4  0.06\n 4        5  0.01\n 5        6  0.02\n 6        7  0.08\n 7        8  0.06\n 8        9  0.09\n 9       10  0.12\n10       11  0.18\n# ℹ 89 more rows\n\n\n　学生数が何人いれば、同じ誕生日の人が2人以上いる割合が50%になるのでしょうか。割合が0.4以上、0.6以下の行を抽出してみましょう。\n\nProb_df |&gt;\n    filter(Probs &gt;= 0.4 & Probs &lt;= 0.6)\n\n# A tibble: 7 × 2\n  Students Probs\n     &lt;int&gt; &lt;dbl&gt;\n1       18  0.41\n2       21  0.46\n3       22  0.41\n4       23  0.45\n5       24  0.52\n6       25  0.58\n7       27  0.56\n\n\n　大体23人前後ですかね。試行回数を増やせばもう少し厳密に検証出来るかも知れませんが、とりあえず以上の結果を可視化してみましょう。\n\nProb_df |&gt;\n    ggplot() +\n    geom_line(aes(x = Students, y = Probs * 100), size = 1) +\n    geom_hline(yintercept = 50, color = \"red\", linetype = 2) +\n    labs(x = \"学生数\",\n         y = \"同じ誕生日の人が2人以上いる割合 (%)\\n(試行回数 = 100)\") +\n    theme_bw(base_size = 12)\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n図 29.2: 同じ誕生日の人が2人以上いる割合 (%) (試行回数 = 100)\n\n\n\n\n　非常に直感に反する結果かも知れませんが、50人程度いれば、ほぼ確実に同じ誕生日の人が2人以上いることが分かります。この誕生日問題は以下のように解くことができます。人が\\(n\\)人いる場合、同じ誕生日の人が2人以上いる確率\\(p(n)\\)は、\n\\[\np(n) = 1 - \\frac{365!}{365^n (365-n)!}\n\\]\n　!は階乗を意味し、5!は\\(5 \\times 4 \\times 3 \\times 2 \\times 1\\)を意味します。Rではfactorial()関数を使います。それでは\\(p(50)\\)はいくらでしょうか。\n\n1 - factorial(365) / (365^50 * factorial(365 - 50))\n\n[1] NaN\n\n\n　あらら、NaNがでましたね。つまり、計算不可です。実際、factorial(365)だけでも計算結果はInfが出ます。むろん、実際に無限ではありませんが、非常に大きい数値ということです。以上の式を計算可能な式に変形すると以下のようになります。\n\\[\np(n) = 1 - \\frac{n! \\times _{365}C_n}{365^n}\n\\]\n　\\(C\\)は二項係数を意味し\\(_nC_k\\)は\\(\\frac{n!}{k!(n-k)!}\\)です。Rではchoose(n, k)で計算可能です。\n\n1 - ((factorial(50) * choose(365, 50)) / 365^50)\n\n[1] 0.9703736\n\n\n　結果は0.9703736です。つまり、人が50人いれば同じ誕生日の人が2人以上いる確率は約97%ということです。それでは、以上の式を関数化し、p(22)とp(23)を計算してみましょう。\n\nBirth_Expect &lt;- function (n) {\n    1 - ((factorial(n) * choose(365, n)) / 365^n)\n}\n\nBirth_Expect(22)\n\n[1] 0.4756953\n\nBirth_Expect(23)\n\n[1] 0.5072972\n\n\n　確率が50%を超える人数は23人であることが分かります。先ほどのデータフレーム (Prob_df)にこの理論値をExpectという名の列として追加してみましょう。\n\nProb_df &lt;- Prob_df |&gt;\n    mutate(Expect = map_dbl(Students, ~Birth_Expect(.x)))\n\nProb_df\n\n# A tibble: 99 × 3\n   Students Probs  Expect\n      &lt;int&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1        2  0.01 0.00274\n 2        3  0.02 0.00820\n 3        4  0.06 0.0164 \n 4        5  0.01 0.0271 \n 5        6  0.02 0.0405 \n 6        7  0.08 0.0562 \n 7        8  0.06 0.0743 \n 8        9  0.09 0.0946 \n 9       10  0.12 0.117  \n10       11  0.18 0.141  \n# ℹ 89 more rows\n\n\n　これは人間にとっては読みやすい表ですが、可視化まで考えると、tidyなデータといは言えません。したがって、pivot_longer()関数を使用してtidyなデータに整形します。{tidyr}パッケージの使い方は第16章を参照してください。\n\nProb_df2 &lt;- Prob_df |&gt;\n    pivot_longer(cols      = Probs:Expect,\n                 names_to  = \"Type\",\n                 values_to = \"Prob\") \n\nProb_df2\n\n# A tibble: 198 × 3\n   Students Type      Prob\n      &lt;int&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1        2 Probs  0.01   \n 2        2 Expect 0.00274\n 3        3 Probs  0.02   \n 4        3 Expect 0.00820\n 5        4 Probs  0.06   \n 6        4 Expect 0.0164 \n 7        5 Probs  0.01   \n 8        5 Expect 0.0271 \n 9        6 Probs  0.02   \n10        6 Expect 0.0405 \n# ℹ 188 more rows\n\n\n　こちらのデータを使用し、シミュレーションから得られた結果と理論値を折れ線グラフで出力してみましょう。\n\nProb_df2 |&gt;\n    mutate(Type = ifelse(Type == \"Probs\", \"シミュレーション\", \"理論値\")) |&gt;\n    ggplot() +\n    geom_line(aes(x = Students, y = Prob * 100, color = Type), size = 1) +\n    labs(x     = \"学生数\",\n         y     = \"同じ誕生日の人が2人以上いる割合 (%)\\n(試行回数 = 100)\",\n         color = \"\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\")\n\n\n\n\n図 29.3: 同じ誕生日の人が2人以上いる割合 (%) (試行回数 = 100)\n\n\n\n\n　最後に以上の作業を試行回数10000としてもう一回やってみましょう。\n\n# 学生数をStudents列に格納したデータフレーム (tibble)を作成\nProb_df &lt;- tibble(Students = 2:100)\n\n# Students列の値に応じてBirthday_Func()を実行\nProb_df &lt;- Prob_df |&gt;\n    mutate(Simul  = map_dbl(Students, ~Birthday_Func(.x, 10000)),\n           Expect = map_dbl(Students, ~Birth_Expect(.x)))\n\nProb_df |&gt;\n    pivot_longer(cols      = Simul:Expect,\n                 names_to  = \"Type\",\n                 values_to = \"Prob\") |&gt;\n    mutate(Type = ifelse(Type == \"Simul\", \"シミュレーション\", \"理論値\")) |&gt;\n    ggplot() +\n    geom_line(aes(x = Students, y = Prob * 100, color = Type), size = 1) +\n    labs(x     = \"学生数\",\n         y     = \"同じ誕生日の人が2人以上いる割合 (%)\\n(試行回数 = 100)\",\n         color = \"\") +\n    theme_bw(base_size = 12) +\n    theme(legend.position = \"bottom\")\n\n\n\n\n図 29.4: 同じ誕生日の人が2人以上いる割合 (%) (試行回数 = 100)\n\n\n\n\n　モンテカルロ・シミュレーションから得られた割合と理論上の確率が非常に近似していることが分かります。"
  },
  {
    "objectID": "monte.html#sec-monte-montyhall",
    "href": "monte.html#sec-monte-montyhall",
    "title": "29  モンテカルロ・シミュレーション",
    "section": "29.4 例2: モンティ・ホール問題",
    "text": "29.4 例2: モンティ・ホール問題\n　抽出される乱数が必ずしも数値である必要はありません。たとえば、コイン投げの表と裏、ポーカーで配られたカードなど、数値以外の乱数もあり得ます。ここでは「AとB、C」から一つを選ぶ例として、モンティ・ホール問題をモンテカルロ法で解いてみましょう。\n　モンティ・ホール問題はアメリカのテレビ番組「Let’s make a deal」の中のゲームであり、この番組の司会者の名前がモンティ・ホール (Monty Hall)さんです。このゲームのルールは非常にシンプルです。\n\n3つのドアがあり、1つのドアの裏に商品 (車)がある。残りの2つは外れ（ヤギ）である。\n参加者はドアを選択する。\n司会者が残りのドア2つの中で商品がないドアを開けて中身を見せる。\nここで参加者はドアの選択を変える機会が与えられる。\n\n　直観的に考えて、司会者が外れのドアを1つ教えてくれたなら、自分が選んだドアを含め、残りの2つのドアの1つに絶対に商品があります。直感的に考えてみると、当たる確率は半々であって、変えても、変えなくても当たる確率は同じだと考えられます。詳細はWikipediaなどを参照してください。この問題を巡る論争とかも紹介されていてなかなか面白いです。\n　結論から申しますと選択を変えた方が、変えなかった場合より当たる確率が2倍になります。これは条件付き確率とベイズの定理を用いることで数学的に説明できますが、ここではあえてモンテカルロ法で調べてみたいと思います。シミュレーションの具体的な手順は以下の通りです。\n\n結果を格納する長さ1万の空ベクトルを2つ用意する。 (Switch_YesとSwitch_No)。\niの初期値を1とする。\n当たり (車)の位置をA, B, Cの中から無作為に1つ決め、Car_Positionに格納する。\n最初の選択肢をA, B, Cの中から無作為に1つ決め、Choiceに格納する。\n選択肢を変更した場合の結果をSwitch_Yesのi番目の要素としてに格納する。\n\n当たりの位置と最初の選択肢が同じなら (Switch_Yes == Choice)、結果は外れ (ヤギ)\n当たりの位置と最初の選択肢が同じでないなら (Switch_Yes != Choice)、結果は当たり (車)\n\n選択肢を変更しなかった場合の結果をSwitch_Noのi番目の要素として格納する。\n\n当たりの位置と最初の選択肢が同じなら (Switch_Yes == Choice)、結果は当たり (車)\n当たりの位置と最初の選択肢が同じでないなら (Switch_Yes != Choice)、結果は外れ (ヤギ)\n\niの値を1増やし、3に戻る。\n3〜7の手順を1万回繰り返す。\n\n　以上の手順をコードで書くと以下のようになります。\n\nSwitch_Yes &lt;- rep(NA, 10000)\nSwitch_No  &lt;- rep(NA, 10000)\n\nset.seed(19861009)\nfor (i in 1:10000) {\n    Car_Position &lt;- sample(c(\"A\", \"B\", \"C\"), 1)\n    Choice       &lt;- sample(c(\"A\", \"B\", \"C\"), 1)\n    \n    Switch_Yes[i] &lt;- ifelse(Car_Position == Choice, \"Goat\", \"Car\")\n    Switch_No[i]  &lt;- ifelse(Car_Position == Choice, \"Car\", \"Goat\")\n}\n\ntable(Switch_Yes)\n\nSwitch_Yes\n Car Goat \n6737 3263 \n\ntable(Switch_No)\n\nSwitch_No\n Car Goat \n3263 6737 \n\n\n　選択肢を変更し、車を獲得した回数は10000回中、6737であり、約67%です。つまり、選択肢を変えた方が、変えなかった場合に比べ、車が当たる確率が約2倍高いことを意味します。むろん、車よりもヤギが重宝される地域に住んでいるなら、あえて選択肢を変えず、ヤギを狙った方が良いかも知れません。"
  },
  {
    "objectID": "monte.html#sec-monte-pi",
    "href": "monte.html#sec-monte-pi",
    "title": "29  モンテカルロ・シミュレーション",
    "section": "29.5 例3: 円周率の計算",
    "text": "29.5 例3: 円周率の計算\n　今回はもう一つの例として、円周率 (\\(\\pi\\))の計算を紹介したいと思います。\\(\\pi\\)は無理数であるため、厳密な計算は出来ませんが、モンテカルロ・シミュレーションである程度近似できます。たとえば、半径1 (\\(r = 1\\))の円を考えてみましょう。\n\n\n\n\n\n\n\n\n\n　円の面積は\\(r^2\\pi\\)であるため、この円の面積は\\(\\pi\\)です。また、四角形は辺の長さが2の正四角形ですから面積は4です。続いて、四角形の範囲内の点を付けます。無作為に20個を付けてみます。\n\n\n\n\n\n\n\n\n\n　20個点のうち、円の外側にあるのは5個、円の内側は15個です。つまり、75%の点が円内にあることを意味します。点の位置は無作為ですので、もし円の大きさが\\(\\pi\\)であれば、点が円内に入る確率は\\(\\frac{\\pi}{4}\\)です。今回の例だと\\(\\frac{\\pi}{4} = 0.75\\)であるため、\\(\\pi = 0.75 \\times 4 = 3\\)となります。実際の円周率は3.141593…なので、そこそこ近似できていますね。\n　それではこれを実際にやってみましょう。今回は20個の点ではなく、100個にしてみましょう。まず、100個の点を無作為に抽出します。\n\nset.seed(19861009)\npi_df &lt;- tibble(x = runif(100, -1, 1),\n                y = runif(100, -1, 1))\n\npi_df\n\n# A tibble: 100 × 2\n         x      y\n     &lt;dbl&gt;  &lt;dbl&gt;\n 1 -0.950  -0.344\n 2  0.0724  0.150\n 3  0.874   0.971\n 4  0.938   0.267\n 5  0.205   0.469\n 6 -0.343  -0.590\n 7 -0.0245 -0.635\n 8 -0.273  -0.886\n 9 -0.405   0.701\n10  0.528  -0.547\n# … with 90 more rows\n\n\n　まず、各辺の長さが2の正四角形とpi_dfで生成した100個の点をプロットします。四角形を描くときにはgeom_rect()幾何オブジェクトを使用します。マッピングは四角形の左下の座標 (xminとymin)、右上の座標 (xmaxとymax)に行います。今回は原点が (0, 0)の半径1の円に接する四角形ですから、左下の座標は (-1, -1)、右上の座標は (1, 1)となります。\n\npi_df |&gt;\n    ggplot() +\n    geom_rect(aes(xmin = -1, ymin = -1, xmax = 1, ymax = 1),\n              fill = \"white\", color = \"black\") +\n    geom_point(aes(x = x, y = y)) +\n    coord_fixed(ratio = 1) +\n    theme_minimal()\n\n\n\n\n\n\n\n\n　ここに円を追加してみましょう。円を描くときには{ggforce}パッケージのgeom_circle()幾何オブジェクトを使用します。マッピングは円の原点 (x0とy0)、円の半径 (r)です。原点は (0, 0)で半径は1の円を重ねます。\n\npi_df |&gt;\n    ggplot() +\n    geom_rect(aes(xmin = -1, ymin = -1, xmax = 1, ymax = 1),\n              fill = \"white\", color = \"black\") +\n    geom_circle(aes(x0 = 0, y0 = 0, r = 1)) +\n    geom_point(aes(x = x, y = y)) +\n    coord_fixed(ratio = 1) +\n    theme_minimal()\n\n\n\n\n\n\n\n\n　これだけだと読みづらいので、円の中か外かで点の色分けをしてみましょう。そのためには各点が円内に入っているかどうかを判定した変数in_circleを追加します。点(\\(x\\), \\(y\\))が、原点が(\\(x^\\prime\\), \\(y^\\prime\\))、かつ半径\\(r\\)の円内に入っている場合、\\((x - x^\\prime)^2 + (y - y^\\prime)^2 &lt; r^2\\)が成立します。今回は原点が (0, 0)で、半径が1であるため、\\(x^2 + y^2 &lt; 1\\)か否かを判定します。この条件を満たしているかどうかを示すin_circleという変数を追加します。\n\npi_df &lt;- pi_df |&gt;\n    mutate(in_circle = if_else(x^2 + y^2 &lt; 1^2, \"円内\", \"円外\"))\n\n　散布図レイヤー (geom_point())内にcolorをin_circle変数でマッピングします。\n\npi_df |&gt;\n    ggplot() +\n    geom_rect(aes(xmin = -1, ymin = -1, xmax = 1, ymax = 1),\n              fill = \"white\", color = \"black\") +\n    # 円の内側か外側かで色分け\n    geom_point(aes(x = x, y = y, color = in_circle), size = 2) +\n    geom_circle(aes(x0 = 0, y0 = 0, r = 1)) +\n    labs(x = \"X\", y = \"Y\", color = \"\") +\n    coord_fixed(ratio = 1) +\n    theme_void(base_size = 12)\n\n\n\n\n\n\n\n\n　実際に円内の点と円外の点の個数を数えてみましょう。\n\npi_df |&gt;\n    group_by(in_circle) |&gt;\n    summarise(N = n())\n\n# A tibble: 2 × 2\n  in_circle     N\n  &lt;chr&gt;     &lt;int&gt;\n1 円内         82\n2 円外         18\n\n\n　円内の点は82個、円外の点は18ですね。つまり、\\(\\frac{\\pi}{4} = 0.82\\)であり、\\(\\pi = 0.82 \\times 4 = 3.28\\)です。\n\n82 / 100 * 4\n\n[1] 3.28\n\n\n　今回は100個の点で円周率の近似値を計算しましたが、点の数を増やすとより正確な近似値が得られます。以下の例は10000個の点から得られた円周率の例です。\n\n\n\n\n\n\n\n\n\n# A tibble: 2 × 2\n  in_circle     N\n  &lt;chr&gt;     &lt;int&gt;\n1 円内       3919\n2 円外       1081\n\n\n　円内の点は3919個、円外の点は1081ですね。この結果から円周率を計算してみましょう。\n\n3919 / 5000 * 4\n\n[1] 3.1352\n\n\n　より実際の円周率に近い値が得られました。"
  },
  {
    "objectID": "monte.html#sec-monte-bootstrap",
    "href": "monte.html#sec-monte-bootstrap",
    "title": "29  モンテカルロ・シミュレーション",
    "section": "29.6 例4: ブートストラップ法",
    "text": "29.6 例4: ブートストラップ法\n　最後に、様々な分析から得られた統計量の不確実性を計算する方法の一つであるブートストラップ法 (bootstrapping)について説明します。たとえば、平均値の差分の検定 (t検定)差、回帰分析における標準誤差などはRのt.test()、lm()関数を使用すれば瞬時に計算できます。こちらの標準誤差はデータを与えられれば、常に同じ値が得られるもので、何らかの計算式があります。しかし、世の中にはモデルが複雑すぎて、統計量の標準誤差がうまく計算できないケースもあります。そこで登場するのがブートストラップ法を用いると、不確実性の近似値が得られます。ブートストラップ法は Efron (1979) が提案した以来、データ分析において広く使われています。ブートストラップ法については優れた教科書が多くあるので詳細な説明は割愛し、以下ではブートストラップ法の簡単な例を紹介します。\n　ブートストラップにおいて重要なのは元のデータセットのサンプルサイズを\\(n\\)とした場合、復元抽出を用いてサンプルサイズ\\(n\\)のデータセットをもう一度構築することです。そしてその平均値を計算します。これらの手順を5000回繰り返せば、5000個の平均値が得られます。この5000個の平均値の平均値は元のデータセットの平均値に近似し、5000個の平均値の標準偏差は元のデータセットの平均値の標準誤差 (標準誤差)に近似できます。これは本当でしょうか。実際にやってみましょう。\n　まずは、長さ100のベクトルを2つ作成します。この2つのベクトルは平均値が0.7、0.9、標準偏差1の正規分布に従うとします。\n\\[\n\\begin{aligned}\n\\mbox{Data1} & \\sim \\mbox{Normal}(\\mu = 0.7, \\sigma = 1) \\\\\n\\mbox{Data2} & \\sim \\mbox{Normal}(\\mu = 0.9, \\sigma = 1)\n\\end{aligned}\n\\]\n　2つの標本の平均値の差分は約0.2です。この差分の不確実性はいくらでしょうか。ここでは主に使われる平均値の差の検定 (\\(t\\)検定)をやってみましょう。回は標準誤差が同じ2つの分布から得られた標本であるため、等分散を仮定する\\(t\\)検定を行います (var.equal = TRUEを追加)。\n\nset.seed(19861009)\nData1 &lt;- rnorm(100, 0.7, 1)\nData2 &lt;- rnorm(100, 0.9, 1)\n\nttest_result &lt;- t.test(Data1, Data2, var.equal = TRUE)\n\nttest_result\n\n\n    Two Sample t-test\n\ndata:  Data1 and Data2\nt = -2.1707, df = 198, p-value = 0.03114\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.58521800 -0.02807095\nsample estimates:\nmean of x mean of y \n0.6912143 0.9978588 \n\n\n平均値の差分の不確実性 (=標準誤差)はttest_result$stderrで抽出可能であり、今回は約0.141です。標準誤差の値さえ分かれば、検定統計量も、信頼区間も、\\(p\\)値も計算できるため、重要なのはやはり標準誤差でしょう。以下では試行回数は1万のブートストラップ法で標準誤差の近似値を計算してみます。\n\n結果を格納する長さ1万の空ベクトルResult_vecを作成する。\niの初期値を1と設定する。\nData1から100個 (= Data1の大きさ)の値を無作為抽出 (復元抽出)し、Sample1に格納する。\nData2から100個 (= Data2の大きさ)の値を無作為抽出 (復元抽出)し、Sample2に格納する。\nResult_vecのi番目の位置にSample1の平均値とSample2の平均値の差分を格納する。\niを1増加させる。\n3~6の手順を1万回繰り返す。\n\n\nn_trials   &lt;- 10000\nResult_vec &lt;- rep(NA, n_trials)\n\nfor (i in 1:n_trials) {\n    Sample1 &lt;- sample(Data1, 100, replace = TRUE)\n    Sample2 &lt;- sample(Data2, 100, replace = TRUE)\n    \n    Result_vec[i] &lt;- mean(Sample1) - mean(Sample2)\n}\n\n　Result_vecには平均値の差分が10000個格納されており、これらの値の平均値をブートストラップ推定量 (bootstrap estimate)と呼ぶとします。\n\n# 元のデータの平均値の差分\ndelta &lt;- mean(Data1) - mean(Data2)\ndelta\n\n[1] -0.3066445\n\n# ブートストラップ推定量 (平均値の差分の平均値)\nboot_delta &lt;- mean(Result_vec)\nboot_delta\n\n[1] -0.3045563\n\n# ブートストラップ推定量のバイアス\nboot_b &lt;- delta - boot_delta\n\n　実際の平均値の差分 (\\(\\delta_0\\)) は-0.3066445、ブートストラップ推定量 (\\(\\delta^*\\)) は -0.3045563であるため、その差は-0.0020881です。これをブートストラップ推定量のバイアス (\\(b\\)) と呼びます。\n　ただし、我々に興味があるのは平均値の差分ではありません。平均値の差分はブートストラップ法を用いなくても普通に計算できるからです。ここで重要なのは平均値の差分の不確実性、つまり標準誤差でしょう。ブートストラップ推定量の標準誤差はResult_vecの標準偏差を計算するだけで十分です。\n\nboot_se &lt;- sd(Result_vec) # ブートストラップ推定量の標準偏差\n\n　ブートストラップ推定量の標準偏差 (\\(\\mbox{se}^*\\))は約0.14であり、t検定の結果から得られた標準誤差0.141と非常に近い値が得られました。\n　95%信頼区間を計算してみます。百分位数信頼区間 (Percentile CI)はResult_Vecの左側の領域が2.5%、右側の領域が2.5%となる区間ですので、quantile()関数で計算することができます。\n\n# 95%信頼区間\nquantile(Result_vec, c(0.025, 0.975))\n\n       2.5%       97.5% \n-0.58084484 -0.02999534 \n\n\n　バイアスを補正しないWald信頼区間は\\(\\delta_0 \\pm 1.96 \\times \\mbox{se}^*\\)のように計算します (1.96は標準正規分布の累積密度分布において下側領域が0.975となる点です。)。\n\ndelta + qnorm(c(0.025, 0.975)) * boot_se\n\n[1] -0.58201710 -0.03127185\n\n\n　バイアス修正Wald信頼区間は\\((\\delta_0 - b) \\pm 1.96 \\times \\mbox{se}^*\\)です。\n\n(delta - boot_b) + qnorm(c(0.025, 0.975)) * boot_se\n\n[1] -0.57992897 -0.02918372\n\n\n　これまでの結果を比較してみましょう。\n\n\n\n\n\n  \n    \n    \n      \n      t検定\n      ブートストラップ\n    \n  \n  \n    (1): 平均値の差分\n-0.307\n-0.305\n    (2): 標準誤差\n0.141\n0.140\n    (3): 95%信頼区間\n[-0.585, -0.028]\n\n    (4): 95%信頼区間 (百分位数)\n\n[-0.581, -0.030]\n    (5): 95%信頼区間 (Wald)\n\n[-0.582, -0.031]\n    (6): 95%信頼区間 (バイアス修正Wald)\n\n[-0.580, -0.029]\n  \n  \n  \n\n\n\n\n　今回の例はt.test()関数を使えば一発で終わる問題ですが、モデルが複雑になれば推定量の不確実性の計算が難しくなるケースがあります。その時に力を発揮するのがブートストラップ方であり、{boot}、{bootstrap}、{simpleboot}など様々なパッケージが利用可能です。\n\n\n\n\nEfron, Bradley. 1979. 「Bootstrap Methods: Another Look at the Jackknife」. The Annals of Statistics 7: 1–26."
  },
  {
    "objectID": "scraping.html#html",
    "href": "scraping.html#html",
    "title": "30  スクレイピング",
    "section": "30.1 HTML",
    "text": "30.1 HTML\n　我々が普段見るウェブページは主にHTML（HyperText Markup Language）という言語で記述されている。裏ではPhp、Ruby、Pythonなどが動いているかも知れないが、少なくとも我々がウェブブラウザー（Firefox、Chrome、Safari、Edge等）越しで見る内容はHTML（+CSS、JavaScript、WebAssembly等）で記述されたものだ。（ウェブ）スクレイピングはこのHTMLで記述された表示内容（の一部）を構造化されたデータとして読み込むことである。\n　したがって、スクレイピングをするためにはHTMLの基本的な知識が必要だ。一つの画面に表示された内容の中で我々が欲しいものは、全体内容の一部だ。これはスクレイピングを行う際、全体内容の中から取得する箇所を指定する必要があることを意味する。そこで重要なのがタグ（tag）と属性（attribute）、セレクター（selector）だ。\n\n30.1.1 タグ\n　タグは&lt;タグ名&gt;と&lt;/タグ名&gt;で構成され1、この間に挟まれた内容は予め決まった書式となる。例えば、&lt;em&gt;R Not for Everyone&lt;/em&gt;は「R Not for Everyone」という文字列に対して&lt;em&gt;タグを適用するコードである。&lt;em&gt;タグは予めHTMLで用意されているものであり、文字列をイタリック（例：R Not for Everyone）にするものだ。また、&lt;strong&gt;タグは太字を意味し、&lt;strong&gt;R Not for Everyone&lt;/strong&gt;は「R Not for Everyone」と出力される。また、段落を意味する&lt;p&gt;タグも頻繁に使われる。HTMLには様々なタグが用意されており、詳細なリストはW3Cなどを参照されたい（リンク先はHTML5基準）。\n　タグの中にタグを入れることもできる。以下のコードを見てみよう。\n\n\nHTMLコード\n&lt;ol&gt;\n  &lt;li&gt; 項目1 \n    &lt;ul&gt;\n      &lt;li&gt; 項目1A &lt;/li&gt;\n      &lt;li&gt; 項目1B &lt;/li&gt;\n      &lt;li&gt; 項目1C &lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt; 項目2 &lt;/li&gt;\n  &lt;li&gt; 項目3 &lt;/li&gt;\n&lt;/ol&gt;\n\n\n\nブラウザー上の出力内容\n\n項目1\n\n項目1A\n項目1B\n項目1C\n\n項目2\n項目3\n\n\n\n　&lt;ol&gt;は順序付きリスト（箇条書き）を意味し、一つ一つの項目は&lt;li&gt;タグで指定する。以上の例は&lt;ol&gt;タグの中に&lt;li&gt;タグが入っている入れ子構造だ。また、順序なしリストのタグ&lt;ul&gt;は最初の&lt;li&gt;の中に入っている。たとえば、「項目1B」は&lt;ol&gt; &gt; &lt;li&gt; &gt; &lt;ul&gt; &gt; &lt;li&gt;で定義された内容である。\n\n\n30.1.2 属性\n　タグの中には属性といものが定義されている場合がある。タグをプログラミング言語における関数とすれば、属性は引数（argumentとparameter）に該当する。たとえば、画像を貼り付けるタグは&lt;img&gt;だ。ちなみに&lt;img&gt;はタグを閉じる必要がなく、単体のみ存在するため&lt;img&gt;〜&lt;/img&gt;でなく、&lt;img&gt;のみか&lt;img/&gt;と記述する。本書では単体で使うタグを区分するために&lt;img/&gt;と表記する。この&lt;img/&gt;タグだけではどの画像を表示するかが分からない。画像の具体的なパスやURLを指定する必要がある。&lt;img/&gt;タグにはsrcという属性があり、src=\"パス or URL\"と書く。たとえば、https://www.jaysong.net/RBook/Figs/favicon.pngというURLの画像を表示させるためには&lt;img src=\"https://www.jaysong.net/RBook/Figs/favicon.png\"/&gt;と記述する必要がある。\n　一つのタグは複数の属性を持つこともできる。&lt;img/&gt;タグの場合、画像の幅と高さをwidthとheight属性で指定することができ、altで代替テキストを指定することもできる。ちなみに属性が不要なタグもあるが、属性を持つことができないタグは存在しない。すべてのタグはclassやhidden、styleなどの属性を持つことができ、このようにすべてのタグで使える属性はグローバル属性（global attributes）と呼ばれる。\n\n\n30.1.3 セレクター\n　セレクターを理解するためにはCSS（Cascading Style Sheets）の知識が必要であるが、ここでは最低限のことのみ解説する。ウェブスクレイピングは指定したHTMLファイルから特定のタグに囲まれた内容を取得するのが一般的、かつ基本的なやり方だ。たとえば、あるページ上の表を取得するためには表のタグである&lt;table&gt;タグで囲まれた内容を取得する。しかし、一つのページ内に複数の&lt;table&gt;タグがあればどうだろうか。多くのスクレイピングのパッケージやライブラリはすべてを読み込むが、それはメモリの無駄遣いだ。予め具体的にどの表を取得するかを指定した方が効率的だろう。ここで必要なのがセレクターだ。\n　そもそもセレクターが何なのかを知るためには、CSSの話を簡単にしておく必要がある。CSSはHTMLの「見た目」を担当するものであり、通常、HTMLとは別途のファイル（.cssファイル）で作成され、HTMLに読み込まれる。.cssファイルの内部には「この箇所はこのような見た目にしてくれ」といったものが細かく書かれている。\n　まずは以下の簡単なHTMLページ（sample00.html）を確認してみよう。\n\nhttps://www.jaysong.net/RBook/Data/scraping/sample00.html\n\n　変哲もないページであるが、このページのソースコードは以下の通りである。例えば、&lt;title&gt;タグで囲まれているテキストはそのページのタイトルとなり、&lt;h1&gt;は見出しとなる。いくつかのタグにはidやclassといった属性もついている。たとえば、7行目の&lt;a&gt;タグにはhref、id、classの3つの属性がある。\n\n\nhttps://www.jaysong.net/RBook/Data/scraping/sample00.html\n\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;meta charset=\"utf-8\"&gt;\n        &lt;title&gt;HTMLの例&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;h1&gt;第1章：文章&lt;/h1&gt;\n        &lt;p&gt;『&lt;a href=\"https://www.jaysong.net/RBook/\" id=\"rbook\" class=\"book-title\"&gt;私たちのR&lt;/a&gt;』は&lt;a href=\"https://www.jaysong.net/\"&gt;宋財泫&lt;/a&gt;（SONG Jaehyun）と&lt;a href=\"https://yukiyanai.github.io/\"&gt;矢内勇生&lt;/a&gt;が共同で執筆するRプログラミングの「入門書」である。統計学の本ではない。&lt;/p&gt;\n        &lt;p&gt;また、本書はデータ分析の手法の解説書でもない。Rを用いたデータ分析については他の本を参照されたい。私たちが専門とする政治学におけるデータ分析については、以下の本を勧める。&lt;/p&gt;\n        &lt;h1&gt;第2章：箇条書き&lt;/h1&gt;\n          &lt;ul&gt;\n            &lt;li&gt;浅野正彦・矢内勇生. 2018. 『&lt;span class=\"book-title\"&gt;Rによる計量政治学&lt;/span&gt;』オーム社.&lt;/li&gt;\n            &lt;li&gt;飯田健. 2013.『&lt;span class=\"book-title\"&gt;計量政治分析&lt;/span&gt;』共立出版.&lt;/li&gt;\n        &lt;/ul&gt;\n        &lt;ol&gt;\n            &lt;li&gt;聞いて...&lt;/li&gt;\n            &lt;li&gt;感じて...&lt;/li&gt;\n            &lt;li&gt;考えて...&lt;/li&gt;\n        &lt;/ol&gt;\n        &lt;h1&gt;第3章：表&lt;/h1&gt;\n        &lt;h2&gt;数学成績&lt;/h2&gt;\n        &lt;table class=\"score\" id=\"math\"&gt;\n            &lt;thead&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;ID&lt;/td&gt;\n                    &lt;td&gt;名前&lt;/td&gt;\n                    &lt;td&gt;成績&lt;/td&gt;\n                &lt;/tr&gt;\n            &lt;/thead&gt;\n            &lt;tbody&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;1&lt;/td&gt;\n                    &lt;td&gt;田中&lt;/td&gt;\n                    &lt;td class=\"tbl-score\"&gt;80&lt;/td&gt;\n                &lt;/tr&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;2&lt;/td&gt;\n                    &lt;td&gt;佐藤&lt;/td&gt;\n                    &lt;td class=\"tbl-score\"&gt;100&lt;/td&gt;\n                &lt;/tr&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;3&lt;/td&gt;\n                    &lt;td&gt;渡辺&lt;/td&gt;\n                    &lt;td class=\"tbl-score\"&gt;75&lt;/td&gt;\n                &lt;/tr&gt;\n            &lt;/tbody&gt;\n        &lt;/table&gt;\n        &lt;h2&gt;英語成績&lt;/h2&gt;\n        &lt;table class=\"score\" id=\"english\"&gt;\n            &lt;thead&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;ID&lt;/td&gt;\n                    &lt;td&gt;名前&lt;/td&gt;\n                    &lt;td&gt;成績&lt;/td&gt;\n                &lt;/tr&gt;\n            &lt;/thead&gt;\n            &lt;tbody&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;1&lt;/td&gt;\n                    &lt;td&gt;田中&lt;/td&gt;\n                    &lt;td class=\"tbl-score\"&gt;20&lt;/td&gt;\n                &lt;/tr&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;2&lt;/td&gt;\n                    &lt;td&gt;佐藤&lt;/td&gt;\n                    &lt;td class=\"tbl-score\"&gt;100&lt;/td&gt;\n                &lt;/tr&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;3&lt;/td&gt;\n                    &lt;td&gt;渡辺&lt;/td&gt;\n                    &lt;td class=\"tbl-score\"&gt;90&lt;/td&gt;\n                &lt;/tr&gt;\n            &lt;/tbody&gt;\n        &lt;/table&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n\n　続いて、もう一つのページ（sample01.html）も見てみよう。\n\nhttps://www.jaysong.net/RBook/Data/scraping/sample01.html\n\n　内容的には同じものであるが、見た目がだいぶ異なることが分かるだろう。ソースコードを見ると、一行を除き、sample00.htmlとsample01.htmlのコードは一致していることが分かる。具体的には4行目に&lt;link/&gt;タグが追加されているだけだ。この4行目のコードはstyle01.cssファイルを読み込み、本ファイル（sample01.html）へ適用するということを意味する。他の内容はsample00.htmlと全く同じだ。つまり、この2つのファイルの見た目が異なるのはstyle01.cssの存在が原因であると推測できる。\n\n.htmlコード.cssコード\n\n\n\n\nhttps://www.jaysong.net/RBook/Data/scraping/sample01.html\n\n&lt;html&gt;\n    &lt;head&gt;\n        &lt;meta charset=\"utf-8\"&gt;\n        &lt;link href=\"sample01.css\" rel=\"stylesheet\" type=\"text/css\" media=\"all\"/&gt;\n        &lt;title&gt;HTMLの例&lt;/title&gt;\n    &lt;/head&gt;\n    &lt;body&gt;\n        &lt;h1&gt;第1章：文章&lt;/h1&gt;\n        &lt;p&gt;『&lt;a href=\"https://www.jaysong.net/RBook/\" id=\"rbook\" class=\"book-title\"&gt;私たちのR&lt;/a&gt;』は&lt;a href=\"https://www.jaysong.net/\"&gt;宋財泫&lt;/a&gt;（SONG Jaehyun）と&lt;a href=\"https://yukiyanai.github.io/\"&gt;矢内勇生&lt;/a&gt;が共同で執筆するRプログラミングの「入門書」である。統計学の本ではない。&lt;/p&gt;\n        &lt;p&gt;また、本書はデータ分析の手法の解説書でもない。Rを用いたデータ分析については他の本を参照されたい。私たちが専門とする政治学におけるデータ分析については、以下の本を勧める。&lt;/p&gt;\n        &lt;h1&gt;第2章：箇条書き&lt;/h1&gt;\n          &lt;ul&gt;\n            &lt;li&gt;浅野正彦・矢内勇生. 2018. 『&lt;span class=\"book-title\"&gt;Rによる計量政治学&lt;/span&gt;』オーム社.&lt;/li&gt;\n            &lt;li&gt;飯田健. 2013.『&lt;span class=\"book-title\"&gt;計量政治分析&lt;/span&gt;』共立出版.&lt;/li&gt;\n        &lt;/ul&gt;\n        &lt;ol&gt;\n            &lt;li&gt;聞いて...&lt;/li&gt;\n            &lt;li&gt;感じて...&lt;/li&gt;\n            &lt;li&gt;考えて...&lt;/li&gt;\n        &lt;/ol&gt;\n        &lt;h1&gt;第3章：表&lt;/h1&gt;\n        &lt;h2&gt;数学成績&lt;/h2&gt;\n        &lt;table class=\"score\" id=\"math\"&gt;\n            &lt;thead&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;ID&lt;/td&gt;\n                    &lt;td&gt;名前&lt;/td&gt;\n                    &lt;td&gt;成績&lt;/td&gt;\n                &lt;/tr&gt;\n            &lt;/thead&gt;\n            &lt;tbody&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;1&lt;/td&gt;\n                    &lt;td&gt;田中&lt;/td&gt;\n                    &lt;td class=\"tbl-score\"&gt;80&lt;/td&gt;\n                &lt;/tr&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;2&lt;/td&gt;\n                    &lt;td&gt;佐藤&lt;/td&gt;\n                    &lt;td class=\"tbl-score\"&gt;100&lt;/td&gt;\n                &lt;/tr&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;3&lt;/td&gt;\n                    &lt;td&gt;渡辺&lt;/td&gt;\n                    &lt;td class=\"tbl-score\"&gt;75&lt;/td&gt;\n                &lt;/tr&gt;\n            &lt;/tbody&gt;\n        &lt;/table&gt;\n        &lt;h2&gt;英語成績&lt;/h2&gt;\n        &lt;table class=\"score\" id=\"english\"&gt;\n            &lt;thead&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;ID&lt;/td&gt;\n                    &lt;td&gt;名前&lt;/td&gt;\n                    &lt;td&gt;成績&lt;/td&gt;\n                &lt;/tr&gt;\n            &lt;/thead&gt;\n            &lt;tbody&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;1&lt;/td&gt;\n                    &lt;td&gt;田中&lt;/td&gt;\n                    &lt;td class=\"tbl-score\"&gt;20&lt;/td&gt;\n                &lt;/tr&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;2&lt;/td&gt;\n                    &lt;td&gt;佐藤&lt;/td&gt;\n                    &lt;td class=\"tbl-score\"&gt;100&lt;/td&gt;\n                &lt;/tr&gt;\n                &lt;tr&gt;\n                    &lt;td&gt;3&lt;/td&gt;\n                    &lt;td&gt;渡辺&lt;/td&gt;\n                    &lt;td class=\"tbl-score\"&gt;90&lt;/td&gt;\n                &lt;/tr&gt;\n            &lt;/tbody&gt;\n        &lt;/table&gt;\n    &lt;/body&gt;\n&lt;/html&gt;\n\n\n\n\n\nhttps://www.jaysong.net/RBook/Data/scraping/sample01.css\n\nh1, h2, h3 {\n    font-family: sans-serif;\n}\na {\n    text-decoration: none;\n    color: royalblue;\n}\ntable {\n    border-collapse: collapse;\n    border: 1px solid;\n}\ntd {\n    border-collapse: collapse;\n    border: 1px solid;\n}\nthead {\n    text-align: center;\n    font-weight: 600;\n}\n#rbook {\n    color: red;\n}\n.book-title {\n    font-weight: 600;\n}\n.score {\n    width: 300px;\n}\n.tbl-score {\n    text-align: right;\n}\n\n\n\n\n　一つずつ確認していこう。まず、「第1章：文章」や「英語成績」のような見出しが明朝体（serif）からゴジック体（sans-serif）に変わったことが分かる。続いてsample01.cssの1〜3行目を確認してみよう。\nh1, h2, h3 {\n    font-family: sans-serif;\n}\n　このCSSの意味は&lt;h1&gt;、&lt;h2&gt;、&lt;h3&gt;タグに囲まれた内容に対し、{}内の設定を適用するといういみで、今回はフォント族（font-family）をゴジック（sans-serif）にした。また、リンクの下線が無くなり、文字の色もロイヤルブルーになったが、これもsample01.cssの4〜7行目で適宜されたものである。このようにタグ名 {}で特定のタグに対し、スタイルを適用することができ、ここでのタグ名はタグに対するセレクターである。このようなタグ名のセレクターは要素型セレクター（type selector）と呼ばれる。\n　引き続き、sample01.htmlを見ると『私たちのR』が太字、かつ赤色になっていることが分かる。また、コードの8行目を見ると『私たちのR』の部分が&lt;a&gt;タグで囲まれ、 リンク先を意味するhref属性以外にも、idとclassにそれぞれ\"rbook\"と\"book-title\"の値が指定されていることが分かる。そして、sample01.cssの20〜25行目にidがrbookの場合とclassがbook-titleの場合のスタイルが定義されている。たとえば、idは#ID名がセレクターであり（今回は#rbook）、赤色が定義されている。クラスは.クラス名がセレクターであり（今回は.book-title）、文字の太さ（weight）が600になっていることが分かる。ちなみに一つのタグに対して複数のクラスを与えることもできる。この場合、タグ内にclass=\"クラス名1 クラス名2 クラス名3\"のように半角スペースでクラス名を区切れば良い。\n　このようにIDセレクターとクラスセレクターが用意されているが、特定のタグに識別可能な名前を付ける点で、2つの役割は非常に似ている。しかし、IDとクラスには決定的な違いがある。それはIDは一つのページ内において1回しか登場できないものの、クラスはこのような制限がないことだ。何回も登場するスタイルであればクラスを使用し、固有の識別子が必要な場合はIDを使う。それでも「クラスを1回だけ使っても良いのでは？」と思う読者もいるだろう。たしかにその通りである。しかし、IDとクラスのもう一つの違いはスタイルが衝突する場合、IDセレクターがクラスセレクターに優先する点にある。たとえば、あるタグが#AIDと.Bクラスを両方持ち、.css内部においてそれぞれ文字の太さが600、300に定義されていると、#Aに指定された太さ600が適用される。スクレイピングにおいてIDとクラスの違いは重要ではないが、念のために述べておく。\n　以上で紹介したもの以外にも、セレクターは多数用意されている。たとえば、文章全体にスタイルを適用したい場合のセレクターは*であり、全称セレクター（universal selector）と呼ばれる。また、特定の属性を持つタグに対してスタイルを適用できる。たとえば、&lt;img&gt;タグすべてでなく、alt属性を持つ&lt;img&gt;タグのみにスタイルを適用する場合のセレクターはimg[alt]のようにタグ名[属性名]のように記述する。また、a[href=\"http://www.jaysong.net\"]のようにhref属性の値が\"http://www.jaysong.net\"と一致する&lt;a&gt;タグを選択することもできる2。\n\n\n\n\n\n\nCSSセレクターとXPath\n\n\n\n　以上ではCSSセレクターの書き方について紹介したが、実はHTML内の要素を指定するもう一つの記述方法があり、それがXPathというものだ。たとえば、&lt;img&gt;タグの場合、CSSはimg、XPathでは//imgと記述する。また、クラスはCSSだと.クラス名、XPathだと//*[contains(@class,\"クラス名\")]となり、IDはそれぞれ#ID名、//*[@id=\"ID名\"]となる。通常、CSSセレクターの方がXPathより簡潔なので、より幅広く使われる。しかし、XPathではCSSセレクターでは指定できない要素まで指定できるなど、機能面ではより強力だ。また、規則的なページ構造を持たないページのスクレイピングはSeleniumというものを使う場面が多いが、SeleniumではCSSセレクターよりXPathの方が幅広く使われる。本章で紹介する{rvest}パッケージはいずれの書き方にも対応しているが、引数を指定しない場合は第2引数であるCSSセレクターの書き方となる。XPathを使う場合はxpath = \"XPath ID\"のように仮引数名を指定する必要がある。\n\n\n\n\n30.1.4 セレクターの確認\n　CSSを勉強する場合のセレクターの話はもっと長くなるが、スクレイピング入門レベルであれば、タグ、ID、クラス、属性セレクターだけでも問題ない3。つまり、自分がスクレイピングしたい内容のタグ、ID、クラス、属性を知るだけで十分だ。これを調べるにはHTMLソースコードを読む必要はあるが、最近のHTMLページは数百〜数千行のコードで構成されているため、すべてを精査することは現実的でない。最近のウェブブラウザーには開発者専用のメニューが用意されており、これを活用すると素早く必要な内容のセレクターを調べることができる。しかし、ブラウザーごとに開発者メニューの開き方が異なる。以下ではstatcounter基準、代表的な4つのブラウザーの例を紹介する。\n\nFirefoxChromeSafariEdge\n\n\n右上の「≡」&gt;その他のツール&gt;ウェブ開発ツール\n\n\n\n右上の「⋮」&gt;その他のツール&gt;デベロッパーツール\n\n\n\n開発 &gt; Webインスペクタを接続\n\n開発メニューがない場合は環境設定の「詳細」タブの「メニューバーに”開発”メニューを表示」にチェックを入れる必要がある。\n\n\n\n\n右上の「…」&gt;その他のツール&gt;開発者ツール\n\n\n\n\n　ここからは筆者（宋）が使用しているFirefox基準で説明するが、どのブラウザーでも使い方は大きく変わらない。以下は『私たちのR』の初期ページからウェブ開発メニューを開いたものである。\n\n　このページのコードは2023年6月現在、1148行である。ここで、画面右にある『私たちのR』のカーバー（仮）のタグ、クラス、ID、属性、親タグなどを調べてみよう。まず、ウェブ開発メニューの左上にあるボタンをクリックする。これはページ内の要素を選択し、その要素のコードなどを表示してくれる機能である。このボタンのアイコンはブラウザーごとにことなるが、開発者メニューの左上か右上に位置する。\n　続いて、調べたい要素を選択する。マウスカーソルを要素の上に乗せるとハイライトされるため、分かりやすい。調べたい要素がハイライトされたらそのままクリックすると、開発者メニューに当該箇所のソースコードが表示される。\n\n　以下は当該箇所のコードの一部を抜粋したものだ。\n&lt;section id=\"紹介\" class=\"level1 unnumbered\"&gt;\n  &lt;h1 class=\"unnumbered\"&gt;紹介&lt;/h1&gt;\n  &lt;p&gt;\n    &lt;img src=\"Figs/Cover.png\" title=\"私たちのR\" class=\"quarto-cover-image img-fluid\"&gt;\n  &lt;/p&gt;\n　当該箇所のタグは&lt;img&gt;である。クラスはquarto-cover-imageとimg-fluid、2つだ。他にもsrcとtitleという属性を持ち、それぞれ\"Figs/Cover.png\"と\"私たちのR\"という値が割り当てられている。他にもこの&lt;img&gt;タグの親タグは&lt;p&gt;であり、その親タグは&lt;section&gt;タグだということが分かる。ここでこの図の情報が必要な場合、セレクターはimg十分だろうか。答えはNoだ。このページにはこの画像以外にもイケメン著者たちの写真もある。imgだけだとどの図なのかが分からない。この図を特定するためには更に情報が必要だ。\n　たとえば、&lt;img&gt;のtitle属性に注目しても良いだろう。イケメン著者たちの画像はtitle属性を持たない（各自確認してみよう）が、カーバー（仮）にはtitle=\"私たちのR\"がある。これを利用するとimg[title=\"私たちのR\"]といったセレクターも有効だろう。もう一つは親のタグ、ID、クラスなどを利用する方法だ。カーバー（仮）の親タグの一つは&lt;section&gt;であり、\"紹介\"というIDが指定されている。IDはこのページに1回しか登場しないものであるため、これは使えるかも知れない。このページ内の2つの画像のコードを簡単に示すと以下の通りだ。\n&lt;section id=\"紹介\" class=\"level1 unnumbered\"&gt;\n  &lt;img src=\"Figs/Cover.png\" title=\"私たちのR\" class=\"quarto-cover-image img-fluid\"&gt;\n&lt;/section&gt;\n&lt;section id=\"著者紹介\" class=\"level1 unnumbered\"&gt;\n  &lt;img src=\"Figs/Authors/SongYanai.jpg\" class=\"img-fluid figure-img\" width=\"350\"&gt;\n&lt;/section&gt;\n　どの画像も親タグは&lt;section&gt;であるが、異なるIDを持つ。つまり、異なる親を持つ。カーバー（仮）はid=\"紹介\"、イケメン著者はid=\"著者紹介\"の&lt;section&gt;親を持つ。この場合、（1）IDが\"著者\"の要素を選択し（#紹介）、（2）&lt;img&gt;タグを選択する（img）といった手順で、欲しい内容が抽出できる。本章では基本的に、このような多段階の抽出方法を採用する。より洗練された書き方で効率的なスクレイピングもできるが、入門レベルだとこのようなやり方でも問題ないだろう。それではRにおけるスクレイピングの定番パッケージ、{rvest}の簡単な使い方を見てみよう。"
  },
  {
    "objectID": "scraping.html#rvestの使い方",
    "href": "scraping.html#rvestの使い方",
    "title": "30  スクレイピング",
    "section": "30.2 {rvest}の使い方",
    "text": "30.2 {rvest}の使い方\n　実際のウェブスクレイピングをやってみる前に、{rvest}パッケージを使って実習用のページ（sample01.html）の内容を取得してみよう。\n\nテキスト/表の取得\n\nhtml_elment()、html_elments()で特定のタグやクラス、IDを抽出\nhtml_text()、html_text2()やhtml_table()で抽出\n画像の場合、&lt;img&gt;タグのsrc属性を抽出する必要があるため、html_attr()\n\n\n　まずは、read_html()関数を使用し、スクレイピングするHTMLファイルそのものを読み込んでおく必要がある。引数はHTMLファイルのURL、もしくはパスだけで問題ないが、Shift-JISやEUC-KRといった邪悪なロケールで作成されたページであれば、encoding引数が必要となる。サンプルページはUTF-8であるため、URLのみで問題ない。\n\nmy_html &lt;- read_html(\"https://www.jaysong.net/RBook/Data/scraping/sample01.html\")\n\n\nmy_html\n\n{html_document}\n&lt;html&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body&gt;\\n\\t\\t&lt;h1&gt;第1章：文章&lt;/h1&gt;\\n\\t\\t&lt;p&gt;『&lt;a href=\"https://www.jaysong.net/RBo ...\n\n\n　中身は簡単にしか確認できないが、そもそもRでコードをすべて表示する必要もないので問題ないだろう。HTMLのソースコード全体が見たい場合はウェブブラウザーから確認しよう。ここでは問題なくHTMLファイルが読み込まれていることだけを確認すれば良い。\n　それではこのmy_htmlからいくつかの要素を抽出してみよう。まずは、タグ名セレクターを使用し、特定のタグだけを抽出する。ここで使用する関数はhtml_elements()だ4。たとえば、ハイパーリンクを意味する&lt;a&gt;タグが使用された箇所すべてを読み組むにはhtml_elemtns(HTMLオブジェクト名, \"a\")で良い。HTMLオブジェクト名（今回はmy_html）は第1引数だから、パイプ演算子を使用しよう。\n\nmy_html |&gt; \n  html_elements(\"a\")\n\n{xml_nodeset (3)}\n[1] &lt;a href=\"https://www.jaysong.net/RBook/\" id=\"rbook\" class=\"book-title\"&gt;私た ...\n[2] &lt;a href=\"https://www.jaysong.net/\"&gt;宋財泫&lt;/a&gt;\n[3] &lt;a href=\"https://yukiyanai.github.io/\"&gt;矢内勇生&lt;/a&gt;\n\n\n　しかし、通常、これらの内容すべてが必要になるケースは稀だろう。普通、&lt;a&gt;と&lt;/a&gt;に囲まれたテキストの内容や、リンク先のURLのリストが欲しいだろう。html_elements()で指定したセレクター内のテキストを抽出する場合は、html_text()を使用する5。\n\nmy_html |&gt; \n  html_elements(\"a\") |&gt; \n  html_text()\n\n[1] \"私たちのR\" \"宋財泫\"    \"矢内勇生\" \n\n\n　&lt;a&gt;と&lt;/a&gt;に囲まれたテキストの内容でなく、リンク先のURLを抽出することもできる。&lt;a&gt;タグのリンク先はhref属性で指定するため、href属性の値を抽出すれば良い。特定の属性の値を取得する関数はhtml_attr()であり、引数として属性名を指定すれば良い。\n\nmy_html |&gt; \n  html_elements(\"a\") |&gt; \n  html_attr(\"href\")\n\n[1] \"https://www.jaysong.net/RBook/\" \"https://www.jaysong.net/\"      \n[3] \"https://yukiyanai.github.io/\"  \n\n\n続いて、箇条書きの要素を抽出してみよう。今回は2本の書籍リストが対象だ。箇条書きの内容は&lt;li&gt;タグで記述されるので、html_elements(\"li\")で&lt;li&gt;タグの内容を取得してみよう。\n\nmy_html |&gt; \n  html_elements(\"li\")\n\n{xml_nodeset (5)}\n[1] &lt;li&gt;浅野正彦・矢内勇生. 2018. 『&lt;span class=\"book-title\"&gt;Rによる計量政治学&lt;/span&gt;』オーム社.&lt;/li&gt;\n[2] &lt;li&gt;飯田健. 2013.『&lt;span class=\"book-title\"&gt;計量政治分析&lt;/span&gt;』共立出版.&lt;/li&gt;\n[3] &lt;li&gt;聞いて...&lt;/li&gt;\n[4] &lt;li&gt;感じて...&lt;/li&gt;\n[5] &lt;li&gt;考えて...&lt;/li&gt;\n\n\n　書籍リストだけでなく、謎の言葉も取得される。実際、サンプルページには2つの箇条書きがあり、書籍は順序なしの箇条書き（&lt;ul&gt;）、謎の言葉は順序付き箇条書き（&lt;ol&gt;）である。したがって、まず、&lt;ul&gt;タグを抽出し、そこから&lt;li&gt;を抽出すれば良い。\n\nmy_html |&gt; \n  html_elements(\"ul\") |&gt; \n  html_elements(\"li\")\n\n{xml_nodeset (2)}\n[1] &lt;li&gt;浅野正彦・矢内勇生. 2018. 『&lt;span class=\"book-title\"&gt;Rによる計量政治学&lt;/span&gt;』オーム社.&lt;/li&gt;\n[2] &lt;li&gt;飯田健. 2013.『&lt;span class=\"book-title\"&gt;計量政治分析&lt;/span&gt;』共立出版.&lt;/li&gt;\n\n\n　ちなみにhtml_elements()が続く場合は引数を\"タグ名 &gt; タグ名\"にしても同じ結果が得られる。\n\nmy_html |&gt; \n  html_elements(\"ul &gt; li\")\n\n{xml_nodeset (2)}\n[1] &lt;li&gt;浅野正彦・矢内勇生. 2018. 『&lt;span class=\"book-title\"&gt;Rによる計量政治学&lt;/span&gt;』オーム社.&lt;/li&gt;\n[2] &lt;li&gt;飯田健. 2013.『&lt;span class=\"book-title\"&gt;計量政治分析&lt;/span&gt;』共立出版.&lt;/li&gt;\n\n\n　ここから更にテキストのみ抽出する場合はhtml_text()を使えば良い。\n\nmy_html |&gt; \n  html_elements(\"ul &gt; li\") |&gt; \n  html_text()\n\n[1] \"浅野正彦・矢内勇生. 2018. 『Rによる計量政治学』オーム社.\"\n[2] \"飯田健. 2013.『計量政治分析』共立出版.\"                  \n\n\n　html_elements()にはタグ名以外のセレクターも使える。たとえば、クラス（.クラス名）やID（#ID名）の指定もできる。サンプルページには書籍名が3回登場し、それらは&lt;span&gt;タグに囲まれている。&lt;span&gt;タグそのものは機能を持たないが、文章の一部などにIDやクラスを割り当てる際によく使われる6。今回の例だと、書籍名はクラスがbook-titleの&lt;span&gt;タグで囲まれている。したがって、書籍名を抽出する時にはhtml_elements(\".book-title\")\n\nmy_html |&gt; \n  html_elements(\".book-title\")\n\n{xml_nodeset (3)}\n[1] &lt;a href=\"https://www.jaysong.net/RBook/\" id=\"rbook\" class=\"book-title\"&gt;私た ...\n[2] &lt;span class=\"book-title\"&gt;Rによる計量政治学&lt;/span&gt;\n[3] &lt;span class=\"book-title\"&gt;計量政治分析&lt;/span&gt;\n\n\n　このようにbook-titleクラスのタグと、その内容が全て抽出される。ここからテキストを抽出する場合はhtml_text()を使えば良い。\n\nmy_html |&gt; \n  html_elements(\".book-title\") |&gt; \n  html_text()\n\n[1] \"私たちのR\"         \"Rによる計量政治学\" \"計量政治分析\"     \n\n\n　スクレイピングで最も需要の高いものは表だろう。表の場合、HTMLでは&lt;table&gt;タグで記述されるが、{rvest}は表を取得し、tibble形式で返すhtml_table()関数が用意されている。これまで使ってきたhtml_elements()関数はあっても良いが、なくても問題ない。サンプルページには2つの表があるが、HTMLオブジェクトをそのままhtml_table()に渡すと表が抽出される。\n\nmy_html |&gt; \n  html_table()\n\n[[1]]\n# A tibble: 4 × 3\n  X1    X2    X3   \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 ID    名前  成績 \n2 1     田中  80   \n3 2     佐藤  100  \n4 3     渡辺  75   \n\n[[2]]\n# A tibble: 4 × 3\n  X1    X2    X3   \n  &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n1 ID    名前  成績 \n2 1     田中  20   \n3 2     佐藤  100  \n4 3     渡辺  90   \n\n\n　長さ2のリストが出力され、それぞれ表が格納されている。今回のように、表のヘッダー（1行目）が中身として出力される場合もあるが、このような場合はheader = TRUEを指定すると、1行目が変数名となる。\n\nmy_tables &lt;- my_html |&gt; \n  html_table(header = TRUE)\n\nmy_tables\n\n[[1]]\n# A tibble: 3 × 3\n     ID 名前   成績\n  &lt;int&gt; &lt;chr&gt; &lt;int&gt;\n1     1 田中     80\n2     2 佐藤    100\n3     3 渡辺     75\n\n[[2]]\n# A tibble: 3 × 3\n     ID 名前   成績\n  &lt;int&gt; &lt;chr&gt; &lt;int&gt;\n1     1 田中     20\n2     2 佐藤    100\n3     3 渡辺     90\n\n\n　この2つの表をbind_rows()を使って結合することもできる。まず、names()関数を使って、リストの各要素に名前を割り当てる。\n\nnames(my_tables) &lt;- c(\"数学\", \"英語\")\n\nmy_tables\n\n$数学\n# A tibble: 3 × 3\n     ID 名前   成績\n  &lt;int&gt; &lt;chr&gt; &lt;int&gt;\n1     1 田中     80\n2     2 佐藤    100\n3     3 渡辺     75\n\n$英語\n# A tibble: 3 × 3\n     ID 名前   成績\n  &lt;int&gt; &lt;chr&gt; &lt;int&gt;\n1     1 田中     20\n2     2 佐藤    100\n3     3 渡辺     90\n\n\n　続いて、bind_rows()関数に表のリストを入れ、.id変数で2つの表を識別する値が格納される列名を指定する。bind_rows()の詳細は第14.5章を参照されたい。\n\nmy_table &lt;- bind_rows(my_tables, .id = \"科目\")\n\nmy_table\n\n# A tibble: 6 × 4\n  科目     ID 名前   成績\n  &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt;\n1 数学      1 田中     80\n2 数学      2 佐藤    100\n3 数学      3 渡辺     75\n4 英語      1 田中     20\n5 英語      2 佐藤    100\n6 英語      3 渡辺     90\n\n\n　すべての表ではない、英語成績の表だけを抽出する場合はどうすれば良いだろうか。今回は表が2つしかなく、2番目の表が英語成績ということが分かっているのでmy_table[[2]]のような書き方でも問題ない。しかし、表が数百個ある場合は、何番目の表かを数えるのも簡単ではない。幸い、今回はそれぞれの表にmathとenglishといったIDが割り当てられている。このセレクターを使えば、IDが\"english\"の表を選択することもできよう。html_element()関数の引数として\"#english\"を指定し、そこからhtml_table()を実行すると英語成績の表だけが抽出される。\n\nmy_html |&gt; \n  html_element(\"#english\") |&gt; \n  html_table(header = TRUE)\n\n# A tibble: 3 × 3\n     ID 名前   成績\n  &lt;int&gt; &lt;chr&gt; &lt;int&gt;\n1     1 田中     20\n2     2 佐藤    100\n3     3 渡辺     90\n\n\n　ここで一つ注意事項があるが、html_elements()でなく、html_element()を使う点だ。IDが1ページに1つしか存在しないため、html_element()を使った方が楽である。html_elements()を使っても良いが、返ってくるのはtibbleでなく、長さ1のリストになるので、更に[[1]]などでリストから表を取り出す必要がある。"
  },
  {
    "objectID": "scraping.html#実践",
    "href": "scraping.html#実践",
    "title": "30  スクレイピング",
    "section": "30.3 実践",
    "text": "30.3 実践\n\n30.3.1 テキスト\n\n\nrbook_html &lt;- read_html(\"https://www.jaysong.net/RBook/\")\nrbook_html\n\n{html_document}\n&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" lang=\"ja\" xml:lang=\"ja\"&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body class=\"nav-sidebar docked\"&gt;\\n\\n&lt;div id=\"quarto-search-results\"&gt;&lt;/di ...\n\n\n　ここからリンクを意味する&lt;a&gt;を抽出すれば良いが、このページには各章へのリンク以外にも多くの&lt;a&gt;タグが存在する。したがって、範囲を絞る必要があるが、本ページの「進行状況」の領域に限定すれば良いだろう。開発者メニューを見ると「進捗状況」の見出しには進捗状況というIDが振られているため、まずはIDセレクターで要素を絞ってから&lt;a&gt;タグを抽出する。\n\nrbook_html |&gt; \n  html_element(\"#進捗状況\") |&gt; \n  html_elements(\"a\")\n\n{xml_nodeset (35)}\n [1] &lt;a href=\"aboutr.html\" class=\"quarto-xref\"&gt;&lt;span&gt;1&lt;/span&gt;&lt;/a&gt;\n [2] &lt;a href=\"installation.html\" class=\"quarto-xref\"&gt;&lt;span&gt;2&lt;/span&gt;&lt;/a&gt;\n [3] &lt;a href=\"ide.html\" class=\"quarto-xref\"&gt;&lt;span&gt;3&lt;/span&gt;&lt;/a&gt;\n [4] &lt;a href=\"r_customize.html\" class=\"quarto-xref\"&gt;&lt;span&gt;4&lt;/span&gt;&lt;/a&gt;\n [5] &lt;a href=\"packages.html\" class=\"quarto-xref\"&gt;&lt;span&gt;5&lt;/span&gt;&lt;/a&gt;\n [6] &lt;a href=\"project.html\" class=\"quarto-xref\"&gt;&lt;span&gt;6&lt;/span&gt;&lt;/a&gt;\n [7] &lt;a href=\"r_basic.html\" class=\"quarto-xref\"&gt;&lt;span&gt;7&lt;/span&gt;&lt;/a&gt;\n [8] &lt;a href=\"io.html\" class=\"quarto-xref\"&gt;&lt;span&gt;8&lt;/span&gt;&lt;/a&gt;\n [9] &lt;a href=\"datatype.html\" class=\"quarto-xref\"&gt;&lt;span&gt;9&lt;/span&gt;&lt;/a&gt;\n[10] &lt;a href=\"datastructure.html\" class=\"quarto-xref\"&gt;&lt;span&gt;10&lt;/span&gt;&lt;/a&gt;\n[11] &lt;a href=\"programming.html\" class=\"quarto-xref\"&gt;&lt;span&gt;11&lt;/span&gt;&lt;/a&gt;\n[12] &lt;a href=\"functions.html\" class=\"quarto-xref\"&gt;&lt;span&gt;12&lt;/span&gt;&lt;/a&gt;\n[13] &lt;a href=\"datahandling1.html\" class=\"quarto-xref\"&gt;&lt;span&gt;13&lt;/span&gt;&lt;/a&gt;\n[14] &lt;a href=\"datahandling2.html\" class=\"quarto-xref\"&gt;&lt;span&gt;14&lt;/span&gt;&lt;/a&gt;\n[15] &lt;a href=\"factor.html\" class=\"quarto-xref\"&gt;&lt;span&gt;15&lt;/span&gt;&lt;/a&gt;\n[16] &lt;a href=\"tidydata.html\" class=\"quarto-xref\"&gt;&lt;span&gt;16&lt;/span&gt;&lt;/a&gt;\n[17] &lt;a href=\"string.html\" class=\"quarto-xref\"&gt;&lt;span&gt;17&lt;/span&gt;&lt;/a&gt;\n[18] &lt;a href=\"visualization1.html\" class=\"quarto-xref\"&gt;&lt;span&gt;18&lt;/span&gt;&lt;/a&gt;\n[19] &lt;a href=\"visualization2.html\" class=\"quarto-xref\"&gt;&lt;span&gt;19&lt;/span&gt;&lt;/a&gt;\n[20] &lt;a href=\"visualization3.html\" class=\"quarto-xref\"&gt;&lt;span&gt;20&lt;/span&gt;&lt;/a&gt;\n...\n\n\n　ここから更にhref属性に割り当てられた値（ここではURL）のみを抽出する必要がある。ここでhtml_attr()関数を使用する。抽出したい属性名を引数として指定するだけだ。\n\nrbook_urls &lt;- rbook_html |&gt; \n  html_element(\"#進捗状況\") |&gt; \n  html_elements(\"a\") |&gt; \n  html_attr(\"href\")\n\nrbook_urls\n\n [1] \"aboutr.html\"         \"installation.html\"   \"ide.html\"           \n [4] \"r_customize.html\"    \"packages.html\"       \"project.html\"       \n [7] \"r_basic.html\"        \"io.html\"             \"datatype.html\"      \n[10] \"datastructure.html\"  \"programming.html\"    \"functions.html\"     \n[13] \"datahandling1.html\"  \"datahandling2.html\"  \"factor.html\"        \n[16] \"tidydata.html\"       \"string.html\"         \"visualization1.html\"\n[19] \"visualization2.html\" \"visualization3.html\" \"visualization4.html\"\n[22] \"table.html\"          \"rmarkdown.html\"      \"rmarkdown2.html\"    \n[25] \"quarto.html\"         \"renv.html\"           \"iteration.html\"     \n[28] \"oop.html\"            \"monte.html\"          \"scraping.html\"      \n[31] \"./dataset.html\"      \"./filesystem.html\"   \"./tips.html\"        \n[34] \"./session.html\"      \"./references.html\"  \n\n\n\nrbook_html |&gt; \n  html_element(\"#進捗状況\") |&gt; \n  html_elements(\"li\") |&gt; \n  html_text()\n\n [1] \"第1部: Rの導入\\n第1章: R?\\n第2章: Rのインストール\\n第3章: IDEの導入\\n第4章: 分析環境のカスタマイズ\\n第5章: Rパッケージ\\n\"                                                              \n [2] \"第1章: R?\"                                                                                                                                                                             \n [3] \"第2章: Rのインストール\"                                                                                                                                                                \n [4] \"第3章: IDEの導入\"                                                                                                                                                                      \n [5] \"第4章: 分析環境のカスタマイズ\"                                                                                                                                                         \n [6] \"第5章: Rパッケージ\"                                                                                                                                                                    \n [7] \"第2部: Rの基礎\\n第6章: プロジェクト管理\\n第7章: 基本的な操作\\n第8章: データの入出力\\n第9章: データ型\\n第10章: データ構造\\n第11章: Rプログラミングの基礎\\n第12章: 関数の自作\\n\"         \n [8] \"第6章: プロジェクト管理\"                                                                                                                                                               \n [9] \"第7章: 基本的な操作\"                                                                                                                                                                   \n[10] \"第8章: データの入出力\"                                                                                                                                                                 \n[11] \"第9章: データ型\"                                                                                                                                                                       \n[12] \"第10章: データ構造\"                                                                                                                                                                    \n[13] \"第11章: Rプログラミングの基礎\"                                                                                                                                                         \n[14] \"第12章: 関数の自作\"                                                                                                                                                                    \n[15] \"第3部: データハンドリング\\n第13章: データハンドリング [抽出]\\n第14章: データハンドリング [拡張]\\n第15章: データハンドリング [factor型]\\n第16章: 整然データ構造\\n第17章: 文字列の処理\\n\"\n[16] \"第13章: データハンドリング [抽出]\"                                                                                                                                                     \n[17] \"第14章: データハンドリング [拡張]\"                                                                                                                                                     \n[18] \"第15章: データハンドリング [factor型]\"                                                                                                                                                 \n[19] \"第16章: 整然データ構造\"                                                                                                                                                                \n[20] \"第17章: 文字列の処理\"                                                                                                                                                                  \n[21] \"第4部: 可視化\\n第18章: 可視化[理論]\\n第19章: 可視化[基礎]\\n第20章: 可視化[応用]\\n第21章: 可視化[発展]\\n第22章: 表の作成\\n\"                                                             \n[22] \"第18章: 可視化[理論]\"                                                                                                                                                                  \n[23] \"第19章: 可視化[基礎]\"                                                                                                                                                                  \n[24] \"第20章: 可視化[応用]\"                                                                                                                                                                  \n[25] \"第21章: 可視化[発展]\"                                                                                                                                                                  \n[26] \"第22章: 表の作成\"                                                                                                                                                                      \n[27] \"第5部: 再現可能な研究\\n第23章: R Markdown [基礎]\\n第24章: R Markdown [応用]\\n第25章: Quarto入門\\n第26章: 分析環境の管理\\n\"                                                             \n[28] \"第23章: R Markdown [基礎]\"                                                                                                                                                             \n[29] \"第24章: R Markdown [応用]\"                                                                                                                                                             \n[30] \"第25章: Quarto入門\"                                                                                                                                                                    \n[31] \"第26章: 分析環境の管理\"                                                                                                                                                                \n[32] \"第6部: 中級者向け\\n第27章: 反復処理\\n第28章: オブジェクト指向プログラミング\\n第29章: モンテカルロ・シミュレーション\\n第30章: スクレイピング\\n\"                                         \n[33] \"第27章: 反復処理\"                                                                                                                                                                      \n[34] \"第28章: オブジェクト指向プログラミング\"                                                                                                                                                \n[35] \"第29章: モンテカルロ・シミュレーション\"                                                                                                                                                \n[36] \"第30章: スクレイピング\"                                                                                                                                                                \n[37] \"付録\\nデータセット\\nファイルシステム\\nR Tips\\n本書の執筆環境\\n参考文献\\n\"                                                                                                              \n[38] \"データセット\"                                                                                                                                                                          \n[39] \"ファイルシステム\"                                                                                                                                                                      \n[40] \"R Tips\"                                                                                                                                                                                \n[41] \"本書の執筆環境\"                                                                                                                                                                        \n[42] \"参考文献\"                                                                                                                                                                              \n\n\n　概ね問題はなさそうに見えるが、章だけでなく、部（\"第1部: Rの導入\\n第1章: R?\\n第2章: Rのインストール\\n第3章: IDEの導入\\n第4章: 分析環境のカスタマイズ\\n第5章: Rパッケージ\\n\"など）が書かれた&lt;li&gt;タグまで抽出されてしまった。スクレイピングする内容が今回のように少ないのであれば、自分で一つ一つ消しても良いが、ここではすべて自動化しよう。\n　まず、開発者メニューを開き、章の箇所（どの章でも良い）を選択する。以下は「第1章: R?」とその前後のコードである。\n&lt;section id=\"進捗状況\" class=\"level2\"&gt;\n&lt;h2 class=\"anchored\" data-anchor-id=\"進捗状況\"&gt;進捗状況&lt;/h2&gt;\n&lt;p&gt;章立ては未定。著者が書きたいものから書く予定 (全部で30~35章くらいになる見込み)。&lt;/p&gt;\n&lt;ul&gt;\n  &lt;li&gt;第1部: Rの導入\n    &lt;ul&gt;\n      &lt;li&gt;第&lt;a href=\"aboutr.html\" class=\"quarto-xref\"&gt;&lt;span&gt;1&lt;/span&gt;&lt;/a&gt;章: R?&lt;/li&gt;\n      &lt;li&gt;第&lt;a href=\"installation.html\" class=\"quarto-xref\"&gt;&lt;span&gt;2&lt;/span&gt;&lt;/a&gt;章: Rのインストール&lt;/li&gt;\n      &lt;li&gt;第&lt;a href=\"ide.html\" class=\"quarto-xref\"&gt;&lt;span&gt;3&lt;/span&gt;&lt;/a&gt;章: IDEの導入&lt;/li&gt;\n      &lt;li&gt;第&lt;a href=\"r_customize.html\" class=\"quarto-xref\"&gt;&lt;span&gt;4&lt;/span&gt;&lt;/a&gt;章: 分析環境のカスタマイズ&lt;/li&gt;\n      &lt;li&gt;第&lt;a href=\"packages.html\" class=\"quarto-xref\"&gt;&lt;span&gt;5&lt;/span&gt;&lt;/a&gt;章: Rパッケージ&lt;/li&gt;\n    &lt;/ul&gt;\n  &lt;/li&gt;\n  &lt;li&gt;第2部: Rの基礎\n　「第1章: R?」は上記のコードの7行目にある。また、その親タグは&lt;ul&gt;、そしてそれの親タグは&lt;li&gt;、そして&lt;ul&gt;もある。これは第2章も、第30章も同じだ。つまり、IDが進捗状況の内容（#進捗状況）の中、&lt;ul&gt;の中の&lt;li&gt;の中の&lt;ul&gt;の中の&lt;li&gt;の箇所を取り出せば良い。セレクターは\"ul li ul li\"と記述する7。\n\nrbook_titles &lt;- rbook_html |&gt; \n  html_element(\"#進捗状況\") |&gt; \n  html_elements(\"ul li ul li\") |&gt; \n  html_text()\n\nrbook_titles\n\n [1] \"第1章: R?\"                             \n [2] \"第2章: Rのインストール\"                \n [3] \"第3章: IDEの導入\"                      \n [4] \"第4章: 分析環境のカスタマイズ\"         \n [5] \"第5章: Rパッケージ\"                    \n [6] \"第6章: プロジェクト管理\"               \n [7] \"第7章: 基本的な操作\"                   \n [8] \"第8章: データの入出力\"                 \n [9] \"第9章: データ型\"                       \n[10] \"第10章: データ構造\"                    \n[11] \"第11章: Rプログラミングの基礎\"         \n[12] \"第12章: 関数の自作\"                    \n[13] \"第13章: データハンドリング [抽出]\"     \n[14] \"第14章: データハンドリング [拡張]\"     \n[15] \"第15章: データハンドリング [factor型]\" \n[16] \"第16章: 整然データ構造\"                \n[17] \"第17章: 文字列の処理\"                  \n[18] \"第18章: 可視化[理論]\"                  \n[19] \"第19章: 可視化[基礎]\"                  \n[20] \"第20章: 可視化[応用]\"                  \n[21] \"第21章: 可視化[発展]\"                  \n[22] \"第22章: 表の作成\"                      \n[23] \"第23章: R Markdown [基礎]\"             \n[24] \"第24章: R Markdown [応用]\"             \n[25] \"第25章: Quarto入門\"                    \n[26] \"第26章: 分析環境の管理\"                \n[27] \"第27章: 反復処理\"                      \n[28] \"第28章: オブジェクト指向プログラミング\"\n[29] \"第29章: モンテカルロ・シミュレーション\"\n[30] \"第30章: スクレイピング\"                \n[31] \"データセット\"                          \n[32] \"ファイルシステム\"                      \n[33] \"R Tips\"                                \n[34] \"本書の執筆環境\"                        \n[35] \"参考文献\"                              \n\n\n　今回は章の文字列だけ取得できた。それでは章のタイトルのベクトル（rbook_titles）とURL（rbook_urls）を一つの表としてまとめてみよう。\n\nrbook_df &lt;- tibble(Titles = rbook_titles,\n                   URL    = rbook_urls)\n\nprint(rbook_df, n = Inf)\n\n# A tibble: 35 × 2\n   Titles                                 URL                \n   &lt;chr&gt;                                  &lt;chr&gt;              \n 1 第1章: R?                              aboutr.html        \n 2 第2章: Rのインストール                 installation.html  \n 3 第3章: IDEの導入                       ide.html           \n 4 第4章: 分析環境のカスタマイズ          r_customize.html   \n 5 第5章: Rパッケージ                     packages.html      \n 6 第6章: プロジェクト管理                project.html       \n 7 第7章: 基本的な操作                    r_basic.html       \n 8 第8章: データの入出力                  io.html            \n 9 第9章: データ型                        datatype.html      \n10 第10章: データ構造                     datastructure.html \n11 第11章: Rプログラミングの基礎          programming.html   \n12 第12章: 関数の自作                     functions.html     \n13 第13章: データハンドリング [抽出]      datahandling1.html \n14 第14章: データハンドリング [拡張]      datahandling2.html \n15 第15章: データハンドリング [factor型]  factor.html        \n16 第16章: 整然データ構造                 tidydata.html      \n17 第17章: 文字列の処理                   string.html        \n18 第18章: 可視化[理論]                   visualization1.html\n19 第19章: 可視化[基礎]                   visualization2.html\n20 第20章: 可視化[応用]                   visualization3.html\n21 第21章: 可視化[発展]                   visualization4.html\n22 第22章: 表の作成                       table.html         \n23 第23章: R Markdown [基礎]              rmarkdown.html     \n24 第24章: R Markdown [応用]              rmarkdown2.html    \n25 第25章: Quarto入門                     quarto.html        \n26 第26章: 分析環境の管理                 renv.html          \n27 第27章: 反復処理                       iteration.html     \n28 第28章: オブジェクト指向プログラミング oop.html           \n29 第29章: モンテカルロ・シミュレーション monte.html         \n30 第30章: スクレイピング                 scraping.html      \n31 データセット                           ./dataset.html     \n32 ファイルシステム                       ./filesystem.html  \n33 R Tips                                 ./tips.html        \n34 本書の執筆環境                         ./session.html     \n35 参考文献                               ./references.html  \n\n\n　続いて、separate()関数を使って章とタイトルを\": \"文字列を基準に別の列として分割し、それぞれSectionとTitleという列とする。ただし、30章以降は付録であるため、\": \"は存在しない。したがって、章かタイトルどちらかは欠損値となるが、今回は左側を欠損値として埋めたいのでfill = \"left\"を追加する。さらに、URLも完全なURLにする。まず、付録のURLが何故か\"./\"で始まるようになっているので、str_remove()を使って除去する。そうすればファイル名だけが残り、後はこれらのファイル名の前に\"https://www.jaysong.net/RBook/\"を付けるだけだ。\n\nrbook_df &lt;- rbook_df |&gt;   \n  separate(col  = Titles,\n           into = c(\"Section\", \"Title\"),\n           sep  = \": \",\n           fill = \"left\") |&gt; \n  mutate(URL = str_remove(URL, \"^\\\\.\\\\/\"),\n         URL = paste0(\"https://www.jaysong.net/RBook/\", URL))\n\nprint(rbook_df, n = Inf)\n\n# A tibble: 35 × 3\n   Section Title                          URL                                   \n   &lt;chr&gt;   &lt;chr&gt;                          &lt;chr&gt;                                 \n 1 第1章   R?                             https://www.jaysong.net/RBook/aboutr.…\n 2 第2章   Rのインストール                https://www.jaysong.net/RBook/install…\n 3 第3章   IDEの導入                      https://www.jaysong.net/RBook/ide.html\n 4 第4章   分析環境のカスタマイズ         https://www.jaysong.net/RBook/r_custo…\n 5 第5章   Rパッケージ                    https://www.jaysong.net/RBook/package…\n 6 第6章   プロジェクト管理               https://www.jaysong.net/RBook/project…\n 7 第7章   基本的な操作                   https://www.jaysong.net/RBook/r_basic…\n 8 第8章   データの入出力                 https://www.jaysong.net/RBook/io.html \n 9 第9章   データ型                       https://www.jaysong.net/RBook/datatyp…\n10 第10章  データ構造                     https://www.jaysong.net/RBook/datastr…\n11 第11章  Rプログラミングの基礎          https://www.jaysong.net/RBook/program…\n12 第12章  関数の自作                     https://www.jaysong.net/RBook/functio…\n13 第13章  データハンドリング [抽出]      https://www.jaysong.net/RBook/datahan…\n14 第14章  データハンドリング [拡張]      https://www.jaysong.net/RBook/datahan…\n15 第15章  データハンドリング [factor型]  https://www.jaysong.net/RBook/factor.…\n16 第16章  整然データ構造                 https://www.jaysong.net/RBook/tidydat…\n17 第17章  文字列の処理                   https://www.jaysong.net/RBook/string.…\n18 第18章  可視化[理論]                   https://www.jaysong.net/RBook/visuali…\n19 第19章  可視化[基礎]                   https://www.jaysong.net/RBook/visuali…\n20 第20章  可視化[応用]                   https://www.jaysong.net/RBook/visuali…\n21 第21章  可視化[発展]                   https://www.jaysong.net/RBook/visuali…\n22 第22章  表の作成                       https://www.jaysong.net/RBook/table.h…\n23 第23章  R Markdown [基礎]              https://www.jaysong.net/RBook/rmarkdo…\n24 第24章  R Markdown [応用]              https://www.jaysong.net/RBook/rmarkdo…\n25 第25章  Quarto入門                     https://www.jaysong.net/RBook/quarto.…\n26 第26章  分析環境の管理                 https://www.jaysong.net/RBook/renv.ht…\n27 第27章  反復処理                       https://www.jaysong.net/RBook/iterati…\n28 第28章  オブジェクト指向プログラミング https://www.jaysong.net/RBook/oop.html\n29 第29章  モンテカルロ・シミュレーション https://www.jaysong.net/RBook/monte.h…\n30 第30章  スクレイピング                 https://www.jaysong.net/RBook/scrapin…\n31 &lt;NA&gt;    データセット                   https://www.jaysong.net/RBook/dataset…\n32 &lt;NA&gt;    ファイルシステム               https://www.jaysong.net/RBook/filesys…\n33 &lt;NA&gt;    R Tips                         https://www.jaysong.net/RBook/tips.ht…\n34 &lt;NA&gt;    本書の執筆環境                 https://www.jaysong.net/RBook/session…\n35 &lt;NA&gt;    参考文献                       https://www.jaysong.net/RBook/referen…\n\n\n　最後にrbook_dfを{gt}パッケージを使って表にする。sub_missing()関数を使って、欠損値の箇所を\"付録\"に置換し、fmt_url()を使って、URL列をリンクボタン化する。\n\nrbook_df |&gt;   \n  gt() |&gt; \n  cols_label(\"Section\" = \"章\",\n             \"Title\"   = \"タイトル\",\n             \"URL\"     = \"リンク\") |&gt; \n  sub_missing(columns = Section, missing_text = \"付録\") |&gt; \n  fmt_url(columns = URL, as_button = TRUE, label = \"Link\")\n\n\n\n\n  \n    \n    \n      章\n      タイトル\n      リンク\n    \n  \n  \n    第1章\nR?\nLink\n    第2章\nRのインストール\nLink\n    第3章\nIDEの導入\nLink\n    第4章\n分析環境のカスタマイズ\nLink\n    第5章\nRパッケージ\nLink\n    第6章\nプロジェクト管理\nLink\n    第7章\n基本的な操作\nLink\n    第8章\nデータの入出力\nLink\n    第9章\nデータ型\nLink\n    第10章\nデータ構造\nLink\n    第11章\nRプログラミングの基礎\nLink\n    第12章\n関数の自作\nLink\n    第13章\nデータハンドリング [抽出]\nLink\n    第14章\nデータハンドリング [拡張]\nLink\n    第15章\nデータハンドリング [factor型]\nLink\n    第16章\n整然データ構造\nLink\n    第17章\n文字列の処理\nLink\n    第18章\n可視化[理論]\nLink\n    第19章\n可視化[基礎]\nLink\n    第20章\n可視化[応用]\nLink\n    第21章\n可視化[発展]\nLink\n    第22章\n表の作成\nLink\n    第23章\nR Markdown [基礎]\nLink\n    第24章\nR Markdown [応用]\nLink\n    第25章\nQuarto入門\nLink\n    第26章\n分析環境の管理\nLink\n    第27章\n反復処理\nLink\n    第28章\nオブジェクト指向プログラミング\nLink\n    第29章\nモンテカルロ・シミュレーション\nLink\n    第30章\nスクレイピング\nLink\n    付録\nデータセット\nLink\n    付録\nファイルシステム\nLink\n    付録\nR Tips\nLink\n    付録\n本書の執筆環境\nLink\n    付録\n参考文献\nLink\n  \n  \n  \n\n\n\n\n\n\n30.3.2 表\n　まずは簡単な例から始めよう。ここでは英語版Wikipediaの世界報道自由度ランキングの表をスクレイピングする。長いURLは別途のオブジェクトに格納しておくと、コードが簡潔になるだけでなく、コードのリサイクルも簡単になる。ここでは読み込んだHTMLファイルをpfi_htmlという名のオブジェクトとして格納しておく。\n\nurl &lt;- \"https://en.wikipedia.org/wiki/World_Press_Freedom_Index\"\n\npfi_html &lt;- read_html(url)\n\npfi_html\n\n{html_document}\n&lt;html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-enabled vector-feature-main-menu-pinned-disabled vector-feature-limited-width-enabled vector-feature-limited-width-content-enabled vector-feature-zebra-design-disabled\" lang=\"en\" dir=\"ltr\"&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body class=\"skin-vector skin-vector-search-vue mediawiki ltr sitedir-ltr ...\n\n\n　続いて、html_table()を使用し、pfi_htmlから表（&lt;table&gt;タグ）を取得し、pfi_tblsオブジェクトに格納する。\n\npfi_tbls &lt;- pfi_html |&gt; \n  html_table()\n\npfi_tbls\n\n[[1]]\n# A tibble: 180 × 6\n   Country     `2023[5]`  `2022[6]`  `2021[7]`  `2020[8]`  `2019[9]` \n   &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;     \n 1 Norway      (001)95.18 (001)92.65 (001)93.28 (001)92.16 (001)92.18\n 2 Ireland     (002)89.91 (006)88.3  (012)88.09 (013)87.40 (015)85.00\n 3 Denmark     (003)89.48 (002)90.27 (004)91.43 (003)91.87 (005)90.13\n 4 Sweden      (004)88.15 (003)88.84 (003)92.76 (004)90.75 (003)91.69\n 5 Finland     (005)87.94 (005)88.42 (002)93.01 (002)92.07 (002)92.10\n 6 Netherlands (006)87.00 (028)77.93 (006)90.33 (005)90.04 (004)91.37\n 7 Lithuania   (007)86.79 (009)84.14 (028)79.95 (028)78.81 (030)77.94\n 8 Estonia     (008)85.31 (004)88.83 (015)84.75 (014)87.39 (011)87.73\n 9 Portugal    (009)84.60 (007)87.07 (009)89.89 (010)88.17 (012)87.37\n10 East Timor  (010)84.49 (017)81.89 (071)70.89 (078)70.10 (084)70.07\n# ℹ 170 more rows\n\n[[2]]\n# A tibble: 8 × 2\n  .mw-parser-output .navbar{display:inline;font-size:88…¹ .mw-parser-output .n…²\n  &lt;chr&gt;                                                   &lt;chr&gt;                 \n1 \"Freedom\"                                               \"Freedom in the World…\n2 \"Corruption\"                                            \"Bribe Payers Index\\n…\n3 \"Competitiveness\"                                       \"Composite Index of N…\n4 \"History\"                                               \"Flag adoption date\\n…\n5 \"Rights\"                                                \"Global Gender Gap Re…\n6 \"Democracy\"                                             \"Democracy indices\\nV…\n7 \"Other\"                                                 \"Commitment to Develo…\n8 \"List of international rankings\\nLists by country\"      \"List of internationa…\n# ℹ abbreviated names:\n#   ¹​`.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a&gt;span,.mw-parser-output .navbar a&gt;abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteLists of countries by political rankings`,\n#   ²​`.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a&gt;span,.mw-parser-output .navbar a&gt;abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}vteLists of countries by political rankings`\n\n\n　当該ページには2つの表があり、我々が欲しい表はリストの1番目の要素である。pfi_tblsの1番目の要素のみを抽出し、更に2023[5]のような列名をYear2023のように修正し、pfi_dfに格納する。\n\npfi_df &lt;- pfi_tbls[[1]] |&gt; \n  rename(\"Year2023\" = \"2023[5]\",\n         \"Year2022\" = \"2022[6]\",\n         \"Year2021\" = \"2021[7]\",\n         \"Year2020\" = \"2020[8]\",\n         \"Year2019\" = \"2019[9]\")\n\npfi_df\n\n# A tibble: 180 × 6\n   Country     Year2023   Year2022   Year2021   Year2020   Year2019  \n   &lt;chr&gt;       &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;      &lt;chr&gt;     \n 1 Norway      (001)95.18 (001)92.65 (001)93.28 (001)92.16 (001)92.18\n 2 Ireland     (002)89.91 (006)88.3  (012)88.09 (013)87.40 (015)85.00\n 3 Denmark     (003)89.48 (002)90.27 (004)91.43 (003)91.87 (005)90.13\n 4 Sweden      (004)88.15 (003)88.84 (003)92.76 (004)90.75 (003)91.69\n 5 Finland     (005)87.94 (005)88.42 (002)93.01 (002)92.07 (002)92.10\n 6 Netherlands (006)87.00 (028)77.93 (006)90.33 (005)90.04 (004)91.37\n 7 Lithuania   (007)86.79 (009)84.14 (028)79.95 (028)78.81 (030)77.94\n 8 Estonia     (008)85.31 (004)88.83 (015)84.75 (014)87.39 (011)87.73\n 9 Portugal    (009)84.60 (007)87.07 (009)89.89 (010)88.17 (012)87.37\n10 East Timor  (010)84.49 (017)81.89 (071)70.89 (078)70.10 (084)70.07\n# ℹ 170 more rows\n\n\n　pfi_dfを見ると、Country以外の列は世界報道自由度指数以外にもカッコ内に順位が書かれていることが分かる。具体的には(順位)指数の構造になっている。str_remove()関数を使って、ここから(順位)の箇所を削除しよう。「(で始まり（=^\\\\(）、一つ以上の数字が並び（=([0-9]+)）、その後に出てくる)まで（=\\\\)）」の箇所が削除対象であるため、正規表現は^\\\\(([0-9]+)\\\\)となる。正規表現の詳細は第17章を参照されたい。抽出が終わっても、まだcharacter型のままなので、as.numeric()関数でnumeric型に変換する。\n\npfi_df &lt;- pfi_df |&gt; \n  mutate(across(Year2023:Year2019, ~str_remove(.x, \"^\\\\(([0-9]+)\\\\)\")),\n         across(Year2023:Year2019, as.numeric))\n\npfi_df\n\n# A tibble: 180 × 6\n   Country     Year2023 Year2022 Year2021 Year2020 Year2019\n   &lt;chr&gt;          &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;\n 1 Norway          95.2     92.6     93.3     92.2     92.2\n 2 Ireland         89.9     88.3     88.1     87.4     85  \n 3 Denmark         89.5     90.3     91.4     91.9     90.1\n 4 Sweden          88.2     88.8     92.8     90.8     91.7\n 5 Finland         87.9     88.4     93.0     92.1     92.1\n 6 Netherlands     87       77.9     90.3     90.0     91.4\n 7 Lithuania       86.8     84.1     80.0     78.8     77.9\n 8 Estonia         85.3     88.8     84.8     87.4     87.7\n 9 Portugal        84.6     87.1     89.9     88.2     87.4\n10 East Timor      84.5     81.9     70.9     70.1     70.1\n# ℹ 170 more rows\n\n\n　これで表の抽出が終わった。すべての表を出力しても良いが、かなり長くなるため東アジア地域のみに限定してpfi_dfを{gt}パッケージで出力し、指数の値ごとに色分けをする。セルの色塗りについては第22.5章を参照されたい。\n\npfi_df |&gt; \n  filter(Country %in% c(\"Japan\", \"South Korea\", \"North Korea\", \"China\",\n                        \"Hong Kong\", \"Taiwan\", \"Mongolia\")) |&gt; \n  gt() |&gt; \n  cols_label(\"Year2023\" = \"2023\",\n             \"Year2022\" = \"2022\",\n             \"Year2021\" = \"2021\",\n             \"Year2020\" = \"2020\",\n             \"Year2019\" = \"2019\") |&gt; \n  data_color(columns = Year2023:Year2019,\n             palette = \"ggsci::blue_material\")\n\n\n\n\n  \n    \n    \n      Country\n      2023\n      2022\n      2021\n      2020\n      2019\n    \n  \n  \n    Taiwan\n75.54\n74.08\n76.14\n76.24\n75.02\n    South Korea\n70.83\n72.11\n76.57\n76.30\n75.06\n    Japan\n63.95\n64.37\n71.12\n71.14\n70.64\n    Mongolia\n59.33\n59.17\n71.03\n70.39\n70.49\n    Hong Kong\n44.86\n41.64\n69.56\n69.99\n70.35\n    China\n22.97\n25.17\n21.28\n21.52\n21.08\n    North Korea\n21.72\n13.92\n18.72\n14.18\n16.60\n  \n  \n  \n\n\n\n\n\n\n30.3.3 表（複数ページ）\n　続いて、複数のHTMLページから表を取得してみよう。今回はJリーグ（1部から3部まで）の順位表が対象である。\n\nJ1: https://www.jleague.jp/standings/j1/\nJ2: https://www.jleague.jp/standings/j2/\nJ3: https://www.jleague.jp/standings/j3/\n\n　3つのページを見ると、ページの構造は一致することが分かる。また、表を意味する&lt;table&gt;タグを見ると、いずれもscoreTable01クラスが付与されていること分かる（各自、開発者メニューから確認してみよう）。したがって、同じ作業を3つのページに対して繰り返すだけで良いだろう。まずは、J1リーグだけ試してみよう。まず、HTMLファイルを読み込み、html_element(\".scoreTable01\")でscoreTalbe01クラスの要素を抽出し、そこからhtml_table()で表を抽出してみよう。\n\nj1_url  &lt;- \"https://www.jleague.jp/standings/j1\"\nj1_html &lt;- read_html(j1_url)\n\nj1_html |&gt; \n  html_element(\".scoreTable01\") |&gt; \n  html_table()\n\n# A tibble: 19 × 12\n   X1    X2    X3          X4    X5    X6    X7    X8    X9    X10   X11   X12  \n   &lt;lgl&gt; &lt;chr&gt; &lt;chr&gt;       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n 1 NA    順位  クラブ名    勝点  試合… 勝    分    負    得点  失点  得失… \"直… \n 2 NA    1     横浜Ｆ・マ… 39    18    12    3     3     38    20    18    \"\"   \n 3 NA    2     ヴィッセル… 36    17    11    3     3     36    13    23    \"\"   \n 4 NA    3     名古屋グラ… 35    18    10    5     3     25    16    9     \"\"   \n 5 NA    4     セレッソ大… 32    18    10    2     6     27    20    7     \"\"   \n 6 NA    5     浦和レッズ… 30    17    8     6     3     21    13    8     \"\"   \n 7 NA    6     サンフレッ… 29    18    9     2     7     22    17    5     \"\"   \n 8 NA    7     鹿島アント… 28    18    8     4     6     24    18    6     \"\"   \n 9 NA    8     サガン鳥栖… 26    18    7     5     6     25    21    4     \"\"   \n10 NA    9     北海道コン… 26    18    7     5     6     39    36    3     \"\"   \n11 NA    10    川崎フロン… 25    17    7     4     6     21    19    2     \"\"   \n12 NA    11    ＦＣ東京Ｆ… 22    18    6     4     8     24    28    -4    \"\"   \n13 NA    12    アビスパ福… 20    18    5     5     8     17    25    -8    \"\"   \n14 NA    13    京都サンガ… 19    18    6     1     11    22    29    -7    \"\"   \n15 NA    14    ガンバ大阪… 19    18    5     4     9     23    34    -11   \"\"   \n16 NA    15    アルビレッ… 18    18    4     6     8     19    28    -9    \"\"   \n17 NA    16    柏レイソル… 13    18    2     7     9     16    28    -12   \"\"   \n18 NA    17    横浜ＦＣ横… 13    18    3     4     11    14    37    -23   \"\"   \n19 NA    18    湘南ベルマ… 12    17    2     6     9     23    34    -11   \"\"   \n\n\n　今回もheader = TRUEを入れてヘッダーを指定する必要があると考えられる。また、取得する列は順位から得失点までなので、必要な列だけを抽出してみよう。\n\nj1_html |&gt; \n  html_element(\".scoreTable01\") |&gt; \n  html_table(header = TRUE) |&gt; \n  select(順位:得失点)\n\n# A tibble: 18 × 10\n    順位 クラブ名               勝点 試合数    勝    分    負  得点  失点 得失点\n   &lt;int&gt; &lt;chr&gt;                 &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n 1     1 横浜Ｆ・マリノス横浜…    39     18    12     3     3    38    20     18\n 2     2 ヴィッセル神戸ヴィッ…    36     17    11     3     3    36    13     23\n 3     3 名古屋グランパス名古…    35     18    10     5     3    25    16      9\n 4     4 セレッソ大阪セレッソ…    32     18    10     2     6    27    20      7\n 5     5 浦和レッズ浦和レッズ     30     17     8     6     3    21    13      8\n 6     6 サンフレッチェ広島サ…    29     18     9     2     7    22    17      5\n 7     7 鹿島アントラーズ鹿島…    28     18     8     4     6    24    18      6\n 8     8 サガン鳥栖サガン鳥栖     26     18     7     5     6    25    21      4\n 9     9 北海道コンサドーレ札…    26     18     7     5     6    39    36      3\n10    10 川崎フロンターレ川崎…    25     17     7     4     6    21    19      2\n11    11 ＦＣ東京ＦＣ東京         22     18     6     4     8    24    28     -4\n12    12 アビスパ福岡アビスパ…    20     18     5     5     8    17    25     -8\n13    13 京都サンガF.C.京都サ…    19     18     6     1    11    22    29     -7\n14    14 ガンバ大阪ガンバ大阪     19     18     5     4     9    23    34    -11\n15    15 アルビレックス新潟ア…    18     18     4     6     8    19    28     -9\n16    16 柏レイソル柏レイソル     13     18     2     7     9    16    28    -12\n17    17 横浜ＦＣ横浜ＦＣ         13     18     3     4    11    14    37    -23\n18    18 湘南ベルマーレ湘南ベ…    12     17     2     6     9    23    34    -11\n\n\n　以上の作業を3つのページに対して繰り返せば良い。まずは、3つのURLが格納されたcharacter型ベクトルを作成しよう。\n\nj_urls &lt;- paste0(\"https://www.jleague.jp/standings/j\", 1:3)\nj_urls\n\n[1] \"https://www.jleague.jp/standings/j1\" \"https://www.jleague.jp/standings/j2\"\n[3] \"https://www.jleague.jp/standings/j3\"\n\n\n　また、取得した3つの表を格納する空のリストを作成する。\n\ntbl_list &lt;- list()\n\n　続いてfor()を使用し、これらのスクレイピングを繰り返す。seq_along(j_urls)は1:length(j_urls)と同じ意味だ。\n\nfor (i in seq_along(j_urls)) {\n  # j_urlsのi番目のURLからHTMLファイルを読み込み、temp_htmlに格納\n  temp_html &lt;- read_html(j_urls[i])\n  # 表を取得し、temp_tblに格納\n  temp_tbl  &lt;- temp_html |&gt; \n    html_element(\".scoreTable01\") |&gt; \n    html_table(header = TRUE) |&gt; \n    select(順位:得失点)\n  \n  # tbl_listにtemp_tblを格納する。\n  # tbl_listの名前はJ1、J2、J3になるようにする。\n  tbl_list[[paste0(\"J\", i)]] &lt;- temp_tbl\n  \n  # 1つの表を取得したら1秒休む\n  Sys.sleep(1)\n}\n\ntbl_list\n\n$J1\n# A tibble: 18 × 10\n    順位 クラブ名               勝点 試合数    勝    分    負  得点  失点 得失点\n   &lt;int&gt; &lt;chr&gt;                 &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n 1     1 横浜Ｆ・マリノス横浜…    39     18    12     3     3    38    20     18\n 2     2 ヴィッセル神戸ヴィッ…    36     17    11     3     3    36    13     23\n 3     3 名古屋グランパス名古…    35     18    10     5     3    25    16      9\n 4     4 セレッソ大阪セレッソ…    32     18    10     2     6    27    20      7\n 5     5 浦和レッズ浦和レッズ     30     17     8     6     3    21    13      8\n 6     6 サンフレッチェ広島サ…    29     18     9     2     7    22    17      5\n 7     7 鹿島アントラーズ鹿島…    28     18     8     4     6    24    18      6\n 8     8 サガン鳥栖サガン鳥栖     26     18     7     5     6    25    21      4\n 9     9 北海道コンサドーレ札…    26     18     7     5     6    39    36      3\n10    10 川崎フロンターレ川崎…    25     17     7     4     6    21    19      2\n11    11 ＦＣ東京ＦＣ東京         22     18     6     4     8    24    28     -4\n12    12 アビスパ福岡アビスパ…    20     18     5     5     8    17    25     -8\n13    13 京都サンガF.C.京都サ…    19     18     6     1    11    22    29     -7\n14    14 ガンバ大阪ガンバ大阪     19     18     5     4     9    23    34    -11\n15    15 アルビレックス新潟ア…    18     18     4     6     8    19    28     -9\n16    16 柏レイソル柏レイソル     13     18     2     7     9    16    28    -12\n17    17 横浜ＦＣ横浜ＦＣ         13     18     3     4    11    14    37    -23\n18    18 湘南ベルマーレ湘南ベ…    12     17     2     6     9    23    34    -11\n\n$J2\n# A tibble: 22 × 10\n    順位 クラブ名               勝点 試合数    勝    分    負  得点  失点 得失点\n   &lt;int&gt; &lt;chr&gt;                 &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n 1     1 ＦＣ町田ゼルビアＦＣ…    47     22    14     5     3    34    13     21\n 2     2 大分トリニータ大分ト…    41     22    12     5     5    28    25      3\n 3     3 東京ヴェルディ東京ヴ…    40     22    12     4     6    30    14     16\n 4     4 Ｖ・ファーレン長崎Ｖ…    38     22    11     5     6    35    22     13\n 5     5 ジュビロ磐田ジュビロ…    36     21    10     6     5    36    24     12\n 6     6 ヴァンフォーレ甲府ヴ…    36     21    11     3     7    29    21      8\n 7     7 清水エスパルス清水エ…    32     21     8     8     5    40    17     23\n 8     8 ベガルタ仙台ベガルタ…    31     22     8     7     7    27    24      3\n 9     9 ザスパクサツ群馬ザス…    31     22     8     7     7    25    26     -1\n10    10 藤枝ＭＹＦＣ藤枝ＭＹ…    31     22     9     4     9    34    37     -3\n# ℹ 12 more rows\n\n$J3\n# A tibble: 20 × 10\n    順位 クラブ名               勝点 試合数    勝    分    負  得点  失点 得失点\n   &lt;int&gt; &lt;chr&gt;                 &lt;int&gt;  &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;  &lt;int&gt;\n 1     1 カターレ富山カターレ…    30     15     9     3     3    26    15     11\n 2     2 愛媛ＦＣ愛媛ＦＣ         28     15     8     4     3    19    17      2\n 3     3 鹿児島ユナイテッドＦ…    25     15     7     4     4    21    15      6\n 4     4 松本山雅ＦＣ松本山雅…    24     15     7     3     5    27    21      6\n 5     5 ＦＣ岐阜ＦＣ岐阜         24     15     7     3     5    18    13      5\n 6     6 ＦＣ今治ＦＣ今治         23     15     6     5     4    20    18      2\n 7     7 アスルクラロ沼津アス…    23     15     6     5     4    18    16      2\n 8     8 ＦＣ大阪ＦＣ大阪         22     15     7     1     7    13    12      1\n 9     9 奈良クラブ奈良クラブ     21     15     5     6     4    17    12      5\n10    10 ＡＣ長野パルセイロＡ…    21     15     6     3     6    23    19      4\n11    11 テゲバジャーロ宮崎テ…    21     15     5     6     4    14    15     -1\n12    12 いわてグルージャ盛岡…    20     15     6     2     7    21    19      2\n13    13 ヴァンラーレ八戸ヴァ…    20     15     5     5     5    16    16      0\n14    14 Ｙ．Ｓ．Ｃ．Ｃ．横浜…    20     15     5     5     5    21    24     -3\n15    15 ガイナーレ鳥取ガイナ…    18     15     4     6     5    20    23     -3\n16    16 ＦＣ琉球ＦＣ琉球         17     15     5     2     8    16    23     -7\n17    17 カマタマーレ讃岐カマ…    16     15     4     4     7     8    22    -14\n18    18 福島ユナイテッドＦＣ…    15     15     4     3     8    10    14     -4\n19    19 ギラヴァンツ北九州ギ…    11     15     2     5     8    14    21     -7\n20    20 ＳＣ相模原ＳＣ相模原     10     15     1     7     7    16    23     -7\n\n\n　bind_rows()を使ってリスト内の3つの表を結合し、{gt}パッケージで表示する。\n\nj_df &lt;- bind_rows(tbl_list, .id = \"リーグ\")\n\nj_df |&gt; \n  gt()\n\n\n\n\n  \n    \n    \n      リーグ\n      順位\n      クラブ名\n      勝点\n      試合数\n      勝\n      分\n      負\n      得点\n      失点\n      得失点\n    \n  \n  \n    J1\n1\n横浜Ｆ・マリノス横浜Ｆ・マリノス\n39\n18\n12\n3\n3\n38\n20\n18\n    J1\n2\nヴィッセル神戸ヴィッセル神戸\n36\n17\n11\n3\n3\n36\n13\n23\n    J1\n3\n名古屋グランパス名古屋グランパス\n35\n18\n10\n5\n3\n25\n16\n9\n    J1\n4\nセレッソ大阪セレッソ大阪\n32\n18\n10\n2\n6\n27\n20\n7\n    J1\n5\n浦和レッズ浦和レッズ\n30\n17\n8\n6\n3\n21\n13\n8\n    J1\n6\nサンフレッチェ広島サンフレッチェ広島\n29\n18\n9\n2\n7\n22\n17\n5\n    J1\n7\n鹿島アントラーズ鹿島アントラーズ\n28\n18\n8\n4\n6\n24\n18\n6\n    J1\n8\nサガン鳥栖サガン鳥栖\n26\n18\n7\n5\n6\n25\n21\n4\n    J1\n9\n北海道コンサドーレ札幌北海道コンサドーレ札幌\n26\n18\n7\n5\n6\n39\n36\n3\n    J1\n10\n川崎フロンターレ川崎フロンターレ\n25\n17\n7\n4\n6\n21\n19\n2\n    J1\n11\nＦＣ東京ＦＣ東京\n22\n18\n6\n4\n8\n24\n28\n-4\n    J1\n12\nアビスパ福岡アビスパ福岡\n20\n18\n5\n5\n8\n17\n25\n-8\n    J1\n13\n京都サンガF.C.京都サンガF.C.\n19\n18\n6\n1\n11\n22\n29\n-7\n    J1\n14\nガンバ大阪ガンバ大阪\n19\n18\n5\n4\n9\n23\n34\n-11\n    J1\n15\nアルビレックス新潟アルビレックス新潟\n18\n18\n4\n6\n8\n19\n28\n-9\n    J1\n16\n柏レイソル柏レイソル\n13\n18\n2\n7\n9\n16\n28\n-12\n    J1\n17\n横浜ＦＣ横浜ＦＣ\n13\n18\n3\n4\n11\n14\n37\n-23\n    J1\n18\n湘南ベルマーレ湘南ベルマーレ\n12\n17\n2\n6\n9\n23\n34\n-11\n    J2\n1\nＦＣ町田ゼルビアＦＣ町田ゼルビア\n47\n22\n14\n5\n3\n34\n13\n21\n    J2\n2\n大分トリニータ大分トリニータ\n41\n22\n12\n5\n5\n28\n25\n3\n    J2\n3\n東京ヴェルディ東京ヴェルディ\n40\n22\n12\n4\n6\n30\n14\n16\n    J2\n4\nＶ・ファーレン長崎Ｖ・ファーレン長崎\n38\n22\n11\n5\n6\n35\n22\n13\n    J2\n5\nジュビロ磐田ジュビロ磐田\n36\n21\n10\n6\n5\n36\n24\n12\n    J2\n6\nヴァンフォーレ甲府ヴァンフォーレ甲府\n36\n21\n11\n3\n7\n29\n21\n8\n    J2\n7\n清水エスパルス清水エスパルス\n32\n21\n8\n8\n5\n40\n17\n23\n    J2\n8\nベガルタ仙台ベガルタ仙台\n31\n22\n8\n7\n7\n27\n24\n3\n    J2\n9\nザスパクサツ群馬ザスパクサツ群馬\n31\n22\n8\n7\n7\n25\n26\n-1\n    J2\n10\n藤枝ＭＹＦＣ藤枝ＭＹＦＣ\n31\n22\n9\n4\n9\n34\n37\n-3\n    J2\n11\nロアッソ熊本ロアッソ熊本\n30\n22\n8\n6\n8\n31\n23\n8\n    J2\n12\nファジアーノ岡山ファジアーノ岡山\n30\n22\n6\n12\n4\n26\n20\n6\n    J2\n13\nモンテディオ山形モンテディオ山形\n29\n22\n9\n2\n11\n33\n30\n3\n    J2\n14\nブラウブリッツ秋田ブラウブリッツ秋田\n27\n21\n7\n6\n8\n17\n21\n-4\n    J2\n15\n徳島ヴォルティス徳島ヴォルティス\n25\n22\n5\n10\n7\n22\n30\n-8\n    J2\n16\nジェフユナイテッド千葉ジェフユナイテッド千葉\n25\n22\n6\n7\n9\n20\n29\n-9\n    J2\n17\nツエーゲン金沢ツエーゲン金沢\n24\n22\n7\n3\n12\n27\n39\n-12\n    J2\n18\n水戸ホーリーホック水戸ホーリーホック\n24\n22\n6\n6\n10\n24\n39\n-15\n    J2\n19\nレノファ山口ＦＣレノファ山口ＦＣ\n23\n22\n5\n8\n9\n19\n38\n-19\n    J2\n20\n栃木ＳＣ栃木ＳＣ\n22\n22\n5\n7\n10\n19\n24\n-5\n    J2\n21\nいわきＦＣいわきＦＣ\n20\n22\n5\n5\n12\n19\n38\n-19\n    J2\n22\n大宮アルディージャ大宮アルディージャ\n14\n22\n4\n2\n16\n19\n40\n-21\n    J3\n1\nカターレ富山カターレ富山\n30\n15\n9\n3\n3\n26\n15\n11\n    J3\n2\n愛媛ＦＣ愛媛ＦＣ\n28\n15\n8\n4\n3\n19\n17\n2\n    J3\n3\n鹿児島ユナイテッドＦＣ鹿児島ユナイテッドＦＣ\n25\n15\n7\n4\n4\n21\n15\n6\n    J3\n4\n松本山雅ＦＣ松本山雅ＦＣ\n24\n15\n7\n3\n5\n27\n21\n6\n    J3\n5\nＦＣ岐阜ＦＣ岐阜\n24\n15\n7\n3\n5\n18\n13\n5\n    J3\n6\nＦＣ今治ＦＣ今治\n23\n15\n6\n5\n4\n20\n18\n2\n    J3\n7\nアスルクラロ沼津アスルクラロ沼津\n23\n15\n6\n5\n4\n18\n16\n2\n    J3\n8\nＦＣ大阪ＦＣ大阪\n22\n15\n7\n1\n7\n13\n12\n1\n    J3\n9\n奈良クラブ奈良クラブ\n21\n15\n5\n6\n4\n17\n12\n5\n    J3\n10\nＡＣ長野パルセイロＡＣ長野パルセイロ\n21\n15\n6\n3\n6\n23\n19\n4\n    J3\n11\nテゲバジャーロ宮崎テゲバジャーロ宮崎\n21\n15\n5\n6\n4\n14\n15\n-1\n    J3\n12\nいわてグルージャ盛岡いわてグルージャ盛岡\n20\n15\n6\n2\n7\n21\n19\n2\n    J3\n13\nヴァンラーレ八戸ヴァンラーレ八戸\n20\n15\n5\n5\n5\n16\n16\n0\n    J3\n14\nＹ．Ｓ．Ｃ．Ｃ．横浜Ｙ．Ｓ．Ｃ．Ｃ．横浜\n20\n15\n5\n5\n5\n21\n24\n-3\n    J3\n15\nガイナーレ鳥取ガイナーレ鳥取\n18\n15\n4\n6\n5\n20\n23\n-3\n    J3\n16\nＦＣ琉球ＦＣ琉球\n17\n15\n5\n2\n8\n16\n23\n-7\n    J3\n17\nカマタマーレ讃岐カマタマーレ讃岐\n16\n15\n4\n4\n7\n8\n22\n-14\n    J3\n18\n福島ユナイテッドＦＣ福島ユナイテッドＦＣ\n15\n15\n4\n3\n8\n10\n14\n-4\n    J3\n19\nギラヴァンツ北九州ギラヴァンツ北九州\n11\n15\n2\n5\n8\n14\n21\n-7\n    J3\n20\nＳＣ相模原ＳＣ相模原\n10\n15\n1\n7\n7\n16\n23\n-7\n  \n  \n  \n\n\n\n\n　クラブ名が「FC矢内FC矢内」のようになっていることが分かる。元のページを見ると、チームのエンブレムが表示されるが、これらの画像には代替テキスト（alt）が付与されており、スクレイピングのように画像が読み込めない場合は、その代替テキストが取得されるのが原因である。\n　解決方法はいくつかあるが、ここでは事後的な解決方法を採用する。具体的にはクラブ名列内の文字列を半分だけ残せば良い。たとえば、「FC矢内FC矢内」は8文字であるため、1番目の文字から8文字の半分である4文字まで残す。文字列から一部を取り出す関数はstr_sub()であり、str_sub(文字列, スタート位置, 終了位置)を指定する。スタート位置は1固定であり、終了位置は文字列の長さ（nchar(文字列)）の半分だからnchar(文字列) / 2で良い。\n　処理が終わったら、リーグ列でグルーピングして表として出力する。\n\nj_df |&gt; \n  mutate(クラブ名 = str_sub(クラブ名, 1, nchar(クラブ名) / 2)) |&gt; \n  group_by(リーグ) |&gt; \n  gt()\n\n\n\n\n  \n    \n    \n      順位\n      クラブ名\n      勝点\n      試合数\n      勝\n      分\n      負\n      得点\n      失点\n      得失点\n    \n  \n  \n    \n      J1\n    \n    1\n横浜Ｆ・マリノス\n39\n18\n12\n3\n3\n38\n20\n18\n    2\nヴィッセル神戸\n36\n17\n11\n3\n3\n36\n13\n23\n    3\n名古屋グランパス\n35\n18\n10\n5\n3\n25\n16\n9\n    4\nセレッソ大阪\n32\n18\n10\n2\n6\n27\n20\n7\n    5\n浦和レッズ\n30\n17\n8\n6\n3\n21\n13\n8\n    6\nサンフレッチェ広島\n29\n18\n9\n2\n7\n22\n17\n5\n    7\n鹿島アントラーズ\n28\n18\n8\n4\n6\n24\n18\n6\n    8\nサガン鳥栖\n26\n18\n7\n5\n6\n25\n21\n4\n    9\n北海道コンサドーレ札幌\n26\n18\n7\n5\n6\n39\n36\n3\n    10\n川崎フロンターレ\n25\n17\n7\n4\n6\n21\n19\n2\n    11\nＦＣ東京\n22\n18\n6\n4\n8\n24\n28\n-4\n    12\nアビスパ福岡\n20\n18\n5\n5\n8\n17\n25\n-8\n    13\n京都サンガF.C.\n19\n18\n6\n1\n11\n22\n29\n-7\n    14\nガンバ大阪\n19\n18\n5\n4\n9\n23\n34\n-11\n    15\nアルビレックス新潟\n18\n18\n4\n6\n8\n19\n28\n-9\n    16\n柏レイソル\n13\n18\n2\n7\n9\n16\n28\n-12\n    17\n横浜ＦＣ\n13\n18\n3\n4\n11\n14\n37\n-23\n    18\n湘南ベルマーレ\n12\n17\n2\n6\n9\n23\n34\n-11\n    \n      J2\n    \n    1\nＦＣ町田ゼルビア\n47\n22\n14\n5\n3\n34\n13\n21\n    2\n大分トリニータ\n41\n22\n12\n5\n5\n28\n25\n3\n    3\n東京ヴェルディ\n40\n22\n12\n4\n6\n30\n14\n16\n    4\nＶ・ファーレン長崎\n38\n22\n11\n5\n6\n35\n22\n13\n    5\nジュビロ磐田\n36\n21\n10\n6\n5\n36\n24\n12\n    6\nヴァンフォーレ甲府\n36\n21\n11\n3\n7\n29\n21\n8\n    7\n清水エスパルス\n32\n21\n8\n8\n5\n40\n17\n23\n    8\nベガルタ仙台\n31\n22\n8\n7\n7\n27\n24\n3\n    9\nザスパクサツ群馬\n31\n22\n8\n7\n7\n25\n26\n-1\n    10\n藤枝ＭＹＦＣ\n31\n22\n9\n4\n9\n34\n37\n-3\n    11\nロアッソ熊本\n30\n22\n8\n6\n8\n31\n23\n8\n    12\nファジアーノ岡山\n30\n22\n6\n12\n4\n26\n20\n6\n    13\nモンテディオ山形\n29\n22\n9\n2\n11\n33\n30\n3\n    14\nブラウブリッツ秋田\n27\n21\n7\n6\n8\n17\n21\n-4\n    15\n徳島ヴォルティス\n25\n22\n5\n10\n7\n22\n30\n-8\n    16\nジェフユナイテッド千葉\n25\n22\n6\n7\n9\n20\n29\n-9\n    17\nツエーゲン金沢\n24\n22\n7\n3\n12\n27\n39\n-12\n    18\n水戸ホーリーホック\n24\n22\n6\n6\n10\n24\n39\n-15\n    19\nレノファ山口ＦＣ\n23\n22\n5\n8\n9\n19\n38\n-19\n    20\n栃木ＳＣ\n22\n22\n5\n7\n10\n19\n24\n-5\n    21\nいわきＦＣ\n20\n22\n5\n5\n12\n19\n38\n-19\n    22\n大宮アルディージャ\n14\n22\n4\n2\n16\n19\n40\n-21\n    \n      J3\n    \n    1\nカターレ富山\n30\n15\n9\n3\n3\n26\n15\n11\n    2\n愛媛ＦＣ\n28\n15\n8\n4\n3\n19\n17\n2\n    3\n鹿児島ユナイテッドＦＣ\n25\n15\n7\n4\n4\n21\n15\n6\n    4\n松本山雅ＦＣ\n24\n15\n7\n3\n5\n27\n21\n6\n    5\nＦＣ岐阜\n24\n15\n7\n3\n5\n18\n13\n5\n    6\nＦＣ今治\n23\n15\n6\n5\n4\n20\n18\n2\n    7\nアスルクラロ沼津\n23\n15\n6\n5\n4\n18\n16\n2\n    8\nＦＣ大阪\n22\n15\n7\n1\n7\n13\n12\n1\n    9\n奈良クラブ\n21\n15\n5\n6\n4\n17\n12\n5\n    10\nＡＣ長野パルセイロ\n21\n15\n6\n3\n6\n23\n19\n4\n    11\nテゲバジャーロ宮崎\n21\n15\n5\n6\n4\n14\n15\n-1\n    12\nいわてグルージャ盛岡\n20\n15\n6\n2\n7\n21\n19\n2\n    13\nヴァンラーレ八戸\n20\n15\n5\n5\n5\n16\n16\n0\n    14\nＹ．Ｓ．Ｃ．Ｃ．横浜\n20\n15\n5\n5\n5\n21\n24\n-3\n    15\nガイナーレ鳥取\n18\n15\n4\n6\n5\n20\n23\n-3\n    16\nＦＣ琉球\n17\n15\n5\n2\n8\n16\n23\n-7\n    17\nカマタマーレ讃岐\n16\n15\n4\n4\n7\n8\n22\n-14\n    18\n福島ユナイテッドＦＣ\n15\n15\n4\n3\n8\n10\n14\n-4\n    19\nギラヴァンツ北九州\n11\n15\n2\n5\n8\n14\n21\n-7\n    20\nＳＣ相模原\n10\n15\n1\n7\n7\n16\n23\n-7\n  \n  \n  \n\n\n\n\n\n\n30.3.4 表以外の内容\n　続いて、表のように見えて表ではないものをスクレイピングしてみよう。OpenCriticというゲームの口コミサイトから2021年発売されたPCゲームのランキングを取得してみよう。対象ページは以下のURLだ。\n\nhttps://opencritic.com/browse/all/2021\n\n\n　ここには上位20位までのゲームのリストがあり、20行86列9の表のように見える。まず、このページを読み込んだものをoc_htmlに格納する。\n\noc_html &lt;- read_html(\"https://opencritic.com/browse/all/2021\")\noc_html\n\n{html_document}\n&lt;html lang=\"en\"&gt;\n[1] &lt;head&gt;\\n&lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8 ...\n[2] &lt;body&gt;\\n&lt;script type=\"text/javascript\"&gt;\\n  if (document && document.cooki ...\n\n\n　続いてoc_htmlからhtml_table()を使用し、表を抽出してみよう。\n\noc_html |&gt; \n  html_table()\n\nlist()\n\n\n　どうみても表があるように見えるものの、html_table()から表は抽出されていない。実はこのページの順位表、&lt;table&gt;タグで記述された表ではない。100個以上の&lt;div&gt;要素を表のように並べたものである。開発者メニューからこの表のようなもののコードを確認してみよう。\n&lt;div _ngcontent-serverapp-c79=\"\" class=\"desktop-game-display\"&gt;\n    &lt;div _ngcontent-serverapp-c79=\"\"&gt;\n        &lt;div _ngcontent-serverapp-c79=\"\" class=\"row no-gutters py-2 game-row align-items-center\"&gt;\n            &lt;div _ngcontent-serverapp-c79=\"\" class=\"rank\"&gt; 1. &lt;/div&gt;\n            &lt;div _ngcontent-serverapp-c79=\"\" class=\"score col-auto\"&gt; 93 &lt;/div&gt;\n            &lt;div _ngcontent-serverapp-c79=\"\" class=\"tier col-auto\"&gt;&lt;app-tier-display _ngcontent-serverapp-c79=\"\" display=\"man\" _nghost-serverapp-c65=\"\"&gt;&lt;img _ngcontent-serverapp-c65=\"\" src=\"//img.opencritic.com/mighty-man/mighty-man.png\" alt=\"Mighty\" width=\"45\" height=\"42\"&gt;&lt;/app-tier-display&gt;&lt;/div&gt;\n            &lt;div _ngcontent-serverapp-c79=\"\" class=\"game-name col\"&gt;&lt;a _ngcontent-serverapp-c79=\"\" href=\"/game/11626/final-fantasy-xiv-endwalker\"&gt;Final Fantasy XIV: Endwalker&lt;/a&gt;&lt;/div&gt;\n            &lt;div _ngcontent-serverapp-c79=\"\" class=\"platforms col-auto\"&gt; PC, PS5, PS4 &lt;/div&gt;\n            &lt;div _ngcontent-serverapp-c79=\"\" class=\"first-release-date col-auto\"&gt;&lt;span _ngcontent-serverapp-c79=\"\"&gt;Dec 7&lt;/span&gt;&lt;/div&gt;\n        &lt;/div&gt;\n        &lt;div _ngcontent-serverapp-c79=\"\" class=\"row no-gutters py-2 game-row align-items-center\"&gt;\n            &lt;div _ngcontent-serverapp-c79=\"\" class=\"rank\"&gt; 2. &lt;/div&gt;\n            &lt;div _ngcontent-serverapp-c79=\"\" class=\"score col-auto\"&gt; 92 &lt;/div&gt;\n            ...\n　数百の&lt;div&gt;タグが入れ子構造でなっていることが分かる。この&lt;div&gt;タグそのものに特別な機能はない。&lt;span&gt;が文中の文章に対してクラスやIDを割り当てるために使われるということは既に説明したが、&lt;div&gt;もほぼ同じ役割をする。違いがあれば、&lt;span&gt;は文中の文章が対象であり、&lt;div&gt;は領域が対象とすることだ。この構造を実際のページに対応すると以下のようになる。\n\n　まず、この順位表全体はクラス名がdesktop-game-displayの&lt;div&gt;タグに囲まれている。この中に、各行はrow、no-gutters、py-2、game-row、align-items-center計5つのクラスを持つ&lt;div&gt;タグで囲まれている。そしてこの中に順位（クラス名：rank）やスコア（クラス名：score、col-auto）、ティア（クラス名：tier、col-auto）の&lt;div&gt;があり、それぞれのセルを構成している。\n　ここからランクを取り出してみよう。まずはクラスがdesktop-game-displayである&lt;div&gt;タグに限定するために、html_element(\"div.desktop-game-display\")で当該&lt;div&gt;のみを残し、oc_htmlを上書きする。このようにクラス名とタグを同時に指定する場合のセレクターはタグ名.クラス名と表記する。\n\noc_html &lt;- oc_html |&gt; \n  html_element(\"div.desktop-game-display\")\noc_html\n\n{html_node}\n&lt;div _ngcontent-sc159=\"\" class=\"desktop-game-display\"&gt;\n[1] &lt;div _ngcontent-sc159=\"\"&gt;\\n&lt;div _ngcontent-sc159=\"\" class=\"row no-gutters ...\n\n\n　続いて、oc_htmlからクラス名がrankの&lt;div&gt;タグを抽出する。今回は抽出対象が20個あるため、html_element()でなく、html_elements()を使用する。\n\noc_html |&gt; \n  html_elements(\"div.rank\")\n\n{xml_nodeset (20)}\n [1] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 1. &lt;/div&gt;\\n\n [2] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 2. &lt;/div&gt;\\n\n [3] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 3. &lt;/div&gt;\\n\n [4] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 4. &lt;/div&gt;\\n\n [5] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 5. &lt;/div&gt;\\n\n [6] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 6. &lt;/div&gt;\\n\n [7] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 7. &lt;/div&gt;\\n\n [8] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 8. &lt;/div&gt;\\n\n [9] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 9. &lt;/div&gt;\\n\n[10] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 10. &lt;/div&gt;\\n\n[11] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 11. &lt;/div&gt;\\n\n[12] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 12. &lt;/div&gt;\\n\n[13] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 13. &lt;/div&gt;\\n\n[14] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 14. &lt;/div&gt;\\n\n[15] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 15. &lt;/div&gt;\\n\n[16] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 16. &lt;/div&gt;\\n\n[17] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 17. &lt;/div&gt;\\n\n[18] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 18. &lt;/div&gt;\\n\n[19] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 19. &lt;/div&gt;\\n\n[20] &lt;div _ngcontent-sc159=\"\" class=\"rank\"&gt; 20. &lt;/div&gt;\\n\n\n\n　さらにここからhtml_text()を使用してテキストのみ抽出してみよう。\n\noc_html |&gt; \n  html_elements(\"div.rank\") |&gt; \n  html_text()\n\n [1] \" 1. \"  \" 2. \"  \" 3. \"  \" 4. \"  \" 5. \"  \" 6. \"  \" 7. \"  \" 8. \"  \" 9. \" \n[10] \" 10. \" \" 11. \" \" 12. \" \" 13. \" \" 14. \" \" 15. \" \" 16. \" \" 17. \" \" 18. \"\n[19] \" 19. \" \" 20. \"\n\n\n　前後の空白が気になる。この場合、html_text2()を使うと無駄な空白や改行、タブなどを除去することができる。\n\noc_html |&gt; \n  html_elements(\"div.rank\") |&gt; \n  html_text2()\n\n [1] \"1.\"  \"2.\"  \"3.\"  \"4.\"  \"5.\"  \"6.\"  \"7.\"  \"8.\"  \"9.\"  \"10.\" \"11.\" \"12.\"\n[13] \"13.\" \"14.\" \"15.\" \"16.\" \"17.\" \"18.\" \"19.\" \"20.\"\n\n\n　これでランキングの抽出ができた。まだ数字の後に付いている点が気になるが、こちらは後ほどまとめて除去しよう。つづいて、ティアーの画像URLを取得してみよう。既にクラスがdesktop-game-displayである&lt;div&gt;タグに限定されたoc_htmlからクラス名がtierの&lt;div&gt;を選択し、さらにそこから&lt;img&gt;タグを抽出し、画像のURLが指定されている\"src\"属性を抽出してみよう。\n\noc_html |&gt; \n  html_elements(\"div.tier img\") |&gt; \n  html_attr(\"src\")\n\n [1] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n [2] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n [3] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n [4] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n [5] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n [6] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n [7] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n [8] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n [9] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n[10] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n[11] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n[12] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n[13] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n[14] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n[15] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n[16] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n[17] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n[18] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n[19] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n[20] \"//img.opencritic.com/mighty-man/mighty-man.png\"\n\n\n　20個の画像が抽出された。URLなのに\"//\"で始まるのが不自然だと感じるかも知れないが、\"//\"で始まるURLは\"https://\"やhttp://に勝手に認識されるので問題ない。あとはこれらの作業を他のセル（ゲーム名、スコアなど）にも適用し、一つの表としてまとめるだけだ。oc_dfという名のオブジェクトとして格納しよう。\n\noc_df &lt;- tibble(Rank      = html_elements(oc_html, \"div.rank\") |&gt; \n                  html_text2(),\n                Tier      = html_elements(oc_html, \"div.tier img\") |&gt; \n                  html_attr(\"src\"),\n                Score     = html_elements(oc_html, \"div.score\") |&gt; \n                  html_text2(),\n                Name      = html_elements(oc_html, \"div.game-name\") |&gt;\n                  html_text2(),\n                Platforms = html_elements(oc_html, \"div.platforms\") |&gt;\n                  html_text2(),\n                Date      = html_elements(oc_html, \"div.first-release-date\") |&gt;\n                  html_text2())\n\noc_df\n\n# A tibble: 20 × 6\n   Rank  Tier                                        Score Name  Platforms Date \n   &lt;chr&gt; &lt;chr&gt;                                       &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;     &lt;chr&gt;\n 1 1.    //img.opencritic.com/mighty-man/mighty-man… 93    Fina… PC, PS5,… Dec 7\n 2 2.    //img.opencritic.com/mighty-man/mighty-man… 92    Forz… PC, XB1,… Nov 9\n 3 3.    //img.opencritic.com/mighty-man/mighty-man… 89    Supe… Switch    Feb …\n 4 4.    //img.opencritic.com/mighty-man/mighty-man… 89    Bust… PC, Swit… Jul …\n 5 5.    //img.opencritic.com/mighty-man/mighty-man… 89    Ratc… PS5       Jun …\n 6 6.    //img.opencritic.com/mighty-man/mighty-man… 89    Swarm Oculus    Apr 8\n 7 7.    //img.opencritic.com/mighty-man/mighty-man… 89    Psyc… PC, XB1,… Aug …\n 8 8.    //img.opencritic.com/mighty-man/mighty-man… 88    Deat… XB1, PC,… Jul …\n 9 9.    //img.opencritic.com/mighty-man/mighty-man… 88    Over… Switch, … Jun 2\n10 10.   //img.opencritic.com/mighty-man/mighty-man… 88    It T… PC, XB1,… Mar …\n11 11.   //img.opencritic.com/mighty-man/mighty-man… 88    Deat… PS5, PC   Sep …\n12 12.   //img.opencritic.com/mighty-man/mighty-man… 88    Mons… Switch    Mar …\n13 13.   //img.opencritic.com/mighty-man/mighty-man… 88    Chic… PS5, PS4… Jun …\n14 14.   //img.opencritic.com/mighty-man/mighty-man… 88    Movi… PC, PS4,… Feb …\n15 15.   //img.opencritic.com/mighty-man/mighty-man… 87    Metr… Switch    Oct 8\n16 16.   //img.opencritic.com/mighty-man/mighty-man… 87    Mass… PS4, PC,… May …\n17 17.   //img.opencritic.com/mighty-man/mighty-man… 87    Tale… PS5, PC,… Sep …\n18 18.   //img.opencritic.com/mighty-man/mighty-man… 87    Vamp… PC        Dec …\n19 19.   //img.opencritic.com/mighty-man/mighty-man… 87    Quake XBXS, PS… Aug …\n20 20.   //img.opencritic.com/mighty-man/mighty-man… 87    The … PS5       Feb 5\n\n\n　後はこの表の細かいところを修正しよう。たとえば、Rank列から\".\"を除去し、numeric型に変換したり、Date列をdate型に変換する。\n\noc_df &lt;- oc_df |&gt; \n1  mutate(Rank  = str_remove(Rank, \"\\\\.\"),\n2         Rank  = as.numeric(Rank),\n3         Score = as.numeric(Score),\n4         Date  = paste0(Date, \", 2021\"),\n5         Date  = mdy(Date))\n\noc_df\n\n\n1\n\nRank列から.を除去する。\n\n2\n\nRank列をnumeric型に変換する。\n\n3\n\nScore列をnumeric型に変換する。\n\n4\n\nDate列の後に\", 2021\"を付ける。\n\n5\n\nDate列がmonth-day-yearで記述されていることを伝え、date型に変換する。\n\n\n\n\n# A tibble: 20 × 6\n    Rank Tier                                   Score Name  Platforms Date      \n   &lt;dbl&gt; &lt;chr&gt;                                  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;     &lt;date&gt;    \n 1     1 //img.opencritic.com/mighty-man/might…    93 Fina… PC, PS5,… 2021-12-07\n 2     2 //img.opencritic.com/mighty-man/might…    92 Forz… PC, XB1,… 2021-11-09\n 3     3 //img.opencritic.com/mighty-man/might…    89 Supe… Switch    2021-02-12\n 4     4 //img.opencritic.com/mighty-man/might…    89 Bust… PC, Swit… 2021-07-30\n 5     5 //img.opencritic.com/mighty-man/might…    89 Ratc… PS5       2021-06-11\n 6     6 //img.opencritic.com/mighty-man/might…    89 Swarm Oculus    2021-04-08\n 7     7 //img.opencritic.com/mighty-man/might…    89 Psyc… PC, XB1,… 2021-08-25\n 8     8 //img.opencritic.com/mighty-man/might…    88 Deat… XB1, PC,… 2021-07-20\n 9     9 //img.opencritic.com/mighty-man/might…    88 Over… Switch, … 2021-06-02\n10    10 //img.opencritic.com/mighty-man/might…    88 It T… PC, XB1,… 2021-03-26\n11    11 //img.opencritic.com/mighty-man/might…    88 Deat… PS5, PC   2021-09-14\n12    12 //img.opencritic.com/mighty-man/might…    88 Mons… Switch    2021-03-26\n13    13 //img.opencritic.com/mighty-man/might…    88 Chic… PS5, PS4… 2021-06-10\n14    14 //img.opencritic.com/mighty-man/might…    88 Movi… PC, PS4,… 2021-02-25\n15    15 //img.opencritic.com/mighty-man/might…    87 Metr… Switch    2021-10-08\n16    16 //img.opencritic.com/mighty-man/might…    87 Mass… PS4, PC,… 2021-05-14\n17    17 //img.opencritic.com/mighty-man/might…    87 Tale… PS5, PC,… 2021-09-10\n18    18 //img.opencritic.com/mighty-man/might…    87 Vamp… PC        2021-12-17\n19    19 //img.opencritic.com/mighty-man/might…    87 Quake XBXS, PS… 2021-08-19\n20    20 //img.opencritic.com/mighty-man/might…    87 The … PS5       2021-02-05\n\n\n　最後にoc_dfを{gt}パッケージを使って表として出力してみよう。\n\noc_df |&gt; \n  gt() |&gt; \n  gt_img_rows(Tier) |&gt; \n  cols_label(\"Date\" = \"First release date\")\n\n\n\n\n  \n    \n    \n      Rank\n      Tier\n      Score\n      Name\n      Platforms\n      First release date\n    \n  \n  \n    1\n\n93\nFinal Fantasy XIV: Endwalker\nPC, PS5, PS4\n2021-12-07\n    2\n\n92\nForza Horizon 5\nPC, XB1, XBXS\n2021-11-09\n    3\n\n89\nSuper Mario 3D World + Bowser's Fury\nSwitch\n2021-02-12\n    4\n\n89\nBustafellows\nPC, Switch\n2021-07-30\n    5\n\n89\nRatchet & Clank: Rift Apart\nPS5\n2021-06-11\n    6\n\n89\nSwarm\nOculus\n2021-04-08\n    7\n\n89\nPsychonauts 2\nPC, XB1, XBXS, PS4\n2021-08-25\n    8\n\n88\nDeath's Door\nXB1, PC, XBXS\n2021-07-20\n    9\n\n88\nOverboard!\nSwitch, PC\n2021-06-02\n    10\n\n88\nIt Takes Two\nPC, XB1, PS5, XBXS, PS4\n2021-03-26\n    11\n\n88\nDeathloop\nPS5, PC\n2021-09-14\n    12\n\n88\nMonster Hunter Rise\nSwitch\n2021-03-26\n    13\n\n88\nChicory: A Colorful Tale\nPS5, PS4, PC\n2021-06-10\n    14\n\n88\nMoving Out: Movers in Paradise\nPC, PS4, XB1, Switch\n2021-02-25\n    15\n\n87\nMetroid Dread\nSwitch\n2021-10-08\n    16\n\n87\nMass Effect Legendary Edition\nPS4, PC, XBXS, PS5\n2021-05-14\n    17\n\n87\nTales of Arise\nPS5, PC, XBXS, XB1, PS4\n2021-09-10\n    18\n\n87\nVampire Survivors\nPC\n2021-12-17\n    19\n\n87\nQuake\nXBXS, PS5, XB1, PS4, Switch, PC\n2021-08-19\n    20\n\n87\nThe Nioh Collection\nPS5\n2021-02-05"
  },
  {
    "objectID": "scraping.html#スクレイピングの注意事項",
    "href": "scraping.html#スクレイピングの注意事項",
    "title": "30  スクレイピング",
    "section": "30.4 スクレイピングの注意事項",
    "text": "30.4 スクレイピングの注意事項\n　スクレイピングの対象は自分が作成したページでなく、自分以外の個人（有志）、集団、機関などが作成したページであろう。そしてそのページ内にはその個人、集団、機関などが収集、作成、整理した資料とデータが含まれる。したがって、スクレイピングをする前に著作権を気にする必要があろう。もし、利用規約（「Terms and conditions」や「Terms of service」など）がある場合は予め読んでおこう。スクレイピングは禁止されている可能性もある。非商業的利用（教育・研究を含む）や個人利用の場合、利用が許されるケースもあるが、筆者らは弁護士でもなく、著作権に関する知識が皆無であるため、断言はできない。また、これらの法律は国によっても異なる。スクレイピングして良いかどうかが不安な場合は、そのページを作成した個人、集団、機関などに問い合わせてみるのが確実だろう。\n　また、サイトによっては「ここは取得しちゃダメ」というのがある可能性もある。全てのサイトに置いてあるわけではないが、多くのサイトにはrobots.txtというファイルが置かれている10。これはウェブ・クローラー（web crawler）と呼ばれる一種のボット（Bot）向けに書かれたものであるが、スクレイピング時にも参考になろう。たとえば、OpenCriticの場合、https://opencritic.com/robots.txtにrobots.txtがある。以下はその中身だ。\n\n\nhttps://opencritic.com/robots.txt\n\nUser-agent: *\nSitemap: https://opencritic.com/sitemap.xml\nDisallow: /profile\n\n　User-agent: *は「以下の内容はすべてのクローラー（*）に該当する」ことを意味し、Disallow: /profileは「profileページは取得してはいけない」ことを意味する（もし/profile/になっている場合は、profileとその以下のフォルダー全体を意味する）。ちなみにDisallow: /となっている場合は、サイト全体がクローリング禁止を意味する。Disallowとは逆のAllowもあり、AllowがDisallowに優先する。また、Sitemapは当該サイトのサイトマップ（ページ等の全体構造が記述されているファイル）のURLだ。以下のrobots.txtはGoogleのもの（の一部）であり、ボットの種類に応じて許可範囲が異なるケースもある。\n\n\nhttps://www.google.com/robots.txt\n\n# AdsBot\nUser-agent: AdsBot-Google\nDisallow: /maps/api/js/\nAllow: /maps/api/js\nDisallow: /maps/api/place/js/\nDisallow: /maps/api/staticmap\nDisallow: /maps/api/streetview\n\n# Crawlers of certain social media sites are allowed to access page markup when google.com/imgres* links are shared. To learn more, please contact images-robots-allowlist@google.com.\nUser-agent: Twitterbot\nAllow: /imgres\nAllow: /search\nDisallow: /groups\nDisallow: /hosted/images/\nDisallow: /m/\n\nUser-agent: facebookexternalhit\nAllow: /imgres\nAllow: /search\nDisallow: /groups\nDisallow: /hosted/images/\nDisallow: /m/\n\nSitemap: https://www.google.com/sitemap.xml\n\n　robots.txtに関するネット記事も多いが、筆者（宋）はGoogleのページをおすすめする。\n　そしてもう一つ重要なのは、サーバーに負担をかけないことだ。今回の例は1ページのみ、Jリーグの順位表の場合は3ページのスクレイピングであったため、サーバーへの負担はほぼないと考えられる。しかし、数百〜数千のページをスクレイピングをするケースも珍しくもない。むしろ、スクレイピングの醍醐味はそこにあろう。しかし、パソコンの動きは我々の想像をはるかに凌駕する。場合によっては1秒に数回、当該サーバーへのアクセスを試みるかも知れない。集団で特定のページをリフレッシュし続けると、サーバーへの負担が増加し、結果としてサーバーが止まることは聞いたことがあるかも知れない。何も考えずに大量のスクレイピングをすることは、そのサーバーに対し、分散型サービス妨害攻撃（DDoS攻撃）を行っていることと同じだ。したがって、ループ時にSys.sleep()などを使って（時間的）間隔を空けたり、{polite}パッケージを使ってサーバーへの負担を緩和したりすることも考える必要がある。また、サーバーごとに1日に許容されるトラフィックにも限度があるため、大量のデータであれば、数日に分けてスクレイピングすることも一つの方法だろう。\n　スクレイピングをする時にはそのデータを作成した人や機関に敬意を払う必要があろう。"
  },
  {
    "objectID": "dataset.html",
    "href": "dataset.html",
    "title": "データセット",
    "section": "",
    "text": "ファイル名\n      ダウンロード\n    \n  \n  \n    \n      第7章：データの入出力\n    \n    FIFA_Women.csv\n\nDownload\n    Vote_ShiftJIS.csv\n\nDownload\n    Vote.csv\n\nDownload\n    Soccer.xlsx\n\nDownload\n    Soccer.dta\n\nDownload\n    Scores.RData\n\nDownload\n    \n      第10章：データ構造\n    \n    Vote.csv\n\nDownload\n    FIFA_Women.csv\n\nDownload\n    FIFA_Men.csv\n\nDownload\n    \n      第11章：Rプログラミングの基礎\n    \n    FIFA_Men.csv\n\nDownload\n    \n      第13章：データハンドリング [抽出]\n    \n    Ramen.csv\n\nDownload\n    \n      第14章：データハンドリング [拡張]\n    \n    Ramen.csv\n\nDownload\n    Ramen2.csv\n\nDownload\n    \n      第15章：データハンドリング [factor型]\n    \n    Ramen.csv\n\nDownload\n    COVID19.csv\n\nDownload\n    \n      第16章：整然データ構造\n    \n    Population2015.csv\n\nDownload\n    COVID19_JK.csv\n\nDownload\n    \n      第17章：文字列の処理\n    \n    Offices.csv\n\nDownload\n    \n      第19章：可視化 [基礎]\n    \n    Countries.csv\n\nDownload\n    COVID19_Worldwide.csv\n\nDownload\n    \n      第20章：可視化 [応用]\n    \n    Countries.csv\n\nDownload\n    COVID19_Worldwide.csv\n\nDownload\n    \n      第21章：可視化 [発展]\n    \n    Countries.csv\n\nDownload\n    COVID19_Worldwide.csv\n\nDownload\n    Japan_Density.csv\n\nDownload\n    Osaka_Student.csv\n\nDownload\n    Bumpchart.csv\n\nDownload\n    Vote_20_21.csv\n\nDownload\n    \n      第22章：表の作成\n    \n    countries_desc1.csv\n\nDownload\n    countries_desc2.csv\n\nDownload\n    countries_desc3.csv\n\nDownload\n    countries_ppp.csv\n\nDownload\n    package_download.csv\n\nDownload\n    \n      第27章：反復処理\n    \n    Countries.csv\n\nDownload"
  },
  {
    "objectID": "filesystem.html#ファイル名",
    "href": "filesystem.html#ファイル名",
    "title": "ファイルシステム",
    "section": "ファイル名",
    "text": "ファイル名\n　まず、コンピュータ上のファイル名について説明する。\n\nファイル名拡張子\n　コンピュータの中には、様々な種類のファイルが含まれている。例えば、多くの人は Microsoft Word や Microsoft Excel のファイルを作ったことがあるだろう。Word や Excel で作ったファイルは、基本的にはそれぞれ専用のソフトウェア（アプリ）で開く必要がある。Word で作ったファイルをExcel で開くことや、Excel で作ったファイルを Wordで開くことなどはできない。\n　ユーザが特に意識しなくても、Word で作ったファイルを [ダブル] クリックすれば Word が起動してそのファイルを開くし、Excel で作ったファイルを [ダブル] クリックすれば Excel が起動して開きたいファイルが開かれる。仮に、Word のファイルとExcelファイルのファイル名が同じ kadai01 だとしても、パソコンは正しいアプリを選んでくれる。パソコンがファイルを区別し、正しいアプリを起動してくれるのはなぜだろうか。\n　実は、各アプリで作ったファイル名は、自分で名前を付けた部分（上の例では kadai01）の後に続きがある。 Word で作ったファイルには自動的に “.docx” が付けられ、Excel の場合には “.xlsx” が同様に付けられている。 したがって、自分では両方のファイルにまったく同じ kadai01 という名前を付けたつもりでも、実際には、kadai01.docx と kadai01.xlsx という別のファイル名が付いている。 この仕組みにより、パソコンは正しいアプリを選択することができる。ファイル名の末尾に .docx があるファイルがクリックされれば Word を、.xlsx があるファイルが選択されれば Excel を開くのである。\n　ファイル名の末尾にあってファイルの種類を区別する部分のことをファイル名拡張子 (filename extension) と呼ぶ。上の例からわかるとおり、ファイル名拡張子はファイルの種類を区別する重要情報である。プログラミングをしないパソコンユーザにとっては、ファイルの種類の違いを気にせずにパソコンを使えたほうが便利なので、パソコン購入時の初期設定ではファイル名拡張子が非表示になっている場合がある。しかし、プログラミングをする場合（つまり、この本を読んでいるあなた）は、ファイル名拡張子が見えないと困る。\n　例えば、Rは様々な形式で保存されたデータファイルを扱うことができるが、種類に応じてデータを読み込む方法（読み込みに使う関数）が異なる。ファイル名拡張子でファイルの種類を区別し、どの方法を使うかを決めるので、拡張子が表示されていないと不便である（MacのFinderやWindows のエクスプローラーで「ファイルの種類」を確認できるので、絶対無理というわけではないが、面倒くさい）。よく使うデータファイルのファイル名拡張子として、次のものがある。\n\n.csv\n.tsv\n.txt\n.dat\n.dta\n.RData\n.Rds\n\n　後の章で説明するが、この他にも種類がある。ファイルの種類がわからないと、様々な方法を試行錯誤することになってしまい、効率が悪い。ファイル名拡張子があればファイルの種類がわかるので、正しい方法を選んで作業を進めることができる。\n　よって、Rユーザ（あるいはその他のプログラミングをする者）にとって、ファイル名拡張子の表示は必須である。自分のパソコンでファイル名拡張子が表示されていないなら、ファイル名拡張子を表示する設定に変えよう。macOS では、Finder の 環境設定 (Preferences) で、詳細設定 (Advanced) タブを開き、「すべてのファイル名拡張子を表示する (Show all filename extensions)」にチェックマークを付ける。 Windows では、エクスプローラー (Explorer) （注意：インターネットエクスプローラーではない。画面下部のタスクバーに表示されている、黄色のフォルダのアイコン）を開き、上部の [表示]タブをクリックする。すると、「ファイル名拡張子」という項目があるので、チェックマークを付ける。チェックマークを付けたら、Word ファイルに .docx （または .doc）、Excelファイルに .xlsx （または .xls）、PDFファイルに .pdf などが付いていることを確認しよう。\n\n\nファイル名の付け方\n　ファイル名は、ファイルの中身がわかるように付けるのが基本である。例えば、日記を書いて保存するなら、diary_20200701.txt, diary_20200702.txt のように名前を付ければ、特定の日付の日記であることがすぐにわかる。\n　また、他人にファイルを渡す必要があるときは、相手の立場になってファイル名を付けるのが望ましい。例えば、比較政治学 (Comparative Politics) の授業のレポートをWord で書く場合を考えよう。レポートを書いている本人にとっては、cp_report.docx というファイル名で中身がわかるので問題ないだろう。しかし、これをメールに添付して担当教員に提出する場合はどうだろうか。受講生が100人いて、全員がこの名前でレポートを提出してきたら、担当教員の元には同じ名前のファイルが100個届く。これでは、担当教員は困ってしまう。つまり、cp_report.docx というファイル名は、受け取る相手のことを考えていない、思いやりのないファイル名である。代わりに、学籍番号（例：123456789）を使い、cp_report_123456789.docx のようにすると、ファイル名の重複がないので、受け取る相手（私たちのことだが）は喜ぶだろう。自分が1つのファイル名を変えるのは大した手間ではないのに対し、相手が全員分のファイル名を変えるの大変な手間だということを理解しよう。\n　加えて、ファイル名の付け方には形式的なルールがある。ファイル名は、英数字と特定の記号（_ [「アンダースコア」、「アンスコ」、「アンダーバー」などと読む] と - [ハイフン]）のみで付けるべきだ。 ファイル名に日本語（または韓国語、中国語などのマルチバイト文字）を使うのは愚かなのでやめよう。日本語のファイル名でも問題ない場合が多いのは確かだが、問題がある場合もあるので使用を回避するのが賢い。日本語のファイル名だと、次のような問題が起こりうる。\n\n日本語（マルチバイト文字）を扱えないプログラムが停止する。\nさらに悪いと、日本語（マルチバイト文字）を扱えないプログラムが想定外の動作をする。\n文字コードの違いにより、ファイル名が文字化けする\n\n例えば、日本語のファイル名がついたファイルを Windows で圧縮 (zip) して macOS で展開すると、日本語部分が謎の暗号になるので、どのファイルを開いていいのかわからず、超絶面倒くさい。本当にやめてほしい。お願いだからやめてください。\n\n\n　日本語のなかでも特に凶悪なのが「全角スペース」である。そもそも、スペースは存在に気付きにくい。万が一末尾にスペースがあると、スペースがない場合との区別が難しい。日本語（マルチバイト文字）を扱えないプログラムでは、半角スペースなら問題ないが、全角でスペースだと問題が起きることがある。しかし、目視で半角スペースと全角スペースの区別をするのは非常に困難である。よって、スペースは使うべきではないし、全角スペースは絶対に使ってはいけない。\n　また、ファイル名の最初の1文字はアルファベットにすることが望ましい。ファイルを並べ替えるときに、数字だとややわかりにくいところがある。例えば、1.txt, 12.txt, 110.txt という3つのファイルをファイル名で並べ替えると、1.txt, 110.txt, 12.txt という順番になる。多くの場合、これはユーザが期待する順番ではない。中身がわかるようにという大原則にしたがえば、アルファベットから始まるファイル名が自然に選ばれるだろう。\n　ファイル名の付け方をまとめると、次のようになる。\n\nファイル名は、英数字 (A-Z, a-z, 0-9) と_, - のみで付ける。\n\nただし、ハイフンがあると動かないプログラムもあるので、できればハイフンも避ける。\n\nファイル名の1文字目はアルファベットにする（数字を1文字目にすることを避ける）。\n.（ドット; ピリオド）は使わない（ファイル名拡張子との混同を避けるため）。\nファイル名にスペースを使わない。全角スペースはもちろん、半角スペースも避けるべき。 -　例えば、my diary.txt というファイル名の代わりに、my_diary.txt または myDiary.txt、MyDiary.txt などのファイル名を使う。\n\nちなみに、my_diary.txt のように単語をアンスコで繋ぐ書き方をスネークケース (snake case) [_ が地を這うヘビである]、myDiary.txt のように単語の1文字目を大文字にして前の単語と区別する書き方をキャメルケース (camel case) [大文字部分がラクダのコブである] と呼ぶ。\n\n\n　ただし、次のような例外もある。\n\n隠しファイル（Windows 以外では通常は非表示のファイル）の1文字目は . である。\n\nRユーザが作る隠しファイルとして、.Rprofile と .Renviron がある。\n\n自分で作るファイル以外には、_ や # などの記号からファイル名が始まるものもある。\n\n　次の節で説明するフォルダ（ディレクトリ）の名前を付ける際も、基本的にはファイル名と同じルールに従うことが望ましい。"
  },
  {
    "objectID": "filesystem.html#ファイルシステムとパス",
    "href": "filesystem.html#ファイルシステムとパス",
    "title": "ファイルシステム",
    "section": "ファイルシステムとパス",
    "text": "ファイルシステムとパス\n　次に、ファイルシステムについて解説する。私たちが使用しているコンピュータには、数千〜数万（あるいはそれ以上）のファイルが含まれている。これらのファイルは基本的には1つのドライブ (ハードディスクドライブ [Hard Disk Drive; HDD] またはソリッドステートドライブ [Solid State Drive; SSD]） に保存されているが、ドライブの中にあるファイルはグループ化・階層化されて保存されている。\n　図 1 はファイルシステムの例を示している。矢印の左側には、ドライブ内にあるファイル（の一部）が示されている。通常、これらのファイルは矢印の右側に示されているように、階層化されている。\n\n\n\n図 1: ファイルシステムの例\n\n\n　図 1 の左側にある Diary_YYYYMMDD.txt がYYYY年MM月DD日の日記を保存したテキストファイルだとしよう1。 3年間毎日日記を書くと、それだけでファイル数は1000個以上になる。また、Analysis_blahblah.R はRスクリプトである2。Rスクリプトファイルも複数ある。さらに、上の図には表示されていないが、自分で作ったファイル以外に、OSやソフトウェア（アプリ）を構成するファイルもドライブ内に保存されているだろう。これらのファイルが整理されずに1つの場所にまとめて置いてあるとしよう（上の図の左側の状態）。そうすると、特定のファイルを開いたり、それぞれのファイルがどのような目的で存在するのかを把握したりするのに少なからぬ労を要する。\n　単に面倒なだけならいい（私たちは面倒なことが大嫌いなので良くないと考える）が、ファイルの置き場が1つだけだと解決できない問題がある。それは、ファイル名の重複が許されないということだ。世の中には、特定の目的のために使われる「お決まりのファイル名」というものがある。例えば、GitHubにレポジトリを追加するときは、そのレポジトリについて説明する README.md というファイルを作ることになっている。しかし、名前が同じだとファイルが区別できないので、同じ場所にまったく同じ名前のファイルを2つ置くことはできない。したがって、ドライブ内にファイル置き場が1つしかないとなると、1つのパソコンで作れる README.md は1つだけということになってしまい、困ってしまう。\n　そこで、多くのOSではファイルをグループ化して管理するという方法が採用されている。このグループのことを「フォルダ (folder)」または「ディレクトリ (directory)」と呼ぶ3。\n　上の図の右側は、ファイルをフォルダに分けた様子を表している。 日記のテキストファイルに注目すると、まず、“Diary” という名前のフォルダがあり、Diary フォルダの中に年ごとのフォルダ “2018”, “2019”, “2020” というフォルダがある。それぞれの年のフォルダの中には、“January”, “February”, \\(\\dots\\), “December” という月ごとのフォルダがある。そして、それぞれの月のフォルダの中に、日付がファイル名になったテキストファイルd_01.txt, d_02.txt, \\(\\dots\\) が保存されている。この例からわかるように、フォルダの中にフォルダを作り、そのフォルダの中にフォルダを作り \\(\\cdots\\) ということができるので、フォルダを入れ子にした階層構造を利用してファイルを管理することができる。\n　ファイルを階層化して管理する場合、フォルダの構造と場所を把握することが必要になる。そのために使われるのがパス (path) である。パスは、コンピュータ内の住所のようなものだと考えればよい。例えば、“Diary” フォルダ内の “2018” フォルダ内の “January” フォルダ内の “d_01.txt” というファイルのパスは、Diary/2018/January/d_01.txt である。この例からわかるように、パスにはフォルダ名やファイル名がそのまま使われる。そして、フォルダの「中」であることは、/ （スラッシュ）記号によって表される。例えば、Diary/ の部分が、Diary フォルダの中であることを示す。ただし、Windows では / の代わりに \\（バックスラッシュ）または ￥（円記号; 日本語環境の場合）が使われる4。 Diary/2018/January/d_01.txt と Diary/2018/February/d_01.txt は、ファイル名だけを見れば同じ d_01.txt だが、パスが異なるので異なるファイルとして認識され、1つのドライブ内に共存することができる。\n　しかし、上に書いたパスは、“Diary” フォルダがどこにあるかを指定していないので完全ではない。パソコンがファイルの場所を正しく把握するには、“Diary” フォルダの置き場所がどこかという情報も必要である。\n　パソコン内でパスの起点になる場所は、OSによって異なる。Linux やmacOSでは、パスの起点となる最上位フォルダは / であり、多くのWindows機では C:\\ （Cドライブと呼ばれる）である5。また、多くのOSでは、ドライブ内に「ホーム (HOME)」と呼ばれる特別なフォルダがあらかじめ用意されており、通常はホームフォルダの中に自分で作ったファイルを保存する。ただし、ホームフォルダの名前は “HOME” ではないので注意が必要である。例えば、macOSではユーザ名がホームフォルダの名前である。例えば、ユーザ名が yukiなら /Users/yuki/ が、ユーザ名が jaehyunsong なら /Users/jaehyunsong/ がホームフォルダのパスである。パスの先頭に / がついており、最上位フォルダの中の “Users” フォルダの中にユーザ名でホームフォルダが作られれている。\n　ホームフォルダの中に Diary フォルダがあるとすると、2018年1月1日の日記までのパスは、 /Users/jaehyunsong/Diary/2018/January/d_01.txt である。このように、ドライブ内の起点から書いた完全なパスを 絶対パス (absolute path) または フルパス (full path) と呼ぶ。絶対パスを使えば、コンピュータ内の特定のファイルを一意に示すことができる。 絶対パスにホームディレクトリが含まれている場合には、ホームディレクトリまでのパスを省略して ${HOME}/ または ~/ と書くことができる。よって、上の絶対パスは、~/Diary/2018/January/d_01.txt と書くことができる。この書き方を使えば、パスを書き換えることなく共同研究者とファイルを共有することが可能になる（もちろん、ホームフォルダ以下の構造を揃える必要がある）。\n　自分が作業・操作の対象としているフォルダは、作業フォルダ (working directory; current directory) と呼ばれる6。絶対パスの代わりに、作業フォルダから見た相対パス (relative path)を使うこともできる。例えば、現在の作業フォルダが ~/Diary/2018/ だとすると、2018年1月1日の日記への相対パスは、Januaray/d_01.txt と書ける。 作業フォルダを指定していることを明示したい場合（プログラムを実行する場合にはこれが必要なことがある）には、 ./Januaray/d_01.txt と書く。つまり、./ が作業フォルダを示す。 また、作業フォルダよりも階層が1つ上のフォルダ（親 [parent] フォルダと呼ぶ）には、../ でアクセスでききる。例えば、、現在の作業フォルダが ~/Diary/2018/ だとすると、../ は ~/Diary/ なので、 2020年1月1日の日記への相対パスは　../2020/Januaray/d_01.txt と書くことができる。\n　相対パスの利点は、\n\n絶対パスより短い\n同じ構造を再利用できる\n\nということである。1は自明だろう。2は、例えば日記の一覧を作るためのプログラムを書き、それを「年」を表すフォルダに保存すれば、1つひとつの日記に毎年同じ相対パスでアクセスできる（ただし、2月29日は除く）ので、毎年同じプログラムを利用できて便利である。絶対パスを使うと、「年」の部分を毎年書き換えなければいけない。\n　絶対パスと相対パスは、目的に応じて使い分けることが必要である。"
  },
  {
    "objectID": "tips.html#true-と-false",
    "href": "tips.html#true-と-false",
    "title": "R Tips",
    "section": "TRUE と FALSE",
    "text": "TRUE と FALSE\nR で真を表す TRUE と 偽を表す FALSE は頻繁に利用する。\nたとえば、行列を作るときに、byrow に TRUE を与えるか、FALSE を与えるかで、結果が変わる。\n\nmatrix(1:9, nrow = 3, byrow = FALSE)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\nmatrix(1:9, nrow = 3, byrow = TRUE)\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n\nTRUE と FALSE は、それぞれ省略して T と F をも書ける。 頻繁に使うので、このような書き方は一見すると便利である。\n\nmatrix(1:9, nrow = 3, byrow = F)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\nmatrix(1:9, nrow = 3, byrow = T)\n\n     [,1] [,2] [,3]\n[1,]    1    2    3\n[2,]    4    5    6\n[3,]    7    8    9\n\n\nしかし、省略形を使うべきではない。省略形を使うと、次のような問題が起こりうる。\n\nT &lt;- FALSE\nmatrix(1:9, nrow = 3, byrow = T)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\nこの例では、T に FALSE を代入した結果、T が偽になっており、byrow = T が bryow = FALSE として処理されている。\n上の書き方では、T が TRUE を意図しているのか、それとも FALSE を意図しているのか、見分けるのが困難である。\nタイプする文字数が少し増えるが、コードの可読性と保守性が高めるために、TRUE と FALSE は常に完全にスペルすべきだ。"
  },
  {
    "objectID": "session.html",
    "href": "session.html",
    "title": "本書の執筆環境",
    "section": "",
    "text": "セッション情報\n\nsessionInfo()\n\nR version 4.3.0 (2023-04-21)\nPlatform: x86_64-apple-darwin20 (64-bit)\nRunning under: macOS Ventura 13.4.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.3-x86_64/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Asia/Tokyo\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.31     fastmap_1.1.1     xfun_0.39         knitr_1.43       \n [5] htmltools_0.5.5   rmarkdown_2.22    cli_3.6.1         textshaping_0.3.6\n [9] systemfonts_1.0.4 compiler_4.3.0    rstudioapi_0.14   tools_4.3.0      \n[13] ragg_1.2.5        evaluate_0.21     yaml_2.3.7        rlang_1.1.1      \n[17] jsonlite_1.8.5    htmlwidgets_1.6.2\n\n\nインストール済みパッケージ\n\npacman::p_load(tidyverse)\ninstalled.packages() %&gt;%\n  as_tibble() %&gt;%\n  select(Package, Version, Built) %&gt;%\n  print(n = Inf)\n\n# A tibble: 454 × 3\n    Package            Version    Built\n    &lt;chr&gt;              &lt;chr&gt;      &lt;chr&gt;\n  1 abind              1.4-5      4.3.0\n  2 AER                1.2-10     4.3.0\n  3 anytime            0.3.9      4.3.0\n  4 arm                1.13-1     4.3.0\n  5 AsioHeaders        1.22.1-2   4.3.0\n  6 askpass            1.1        4.3.0\n  7 assertthat         0.2.1      4.3.0\n  8 attachment         0.4.0      4.3.0\n  9 attempt            0.3.1      4.3.0\n 10 backports          1.4.1      4.3.0\n 11 BalanceR           0.8.0      4.3.0\n 12 BART               2.9.4      4.3.0\n 13 base               4.3.0      4.3.0\n 14 base64enc          0.1-3      4.3.0\n 15 bayestestR         0.13.1     4.3.0\n 16 BH                 1.81.0-1   4.3.0\n 17 bibtex             0.5.1      4.3.0\n 18 bigD               0.2.0      4.3.0\n 19 bit                4.0.5      4.3.0\n 20 bit64              4.0.5      4.3.0\n 21 bitops             1.0-7      4.3.0\n 22 blob               1.2.4      4.3.0\n 23 blogdown           1.18       4.3.0\n 24 bookdown           0.34       4.3.0\n 25 boot               1.3-28.1   4.3.0\n 26 brew               1.0-8      4.3.0\n 27 brio               1.1.3      4.3.0\n 28 broom              1.0.5      4.3.0\n 29 bsicons            0.1        4.3.0\n 30 bslib              0.5.0      4.3.0\n 31 cachem             1.0.8      4.3.0\n 32 callr              3.7.3      4.3.0\n 33 car                3.1-2      4.3.0\n 34 carData            3.0-5      4.3.0\n 35 cellranger         1.1.0      4.3.0\n 36 checkmate          2.2.0      4.3.0\n 37 chromote           0.1.1.9001 4.3.0\n 38 cjoint             2.1.0      4.3.0\n 39 class              7.3-22     4.3.0\n 40 classInt           0.4-9      4.3.0\n 41 cli                3.6.1      4.3.0\n 42 clipr              0.8.0      4.3.0\n 43 cluster            2.1.4      4.3.0\n 44 coda               0.19-4     4.3.0\n 45 codetools          0.2-19     4.3.0\n 46 collections        0.3.7      4.3.0\n 47 colorspace         2.1-0      4.3.0\n 48 colourpicker       1.2.0      4.3.0\n 49 combinat           0.0-8      4.3.0\n 50 commonmark         1.9.0      4.3.0\n 51 compiler           4.3.0      4.3.0\n 52 conf.design        2.0.0      4.3.0\n 53 config             0.3.1      4.3.0\n 54 conflicted         1.2.0      4.3.0\n 55 corpcor            1.6.10     4.3.0\n 56 corrplot           0.92       4.3.0\n 57 countrycode        1.5.0      4.3.0\n 58 cowplot            1.1.1      4.3.0\n 59 cpp11              0.4.3      4.3.0\n 60 cranlogs           2.1.1      4.3.0\n 61 crayon             1.5.2      4.3.0\n 62 credentials        1.3.2      4.3.0\n 63 cregg              0.4.0      4.3.0\n 64 crosstalk          1.2.0      4.3.0\n 65 crul               1.4.0      4.3.0\n 66 cshapes            2.0        4.3.0\n 67 curl               5.0.1      4.3.0\n 68 cyclocomp          1.1.0      4.3.0\n 69 dagitty            0.3-1      4.3.0\n 70 data.table         1.14.8     4.3.0\n 71 data.tree          1.0.0      4.3.0\n 72 DataCombine        0.2.21     4.3.0\n 73 datasets           4.3.0      4.3.0\n 74 datawizard         0.8.0      4.3.0\n 75 DBI                1.1.3      4.3.0\n 76 dbplyr             2.3.2      4.3.0\n 77 dcurver            0.9.2      4.3.0\n 78 democracyData      0.5.0      4.3.0\n 79 dendextend         1.17.1     4.3.0\n 80 Deriv              4.1.3      4.3.0\n 81 desc               1.4.2      4.3.0\n 82 DescTools          0.99.49    4.3.0\n 83 devtools           2.4.5      4.3.0\n 84 diffobj            0.3.5      4.3.0\n 85 digest             0.6.31     4.3.0\n 86 DoE.base           1.2-2      4.3.0\n 87 downlit            0.4.2      4.3.0\n 88 dplyr              1.1.2      4.3.0\n 89 DT                 0.28       4.3.0\n 90 dtplyr             1.3.1      4.3.0\n 91 e1071              1.7-13     4.3.0\n 92 ellipsis           0.3.2      4.3.0\n 93 estimatr           1.0.0      4.3.0\n 94 evaluate           0.21       4.3.0\n 95 Exact              3.2        4.3.0\n 96 expm               0.999-7    4.3.0\n 97 expss              0.11.4     4.3.0\n 98 extrafont          0.19       4.3.0\n 99 extrafontdb        1.0        4.3.0\n100 fansi              1.0.4      4.3.0\n101 farver             2.1.1      4.3.0\n102 fastDummies        1.6.3      4.3.0\n103 fastmap            1.1.1      4.3.0\n104 fontawesome        0.5.1      4.3.0\n105 fontBitstreamVera  0.1.1      4.3.0\n106 fontLiberation     0.1.0      4.3.0\n107 fontquiver         0.2.1      4.3.0\n108 forcats            1.0.0      4.3.0\n109 foreign            0.8-84     4.3.0\n110 formatR            1.14       4.3.0\n111 Formula            1.2-5      4.3.0\n112 fs                 1.6.2      4.3.0\n113 furrr              0.3.1      4.3.0\n114 fusen              0.4.2      4.3.0\n115 future             1.32.0     4.3.0\n116 fuzzyjoin          0.1.6      4.3.0\n117 gamlss.dist        6.0-5      4.3.0\n118 gapminder          1.0.0      4.3.0\n119 gargle             1.5.1      4.3.0\n120 gdtools            0.3.3      4.3.0\n121 generics           0.1.3      4.3.0\n122 geojsonsf          2.0.3      4.3.0\n123 geometries         0.2.3      4.3.0\n124 geosphere          1.5-18     4.3.0\n125 gert               1.9.2      4.3.0\n126 gfonts             0.2.0      4.3.0\n127 ggalluvial         0.12.5     4.3.0\n128 GGally             2.1.2      4.3.0\n129 ggbump             0.1.0      4.3.0\n130 ggdag              0.2.10     4.3.0\n131 ggdendro           0.1.23     4.3.0\n132 ggExtra            0.10.0     4.3.0\n133 ggfittext          0.10.0     4.3.0\n134 ggforce            0.4.1      4.3.0\n135 ggfortify          0.4.16     4.3.0\n136 gghighlight        0.4.0      4.3.0\n137 ggmosaic           0.3.3      4.3.0\n138 ggplot2            3.4.2      4.3.0\n139 ggpubr             0.6.0      4.3.0\n140 ggraph             2.1.0      4.3.0\n141 ggrepel            0.9.3      4.3.0\n142 ggridges           0.5.4      4.3.0\n143 ggsci              3.0.0      4.3.0\n144 ggsignif           0.6.4      4.3.0\n145 ggstance           0.3.6      4.3.0\n146 gh                 1.4.0      4.3.0\n147 ghibli             0.3.3      4.3.0\n148 gitcreds           0.1.2      4.3.0\n149 gld                2.6.6      4.3.0\n150 globals            0.16.2     4.3.0\n151 glue               1.6.2      4.3.0\n152 gmp                0.7-1      4.3.0\n153 golem              0.4.1      4.3.0\n154 googledrive        2.1.1      4.3.0\n155 googlePolylines    0.8.3      4.3.0\n156 googlesheets4      1.1.1      4.3.0\n157 GPArotation        2023.3-1   4.3.0\n158 graphics           4.3.0      4.3.0\n159 graphlayouts       1.0.0      4.3.0\n160 grDevices          4.3.0      4.3.0\n161 grid               4.3.0      4.3.0\n162 gridExtra          2.3        4.3.0\n163 gridlayout         0.2.0      4.3.0\n164 gridtext           0.1.5      4.3.0\n165 gt                 0.9.0      4.3.0\n166 gtable             0.3.3      4.3.0\n167 gtExtras           0.4.5      4.3.0\n168 gtools             3.9.4      4.3.0\n169 haven              2.5.2      4.3.0\n170 here               1.0.1      4.3.0\n171 highr              0.10       4.3.0\n172 hms                1.1.3      4.3.0\n173 hrbrthemes         0.8.0      4.3.0\n174 htmlTable          2.4.1      4.3.0\n175 htmltools          0.5.5      4.3.0\n176 htmlwidgets        1.6.2      4.3.0\n177 httpcode           0.3.0      4.3.0\n178 httpgd             1.3.1      4.3.0\n179 httpuv             1.6.11     4.3.0\n180 httr               1.4.6      4.3.0\n181 httr2              0.2.3      4.3.0\n182 icons              0.2.0      4.3.0\n183 ids                1.0.1      4.3.0\n184 igraph             1.5.0      4.3.0\n185 ini                0.3.1      4.3.0\n186 inline             0.3.19     4.3.0\n187 insight            0.19.2     4.3.0\n188 isoband            0.2.7      4.3.0\n189 jpeg               0.1-10     4.3.0\n190 jpmesh             2.1.0      4.3.0\n191 jpndistrict        0.3.9.9000 4.3.0\n192 jquerylib          0.1.4      4.3.0\n193 jsonify            1.2.2      4.3.0\n194 jsonlite           1.8.5      4.3.0\n195 juicyjuice         0.1.0      4.3.0\n196 kableExtra         1.3.4      4.3.0\n197 KernSmooth         2.23-21    4.3.0\n198 knitr              1.43       4.3.0\n199 labeling           0.4.2      4.3.0\n200 languageserver     0.3.15     4.3.0\n201 later              1.3.1      4.3.0\n202 latex2exp          0.9.6      4.3.0\n203 lattice            0.21-8     4.3.0\n204 lazyeval           0.2.2      4.3.0\n205 leaflet            2.1.2      4.3.0\n206 leaflet.providers  1.9.0      4.3.0\n207 learnr             0.11.3     4.3.0\n208 lifecycle          1.0.3      4.3.0\n209 lintr              3.0.2      4.3.0\n210 list               9.2.4      4.3.0\n211 listenv            0.9.0      4.3.0\n212 lme4               1.1-33     4.3.0\n213 lmom               2.9        4.3.0\n214 lmtest             0.9-40     4.3.0\n215 lobstr             1.1.2      4.3.0\n216 loo                2.6.0      4.3.0\n217 lpdensity          2.4        4.3.0\n218 lubridate          1.9.2      4.3.0\n219 maditr             0.8.3      4.3.0\n220 magic              1.6-1      4.3.0\n221 magick             2.7.4      4.3.0\n222 magrittr           2.0.3      4.3.0\n223 makedummies        1.2.1      4.3.0\n224 marginaleffects    0.13.0     4.3.0\n225 margins            0.3.26     4.3.0\n226 markdown           1.7        4.3.0\n227 MASS               7.3-60     4.3.0\n228 mathjaxr           1.6-0      4.3.0\n229 Matrix             1.5-4.1    4.3.0\n230 MatrixModels       0.5-1      4.3.0\n231 matrixStats        1.0.0      4.3.0\n232 memoise            2.0.1      4.3.0\n233 methods            4.3.0      4.3.0\n234 mgcv               1.8-42     4.3.0\n235 mime               0.12       4.3.0\n236 miniUI             0.1.1.1    4.3.0\n237 minqa              1.2.5      4.3.0\n238 mirt               1.39       4.3.0\n239 mitools            2.4        4.3.0\n240 modelr             0.1.11     4.3.0\n241 modelsummary       1.4.1      4.3.0\n242 munsell            0.5.0      4.3.0\n243 mvtnorm            1.2-2      4.3.0\n244 naniar             1.0.0      4.3.0\n245 nlme               3.1-162    4.3.0\n246 nloptr             2.0.3      4.3.0\n247 nnet               7.3-19     4.3.0\n248 norm               1.0-11.1   4.3.0\n249 numbers            0.8-5      4.3.0\n250 numDeriv           2016.8-1.1 4.3.0\n251 openssl            2.0.6      4.3.0\n252 openxlsx           4.2.5.2    4.3.0\n253 packrat            0.9.1      4.3.0\n254 pacman             0.5.1      4.3.0\n255 pagedown           0.20       4.3.0\n256 paletteer          1.5.0      4.3.0\n257 pander             0.6.5      4.3.0\n258 parallel           4.3.0      4.3.0\n259 parallelly         1.36.0     4.3.0\n260 parameters         0.21.1     4.3.0\n261 parsermd           0.1.2      4.3.0\n262 partitions         1.10-7     4.3.0\n263 pbapply            1.7-0      4.3.0\n264 pbkrtest           0.5.2      4.3.0\n265 performance        0.10.4     4.3.0\n266 permute            0.9-7      4.3.0\n267 pillar             1.9.0      4.3.0\n268 pkgbuild           1.4.1      4.3.0\n269 pkgconfig          2.0.3      4.3.0\n270 pkgdown            2.0.7      4.3.0\n271 pkgload            1.3.2      4.3.0\n272 plotly             4.10.2     4.3.0\n273 plyr               1.8.8      4.3.0\n274 png                0.1-8      4.3.0\n275 polyclip           1.10-4     4.3.0\n276 polynom            1.4-1      4.3.0\n277 praise             1.0.0      4.3.0\n278 PRcalc             0.7.0      4.3.0\n279 prediction         0.3.14     4.3.0\n280 prettyunits        1.1.1      4.3.0\n281 prismatic          1.1.1      4.3.0\n282 processx           3.8.1      4.3.0\n283 productplots       0.1.1      4.3.0\n284 profvis            0.3.8      4.3.0\n285 progress           1.2.2      4.3.0\n286 promises           1.2.0.1    4.3.0\n287 proxy              0.4-27     4.3.0\n288 pryr               0.1.6      4.3.0\n289 ps                 1.7.5      4.3.0\n290 psData             0.2.2      4.3.0\n291 purrr              1.0.1      4.3.0\n292 q2c                0.2.0      4.3.0\n293 quadprog           1.5-8      4.3.0\n294 qualtRics          3.1.7      4.3.0\n295 quantreg           5.95       4.3.0\n296 quarto             1.2        4.3.0\n297 R.cache            0.16.0     4.3.0\n298 R.methodsS3        1.8.2      4.3.0\n299 R.oo               1.25.0     4.3.0\n300 R.utils            2.12.2     4.3.0\n301 R6                 2.5.1      4.3.0\n302 ragg               1.2.5      4.3.0\n303 rapidjsonr         1.2.0      4.3.0\n304 rappdirs           0.3.3      4.3.0\n305 rapportools        1.1        4.3.0\n306 raster             3.6-20     4.3.0\n307 rbibutils          2.2.13     4.3.0\n308 rcmdcheck          1.4.0      4.3.0\n309 RColorBrewer       1.1-3      4.3.0\n310 Rcpp               1.0.10     4.3.0\n311 RcppArmadillo      0.12.4.1.0 4.3.0\n312 RcppEigen          0.3.3.9.3  4.3.0\n313 RcppParallel       5.1.7      4.3.0\n314 rdd                0.57       4.3.0\n315 rddensity          2.4        4.3.0\n316 Rdpack             2.4        4.3.0\n317 rdrobust           2.1.1      4.3.0\n318 reactable          0.4.4      4.3.0\n319 reactR             0.4.4      4.3.0\n320 readr              2.1.4      4.3.0\n321 readxl             1.4.2      4.3.0\n322 RefManageR         1.4.0      4.3.0\n323 rematch            1.0.1      4.3.0\n324 rematch2           2.1.2      4.3.0\n325 remotes            2.4.2      4.3.0\n326 renderthis         0.2.1      4.3.0\n327 renv               0.17.3     4.3.0\n328 reprex             2.0.2      4.3.0\n329 reshape            0.8.9      4.3.0\n330 reshape2           1.4.4      4.3.0\n331 rex                1.2.1      4.3.0\n332 rgeos              0.6-3      4.3.0\n333 rio                0.5.29     4.3.0\n334 rJava              1.0-6      4.3.0\n335 rlang              1.1.1      4.3.0\n336 rmapshaper         0.5.0      4.3.0\n337 rmarkdown          2.22       4.3.0\n338 rmdja              0.4.6.9    4.3.0\n339 rnaturalearth      0.3.3      4.3.0\n340 rnaturalearthdata  0.1.0      4.3.0\n341 rnaturalearthhires 0.2.1      4.3.0\n342 rootSolve          1.8.2.3    4.3.0\n343 roxygen2           7.2.3      4.3.0\n344 rpart              4.1.19     4.3.0\n345 rprojroot          2.0.3      4.3.0\n346 rqog               0.4.2023   4.3.0\n347 rsconnect          0.8.29     4.3.0\n348 rstan              2.21.8     4.3.0\n349 rstatix            0.7.2      4.3.0\n350 rstudioapi         0.14       4.3.0\n351 Rttf2pt1           1.3.12     4.3.0\n352 rversions          2.1.2      4.3.0\n353 rvest              1.0.3      4.3.0\n354 s2                 1.1.4      4.3.0\n355 sandwich           3.0-2      4.3.0\n356 sass               0.4.6      4.3.0\n357 scales             1.2.1      4.3.0\n358 selectr            0.4-2      4.3.0\n359 servr              0.27       4.3.0\n360 sessioninfo        1.2.2      4.3.0\n361 sets               1.0-24     4.3.0\n362 sf                 1.0-13     4.3.0\n363 sfheaders          0.4.3      4.3.0\n364 shades             1.4.0      4.3.0\n365 shiny              1.7.4      4.3.0\n366 shiny.i18n         0.3.0      4.3.0\n367 shinyBS            0.61.1     4.3.0\n368 shinydashboard     0.7.2      4.3.0\n369 shinyglide         0.1.4      4.3.0\n370 shinyjs            2.1.0      4.3.0\n371 shinythemes        1.2.0      4.3.0\n372 shinyuieditor      0.4.3      4.3.0\n373 shinyWidgets       0.7.6      4.3.0\n374 simex              1.8        4.3.0\n375 SimpleConjoint     0.1.1      4.3.0\n376 sjlabelled         1.2.0      4.3.0\n377 sortable           0.5.0      4.3.0\n378 sourcetools        0.1.7-1    4.3.0\n379 sp                 2.0-0      4.3.0\n380 SparseM            1.81       4.3.0\n381 spatial            7.3-16     4.3.0\n382 splines            4.3.0      4.3.0\n383 StanHeaders        2.26.27    4.3.0\n384 stargazer          5.2.3      4.3.0\n385 stats              4.3.0      4.3.0\n386 stats4             4.3.0      4.3.0\n387 stringdist         0.9.10     4.3.0\n388 stringi            1.7.12     4.3.0\n389 stringr            1.5.0      4.3.0\n390 styler             1.10.1     4.3.0\n391 summarytools       1.0.1      4.3.0\n392 support.CEs        0.5-0      4.3.0\n393 survey             4.2-1      4.3.0\n394 survival           3.5-5      4.3.0\n395 svglite            2.1.1      4.3.0\n396 sys                3.4.2      4.3.0\n397 systemfonts        1.0.4      4.3.0\n398 tables             0.9.17     4.3.0\n399 tcltk              4.3.0      4.3.0\n400 terra              1.7-39     4.3.0\n401 testthat           3.1.9      4.3.0\n402 textshaping        0.3.6      4.3.0\n403 tibble             3.2.1      4.3.0\n404 tidyfast           0.2.1      4.3.0\n405 tidygraph          1.2.3      4.3.0\n406 tidyr              1.3.0      4.3.0\n407 tidyselect         1.2.0      4.3.0\n408 tidyverse          2.0.0      4.3.0\n409 timechange         0.2.0      4.3.0\n410 tinytex            0.45       4.3.0\n411 titanic            0.1.0      4.3.0\n412 tools              4.3.0      4.3.0\n413 treemapify         2.5.5      4.3.0\n414 triebeard          0.4.1      4.3.0\n415 tweenr             2.0.2      4.3.0\n416 tzdb               0.4.0      4.3.0\n417 units              0.8-2      4.3.0\n418 UpSetR             1.4.0      4.3.0\n419 urlchecker         1.0.1      4.3.0\n420 urlshorteneR       1.5.7      4.3.0\n421 urltools           1.7.3      4.3.0\n422 usethis            2.2.1      4.3.0\n423 utf8               1.2.3      4.3.0\n424 utils              4.3.0      4.3.0\n425 uuid               1.1-0      4.3.0\n426 V8                 4.3.0      4.3.0\n427 vcd                1.4-11     4.3.0\n428 vctrs              0.6.3      4.3.0\n429 vdemdata           13.0       4.3.0\n430 vegan              2.6-4      4.3.0\n431 VGAM               1.1-8      4.3.0\n432 viridis            0.6.3      4.3.0\n433 viridisLite        0.4.2      4.3.0\n434 visdat             0.6.0      4.3.0\n435 vroom              1.6.3      4.3.0\n436 waldo              0.5.1      4.3.0\n437 webshot            0.5.4      4.3.0\n438 websocket          1.4.1      4.3.0\n439 whisker            0.4.1      4.3.0\n440 withr              2.5.0      4.3.0\n441 wk                 0.7.3      4.3.0\n442 woRdle             0.0.1      4.3.0\n443 xaringan           0.28       4.3.0\n444 xaringanExtra      0.7.0.9000 4.3.0\n445 xfun               0.39       4.3.0\n446 xlsx               0.6.5      4.3.0\n447 xlsxjars           0.6.1      4.3.0\n448 xml2               1.3.4      4.3.0\n449 xmlparsedata       1.0.5      4.3.0\n450 xopen              1.0.0      4.3.0\n451 xtable             1.8-4      4.3.0\n452 yaml               2.3.7      4.3.0\n453 zip                2.3.0      4.3.0\n454 zoo                1.8-12     4.3.0"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "参考文献",
    "section": "",
    "text": "Cattaneo, Matias D., Brigham R. Frandsen, and Rocío Titiunik. 2015.\n“Randomization Inference in the Regression Discontinuity Design:\nAn Application to the Study of Party Advantages in the u.s.\nSenate.” Journal of Causal Inference 3: 1–24.\n\n\nChambers, John M. 2016. Extending r. Boca Raton, FL: CRC Press.\n\n\nEfron, Bradley. 1979. “Bootstrap Methods: Another Look at the\nJackknife.” The Annals of Statistics 7: 1–26.\n\n\nGrolemund, Garrett, and Hadley Wickham. 2016. R for Data\nScience. O’Reilly.\n\n\nHartigan, J. A., and Beat Kleiner. 1984. “A Mosaic of Television\nRatings.” The American Statistician 38: 32–35.\n\n\nHeer, Jeffrey, and Michael Bostock. 2010. “Crowdsourcing Graphical\nPerception: Using Mechanical Turk to Assess Visualization\nDesign.” Proceedings of the SIGCHI Conference on Human\nFactors in Computing Systems.\n\n\nImbens, Guido, and Karthik Kalyanaraman. 2012. “Optimal Bandwidth\nChoice for the Regression Discontinuity Estimator.” The\nReview of Economic Studies 79: 933–59.\n\n\nInbar, Ohad, Noam Tractinsky, and Joachim Meyer. 2007. “Minimalism\nin Information Visualization: Attitudes Towards Maximizing the Data-Ink\nRatio.” In ECCE ’07: Proceedings of the 14th European\nConference on Cognitive Ergonomics: Invent! Explore!, 185–88.\n\n\nKuznicki, James T., and N. Bruce McCutcheon. 1979.\n“Cross-Enhancement of the Sour Taste on Single Human Taste\nPapillae.” Journal of Experimental Psychology: General\n108: 68–89.\n\n\nTufte, Edward R. 2001. The Visual Display of Quantitative\nInformation (2nd Ed.). Graphics Press.\n\n\nWickham, Hadley. 2014. “Tidy Data.” Journal of\nStatistical Software 59.\n\n\nWilkinson, Leland. 2005. The Grammar of Graphics. Springer."
  }
]